<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 85]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.RO](#cs.RO) [Total: 21]
- [cs.SD](#cs.SD) [Total: 12]
- [cs.HC](#cs.HC) [Total: 4]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 3]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 12]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [eess.AS](#eess.AS) [Total: 3]
- [eess.SY](#eess.SY) [Total: 3]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.CR](#cs.CR) [Total: 12]
- [stat.AP](#stat.AP) [Total: 2]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.DS](#cs.DS) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [stat.ML](#stat.ML) [Total: 7]
- [stat.ME](#stat.ME) [Total: 1]
- [q-bio.PE](#q-bio.PE) [Total: 1]
- [cs.CY](#cs.CY) [Total: 7]
- [math.OC](#math.OC) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.SP](#eess.SP) [Total: 3]
- [cs.DC](#cs.DC) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Main category: cs.AI

TL;DR: MEWI是一种三维多人模拟工具，用于模拟战场医疗撤离网络，提升教学效果和决策能力。


<details>
  <summary>Details</summary>
Motivation: 缺乏在课堂环境中模拟医疗撤离网络并评估规划和决策的工具。

Method: 开发基于Unity的MEWI模拟器，模拟战场约束和不确定性，并在两个场景中测试。

Result: MEWI显著提升了学员对医疗撤离知识的掌握和协作决策能力。

Conclusion: MEWI是高保真医疗教育工具的重要进步，对改进医疗撤离教育和操作具有关键意义。

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [2] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Main category: cs.AI

TL;DR: 本文介绍了Prompt Declaration Language (PDL)，一种新型提示表示方法，旨在解决LLM提示工程的复杂性，通过将提示置于核心位置，支持手动和自动提示调优，并整合规则代码和外部工具。


<details>
  <summary>Details</summary>
Motivation: 现有提示工程框架要么隐藏复杂性，要么提供不灵活的固定模式，限制了高级代理编程的可能性。

Method: 提出PDL，一种声明式语言，抽象化组合逻辑，支持提示调优和优化。

Result: 通过合规代理案例研究，PDL相比固定模式实现了高达4倍的性能提升。

Conclusion: PDL通过声明式表示和优化能力，显著提升了程序员的生产力和LLM应用的性能。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


### [3] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
*David Orban*

Main category: cs.AI

TL;DR: 论文研究了Jolting Technologies假说，提出AI能力发展可能呈现超指数增长（加速增长或正三阶导数），并通过蒙特卡洛模拟验证检测方法，为未来实证研究提供工具。


<details>
  <summary>Details</summary>
Motivation: 探索AI能力发展的超指数增长模式及其潜在影响，为AGI（通用人工智能）的出现提供理论基础和政策启示。

Method: 开发理论框架并通过蒙特卡洛模拟验证检测方法，分析缩短的创意到行动周期和迭代AI改进的复合效应。

Result: 建立了描述jolt动态的数学模型，并通过模拟验证了检测方法的有效性，为未来实证研究奠定基础。

Conclusion: 研究为理解AI发展轨迹及其对AGI的潜在影响提供了数学工具，对研究和政策制定具有重要启示。

Abstract: This paper investigates the Jolting Technologies Hypothesis, which posits
superexponential growth (increasing acceleration, or a positive third
derivative) in the development of AI capabilities. We develop a theoretical
framework and validate detection methodologies through Monte Carlo simulations,
while acknowledging that empirical validation awaits suitable longitudinal
data. Our analysis focuses on creating robust tools for future empirical
studies and exploring the potential implications should the hypothesis prove
valid. The study examines how factors such as shrinking idea-to-action
intervals and compounding iterative AI improvements drive this jolting pattern.
By formalizing jolt dynamics and validating detection methods through
simulation, this work provides the mathematical foundation necessary for
understanding potential AI trajectories and their consequences for AGI
emergence, offering insights for research and policy.

</details>


### [4] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 论文证明了q-辩证系统比p-辩证系统更强大，后者又比d-辩证系统更强，强调了反例和矛盾在自动信念修正中的互补作用。


<details>
  <summary>Details</summary>
Motivation: 研究辩证系统的不同模型，以解决文献中关于其相对能力的开放问题，并揭示反例和矛盾在信念修正中的作用。

Method: 通过数学证明比较q-、p-和d-辩证系统的能力，展示其层次关系。

Result: q-辩证系统严格强于p-辩证系统，而p-辩证系统又严格强于d-辩证系统。

Conclusion: 反例和矛盾在自动信念修正中具有互补作用，这对数学家和研究社区的推理过程有重要意义。

Abstract: Dialectical systems are a mathematical formalism for modeling an agent
updating a knowledge base seeking consistency. Introduced in the 1970s by
Roberto Magari, they were originally conceived to capture how a working
mathematician or a research community refines beliefs in the pursuit of truth.
Dialectical systems also serve as natural models for the belief change of an
automated agent, offering a unifying, computable framework for dynamic belief
management.
  The literature distinguishes three main models of dialectical systems:
(d-)dialectical systems based on revising beliefs when they are seen to be
inconsistent, p-dialectical systems based on revising beliefs based on finding
a counterexample, and q-dialectical systems which can do both. We answer an
open problem in the literature by proving that q-dialectical systems are
strictly more powerful than p-dialectical systems, which are themselves known
to be strictly stronger than (d-)dialectical systems. This result highlights
the complementary roles of counterexample and contradiction in automated belief
revision, and thus also in the reasoning processes of mathematicians and
research communities.

</details>


### [5] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 论文提出两种方法将SCC递归语义扩展到无限论证框架，并评估其性能，发现方向性在一般情况下失效，但在有限框架中部分语义满足方向性。


<details>
  <summary>Details</summary>
Motivation: 解决SCC递归语义在无限论证框架中的失效问题，推动无限论证理论的发展。

Method: 提出两种扩展SCC递归语义的方法，并基于Baroni和Giacomin的标准进行系统评估。

Result: 方向性在一般情况下失效，但在有限框架中部分语义满足方向性。

Conclusion: 研究结果为无限论证理论提供了基础，支持处理无界或动态领域的推理系统。

Abstract: Argumentation frameworks (AFs) are a foundational tool in artificial
intelligence for modeling structured reasoning and conflict. SCC-recursiveness
is a well-known design principle in which the evaluation of arguments is
decomposed according to the strongly connected components (SCCs) of the attack
graph, proceeding recursively from "higher" to "lower" components. While
SCC-recursive semantics such as \cft and \stgt have proven effective for finite
AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to
generalize reliably to infinite AFs due to issues with well-foundedness.
  We propose two approaches to extending SCC-recursiveness to the infinite
setting. We systematically evaluate these semantics using Baroni and Giacomin's
established criteria, showing in particular that directionality fails in
general. We then examine these semantics' behavior in finitary frameworks,
where we find some of our semantics satisfy directionality. These results
advance the theory of infinite argumentation and lay the groundwork for
reasoning systems capable of handling unbounded or evolving domains.

</details>


### [6] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

Main category: cs.AI

TL;DR: 论文提出了一种系统化的指令数据构建框架，通过分层标注、种子选择、数据合成和模型缺陷诊断，构建了高质量数据集InfinityInstruct-Subject，提升了模型的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 当前指令数据集虽规模庞大，但在复杂指令和罕见领域任务上表现不佳，主要因覆盖面和深度不足。

Method: 提出分层标注系统、种子选择算法、进化数据合成和模型缺陷诊断的闭环框架。

Result: 构建了包含150万指令的高质量数据集，实验证明其能有效提升模型性能。

Conclusion: 工作为指令数据集从数量扩张到质量提升提供了理论和实践基础。

Abstract: Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

</details>


### [7] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种动态旅行规划系统，通过三个协作代理解决传统系统的不足，显著提升了查询解析、导航精度和应对干扰的能力。


<details>
  <summary>Details</summary>
Motivation: 传统旅行规划系统静态且碎片化，无法应对现实世界的复杂性和突发干扰，导致用户体验不佳。

Method: 设计了三个协作代理：旅行规划代理（基于网格空间和地图分析）、目的地助手代理（精细导航）和本地发现代理（利用图像嵌入和RAG应对干扰）。

Result: 系统在查询解析、导航精度和干扰应对方面表现显著提升。

Conclusion: 该系统在从城市探索到应急响应等多个领域具有广泛应用前景。

Abstract: Traditional travel-planning systems are often static and fragmented, leaving
them ill-equipped to handle real-world complexities such as evolving
environmental conditions and unexpected itinerary disruptions. In this paper,
we identify three gaps between existing service providers causing frustrating
user experience: intelligent trip planning, precision "last-100-meter"
navigation, and dynamic itinerary adaptation. We propose three cooperative
agents: a Travel Planning Agent that employs grid-based spatial grounding and
map analysis to help resolve complex multi-modal user queries; a Destination
Assistant Agent that provides fine-grained guidance for the final navigation
leg of each journey; and a Local Discovery Agent that leverages image
embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to
trip plan disruptions. With evaluations and experiments, our system
demonstrates substantial improvements in query interpretation, navigation
accuracy, and disruption resilience, underscoring its promise for applications
from urban exploration to emergency response.

</details>


### [8] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

Main category: cs.AI

TL;DR: FR3E框架通过结构化探索提升LLM推理能力，解决RLVR的不稳定探索问题。


<details>
  <summary>Details</summary>
Motivation: RLVR提升LLM推理能力但存在探索不稳定问题。

Method: 提出FR3E框架，识别高不确定性决策点并进行针对性探索。

Result: 在数学推理基准测试中，FR3E提升训练稳定性、生成更长且连贯的回答，并增加完全正确轨迹比例。

Conclusion: FR3E通过结构化探索有效提升LLM推理能力。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning
abilities of Large Language Models (LLMs) but it struggles with unstable
exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a
structured exploration framework that identifies high-uncertainty decision
points in reasoning trajectories and performs targeted rollouts to construct
semantically grounded intermediate feedback. Our method provides targeted
guidance without relying on dense supervision. Empirical results on
mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable
training, produces longer and more coherent responses, and increases the
proportion of fully correct trajectories. These results highlight the
framework's effectiveness in improving LLM reasoning through more robust and
structured exploration.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
*Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju,Mohit Agarwal,Sławek Kwasiborski,Paramjit Sandhu,Patrick Siegler,Ahmet Iscen,Eyal Ben-David,Shiraz Butt,Miltos Allamanis,Seth Benjamin,Robert Busa-Fekete,Felix Hernandez-Campos,Sasha Goldshtein,Matt Dibb,Weiyang Zhang,Annie Marsden,Carey Radebaugh,Stephen Roller,Abhishek Nayyar,Jacob Austin,Tayfun Terzi,Bhargav Kanagal Shamanna,Pete Shaw,Aayush Singh,Florian Luisier,Artur Mendonça,Vaibhav Aggarwal,Larisa Markeeva,Claudio Fantacci,Sergey Brin,HyunJeong Choe,Guanyu Wang,Hartwig Adam,Avigail Dabush,Tatsuya Kiyono,Eyal Marcus,Jeremy Cole,Theophane Weber,Hongrae Lee,Ronny Huang,Alex Muzio,Leandro Kieliger,Maigo Le,Courtney Biles,Long Le,Archit Sharma,Chengrun Yang,Avery Lamp,Dave Dopson,Nate Hurley,Katrina,Xu,Zhihao Shan,Shuang Song,Jiewen Tan,Alexandre Senges,George Zhang,Chong You,Yennie Jun,David Raposo,Susanna Ricco,Xuan Yang,Weijie Chen,Prakhar Gupta,Arthur Szlam,Kevin Villela,Chun-Sung Ferng,Daniel Kasenberg,Chen Liang,Rui Zhu,Arunachalam Narayanaswamy,Florence Perot,Paul Pucciarelli,Anna Shekhawat,Alexey Stern,Rishikesh Ingale,Stefani Karp,Sanaz Bahargam,Adrian Goedeckemeyer,Jie Han,Sicheng Li,Andrea Tacchetti,Dian Yu,Abhishek Chakladar,Zhiying Zhang,Mona El Mahdy,Xu Gao,Dale Johnson,Samrat Phatale,AJ Piergiovanni,Hyeontaek Lim,Clement Farabet,Carl Lebsack,Theo Guidroz,John Blitzer,Nico Duduta,David Madras,Steve Li,Daniel von Dincklage,Xin Li,Mahdis Mahdieh,George Tucker,Ganesh Jawahar,Owen Xiao,Danny Tarlow,Robert Geirhos,Noam Velan,Daniel Vlasic,Kalesha Bullard,SK Park,Nishesh Gupta,Kellie Webster,Ayal Hitron,Jieming Mao,Julian Eisenschlos,Laurel Prince,Nina D'Souza,Kelvin Zheng,Sara Nasso,Gabriela Botea,Carl Doersch,Caglar Unlu,Chris Alberti,Alexey Svyatkovskiy,Ankita Goel,Krzysztof Choromanski,Pan-Pan Jiang,Richard Nguyen,Four Flynn,Daria Ćurko,Peter Chen,Nicholas Roth,Kieran Milan,Caleb Habtegebriel,Shashi Narayan,Michael Moffitt,Jake Marcus,Thomas Anthony,Brendan McMahan,Gowoon Cheon,Ruibo Liu,Megan Barnes,Lukasz Lew,Rebeca Santamaria-Fernandez,Mayank Upadhyay,Arjun Akula,Arnar Mar Hrafnkelsson,Alvaro Caceres,Andrew Bunner,Michal Sokolik,Subha Puttagunta,Lawrence Moore,Berivan Isik,Weilun Chen,Jay Hartford,Lawrence Chan,Pradeep Shenoy,Dan Holtmann-Rice,Jane Park,Fabio Viola,Alex Salcianu,Sujeevan Rajayogam,Ian Stewart-Binks,Zelin Wu,Richard Everett,Xi Xiong,Pierre-Antoine Manzagol,Gary Leung,Carl Saroufim,Bo Pang,Dawid Wegner,George Papamakarios,Jennimaria Palomaki,Helena Pankov,Guangda Lai,Guilherme Tubone,Shubin Zhao,Theofilos Strinopoulos,Seth Neel,Mingqiu Wang,Joe Kelley,Li Li,Pingmei Xu,Anitha Vijayakumar,Andrea D'olimpio,Omer Levy,Massimo Nicosia,Grigory Rozhdestvenskiy,Ni Lao,Sirui Xie,Yash Katariya,Jon Simon,Sanjiv Kumar,Florian Hartmann,Michael Kilgore,Jinhyuk Lee,Aroma Mahendru,Roman Ring,Tom Hennigan,Fiona Lang,Colin Cherry,David Steiner,Dawsen Hwang,Ray Smith,Pidong Wang,Jeremy Chen,Ming-Hsuan Yang,Sam Kwei,Philippe Schlattner,Donnie Kim,Ganesh Poomal Girirajan,Nikola Momchev,Ayushi Agarwal,Xingyi Zhou,Ilkin Safarli,Zachary Garrett,AJ Pierigiovanni,Sarthak Jauhari,Alif Raditya Rochman,Shikhar Vashishth,Quan Yuan,Christof Angermueller,Jon Blanton,Xinying Song,Nitesh Bharadwaj Gundavarapu,Thi Avrahami,Maxine Deines,Subhrajit Roy,Manish Gupta,Christopher Semturs,Shobha Vasudevan,Aditya Srikanth Veerubhotla,Shriya Sharma,Josh Jacob,Zhen Yang,Andreas Terzis,Dan Karliner,Auriel Wright,Tania Rojas-Esponda,Ashley Brown,Abhijit Guha Roy,Pawan Dogra,Andrei Kapishnikov,Peter Young,Wendy Kan,Vinodh Kumar Rajendran,Maria Ivanova,Salil Deshmukh,Chia-Hua Ho,Mike Kwong,Stav Ginzburg,Annie Louis,KP Sawhney,Slav Petrov,Jing Xie,Yunfei Bai,Georgi Stoyanov,Alex Fabrikant,Rajesh Jayaram,Yuqi Li,Joe Heyward,Justin Gilmer,Yaqing Wang,Radu Soricut,Luyang Liu,Qingnan Duan,Jamie Hayes,Maura O'Brien,Gaurav Singh Tomar,Sivan Eiger,Bahar Fatemi,Jeffrey Hui,Catarina Barros,Adaeze Chukwuka,Alena Butryna,Saksham Thakur,Austin Huang,Zhufeng Pan,Haotian Tang,Serkan Cabi,Tulsee Doshi,Michiel Bakker,Sumit Bagri,Ruy Ley-Wild,Adam Lelkes,Jennie Lees,Patrick Kane,David Greene,Shimu Wu,Jörg Bornschein,Gabriela Surita,Sarah Hodkinson,Fangtao Li,Chris Hidey,Sébastien Pereira,Sean Ammirati,Phillip Lippe,Adam Kraft,Pu Han,Sebastian Gerlach,Zifeng Wang,Liviu Panait,Feng Han,Brian Farris,Yingying Bi,Hannah DeBalsi,Miaosen Wang,Gladys Tyen,James Cohan,Susan Zhang,Jarred Barber,Da-Woon Chung,Jaeyoun Kim,Markus Kunesch,Steven Pecht,Nami Akazawa,Abe Friesen,James Lyon,Ali Eslami,Junru Wu,Jie Tan,Yue Song,Ravi Kumar,Chris Welty,Ilia Akolzin,Gena Gibson,Sean Augenstein,Arjun Pillai,Nancy Yuen,Du Phan,Xin Wang,Iain Barr,Heiga Zen,Nan Hua,Casper Liu,Jilei,Wang,Tanuj Bhatia,Hao Xu,Oded Elyada,Pushmeet Kohli,Mirek Olšák,Ke Chen,Azalia Mirhoseini,Noam Shazeer,Shoshana Jakobovits,Maggie Tran,Nolan Ramsden,Tarun Bharti,Fred Alcober,Yunjie Li,Shilpa Shetty,Jing Chen,Dmitry Kalashnikov,Megha Nawhal,Sercan Arik,Hanwen Chen,Michiel Blokzijl,Shubham Gupta,James Rubin,Rigel Swavely,Sophie Bridgers,Ian Gemp,Chen Su,Arun Suggala,Juliette Pluto,Mary Cassin,Alain Vaucher,Kaiyang Ji,Jiahao Cai,Andrew Audibert,Animesh Sinha,David Tian,Efrat Farkash,Amy Hua,Jilin Chen,Duc-Hieu Tran,Edward Loper,Nicole Brichtova,Lara McConnaughey,Ballie Sandhu,Robert Leland,Doug DeCarlo,Andrew Over,James Huang,Xing Wu,Connie Fan,Eric Li,Yun Lei,Deepak Sharma,Cosmin Paduraru,Luo Yu,Matko Bošnjak,Phuong Dao,Min Choi,Sneha Kudugunta,Jakub Adamek,Carlos Guía,Ali Khodaei,Jie Feng,Wenjun Zeng,David Welling,Sandeep Tata,Christina Butterfield,Andrey Vlasov,Seliem El-Sayed,Swaroop Mishra,Tara Sainath,Shentao Yang,RJ Skerry-Ryan,Jeremy Shar,Robert Berry,Arunkumar Rajendran,Arun Kandoor,Andrea Burns,Deepali Jain,Tom Stone,Wonpyo Park,Shibo Wang,Albin Cassirer,Guohui Wang,Hayato Kobayashi,Sergey Rogulenko,Vineetha Govindaraj,Mikołaj Rybiński,Nadav Olmert,Colin Evans,Po-Sen Huang,Kelvin Xu,Premal Shah,Terry Thurk,Caitlin Sikora,Mu Cai,Jin Xie,Elahe Dabir,Saloni Shah,Norbert Kalb,Carrie Zhang,Shruthi Prabhakara,Amit Sabne,Artiom Myaskovsky,Vikas Raunak,Blanca Huergo,Behnam Neyshabur,Jon Clark,Ye Zhang,Shankar Krishnan,Eden Cohen,Dinesh Tewari,James Lottes,Yumeya Yamamori,Hui,Li,Mohamed Elhawaty,Ada Maksutaj Oflazer,Adrià Recasens,Sheryl Luo,Duy Nguyen,Taylor Bos,Kalyan Andra,Ana Salazar,Ed Chi,Jeongwoo Ko,Matt Ginsberg,Anders Andreassen,Anian Ruoss,Todor Davchev,Elnaz Davoodi,Chenxi Liu,Min Kim,Santiago Ontanon,Chi Ming To,Dawei Jia,Rosemary Ke,Jing Wang,Anna Korsun,Moran Ambar,Ilya Kornakov,Irene Giannoumis,Toni Creswell,Denny Zhou,Yi Su,Ishaan Watts,Aleksandr Zaks,Evgenii Eltyshev,Ziqiang Feng,Sidharth Mudgal,Alex Kaskasoli,Juliette Love,Kingshuk Dasgupta,Sam Shleifer,Richard Green,Sungyong Seo,Chansoo Lee,Dale Webster,Prakash Shroff,Ganna Raboshchuk,Isabel Leal,James Manyika,Sofia Erell,Daniel Murphy,Zhisheng Xiao,Anton Bulyenov,Julian Walker,Mark Collier,Matej Kastelic,Nelson George,Sushant Prakash,Sailesh Sidhwani,Alexey Frolov,Steven Hansen,Petko Georgiev,Tiberiu Sosea,Chris Apps,Aishwarya Kamath,David Reid,Emma Cooney,Charlotte Magister,Oriana Riva,Alec Go,Pu-Chin Chen,Sebastian Krause,Nir Levine,Marco Fornoni,Ilya Figotin,Nick Roy,Parsa Mahmoudieh,Vladimir Magay,Mukundan Madhavan,Jin Miao,Jianmo Ni,Yasuhisa Fujii,Ian Chou,George Scrivener,Zak Tsai,Siobhan Mcloughlin,Jeremy Selier,Sandra Lefdal,Jeffrey Zhao,Abhijit Karmarkar,Kushal Chauhan,Shivanker Goel,Zhaoyi Zhang,Vihan Jain,Parisa Haghani,Mostafa Dehghani,Jacob Scott,Erin Farnese,Anastasija Ilić,Steven Baker,Julia Pawar,Li Zhong,Josh Camp,Yoel Zeldes,Shravya Shetty,Anand Iyer,Vít Listík,Jiaxian Guo,Luming Tang,Mark Geller,Simon Bucher,Yifan Ding,Hongzhi Shi,Carrie Muir,Dominik Grewe,Ramy Eskander,Octavio Ponce,Boqing Gong,Derek Gasaway,Samira Khan,Umang Gupta,Angelos Filos,Weicheng Kuo,Klemen Kloboves,Jennifer Beattie,Christian Wright,Leon Li,Alicia Jin,Sandeep Mariserla,Miteyan Patel,Jens Heitkaemper,Dilip Krishnan,Vivek Sharma,David Bieber,Christian Frank,John Lambert,Paul Caron,Martin Polacek,Mai Giménez,Himadri Choudhury,Xing Yu,Sasan Tavakkol,Arun Ahuja,Franz Och,Rodolphe Jenatton,Wojtek Skut,Bryan Richter,David Gaddy,Andy Ly,Misha Bilenko,Megh Umekar,Ethan Liang,Martin Sevenich,Mandar Joshi,Hassan Mansoor,Rebecca Lin,Sumit Sanghai,Abhimanyu Singh,Xiaowei Li,Sudheendra Vijayanarasimhan,Zaheer Abbas,Yonatan Bitton,Hansa Srinivasan,Manish Reddy Vuyyuru,Alexander Frömmgen,Yanhua Sun,Ralph Leith,Alfonso Castaño,DJ Strouse,Le Yan,Austin Kyker,Satish Kambala,Mary Jasarevic,Thibault Sellam,Chao Jia,Alexander Pritzel,Raghavender R,Huizhong Chen,Natalie Clay,Sudeep Gandhe,Sean Kirmani,Sayna Ebrahimi,Hannah Kirkwood,Jonathan Mallinson,Chao Wang,Adnan Ozturel,Kuo Lin,Shyam Upadhyay,Vincent Cohen-Addad,Sean Purser-haskell,Yichong Xu,Ebrahim Songhori,Babi Seal,Alberto Magni,Almog Gueta,Tingting Zou,Guru Guruganesh,Thais Kagohara,Hung Nguyen,Khalid Salama,Alejandro Cruzado Ruiz,Justin Frye,Zhenkai Zhu,Matthias Lochbrunner,Simon Osindero,Wentao Yuan,Lisa Lee,Aman Prasad,Lam Nguyen Thiet,Daniele Calandriello,Victor Stone,Qixuan Feng,Han Ke,Maria Voitovich,Geta Sampemane,Lewis Chiang,Ling Wu,Alexander Bykovsky,Matt Young,Luke Vilnis,Ishita Dasgupta,Aditya Chawla,Qin Cao,Bowen Liang,Daniel Toyama,Szabolcs Payrits,Anca Stefanoiu,Dimitrios Vytiniotis,Ankesh Anand,Tianxiao Shen,Blagoj Mitrevski,Michael Tschannen,Sreenivas Gollapudi,Aishwarya P S,José Leal,Zhe Shen,Han Fu,Wei Wang,Arvind Kannan,Doron Kukliansky,Sergey Yaroshenko,Svetlana Grant,Umesh Telang,David Wood,Alexandra Chronopoulou,Alexandru Ţifrea,Tao Zhou,Tony,Nguy\~ên,Muge Ersoy,Anima Singh,Meiyan Xie,Emanuel Taropa,Woohyun Han,Eirikur Agustsson,Andrei Sozanschi,Hui Peng,Alex Chen,Yoel Drori,Efren Robles,Yang Gao,Xerxes Dotiwalla,Ying Chen,Anudhyan Boral,Alexei Bendebury,John Nham,Chris Tar,Luis Castro,Jiepu Jiang,Canoee Liu,Felix Halim,Jinoo Baek,Andy Wan,Jeremiah Liu,Yuan Cao,Shengyang Dai,Trilok Acharya,Ruoxi Sun,Fuzhao Xue,Saket Joshi,Morgane Lustman,Yongqin Xian,Rishabh Joshi,Deep Karkhanis,Nora Kassner,Jamie Hall,Xiangzhuo Ding,Gan Song,Gang Li,Chen Zhu,Yana Kulizhskaya,Bin Ni,Alexey Vlaskin,Solomon Demmessie,Lucio Dery,Salah Zaiem,Yanping Huang,Cindy Fan,Felix Gimeno,Ananth Balashankar,Koji Kojima,Hagai Taitelbaum,Maya Meng,Dero Gharibian,Sahil Singla,Wei Chen,Ambrose Slone,Guanjie Chen,Sujee Rajayogam,Max Schumacher,Suyog Kotecha,Rory Blevins,Qifei Wang,Mor Hazan Taege,Alex Morris,Xin Liu,Fayaz Jamil,Richard Zhang,Pratik Joshi,Ben Ingram,Tyler Liechty,Ahmed Eleryan,Scott Baird,Alex Grills,Gagan Bansal,Shan Han,Kiran Yalasangi,Shawn Xu,Majd Al Merey,Isabel Gao,Felix Weissenberger,Igor Karpov,Robert Riachi,Ankit Anand,Gautam Prasad,Kay Lamerigts,Reid Hayes,Jamie Rogers,Mandy Guo,Ashish Shenoy,Qiong,Hu,Kyle He,Yuchen Liu,Polina Zablotskaia,Sagar Gubbi,Yifan Chang,Jay Pavagadhi,Kristian Kjems,Archita Vadali,Diego Machado,Yeqing Li,Renshen Wang,Dipankar Ghosh,Aahil Mehta,Dana Alon,George Polovets,Alessio Tonioni,Nate Kushman,Joel D'sa,Lin Zhuo,Allen Wu,Rohin Shah,John Youssef,Jiayu Ye,Justin Snyder,Karel Lenc,Senaka Buthpitiya,Matthew Tung,Jichuan Chang,Tao Chen,David Saxton,Jenny Lee,Lydia Lihui Zhang,James Qin,Prabakar Radhakrishnan,Maxwell Chen,Piotr Ambroszczyk,Metin Toksoz-Exley,Yan Zhong,Nitzan Katz,Brendan O'Donoghue,Tamara von Glehn,Adi Gerzi Rosenthal,Aga Świetlik,Xiaokai Zhao,Nick Fernando,Jinliang Wei,Jieru Mei,Sergei Vassilvitskii,Diego Cedillo,Pranjal Awasthi,Hui Zheng,Koray Kavukcuoglu,Itay Laish,Joseph Pagadora,Marc Brockschmidt,Christopher A. Choquette-Choo,Arunkumar Byravan,Yifeng Lu,Xu Chen,Mia Chen,Kenton Lee,Rama Pasumarthi,Sijal Bhatnagar,Aditya Shah,Qiyin Wu,Zhuoyuan Chen,Zack Nado,Bartek Perz,Zixuan Jiang,David Kao,Ganesh Mallya,Nino Vieillard,Lantao Mei,Sertan Girgin,Mandy Jordan,Yeongil Ko,Alekh Agarwal,Yaxin Liu,Yasemin Altun,Raoul de Liedekerke,Anastasios Kementsietsidis,Daiyi Peng,Dangyi Liu,Utku Evci,Peter Humphreys,Austin Tarango,Xiang Deng,Yoad Lewenberg,Kevin Aydin,Chengda Wu,Bhavishya Mittal,Tsendsuren Munkhdalai,Kleopatra Chatziprimou,Rodrigo Benenson,Uri First,Xiao Ma,Jinning Li,Armand Joulin,Hamish Tomlinson,Tingnan Zhang,Milad Nasr,Zhi Hong,Michaël Sander,Lisa Anne Hendricks,Anuj Sharma,Andrew Bolt,Eszter Vértes,Jiri Simsa,Tomer Levinboim,Olcan Sercinoglu,Divyansh Shukla,Austin Wu,Craig Swanson,Danny Vainstein,Fan Bu,Bo Wang,Ryan Julian,Charles Yoon,Sergei Lebedev,Antonious Girgis,Bernd Bandemer,David Du,Todd Wang,Xi Chen,Ying Xiao,Peggy Lu,Natalie Ha,Vlad Ionescu,Simon Rowe,Josip Matak,Federico Lebron,Andreas Steiner,Lalit Jain,Manaal Faruqui,Nicolas Lacasse,Georgie Evans,Neesha Subramaniam,Dean Reich,Giulia Vezzani,Aditya Pandey,Joe Stanton,Tianhao Zhou,Liam McCafferty,Henry Griffiths,Verena Rieser,Soheil Hassas Yeganeh,Eleftheria Briakou,Lu Huang,Zichuan Wei,Liangchen Luo,Erik Jue,Gabby Wang,Victor Cotruta,Myriam Khan,Jongbin Park,Qiuchen Guo,Peiran Li,Rong Rong,Diego Antognini,Anastasia Petrushkina,Chetan Tekur,Eli Collins,Parul Bhatia,Chester Kwak,Wenhu Chen,Arvind Neelakantan,Immanuel Odisho,Sheng Peng,Vincent Nallatamby,Vaibhav Tulsyan,Fabian Pedregosa,Peng Xu,Raymond Lin,Yulong Wang,Emma Wang,Sholto Douglas,Reut Tsarfaty,Elena Gribovskaya,Renga Aravamudhan,Manu Agarwal,Mara Finkelstein,Qiao Zhang,Elizabeth Cole,Phil Crone,Sarmishta Velury,Anil Das,Chris Sauer,Luyao Xu,Danfeng Qin,Chenjie Gu,Dror Marcus,CJ Zheng,Wouter Van Gansbeke,Sobhan Miryoosefi,Haitian Sun,YaGuang Li,Charlie Chen,Jae Yoo,Pavel Dubov,Alex Tomala,Adams Yu,Paweł Wesołowski,Alok Gunjan,Eddie Cao,Jiaming Luo,Nikhil Sethi,Arkadiusz Socala,Laura Graesser,Tomas Kocisky,Arturo BC,Minmin Chen,Edward Lee,Sophie Wang,Weize Kong,Qiantong Xu,Nilesh Tripuraneni,Yiming Li,Xinxin Yu,Allen Porter,Paul Voigtlaender,Biao Zhang,Arpi Vezer,Sarah York,Qing Wei,Geoffrey Cideron,Mark Kurzeja,Seungyeon Kim,Benny Li,Angéline Pouget,Hyo Lee,Kaspar Daugaard,Yang Li,Dave Uthus,Aditya Siddhant,Paul Cavallaro,Sriram Ganapathy,Maulik Shah,Rolf Jagerman,Jeff Stanway,Piermaria Mendolicchio,Li Xiao,Kayi Lee,Tara Thompson,Shubham Milind Phal,Jason Chase,Sun Jae Lee,Adrian N Reyes,Disha Shrivastava,Zhen Qin,Roykrong Sukkerd,Seth Odoom,Lior Madmoni,John Aslanides,Jonathan Herzig,Elena Pochernina,Sheng Zhang,Parker Barnes,Daisuke Ikeda,Qiujia Li,Shuo-yiin Chang,Shakir Mohamed,Jim Sproch,Richard Powell,Bidisha Samanta,Domagoj Ćevid,Anton Kovsharov,Shrestha Basu Mallick,Srinivas Tadepalli,Anne Zheng,Kareem Ayoub,Andreas Noever,Christian Reisswig,Zhuo Xu,Junhyuk Oh,Martin Matysiak,Tim Blyth,Shereen Ashraf,Julien Amelot,Boone Severson,Michele Bevilacqua,Motoki Sano,Ethan Dyer,Ofir Roval,Anu Sinha,Yin Zhong,Sagi Perel,Tea Sabolić,Johannes Mauerer,Willi Gierke,Mauro Verzetti,Rodrigo Cabrera,Alvin Abdagic,Steven Hemingray,Austin Stone,Jong Lee,Farooq Ahmad,Karthik Raman,Lior Shani,Jonathan Lai,Orhan Firat,Nathan Waters,Eric Ge,Mo Shomrat,Himanshu Gupta,Rajeev Aggarwal,Tom Hudson,Bill Jia,Simon Baumgartner,Palak Jain,Joe Kovac,Junehyuk Jung,Ante Žužul,Will Truong,Morteza Zadimoghaddam,Songyou Peng,Marco Liang,Rachel Sterneck,Balaji Lakshminarayanan,Machel Reid,Oliver Woodman,Tong Zhou,Jianling Wang,Vincent Coriou,Arjun Narayanan,Jay Hoover,Yenai Ma,Apoorv Jindal,Clayton Sanford,Doug Reid,Swaroop Ramaswamy,Alex Kurakin,Roland Zimmermann,Yana Lunts,Dragos Dena,Zalán Borsos,Vered Cohen,Shujian Zhang,Will Grathwohl,Robert Dadashi,Morgan Redshaw,Joshua Kessinger,Julian Odell,Silvano Bonacina,Zihang Dai,Grace Chen,Ayush Dubey,Pablo Sprechmann,Mantas Pajarskas,Wenxuan Zhou,Niharika Ahuja,Tara Thomas,Martin Nikoltchev,Matija Kecman,Bharath Mankalale,Andrey Ryabtsev,Jennifer She,Christian Walder,Jiaming Shen,Lu Li,Carolina Parada,Sheena Panthaplackel,Okwan Kwon,Matt Lawlor,Utsav Prabhu,Yannick Schroecker,Marc'aurelio Ranzato,Pete Blois,Iurii Kemaev,Ting Yu,Dmitry,Lepikhin,Hao Xiong,Sahand Sharifzadeh,Oleaser Johnson,Jeremiah Willcock,Rui Yao,Greg Farquhar,Sujoy Basu,Hidetoshi Shimokawa,Nina Anderson,Haiguang Li,Khiem Pham,Yizhong Liang,Sebastian Borgeaud,Alexandre Moufarek,Hideto Kazawa,Blair Kutzman,Marcin Sieniek,Sara Smoot,Ruth Wang,Natalie Axelsson,Nova Fallen,Prasha Sundaram,Yuexiang Zhai,Varun Godbole,Petros Maniatis,Alek Wang,Ilia Shumailov,Santhosh Thangaraj,Remi Crocker,Nikita Gupta,Gang Wu,Phil Chen,Gellért Weisz,Celine Smith,Mojtaba Seyedhosseini,Boya Fang,Xiyang Luo,Roey Yogev,Zeynep Cankara,Andrew Hard,Helen Ran,Rahul Sukthankar,George Necula,Gaël Liu,Honglong Cai,Praseem Banzal,Daniel Keysers,Sanjay Ghemawat,Connie Tao,Emma Dunleavy,Aditi Chaudhary,Wei Li,Maciej Mikuła,Chen-Yu Lee,Tiziana Refice,Krishna Somandepalli,Alexandre Fréchette,Dan Bahir,John Karro,Keith Rush,Sarah Perrin,Bill Rosgen,Xiaomeng Yang,Clara Huiyi Hu,Mahmoud Alnahlawi,Justin Mao-Jones,Roopal Garg,Hoang Nguyen,Bat-Orgil Batsaikhan,Iñaki Iturrate,Anselm Levskaya,Avi Singh,Ashyana Kachra,Tony Lu,Denis Petek,Zheng Xu,Mark Graham,Lukas Zilka,Yael Karov,Marija Kostelac,Fangyu Liu,Yaohui Guo,Weiyue Wang,Bernd Bohnet,Emily Pitler,Tony Bruguier,Keisuke Kinoshita,Chrysovalantis Anastasiou,Nilpa Jha,Ting Liu,Jerome Connor,Phil Wallis,Philip Pham,Eric Bailey,Shixin Li,Heng-Tze Cheng,Sally Ma,Haiqiong Li,Akanksha Maurya,Kate Olszewska,Manfred Warmuth,Christy Koh,Dominik Paulus,Siddhartha Reddy Jonnalagadda,Enrique Piqueras,Ali Elqursh,Geoff Brown,Hadar Shemtov,Loren Maggiore,Fei Xia,Ryan Foley,Beka Westberg,George van den Driessche,Livio Baldini Soares,Arjun Kar,Michael Quinn,Siqi Zuo,Jialin Wu,Kyle Kastner,Anna Bortsova,Aijun Bai,Ales Mikhalap,Luowei Zhou,Jennifer Brennan,Vinay Ramasesh,Honglei Zhuang,John Maggs,Johan Schalkwyk,Yuntao Xu,Hui Huang,Andrew Howard,Sasha Brown,Linting Xue,Gloria Shen,Brian Albert,Neha Jha,Daniel Zheng,Varvara Krayvanova,Spurthi Amba Hombaiah,Olivier Lacombe,Gautam Vasudevan,Dan Graur,Tian Xie,Meet Gandhi,Bangju Wang,Dustin Zelle,Harman Singh,Dahun Kim,Sébastien Cevey,Victor Ungureanu,Natasha Noy,Fei Liu,Annie Xie,Fangxiaoyu Feng,Katerina Tsihlas,Daniel Formoso,Neera Vats,Quentin Wellens,Yinan Wang,Niket Kumar Bhumihar,Samrat Ghosh,Matt Hoffman,Tom Lieber,Oran Lang,Kush Bhatia,Tom Paine,Aroonalok Pyne,Ronny Votel,Madeleine Clare Elish,Benoit Schillings,Alex Panagopoulos,Haichuan Yang,Adam Raveret,Zohar Yahav,Shuang Liu,Warren Chen,Dalia El Badawy,Nishant Agrawal,Mohammed Badawi,Mahdi Mirzazadeh,Carla Bromberg,Fan Ye,Chang Liu,Tatiana Sholokhova,George-Cristian Muraru,Gargi Balasubramaniam,Jonathan Malmaud,Alen Carin,Danilo Martins,Irina Jurenka,Pankil Botadra,Dave Lacey,Richa Singh,Mariano Schain,Dan Zheng,Isabelle Guyon,Victor Lavrenko,Seungji Lee,Xiang Zhou,Demis Hassabis,Jeshwanth Challagundla,Derek Cheng,Nikhil Mehta,Matthew Mauger,Michela Paganini,Pushkar Mishra,Kate Lee,Zhang Li,Lexi Baugher,Ondrej Skopek,Max Chang,Amir Zait,Gaurav Menghani,Lizzetth Bellot,Guangxing Han,Jean-Michel Sarr,Sharat Chikkerur,Himanshu Sahni,Rohan Anil,Arun Narayanan,Chandu Thekkath,Daniele Pighin,Hana Strejček,Marko Velic,Fred Bertsch,Manuel Tragut,Keran Rong,Alicia Parrish,Kai Bailey,Jiho Park,Isabela Albuquerque,Abhishek Bapna,Rajesh Venkataraman,Alec Kosik,Johannes Griesser,Zhiwei Deng,Alek Andreev,Qingyun Dou,Kevin Hui,Fanny Wei,Xiaobin Yu,Lei Shu,Avia Aharon,David Barker,Badih Ghazi,Sebastian Flennerhag,Chris Breaux,Yuchuan Liu,Matthew Bilotti,Josh Woodward,Uri Alon,Stephanie Winkler,Tzu-Kuo Huang,Kostas Andriopoulos,João Gabriel Oliveira,Penporn Koanantakool,Berkin Akin,Michael Wunder,Cicero Nogueira dos Santos,Mohammad Hossein Bateni,Lin Yang,Dan Horgan,Beer Changpinyo,Keyvan Amiri,Min Ma,Dayeong Lee,Lihao Liang,Anirudh Baddepudi,Tejasi Latkar,Raia Hadsell,Jun Xu,Hairong Mu,Michael Han,Aedan Pope,Snchit Grover,Frank Kim,Ankit Bhagatwala,Guan Sun,Yamini Bansal,Amir Globerson,Alireza Nazari,Samira Daruki,Hagen Soltau,Jane Labanowski,Laurent El Shafey,Matt Harvey,Yanif Ahmad,Elan Rosenfeld,William Kong,Etienne Pot,Yi-Xuan Tan,Aurora Wei,Victoria Langston,Marcel Prasetya,Petar Veličković,Richard Killam,Robin Strudel,Darren Ni,Zhenhai Zhu,Aaron Archer,Kavya Kopparapu,Lynn Nguyen,Emilio Parisotto,Hussain Masoom,Sravanti Addepalli,Jordan Grimstad,Hexiang Hu,Joss Moore,Avinatan Hassidim,Le Hou,Mukund Raghavachari,Jared Lichtarge,Adam R. Brown,Hilal Dib,Natalia Ponomareva,Justin Fu,Yujing Zhang,Altaf Rahman,Joana Iljazi,Edouard Leurent,Gabriel Dulac-Arnold,Cosmo Du,Chulayuth Asawaroengchai,Larry Jin,Ela Gruzewska,Ziwei Ji,Benigno Uria,Daniel De Freitas,Paul Barham,Lauren Beltrone,Víctor Campos,Jun Yan,Neel Kovelamudi,Arthur Nguyen,Elinor Davies,Zhichun Wu,Zoltan Egyed,Kristina Toutanova,Nithya Attaluri,Hongliang Fei,Peter Stys,Siddhartha Brahma,Martin Izzard,Siva Velusamy,Scott Lundberg,Vincent Zhuang,Kevin Sequeira,Adam Santoro,Ehsan Amid,Ophir Aharoni,Shuai Ye,Mukund Sundararajan,Lijun Yu,Yu-Cheng Ling,Stephen Spencer,Hugo Song,Josip Djolonga,Christo Kirov,Sonal Gupta,Alessandro Bissacco,Clemens Meyer,Mukul Bhutani,Andrew Dai,Weiyi Wang,Siqi Liu,Ashwin Sreevatsa,Qijun Tan,Maria Wang,Lucy Kim,Yicheng Wang,Alex Irpan,Yang Xiao,Stanislav Fort,Yifan He,Alex Gurney,Bryan Gale,Yue Ma,Monica Roy,Viorica Patraucean,Taylan Bilal,Golnaz Ghiasi,Anahita Hosseini,Melvin Johnson,Zhuowan Li,Yi Tay,Benjamin Beyret,Katie Millican,Josef Broder,Mayank Lunayach,Danny Swisher,Eugen Vušak,David Parkinson,MH Tessler,Adi Mayrav Gilady,Richard Song,Allan Dafoe,Yves Raimond,Masa Yamaguchi,Itay Karo,Elizabeth Nielsen,Kevin Kilgour,Mike Dusenberry,Rajiv Mathews,Jiho Choi,Siyuan Qiao,Harsh Mehta,Sahitya Potluri,Chris Knutsen,Jialu Liu,Tat Tan,Kuntal Sengupta,Keerthana Gopalakrishnan,Abodunrinwa Toki,Mencher Chiang,Mike Burrows,Grace Vesom,Zafarali Ahmed,Ilia Labzovsky,Siddharth Vashishtha,Preeti Singh,Ankur Sharma,Ada Ma,Jinyu Xie,Pranav Talluri,Hannah Forbes-Pollard,Aarush Selvan,Joel Wee,Loic Matthey,Tom Funkhouser,Parthasarathy Gopavarapu,Lev Proleev,Cheng Li,Matt Thomas,Kashyap Kolipaka,Zhipeng Jia,Ashwin Kakarla,Srinivas Sunkara,Joan Puigcerver,Suraj Satishkumar Sheth,Emily Graves,Chen Wang,Sadh MNM Khan,Kai Kang,Shyamal Buch,Fred Zhang,Omkar Savant,David Soergel,Kevin Lee,Linda Friso,Xuanyi Dong,Rahul Arya,Shreyas Chandrakaladharan,Connor Schenck,Greg Billock,Tejas Iyer,Anton Bakalov,Leslie Baker,Alex Ruiz,Angad Chandorkar,Trieu Trinh,Matt Miecnikowski,Yanqi Zhou,Yangsibo Huang,Jiazhong Nie,Ali Shah,Ashish Thapliyal,Sam Haves,Lun Wang,Uri Shaham,Patrick Morris-Suzuki,Soroush Radpour,Leonard Berrada,Thomas Strohmann,Chaochao Yan,Jingwei Shen,Sonam Goenka,Tris Warkentin,Petar Dević,Dan Belov,Albert Webson,Madhavi Yenugula,Puranjay Datta,Jerry Chang,Nimesh Ghelani,Aviral Kumar,Vincent Perot,Jessica Lo,Yang Song,Herman Schmit,Jianmin Chen,Vasilisa Bashlovkina,Xiaoyue Pan,Diana Mincu,Paul Roit,Isabel Edkins,Andy Davis,Yujia Li,Ben Horn,Xinjian Li,Pradeep Kumar S,Eric Doi,Wanzheng Zhu,Sri Gayatri Sundara Padmanabhan,Siddharth Verma,Jasmine Liu,Heng Chen,Mihajlo Velimirović,Malcolm Reynolds,Priyanka Agrawal,Nick Sukhanov,Abhinit Modi,Siddharth Goyal,John Palowitch,Nima Khajehnouri,Wing Lowe,David Klinghoffer,Sharon Silver,Vinh Tran,Candice Schumann,Francesco Piccinno,Xi Liu,Mario Lučić,Xiaochen Yang,Sandeep Kumar,Ajay Kannan,Ragha Kotikalapudi,Mudit Bansal,Fabian Fuchs,Javad Hosseini,Abdelrahman Abdelhamed,Dawn Bloxwich,Tianhe Yu,Ruoxin Sang,Gregory Thornton,Karan Gill,Yuchi Liu,Virat Shejwalkar,Jason Lin,Zhipeng Yan,Kehang Han,Thomas Buschmann,Michael Pliskin,Zhi Xing,Susheel Tatineni,Junlin Zhang,Sissie Hsiao,Gavin Buttimore,Marcus Wu,Zefei Li,Geza Kovacs,Legg Yeung,Tao Huang,Aaron Cohen,Bethanie Brownfield,Averi Nowak,Mikel Rodriguez,Tianze Shi,Hado van Hasselt,Kevin Cen,Deepanway Ghoshal,Kushal Majmundar,Weiren Yu,Warren,Chen,Danila Sinopalnikov,Hao Zhang,Vlado Galić,Di Lu,Zeyu Zheng,Maggie Song,Gary Wang,Gui Citovsky,Swapnil Gawde,Isaac Galatzer-Levy,David Silver,Ivana Balazevic,Dipanjan Das,Kingshuk Majumder,Yale Cong,Praneet Dutta,Dustin Tran,Hui Wan,Junwei Yuan,Daniel Eppens,Alanna Walton,Been Kim,Harry Ragan,James Cobon-Kerr,Lu Liu,Weijun Wang,Bryce Petrini,Jack Rae,Rakesh Shivanna,Yan Xiong,Chace Lee,Pauline Coquinot,Yiming Gu,Lisa Patel,Blake Hechtman,Aviel Boag,Orion Jankowski,Alex Wertheim,Alex Lee,Paul Covington,Hila Noga,Sam Sobell,Shanthal Vasanth,William Bono,Chirag Nagpal,Wei Fan,Xavier Garcia,Kedar Soparkar,Aybuke Turker,Nathan Howard,Sachit Menon,Yuankai Chen,Vikas Verma,Vladimir Pchelin,Harish Rajamani,Valentin Dalibard,Ana Ramalho,Yang Guo,Kartikeya Badola,Seojin Bang,Nathalie Rauschmayr,Julia Proskurnia,Sudeep Dasari,Xinyun Chen,Mikhail Sushkov,Anja Hauth,Pauline Sho,Abhinav Singh,Bilva Chandra,Allie Culp,Max Dylla,Olivier Bachem,James Besley,Heri Zhao,Timothy Lillicrap,Wei Wei,Wael Al Jishi,Ning Niu,Alban Rrustemi,Raphaël Lopez Kaufman,Ryan Poplin,Jewel Zhao,Minh Truong,Shikhar Bharadwaj,Ester Hlavnova,Eli Stickgold,Cordelia Schmid,Georgi Stephanov,Zhaoqi Leng,Frederick Liu,Léonard Hussenot,Shenil Dodhia,Juliana Vicente Franco,Lesley Katzen,Abhanshu Sharma,Sarah Cogan,Zuguang Yang,Aniket Ray,Sergi Caelles,Shen Yan,Ravin Kumar,Daniel Gillick,Renee Wong,Joshua Ainslie,Jonathan Hoech,Séb Arnold,Dan Abolafia,Anca Dragan,Ben Hora,Grace Hu,Alexey Guseynov,Yang Lu,Chas Leichner,Jinmeng Rao,Abhimanyu Goyal,Nagabhushan Baddi,Daniel Hernandez Diaz,Tim McConnell,Max Bain,Jake Abernethy,Qiqi Yan,Rylan Schaeffer,Paul Vicol,Will Thompson,Montse Gonzalez Arenas,Mathias Bellaiche,Pablo Barrio,Stefan Zinke,Riccardo Patana,Pulkit Mehta,JK Kearns,Avraham Ruderman,Scott Pollom,David D'Ambrosio,Cath Hope,Yang Yu,Andrea Gesmundo,Kuang-Huei Lee,Aviv Rosenberg,Yiqian Zhou,Yaoyiran Li,Drew Garmon,Yonghui Wu,Safeen Huda,Gil Fidel,Martin Baeuml,Jian Li,Phoebe Kirk,Rhys May,Tao Tu,Sara Mc Carthy,Toshiyuki Fukuzawa,Miranda Aperghis,Chih-Kuan Yeh,Toshihiro Yoshino,Bo Li,Austin Myers,Kaisheng Yao,Ben Limonchik,Changwan Ryu,Rohun Saxena,Alex Goldin,Ruizhe Zhao,Rocky Rhodes,Tao Zhu,Divya Tyam,Heidi Howard,Nathan Byrd,Hongxu Ma,Yan Wu,Ryan Mullins,Qingze Wang,Aida Amini,Sebastien Baur,Yiran Mao,Subhashini Venugopalan,Will Song,Wen Ding,Paul Collins,Sashank Reddi,Megan Shum,Andrei Rusu,Luisa Zintgraf,Kelvin Chan,Sheela Goenka,Mathieu Blondel,Michael Collins,Renke Pan,Marissa Giustina,Nikolai Chinaev,Christian Schuler,Ce Zheng,Jonas Valfridsson,Alyssa Loo,Alex Yakubovich,Jamie Smith,Tao Jiang,Rich Munoz,Gabriel Barcik,Rishabh Bansal,Mingyao Yang,Yilun Du,Pablo Duque,Mary Phuong,Alexandra Belias,Kunal Lad,Zeyu Liu,Tal Schuster,Karthik Duddu,Jieru Hu,Paige Kunkle,Matthew Watson,Jackson Tolins,Josh Smith,Denis Teplyashin,Garrett Bingham,Marvin Ritter,Marco Andreetto,Divya Pitta,Mohak Patel,Shashank Viswanadha,Trevor Strohman,Catalin Ionescu,Jincheng Luo,Yogesh Kalley,Jeremy Wiesner,Dan Deutsch,Derek Lockhart,Peter Choy,Rumen Dangovski,Chawin Sitawarin,Cat Graves,Tanya Lando,Joost van Amersfoort,Ndidi Elue,Zhouyuan Huo,Pooya Moradi,Jean Tarbouriech,Henryk Michalewski,Wenting Ye,Eunyoung Kim,Alex Druinsky,Florent Altché,Xinyi Chen,Artur Dwornik,Da-Cheng Juan,Rivka Moroshko,Horia Toma,Jarrod Kahn,Hai Qian,Maximilian Sieb,Irene Cai,Roman Goldenberg,Praneeth Netrapalli,Sindhu Raghuram,Yuan Gong,Lijie Fan,Evan Palmer,Yossi Matias,Valentin Gabeur,Shreya Pathak,Tom Ouyang,Don Metzler,Geoff Bacon,Srinivasan Venkatachary,Sridhar Thiagarajan,Alex Cullum,Eran Ofek,Vytenis Sakenas,Mohamed Hammad,Cesar Magalhaes,Mayank Daswani,Oscar Chang,Ashok Popat,Ruichao Li,Komal Jalan,Yanhan Hou,Josh Lipschultz,Antoine He,Wenhao Jia,Pier Giuseppe Sessa,Prateek Kolhar,William Wong,Sumeet Singh,Lukas Haas,Jay Whang,Hanna Klimczak-Plucińska,Georges Rotival,Grace Chung,Yiqing Hua,Anfal Siddiqui,Nicolas Serrano,Dongkai Chen,Billy Porter,Libin Bai,Keshav Shivam,Sho Arora,Partha Talukdar,Tom Cobley,Sangnie Bhardwaj,Evgeny Gladchenko,Simon Green,Kelvin Guu,Felix Fischer,Xiao Wu,Eric Wang,Achintya Singhal,Tatiana Matejovicova,James Martens,Hongji Li,Roma Patel,Elizabeth Kemp,Jiaqi Pan,Lily Wang,Blake JianHang Chen,Jean-Baptiste Alayrac,Navneet Potti,Erika Gemzer,Eugene Ie,Kay McKinney,Takaaki Saeki,Edward Chou,Pascal Lamblin,SQ Mah,Zach Fisher,Martin Chadwick,Jon Stritar,Obaid Sarvana,Andrew Hogue,Artem Shtefan,Hadi Hashemi,Yang Xu,Jindong Gu,Sharad Vikram,Chung-Ching Chang,Sabela Ramos,Logan Kilpatrick,Weijuan Xi,Jenny Brennan,Yinghao Sun,Abhishek Jindal,Ionel Gog,Dawn Chen,Felix Wu,Jason Lee,Sudhindra Kopalle,Srinadh Bhojanapalli,Oriol Vinyals,Natan Potikha,Burcu Karagol Ayan,Yuan Yuan,Michael Riley,Piotr Stanczyk,Sergey Kishchenko,Bing Wang,Dan Garrette,Antoine Yang,Vlad Feinberg,CJ Carey,Javad Azizi,Viral Shah,Erica Moreira,Chongyang Shi,Josh Feldman,Elizabeth Salesky,Thomas Lampe,Aneesh Pappu,Duhyeon Kim,Jonas Adler,Avi Caciularu,Brian Walker,Yunhan Xu,Yochai Blau,Dylan Scandinaro,Terry Huang,Sam El-Husseini,Abhishek Sinha,Lijie Ren,Taylor Tobin,Patrik Sundberg,Tim Sohn,Vikas Yadav,Mimi Ly,Emily Xue,Jing Xiong,Afzal Shama Soudagar,Sneha Mondal,Nikhil Khadke,Qingchun Ren,Ben Vargas,Stan Bileschi,Sarah Chakera,Cindy Wang,Boyu Wang,Yoni Halpern,Joe Jiang,Vikas Sindhwani,Petre Petrov,Pranavaraj Ponnuramu,Sanket Vaibhav Mehta,Yu Watanabe,Betty Chan,Matheus Wisniewski,Trang Pham,Jingwei Zhang,Conglong Li,Dario de Cesare,Art Khurshudov,Alex Vasiloff,Melissa Tan,Zoe Ashwood,Bobak Shahriari,Maryam Majzoubi,Garrett Tanzer,Olga Kozlova,Robin Alazard,James Lee-Thorp,Nguyet Minh Phu,Isaac Tian,Junwhan Ahn,Andy Crawford,Lauren Lax,Yuan,Shangguan,Iftekhar Naim,David Ross,Oleksandr Ferludin,Tongfei Guo,Andrea Banino,Hubert Soyer,Xiaoen Ju,Dominika Rogozińska,Ishaan Malhi,Marcella Valentine,Daniel Balle,Apoorv Kulshreshtha,Maciej Kula,Yiwen Song,Sophia Austin,John Schultz,Roy Hirsch,Arthur Douillard,Apoorv Reddy,Michael Fink,Summer Yue,Khyatti Gupta,Adam Zhang,Norman Rink,Daniel McDuff,Lei Meng,András György,Yasaman Razeghi,Ricky Liang,Kazuki Osawa,Aviel Atias,Matan Eyal,Tyrone Hill,Nikolai Grigorev,Zhengdong Wang,Nitish Kulkarni,Rachel Soh,Ivan Lobov,Zachary Charles,Sid Lall,Kazuma Hashimoto,Ido Kessler,Victor Gomes,Zelda Mariet,Danny Driess,Alessandro Agostini,Canfer Akbulut,Jingcao Hu,Marissa Ikonomidis,Emily Caveness,Kartik Audhkhasi,Saurabh Agrawal,Ioana Bica,Evan Senter,Jayaram Mudigonda,Kelly Chen,Jingchen Ye,Xuanhui Wang,James Svensson,Philipp Fränken,Josh Newlan,Li Lao,Eva Schnider,Sami Alabed,Joseph Kready,Jesse Emond,Afief Halumi,Tim Zaman,Chengxi Ye,Naina Raisinghani,Vilobh Meshram,Bo Chang,Ankit Singh Rawat,Axel Stjerngren,Sergey Levi,Rui Wang,Xiangzhu Long,Mitchelle Rasquinha,Steven Hand,Aditi Mavalankar,Lauren Agubuzu,Sudeshna Roy,Junquan Chen,Jarek Wilkiewicz,Hao Zhou,Michal Jastrzebski,Qiong Hu,Agustin Dal Lago,Ramya Sree Boppana,Wei-Jen Ko,Jennifer Prendki,Yao Su,Zhi Li,Eliza Rutherford,Girish Ramchandra Rao,Ramona Comanescu,Adrià Puigdomènech,Qihang Chen,Dessie Petrova,Christine Chan,Vedrana Milutinovic,Felipe Tiengo Ferreira,Chin-Yi Cheng,Ming Zhang,Tapomay Dey,Sherry Yang,Ramesh Sampath,Quoc Le,Howard Zhou,Chu-Cheng Lin,Hoi Lam,Christine Kaeser-Chen,Kai Hui,Dean Hirsch,Tom Eccles,Basil Mustafa,Shruti Rijhwani,Morgane Rivière,Yuanzhong Xu,Junjie Wang,Xinyang Geng,Xiance Si,Arjun Khare,Cheolmin Kim,Vahab Mirrokni,Kamyu Lee,Khuslen Baatarsukh,Nathaniel Braun,Lisa Wang,Pallavi LV,Richard Tanburn,Yuvein,Zhu,Fangda Li,Setareh Ariafar,Dan Goldberg,Ken Burke,Daniil Mirylenka,Meiqi Guo,Olaf Ronneberger,Hadas Natalie Vogel,Liqun Cheng,Nishita Shetty,Johnson Jia,Thomas Jimma,Corey Fry,Ted Xiao,Martin Sundermeyer,Ryan Burnell,Yannis Assael,Mario Pinto,JD Chen,Rohit Sathyanarayana,Donghyun Cho,Jing Lu,Rishabh Agarwal,Sugato Basu,Lucas Gonzalez,Dhruv Shah,Meng Wei,Dre Mahaarachchi,Rohan Agrawal,Tero Rissa,Yani Donchev,Ramiro Leal-Cavazos,Adrian Hutter,Markus Mircea,Alon Jacovi,Faruk Ahmed,Jiageng Zhang,Shuguang Hu,Bo-Juen Chen,Jonni Kanerva,Guillaume Desjardins,Andrew Lee,Nikos Parotsidis,Asier Mujika,Tobias Weyand,Jasper Snoek,Jo Chick,Kai Chen,Paul Chang,Ethan Mahintorabi,Zi Wang,Tolly Powell,Orgad Keller,Abhirut Gupta,Claire Sha,Kanav Garg,Nicolas Heess,Ágoston Weisz,Cassidy Hardin,Bartek Wydrowski,Ben Coleman,Karina Zainullina,Pankaj Joshi,Alessandro Epasto,Terry Spitz,Binbin Xiong,Kai Zhao,Arseniy Klimovskiy,Ivy Zheng,Johan Ferret,Itay Yona,Waleed Khawaja,Jean-Baptiste Lespiau,Maxim Krikun,Siamak Shakeri,Timothee Cour,Bonnie Li,Igor Krivokon,Dan Suh,Alex Hofer,Jad Al Abdallah,Nikita Putikhin,Oscar Akerlund,Silvio Lattanzi,Anurag Kumar,Shane Settle,Himanshu Srivastava,Folawiyo Campbell-Ajala,Edouard Rosseel,Mihai Dorin Istin,Nishanth Dikkala,Anand Rao,Nick Young,Kate Lin,Dhruva Bhaswar,Yiming Wang,Jaume Sanchez Elias,Kritika Muralidharan,James Keeling,Dayou Du,Siddharth Gopal,Gregory Dibb,Charles Blundell,Manolis Delakis,Jacky Liang,Marco Tulio Ribeiro,Georgi Karadzhov,Guillermo Garrido,Ankur Bapna,Jiawei Cao,Adam Sadovsky,Pouya Tafti,Arthur Guez,Coline Devin,Yixian Di,Jinwei Xing,Chuqiao,Xu,Hanzhao Lin,Chun-Te Chu,Sameera Ponda,Wesley Helmholz,Fan Yang,Yue Gao,Sara Javanmardi,Wael Farhan,Alex Ramirez,Ricardo Figueira,Khe Chai Sim,Yuval Bahat,Ashwin Vaswani,Liangzhe Yuan,Gufeng Zhang,Leland Rechis,Hanjun Dai,Tayo Oguntebi,Alexandra Cordell,Eugénie Rives,Kaan Tekelioglu,Naveen Kumar,Bing Zhang,Aurick Zhou,Nikolay Savinov,Andrew Leach,Alex Tudor,Sanjay Ganapathy,Yanyan Zheng,Mirko Rossini,Vera Axelrod,Arnaud Autef,Yukun Zhu,Zheng Zheng,Mingda Zhang,Baochen Sun,Jie Ren,Nenad Tomasev,Nithish Kannan,Amer Sinha,Charles Chen,Louis O'Bryan,Alex Pak,Aditya Kusupati,Weel Yang,Deepak Ramachandran,Patrick Griffin,Seokhwan Kim,Philipp Neubeck,Craig Schiff,Tammo Spalink,Mingyang Ling,Arun Nair,Ga-Young Joung,Linda Deng,Avishkar Bhoopchand,Lora Aroyo,Tom Duerig,Jordan Griffith,Gabe Barth-Maron,Jake Ades,Alex Haig,Ankur Taly,Yunting Song,Paul Michel,Dave Orr,Dean Weesner,Corentin Tallec,Carrie Grimes Bostock,Paul Niemczyk,Andy Twigg,Mudit Verma,Rohith Vallu,Henry Wang,Marco Gelmi,Kiranbir Sodhia,Aleksandr Chuklin,Omer Goldman,Jasmine George,Liang Bai,Kelvin Zhang,Petar Sirkovic,Efrat Nehoran,Golan Pundak,Jiaqi Mu,Alice Chen,Alex Greve,Paulo Zacchello,David Amos,Heming Ge,Eric Noland,Colton Bishop,Jeffrey Dudek,Youhei Namiki,Elena Buchatskaya,Jing Li,Dorsa Sadigh,Masha Samsikova,Dan Malkin,Damien Vincent,Robert David,Rob Willoughby,Phoenix Meadowlark,Shawn Gao,Yan Li,Raj Apte,Amit Jhindal,Stein Xudong Lin,Alex Polozov,Zhicheng Wang,Tomas Mery,Anirudh GP,Varun Yerram,Sage Stevens,Tianqi Liu,Noah Fiedel,Charles Sutton,Matthew Johnson,Xiaodan Song,Kate Baumli,Nir Shabat,Muqthar Mohammad,Hao Liu,Marco Selvi,Yichao Zhou,Mehdi Hafezi Manshadi,Chu-ling Ko,Anthony Chen,Michael Bendersky,Jorge Gonzalez Mendez,Nisarg Kothari,Amir Zandieh,Yiling Huang,Daniel Andor,Ellie Pavlick,Idan Brusilovsky,Jitendra Harlalka,Sally Goldman,Andrew Lampinen,Guowang Li,Asahi Ushio,Somit Gupta,Lei Zhang,Chuyuan Kelly Fu,Madhavi Sewak,Timo Denk,Jed Borovik,Brendan Jou,Avital Zipori,Prateek Jain,Junwen Bai,Thang Luong,Jonathan Tompson,Alice Li,Li Liu,George Powell,Jiajun Shen,Alex Feng,Grishma Chole,Da Yu,Yinlam Chow,Tongxin Yin,Eric Malmi,Kefan Xiao,Yash Pande,Shachi Paul,Niccolò Dal Santo,Adil Dostmohamed,Sergio Guadarrama,Aaron Phillips,Thanumalayan Sankaranarayana Pillai,Gal Yona,Amin Ghafouri,Preethi Lahoti,Benjamin Lee,Dhruv Madeka,Eren Sezener,Simon Tokumine,Adrian Collister,Nicola De Cao,Richard Shin,Uday Kalra,Parker Beak,Emily Nottage,Ryo Nakashima,Ivan Jurin,Vikash Sehwag,Meenu Gaba,Junhao Zeng,Kevin R. McKee,Fernando Pereira,Tamar Yakar,Amayika Panda,Arka Dhar,Peilin Zhong,Daniel Sohn,Mark Brand,Lars Lowe Sjoesund,Viral Carpenter,Sharon Lin,Shantanu Thakoor,Marcus Wainwright,Ashwin Chaugule,Pranesh Srinivasan,Muye Zhu,Bernett Orlando,Jack Weber,Ayzaan Wahid,Gilles Baechler,Apurv Suman,Jovana Mitrović,Gabe Taubman,Honglin Yu,Helen King,Josh Dillon,Cathy Yip,Dhriti Varma,Tomas Izo,Levent Bolelli,Borja De Balle Pigem,Julia Di Trapani,Fotis Iliopoulos,Adam Paszke,Nishant Ranka,Joe Zou,Francesco Pongetti,Jed McGiffin,Alex Siegman,Rich Galt,Ross Hemsley,Goran Žužić,Victor Carbune,Tao Li,Myle Ott,Félix de Chaumont Quitry,David Vilar Torres,Yuri Chervonyi,Tomy Tsai,Prem Eruvbetine,Samuel Yang,Matthew Denton,Jake Walker,Slavica Andačić,Idan Heimlich Shtacher,Vittal Premachandran,Harshal Tushar Lehri,Cip Baetu,Damion Yates,Lampros Lamprou,Mariko Iinuma,Ioana Mihailescu,Ben Albrecht,Shachi Dave,Susie Sargsyan,Bryan Perozzi,Lucas Manning,Chiyuan Zhang,Denis Vnukov,Igor Mordatch,Raia Hadsell Wolfgang Macherey,Ryan Kappedal,Jim Stephan,Aditya Tripathi,Klaus Macherey,Jun Qian,Abhishek Bhowmick,Shekoofeh Azizi,Rémi Leblond,Shiva Mohan Reddy Garlapati,Timothy Knight,Matthew Wiethoff,Wei-Chih Hung,Anelia Angelova,Georgios Evangelopoulos,Pawel Janus,Dimitris Paparas,Matthew Rahtz,Ken Caluwaerts,Vivek Sampathkumar,Daniel Jarrett,Shadi Noghabi,Antoine Miech,Chak Yeung,Geoff Clark,Henry Prior,Fei Zheng,Jean Pouget-Abadie,Indro Bhattacharya,Kalpesh Krishna,Will Bishop,Zhe Yuan,Yunxiao Deng,Ashutosh Sathe,Kacper Krasowiak,Ciprian Chelba,Cho-Jui Hsieh,Kiran Vodrahalli,Buhuang Liu,Thomas Köppe,Amr Khalifa,Lubo Litchev,Pichi Charoenpanit,Reed Roberts,Sachin Yadav,Yasumasa Onoe,Desi Ivanov,Megha Mohabey,Vighnesh Birodkar,Nemanja Rakićević,Pierre Sermanet,Vaibhav Mehta,Krishan Subudhi,Travis Choma,Will Ng,Luheng He,Kathie Wang,Tasos Kementsietsidis,Shane Gu,Mansi Gupta,Andrew Nystrom,Mehran Kazemi,Timothy Chung,Nacho Cano,Nikhil Dhawan,Yufei Wang,Jiawei Xia,Trevor Yacovone,Eric Jia,Mingqing Chen,Simeon Ivanov,Ashrith Sheshan,Sid Dalmia,Paweł Stradomski,Pengcheng Yin,Salem Haykal,Congchao Wang,Dennis Duan,Neslihan Bulut,Greg Kochanski,Liam MacDermed,Namrata Godbole,Shitao Weng,Jingjing Chen,Rachana Fellinger,Ramin Mehran,Daniel Suo,Hisham Husain,Tong He,Kaushal Patel,Joshua Howland,Randall Parker,Kelvin Nguyen,Sharath Maddineni,Chris Rawles,Mina Khan,Shlomi Cohen-Ganor,Amol Mandhane,Xinyi Wu,Chenkai Kuang,Iulia Comşa,Ramya Ganeshan,Hanie Sedghi,Adam Bloniarz,Nuo Wang Pierse,Anton Briukhov,Petr Mitrichev,Anita Gergely,Serena Zhan,Allan Zhou,Nikita Saxena,Eva Lu,Josef Dean,Ashish Gupta,Nicolas Perez-Nieves,Renjie Wu,Cory McLean,Wei Liang,Disha Jindal,Anton Tsitsulin,Wenhao Yu,Kaiz Alarakyia,Tom Schaul,Piyush Patil,Peter Sung,Elijah Peake,Hongkun Yu,Feryal Behbahani,JD Co-Reyes,Alan Ansell,Sean Sun,Clara Barbu,Jonathan Lee,Seb Noury,James Allingham,Bilal Piot,Mohit Sharma,Christopher Yew,Ivan Korotkov,Bibo Xu,Demetra Brady,Goran Petrovic,Shibl Mourad,Claire Cui,Aditya Gupta,Parker Schuh,Saarthak Khanna,Anna Goldie,Abhinav Arora,Vadim Zubov,Amy Stuart,Mark Epstein,Yun Zhu,Jianqiao Liu,Yury Stuken,Ziyue Wang,Karolis Misiunas,Dee Guo,Ashleah Gill,Ale Hartman,Zaid Nabulsi,Aurko Roy,Aleksandra Faust,Jason Riesa,Ben Withbroe,Mengchao Wang,Marco Tagliasacchi,Andreea Marzoca,James Noraky,Serge Toropov,Malika Mehrotra,Bahram Raad,Sanja Deur,Steve Xu,Marianne Monteiro,Zhongru Wu,Yi Luan,Sam Ritter,Nick Li,Håvard Garnes,Yanzhang He,Martin Zlocha,Jifan Zhu,Matteo Hessel,Will Wu,Spandana Raj Babbula,Chizu Kawamoto,Yuanzhen Li,Mehadi Hassen,Yan Wang,Brian Wieder,James Freedman,Yin Zhang,Xinyi Bai,Tianli Yu,David Reitter,XiangHai Sheng,Mateo Wirth,Aditya Kini,Dima Damen,Mingcen Gao,Rachel Hornung,Michael Voznesensky,Brian Roark,Adhi Kuncoro,Yuxiang Zhou,Rushin Shah,Anthony Brohan,Kuangyuan Chen,James Wendt,David Rim,Paul Kishan Rubenstein,Jonathan Halcrow,Michelle Liu,Ty Geri,Yunhsuan Sung,Jane Shapiro,Shaan Bijwadia,Chris Duvarney,Christina Sorokin,Paul Natsev,Reeve Ingle,Pramod Gupta,Young Maeng,Ndaba Ndebele,Kexin Zhu,Valentin Anklin,Katherine Lee,Yuan Liu,Yaroslav Akulov,Shaleen Gupta,Guolong Su,Flavien Prost,Tianlin Liu,Vitaly Kovalev,Pol Moreno,Martin Scholz,Sam Redmond,Zongwei Zhou,Alex Castro-Ros,André Susano Pinto,Dia Kharrat,Michal Yarom,Rachel Saputro,Jannis Bulian,Ben Caine,Ji Liu,Abbas Abdolmaleki,Shariq Iqbal,Tautvydas Misiunas,Mikhail Sirotenko,Shefali Garg,Guy Bensky,Huan Gui,Xuezhi Wang,Raphael Koster,Mike Bernico,Da Huang,Romal Thoppilan,Trevor Cohn,Ben Golan,Wenlei Zhou,Andrew Rosenberg,Markus Freitag,Tynan Gangwani,Vincent Tsang,Anand Shukla,Xiaoqi Ren,Minh Giang,Chi Zou,Andre Elisseeff,Charline Le Lan,Dheeru Dua,Shuba Lall,Pranav Shyam,Frankie Garcia,Sarah Nguyen,Michael Guzman,AJ Maschinot,Marcello Maggioni,Ming-Wei Chang,Karol Gregor,Lotte Weerts,Kumaran Venkatesan,Bogdan Damoc,Leon Liu,Jan Wassenberg,Lewis Ho,Becca Roelofs,Majid Hadian,François-Xavier Aubet,Yu Liang,Sami Lachgar,Danny Karmon,Yong Cheng,Amelio Vázquez-Reina,Angie Chen,Zhuyun Dai,Andy Brock,Shubham Agrawal,Chenxi Pang,Peter Garst,Mariella Sanchez-Vargas,Ivor Rendulic,Aditya Ayyar,Andrija Ražnatović,Olivia Ma,Roopali Vij,Neha Sharma,Ashwin Balakrishna,Bingyuan Liu,Ian Mackinnon,Sorin Baltateanu,Petra Poklukar,Gabriel Ibagon,Colin Ji,Hongyang Jiao,Isaac Noble,Wojciech Stokowiec,Zhihao Li,Jeff Dean,David Lindner,Mark Omernick,Kristen Chiafullo,Mason Dimarco,Vitor Rodrigues,Vittorio Selo,Garrett Honke,Xintian,Wu,Wei He,Adam Hillier,Anhad Mohananey,Vihari Piratla,Chang Ye,Chase Malik,Sebastian Riedel,Samuel Albanie,Zi Yang,Kenny Vassigh,Maria Bauza,Sheng Li,Yiqing Tao,Nevan Wichers,Andrii Maksai,Abe Ittycheriah,Ross Mcilroy,Bryan Seybold,Noah Goodman,Romina Datta,Steven M. Hernandez,Tian Shi,Yony Kochinski,Anna Bulanova,Ken Franko,Mikita Sazanovich,Nicholas FitzGerald,Praneeth Kacham,Shubha Srinivas Raghvendra,Vincent Hellendoorn,Alexander Grushetsky,Julian Salazar,Angeliki Lazaridou,Jason Chang,Jan-Thorsten Peter,Sushant Kafle,Yann Dauphin,Abhishek Rao,Filippo Graziano,Izhak Shafran,Yuguo Liao,Tianli Ding,Geng Yan,Grace Chu,Zhao Fu,Vincent Roulet,Gabriel Rasskin,Duncan Williams,Shahar Drath,Alex Mossin,Raphael Hoffmann,Jordi Orbay,Francesco Bertolini,Hila Sheftel,Justin Chiu,Siyang Xue,Yuheng Kuang,Ferjad Naeem,Swaroop Nath,Nana Nti,Phil Culliton,Kashyap Krishnakumar,Michael Isard,Pei Sun,Ayan Chakrabarti,Nathan Clement,Regev Cohen,Arissa Wongpanich,GS Oh,Ashwin Murthy,Hao Zheng,Jessica Hamrick,Oskar Bunyan,Suhas Ganesh,Nitish Gupta,Roy Frostig,John Wieting,Yury Malkov,Pierre Marcenac,Zhixin,Lai,Xiaodan Tang,Mohammad Saleh,Fedir Zubach,Chinmay Kulkarni,Huanjie Zhou,Vicky Zayats,Nan Ding,Anshuman Tripathi,Arijit Pramanik,Patrik Zochbauer,Harish Ganapathy,Vedant Misra,Zach Behrman,Hugo Vallet,Mingyang Zhang,Mukund Sridhar,Ye Jin,Mohammad Babaeizadeh,Siim Põder,Megha Goel,Divya Jain,Tajwar Nasir,Shubham Mittal,Tim Dozat,Diego Ardila,Aliaksei Severyn,Fabio Pardo,Sammy Jerome,Siyang Qin,Louis Rouillard,Amir Yazdanbakhsh,Zizhao Zhang,Shivani Agrawal,Kaushik Shivakumar,Caden Lu,Praveen Kallakuri,Rachita Chhaparia,Kanishka Rao,Charles Kwong,Asya Fadeeva,Shitij Nigam,Yan Virin,Yuan Zhang,Balaji Venkatraman,Beliz Gunel,Marc Wilson,Huiyu Wang,Abhinav Gupta,Xiaowei Xu,Adrien Ali Taïga,Kareem Mohamed,Doug Fritz,Daniel Rodriguez,Zoubin Ghahramani,Harry Askham,Lior Belenki,James Zhao,Rahul Gupta,Krzysztof Jastrzębski,Takahiro Kosakai,Kaan Katircioglu,Jon Schneider,Rina Panigrahy,Konstantinos Bousmalis,Peter Grabowski,Prajit Ramachandran,Chaitra Hegde,Mihaela Rosca,Angelo Scorza Scarpati,Kyriakos Axiotis,Ying Xu,Zach Gleicher,Assaf Hurwitz Michaely,Mandar Sharma,Sanil Jain,Christoph Hirnschall,Tal Marian,Xuhui Jia,Kevin Mather,Kilol Gupta,Linhai Qiu,Nigamaa Nayakanti,Lucian Ionita,Steven Zheng,Lucia Loher,Kurt Shuster,Igor Petrovski,Roshan Sharma,Rahma Chaabouni,Angel Yeh,James An,Arushi Gupta,Steven Schwarcz,Seher Ellis,Sam Conway-Rahman,Javier Snaider,Alex Zhai,James Atwood,Daniel Golovin,Liqian Peng,Te I,Vivian Xia,Salvatore Scellato,Mahan Malihi,Arthur Bražinskas,Vlad-Doru Ion,Younghoon Jun,James Swirhun,Soroosh Mariooryad,Jiao Sun,Steve Chien,Rey Coaguila,Ariel Brand,Yi Gao,Tom Kwiatkowski,Roee Aharoni,Cheng-Chun Lee,Mislav Žanić,Yichi Zhang,Dan Ethier,Vitaly Nikolaev,Pranav Nair,Yoav Ben Shalom,Hen Fitoussi,Jai Gupta,Hongbin Liu,Dee Cattle,Tolga Bolukbasi,Ben Murdoch,Fantine Huot,Yin Li,Chris Hahn*

Main category: cs.CL

TL;DR: 介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro和2.5 Flash，以及早期的2.0 Flash和Flash-Lite模型，展示了其在编码、推理和多模态理解方面的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 推动前沿编码和推理基准的性能，提供多模态理解和长上下文处理能力，以支持复杂的代理工作流程。

Method: 开发了Gemini 2.5 Pro和2.5 Flash模型，分别优化了性能和计算效率，同时保留了多模态和长上下文处理能力。

Result: Gemini 2.5 Pro在编码和推理基准上达到SoTA性能，并能处理长达3小时的视频内容；2.5 Flash在低计算和延迟下提供优秀推理能力。

Conclusion: Gemini 2.X模型家族在性能和成本之间实现了帕累托最优，为复杂代理问题解决提供了广泛选择。

Abstract: In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and
Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite
models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA
performance on frontier coding and reasoning benchmarks. In addition to its
incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that
excels at multimodal understanding and it is now able to process up to 3 hours
of video content. Its unique combination of long context, multimodal and
reasoning capabilities can be combined to unlock new agentic workflows. Gemini
2.5 Flash provides excellent reasoning abilities at a fraction of the compute
and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high
performance at low latency and cost. Taken together, the Gemini 2.X model
generation spans the full Pareto frontier of model capability vs cost, allowing
users to explore the boundaries of what is possible with complex agentic
problem solving.

</details>


### [10] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在多语言环境中存在过度自信和用户过度依赖的问题，尤其是在不同语言中表达不确定性的方式差异显著。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在全球范围内的安全性，尤其是其在不同语言中表达不确定性和局限性时的校准问题。

Method: 分析五种语言中LLM生成的认识标记分布，并测量用户在不同语言中对模型输出的依赖行为。

Result: LLMs在所有语言中都表现出过度自信，但能捕捉到语言间的差异；用户对自信输出的依赖行为因语言而异。

Conclusion: 多语言校准面临挑战，需结合文化和语言背景进行模型安全性评估。

Abstract: As large language models (LLMs) are deployed globally, it is crucial that
their responses are calibrated across languages to accurately convey
uncertainty and limitations. Previous work has shown that LLMs are
linguistically overconfident in English, leading users to overrely on confident
generations. However, the usage and interpretation of epistemic markers (e.g.,
'It's definitely,' 'I think') can differ sharply across languages. Here, we
study the risks of multilingual linguistic (mis)calibration, overconfidence,
and overreliance across five languages to evaluate the safety of LLMs in a
global context.
  We find that overreliance risks are high across all languages. We first
analyze the distribution of LLM-generated epistemic markers, and observe that
while LLMs are cross-linguistically overconfident, they are also sensitive to
documented linguistic variation. For example, models generate the most markers
of uncertainty in Japanese and the most markers of certainty in German and
Mandarin. We then measure human reliance rates across languages, finding that
while users strongly rely on confident LLM generations in all languages,
reliance behaviors differ cross-linguistically: for example, users rely
significantly more on expressions of uncertainty in Japanese than in English.
Taken together, these results indicate high risk of reliance on overconfident
model generations across languages. Our findings highlight the challenges of
multilingual linguistic calibration and stress the importance of culturally and
linguistically contextualized model safety evaluations.

</details>


### [11] [ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time](https://arxiv.org/abs/2507.06313)
*Kiarash Zahirnia,Zahra Golpayegani,Walid Ahmad,Yang Liu*

Main category: cs.CL

TL;DR: 论文提出ETT方法，通过高效微调短上下文Transformer模型的参数，以线性计算开销和恒定内存需求扩展上下文长度，提升模型在长序列任务中的表现。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长序列时面临二次计算和内存开销的问题，限制了其应用范围。

Method: ETT方法通过将输入上下文分块为重叠子序列，并在测试时高效微调模型参数，实现上下文长度的扩展。

Result: 在LongBench上，ETT将GPT-Large和Phi-2的上下文长度从1k扩展到32k，准确率提升30%。研究发现微调FFN的第二层比全微调更有效。

Conclusion: ETT是一种高效扩展Transformer模型上下文长度的方法，显著提升模型性能，且微调特定模块效果更佳。

Abstract: Transformer-based Language Models' computation and memory overhead increase
quadratically as a function of sequence length. The quadratic cost poses
challenges when employing LLMs for processing long sequences. In this work, we
introduce \ourmodelacronym~(Extend at Test-Time), method for extending the
context length of short context Transformer-based LLMs, with constant memory
requirement and linear computation overhead. ETT enable the extension of the
context length at test-time by efficient fine-tuning the model's parameters on
the input context, chunked into overlapping small subsequences. We evaluate ETT
on LongBench by extending the context length of GPT-Large and Phi-2 up to 32
times, increasing from 1k to 32k tokens. This results in up to a 30 percent
improvement in the model's accuracy. We also study how context can be stored in
LLM's weights effectively and efficiently. Through a detailed ablation study,
we examine which Transformer modules are most beneficial to fine-tune at
test-time. Interestingly, we find that fine-tuning the second layer of the FFNs
is more effective than full fine-tuning, leading to a further improvement in
the models' accuracy.

</details>


### [12] [Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?](https://arxiv.org/abs/2507.06335)
*Casey Kennington,David Schlangen*

Main category: cs.CL

TL;DR: 本文提出通过“词作为分类器”模型统一形式、分布和接地语义理论，结合认知科学和实验验证其潜力。


<details>
  <summary>Details</summary>
Motivation: 形式、分布和接地语义理论各有优缺点，需要一种方法结合三者优势。

Method: 回顾文献，结合认知科学，提出“词作为分类器”模型，并进行小规模实验验证。

Result: “词作为分类器”模型在对话环境中表现良好，有望统一三种语义理论。

Conclusion: “词作为分类器”模型为统一形式、分布和接地语义提供了可行路径。

Abstract: Formal, Distributional, and Grounded theories of computational semantics each
have their uses and their drawbacks. There has been a shift to ground models of
language by adding visual knowledge, and there has been a call to enrich models
of language with symbolic methods to gain the benefits from formal,
distributional, and grounded theories. In this paper, we attempt to make the
case that one potential path forward in unifying all three semantic fields is
paved with the words-as-classifier model, a model of word-level grounded
semantics that has been incorporated into formalisms and distributional
language models in the literature, and it has been well-tested within
interactive dialogue settings. We review that literature, motivate the
words-as-classifiers model with an appeal to recent work in cognitive science,
and describe a small experiment. Finally, we sketch a model of semantics
unified through words-as-classifiers.

</details>


### [13] [Evaluating Morphological Alignment of Tokenizers in 70 Languages](https://arxiv.org/abs/2507.06378)
*Catherine Arnett,Marisa Hudspeth,Brendan O'Connor*

Main category: cs.CL

TL;DR: 论文扩展了MorphScore以支持更多语言，并探讨了分词器质量与模型性能的关系，发现形态对齐对性能影响有限。


<details>
  <summary>Details</summary>
Motivation: 评估分词器质量的方法尚不明确，尤其是分词器是否保留语言学上有意义的子词。

Method: 扩展MorphScore至70种语言，并分析形态对齐分数与下游任务性能的相关性。

Result: 形态对齐分数对模型性能的方差解释力较弱。

Conclusion: 仅形态对齐不足以衡量与模型性能相关的分词器质量。

Abstract: While tokenization is a key step in language modeling, with effects on model
training and performance, it remains unclear how to effectively evaluate
tokenizer quality. One proposed dimension of tokenizer quality is the extent to
which tokenizers preserve linguistically meaningful subwords, aligning token
boundaries with morphological boundaries within a word. We expand MorphScore
(Arnett & Bergen, 2025), which previously covered 22 languages, to support a
total of 70 languages. The updated MorphScore offers more flexibility in
evaluation and addresses some of the limitations of the original version. We
then correlate our alignment scores with downstream task performance for five
pre-trained languages models on seven tasks, with at least one task in each of
the languages in our sample. We find that morphological alignment does not
explain very much variance in model performance, suggesting that morphological
alignment alone does not measure dimensions of tokenization quality relevant to
model performance.

</details>


### [14] [Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings](https://arxiv.org/abs/2507.06506)
*Russell Taylor,Benjamin Herbert,Michael Sana*

Main category: cs.CL

TL;DR: 提出了一种结合大型语言模型和专门技术的创新方法，用于将英语双关语翻译成法语，并在CLEF JOKER 2025比赛中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决跨语言双关语翻译的挑战，弥补翻译研究与计算语言学之间的空白。

Method: 采用三阶段方法：基线模型建立、引导思维链管道、多代理生成-判别框架。

Result: 在CLEF JOKER 2025比赛中获得第一和第二名。

Conclusion: 通过语言学技术推动双关语翻译，深化了对语言模型处理语义模糊性和文化背景的理解。

Abstract: Translating wordplay across languages presents unique challenges that have
long confounded both professional human translators and machine translation
systems. This research proposes a novel approach for translating puns from
English to French by combining state-of-the-art large language models with
specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a
baseline using multiple frontier large language models with feedback based on a
new contrastive learning dataset. Second, we implement a guided
chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we
implement a multi-agent generator-discriminator framework for evaluating and
regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's
primary objective is to capture the linguistic creativity and humor of the
source text wordplay, rather than simply duplicating its vocabulary. Our best
runs earned first and second place in the CLEF JOKER 2025 Task 2 competition
where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational
linguistics by implementing linguistically-informed techniques for wordplay
translation, advancing our understanding of how language models can be
leveraged to handle the complex interplay between semantic ambiguity, phonetic
similarity, and the implicit cultural and linguistic awareness needed for
successful humor.

</details>


### [15] [Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles](https://arxiv.org/abs/2507.06393)
*Matilde Marcolli,Riny Huijbregts,Richard K. Larson*

Main category: cs.CL

TL;DR: 论文展示了句法对象的头部函数如何将代数结构扩展为超代数结构，并探讨了c-命令和m-命令关系的兼容性。此外，通过彩色操作数的形式，描述了句法结构的生成系统及其与θ角色的相似性。


<details>
  <summary>Details</summary>
Motivation: 研究目的是将句法结构与代数结构联系起来，探索句法生成和移动规则的统一数学框架。

Method: 使用超代数结构和彩色操作数理论，将句法生成和移动规则形式化为代数操作。

Result: 证明了句法生成和移动规则可以通过彩色操作数统一描述，并展示了其与超代数结构的关联。

Conclusion: 研究为句法理论提供了统一的数学框架，将生成和移动规则纳入代数结构中。

Abstract: We show that head functions on syntactic objects extend the magma structure
to a hypermagma, with the c-command relation compatible with the magma
operation and the m-command relation with the hypermagma. We then show that the
structure of head and complement and specifier, additional modifier positions,
and the structure of phases in the Extended Projection can be formulated as a
bud generating system of a colored operad, in a form similar to the structure
of theta roles. We also show that, due to the special form of the colored
operad generators, the filtering of freely generated syntactic objects by these
coloring rules can be equivalently formulated as a filtering in the course of
structure formation via a colored Merge, which can in turn be related to the
hypermagma structure. The rules on movement by Internal Merge with respect to
phases, the Extended Projection Principle, Empty Category Principle, and Phase
Impenetrability Condition are all subsumed into the form of the colored operad
generators. Movement compatibilities between the phase structure and the theta
roles assignments can then be formulated in terms of the respective colored
operads and a transduction of colored operads.

</details>


### [16] [PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning](https://arxiv.org/abs/2507.06415)
*Zeming Chen,Angelika Romanou,Gail Weiss,Antoine Bosselut*

Main category: cs.CL

TL;DR: PERK是一种参数高效的方法，通过梯度更新轻量级适配器在测试时编码长上下文，显著优于传统提示方法。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文推理中噪声信息处理的问题，同时避免传统元学习方法的高内存消耗。

Method: 采用双嵌套优化循环：内循环将上下文编码到低秩适配器（LoRA），外循环学习利用适配器进行信息回忆和推理。

Result: 在多个长上下文任务中，PERK显著优于基线方法，性能提升高达90%（小模型）和27%（大模型）。

Conclusion: PERK在推理时更高效，对复杂推理、长度外推和信息位置更鲁棒。

Abstract: Long-context reasoning requires accurately identifying relevant information
in extensive, noisy input contexts. Previous research shows that using
test-time learning to encode context directly into model parameters can
effectively enable reasoning over noisy information. However, meta-learning
methods for enabling test-time learning are prohibitively memory-intensive,
preventing their application to long context settings. In this work, we propose
PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for
learning to encode long input contexts using gradient updates to a lightweight
model adapter at test time. Specifically, PERK employs two nested optimization
loops in a meta-training phase. The inner loop rapidly encodes contexts into a
low-rank adapter (LoRA) that serves as a parameter-efficient memory module for
the base model. Concurrently, the outer loop learns to use the updated adapter
to accurately recall and reason over relevant information from the encoded long
context. Our evaluations on several long-context reasoning tasks show that PERK
significantly outperforms the standard prompt-based long-context baseline,
achieving average absolute performance gains of up to 90% for smaller models
(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In
general, PERK is more robust to reasoning complexity, length extrapolation, and
the locations of relevant information in contexts. Finally, we show that while
PERK is memory-intensive during training, it scales more efficiently at
inference time than prompt-based long-context inference.

</details>


### [17] [Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling](https://arxiv.org/abs/2507.06419)
*Pankayaraj Pathmanathan,Furong Huang*

Main category: cs.CL

TL;DR: 提出了一种无需先验知识的奖励模型失败模式发现方法REFORM，通过自增强框架提升奖励模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 奖励模型（RM）在分布偏移或对抗扰动下容易失效，现有方法依赖先验知识，实用性受限。

Method: 提出基于奖励引导的解码方法发现失败模式，并引入自增强框架REFORM，利用对抗样本增强训练数据。

Result: 在Anthropic HH和PKU Beavertails数据集上显著提升鲁棒性，且不影响奖励质量。

Conclusion: REFORM在直接评估和下游策略训练中均表现优异，同时通过消除虚假相关性提升对齐质量。

Abstract: Reward modeling (RM), which captures human preferences to align large
language models (LLMs), is increasingly employed in tasks such as model
finetuning, response filtering, and ranking. However, due to the inherent
complexity of human preferences and the limited coverage of available datasets,
reward models often fail under distributional shifts or adversarial
perturbations. Existing approaches for identifying such failure modes typically
rely on prior knowledge about preference distributions or failure attributes,
limiting their practicality in real-world settings where such information is
unavailable. In this work, we propose a tractable, preference-distribution
agnostic method for discovering reward model failure modes via reward guided
controlled decoding. Building on this, we introduce REFORM, a self-improving
reward modeling framework that enhances robustness by using the reward model
itself to guide the generation of falsely scored responses. These adversarial
examples are then used to augment the training data and patch the reward
model's misaligned behavior. We evaluate REFORM on two widely used preference
datasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate
that it significantly improves robustness without sacrificing reward quality.
Notably, REFORM preserves performance both in direct evaluation and in
downstream policy training, and further improves alignment quality by removing
spurious correlations.

</details>


### [18] [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](https://arxiv.org/abs/2507.06427)
*Shun Wang,Tyler Loakman,Youbo Lei,Yi Liu,Bohao Yang,Yuting Zhao,Dong Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: 通过字典学习和稀疏自编码器分解LLM，提取单义特征，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统LLM被视为黑箱，缺乏可解释性，影响信任度和性能优化。

Method: 采用字典学习和稀疏自编码器分解LLM，提取单义特征并自动优化提示。

Result: 显著提升数学推理和隐喻检测等下游任务性能。

Conclusion: LLM分解方法增强可解释性，优化性能，具有实际应用潜力。

Abstract: Large Language Models (LLMs) are traditionally viewed as black-box
algorithms, therefore reducing trustworthiness and obscuring potential
approaches to increasing performance on downstream tasks. In this work, we
apply an effective LLM decomposition method using a dictionary-learning
approach with sparse autoencoders. This helps extract monosemantic features
from polysemantic LLM neurons. Remarkably, our work identifies model-internal
misunderstanding, allowing the automatic reformulation of the prompts with
additional annotations to improve the interpretation by LLMs. Moreover, this
approach demonstrates a significant performance improvement in downstream
tasks, such as mathematical reasoning and metaphor detection.

</details>


### [19] [Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling](https://arxiv.org/abs/2507.06435)
*Rafiu Adekoya Badekale,Adewale Akinfaderin*

Main category: cs.CL

TL;DR: 论文提出了一种基于动态嵌入主题模型（DETM）的新方法，用于分析全球气候政策话语的演变，揭示了从温室气体到实施与技术合作的主题变化。


<details>
  <summary>Details</summary>
Motivation: 理解政策语言的演变对评估全球应对复杂挑战（如气候变化）至关重要，传统方法效率低且难以捕捉复杂关联。

Method: 应用动态嵌入主题模型（DETM）分析1995年至2023年UNFCCC政策决策的语料库，排除2020年数据。

Result: 模型揭示了政策主题从温室气体转向实施、技术合作、能力建设和全球协议的变化。

Conclusion: DETM是一种可扩展且有效的工具，未来可扩展至其他政策领域。

Abstract: Understanding how policy language evolves over time is critical for assessing
global responses to complex challenges such as climate change. Temporal
analysis helps stakeholders, including policymakers and researchers, to
evaluate past priorities, identify emerging themes, design governance
strategies, and develop mitigation measures. Traditional approaches, such as
manual thematic coding, are time-consuming and limited in capturing the
complex, interconnected nature of global policy discourse. With the increasing
relevance of unsupervised machine learning, these limitations can be addressed,
particularly under high-volume, complex, and high-dimensional data conditions.
In this work, we explore a novel approach that applies the dynamic embedded
topic model (DETM) to analyze the evolution of global climate policy discourse.
A probabilistic model designed to capture the temporal dynamics of topics over
time. We collected a corpus of United Nations Framework Convention on Climate
Change (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the
postponement of COP26 as a result of the COVID-19 pandemic. The model reveals
shifts from early emphases on greenhouse gases and international conventions to
recent focuses on implementation, technical collaboration, capacity building,
finance, and global agreements. Section 3 presents the modeling pipeline,
including preprocessing, model training, and visualization of temporal word
distributions. Our results show that DETM is a scalable and effective tool for
analyzing the evolution of global policy discourse. Section 4 discusses the
implications of these findings and we concluded with future directions and
refinements to extend this approach to other policy domains.

</details>


### [20] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
*Zhenhailong Wang,Xuehang Guo,Sofia Stoica,Haiyang Xu,Hongru Wang,Hyeonjeong Ha,Xiusi Chen,Yangyi Chen,Ming Yan,Fei Huang,Heng Ji*

Main category: cs.CL

TL;DR: 论文提出了PAPO方法，通过引入隐式感知损失改进多模态推理任务中的视觉输入感知问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前RLVR方法在多模态推理任务中表现不佳，主要问题在于视觉输入的感知能力不足。

Method: 提出PAPO方法，扩展GRPO目标，引入KL散度形式的隐式感知损失，无需额外数据或外部奖励模型。

Result: 在多模态基准测试中整体提升4.4%，视觉依赖任务中提升8.0%，感知错误减少30.5%。

Conclusion: PAPO通过感知感知监督的深度集成，为视觉基础推理的新RL框架奠定了基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a
highly effective strategy for endowing Large Language Models (LLMs) with robust
multi-step reasoning abilities. However, its design and optimizations remain
tailored to purely textual domains, resulting in suboptimal performance when
applied to multimodal reasoning tasks. In particular, we observe that a major
source of error in current multimodal reasoning lies in the perception of
visual inputs. To address this bottleneck, we propose Perception-Aware Policy
Optimization (PAPO), a simple yet effective extension of GRPO that encourages
the model to learn to perceive while learning to reason, entirely from internal
supervision signals. Notably, PAPO does not rely on additional data curation,
external reward models, or proprietary models. Specifically, we introduce the
Implicit Perception Loss in the form of a KL divergence term to the GRPO
objective, which, despite its simplicity, yields significant overall
improvements (4.4%) on diverse multimodal benchmarks. The improvements are more
pronounced, approaching 8.0%, on tasks with high vision dependency. We also
observe a substantial reduction (30.5%) in perception errors, indicating
improved perceptual capabilities with PAPO. We conduct comprehensive analysis
of PAPO and identify a unique loss hacking issue, which we rigorously analyze
and mitigate through a Double Entropy Loss. Overall, our work introduces a
deeper integration of perception-aware supervision into RLVR learning
objectives and lays the groundwork for a new RL framework that encourages
visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.

</details>


### [21] [A Semantic Parsing Framework for End-to-End Time Normalization](https://arxiv.org/abs/2507.06450)
*Xin Su,Sungduk Yu,Phillip Howard,Steven Bethard*

Main category: cs.CL

TL;DR: 论文提出了一种基于SCATE框架的时间归一化方法，将自然语言时间表达式转换为机器可读表示，并通过LLM生成可执行代码和数据增强，提升了小模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于ISO-TimeML的系统表达能力有限，难以处理复杂时间表达式，如组合式、事件相对和多跨度表达式。

Method: 将时间归一化任务重新定义为基于SCATE框架的代码生成任务，开发了可执行的SCATE Python库，并利用LLM生成可执行代码和数据增强。

Result: 实验表明，小模型在增强数据上训练后性能优异，甚至超过LLM，实现了高效、准确且可解释的时间归一化。

Conclusion: 该方法通过SCATE框架和LLM数据增强，显著提升了时间归一化的性能和实用性。

Abstract: Time normalization is the task of converting natural language temporal
expressions into machine-readable representations. It underpins many downstream
applications in information retrieval, question answering, and clinical
decision-making. Traditional systems based on the ISO-TimeML schema limit
expressivity and struggle with complex constructs such as compositional,
event-relative, and multi-span time expressions. In this work, we introduce a
novel formulation of time normalization as a code generation task grounded in
the SCATE framework, which defines temporal semantics through symbolic and
compositional operators. We implement a fully executable SCATE Python library
and demonstrate that large language models (LLMs) can generate executable SCATE
code. Leveraging this capability, we develop an automatic data augmentation
pipeline using LLMs to synthesize large-scale annotated data with code-level
validation. Our experiments show that small, locally deployable models trained
on this augmented data can achieve strong performance, outperforming even their
LLM parents and enabling practical, accurate, and interpretable time
normalization.

</details>


### [22] [A Systematic Analysis of Hybrid Linear Attention](https://arxiv.org/abs/2507.06457)
*Dustin Wang,Rui-Jie Zhu,Steven Abreu,Yong Shan,Taylor Kergan,Yuqi Pan,Yuhong Chou,Zheng Li,Ge Zhang,Wenhao Huang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 论文探讨了线性注意力机制在长序列处理中的局限性，并系统评估了多种线性注意力模型及其混合架构的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理长序列时面临二次复杂度和内存问题，线性注意力机制虽能缓解但存在召回性能不足的问题，因此需要研究混合架构中线性注意力组件的选择。

Method: 系统评估了六种线性注意力变体及其五种混合比例，训练并开源了72个模型（340M和1.3B参数），涵盖语言建模和召回任务。

Result: 研究发现，优秀的独立线性模型在混合架构中未必表现最佳；召回性能在增加全注意力层后显著提升，尤其是在3:1以下比例时。

Conclusion: 研究推荐使用HGRN-2或GatedDeltaNet等架构，线性与全注意力比例在3:1到6:1之间，以实现高效的Transformer级召回性能。

Abstract: Transformers face quadratic complexity and memory issues with long sequences,
prompting the adoption of linear attention mechanisms using fixed-size hidden
states. However, linear models often suffer from limited recall performance,
leading to hybrid architectures that combine linear and full attention layers.
Despite extensive hybrid architecture research, the choice of linear attention
component has not been deeply explored. We systematically evaluate various
linear attention models across generations - vector recurrences to advanced
gating mechanisms - both standalone and hybridized. To enable this
comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M
parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six
linear attention variants across five hybridization ratios. Benchmarking on
standard language modeling and recall tasks reveals that superior standalone
linear models do not necessarily excel in hybrids. While language modeling
remains stable across linear-to-full attention ratios, recall significantly
improves with increased full attention layers, particularly below a 3:1 ratio.
Our study highlights selective gating, hierarchical recurrence, and controlled
forgetting as critical for effective hybrid models. We recommend architectures
such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1
to achieve Transformer-level recall efficiently. Our models are open-sourced at
https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.

</details>


### [23] [On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489)
*Stephen Obadinma,Xiaodan Zhu*

Main category: cs.CL

TL;DR: 研究首次全面探讨了大型语言模型（LLM）在对抗攻击下语言置信度的鲁棒性，发现现有方法易受攻击且防御措施无效。


<details>
  <summary>Details</summary>
Motivation: 确保LLM在人类-AI交互中的透明性、信任和安全性，尤其是在高风险应用中。

Method: 提出通过扰动和越狱方法攻击语言置信度的新框架，测试多种提示策略、模型规模和应用领域。

Result: 攻击显著危害置信度估计并导致频繁答案更改，现有防御技术大多无效或适得其反。

Conclusion: 亟需设计更鲁棒的语言置信度表达机制，因细微语义保留修改也可能导致误导性置信度。

Abstract: Robust verbal confidence generated by large language models (LLMs) is crucial
for the deployment of LLMs to ensure transparency, trust, and safety in
human-AI interactions across many high-stakes applications. In this paper, we
present the first comprehensive study on the robustness of verbal confidence
under adversarial attacks. We introduce a novel framework for attacking verbal
confidence scores through both perturbation and jailbreak-based methods, and
show that these attacks can significantly jeopardize verbal confidence
estimates and lead to frequent answer changes. We examine a variety of
prompting strategies, model sizes, and application domains, revealing that
current confidence elicitation methods are vulnerable and that commonly used
defence techniques are largely ineffective or counterproductive. Our findings
underscore the urgent need to design more robust mechanisms for confidence
expression in LLMs, as even subtle semantic-preserving modifications can lead
to misleading confidence in responses.

</details>


### [24] [SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](https://arxiv.org/abs/2507.06517)
*Zicong Tang,Shi Luohe,Zuchao Li,Baoyuan Qi,Guoming Liu,Lefei Zhang,Ping Wang*

Main category: cs.CL

TL;DR: SpindleKV是一种新型的KV缓存减少方法，通过平衡浅层和深层的处理，优化了LLMs的推理效率。


<details>
  <summary>Details</summary>
Motivation: KV缓存的冗余问题，尤其是在浅层处理不足的情况下，需要一种更高效的减少方法。

Method: 结合注意力权重驱逐（深层）和基于相似性的码本替换（浅层），并解决GQA问题。

Result: 在多个基准测试中，SpindleKV相比基线方法减少了KV缓存，同时保持了模型性能。

Conclusion: SpindleKV有效平衡了浅层和深层的KV缓存减少，提升了LLMs的推理效率。

Abstract: Large Language Models (LLMs) have achieved impressive accomplishments in
recent years. However, the increasing memory consumption of KV cache has
possessed a significant challenge to the inference system. Eviction methods
have revealed the inherent redundancy within the KV cache, demonstrating its
potential for reduction, particularly in deeper layers. However, KV cache
reduction for shallower layers has been found to be insufficient. Based on our
observation that, the KV cache exhibits a high degree of similarity. Based on
this observation, we proposed a novel KV cache reduction method, SpindleKV,
which balances both shallow and deep layers. For deep layers, we employ an
attention weight based eviction method, while for shallow layers, we apply a
codebook based replacement approach which is learnt by similarity and merging
policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma
faced by other attention based eviction methods. Experiments on two common
benchmarks with three different LLMs shown that SpindleKV obtained better KV
cache reduction effect compared to baseline methods, while preserving similar
or even better model performance.

</details>


### [25] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

Main category: cs.CL

TL;DR: 提出InvestAlign框架，通过理论解构建高质量SFT数据集，解决LLM与投资者从众行为对齐问题，减少对真实用户数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 行为金融中，LLM与投资者从众行为对齐需大量真实数据，但数据稀缺且成本高。

Method: 利用理论解构建SFT数据集，训练LLM（InvestAgent），优于真实数据训练。

Result: InvestAlign生成的数据使LLM参数收敛更快，InvestAgent更贴近真实用户行为。

Conclusion: InvestAlign为复杂投资问题提供高效解决方案，减少数据依赖，提升LLM对齐能力。

Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

</details>


### [26] [Large Language Model for Extracting Complex Contract Information in Industrial Scenes](https://arxiv.org/abs/2507.06539)
*Yunyang Cao,Yanjun Li,Silong Dai*

Main category: cs.CL

TL;DR: 提出了一种工业场景下复杂合同信息提取的高质量数据集构建方法，并基于此微调大语言模型，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决工业合同信息提取任务中高质量数据稀缺和模型性能不足的问题。

Method: 通过聚类分析和GPT-4/GPT-3.5提取关键信息，数据增强生成新文本，并微调大语言模型。

Result: 模型在召回率、精确度和解析效率上表现优异，LoRA、数据平衡和数据增强提升了准确性和鲁棒性。

Conclusion: 该方法为工业合同信息提取提供了高效新颖的解决方案。

Abstract: This paper proposes a high-quality dataset construction method for complex
contract information extraction tasks in industrial scenarios and fine-tunes a
large language model based on this dataset. Firstly, cluster analysis is
performed on industrial contract texts, and GPT-4 and GPT-3.5 are used to
extract key information from the original contract data, obtaining high-quality
data annotations. Secondly, data augmentation is achieved by constructing new
texts, and GPT-3.5 generates unstructured contract texts from randomly combined
keywords, improving model robustness. Finally, the large language model is
fine-tuned based on the high-quality dataset. Experimental results show that
the model achieves excellent overall performance while ensuring high field
recall and precision and considering parsing efficiency. LoRA, data balancing,
and data augmentation effectively enhance model accuracy and robustness. The
proposed method provides a novel and efficient solution for industrial contract
information extraction tasks.

</details>


### [27] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
*Juan B. Gutiérrez*

Main category: cs.CL

TL;DR: 论文提出了一种基于讨论网络的模型，将人类与大型语言模型（LLM）平等视为节点，分析其交互中的无效性（如事实、逻辑或结构错误），并揭示了四种危害。通过数学模型发现，网络在漂移和自我修复下趋于稳定，而加入伪造会重现当前LLM的高错误率。引入同行评审可显著提升真实性，并通过开源算法FOO实现。


<details>
  <summary>Details</summary>
Motivation: 研究人类与LLM交互中的无效性问题，探索如何通过讨论网络提升模型可靠性。

Method: 提出讨论网络模型，定义无效性及其四种危害，建立数学模型分析网络行为，并开发FOO算法实现同行评审。

Result: 网络在漂移和自我修复下稳定于较低错误率；加入伪造导致高错误率；同行评审显著提升真实性。

Conclusion: 提升LLM可靠性的关键在于将不完美模型整合到相互监督的网络中，而非追求单一模型的完美。

Abstract: Large-language models turn writing into a live exchange between humans and
software. We capture this new medium with a discursive-network model that
treats people and LLMs as equal nodes and tracks how their statements
circulate. Broadening the focus from isolated hallucinations, we define
invalidation (any factual, logical, or structural breach) and show it follows
four hazards: drift from truth, self-repair, fresh fabrication, and external
detection. A general mathematical model of discursive networks is developed to
provide valuable insights: A network governed only by drift and self-repair
stabilizes at a modest error rate; adding fabrication reproduces the high rates
seen in current LLMs. Giving each false claim even a small chance of peer
review shifts the system to a truth-dominant state. We operationalize peer
review with the open-source \emph{Flaws-of-Others (FOO) algorithm}: a
configurable loop in which any set of agents critique one another while a
harmoniser merges their verdicts. The takeaway is practical and cultural:
reliability in this new medium comes not from perfecting single models but from
wiring imperfect ones into networks that keep each other honest.

</details>


### [28] [Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis](https://arxiv.org/abs/2507.06571)
*Srihari K B,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 提出了一种结合多模态知识图谱（MMKG）与生成式AI的食品领域QA框架，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 通过结合结构化知识与多模态生成技术，提升食品领域问答系统的可靠性和多样性。

Method: 构建包含13,000食谱、3,000食材的MMKG，生成40,000 QA对，联合微调LLaMA 3.1-8B和Stable Diffusion 3.5-Large。

Result: BERTScore提升16.2%，FID降低37.8%，CLIP对齐提升31.1%，图像重用准确率达94.1%。

Conclusion: 结构化知识与多模态生成结合显著提升了食品QA的可靠性和多样性。

Abstract: We propose a unified food-domain QA framework that combines a large-scale
multimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000
recipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate
40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint
fine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves
BERTScore by 16.2\%, reduces FID by 37.8\%, and boosts CLIP alignment by
31.1\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\% to 7.3\%) and
LLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid
retrieval-generation strategy achieves 94.1\% accurate image reuse and 85\%
adequacy in synthesis. Our results demonstrate that structured knowledge and
multimodal generation together enhance reliability and diversity in food QA.

</details>


### [29] [Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation](https://arxiv.org/abs/2507.06607)
*Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen*

Main category: cs.CL

TL;DR: 论文提出了一种名为Gated Memory Unit (GMU)的机制，用于在SSM层之间高效共享内存，并基于此构建了SambaY架构，显著提升了解码效率和长上下文性能。


<details>
  <summary>Details</summary>
Motivation: 尽管混合架构如Samba和YOCO在序列建模中表现优异，但此前研究未探索SSM层间表示共享的效率潜力。

Method: 引入GMU机制，构建SambaY架构，结合Samba和YOCO的优势，实现跨层内存共享。

Result: SambaY显著提升解码效率，保持线性预填充时间复杂度，并在长上下文任务中表现优异。最大模型在推理任务中性能优于基线，且解码吞吐量提升10倍。

Conclusion: GMU和SambaY架构为高效序列建模提供了新思路，尤其在长上下文和大规模计算场景下表现突出。

Abstract: Recent advances in language modeling have demonstrated the effectiveness of
State Space Models (SSMs) for efficient sequence modeling. While hybrid
architectures such as Samba and the decoder-decoder architecture, YOCO, have
shown promising performance gains over Transformers, prior works have not
investigated the efficiency potential of representation sharing between SSM
layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet
effective mechanism for efficient memory sharing across layers. We apply it to
create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in
the cross-decoder to share memory readout states from a Samba-based
self-decoder. SambaY significantly enhances decoding efficiency, preserves
linear pre-filling time complexity, and boosts long-context performance, all
while eliminating the need for explicit positional encoding. Through extensive
scaling experiments, we demonstrate that our model exhibits a significantly
lower irreducible loss compared to a strong YOCO baseline, indicating superior
performance scalability under large-scale compute regimes. Our largest model
enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves
significantly better performance than Phi4-mini-Reasoning on reasoning tasks
such as Math500, AIME24/25, and GPQA Diamond without any reinforcement
learning, while delivering up to 10x higher decoding throughput on 2K-length
prompts with 32K generation length under the vLLM inference framework. We
release our training codebase on open-source data at
https://github.com/microsoft/ArchScale.

</details>


### [30] [FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation](https://arxiv.org/abs/2507.06622)
*Boshko Koloski,Senja Pollak,Roberto Navigli,Blaž Škrlj*

Main category: cs.CL

TL;DR: FuDoBa是一种基于贝叶斯优化的方法，结合LLM嵌入与领域知识，生成低维、任务相关的表示，提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成的高维嵌入在领域应用中过于通用或低效的问题。

Method: 通过贝叶斯优化融合LLM嵌入与领域知识（本地和WikiData），生成低维表示。

Result: 在六个数据集上验证，性能优于或媲美专有LLM嵌入基线。

Conclusion: FuDoBa能有效生成高效、可解释的表示，适用于领域特定任务。

Abstract: Building on the success of Large Language Models (LLMs), LLM-based
representations have dominated the document representation landscape, achieving
great performance on the document embedding benchmarks. However, the
high-dimensional, computationally expensive embeddings from LLMs tend to be
either too generic or inefficient for domain-specific applications. To address
these limitations, we introduce FuDoBa a Bayesian optimisation-based method
that integrates LLM-based embeddings with domain-specific structured knowledge,
sourced both locally and from external repositories like WikiData. This fusion
produces low-dimensional, task-relevant representations while reducing training
complexity and yielding interpretable early-fusion weights for enhanced
classification performance. We demonstrate the effectiveness of our approach on
six datasets in two domains, showing that when paired with robust AutoML-based
classifiers, our proposed representation learning approach performs on par
with, or surpasses, those produced solely by the proprietary LLM-based
embedding baselines.

</details>


### [31] [Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review](https://arxiv.org/abs/2507.06623)
*James Stewart-Evans,Emma Wilson,Tessa Langley,Andrew Prayle,Angela Hands,Karen Exley,Jo Leonardi-Bee*

Main category: cs.CL

TL;DR: 论文探讨了使用Claude 3.5 Sonnet和审查协议进行数据提取的两种方法，发现其在简单数据提取中准确性高，但在复杂数据中表现不佳，建议进一步评估和报告LLM性能。


<details>
  <summary>Details</summary>
Motivation: 解决数据提取阶段资源密集的问题，尝试利用大型语言模型（LLM）和审查协议提高效率。

Method: 使用Claude 3.5 Sonnet和审查协议对10个证据源进行数据提取，并评估其性能。

Result: 简单数据提取准确率高（83.3%和100%），复杂数据提取准确率低（9.6%和15.8%）；总体精度>90%，但召回率和F1分数低。

Conclusion: 建议在更广泛的LLM和审查背景下进行更严格的性能评估，并报告LLM性能以支持未来研究。

Abstract: The data extraction stages of reviews are resource-intensive, and researchers
may seek to expediate data extraction using online (large language models) LLMs
and review protocols. Claude 3.5 Sonnet was used to trial two approaches that
used a review protocol to prompt data extraction from 10 evidence sources
included in a case study scoping review. A protocol-based approach was also
used to review extracted data. Limited performance evaluation was undertaken
which found high accuracy for the two extraction approaches (83.3% and 100%)
when extracting simple, well-defined citation details; accuracy was lower (9.6%
and 15.8%) when extracting more complex, subjective data items. Considering all
data items, both approaches had precision >90% but low recall (<25%) and F1
scores (<40%). The context of a complex scoping review, open response types and
methodological approach likely impacted performance due to missed and
misattributed data. LLM feedback considered the baseline extraction accurate
and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of
38 (21.1%) to key findings data items were considered to potentially add value.
However, when repeating the process with a dataset featuring deliberate errors,
only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for
expediency require more robust performance evaluation across a range of LLMs
and review contexts with comparison to conventional prompt engineering
approaches. We recommend researchers evaluate and report LLM performance if
using them similarly to conduct data extraction or review extracted data. LLM
feedback contributed to protocol adaptation and may assist future review
protocol drafting.

</details>


### [32] [Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models](https://arxiv.org/abs/2507.06658)
*Gennadii Iakovlev*

Main category: cs.CL

TL;DR: 该论文提出了一种基于人工智能的精英极化测量方法，通过分析政客在议会演讲中提及彼此的情况，评估情绪温度，构建相互敌意指数。


<details>
  <summary>Details</summary>
Motivation: 研究精英极化现象，通过量化政客间的相互评价和情绪反应，揭示政治对立程度。

Method: 利用人工智能检测演讲中的提及对象和情绪，构建时间序列数据集，分析英国、匈牙利和意大利的数据。

Result: 生成的指数对选举活动、政党危机等事件反应良好，验证了其有效性。

Conclusion: 该方法为欧盟范围内的精英极化研究提供了基础，未来可扩展为20年的时间序列数据集。

Abstract: This project introduces a new measure of elite polarization via actor and
subject detection using artificial intelligence. I identify when politicians
mention one another in parliamentary speeches, note who is speaking and who is
being addressed, and assess the emotional temperature behind these evaluations.
This maps how elites evaluate their various out-parties, allowing us to create
an index of mutual out-party hostility, that is, elite polarization. While I
analyzed polarization data over the past four decades for the UK, and two
decades for Hungary and Italy, my approach lays the groundwork for a
twenty-year, EU-wide time-series dataset on elite polarization. I obtain the
results that can be aggregated by party and quarter. The resulting index
demonstrates a good face validity: it reacts to events such as electoral
campaigns, country- and party-level crises, and to parties losing and assuming
power.

</details>


### [33] [CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs](https://arxiv.org/abs/2507.06715)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: CLI-RAG框架通过分层分块和双阶段检索机制，解决了临床文本生成中数据分散和语义密集的挑战，显著提升了生成笔记的时序和语义对齐。


<details>
  <summary>Details</summary>
Motivation: 解决临床文本生成中因数据分散和语义密集导致的提示不完整和信息遗漏问题。

Method: 提出CLI-RAG框架，采用分层分块策略和双阶段检索机制（全局阶段识别相关笔记类型，局部阶段提取高价值内容）。

Result: 在MIMIC-III数据集上，生成的结构化进展笔记平均对齐分数达87.7%，优于临床医生笔记的80.7%。

Conclusion: CLI-RAG框架在临床文本生成中表现出高效性和一致性，为临床应用的可靠性和可重复性提供了支持。

Abstract: Large language models (LLMs), including zero-shot and few-shot paradigms,
have shown promising capabilities in clinical text generation. However,
real-world applications face two key challenges: (1) patient data is highly
unstructured, heterogeneous, and scattered across multiple note types and (2)
clinical notes are often long and semantically dense, making naive prompting
infeasible due to context length constraints and the risk of omitting
clinically relevant information.
  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a
domain-specific framework for structured and clinically grounded text
generation using LLMs. It incorporates a novel hierarchical chunking strategy
that respects clinical document structure and introduces a task-specific
dual-stage retrieval mechanism. The global stage identifies relevant note types
using evidence-based queries, while the local stage extracts high-value content
within those notes creating relevance at both document and section levels.
  We apply the system to generate structured progress notes for individual
hospital visits using 15 clinical note types from the MIMIC-III dataset.
Experiments show that it preserves temporal and semantic alignment across
visits, achieving an average alignment score of 87.7%, surpassing the 80.7%
baseline from real clinician-authored notes. The generated outputs also
demonstrate high consistency across LLMs, reinforcing deterministic behavior
essential for reproducibility, reliability, and clinical trust.

</details>


### [34] [On the Effect of Uncertainty on Layer-wise Inference Dynamics](https://arxiv.org/abs/2507.06722)
*Sunwoo Kim,Haneul Yoo,Alice Oh*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在处理确定和不确定预测时，其隐藏状态的动态变化基本一致，不确定性并未显著影响推理动态。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs内部如何表示和处理不确定性，以检测不确定性并防止幻觉。

Method: 使用Tuned Lens（Logit Lens的变体）分析11个数据集和5个模型的层间概率轨迹。

Result: 确定和不确定预测的轨迹一致，均在相似层出现置信度骤增；更强大的模型可能学会不同处理不确定性。

Conclusion: 研究质疑了简单方法检测不确定性的可行性，并展示了可解释性方法在研究不确定性影响推理中的应用。

Abstract: Understanding how large language models (LLMs) internally represent and
process their predictions is central to detecting uncertainty and preventing
hallucinations. While several studies have shown that models encode uncertainty
in their hidden states, it is underexplored how this affects the way they
process such hidden states. In this work, we demonstrate that the dynamics of
output token probabilities across layers for certain and uncertain outputs are
largely aligned, revealing that uncertainty does not seem to affect inference
dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to
analyze the layer-wise probability trajectories of final prediction tokens
across 11 datasets and 5 models. Using incorrect predictions as those with
higher epistemic uncertainty, our results show aligned trajectories for certain
and uncertain predictions that both observe abrupt increases in confidence at
similar layers. We balance this finding by showing evidence that more competent
models may learn to process uncertainty differently. Our findings challenge the
feasibility of leveraging simplistic methods for detecting uncertainty at
inference. More broadly, our work demonstrates how interpretability methods may
be used to investigate the way uncertainty affects inference.

</details>


### [35] [KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution](https://arxiv.org/abs/2507.06753)
*Ye Kyaw Thu,Thura Aung,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: 论文首次将Kolmogorov-Arnold卷积（KAConvText）应用于句子分类，涵盖仇恨言论检测、新闻分类和民族语言识别任务，比较不同嵌入配置，结果显示KAConvText-MLP结合微调fastText嵌入表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索KAConvText在句子分类中的首次应用，解决不平衡和平衡分类任务，并比较不同嵌入方法的效果。

Method: 使用KAConvText模型，比较随机和fastText嵌入（静态和微调），结合MLP和KAN分类头，并与CNN和CNN-KAN基线对比。

Result: KAConvText-MLP在仇恨言论检测、新闻分类和语言识别任务中分别达到91.23%、92.66%和99.82%的准确率。

Conclusion: KAConvText-MLP结合微调fastText嵌入在句子分类任务中表现最优，且KAN分类头增强了模型可解释性。

Abstract: This paper presents the first application of Kolmogorov-Arnold Convolution
for Text (KAConvText) in sentence classification, addressing three tasks:
imbalanced binary hate speech detection, balanced multiclass news
classification, and imbalanced multiclass ethnic language identification. We
investigate various embedding configurations, comparing random to fastText
embeddings in both static and fine-tuned settings, with embedding dimensions of
100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs
and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we
investigated KAConvText with different classification heads - MLP and KAN,
where using KAN head supports enhanced interpretability. Results show that
KAConvText-MLP with fine-tuned fastText embeddings achieves the best
performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,
92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%
accuracy (F1-score = 0.9982) for language identification.

</details>


### [36] [Checklist Engineering Empowers Multilingual LLM Judges](https://arxiv.org/abs/2507.06774)
*Mohammad Ghiasvand Mohammadkhani,Hamid Beigy*

Main category: cs.CL

TL;DR: 论文提出了一种无需训练的框架CE-Judge，利用清单直觉进行多语言文本评估，性能优于基线模型且与GPT-4o相当。


<details>
  <summary>Details</summary>
Motivation: 当前多语言文本评估依赖专有模型或大量训练数据，成本高且效率低，亟需一种更高效的方法。

Method: 提出CE-Judge框架，基于清单直觉，使用开源模型进行多语言评估，无需训练。

Result: 在多种语言和三个基准数据集上，CE-Judge表现优于基线模型，与GPT-4o相当。

Conclusion: CE-Judge为多语言文本评估提供了一种高效、低成本且无需训练的解决方案。

Abstract: Automated text evaluation has long been a central issue in Natural Language
Processing (NLP). Recently, the field has shifted toward using Large Language
Models (LLMs) as evaluators-a trend known as the LLM-as-a-Judge paradigm. While
promising and easily adaptable across tasks, this approach has seen limited
exploration in multilingual contexts. Existing multilingual studies often rely
on proprietary models or require extensive training data for fine-tuning,
raising concerns about cost, time, and efficiency. In this paper, we propose
Checklist Engineering based LLM-as-a-Judge (CE-Judge), a training-free
framework that uses checklist intuition for multilingual evaluation with an
open-source model. Experiments across multiple languages and three benchmark
datasets, under both pointwise and pairwise settings, show that our method
generally surpasses the baselines and performs on par with the GPT-4o model.

</details>


### [37] [Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications](https://arxiv.org/abs/2507.06795)
*Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CL

TL;DR: 研究验证了基于DACP的方法在小型语言模型（sLLMs）上的有效性，证明其在目标领域性能提升的同时保持通用能力，为企业部署提供了经济高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管开源大语言模型（LLMs）为企业应用提供了机会，但许多组织缺乏部署和维护大规模模型的基础设施，因此小型LLMs（sLLMs）成为实用替代方案。然而，其性能限制和领域适应性仍需改进。

Method: 采用领域自适应持续预训练（DACP）方法，应用于多种基础模型和服务领域，通过实验和实际评估验证其效果。

Result: 实验表明，应用DACP的sLLMs在目标领域性能显著提升，同时保持通用能力。

Conclusion: DACP为sLLMs提供了一种经济高效且可扩展的解决方案，适合企业级部署。

Abstract: The emergence of open-source large language models (LLMs) has expanded
opportunities for enterprise applications; however, many organizations still
lack the infrastructure to deploy and maintain large-scale models. As a result,
small LLMs (sLLMs) have become a practical alternative, despite their inherent
performance limitations. While Domain Adaptive Continual Pretraining (DACP) has
been previously explored as a method for domain adaptation, its utility in
commercial applications remains under-examined. In this study, we validate the
effectiveness of applying a DACP-based recipe across diverse foundation models
and service domains. Through extensive experiments and real-world evaluations,
we demonstrate that DACP-applied sLLMs achieve substantial gains in target
domain performance while preserving general capabilities, offering a
cost-efficient and scalable solution for enterprise-level deployment.

</details>


### [38] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
*Matthew Anderson Hendricks,Alice Cicirello*

Main category: cs.CL

TL;DR: 提出一种利用领域和专家知识自动生成动态系统计算模型的策略，通过SysML图、NLP和LLM提升生成效率，并通过案例验证其性能优于仅用LLM的方法。


<details>
  <summary>Details</summary>
Motivation: 加速工程动态系统的设计和部署，通过自动化生成计算模型减少人工干预。

Method: 分五步实现，结合SysML图、NLP和LLM技术，提取关键信息并生成模型。

Result: 通过案例研究验证了方法的有效性，性能优于仅依赖LLM的生成方式。

Conclusion: 该方法具有通用性，适用于多种系统和领域，并能显著提升模型生成效率。

Abstract: This paper contributes to speeding up the design and deployment of
engineering dynamical systems by proposing a strategy for exploiting domain and
expert knowledge for the automated generation of dynamical system computational
model starting from a corpus of document relevant to the dynamical system of
interest and an input document describing the specific system. This strategy is
implemented in five steps and, crucially, it uses system modeling language
diagrams (SysML) to extract accurate information about the dependencies,
attributes, and operations of components. Natural Language Processing (NLP)
strategies and Large Language Models (LLMs) are employed in specific tasks to
improve intermediate outputs of the SySML diagrams automated generation, such
as: list of key nouns; list of extracted relationships; list of key phrases and
key relationships; block attribute values; block relationships; and BDD diagram
generation. The applicability of automated SysML diagram generation is
illustrated with different case studies. The computational models of complex
dynamical systems from SysML diagrams are then obtained via code generation and
computational model generation steps. In the code generation step, NLP
strategies are used for summarization, while LLMs are used for validation only.
The proposed approach is not limited to a specific system, domain, or
computational software. The applicability of the proposed approach is shown via
an end-to-end example from text to model of a simple pendulum, showing improved
performance compared to results yielded by LLMs only.

</details>


### [39] [Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework](https://arxiv.org/abs/2507.06829)
*Zenan Xu,Zexuan Qiu,Guanhua Huang,Kun Li,Siheng Li,Chenchen Zhang,Kejiao Li,Qi Yi,Yuhao Jiang,Bo Zhou,Fengzong Lian,Zhanhui Kang*

Main category: cs.CL

TL;DR: 论文提出了一种结合顺序推理和并行推理优势的协作推理框架，并引入语义熵（SE）作为动态控制推理质量的指标。


<details>
  <summary>Details</summary>
Motivation: 现有顺序推理和并行推理方法存在效率低或缺乏协调的问题，需要一种更灵活的推理框架。

Method: 设计了协作推理框架，利用语义熵（SE）评估并行模型响应的语义多样性，动态控制推理过程。

Result: 语义熵（SE）与准确性呈强负相关，能有效指示推理质量。

Conclusion: 协作推理框架结合了两种推理范式的优势，语义熵（SE）为动态控制提供了可靠指标。

Abstract: Recent advances in large language models (LLMs) have accelerated progress
toward artificial general intelligence, with inference-time scaling emerging as
a key technique. Contemporary approaches leverage either sequential reasoning
(iteratively extending chains of thought) or parallel reasoning (generating
multiple solutions simultaneously) to scale inference. However, both paradigms
face fundamental limitations: sequential scaling typically relies on arbitrary
token budgets for termination, leading to inefficiency or premature cutoff;
while parallel scaling often lacks coordination among parallel branches and
requires intrusive fine-tuning to perform effectively. In light of these
challenges, we aim to design a flexible test-time collaborative inference
framework that exploits the complementary strengths of both sequential and
parallel reasoning paradigms. Towards this goal, the core challenge lies in
developing an efficient and accurate intrinsic quality metric to assess model
responses during collaborative inference, enabling dynamic control and early
termination of the reasoning trace. To address this challenge, we introduce
semantic entropy (SE), which quantifies the semantic diversity of parallel
model responses and serves as a robust indicator of reasoning quality due to
its strong negative correlation with accuracy...

</details>


### [40] [Shifting from Ranking to Set Selection for Retrieval Augmented Generation](https://arxiv.org/abs/2507.06838)
*Dahyun Lee,Yongrae Jo,Haeju Park,Moontae Lee*

Main category: cs.CL

TL;DR: SETR提出了一种基于集合的段落选择方法，通过Chain-of-Thought推理明确查询的信息需求，并选择最优段落集合以满足需求，显著提升了多跳问答中的检索质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于段落个体相关性重排序，难以满足复杂查询（如多跳问答）的信息需求。

Method: 引入SETR，通过Chain-of-Thought推理识别查询的信息需求，并选择最优段落集合。

Result: 在多跳RAG基准测试中，SETR在答案正确性和检索质量上优于现有方法。

Conclusion: SETR为RAG系统提供了一种高效且有效的替代方案，优于传统重排序方法。

Abstract: Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved
passages are not only individually relevant but also collectively form a
comprehensive set. Existing approaches primarily rerank top-k passages based on
their individual relevance, often failing to meet the information needs of
complex queries in multi-hop question answering. In this work, we propose a
set-wise passage selection approach and introduce SETR, which explicitly
identifies the information requirements of a query through Chain-of-Thought
reasoning and selects an optimal set of passages that collectively satisfy
those requirements. Experiments on multi-hop RAG benchmarks show that SETR
outperforms both proprietary LLM-based rerankers and open-source baselines in
terms of answer correctness and retrieval quality, providing an effective and
efficient alternative to traditional rerankers in RAG systems. The code is
available at https://github.com/LGAI-Research/SetR

</details>


### [41] [Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights](https://arxiv.org/abs/2507.06893)
*Alexandra Abbas,Celia Waggoner,Justin Olive*

Main category: cs.CL

TL;DR: 本文总结了维护开源AI评估工具库的实践经验，提出了解决社区贡献扩展、统计方法和质量控制的关键挑战。


<details>
  <summary>Details</summary>
Motivation: AI评估对评估大型语言模型的能力和安全性至关重要，但实施和维护这些评估面临诸多挑战。

Method: 提出了三种解决方案：(1) 结构化队列管理框架，(2) 统计方法优化重采样和跨模型比较，(3) 系统化的质量控制流程。

Result: 分析表明，AI评估需要专门的基础设施、统计严谨性和社区协调。

Conclusion: AI评估需要超越传统软件开发实践的专门方法和工具。

Abstract: AI evaluations have become critical tools for assessing large language model
capabilities and safety. This paper presents practical insights from eight
months of maintaining $inspect\_evals$, an open-source repository of 70+
community-contributed AI evaluations. We identify key challenges in
implementing and maintaining AI evaluations and develop solutions including:
(1) a structured cohort management framework for scaling community
contributions, (2) statistical methodologies for optimal resampling and
cross-model comparison with uncertainty quantification, and (3) systematic
quality control processes for reproducibility. Our analysis reveals that AI
evaluation requires specialized infrastructure, statistical rigor, and
community coordination beyond traditional software development practices.

</details>


### [42] [SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN](https://arxiv.org/abs/2507.06895)
*Luca Mariotti,Veronica Guidetti,Federica Mandreoli*

Main category: cs.CL

TL;DR: SCoRE是一个模块化、低成本的句子级关系抽取系统，结合对比学习和贝叶斯kNN分类器，在噪声标注下表现优异，并提出了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱（KG）增强中关系抽取（RE）在低监督设置下的需求，特别是适应性和噪声鲁棒性。

Method: 结合监督对比学习和贝叶斯kNN分类器，无需微调，支持多种预训练语言模型（PLM）。

Result: 在五个基准测试中表现优于或匹配现有方法，显著降低能耗。

Conclusion: SCoRE因其高效、模块化和可扩展性，成为现实世界RE应用的理想选择。

Abstract: The growing demand for efficient knowledge graph (KG) enrichment leveraging
external corpora has intensified interest in relation extraction (RE),
particularly under low-supervision settings. To address the need for adaptable
and noise-resilient RE solutions that integrate seamlessly with pre-trained
large language models (PLMs), we introduce SCoRE, a modular and cost-effective
sentence-level RE system. SCoRE enables easy PLM switching, requires no
finetuning, and adapts smoothly to diverse corpora and KGs. By combining
supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)
classifier for multi-label classification, it delivers robust performance
despite the noisy annotations of distantly supervised corpora. To improve RE
evaluation, we propose two novel metrics: Correlation Structure Distance (CSD),
measuring the alignment between learned relational patterns and KG structures,
and Precision at R (P@R), assessing utility as a recommender system. We also
release Wiki20d, a benchmark dataset replicating real-world RE conditions where
only KG-derived annotations are available. Experiments on five benchmarks show
that SCoRE matches or surpasses state-of-the-art methods while significantly
reducing energy consumption. Further analyses reveal that increasing model
complexity, as seen in prior work, degrades performance, highlighting the
advantages of SCoRE's minimal design. Combining efficiency, modularity, and
scalability, SCoRE stands as an optimal choice for real-world RE applications.

</details>


### [43] [VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation](https://arxiv.org/abs/2507.06899)
*Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: GUI代理（基于大型视觉语言模型）存在视觉定位漏洞，易受新型后门攻击（如VisualTrap），仅需5%污染数据即可生效，且攻击具有跨环境泛化能力。


<details>
  <summary>Details</summary>
Motivation: GUI代理的视觉定位功能可能引入安全漏洞，但目前相关威胁（如后门攻击）研究不足。

Method: 提出VisualTrap方法，通过污染预训练数据误导代理的视觉定位，使其将文本计划映射到错误位置。

Result: 实验表明，仅需5%污染数据和隐蔽视觉触发即可高效攻击，且攻击能跨任务和环境泛化。

Conclusion: GUI代理的后门攻击风险亟需进一步研究。

Abstract: Graphical User Interface (GUI) agents powered by Large Vision-Language Models
(LVLMs) have emerged as a revolutionary approach to automating human-machine
interactions, capable of autonomously operating personal devices (e.g., mobile
phones) or applications within the device to perform complex real-world tasks
in a human-like manner. However, their close integration with personal devices
raises significant security concerns, with many threats, including backdoor
attacks, remaining largely unexplored. This work reveals that the visual
grounding of GUI agent-mapping textual plans to GUI elements-can introduce
vulnerabilities, enabling new types of backdoor attacks. With backdoor attack
targeting visual grounding, the agent's behavior can be compromised even when
given correct task-solving plans. To validate this vulnerability, we propose
VisualTrap, a method that can hijack the grounding by misleading the agent to
locate textual plans to trigger locations instead of the intended targets.
VisualTrap uses the common method of injecting poisoned data for attacks, and
does so during the pre-training of visual grounding to ensure practical
feasibility of attacking. Empirical results show that VisualTrap can
effectively hijack visual grounding with as little as 5% poisoned data and
highly stealthy visual triggers (invisible to the human eye); and the attack
can be generalized to downstream tasks, even after clean fine-tuning. Moreover,
the injected trigger can remain effective across different GUI environments,
e.g., being trained on mobile/web and generalizing to desktop environments.
These findings underscore the urgent need for further research on backdoor
attack risks in GUI agents.

</details>


### [44] [MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection](https://arxiv.org/abs/2507.06908)
*Ziyan Liu,Chunxiao Fan,Haoran Lou,Yuexin Wu,Kaiwei Deng*

Main category: cs.CL

TL;DR: MIND是一个多智能体框架，用于零样本有害模因检测，无需标注数据，通过检索相似模因、双向洞察机制和多智能体辩论实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法难以检测新模因，因其动态变化且缺乏最新标注数据，MIND旨在解决这一问题。

Method: MIND采用三种策略：检索相似模因提供上下文、双向洞察机制提取全面理解、多智能体辩论确保决策稳健。

Result: 在三个模因数据集上，MIND优于现有零样本方法，且在不同模型架构和参数规模上表现良好。

Conclusion: MIND为有害模因检测提供了可扩展的解决方案，代码已开源。

Abstract: The rapid expansion of memes on social media has highlighted the urgent need
for effective approaches to detect harmful content. However, traditional
data-driven approaches struggle to detect new memes due to their evolving
nature and the lack of up-to-date annotated data. To address this issue, we
propose MIND, a multi-agent framework for zero-shot harmful meme detection that
does not rely on annotated data. MIND implements three key strategies: 1) We
retrieve similar memes from an unannotated reference set to provide contextual
information. 2) We propose a bi-directional insight derivation mechanism to
extract a comprehensive understanding of similar memes. 3) We then employ a
multi-agent debate mechanism to ensure robust decision-making through reasoned
arbitration. Extensive experiments on three meme datasets demonstrate that our
proposed framework not only outperforms existing zero-shot approaches but also
shows strong generalization across different model architectures and parameter
scales, providing a scalable solution for harmful meme detection. The code is
available at https://github.com/destroy-lonely/MIND.

</details>


### [45] [MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction](https://arxiv.org/abs/2507.06909)
*Xiao Wang,Jiahuan Pei,Diancheng Shui,Zhiguang Han,Xin Sun,Dawei Zhu,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 论文研究了法律判决预测中多被告和多罪名是否应分开处理的问题，提出了MPMCP数据集，并评估了不同LLM在四种法律场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨多被告和多罪名在法律判决预测中的影响，填补研究空白。

Method: 引入MPMCP数据集，评估四种法律场景下LLM的表现，包括单被告单罪名、单被告多罪名、多被告单罪名和多被告多罪名。

Result: 多被告多罪名场景（S4）最具挑战性，不同模型表现差异显著，如InternLM2和Lawformer在S4中的F1-score和LogD变化明显。

Conclusion: 多被告和多罪名对法律判决预测有显著影响，需针对性优化模型。

Abstract: Legal judgment prediction offers a compelling method to aid legal
practitioners and researchers. However, the research question remains
relatively under-explored: Should multiple defendants and charges be treated
separately in LJP? To address this, we introduce a new dataset namely
multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating
the performance of several prevailing legal large language models (LLMs) on
four practical legal judgment scenarios: (S1) single defendant with a single
charge, (S2) single defendant with multiple charges, (S3) multiple defendants
with a single charge, and (S4) multiple defendants with multiple charges. We
evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty
term prediction. We have conducted extensive experiments and found that the
scenario involving multiple defendants and multiple charges (S4) poses the
greatest challenges, followed by S2, S3, and S1. The impact varies
significantly depending on the model. For example, in S4 compared to S1,
InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD,
while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD.
Our dataset and code are available at
https://github.com/lololo-xiao/MultiJustice-MPMCP.

</details>


### [46] [Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues](https://arxiv.org/abs/2507.06910)
*Fareya Ikram,Alexander Scarlatos,Andrew Lan*

Main category: cs.CL

TL;DR: 研究了现代大语言模型（如Llama 3和GPT-4o）在预测辅导对话中导师策略和学生表现的能力，发现即使最先进的模型也难以准确预测导师策略，但导师策略对学生表现有显著影响。


<details>
  <summary>Details</summary>
Motivation: 在线学习和AI辅导的兴起使得导师策略对学生表现的影响备受关注，但目前缺乏预测导师策略的研究。

Method: 使用两个数学辅导对话数据集，评估Llama 3和GPT-4o在预测导师策略和学生表现方面的能力。

Result: 最先进的大语言模型在预测导师策略方面表现不佳，但导师策略对学生表现有显著影响。

Conclusion: 需要更强大的方法来预测导师策略，以优化辅导效果。

Abstract: Tutoring dialogues have gained significant attention in recent years, given
the prominence of online learning and the emerging tutoring abilities of
artificial intelligence (AI) agents powered by large language models (LLMs).
Recent studies have shown that the strategies used by tutors can have
significant effects on student outcomes, necessitating methods to predict how
tutors will behave and how their actions impact students. However, few works
have studied predicting tutor strategy in dialogues. Therefore, in this work we
investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to
predict both future tutor moves and student outcomes in dialogues, using two
math tutoring dialogue datasets. We find that even state-of-the-art LLMs
struggle to predict future tutor strategy while tutor strategy is highly
indicative of student outcomes, outlining a need for more powerful methods to
approach this task.

</details>


### [47] [Rethinking Verification for LLM Code Generation: From Generation to Testing](https://arxiv.org/abs/2507.06920)
*Zihan Ma,Taolin Zhang,Maosong Cao,Wenwei Zhang,Minnan Luo,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 论文提出了一种名为SAGA的人机协作方法，通过多维度指标和TCGBench提升测试用例的覆盖率和质量，显著提高了代码生成评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评估套件（如HumanEval和LiveCodeBench）的测试用例数量有限且同质化，导致性能评估不准确，影响了强化学习框架中的奖励估计。

Method: 提出多维度指标量化测试套件全面性，并引入SAGA方法，结合人类编程经验和LLM推理能力生成高质量测试用例。开发TCGBench用于TCG任务研究。

Result: SAGA在TCGBench上的检测率达到90.62%，验证器准确率为32.58%，比LiveCodeBench-v6高10.78%。

Conclusion: SAGA方法显著提升了代码生成评估的可靠性，为RLVR和自动化测试合成奠定了基础。

Abstract: Large language models (LLMs) have recently achieved notable success in
code-generation benchmarks such as HumanEval and LiveCodeBench. However, a
detailed examination reveals that these evaluation suites often comprise only a
limited number of homogeneous test cases, resulting in subtle faults going
undetected. This not only artificially inflates measured performance but also
compromises accurate reward estimation in reinforcement learning frameworks
utilizing verifiable rewards (RLVR). To address these critical shortcomings, we
systematically investigate the test-case generation (TCG) task by proposing
multi-dimensional metrics designed to rigorously quantify test-suite
thoroughness. Furthermore, we introduce a human-LLM collaborative method
(SAGA), leveraging human programming expertise with LLM reasoning capability,
aimed at significantly enhancing both the coverage and the quality of generated
test cases. In addition, we develop a TCGBench to facilitate the study of the
TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a
verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc)
of the code generation evaluation benchmark synthesized by SAGA is 10.78%
higher than that of LiveCodeBench-v6. These results demonstrate the
effectiveness of our proposed method. We hope this work contributes to building
a scalable foundation for reliable LLM code evaluation, further advancing RLVR
in code generation, and paving the way for automated adversarial test synthesis
and adaptive benchmark integration.

</details>


### [48] [Investigating the Robustness of Retrieval-Augmented Generation at the Query Level](https://arxiv.org/abs/2507.06956)
*Sezen Perçin,Xin Su,Qutub Sha Syed,Phillip Howard,Aleksei Kuvshinov,Leo Schwinn,Kay-Ulrich Scholl*

Main category: cs.CL

TL;DR: 论文研究了检索增强生成（RAG）系统对查询扰动的敏感性，发现常用检索器性能在轻微查询变化下显著下降，并提出评估框架和改进建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）更新成本高且效率低，RAG通过动态整合外部知识改善事实一致性和减少幻觉，但其性能高度依赖查询质量。

Method: 分析RAG流程中各组件对查询扰动的敏感性，研究模块单独及组合效果，并提出评估框架。

Result: 实验显示检索器性能在轻微查询变化下显著下降，基于1092次实验结果提出改进建议。

Conclusion: RAG系统对查询质量敏感，需系统性评估和改进以提升鲁棒性。

Abstract: Large language models (LLMs) are very costly and inefficient to update with
new information. To address this limitation, retrieval-augmented generation
(RAG) has been proposed as a solution that dynamically incorporates external
knowledge during inference, improving factual consistency and reducing
hallucinations. Despite its promise, RAG systems face practical challenges-most
notably, a strong dependence on the quality of the input query for accurate
retrieval. In this paper, we investigate the sensitivity of different
components in the RAG pipeline to various types of query perturbations. Our
analysis reveals that the performance of commonly used retrievers can degrade
significantly even under minor query variations. We study each module in
isolation as well as their combined effect in an end-to-end question answering
setting, using both general-domain and domain-specific datasets. Additionally,
we propose an evaluation framework to systematically assess the query-level
robustness of RAG pipelines and offer actionable recommendations for
practitioners based on the results of more than 1092 experiments we performed.

</details>


### [49] [FRaN-X: FRaming and Narratives-eXplorer](https://arxiv.org/abs/2507.06974)
*Artur Muratov,Hana Fatima Shaikh,Vanshikaa Jani,Tarek Mahmoud,Zhuohan Xie,Daniil Orel,Aaryamonvikram Singh,Yuxia Wang,Aadi Joshi,Hasan Iqbal,Ming Shan Hee,Dhruv Sahnan,Nikolaos Nikolaidis,Purificação Silvano,Dimitar Dimitrov,Roman Yangarber,Ricardo Campos,Alípio Jorge,Nuno Guimarães,Elisa Sartori,Nicolas Stefanovitch,Giovanni Da San Martino,Jakub Piskorski,Preslav Nakov*

Main category: cs.CL

TL;DR: FRaN-X是一个自动检测实体提及并分类其叙事角色的系统，支持五种语言和两种领域，提供交互式界面和可视化分析。


<details>
  <summary>Details</summary>
Motivation: 解决自动检测和标记实体如何被框架化的挑战，帮助媒体分析师探索和比较不同来源的叙事。

Method: 采用两阶段系统，结合序列标记和细粒度角色分类，使用22种细粒度角色分类实体。

Result: 系统支持多语言和多领域分析，提供交互式界面、搜索功能和时间线视图，便于用户跟踪实体角色变化。

Conclusion: FRaN-X为媒体分析师提供了强大的工具，公开可用，支持多语言和多领域分析。

Abstract: We present FRaN-X, a Framing and Narratives Explorer that automatically
detects entity mentions and classifies their narrative roles directly from raw
text. FRaN-X comprises a two-stage system that combines sequence labeling with
fine-grained role classification to reveal how entities are portrayed as
protagonists, antagonists, or innocents, using a unique taxonomy of 22
fine-grained roles nested under these three main categories. The system
supports five languages (Bulgarian, English, Hindi, Russian, and Portuguese)
and two domains (the Russia-Ukraine Conflict and Climate Change). It provides
an interactive web interface for media analysts to explore and compare framing
across different sources, tackling the challenge of automatically detecting and
labeling how entities are framed. Our system allows end users to focus on a
single article as well as analyze up to four articles simultaneously. We
provide aggregate level analysis including an intuitive graph visualization
that highlights the narrative a group of articles are pushing. Our system
includes a search feature for users to look up entities of interest, along with
a timeline view that allows analysts to track an entity's role transitions
across different contexts within the article. The FRaN-X system and the trained
models are licensed under an MIT License. FRaN-X is publicly accessible at
https://fran-x.streamlit.app/ and a video demonstration is available at
https://youtu.be/VZVi-1B6yYk.

</details>


### [50] [FlexOlmo: Open Language Models for Flexible Data Use](https://arxiv.org/abs/2507.07024)
*Weijia Shi,Akshita Bhagia,Kevin Farhat,Niklas Muennighoff,Pete Walsh,Jacob Morrison,Dustin Schwenk,Shayne Longpre,Jake Poznanski,Allyson Ettinger,Daogao Liu,Margaret Li,Dirk Groeneveld,Mike Lewis,Wen-tau Yih,Luca Soldaini,Kyle Lo,Noah A. Smith,Luke Zettlemoyer,Pang Wei Koh,Hannaneh Hajishirzi,Ali Farhadi,Sewon Min*

Main category: cs.CL

TL;DR: FlexOlmo是一种新型语言模型，支持分布式训练和数据灵活推理，无需共享数据，通过混合专家架构实现独立训练和灵活集成。


<details>
  <summary>Details</summary>
Motivation: 解决在受监管行业中使用敏感或受保护数据时的数据共享和访问控制问题。

Method: 采用混合专家（MoE）架构，每个专家独立训练于封闭数据集，通过领域感知路由集成，无需联合训练。

Result: 在31个任务上评估，FlexOlmo平均相对改进41%，优于现有模型合并方法10.1%，且与无限制训练的MoE性能相当。

Conclusion: FlexOlmo为数据所有者和研究者提供了一种解决方案，既能利用封闭数据，又能尊重数据所有者的访问控制需求。

Abstract: We introduce FlexOlmo, a new class of language models (LMs) that supports (1)
distributed training without data sharing, where different model parameters are
independently trained on closed datasets, and (2) data-flexible inference,
where these parameters along with their associated data can be flexibly
included or excluded from model inferences with no further training. FlexOlmo
employs a mixture-of-experts (MoE) architecture where each expert is trained
independently on closed datasets and later integrated through a new
domain-informed routing without any joint training. FlexOlmo is trained on
FlexMix, a corpus we curate comprising publicly available datasets alongside
seven domain-specific sets, representing realistic approximations of closed
sets. We evaluate models with up to 37 billion parameters (20 billion active)
on 31 diverse downstream tasks. We show that a general expert trained on public
data can be effectively combined with independently trained experts from other
data owners, leading to an average 41% relative improvement while allowing
users to opt out of certain data based on data licensing or permission
requirements. Our approach also outperforms prior model merging methods by
10.1% on average and surpasses the standard MoE trained without data
restrictions using the same training FLOPs. Altogether, this research presents
a solution for both data owners and researchers in regulated industries with
sensitive or protected data. FlexOlmo enables benefiting from closed data while
respecting data owners' preferences by keeping their data local and supporting
fine-grained control of data access during inference.

</details>


### [51] [UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations](https://arxiv.org/abs/2507.07030)
*Fengran Mo,Yifan Gao,Chuan Meng,Xin Liu,Zhuofeng Wu,Kelong Mao,Zhengyang Wang,Pei Chen,Zheng Li,Xian Li,Bing Yin,Meng Jiang*

Main category: cs.CL

TL;DR: 论文提出了一种统一密集检索和响应生成的模型，通过联合微调和机制设计解决了现有分离模型的局限性，并在多个数据集上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有对话搜索系统通常使用分离的模型，无法同时利用模型的内在知识，影响了检索和生成的效果。

Method: 通过联合微调不同目标，并设计两种机制以减少不一致风险和数据差异。

Result: 在五个对话搜索数据集上的评估表明，统一模型能同时提升两项任务，并优于现有基线。

Conclusion: 统一模型能有效解决分离模型的局限性，提升对话搜索系统的性能。

Abstract: The rapid advancement of conversational search systems revolutionizes how
information is accessed by enabling the multi-turn interaction between the user
and the system. Existing conversational search systems are usually built with
two different models. This separation restricts the system from leveraging the
intrinsic knowledge of the models simultaneously, which cannot ensure the
effectiveness of retrieval benefiting the generation. The existing studies for
developing unified models cannot fully address the aspects of understanding
conversational context, managing retrieval independently, and generating
responses. In this paper, we explore how to unify dense retrieval and response
generation for large language models in conversation. We conduct joint
fine-tuning with different objectives and design two mechanisms to reduce the
inconsistency risks while mitigating data discrepancy. The evaluations on five
conversational search datasets demonstrate that our unified model can mutually
improve both tasks and outperform the existing baselines.

</details>


### [52] [Discrete Diffusion Models for Language Generation](https://arxiv.org/abs/2507.07050)
*Ashen Weligalle*

Main category: cs.CL

TL;DR: 该论文研究了离散扩散模型（D3PM）在自然语言生成中的表现，并与传统的自回归模型（AR）进行了比较。结果显示D3PM在生成速度上具有优势，但在压缩性能上略逊于AR模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在连续数据领域（如图像和视频生成）表现出色，但在离散数据（如自然语言）中的应用仍面临挑战。本研究旨在探索离散扩散模型在自然语言生成中的可行性和性能。

Method: 使用离散去噪扩散概率模型（D3PM）与传统自回归模型（AR）进行对比，评估指标包括Bits Per Token（BPT）、Negative Log-Likelihood（NLL）、Perplexity（PPL）和Batch Processing Speed。

Result: D3PM的最佳BPT为5.72，均值为8.05，而AR模型的BPT均值为4.59。D3PM在生成速度上表现更优，达到3.97批次/秒。

Conclusion: 离散扩散模型在自然语言生成中展现出潜力，尤其是在并行生成方面，但在生成质量上仍需改进。研究为未来非自回归语言生成提供了参考。

Abstract: Diffusion models have emerged as a powerful class of generative models,
achieving state-of-the-art results in continuous data domains such as image and
video generation. Their core mechanism involves a forward diffusion process
that gradually transforms structured data into a Gaussian-like distribution,
followed by a learned reverse process to reconstruct the data. While successful
in continuous modalities, applying this framework to discrete data-particularly
natural language-remains challenging due to token dependency complexities and
the lack of a defined generation order.This thesis investigates the feasibility
and performance of discrete diffusion models for natural language generation.
Specifically, we evaluate the Discrete Denoising Diffusion Probabilistic Model
(D3PM) and compare it with traditional autoregressive (AR) language models. To
assess generative performance, we use Bits Per Token (BPT), Negative
Log-Likelihood (NLL), Perplexity (PPL), and Batch Processing Speed.
  Results show the best-performing D3PM model achieves a BPT of 5.72, with a
mean of 8.05. The AR model outperforms in compression with a lower mean BPT of
4.59, but D3PM achieves higher processing speed, reaching up to 3.97 batches
per sec., indicating potential for parallel generation.All evaluations were
conducted under consistent conditions-generating 100,000 tokens per model with
a fixed batch size of four-for fair comparison. This research presents a
detailed analysis of diffusion-based vs. autoregressive models, highlighting
trade-offs in generative quality and efficiency. Findings emphasize both the
promise and limitations of diffusion models for discrete data, supporting
future work in non-autoregressive language generation.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [53] [Unveiling the Underwater World: CLIP Perception Model-Guided Underwater Image Enhancement](https://arxiv.org/abs/2507.06234)
*Jiangzhong Cao,Zekai Zeng,Xu Zhang,Huan Zhang,Chunling Fan,Gangyi Jiang,Weisi Lin*

Main category: cs.CV

TL;DR: 提出了一种结合CLIP感知损失模块和课程对比正则化的水下图像增强方法，显著提升了图像的感知质量和内容恢复能力。


<details>
  <summary>Details</summary>
Motivation: 水下图像质量受光吸收和散射影响，现有深度学习方法忽视人类感知且解空间约束不足，导致增强后图像感知质量下降或内容恢复不佳。

Method: 利用CLIP模型的视觉语义特征提取能力，设计感知损失模块；结合课程对比正则化，增强解空间约束，避免欠增强或过增强。

Result: 实验表明，该方法在视觉质量和泛化能力上优于现有技术。

Conclusion: 结合CLIP感知和课程对比正则化能有效提升水下图像增强的感知质量和内容恢复效果。

Abstract: High-quality underwater images are essential for both machine vision tasks
and viewers with their aesthetic appeal.However, the quality of underwater
images is severely affected by light absorption and scattering. Deep
learning-based methods for Underwater Image Enhancement (UIE) have achieved
good performance. However, these methods often overlook considering human
perception and lack sufficient constraints within the solution space.
Consequently, the enhanced images often suffer from diminished perceptual
quality or poor content restoration.To address these issues, we propose a UIE
method with a Contrastive Language-Image Pre-Training (CLIP) perception loss
module and curriculum contrastive regularization. Above all, to develop a
perception model for underwater images that more aligns with human visual
perception, the visual semantic feature extraction capability of the CLIP model
is leveraged to learn an appropriate prompt pair to map and evaluate the
quality of underwater images. This CLIP perception model is then incorporated
as a perception loss module into the enhancement network to improve the
perceptual quality of enhanced images. Furthermore, the CLIP perception model
is integrated with the curriculum contrastive regularization to enhance the
constraints imposed on the enhanced images within the CLIP perceptual space,
mitigating the risk of both under-enhancement and over-enhancement.
Specifically, the CLIP perception model is employed to assess and categorize
the learning difficulty level of negatives in the regularization process,
ensuring comprehensive and nuanced utilization of distorted images and
negatives with varied quality levels. Extensive experiments demonstrate that
our method outperforms state-of-the-art methods in terms of visual quality and
generalization ability.

</details>


### [54] [SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability](https://arxiv.org/abs/2507.06265)
*Ali Nasiri-Sarvi,Hassan Rivaz,Mahdi S. Hosseini*

Main category: cs.CV

TL;DR: SPARC框架通过统一潜在空间和跨模型对齐机制，显著提升了不同AI模型间概念表示的兼容性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法（如SAEs）因模型独立潜在概念空间导致的跨模型可解释性受限问题。

Method: 引入SPARC框架，采用Global TopK稀疏机制和Cross-Reconstruction Loss，强制跨模型共享潜在空间。

Result: 在Open Images上，SPARC将概念对齐的Jaccard相似度提升至0.80，远超之前方法。

Conclusion: SPARC实现了跨模型和跨模态的概念对齐，支持直接比较不同架构的概念表示，并具备实际应用潜力。

Abstract: Understanding how different AI models encode the same high-level concepts,
such as objects or attributes, remains challenging because each model typically
produces its own isolated representation. Existing interpretability methods
like Sparse Autoencoders (SAEs) produce latent concepts individually for each
model, resulting in incompatible concept spaces and limiting cross-model
interpretability. To address this, we introduce SPARC (Sparse Autoencoders for
Aligned Representation of Concepts), a new framework that learns a single,
unified latent space shared across diverse architectures and modalities (e.g.,
vision models like DINO, and multimodal models like CLIP). SPARC's alignment is
enforced through two key innovations: (1) a Global TopK sparsity mechanism,
ensuring all input streams activate identical latent dimensions for a given
concept; and (2) a Cross-Reconstruction Loss, which explicitly encourages
semantic consistency between models. On Open Images, SPARC dramatically
improves concept alignment, achieving a Jaccard similarity of 0.80, more than
tripling the alignment compared to previous methods. SPARC creates a shared
sparse latent space where individual dimensions often correspond to similar
high-level concepts across models and modalities, enabling direct comparison of
how different architectures represent identical concepts without requiring
manual alignment or model-specific analysis. As a consequence of this aligned
representation, SPARC also enables practical applications such as text-guided
spatial localization in vision-only models and cross-model/cross-modal
retrieval. Code and models are available at
https://github.com/AtlasAnalyticsLab/SPARC.

</details>


### [55] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
*Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma*

Main category: cs.CV

TL;DR: RPFNet通过残差先验和频域融合，高效整合多模态图像信息，提升融合质量和高级视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统图像融合方法中长距离特征依赖计算成本高和缺乏真实标注的问题。

Method: 采用双分支框架（RPM和FDFM）提取模态差异和频域特征，并通过CPM增强局部与全局特征协同。

Result: RPFNet有效整合特征，提升纹理细节和显著对象，支持高级视觉任务部署。

Conclusion: RPFNet在多模态图像融合中表现出色，兼具高效性和性能优势。

Abstract: Image fusion aims to integrate complementary information across modalities to
generate high-quality fused images, thereby enhancing the performance of
high-level vision tasks. While global spatial modeling mechanisms show
promising results, constructing long-range feature dependencies in the spatial
domain incurs substantial computational costs. Additionally, the absence of
ground-truth exacerbates the difficulty of capturing complementary features
effectively. To tackle these challenges, we propose a Residual Prior-driven
Frequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a
dual-branch feature extraction framework: the Residual Prior Module (RPM)
extracts modality-specific difference information from residual maps, thereby
providing complementary priors for fusion; the Frequency Domain Fusion Module
(FDFM) achieves efficient global feature modeling and integration through
frequency-domain convolution. Additionally, the Cross Promotion Module (CPM)
enhances the synergistic perception of local details and global structures
through bidirectional feature interaction. During training, we incorporate an
auxiliary decoder and saliency structure loss to strengthen the model's
sensitivity to modality-specific differences. Furthermore, a combination of
adaptive weight-based frequency contrastive loss and SSIM loss effectively
constrains the solution space, facilitating the joint capture of local details
and global features while ensuring the retention of complementary information.
Extensive experiments validate the fusion performance of RPFNet, which
effectively integrates discriminative features, enhances texture details and
salient objects, and can effectively facilitate the deployment of the
high-level vision task.

</details>


### [56] [A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry](https://arxiv.org/abs/2507.06269)
*Rushil Desai,Frederik Warburg,Trevor Darrell,Marissa Ramirez de Chanlatte*

Main category: cs.CV

TL;DR: BayesSDF提出了一种新的概率框架，用于量化神经隐式SDF模型中的不确定性，解决了现有方法在几何一致性和计算效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 科学模拟应用（如森林中的流体模拟）需要精确的表面几何和不确定性量化，但现有方法缺乏几何整合和校准。

Method: BayesSDF利用拉普拉斯近似和基于Hessian的度量，实现高效、表面感知的不确定性估计。

Result: 实验表明，BayesSDF在校准和几何一致性上优于现有方法，并提供可操作的下游置信度。

Conclusion: BayesSDF为不确定性感知的3D场景重建、模拟和机器人决策奠定了坚实基础。

Abstract: Quantifying uncertainty in neural implicit 3D representations, particularly
those utilizing Signed Distance Functions (SDFs), remains a substantial
challenge due to computational inefficiencies, scalability issues, and
geometric inconsistencies. Existing methods typically neglect direct geometric
integration, leading to poorly calibrated uncertainty maps. We introduce
BayesSDF, a novel probabilistic framework for uncertainty quantification in
neural implicit SDF models, motivated by scientific simulation applications
with 3D environments (e.g., forests) such as modeling fluid flow through
forests, where precise surface geometry and awareness of fidelity surface
geometric uncertainty are essential. Unlike radiance-based models such as NeRF
or 3D Gaussian splatting, which lack explicit surface formulations, SDFs define
continuous and differentiable geometry, making them better suited for physical
modeling and analysis. BayesSDF leverages a Laplace approximation to quantify
local surface instability via Hessian-based metrics, enabling computationally
efficient, surface-aware uncertainty estimation. Our method shows that
uncertainty predictions correspond closely with poorly reconstructed geometry,
providing actionable confidence measures for downstream use. Extensive
evaluations on synthetic and real-world datasets demonstrate that BayesSDF
outperforms existing methods in both calibration and geometric consistency,
establishing a strong foundation for uncertainty-aware 3D scene reconstruction,
simulation, and robotic decision-making.

</details>


### [57] [Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching](https://arxiv.org/abs/2507.06744)
*Yafei Zhang,Yongle Shang,Huafeng Li*

Main category: cs.CV

TL;DR: 提出了一种局部与全局双粒度身份关联机制，通过跨模态身份关系增强和动态调整机制，显著提升文本到人像匹配的准确性。


<details>
  <summary>Details</summary>
Motivation: 弱监督文本到人像匹配方法依赖大规模人工标注样本，现有方法难以处理复杂的一对多身份关系，限制了性能提升。

Method: 提出局部与全局双粒度身份关联机制：局部层面显式建立跨模态身份关系；全局层面构建动态跨模态身份关联网络，并引入基于置信度的动态调整机制。同时结合信息不对称样本对构建和一致性学习。

Result: 实验结果表明，该方法显著提升了跨模态匹配的准确性。

Conclusion: 该方法为文本到人像匹配提供了一种高效实用的解决方案。

Abstract: Weakly supervised text-to-person image matching, as a crucial approach to
reducing models' reliance on large-scale manually labeled samples, holds
significant research value. However, existing methods struggle to predict
complex one-to-many identity relationships, severely limiting performance
improvements. To address this challenge, we propose a local-and-global
dual-granularity identity association mechanism. Specifically, at the local
level, we explicitly establish cross-modal identity relationships within a
batch, reinforcing identity constraints across different modalities and
enabling the model to better capture subtle differences and correlations. At
the global level, we construct a dynamic cross-modal identity association
network with the visual modality as the anchor and introduce a confidence-based
dynamic adjustment mechanism, effectively enhancing the model's ability to
identify weakly associated samples while improving overall sensitivity.
Additionally, we propose an information-asymmetric sample pair construction
method combined with consistency learning to tackle hard sample mining and
enhance model robustness. Experimental results demonstrate that the proposed
method substantially boosts cross-modal matching accuracy, providing an
efficient and practical solution for text-to-person image matching.

</details>


### [58] [LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance](https://arxiv.org/abs/2507.06272)
*Zhang Li,Biao Yang,Qiang Liu,Shuo Zhang,Zhiyin Ma,Shuo Zhang,Liang Yin,Linger Deng,Yabo Sun,Yuliang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: LIRA框架通过结合语义增强特征提取器和交错局部视觉耦合，解决了多模态模型在分割和理解任务中的不准确和幻觉问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在分割和理解任务中存在不准确分割和幻觉理解的问题，主要源于视觉理解能力弱和缺乏细粒度感知。

Method: 提出LIRA框架，包含语义增强特征提取器（SEFE）和交错局部视觉耦合（ILVC），分别提升分割准确性和减少幻觉理解。

Result: LIRA在分割和理解任务中达到最先进性能，并通过AttrEval数据集量化了语义推断能力。

Conclusion: LIRA通过结合视觉理解和分割的互补关系，有效解决了现有模型的局限性，并展示了优越性能。

Abstract: While large multi-modal models (LMMs) demonstrate promising capabilities in
segmentation and comprehension, they still struggle with two limitations:
inaccurate segmentation and hallucinated comprehension. These challenges stem
primarily from constraints in weak visual comprehension and a lack of
fine-grained perception. To alleviate these limitations, we propose LIRA, a
framework that capitalizes on the complementary relationship between visual
comprehension and segmentation via two key components: (1) Semantic-Enhanced
Feature Extractor (SEFE) improves object attribute inference by fusing semantic
and pixel-level features, leading to more accurate segmentation; (2)
Interleaved Local Visual Coupling (ILVC) autoregressively generates local
descriptions after extracting local features based on segmentation masks,
offering fine-grained supervision to mitigate hallucinations. Furthermore, we
find that the precision of object segmentation is positively correlated with
the latent related semantics of the <seg> token. To quantify this relationship
and the model's potential semantic inferring ability, we introduce the
Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA
achieves state-of-the-art performance in both segmentation and comprehension
tasks. Code will be available at https://github.com/echo840/LIRA.

</details>


### [59] [Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques](https://arxiv.org/abs/2507.06275)
*Yassin Hussein Rassul,Aram M. Ahmed,Polla Fattah,Bryar A. Hassan,Arwaa W. Abdulkareem,Tarik A. Rashid,Joan Lu*

Main category: cs.CV

TL;DR: 本文综述了离线手写文本识别（HTR）中的数据增强与生成技术，探讨了传统方法与深度学习方法（如GANs、扩散模型和Transformer）的应用，并分析了生成多样且真实手写样本的挑战。


<details>
  <summary>Details</summary>
Motivation: 离线HTR系统在历史文档数字化等领域至关重要，但标注数据稀缺，尤其是低资源语言和复杂脚本，限制了其性能。

Method: 采用PRISMA方法，系统筛选了1,302篇研究，最终纳入848篇，分析了传统和深度学习的数据增强与生成技术。

Result: 综述总结了现有数据集、评估指标和先进方法，揭示了研究空白。

Conclusion: 提出了未来研究方向，以推动手写文本生成在多语言和多风格场景中的发展。

Abstract: Offline Handwritten Text Recognition (HTR) systems play a crucial role in
applications such as historical document digitization, automatic form
processing, and biometric authentication. However, their performance is often
hindered by the limited availability of annotated training data, particularly
for low-resource languages and complex scripts. This paper presents a
comprehensive survey of offline handwritten data augmentation and generation
techniques designed to improve the accuracy and robustness of HTR systems. We
systematically examine traditional augmentation methods alongside recent
advances in deep learning, including Generative Adversarial Networks (GANs),
diffusion models, and transformer-based approaches. Furthermore, we explore the
challenges associated with generating diverse and realistic handwriting
samples, particularly in preserving script authenticity and addressing data
scarcity. This survey follows the PRISMA methodology, ensuring a structured and
rigorous selection process. Our analysis began with 1,302 primary studies,
which were filtered down to 848 after removing duplicates, drawing from key
academic sources such as IEEE Digital Library, Springer Link, Science Direct,
and ACM Digital Library. By evaluating existing datasets, assessment metrics,
and state-of-the-art methodologies, this survey identifies key research gaps
and proposes future directions to advance the field of handwritten text
generation across diverse linguistic and stylistic landscapes.

</details>


### [60] [VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting](https://arxiv.org/abs/2507.05116)
*Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang*

Main category: cs.CV

TL;DR: 提出了一种高效的VLA模型优化框架VOTE，通过免分词器的微调方法和集成投票策略，显著提升推理速度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在新对象或陌生环境中的泛化能力有限，且额外组件增加了计算开销，因此需要高效的动作预测方法。

Method: 采用免分词器的微调方法并行预测动作，结合集成投票策略优化动作采样。

Result: 实验显示，方法实现了35倍推理加速和145 Hz吞吐量，达到SOTA性能。

Conclusion: VOTE框架高效且泛化能力强，代码将开源。

Abstract: Recent large-scale Vision Language Action (VLA) models have shown superior
performance in robotic manipulation tasks guided by natural language. However,
their generalization remains limited when applied to novel objects or
unfamiliar environments that lie outside the training distribution. To address
this, many existing approaches integrate additional components such as depth
estimation, segmentation, or even diffusion to improve generalization, at the
cost of adding significant computation overhead, resulting in low efficiency.
This motivates the exploration of efficient action prediction methods, which
are independent of additional high-level visual representations or diffusion
techniques. In this work, we propose VOTE, an efficient and general framework
for the optimization and acceleration of VLA models. In details, we propose a
novel tokenizer-free fine-tuning approach for parallel accurate action
prediction, which reduces computational overhead and accelerates inference
speed. Additionally, we adopt an ensemble voting strategy for the action
sampling, which significantly improves model performance and enhances
generalization. Experimental results show that our method achieves
state-of-the-art performance with 35$\times$ faster inference and 145 Hz
throughput. All the details and codes will be open-sourced.

</details>


### [61] [MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation](https://arxiv.org/abs/2507.07015)
*Hui Li,Pengfei Yang,Juanyang Chen,Le Dong,Yanxin Chen,Quan Wang*

Main category: cs.CV

TL;DR: MST-Distill提出了一种新颖的跨模态知识蒸馏框架，通过混合专家教师模型和动态路由网络解决传统方法的局限性，显著提升了跨模态任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在跨模态场景中因数据和统计异质性难以利用跨模态教师模型的互补知识，存在蒸馏路径选择和知识漂移问题。

Method: 提出MST-Distill框架，结合跨模态和多模态教师模型，使用动态路由网络和掩码模块抑制模态差异并重构表示。

Result: 在五个多模态数据集上的实验表明，MST-Distill显著优于现有最先进的跨模态知识蒸馏方法。

Conclusion: MST-Distill通过动态教师模型和掩码模块有效解决了跨模态知识蒸馏的挑战，提升了性能。

Abstract: Knowledge distillation as an efficient knowledge transfer technique, has
achieved remarkable success in unimodal scenarios. However, in cross-modal
settings, conventional distillation methods encounter significant challenges
due to data and statistical heterogeneities, failing to leverage the
complementary prior knowledge embedded in cross-modal teacher models. This
paper empirically reveals two critical issues in existing approaches:
distillation path selection and knowledge drift. To address these limitations,
we propose MST-Distill, a novel cross-modal knowledge distillation framework
featuring a mixture of specialized teachers. Our approach employs a diverse
ensemble of teacher models across both cross-modal and multimodal
configurations, integrated with an instance-level routing network that
facilitates adaptive and dynamic distillation. This architecture effectively
transcends the constraints of traditional methods that rely on monotonous and
static teacher models. Additionally, we introduce a plug-in masking module,
independently trained to suppress modality-specific discrepancies and
reconstruct teacher representations, thereby mitigating knowledge drift and
enhancing transfer effectiveness. Extensive experiments across five diverse
multimodal datasets, spanning visual, audio, and text, demonstrate that our
method significantly outperforms existing state-of-the-art knowledge
distillation methods in cross-modal distillation tasks. The source code is
available at https://github.com/Gray-OREO/MST-Distill.

</details>


### [62] [Centralized Copy-Paste: Enhanced Data Augmentation Strategy for Wildland Fire Semantic Segmentation](https://arxiv.org/abs/2507.06321)
*Joon Tai Kim,Tianle Chen,Ziyu Dong,Nishanth Kunchala,Alexander Guller,Daniel Ospina Acero,Roger Williams,Mrinal Kumar*

Main category: cs.CV

TL;DR: 论文提出了一种名为CCPDA的数据增强方法，用于提升野火科学中多类分割模型的训练效果，特别是针对火类的分割性能。


<details>
  <summary>Details</summary>
Motivation: 由于收集和标注图像用于训练分割模型的成本高昂，且野火科学领域缺乏可靠的公开数据集，因此需要一种有效的数据增强方法来缓解这一问题。

Method: CCPDA方法包括三个步骤：(i)识别源图像中的火簇，(ii)应用中心化技术聚焦火区核心，(iii)将精炼的火簇粘贴到目标图像上。

Result: 通过数值分析和多目标优化比较，CCPDA在提升火类分割性能方面优于其他增强方法，并有效缓解了小规模标注数据集的训练困难。

Conclusion: CCPDA方法在野火科学中显著提升了火类分割的性能，为小规模标注数据集的训练提供了有效解决方案。

Abstract: Collecting and annotating images for the purpose of training segmentation
models is often cost prohibitive. In the domain of wildland fire science, this
challenge is further compounded by the scarcity of reliable public datasets
with labeled ground truth. This paper presents the Centralized Copy-Paste Data
Augmentation (CCPDA) method, for the purpose of assisting with the training of
deep-learning multiclass segmentation models, with special focus on improving
segmentation outcomes for the fire-class. CCPDA has three main steps: (i)
identify fire clusters in the source image, (ii) apply a centralization
technique to focus on the core of the fire area, and (iii) paste the refined
fire clusters onto a target image. This method increases dataset diversity
while preserving the essential characteristics of the fire class. The
effectiveness of this augmentation technique is demonstrated via numerical
analysis and comparison against various other augmentation methods using a
weighted sum-based multi-objective optimization approach. This approach helps
elevate segmentation performance metrics specific to the fire class, which
carries significantly more operational significance than other classes (fuel,
ash, or background). Numerical performance assessment validates the efficacy of
the presented CCPDA method in alleviating the difficulties associated with
small, manually labeled training datasets. It also illustrates that CCPDA
outperforms other augmentation strategies in the application scenario
considered, particularly in improving fire-class segmentation performance.

</details>


### [63] [AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions](https://arxiv.org/abs/2507.06332)
*Fuyuan Zhang,Qichen Wang,Jianjun Zhao*

Main category: cs.CV

TL;DR: AR2是一种通过对齐干净和损坏图像的类激活图（CAMs）来提升预训练CNN鲁棒性的方法，无需改变架构，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在常见损坏（如噪声、模糊等）下性能显著下降，限制了其在实际应用中的可靠性。

Method: AR2通过迭代修复策略，交替进行CAM引导的细化和标准微调，对齐干净和损坏图像的CAMs。

Result: AR2在CIFAR-10-C、CIFAR-100-C和ImageNet-C等基准测试中优于现有方法，平衡了干净数据准确性和损坏鲁棒性。

Conclusion: AR2为提升模型在多样化损坏环境中的可靠性提供了有效且可扩展的解决方案。

Abstract: Deep neural networks suffer from significant performance degradation when
exposed to common corruptions such as noise, blur, weather, and digital
distortions, limiting their reliability in real-world applications. In this
paper, we propose AR2 (Attention-Guided Repair for Robustness), a simple yet
effective method to enhance the corruption robustness of pretrained CNNs. AR2
operates by explicitly aligning the class activation maps (CAMs) between clean
and corrupted images, encouraging the model to maintain consistent attention
even under input perturbations. Our approach follows an iterative repair
strategy that alternates between CAM-guided refinement and standard
fine-tuning, without requiring architectural changes. Extensive experiments
show that AR2 consistently outperforms existing state-of-the-art methods in
restoring robustness on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C
and ImageNet-C), achieving a favorable balance between accuracy on clean data
and corruption robustness. These results demonstrate that AR2 provides a robust
and scalable solution for enhancing model reliability in real-world
environments with diverse corruptions.

</details>


### [64] [When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking](https://arxiv.org/abs/2507.06400)
*Weiran Li,Yeqiang Liu,Qiannan Guo,Yijie Wei,Hwa Liang Leo,Zhenbo Li*

Main category: cs.CV

TL;DR: 论文介绍了首个水下多鱼跟踪数据集MFT25和专用跟踪框架SU-T，展示了其在水下场景中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 水下多目标跟踪在海洋生态和水产养殖中很重要，但相关研究较少。

Method: 提出MFT25数据集和SU-T框架，结合UKF和FishIoU匹配算法。

Result: SU-T在MFT25上表现优异，HOTA为34.1，IDF1为44.6。

Conclusion: MFT25和SU-T为水下跟踪研究提供了重要基础，促进海洋生物学和水产养殖应用。

Abstract: Multiple object tracking (MOT) technology has made significant progress in
terrestrial applications, but underwater tracking scenarios remain
underexplored despite their importance to marine ecology and aquaculture. We
present Multiple Fish Tracking Dataset 2025 (MFT25), the first comprehensive
dataset specifically designed for underwater multiple fish tracking, featuring
15 diverse video sequences with 408,578 meticulously annotated bounding boxes
across 48,066 frames. Our dataset captures various underwater environments,
fish species, and challenging conditions including occlusions, similar
appearances, and erratic motion patterns. Additionally, we introduce
Scale-aware and Unscented Tracker (SU-T), a specialized tracking framework
featuring an Unscented Kalman Filter (UKF) optimized for non-linear fish
swimming patterns and a novel Fish-Intersection-over-Union (FishIoU) matching
that accounts for the unique morphological characteristics of aquatic species.
Extensive experiments demonstrate that our SU-T baseline achieves
state-of-the-art performance on MFT25, with 34.1 HOTA and 44.6 IDF1, while
revealing fundamental differences between fish tracking and terrestrial object
tracking scenarios. MFT25 establishes a robust foundation for advancing
research in underwater tracking systems with important applications in marine
biology, aquaculture monitoring, and ecological conservation. The dataset and
codes are released at https://vranlee.github.io/SU-T/.

</details>


### [65] [SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models](https://arxiv.org/abs/2507.06405)
*Lala Shakti Swarup Ray,Mengxi Liu,Deepika Gurung,Bo Zhou,Sungho Suh,Paul Lukowicz*

Main category: cs.CV

TL;DR: SImpHAR框架通过仿真生成生物阻抗信号和两阶段训练策略，显著提升了基于生物阻抗的人体活动识别性能。


<details>
  <summary>Details</summary>
Motivation: 生物阻抗传感在细粒度运动捕捉中有独特优势，但缺乏标记数据限制了其应用。

Method: 提出仿真流水线生成生物阻抗信号，并设计两阶段训练策略，无需标签对齐的合成数据。

Result: 在多个数据集上表现优于现有方法，准确率和F1分数分别提升22.3%和21.8%。

Conclusion: 仿真驱动增强和模块化训练为基于生物阻抗的人体活动识别提供了新思路。

Abstract: Human Activity Recognition (HAR) with wearable sensors is essential for
applications in healthcare, fitness, and human-computer interaction.
Bio-impedance sensing offers unique advantages for fine-grained motion capture
but remains underutilized due to the scarcity of labeled data. We introduce
SImpHAR, a novel framework addressing this limitation through two core
contributions. First, we propose a simulation pipeline that generates realistic
bio-impedance signals from 3D human meshes using shortest-path estimation,
soft-body physics, and text-to-motion generation serving as a digital twin for
data augmentation. Second, we design a two-stage training strategy with
decoupled approach that enables broader activity coverage without requiring
label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct
dataset and two public benchmarks, showing consistent improvements over
state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of
accuracy and macro F1 score, respectively. Our results highlight the promise of
simulation-driven augmentation and modular training for impedance-based HAR.

</details>


### [66] [Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization](https://arxiv.org/abs/2507.06411)
*Hayat Ullah,Arslan Munir,Oliver Nina*

Main category: cs.CV

TL;DR: 提出了一种名为PCL-Former的分层多阶段Transformer架构，用于时间动作定位任务，通过专用模块处理不同子任务，并在多个基准数据集上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 受到Transformer和多阶段架构在视频识别和目标检测领域成功的启发，探索其在时间动作定位任务中的时空特性。

Method: 设计了PCL-Former，包含三个专用Transformer模块：Proposal-Former（候选片段识别）、Classification-Former（动作分类）和Localization-Former（时间边界预测）。

Result: 在THUMOS14、ActivityNet-1.3和HACS数据集上分别优于现有方法2.8%、1.2%和4.8%。

Conclusion: PCL-Former通过模块化设计和专用损失函数，显著提升了时间动作定位任务的性能。

Abstract: Inspired by the recent success of transformers and multi-stage architectures
in video recognition and object detection domains. We thoroughly explore the
rich spatio-temporal properties of transformers within a multi-stage
architecture paradigm for the temporal action localization (TAL) task. This
exploration led to the development of a hierarchical multi-stage transformer
architecture called PCL-Former, where each subtask is handled by a dedicated
transformer module with a specialized loss function. Specifically, the
Proposal-Former identifies candidate segments in an untrimmed video that may
contain actions, the Classification-Former classifies the action categories
within those segments, and the Localization-Former precisely predicts the
temporal boundaries (i.e., start and end) of the action instances. To evaluate
the performance of our method, we have conducted extensive experiments on three
challenging benchmark datasets: THUMOS-14, ActivityNet-1.3, and HACS Segments.
We also conducted detailed ablation experiments to assess the impact of each
individual module of our PCL-Former. The obtained quantitative results validate
the effectiveness of the proposed PCL-Former, outperforming state-of-the-art
TAL approaches by 2.8%, 1.2%, and 4.8% on THUMOS14, ActivityNet-1.3, and HACS
datasets, respectively.

</details>


### [67] [THOR: Thermal-guided Hand-Object Reasoning via Adaptive Vision Sampling](https://arxiv.org/abs/2507.06442)
*Soroush Shahi,Farzad Shahabi,Rama Nabulsi,Glenn Fernandes,Aggelos Katsaggelos,Nabil Alshurafa*

Main category: cs.CV

TL;DR: THOR是一种实时自适应时空RGB帧采样方法，利用热感技术捕捉手部活动，显著减少数据处理量和能耗。


<details>
  <summary>Details</summary>
Motivation: 解决穿戴相机连续处理RGB图像的高能耗、大数据量、隐私问题和计算资源需求。

Method: 结合低分辨率热感数据动态调整RGB帧采样率，并利用热感线索定位手部活动区域以减少图像处理范围。

Result: 仅使用3%的原始RGB数据，实现了95%的手部活动识别准确率，与全数据（94%）相当。

Conclusion: THOR为穿戴相机实时监测手部活动和健康风险行为提供了更实用的解决方案。

Abstract: Wearable cameras are increasingly used as an observational and interventional
tool for human behaviors by providing detailed visual data of hand-related
activities. This data can be leveraged to facilitate memory recall for logging
of behavior or timely interventions aimed at improving health. However,
continuous processing of RGB images from these cameras consumes significant
power impacting battery lifetime, generates a large volume of unnecessary video
data for post-processing, raises privacy concerns, and requires substantial
computational resources for real-time analysis. We introduce THOR, a real-time
adaptive spatio-temporal RGB frame sampling method that leverages thermal
sensing to capture hand-object patches and classify them in real-time. We use
low-resolution thermal camera data to identify moments when a person switches
from one hand-related activity to another, and adjust the RGB frame sampling
rate by increasing it during activity transitions and reducing it during
periods of sustained activity. Additionally, we use the thermal cues from the
hand to localize the region of interest (i.e., the hand-object interaction) in
each RGB frame, allowing the system to crop and process only the necessary part
of the image for activity recognition. We develop a wearable device to validate
our method through an in-the-wild study with 14 participants and over 30
activities, and further evaluate it on Ego4D (923 participants across 9
countries, totaling 3,670 hours of video). Our results show that using only 3%
of the original RGB video data, our method captures all the activity segments,
and achieves hand-related activity recognition F1-score (95%) comparable to
using the entire RGB video (94%). Our work provides a more practical path for
the longitudinal use of wearable cameras to monitor hand-related activities and
health-risk behaviors in real time.

</details>


### [68] [EA: An Event Autoencoder for High-Speed Vision Sensing](https://arxiv.org/abs/2507.06459)
*Riadul Islam,Joey Mulé,Dhandeep Challagundla,Shahmir Rizvi,Sean Carson*

Main category: cs.CV

TL;DR: 提出了一种事件自动编码器架构，用于高效压缩和重建事件数据，提升事件相机在动态环境中的物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统帧式视觉系统在动态环境中存在运动模糊、高延迟和数据冗余问题，事件相机虽能异步捕捉亮度变化，但稀疏和噪声事件流对物体检测构成挑战。

Method: 采用卷积编码的自适应阈值选择和轻量级分类器，减少计算复杂度并提高识别精度。

Result: 在SEFD数据集上，模型精度与YOLO-v4相当，但参数减少35.5倍；在嵌入式平台上实现8-44.8 FPS的高帧率。

Conclusion: 该模型显著提升了事件相机的视觉性能，适用于低功耗、高速实时边缘计算应用。

Abstract: High-speed vision sensing is essential for real-time perception in
applications such as robotics, autonomous vehicles, and industrial automation.
Traditional frame-based vision systems suffer from motion blur, high latency,
and redundant data processing, limiting their performance in dynamic
environments. Event cameras, which capture asynchronous brightness changes at
the pixel level, offer a promising alternative but pose challenges in object
detection due to sparse and noisy event streams. To address this, we propose an
event autoencoder architecture that efficiently compresses and reconstructs
event data while preserving critical spatial and temporal features. The
proposed model employs convolutional encoding and incorporates adaptive
threshold selection and a lightweight classifier to enhance recognition
accuracy while reducing computational complexity. Experimental results on the
existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves
comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\times$
fewer parameters. Implementations on embedded platforms, including Raspberry Pi
4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8
FPS. The proposed classifier exhibits up to 87.84x better FPS than the
state-of-the-art and significantly improves event-based vision performance,
making it ideal for low-power, high-speed applications in real-time edge
computing.

</details>


### [69] [Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning](https://arxiv.org/abs/2507.06485)
*Ziyang Wang,Jaehong Yoon,Shoubin Yu,Md Mohaiminul Islam,Gedas Bertasius,Mohit Bansal*

Main category: cs.CV

TL;DR: Video-RTS提出了一种结合数据高效强化学习和视频自适应测试时间扩展策略的新方法，显著提高了视频推理能力的数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习和大型语言模型的视频推理方法依赖大规模监督微调和长链思维标注，成本高且难以扩展。

Method: 跳过资源密集的监督微调步骤，采用纯强化学习训练和稀疏到密集的视频测试时间扩展策略。

Result: 在多个视频推理基准测试中，Video-RTS仅用3.6%的训练样本即超越现有模型平均2.4%的准确率。

Conclusion: Video-RTS通过纯强化学习和自适应视频扩展策略的互补优势，实现了强大的推理性能。

Abstract: Despite advances in reinforcement learning (RL)-based video reasoning with
large language models (LLMs), data collection and finetuning remain significant
challenges. These methods often rely on large-scale supervised fine-tuning
(SFT) with extensive video data and long Chain-of-Thought (CoT) annotations,
making them costly and hard to scale. To address this, we present Video-RTS, a
new approach to improve video reasoning capability with drastically improved
data efficiency by combining data-efficient RL with a video-adaptive test-time
scaling (TTS) strategy. Based on observations about the data scaling of RL
samples, we skip the resource-intensive SFT step and employ efficient pure-RL
training with output-based rewards, requiring no additional annotations or
extensive fine-tuning. Furthermore, to utilize computational resources more
efficiently, we introduce a sparse-to-dense video TTS strategy that improves
inference by iteratively adding frames based on output consistency. We validate
our approach on multiple video reasoning benchmarks, showing that Video-RTS
surpasses existing video reasoning models by an average of 2.4% in accuracy
using only 3.6% training samples. For example, Video-RTS achieves a 4.2%
improvement on Video-Holmes, a recent and challenging video reasoning
benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and
adaptive video TTS offer complementary strengths, enabling Video-RTS's strong
reasoning performance.

</details>


### [70] [Mask6D: Masked Pose Priors For 6D Object Pose Estimation](https://arxiv.org/abs/2507.06486)
*Yuechen Xie,Haobo Jiang,Jin Xie*

Main category: cs.CV

TL;DR: 提出了一种名为Mask6D的新型预训练策略，用于在单目RGB图像中实现鲁棒的6D物体姿态估计，尤其在遮挡或杂乱场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前姿态估计网络在2D特征骨干网络中难以提取区分性强的姿态感知特征，尤其是在目标被遮挡或场景杂乱时RGB信息受限的情况下。

Method: 结合姿态感知的2D-3D对应图和可见掩码图作为额外模态信息，与RGB图像一起用于基于重建的模型预训练，并设计了专注于物体的预训练损失函数。

Result: 实验表明，该方法在端到端姿态估计任务中优于现有方法。

Conclusion: Mask6D通过引入姿态感知的模态信息和预训练策略，显著提升了在复杂场景中的6D姿态估计性能。

Abstract: Robust 6D object pose estimation in cluttered or occluded conditions using
monocular RGB images remains a challenging task. One reason is that current
pose estimation networks struggle to extract discriminative, pose-aware
features using 2D feature backbones, especially when the available RGB
information is limited due to target occlusion in cluttered scenes. To mitigate
this, we propose a novel pose estimation-specific pre-training strategy named
Mask6D. Our approach incorporates pose-aware 2D-3D correspondence maps and
visible mask maps as additional modal information, which is combined with RGB
images for the reconstruction-based model pre-training. Essentially, this 2D-3D
correspondence maps a transformed 3D object model to 2D pixels, reflecting the
pose information of the target in camera coordinate system. Meanwhile, the
integrated visible mask map can effectively guide our model to disregard
cluttered background information. In addition, an object-focused pre-training
loss function is designed to further facilitate our network to remove the
background interference. Finally, we fine-tune our pre-trained pose prior-aware
network via conventional pose training strategy to realize the reliable pose
prediction. Extensive experiments verify that our method outperforms previous
end-to-end pose estimation methods.

</details>


### [71] [Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection](https://arxiv.org/abs/2507.06510)
*Yupeng Hu,Changxing Ding,Chang Sun,Shaoli Huang,Xiangmin Xu*

Main category: cs.CV

TL;DR: 提出了一种双边协作框架（BC-HOI），用于开放词汇HOI检测，通过注意力偏差引导（ABG）和基于LLM的监督引导（LSG）提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖视觉语言模型（VLM）生成的特征，但这些特征过于粗粒度，不符合检测任务需求。

Method: 提出BC-HOI框架，包含ABG（引导VLM生成细粒度特征）和LSG（利用LLM提供细粒度监督）。

Result: 在HICO-DET和V-COCO基准上表现优异，优于现有方法。

Conclusion: BC-HOI框架有效解决了开放词汇HOI检测中的细粒度特征问题，性能显著提升。

Abstract: Open vocabulary Human-Object Interaction (HOI) detection is a challenging
task that detects all <human, verb, object> triplets of interest in an image,
even those that are not pre-defined in the training set. Existing approaches
typically rely on output features generated by large Vision-Language Models
(VLMs) to enhance the generalization ability of interaction representations.
However, the visual features produced by VLMs are holistic and coarse-grained,
which contradicts the nature of detection tasks. To address this issue, we
propose a novel Bilateral Collaboration framework for open vocabulary HOI
detection (BC-HOI). This framework includes an Attention Bias Guidance (ABG)
component, which guides the VLM to produce fine-grained instance-level
interaction features according to the attention bias provided by the HOI
detector. It also includes a Large Language Model (LLM)-based Supervision
Guidance (LSG) component, which provides fine-grained token-level supervision
for the HOI detector by the LLM component of the VLM. LSG enhances the ability
of ABG to generate high-quality attention bias. We conduct extensive
experiments on two popular benchmarks: HICO-DET and V-COCO, consistently
achieving superior performance in the open vocabulary and closed settings. The
code will be released in Github.

</details>


### [72] [What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies](https://arxiv.org/abs/2507.06513)
*Yaoqi Huang,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 该论文综述了基于视觉的交通场景分析，提出了一个分类法将交通实体分为异常和关键正常实体，分析了35个视觉驱动任务和73个数据集，并探讨了现有弱点与潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 利用视觉传感器和计算机视觉算法的进步，提升交通安全，通过系统分类和全面分析为研究者提供统一框架和资源优化指导。

Method: 提出分类法将交通实体分为异常和关键正常实体，整合10个类别和20个子类，分析35个视觉驱动任务和73个数据集。

Result: 建立了跨领域的统一分析框架，总结了现有数据集的优缺点，并指出了标准和资源优化的方向。

Conclusion: 该综述为快速发展的交通视觉分析领域提供了全面概述，指导资源选择并突出了关键研究空白。

Abstract: Advances in vision-based sensors and computer vision algorithms have
significantly improved the analysis and understanding of traffic scenarios. To
facilitate the use of these improvements for road safety, this survey
systematically categorizes the critical elements that demand attention in
traffic scenarios and comprehensively analyzes available vision-driven tasks
and datasets. Compared to existing surveys that focus on isolated domains, our
taxonomy categorizes attention-worthy traffic entities into two main groups
that are anomalies and normal but critical entities, integrating ten categories
and twenty subclasses. It establishes connections between inherently related
fields and provides a unified analytical framework. Our survey highlights the
analysis of 35 vision-driven tasks and comprehensive examinations and
visualizations of 73 available datasets based on the proposed taxonomy. The
cross-domain investigation covers the pros and cons of each benchmark with the
aim of providing information on standards unification and resource
optimization. Our article concludes with a systematic discussion of the
existing weaknesses, underlining the potential effects and promising solutions
from various perspectives. The integrated taxonomy, comprehensive analysis, and
recapitulatory tables serve as valuable contributions to this rapidly evolving
field by providing researchers with a holistic overview, guiding strategic
resource selection, and highlighting critical research gaps.

</details>


### [73] [FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation](https://arxiv.org/abs/2507.06523)
*Liqiang Jing,Viet Lai,Seunghyun Yoon,Trung Bui,Xinya Du*

Main category: cs.CV

TL;DR: FIFA是一个统一的视频多模态大语言模型（VideoMLLMs）忠实性评估框架，通过提取描述性事实、建模语义依赖关系并验证，解决了现有评估方法在开放回答中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法局限于单一任务且无法评估开放回答中的幻觉问题，导致模型生成内容与视觉输入不符。

Method: 提出FIFA框架，提取描述性事实，构建时空语义依赖图，并通过VideoQA模型验证；引入基于工具的后校正框架修正幻觉内容。

Result: FIFA比现有评估方法更接近人类判断，后校正显著提高了文本和视频生成的事实一致性。

Conclusion: FIFA和后校正框架有效解决了VideoMLLMs中的幻觉问题，提升了生成内容的忠实性。

Abstract: Video Multimodal Large Language Models (VideoMLLMs) have achieved remarkable
progress in both Video-to-Text and Text-to-Video tasks. However, they often
suffer fro hallucinations, generating content that contradicts the visual
input. Existing evaluation methods are limited to one task (e.g., V2T) and also
fail to assess hallucinations in open-ended, free-form responses. To address
this gap, we propose FIFA, a unified FaIthFulness evAluation framework that
extracts comprehensive descriptive facts, models their semantic dependencies
via a Spatio-Temporal Semantic Dependency Graph, and verifies them using
VideoQA models. We further introduce Post-Correction, a tool-based correction
framework that revises hallucinated content. Extensive experiments demonstrate
that FIFA aligns more closely with human judgment than existing evaluation
methods, and that Post-Correction effectively improves factual consistency in
both text and video generation.

</details>


### [74] [Concept Unlearning by Modeling Key Steps of Diffusion Process](https://arxiv.org/abs/2507.06526)
*Chaoshuo Zhang,Chenhao Lin,Zhengyu Zhao,Le Yang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了一种名为KSCU的新方法，通过针对扩散模型的关键步骤进行概念遗忘，有效平衡了遗忘效果与生成能力的保留。


<details>
  <summary>Details</summary>
Motivation: 现有的概念遗忘方法难以平衡遗忘效果与生成能力的保留，导致文本到图像扩散模型（T2I DMs）的滥用风险。

Method: KSCU方法利用扩散模型的逐步采样特性，专注于对最终结果影响最大的关键步骤，仅在这些步骤上微调模型。

Result: 实验表明，KSCU能有效防止生成不良图像，同时更好地保留模型的生成能力。

Conclusion: KSCU通过优化步骤选择，显著提升了概念遗忘的效率和效果。

Abstract: Text-to-image diffusion models (T2I DMs), represented by Stable Diffusion,
which generate highly realistic images based on textual input, have been widely
used. However, their misuse poses serious security risks. While existing
concept unlearning methods aim to mitigate these risks, they struggle to
balance unlearning effectiveness with generative retainability.To overcome this
limitation, we innovatively propose the Key Step Concept Unlearning (KSCU)
method, which ingeniously capitalizes on the unique stepwise sampling
characteristic inherent in diffusion models during the image generation
process. Unlike conventional approaches that treat all denoising steps equally,
KSCU strategically focuses on pivotal steps with the most influence over the
final outcome by dividing key steps for different concept unlearning tasks and
fine-tuning the model only at those steps. This targeted approach reduces the
number of parameter updates needed for effective unlearning, while maximizing
the retention of the model's generative capabilities.Through extensive
benchmark experiments, we demonstrate that KSCU effectively prevents T2I DMs
from generating undesirable images while better retaining the model's
generative capabilities.Our code will be released.

</details>


### [75] [Speak2Sign3D: A Multi-modal Pipeline for English Speech to American Sign Language Animation](https://arxiv.org/abs/2507.06530)
*Kazi Mahathir Rahman,Naveed Imtiaz Nafis,Md. Farhan Sadik,Mohammad Al Rafi,Mehedi Hasan Shahed*

Main category: cs.CV

TL;DR: 该论文提出了一种将英语语音转化为流畅、逼真的3D手语动画的完整流程，填补了从口语到手语动画生成的研究空白。


<details>
  <summary>Details</summary>
Motivation: 帮助聋人和听力障碍者更轻松地交流，解决以往研究多集中于手语转文本而忽略口语转手语动画的问题。

Method: 使用Whisper将英语语音转为文本，MarianMT模型将文本翻译为美国手语（ASL）gloss，结合Word2Vec和FastText优化翻译，最后通过3D关键点运动系统生成动画。

Result: 系统表现优异，BLEU分数达到0.7714和0.8923，并创建了新数据集Sign3D-WLASL和BookGlossCorpus-CG。

Conclusion: 该研究提供了一个从口语到3D手语动画的完整框架，整合了音频、文本和动作数据，优于以往专注于单一任务的研究。

Abstract: Helping deaf and hard-of-hearing people communicate more easily is the main
goal of Automatic Sign Language Translation. Although most past research has
focused on turning sign language into text, doing the reverse, turning spoken
English into sign language animations, has been largely overlooked. That's
because it involves multiple steps, such as understanding speech, translating
it into sign-friendly grammar, and generating natural human motion. In this
work, we introduce a complete pipeline that converts English speech into
smooth, realistic 3D sign language animations. Our system starts with Whisper
to translate spoken English into text. Then, we use a MarianMT machine
translation model to translate that text into American Sign Language (ASL)
gloss, a simplified version of sign language that captures meaning without
grammar. This model performs well, reaching BLEU scores of 0.7714 and 0.8923.
To make the gloss translation more accurate, we also use word embeddings such
as Word2Vec and FastText to understand word meanings. Finally, we animate the
translated gloss using a 3D keypoint-based motion system trained on
Sign3D-WLASL, a dataset we created by extracting body, hand, and face key
points from real ASL videos in the WLASL dataset. To support the gloss
translation stage, we also built a new dataset called BookGlossCorpus-CG, which
turns everyday English sentences from the BookCorpus dataset into ASL gloss
using grammar rules. Our system stitches everything together by smoothly
interpolating between signs to create natural, continuous animations. Unlike
previous works like How2Sign and Phoenix-2014T that focus on recognition or use
only one type of data, our pipeline brings together audio, text, and motion in
a single framework that goes all the way from spoken English to lifelike 3D
sign language animation.

</details>


### [76] [ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture](https://arxiv.org/abs/2507.06531)
*Mingjin Zeng,Nan Ouyang,Wenkang Wan,Lei Ao,Qing Cai,Kai Sheng*

Main category: cs.CV

TL;DR: ILNet提出了一种多智能体轨迹预测方法，结合逆向学习注意力机制和动态锚点选择模块，显著提升了复杂交互场景下的预测性能。


<details>
  <summary>Details</summary>
Motivation: 受人类驾驶行为的启发，旨在解决现有方法在时空协调和动态适应性上的不足。

Method: 采用逆向学习注意力机制（IL Attention）建模交互意图，并引入动态锚点选择模块（DAS）提取关键点。

Result: 在INTERACTION和Argoverse数据集上达到最优性能，尤其在复杂交互场景中表现突出。

Conclusion: ILNet通过动态建模和高效参数利用，显著提升了轨迹预测的准确性和多模态分布能力。

Abstract: Trajectory prediction for multi-agent interaction scenarios is a crucial
challenge. Most advanced methods model agent interactions by efficiently
factorized attention based on the temporal and agent axes. However, this static
and foward modeling lacks explicit interactive spatio-temporal coordination,
capturing only obvious and immediate behavioral intentions. Alternatively, the
modern trajectory prediction framework refines the successive predictions by a
fixed-anchor selection strategy, which is difficult to adapt in different
future environments. It is acknowledged that human drivers dynamically adjust
initial driving decisions based on further assumptions about the intentions of
surrounding vehicles. Motivated by human driving behaviors, this paper proposes
ILNet, a multi-agent trajectory prediction method with Inverse Learning (IL)
attention and Dynamic Anchor Selection (DAS) module. IL Attention employs an
inverse learning paradigm to model interactions at neighboring moments,
introducing proposed intentions to dynamically encode the spatio-temporal
coordination of interactions, thereby enhancing the model's ability to capture
complex interaction patterns. Then, the learnable DAS module is proposed to
extract multiple trajectory change keypoints as anchors in parallel with almost
no increase in parameters. Experimental results show that the ILNet achieves
state-of-the-art performance on the INTERACTION and Argoverse motion
forecasting datasets. Particularly, in challenged interaction scenarios, ILNet
achieves higher accuracy and more multimodal distributions of trajectories over
fewer parameters. Our codes are available at https://github.com/mjZeng11/ILNet.

</details>


### [77] [A model-agnostic active learning approach for animal detection from camera traps](https://arxiv.org/abs/2507.06537)
*Thi Thu Thuy Nguyen,Duc Thanh Nguyen*

Main category: cs.CV

TL;DR: 提出了一种模型无关的主动学习方法，用于优化相机陷阱捕获的野生动物数据标注，仅需30%的训练数据即可达到或超过完整数据集的检测性能。


<details>
  <summary>Details</summary>
Motivation: 野生动物数据标注和模型训练成本高，现有主动学习方法需完全访问模型，限制了其应用。

Method: 结合对象和图像层面的不确定性与多样性指标，进行主动学习样本选择。

Result: 实验表明，使用30%的训练数据，动物检测器性能可达到或超过完整数据集的效果。

Conclusion: 该方法为自动化野生动物监测提供了高效的数据选择方案。

Abstract: Smart data selection is becoming increasingly important in data-driven
machine learning. Active learning offers a promising solution by allowing
machine learning models to be effectively trained with optimal data including
the most informative samples from large datasets. Wildlife data captured by
camera traps are excessive in volume, requiring tremendous effort in data
labelling and animal detection models training. Therefore, applying active
learning to optimise the amount of labelled data would be a great aid in
enabling automated wildlife monitoring and conservation. However, existing
active learning techniques require that a machine learning model (i.e., an
object detector) be fully accessible, limiting the applicability of the
techniques. In this paper, we propose a model-agnostic active learning approach
for detection of animals captured by camera traps. Our approach integrates
uncertainty and diversity quantities of samples at both the object-based and
image-based levels into the active learning sample selection process. We
validate our approach in a benchmark animal dataset. Experimental results
demonstrate that, using only 30% of the training data selected by our approach,
a state-of-the-art animal detector can achieve a performance of equal or
greater than that with the use of the complete training dataset.

</details>


### [78] [Token Bottleneck: One Token to Remember Dynamics](https://arxiv.org/abs/2507.06543)
*Taekyung Kim,Dongyoon Han,Byeongho Heo,Jeongeun Park,Sangdoo Yun*

Main category: cs.CV

TL;DR: ToBo是一种自监督学习框架，通过压缩场景为瓶颈令牌并预测后续场景，学习动态场景的紧凑表示。


<details>
  <summary>Details</summary>
Motivation: 动态场景的紧凑和时间感知表示对视觉跟踪和机器人操作等任务至关重要。

Method: ToBo通过压缩步骤将参考场景编码为瓶颈令牌，并在扩展步骤中使用少量目标补丁预测目标场景。

Result: 在视频标签传播和机器人操作等任务中，ToBo表现优于基线方法，并在真实环境中验证了其鲁棒性。

Conclusion: ToBo能有效学习动态场景的时序依赖，适用于不同规模的模型。

Abstract: Deriving compact and temporally aware visual representations from dynamic
scenes is essential for successful execution of sequential scene understanding
tasks such as visual tracking and robotic manipulation. In this paper, we
introduce Token Bottleneck (ToBo), a simple yet intuitive self-supervised
learning pipeline that squeezes a scene into a bottleneck token and predicts
the subsequent scene using minimal patches as hints. The ToBo pipeline
facilitates the learning of sequential scene representations by conservatively
encoding the reference scene into a compact bottleneck token during the squeeze
step. In the expansion step, we guide the model to capture temporal dynamics by
predicting the target scene using the bottleneck token along with few target
patches as hints. This design encourages the vision backbone to embed temporal
dependencies, thereby enabling understanding of dynamic transitions across
scenes. Extensive experiments in diverse sequential tasks, including video
label propagation and robot manipulation in simulated environments demonstrate
the superiority of ToBo over baselines. Moreover, deploying our pre-trained
model on physical robots confirms its robustness and effectiveness in
real-world environments. We further validate the scalability of ToBo across
different model scales.

</details>


### [79] [Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution](https://arxiv.org/abs/2507.06547)
*Yonghyun Park,Chieh-Hsin Lai,Satoshi Hayakawa,Yuhta Takida,Naoki Murata,Wei-Hsiang Liao,Woosung Choi,Kin Wai Cheuk,Junghyun Koo,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 论文提出了一种名为Concept-TRAK的新方法，用于解决扩散模型在图像生成中的版权和透明度问题，通过概念级归因提供更细粒度的分析。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中表现优异，但其广泛使用引发了版权和透明度问题，现有方法无法对图像中的特定元素（如风格或对象）进行归因。

Method: 提出了Concept-TRAK方法，扩展了影响函数，包括基于扩散后验采样的训练损失重构和概念感知奖励函数。

Result: 在AbC基准测试中，Concept-TRAK显著优于现有方法，并通过案例研究展示了其在版权保护、内容安全和生成AI治理中的实用性。

Conclusion: Concept-TRAK为生成AI的负责任开发和治理提供了可操作的见解，解决了现有方法的局限性。

Abstract: While diffusion models excel at image generation, their growing adoption
raises critical concerns around copyright issues and model transparency.
Existing attribution methods identify training examples influencing an entire
image, but fall short in isolating contributions to specific elements, such as
styles or objects, that matter most to stakeholders. To bridge this gap, we
introduce \emph{concept-level attribution} via a novel method called
\emph{Concept-TRAK}. Concept-TRAK extends influence functions with two key
innovations: (1) a reformulated diffusion training loss based on diffusion
posterior sampling, enabling robust, sample-specific attribution; and (2) a
concept-aware reward function that emphasizes semantic relevance. We evaluate
Concept-TRAK on the AbC benchmark, showing substantial improvements over prior
methods. Through diverse case studies--ranging from identifying IP-protected
and unsafe content to analyzing prompt engineering and compositional
learning--we demonstrate how concept-level attribution yields actionable
insights for responsible generative AI development and governance.

</details>


### [80] [MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning](https://arxiv.org/abs/2507.06662)
*Yifan Yang,Peili Song,Enfan Lan,Dong Liu,Jingtai Liu*

Main category: cs.CV

TL;DR: MK-Pose是一种多模态关键点学习框架，结合RGB图像、点云和类别文本描述，用于类别级物体姿态估计，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在物体遮挡和跨实例、跨类别泛化能力上的不足。

Method: 提出自监督关键点检测模块，结合注意力查询生成、软热图匹配和图关系建模，并设计图增强特征融合模块。

Result: 在CAMERA25、REAL275和HouseCat6D数据集上表现优异，IoU和平均精度超越现有方法。

Conclusion: MK-Pose通过多模态融合和图建模显著提升了类别级姿态估计的性能。

Abstract: Category-level object pose estimation, which predicts the pose of objects
within a known category without prior knowledge of individual instances, is
essential in applications like warehouse automation and manufacturing. Existing
methods relying on RGB images or point cloud data often struggle with object
occlusion and generalization across different instances and categories. This
paper proposes a multimodal-based keypoint learning framework (MK-Pose) that
integrates RGB images, point clouds, and category-level textual descriptions.
The model uses a self-supervised keypoint detection module enhanced with
attention-based query generation, soft heatmap matching and graph-based
relational modeling. Additionally, a graph-enhanced feature fusion module is
designed to integrate local geometric information and global context. MK-Pose
is evaluated on CAMERA25 and REAL275 dataset, and is further tested for
cross-dataset capability on HouseCat6D dataset. The results demonstrate that
MK-Pose outperforms existing state-of-the-art methods in both IoU and average
precision without shape priors. Codes will be released at
\href{https://github.com/yangyifanYYF/MK-Pose}{https://github.com/yangyifanYYF/MK-Pose}.

</details>


### [81] [Divergence-Based Similarity Function for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06560)
*Jae Hyoung Jeon,Cheolsu Lim,Myungjoo Kang*

Main category: cs.CV

TL;DR: 提出了一种基于分布散度的相似性函数（DSF），通过将多视图表示为分布并测量分布间的散度，显式捕捉多视图的联合结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要捕捉视图间的成对关系，未能建模所有视图的联合结构，限制了多视图学习的有效性。

Method: 提出DSF，将多视图表示为分布，通过分布间的散度衡量相似性。

Result: DSF在kNN分类和线性评估等任务中表现优异，且效率更高。

Conclusion: DSF无需温度超参数即可有效工作，且理论证明其与余弦相似性相关。

Abstract: Recent success in contrastive learning has sparked growing interest in more
effectively leveraging multiple augmented views of an instance. While prior
methods incorporate multiple views at the loss or feature level, they primarily
capture pairwise relationships and fail to model the joint structure across all
views. In this work, we propose a divergence-based similarity function (DSF)
that explicitly captures the joint structure by representing each set of
augmented views as a distribution and measuring similarity as the divergence
between distributions. Extensive experiments demonstrate that DSF consistently
improves performance across various tasks, including kNN classification and
linear evaluation, while also offering greater efficiency compared to other
multi-view methods. Furthermore, we establish a theoretical connection between
DSF and cosine similarity, and show that, unlike cosine similarity, DSF
operates effectively without requiring a temperature hyperparameter.

</details>


### [82] [StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception](https://arxiv.org/abs/2507.06687)
*Marcel Vosshans,Omar Ait-Aider,Youcef Mezouar,Markus Enzweiler*

Main category: cs.CV

TL;DR: StixelNExT++是一种用于单目感知系统的新型场景表示方法，通过聚类3D Stixel单元增强对象分割，实现高压缩且适应点云和鸟瞰图表示，实时性能达10毫秒/帧。


<details>
  <summary>Details</summary>
Motivation: 提升单目感知系统的场景表示能力，同时保持高压缩和实时性能。

Method: 基于Stixel表示，推断3D Stixels并通过聚类增强分割，使用轻量级神经网络训练LiDAR生成的真值。

Result: 在Waymo数据集上30米范围内表现优异，计算时间低至10毫秒/帧。

Conclusion: StixelNExT++在自主系统中具有集体感知潜力。

Abstract: This paper presents StixelNExT++, a novel approach to scene representation
for monocular perception systems. Building on the established Stixel
representation, our method infers 3D Stixels and enhances object segmentation
by clustering smaller 3D Stixel units. The approach achieves high compression
of scene information while remaining adaptable to point cloud and
bird's-eye-view representations. Our lightweight neural network, trained on
automatically generated LiDAR-based ground truth, achieves real-time
performance with computation times as low as 10 ms per frame. Experimental
results on the Waymo dataset demonstrate competitive performance within a
30-meter range, highlighting the potential of StixelNExT++ for collective
perception in autonomous systems.

</details>


### [83] [Edge-Boundary-Texture Loss: A Tri-Class Generalization of Weighted Binary Cross-Entropy for Enhanced Edge Detection](https://arxiv.org/abs/2507.06569)
*Hao Shu*

Main category: cs.CV

TL;DR: 论文提出了一种新的损失函数EBT，通过将像素分为边缘、边界和纹理三类，并赋予不同的监督权重，改进了边缘检测任务。


<details>
  <summary>Details</summary>
Motivation: 传统的WBCE损失函数对所有非边缘像素一视同仁，忽略了边缘附近的结构差异，导致预测模糊。

Method: 提出EBT损失函数，将像素分为边缘、边界和纹理三类，并为每类分配不同的监督权重。

Result: 实验证明EBT损失在多个基准测试中表现优异，且对超参数变化鲁棒。

Conclusion: EBT损失函数易于部署，且显著提升了边缘检测的性能。

Abstract: Edge detection (ED) remains a fundamental task in computer vision, yet its
performance is often hindered by the ambiguous nature of non-edge pixels near
object boundaries. The widely adopted Weighted Binary Cross-Entropy (WBCE) loss
treats all non-edge pixels uniformly, overlooking the structural nuances around
edges and often resulting in blurred predictions. In this paper, we propose the
Edge-Boundary-Texture (EBT) loss, a novel objective that explicitly divides
pixels into three categories, edge, boundary, and texture, and assigns each a
distinct supervisory weight. This tri-class formulation enables more structured
learning by guiding the model to focus on both edge precision and contextual
boundary localization. We theoretically show that the EBT loss generalizes the
WBCE loss, with the latter becoming a limit case. Extensive experiments across
multiple benchmarks demonstrate the superiority of the EBT loss both
quantitatively and perceptually. Furthermore, the consistent use of unified
hyperparameters across all models and datasets, along with robustness to their
moderate variations, indicates that the EBT loss requires minimal fine-tuning
and is easily deployable in practice.

</details>


### [84] [A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding](https://arxiv.org/abs/2507.06719)
*Zhenyang Liu,Sixiao Zheng,Siyu Chen,Cairong Zhao,Longfei Liang,Xiangyang Xue,Yanwei Fu*

Main category: cs.CV

TL;DR: 提出SpatialReasoner框架，通过LLM驱动的空间推理和分层特征场，提升开放词汇3D视觉定位中空间关系的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在语言查询中处理空间关系（如“椅子上的书”）时表现不佳，主要原因是缺乏对语言和3D场景中空间关系的充分推理。

Method: 结合LLM驱动的空间推理和视觉属性增强的分层特征场，通过CLIP特征和SAM提取的掩码构建特征场，并分层查询目标实例。

Result: 实验表明，该框架能无缝集成到不同神经表示中，显著优于基线模型，并增强其空间推理能力。

Conclusion: SpatialReasoner通过改进空间推理和特征表示，有效提升了开放词汇3D视觉定位的性能。

Abstract: Open-vocabulary 3D visual grounding aims to localize target objects based on
free-form language queries, which is crucial for embodied AI applications such
as autonomous navigation, robotics, and augmented reality. Learning 3D language
fields through neural representations enables accurate understanding of 3D
scenes from limited viewpoints and facilitates the localization of target
objects in complex environments. However, existing language field methods
struggle to accurately localize instances using spatial relations in language
queries, such as ``the book on the chair.'' This limitation mainly arises from
inadequate reasoning about spatial relations in both language queries and 3D
scenes. In this work, we propose SpatialReasoner, a novel neural
representation-based framework with large language model (LLM)-driven spatial
reasoning that constructs a visual properties-enhanced hierarchical feature
field for open-vocabulary 3D visual grounding. To enable spatial reasoning in
language queries, SpatialReasoner fine-tunes an LLM to capture spatial
relations and explicitly infer instructions for the target, anchor, and spatial
relation. To enable spatial reasoning in 3D scenes, SpatialReasoner
incorporates visual properties (opacity and color) to construct a hierarchical
feature field. This field represents language and instance features using
distilled CLIP features and masks extracted via the Segment Anything Model
(SAM). The field is then queried using the inferred instructions in a
hierarchical manner to localize the target 3D instance based on the spatial
relation in the language query. Extensive experiments show that our framework
can be seamlessly integrated into different neural representations,
outperforming baseline models in 3D visual grounding while empowering their
spatial reasoning capability.

</details>


### [85] [MOST: Motion Diffusion Model for Rare Text via Temporal Clip Banzhaf Interaction](https://arxiv.org/abs/2507.06590)
*Yin Wang,Mu li,Zhiying Leng,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: MOST是一种通过时间片段Banzhaf交互的新型运动扩散模型，旨在解决从罕见语言提示生成人类运动的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在粗粒度匹配和忽略语义线索方面存在问题，MOST通过利用细粒度片段关系来解决这些问题。

Method: MOST采用时间片段Banzhaf交互量化文本-运动一致性，并通过运动提示模块生成语义一致的运动。

Result: MOST在文本到运动的检索和生成性能上达到最先进水平，尤其在罕见提示上表现突出。

Conclusion: MOST通过细粒度匹配和消除冗余，显著提升了文本到运动生成的效果。

Abstract: We introduce MOST, a novel motion diffusion model via temporal clip Banzhaf
interaction, aimed at addressing the persistent challenge of generating human
motion from rare language prompts. While previous approaches struggle with
coarse-grained matching and overlook important semantic cues due to motion
redundancy, our key insight lies in leveraging fine-grained clip relationships
to mitigate these issues. MOST's retrieval stage presents the first formulation
of its kind - temporal clip Banzhaf interaction - which precisely quantifies
textual-motion coherence at the clip level. This facilitates direct,
fine-grained text-to-motion clip matching and eliminates prevalent redundancy.
In the generation stage, a motion prompt module effectively utilizes retrieved
motion clips to produce semantically consistent movements. Extensive
evaluations confirm that MOST achieves state-of-the-art text-to-motion
retrieval and generation performance by comprehensively addressing previous
challenges, as demonstrated through quantitative and qualitative results
highlighting its effectiveness, especially for rare prompts.

</details>


### [86] [Hallucinating 360°: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting](https://arxiv.org/abs/2507.06971)
*Fei Teng,Kai Luo,Sheng Wu,Siyu Li,Pujun Guo,Jiale Wei,Kunyu Peng,Jiaming Zhang,Kailun Yang*

Main category: cs.CV

TL;DR: 论文提出Percep360方法，用于自动驾驶中的全景数据生成，解决了现有方法在连贯性和可控性上的不足，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要全景感知，但数据采集和标注复杂耗时。现有生成模型无法高质量、可控地生成全景数据。

Method: 提出局部场景扩散方法（LSDM）和概率提示方法（PPM），分别解决信息丢失和可控生成问题。

Result: 生成图像在质量评估、可控性和下游任务（如BEV分割）中表现优于原始拼接图像。

Conclusion: Percep360为自动驾驶提供了高质量、可控的全景数据生成方案，并开源了代码。

Abstract: Panoramic perception holds significant potential for autonomous driving,
enabling vehicles to acquire a comprehensive 360{\deg} surround view in a
single shot. However, autonomous driving is a data-driven task. Complete
panoramic data acquisition requires complex sampling systems and annotation
pipelines, which are time-consuming and labor-intensive. Although existing
street view generation models have demonstrated strong data regeneration
capabilities, they can only learn from the fixed data distribution of existing
datasets and cannot achieve high-quality, controllable panoramic generation. In
this paper, we propose the first panoramic generation method Percep360 for
autonomous driving. Percep360 enables coherent generation of panoramic data
with control signals based on the stitched panoramic data. Percep360 focuses on
two key aspects: coherence and controllability. Specifically, to overcome the
inherent information loss caused by the pinhole sampling process, we propose
the Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama
generation as a spatially continuous diffusion process, bridging the gaps
between different data distributions. Additionally, to achieve the controllable
generation of panoramic images, we propose a Probabilistic Prompting Method
(PPM). PPM dynamically selects the most relevant control cues, enabling
controllable panoramic image generation. We evaluate the effectiveness of the
generated images from three perspectives: image quality assessment (i.e.,
no-reference and with reference), controllability, and their utility in
real-world Bird's Eye View (BEV) segmentation. Notably, the generated data
consistently outperforms the original stitched images in no-reference quality
metrics and enhances downstream perception models. The source code will be
publicly available at https://github.com/Bryant-Teng/Percep360.

</details>


### [87] [Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning](https://arxiv.org/abs/2507.06592)
*Yang Chen,Yueqi Duan,Haowen Sun,Jiwen Lu,Yap-Peng Tan*

Main category: cs.CV

TL;DR: 提出了一种自适应边距对比学习方法（AMContrast3D和AMContrast3D++），用于点云的3D语义分割，通过模糊度感知优化模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法对模糊区域的点采用均等惩罚目标，导致模型性能受限，而人工标注的模糊点标签不可靠，需自适应优化。

Method: 设计了AMContrast3D，将对比学习融入模糊度估计框架，根据点模糊度自适应调整目标；进一步提出AMContrast3D++，通过并行分支和掩码细化机制提升模糊嵌入的可靠性。

Result: 在S3DIS和ScanNet数据集上验证了方法的有效性，提升了分割性能和鲁棒性。

Conclusion: 通过模糊度感知的自适应对比学习，显著优化了点云语义分割的性能。

Abstract: This paper proposes an adaptive margin contrastive learning method for 3D
semantic segmentation on point clouds. Most existing methods use equally
penalized objectives, which ignore the per-point ambiguities and less
discriminated features stemming from transition regions. However, as highly
ambiguous points may be indistinguishable even for humans, their manually
annotated labels are less reliable, and hard constraints over these points
would lead to sub-optimal models. To address this, we first design
AMContrast3D, a method comprising contrastive learning into an ambiguity
estimation framework, tailored to adaptive objectives for individual points
based on ambiguity levels. As a result, our method promotes model training,
which ensures the correctness of low-ambiguity points while allowing mistakes
for high-ambiguity points. As ambiguities are formulated based on position
discrepancies across labels, optimization during inference is constrained by
the assumption that all unlabeled points are uniformly unambiguous, lacking
ambiguity awareness. Inspired by the insight of joint training, we further
propose AMContrast3D++ integrating with two branches trained in parallel, where
a novel ambiguity prediction module concurrently learns point ambiguities from
generated embeddings. To this end, we design a masked refinement mechanism that
leverages predicted ambiguities to enable the ambiguous embeddings to be more
reliable, thereby boosting segmentation performance and enhancing robustness.
Experimental results on 3D indoor scene datasets, S3DIS and ScanNet,
demonstrate the effectiveness of the proposed method. Code is available at
https://github.com/YangChenApril/AMContrast3D.

</details>


### [88] [Capturing Stable HDR Videos Using a Dual-Camera System](https://arxiv.org/abs/2507.06593)
*Qianyu Zhang,Bolun Zheng,Hangjia Pan,Lingyu Zhu,Zunjie Zhu,Zongpeng Li,Shiqi Wang*

Main category: cs.CV

TL;DR: 提出了一种双摄像头系统（DCS）和曝光自适应融合网络（EAFNet）来解决HDR视频重建中的闪烁问题，通过选择性特征融合和多尺度架构实现高性能。


<details>
  <summary>Details</summary>
Motivation: 交替曝光方法中的曝光波动导致参考图像闪烁，影响了HDR视频的质量。

Method: 使用双摄像头系统（DCS）分别捕获参考序列和非参考序列，并设计EAFNet网络进行特征对齐、选择性融合和多尺度重建。

Result: 实验表明，该方法在不同数据集上达到了最先进的性能。

Conclusion: DCS和EAFNet在HDR视频重建中具有巨大潜力，代码和数据将开源。

Abstract: In HDR video reconstruction, exposure fluctuations in reference images from
alternating exposure methods often result in flickering. To address this issue,
we propose a dual-camera system (DCS) for HDR video acquisition, where one
camera is assigned to capture consistent reference sequences, while the other
is assigned to capture non-reference sequences for information supplementation.
To tackle the challenges posed by video data, we introduce an exposure-adaptive
fusion network (EAFNet) to achieve more robust results. EAFNet introduced a
pre-alignment subnetwork to explore the influence of exposure, selectively
emphasizing the valuable features across different exposure levels. Then, the
enhanced features are fused by the asymmetric cross-feature fusion subnetwork,
which explores reference-dominated attention maps to improve image fusion by
aligning cross-scale features and performing cross-feature fusion. Finally, the
reconstruction subnetwork adopts a DWT-based multiscale architecture to reduce
ghosting artifacts and refine features at different resolutions. Extensive
experimental evaluations demonstrate that the proposed method achieves
state-of-the-art performance on different datasets, validating the great
potential of the DCS in HDR video reconstruction. The codes and data captured
by DCS will be available at https://github.com/zqqqyu/DCS.

</details>


### [89] [Cross-Modal Dual-Causal Learning for Long-Term Action Recognition](https://arxiv.org/abs/2507.06603)
*Xu Shaowu,Jia Xibin,Gao Junyu,Sun Qianmei,Chang Jing,Fan Chao*

Main category: cs.CV

TL;DR: 论文提出了一种跨模态双因果学习（CMDCL）方法，通过结构因果模型解决视频和标签文本之间的因果关系，提升长期动作识别的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 长期动作识别（LTAR）因时间跨度长、动作关联复杂以及视觉干扰因素而具有挑战性。现有方法多依赖统计相关性而非因果机制，且缺乏跨模态因果建模。

Method: CMDCL通过文本因果干预解决文本嵌入的跨模态偏差，并通过视觉因果干预去除视觉模态中的干扰因素。

Result: 在Charades、Breakfast和COIN三个基准测试中验证了CMDCL的有效性。

Conclusion: CMDCL通过双因果干预显著提升了长期动作识别的性能。

Abstract: Long-term action recognition (LTAR) is challenging due to extended temporal
spans with complex atomic action correlations and visual confounders. Although
vision-language models (VLMs) have shown promise, they often rely on
statistical correlations instead of causal mechanisms. Moreover, existing
causality-based methods address modal-specific biases but lack cross-modal
causal modeling, limiting their utility in VLM-based LTAR. This paper proposes
\textbf{C}ross-\textbf{M}odal \textbf{D}ual-\textbf{C}ausal \textbf{L}earning
(CMDCL), which introduces a structural causal model to uncover causal
relationships between videos and label texts.
  CMDCL addresses cross-modal biases in text embeddings via textual causal
intervention and removes confounders inherent in the visual modality through
visual causal intervention guided by the debiased text.
  These dual-causal interventions enable robust action representations to
address LTAR challenges. Experimental results on three benchmarks including
Charades, Breakfast and COIN, demonstrate the effectiveness of the proposed
model. Our code is available at https://github.com/xushaowu/CMDCL.

</details>


### [90] [Omni-Fusion of Spatial and Spectral for Hyperspectral Image Segmentation](https://arxiv.org/abs/2507.06606)
*Qing Zhang,Guoquan Pei,Yan Wang*

Main category: cs.CV

TL;DR: 提出了一种名为Omni-Fuse的新型空间-光谱全融合网络，用于高光谱图像分割，通过跨维度特征融合和双向注意力机制显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学高光谱成像（MHSI）在疾病诊断中潜力巨大，但高维度和光谱冗余特性使其空间和光谱信息融合成为挑战。

Method: 设计了跨维度增强模块、光谱引导的空间查询选择和两阶段跨维度解码器，动态优化模型对空间查询的关注。

Result: 在两个显微高光谱图像数据集上的实验表明，Omni-Fuse在分割性能上显著优于现有方法，DSC提升超过5.73%。

Conclusion: Omni-Fuse通过高效的跨维度特征融合，有效解决了MHSI的高维度和冗余问题，为高光谱图像分割提供了新思路。

Abstract: Medical Hyperspectral Imaging (MHSI) has emerged as a promising tool for
enhanced disease diagnosis, particularly in computational pathology, offering
rich spectral information that aids in identifying subtle biochemical
properties of tissues. Despite these advantages, effectively fusing both
spatial-dimensional and spectral-dimensional information from MHSIs remains
challenging due to its high dimensionality and spectral redundancy inherent
characteristics. To solve the above challenges, we propose a novel
spatial-spectral omni-fusion network for hyperspectral image segmentation,
named as Omni-Fuse. Here, we introduce abundant cross-dimensional feature
fusion operations, including a cross-dimensional enhancement module that
refines both spatial and spectral features through bidirectional attention
mechanisms, a spectral-guided spatial query selection to select the most
spectral-related spatial feature as the query, and a two-stage
cross-dimensional decoder which dynamically guide the model to focus on the
selected spatial query. Despite of numerous attention blocks, Omni-Fuse remains
efficient in execution. Experiments on two microscopic hyperspectral image
datasets show that our approach can significantly improve the segmentation
performance compared with the state-of-the-art methods, with over 5.73 percent
improvement in DSC. Code available at:
https://github.com/DeepMed-Lab-ECNU/Omni-Fuse.

</details>


### [91] [PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation](https://arxiv.org/abs/2507.06618)
*Yang Chen,Yueqi Duan,Haowen Sun,Ziwei Wang,Jiwen Lu,Yap-Peng Tan*

Main category: cs.CV

TL;DR: 提出了一种基于视点依赖投影（VDP）的点云分割方法，通过动态适应视点变化的3D到2D映射，解决了现有投影方法因固定参数导致的多样性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有投影方法依赖固定参数，限制了点云感知和投影多样性，且多投影导致计算冗余。

Method: 设计了VDP框架，通过数据驱动的投影生成自适应射线，并结合颜色正则化优化投影图像。

Result: 在S3DIS和ScanNet基准测试中表现优异，计算成本低。

Conclusion: PointVDP提供了一种资源高效的语义理解解决方案。

Abstract: In this paper, we propose view-dependent projection (VDP) to facilitate point
cloud segmentation, designing efficient 3D-to-2D mapping that dynamically
adapts to the spatial geometry from view variations. Existing projection-based
methods leverage view-independent projection in complex scenes, relying on
straight lines to generate direct rays or upward curves to reduce occlusions.
However, their view independence provides projection rays that are limited to
pre-defined parameters by human settings, restricting point awareness and
failing to capture sufficient projection diversity across different view
planes. Although multiple projections per view plane are commonly used to
enhance spatial variety, the projected redundancy leads to excessive
computational overhead and inefficiency in image processing. To address these
limitations, we design a framework of VDP to generate data-driven projections
from 3D point distributions, producing highly informative single-image inputs
by predicting rays inspired by the adaptive behavior of fireworks. In addition,
we construct color regularization to optimize the framework, which emphasizes
essential features within semantic pixels and suppresses the non-semantic
features within black pixels, thereby maximizing 2D space utilization in a
projected image. As a result, our approach, PointVDP, develops lightweight
projections in marginal computation costs. Experiments on S3DIS and ScanNet
benchmarks show that our approach achieves competitive results, offering a
resource-efficient solution for semantic understanding.

</details>


### [92] [EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision](https://arxiv.org/abs/2507.06639)
*Myungjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee*

Main category: cs.CV

TL;DR: EXAONE Path 2.0提出了一种基于全切片监督的病理学基础模型，解决了传统自监督学习方法在生物标志物预测中的局限性，显著提高了数据效率。


<details>
  <summary>Details</summary>
Motivation: 传统自监督学习（SSL）方法在数字病理学中因依赖小区域补丁级训练和自然图像领域的增强方法，可能忽略复杂的领域特异性特征，且数据效率较低。

Method: EXAONE Path 2.0通过直接利用全切片级监督学习补丁级表示，仅需37k全切片图像进行训练。

Result: 在10项生物标志物预测任务中，EXAONE Path 2.0实现了最先进的平均性能，表现出卓越的数据效率。

Conclusion: EXAONE Path 2.0为病理学领域提供了一种高效且性能优越的基础模型，解决了现有方法的局限性。

Abstract: In digital pathology, whole-slide images (WSIs) are often difficult to handle
due to their gigapixel scale, so most approaches train patch encoders via
self-supervised learning (SSL) and then aggregate the patch-level embeddings
via multiple instance learning (MIL) or slide encoders for downstream tasks.
However, patch-level SSL may overlook complex domain-specific features that are
essential for biomarker prediction, such as mutation status and molecular
characteristics, as SSL methods rely only on basic augmentations selected for
natural image domains on small patch-level area. Moreover, SSL methods remain
less data efficient than fully supervised approaches, requiring extensive
computational resources and datasets to achieve competitive performance. To
address these limitations, we present EXAONE Path 2.0, a pathology foundation
model that learns patch-level representations under direct slide-level
supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves
state-of-the-art average performance across 10 biomarker prediction tasks,
demonstrating remarkable data efficiency.

</details>


### [93] [Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment](https://arxiv.org/abs/2507.06643)
*Farahdiba Zarin,Riccardo Oliva,Vinkle Srivastav,Armine Vardazaryan,Andrea Rosati,Alice Zampolini Faustini,Giovanni Scambia,Anna Fagotti,Pietro Mascagni,Nicolas Padoy*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Crag and Tail的损失函数，用于从稀疏标注中学习密集预测任务，特别是在医学图像中关键点定位的应用。


<details>
  <summary>Details</summary>
Motivation: 医学领域中稀疏标注学习是一个常见挑战，尤其是需要密集像素级标注时。本文旨在解决这一问题，推动在标注不完善情况下的研究进展。

Method: 将问题建模为稀疏热图回归，并提出Crag and Tail损失函数，有效利用稀疏标注并减少假阴性或漏标的影响。

Result: 通过大量实验验证，该方法在2D腹腔镜视频帧中实现了准确的癌变关键点密集定位。

Conclusion: 该方法在标注难以获取的场景中具有潜力，能够推动相关研究的进展。

Abstract: Learning from sparse labels is a challenge commonplace in the medical domain.
This is due to numerous factors, such as annotation cost, and is especially
true for newly introduced tasks. When dense pixel-level annotations are needed,
this becomes even more unfeasible. However, being able to learn from just a few
annotations at the pixel-level, while extremely difficult and underutilized,
can drive progress in studies where perfect annotations are not immediately
available. This work tackles the challenge of learning the dense prediction
task of keypoint localization from a few point annotations in the context of 2d
carcinosis keypoint localization from laparoscopic video frames for diagnostic
planning of advanced ovarian cancer patients. To enable this, we formulate the
problem as a sparse heatmap regression from a few point annotations per image
and propose a new loss function, called Crag and Tail loss, for efficient
learning. Our proposed loss function effectively leverages positive sparse
labels while minimizing the impact of false negatives or missed annotations.
Through an extensive ablation study, we demonstrate the effectiveness of our
approach in achieving accurate dense localization of carcinosis keypoints,
highlighting its potential to advance research in scenarios where dense
annotations are challenging to obtain.

</details>


### [94] [ClipGS: Clippable Gaussian Splatting for Interactive Cinematic Visualization of Volumetric Medical Data](https://arxiv.org/abs/2507.06647)
*Chengkun Li,Yuqi Tong,Kai Chen,Zhenya Yang,Ruiyang Li,Shi Qiu,Jason Ying-Kuen Chan,Pheng-Ann Heng,Qi Dou*

Main category: cs.CV

TL;DR: ClipGS框架通过高斯样条和剪裁平面支持，实现了医学体积数据的交互式电影级可视化，提升了渲染质量和效率。


<details>
  <summary>Details</summary>
Motivation: 医学体积数据的可视化对诊断和手术规划至关重要，但现有方法计算成本高、渲染速度慢，难以满足交互需求。

Method: 提出ClipGS框架，结合可学习的截断方案和自适应调整模型，动态优化高斯基元的可见性和变形。

Result: 在五种医学数据上测试，平均PSNR为36.635，帧率156 FPS，模型大小16.1 MB，优于现有方法。

Conclusion: ClipGS在渲染质量和效率上表现优异，适用于医学数据的交互式可视化。

Abstract: The visualization of volumetric medical data is crucial for enhancing
diagnostic accuracy and improving surgical planning and education. Cinematic
rendering techniques significantly enrich this process by providing
high-quality visualizations that convey intricate anatomical details, thereby
facilitating better understanding and decision-making in medical contexts.
However, the high computing cost and low rendering speed limit the requirement
of interactive visualization in practical applications. In this paper, we
introduce ClipGS, an innovative Gaussian splatting framework with the clipping
plane supported, for interactive cinematic visualization of volumetric medical
data. To address the challenges posed by dynamic interactions, we propose a
learnable truncation scheme that automatically adjusts the visibility of
Gaussian primitives in response to the clipping plane. Besides, we also design
an adaptive adjustment model to dynamically adjust the deformation of Gaussians
and refine the rendering performance. We validate our method on five volumetric
medical data (including CT and anatomical slice data), and reach an average
36.635 PSNR rendering quality with 156 FPS and 16.1 MB model size,
outperforming state-of-the-art methods in rendering quality and efficiency.

</details>


### [95] [Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior](https://arxiv.org/abs/2507.06651)
*Juncheng Mu,Chengwei Ren,Weixiang Zhang,Liang Pan,Xiao-Ping Zhang,Yue Gao*

Main category: cs.CV

TL;DR: 论文提出Diff$^2$I2P框架，利用扩散模型作为先验知识，通过可微分方法优化跨模态特征对齐，显著提升图像到点云的配准性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过度量学习实现跨模态特征对齐，但忽视了图像与点云之间的固有模态差异，导致配准不准确。

Method: 提出Control-Side Score Distillation (CSD)技术和Deformable Correspondence Tuning (DCT)模块，分别用于优化变换预测和可微分地估计对应关系。

Result: 在7-Scenes基准测试中，Diff$^2$I2P比现有方法提升了7%以上的配准召回率。

Conclusion: Diff$^2$I2P通过扩散模型先验和可微分设计，显著提升了跨模态配准的准确性和鲁棒性。

Abstract: Learning cross-modal correspondences is essential for image-to-point cloud
(I2P) registration. Existing methods achieve this mostly by utilizing metric
learning to enforce feature alignment across modalities, disregarding the
inherent modality gap between image and point data. Consequently, this paradigm
struggles to ensure accurate cross-modal correspondences. To this end, inspired
by the cross-modal generation success of recent large diffusion models, we
propose Diff$^2$I2P, a fully Differentiable I2P registration framework,
leveraging a novel and effective Diffusion prior for bridging the modality gap.
Specifically, we propose a Control-Side Score Distillation (CSD) technique to
distill knowledge from a depth-conditioned diffusion model to directly optimize
the predicted transformation. However, the gradients on the transformation fail
to backpropagate onto the cross-modal features due to the non-differentiability
of correspondence retrieval and PnP solver. To this end, we further propose a
Deformable Correspondence Tuning (DCT) module to estimate the correspondences
in a differentiable way, followed by the transformation estimation using a
differentiable PnP solver. With these two designs, the Diffusion model serves
as a strong prior to guide the cross-modal feature learning of image and point
cloud for forming robust correspondences, which significantly improves the
registration. Extensive experimental results demonstrate that Diff$^2$I2P
consistently outperforms SoTA I2P registration methods, achieving over 7%
improvement in registration recall on the 7-Scenes benchmark.

</details>


### [96] [MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval](https://arxiv.org/abs/2507.06654)
*Naoya Sogi,Takashi Shibata,Makoto Terao,Masanori Suganuma,Takayuki Okatani*

Main category: cs.CV

TL;DR: 本文提出了一种名为CDR-CA的新任务，通过多源DPP方法优化多属性多样性，以适应不同应用场景。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅关注图像外观多样性，忽略了应用场景的多样性需求，限制了结果多样化（RD）的应用范围。

Method: 提出Multi-Source DPPs，扩展DPP至多源，基于流形表示的统一相似性矩阵建模，并引入Tangent Normalization以反映上下文。

Result: 实验证明该方法有效。

Conclusion: CDR-CA任务及Multi-Source DPPs方法为结果多样化提供了更灵活的解决方案。

Abstract: Result diversification (RD) is a crucial technique in Text-to-Image Retrieval
for enhancing the efficiency of a practical application. Conventional methods
focus solely on increasing the diversity metric of image appearances. However,
the diversity metric and its desired value vary depending on the application,
which limits the applications of RD. This paper proposes a novel task called
CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims
to refine the diversities of multiple attributes, according to the
application's context. To address this task, we propose Multi-Source DPPs, a
simple yet strong baseline that extends the Determinantal Point Process (DPP)
to multi-sources. We model MS-DPP as a single DPP model with a unified
similarity matrix based on a manifold representation. We also introduce Tangent
Normalization to reflect contexts. Extensive experiments demonstrate the
effectiveness of the proposed method. Our code is publicly available at
https://github.com/NEC-N-SOGI/msdpp.

</details>


### [97] [Enhancing Diffusion Model Stability for Image Restoration via Gradient Management](https://arxiv.org/abs/2507.06656)
*Hongjie Wu,Mingqin Zhang,Linchao He,Ji-Zhe Zhou,Jiancheng Lv*

Main category: cs.CV

TL;DR: 论文提出了一种名为SPGD的新梯度管理技术，用于解决扩散模型中先验和似然梯度方向冲突及梯度波动问题，显著提升了图像恢复性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像恢复中表现出色，但先验和似然梯度方向的冲突及梯度波动问题未被充分研究，影响了生成过程的稳定性。

Method: 提出了SPGD技术，包括渐进式似然预热策略和自适应方向动量平滑，以缓解梯度冲突和减少波动。

Result: 实验表明，SPGD显著提升了生成稳定性，在多个恢复任务中取得了最先进的定量和视觉结果。

Conclusion: SPGD通过梯度管理有效解决了扩散模型中的不稳定问题，为图像恢复提供了更优的解决方案。

Abstract: Diffusion models have shown remarkable promise for image restoration by
leveraging powerful priors. Prominent methods typically frame the restoration
problem within a Bayesian inference framework, which iteratively combines a
denoising step with a likelihood guidance step. However, the interactions
between these two components in the generation process remain underexplored. In
this paper, we analyze the underlying gradient dynamics of these components and
identify significant instabilities. Specifically, we demonstrate conflicts
between the prior and likelihood gradient directions, alongside temporal
fluctuations in the likelihood gradient itself. We show that these
instabilities disrupt the generative process and compromise restoration
performance. To address these issues, we propose Stabilized Progressive
Gradient Diffusion (SPGD), a novel gradient management technique. SPGD
integrates two synergistic components: (1) a progressive likelihood warm-up
strategy to mitigate gradient conflicts; and (2) adaptive directional momentum
(ADM) smoothing to reduce fluctuations in the likelihood gradient. Extensive
experiments across diverse restoration tasks demonstrate that SPGD
significantly enhances generation stability, leading to state-of-the-art
performance in quantitative metrics and visually superior results. Code is
available at \href{https://github.com/74587887/SPGD}{here}.

</details>


### [98] [FlexGaussian: Flexible and Cost-Effective Training-Free Compression for 3D Gaussian Splatting](https://arxiv.org/abs/2507.06671)
*Boyuan Tian,Qizhe Gao,Siran Xianyu,Xiaotong Cui,Minjia Zhang*

Main category: cs.CV

TL;DR: FlexGaussian是一种无需重新训练的3D高斯压缩方法，结合混合精度量化和属性判别剪枝，实现高效压缩，适用于移动设备。


<details>
  <summary>Details</summary>
Motivation: 大规模3D模型的需求增长需要有效的压缩方法以减少内存和计算成本，现有方法缺乏灵活性且需要重新训练。

Method: 结合混合精度量化和属性判别剪枝，无需重新训练，适应不同压缩目标。

Result: 压缩率高达96.4%，渲染质量损失小（PSNR下降<1 dB），速度快于现有方法。

Conclusion: FlexGaussian提供了一种灵活、高效的3D高斯压缩解决方案，适用于资源受限的设备。

Abstract: 3D Gaussian splatting has become a prominent technique for representing and
rendering complex 3D scenes, due to its high fidelity and speed advantages.
However, the growing demand for large-scale models calls for effective
compression to reduce memory and computation costs, especially on mobile and
edge devices with limited resources. Existing compression methods effectively
reduce 3D Gaussian parameters but often require extensive retraining or
fine-tuning, lacking flexibility under varying compression constraints.
  In this paper, we introduce FlexGaussian, a flexible and cost-effective
method that combines mixed-precision quantization with attribute-discriminative
pruning for training-free 3D Gaussian compression. FlexGaussian eliminates the
need for retraining and adapts easily to diverse compression targets.
Evaluation results show that FlexGaussian achieves up to 96.4% compression
while maintaining high rendering quality (<1 dB drop in PSNR), and is
deployable on mobile devices. FlexGaussian delivers high compression ratios
within seconds, being 1.7-2.1x faster than state-of-the-art training-free
methods and 10-100x faster than training-involved approaches. The code is being
prepared and will be released soon at:
https://github.com/Supercomputing-System-AI-Lab/FlexGaussian

</details>


### [99] [Text-promptable Object Counting via Quantity Awareness Enhancement](https://arxiv.org/abs/2507.06679)
*Miaojing Shi,Xiaowen Zhang,Zijie Yue,Yong Luo,Cairong Zhao,Li Li*

Main category: cs.CV

TL;DR: QUANet通过引入数量导向的文本提示和视觉-文本数量对齐损失，提升了模型在计数任务中的数量感知能力，并通过双流自适应计数解码器实现了高性能的零样本类无关计数。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本提示中仅包含对象类别信息，不足以训练模型准确区分计数任务中的对象数量。

Method: 提出QUANet，包括数量导向的文本提示、视觉-文本数量对齐损失、双流自适应计数解码器（Transformer和CNN流）及T2C适配器，以及跨流数量排序损失。

Result: 在FSC-147、CARPK、PUCPR+和ShanghaiTech等标准基准测试中表现出强大的零样本类无关计数泛化能力。

Conclusion: QUANet通过创新的数量感知设计和双流解码器，显著提升了计数任务的性能。

Abstract: Recent advances in large vision-language models (VLMs) have shown remarkable
progress in solving the text-promptable object counting problem. Representative
methods typically specify text prompts with object category information in
images. This however is insufficient for training the model to accurately
distinguish the number of objects in the counting task. To this end, we propose
QUANet, which introduces novel quantity-oriented text prompts with a
vision-text quantity alignment loss to enhance the model's quantity awareness.
Moreover, we propose a dual-stream adaptive counting decoder consisting of a
Transformer stream, a CNN stream, and a number of Transformer-to-CNN
enhancement adapters (T2C-adapters) for density map prediction. The
T2C-adapters facilitate the effective knowledge communication and aggregation
between the Transformer and CNN streams. A cross-stream quantity ranking loss
is proposed in the end to optimize the ranking orders of predictions from the
two streams. Extensive experiments on standard benchmarks such as FSC-147,
CARPK, PUCPR+, and ShanghaiTech demonstrate our model's strong generalizability
for zero-shot class-agnostic counting. Code is available at
https://github.com/viscom-tongji/QUANet

</details>


### [100] [Spatial-Temporal Graph Mamba for Music-Guided Dance Video Synthesis](https://arxiv.org/abs/2507.06689)
*Hao Tang,Ling Shao,Zhenyu Zhang,Luc Van Gool,Nicu Sebe*

Main category: cs.CV

TL;DR: STG-Mamba是一种用于音乐引导舞蹈视频合成的空间-时间图模型，包含音乐到骨架和骨架到视频两个翻译映射，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决将输入音乐翻译为舞蹈视频的任务，通过空间-时间图模型捕捉关节依赖关系。

Method: 1. 音乐到骨架翻译：使用STGM块构建骨架序列；2. 骨架到视频翻译：提出自监督正则化网络。

Result: 实验表明STG-Mamba显著优于现有方法。

Conclusion: STG-Mamba在音乐到舞蹈视频合成任务中表现出色，具有创新性和实用性。

Abstract: We propose a novel spatial-temporal graph Mamba (STG-Mamba) for the
music-guided dance video synthesis task, i.e., to translate the input music to
a dance video. STG-Mamba consists of two translation mappings:
music-to-skeleton translation and skeleton-to-video translation. In the
music-to-skeleton translation, we introduce a novel spatial-temporal graph
Mamba (STGM) block to effectively construct skeleton sequences from the input
music, capturing dependencies between joints in both the spatial and temporal
dimensions. For the skeleton-to-video translation, we propose a novel
self-supervised regularization network to translate the generated skeletons,
along with a conditional image, into a dance video. Lastly, we collect a new
skeleton-to-video translation dataset from the Internet, containing 54,944
video clips. Extensive experiments demonstrate that STG-Mamba achieves
significantly better results than existing methods.

</details>


### [101] [Hierarchical Feature Alignment for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2507.06732)
*Sobhan Asasi,Mohamed Ilyes Lakhal,Richard Bowden*

Main category: cs.CV

TL;DR: 提出了一种基于伪注释和对比视频-语言对齐的分层预训练策略，用于提升手语翻译质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在视觉与文本表示之间的差异问题，同时避免依赖注释的负担。

Method: 采用分层特征提取（帧、片段、视频级）并与伪注释和口语对齐。

Result: 实验表明，该方法提高了BLEU-4和ROUGE分数，且保持高效。

Conclusion: 分层预训练策略有效提升了手语翻译的性能和灵活性。

Abstract: Sign Language Translation (SLT) attempts to convert sign language videos into
spoken sentences. However, many existing methods struggle with the disparity
between visual and textual representations during end-to-end learning.
Gloss-based approaches help to bridge this gap by leveraging structured
linguistic information. While, gloss-free methods offer greater flexibility and
remove the burden of annotation, they require effective alignment strategies.
Recent advances in Large Language Models (LLMs) have enabled gloss-free SLT by
generating text-like representations from sign videos. In this work, we
introduce a novel hierarchical pre-training strategy inspired by the structure
of sign language, incorporating pseudo-glosses and contrastive video-language
alignment. Our method hierarchically extracts features at frame, segment, and
video levels, aligning them with pseudo-glosses and the spoken sentence to
enhance translation quality. Experiments demonstrate that our approach improves
BLEU-4 and ROUGE scores while maintaining efficiency.

</details>


### [102] [MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport](https://arxiv.org/abs/2507.06733)
*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

Main category: cs.CV

TL;DR: 提出了一种结合视觉适配器、提示学习和部分最优传输（POT）与对比学习（CL）的新方法，用于提升CLIP在医学图像异常检测中的适应性。


<details>
  <summary>Details</summary>
Motivation: 医学异常检测面临成像模态多样、解剖变异大和标记数据有限等挑战，需要更灵活的方法。

Method: 采用多提示学习与局部特征对齐（通过POT），结合对比学习增强类内凝聚和类间分离。

Result: 在少样本、零样本和跨数据集场景中取得最优结果，无需合成数据或记忆库。

Conclusion: 该方法显著提升了医学图像异常检测的性能，代码已开源。

Abstract: Medical anomaly detection (AD) is challenging due to diverse imaging
modalities, anatomical variations, and limited labeled data. We propose a novel
approach combining visual adapters and prompt learning with Partial Optimal
Transport (POT) and contrastive learning (CL) to improve CLIP's adaptability to
medical images, particularly for AD. Unlike standard prompt learning, which
often yields a single representation, our method employs multiple prompts
aligned with local features via POT to capture subtle abnormalities. CL further
enforces intra-class cohesion and inter-class separation. Our method achieves
state-of-the-art results in few-shot, zero-shot, and cross-dataset scenarios
without synthetic data or memory banks. The code is available at
https://github.com/mahshid1998/MADPOT.

</details>


### [103] [DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement](https://arxiv.org/abs/2507.06738)
*Xinyu Xie,Weifeng Cao,Jun Shi,Yangyang Hu,Hui Liang,Wanyong Liang,Xiaoliang Qian*

Main category: cs.CV

TL;DR: 论文提出了首个半导体晶圆切割过程的公开数据集CHDL，并设计了一种双路径预测架构DIFFUMA，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 在高精度工业场景（如半导体制造）中，缺乏专用数据集阻碍了复杂过程建模和预测的研究。

Method: 构建CHDL数据集，并提出DIFFUMA模型，结合Mamba模块和扩散模块，分别捕获全局时间上下文和增强空间细节。

Result: DIFFUMA在CHDL数据集上MSE降低39%，SSIM从0.926提升至0.988，并在自然现象数据集上表现优异。

Conclusion: 该工作不仅提供了新的SOTA模型，还为工业AI研究提供了宝贵的数据资源。

Abstract: Spatio-temporal video prediction plays a pivotal role in critical domains,
ranging from weather forecasting to industrial automation. However, in
high-precision industrial scenarios such as semiconductor manufacturing, the
absence of specialized benchmark datasets severely hampers research on modeling
and predicting complex processes. To address this challenge, we make a twofold
contribution.First, we construct and release the Chip Dicing Lane Dataset
(CHDL), the first public temporal image dataset dedicated to the semiconductor
wafer dicing process. Captured via an industrial-grade vision system, CHDL
provides a much-needed and challenging benchmark for high-fidelity process
modeling, defect detection, and digital twin development.Second, we propose
DIFFUMA, an innovative dual-path prediction architecture specifically designed
for such fine-grained dynamics. The model captures global long-range temporal
context through a parallel Mamba module, while simultaneously leveraging a
diffusion module, guided by temporal features, to restore and enhance
fine-grained spatial details, effectively combating feature degradation.
Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly
outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and
improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988.
This superior performance also generalizes to natural phenomena datasets. Our
work not only delivers a new state-of-the-art (SOTA) model but, more
importantly, provides the community with an invaluable data resource to drive
future research in industrial AI.

</details>


### [104] [PromptTea: Let Prompts Tell TeaCache the Optimal Threshold](https://arxiv.org/abs/2507.06739)
*Zishen Huang,Chunyu Yang,Mengyuan Ren*

Main category: cs.CV

TL;DR: 提出了一种基于提示复杂度的自适应缓存方法（PCA缓存），通过动态调整重用阈值和优化输入输出建模，显著提升了视频生成的推理速度，同时保持高质量输出。


<details>
  <summary>Details</summary>
Motivation: 固定频率的缓存机制在复杂场景中会导致质量下降，手动调整阈值效率低且不鲁棒，因此需要一种更智能的自适应方法。

Method: 提出PCA缓存，根据输入提示的语义复杂度动态调整重用阈值；改进TeaCache的输入输出建模，增强文本信息贡献；引入动态CFGCache机制，选择性重用CFG输出。

Result: 实验表明，该方法在Wan2.1模型上实现了2.79倍的加速，同时保持了高视觉保真度。

Conclusion: PCA缓存和动态CFGCache的结合显著提升了视频生成的效率和适应性，为复杂场景下的实时生成提供了有效解决方案。

Abstract: Despite recent progress in video generation, inference speed remains a major
bottleneck. A common acceleration strategy involves reusing model outputs via
caching mechanisms at fixed intervals. However, we find that such
fixed-frequency reuse significantly degrades quality in complex scenes, while
manually tuning reuse thresholds is inefficient and lacks robustness. To
address this, we propose Prompt-Complexity-Aware (PCA) caching, a method that
automatically adjusts reuse thresholds based on scene complexity estimated
directly from the input prompt. By incorporating prompt-derived semantic cues,
PCA enables more adaptive and informed reuse decisions than conventional
caching methods. We also revisit the assumptions behind TeaCache and identify a
key limitation: it suffers from poor input-output relationship modeling due to
an oversimplified prior. To overcome this, we decouple the noisy input, enhance
the contribution of meaningful textual information, and improve the model's
predictive accuracy through multivariate polynomial feature expansion. To
further reduce computational cost, we replace the static CFGCache with
DynCFGCache, a dynamic mechanism that selectively reuses classifier-free
guidance (CFG) outputs based on estimated output variations. This allows for
more flexible reuse without compromising output quality. Extensive experiments
demonstrate that our approach achieves significant acceleration-for example,
2.79x speedup on the Wan2.1 model-while maintaining high visual fidelity across
a range of scenes.

</details>


### [105] [Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu](https://arxiv.org/abs/2507.06761)
*Yan Hon Michael Chung,Donghyeok Choi*

Main category: cs.CV

TL;DR: 该研究通过微调三种开源视觉语言模型，开发了高性能的满文OCR系统，显著提升了真实历史文档的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 满文作为濒危语言对研究早期现代东亚历史至关重要，但缺乏有效的OCR系统处理真实历史文档。

Method: 使用60,000张合成满文单词图像对三种模型（LLaMA-3.2-11B、Qwen2.5-VL-7B、Qwen2.5-VL-3B）进行参数高效训练。

Result: LLaMA-3.2-11B在合成数据上达到98.3%的单词准确率和0.0024的字符错误率，在真实手写文档上保持93.1%的准确率，显著优于传统方法。

Conclusion: 该研究为濒危语言OCR提供了可转移的框架，降低了技术和财务门槛，助力历史学家和语言学家处理历史档案。

Abstract: Manchu, a critically endangered language essential for understanding early
modern Eastern Eurasian history, lacks effective OCR systems that can handle
real-world historical documents. This study develops high-performing OCR
systems by fine-tuning three open-source vision-language models (LLaMA-3.2-11B,
Qwen2.5-VL-7B, Qwen2.5-VL-3B) on 60,000 synthetic Manchu word images using
parameter-efficient training. LLaMA-3.2-11B achieved exceptional performance
with 98.3\% word accuracy and 0.0024 character error rate on synthetic data,
while crucially maintaining 93.1\% accuracy on real-world handwritten
documents. Comparative evaluation reveals substantial advantages over
traditional approaches: while a CRNN baseline achieved 99.8\% synthetic
accuracy, it suffered severe degradation to 72.5\% on real documents. Our
approach demonstrates effective synthetic-to-real domain transfer, providing a
cost-effective solution deployable on accessible infrastructure. This work
establishes a transferable framework for endangered language OCR that removes
technical and financial barriers in digital humanities, enabling historians and
linguists to process historical archives without specialized computing
resources. Code and model weights are available at
https://github.com/mic7ch1/ManchuAI-OCR.

</details>


### [106] [FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views](https://arxiv.org/abs/2507.06763)
*Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel*

Main category: cs.CV

TL;DR: FOLC-Net框架通过轻量级架构和优化机制提升MRI多视角诊断性能，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有SOTA模型在处理MRI多视角（轴向、冠状、矢状）时性能下降的问题。

Method: 引入FOLC-Net，结合MRFO优化、全局模型克隆和ConvNeXt，参数仅1.217M，存储0.9MB。

Result: 在矢状视角准确率达92.44%，优于其他模型（88.37%和88.95%），多视角表现稳健。

Conclusion: FOLC-Net为分散式医疗图像分析提供了更可靠、适应性更强的解决方案。

Abstract: The framework is designed to improve performance in the analysis of combined
as well as single anatomical perspectives for MRI disease diagnosis. It
specifically addresses the performance degradation observed in state-of-the-art
(SOTA) models, particularly when processing axial, coronal, and sagittal
anatomical planes. The paper introduces the FOLC-Net framework, which
incorporates a novel federated-optimized lightweight architecture with
approximately 1.217 million parameters and a storage requirement of only 0.9
MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for
efficient model structure generation, global model cloning for scalable
training, and ConvNeXt for enhanced client adaptability. The model was
evaluated on combined multi-view data as well as individual views, such as
axial, coronal, and sagittal, to assess its robustness in various medical
imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different
data to evaluate its ability to generalize beyond the training dataset. The
results show that FOLC-Net outperforms existing models, particularly in the
challenging sagittal view. For instance, FOLC-Net achieved an accuracy of
92.44% on the sagittal view, significantly higher than the 88.37% accuracy of
study method (DL + Residual Learning) and 88.95% of DL models. Additionally,
FOLC-Net demonstrated improved accuracy across all individual views, providing
a more reliable and robust solution for medical image analysis in decentralized
environments. FOLC-Net addresses the limitations of existing SOTA models by
providing a framework that ensures better adaptability to individual views
while maintaining strong performance in multi-view settings. The incorporation
of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs
better in real-world medical applications.

</details>


### [107] [Unlocking Thermal Aerial Imaging: Synthetic Enhancement of UAV Datasets](https://arxiv.org/abs/2507.06797)
*Antonella Barisic Kulas,Andreja Jurasovic,Stjepan Bogdan*

Main category: cs.CV

TL;DR: 提出了一种生成合成热成像数据的流程，用于扩展热成像数据集，提升无人机热成像应用中的深度学习模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决热成像数据稀缺问题，推动无人机在搜索救援、野生动物监测等领域的应用。

Method: 通过合成方法将任意物体类别嵌入现有热成像背景，控制位置、尺度和方向，并增强现有数据集。

Result: 在目标检测任务中表现优异，热成像检测器优于可见光训练模型。

Conclusion: 合成热成像数据能有效扩展数据集，提升模型性能，尤其在无人机视角下表现突出。

Abstract: Thermal imaging from unmanned aerial vehicles (UAVs) holds significant
potential for applications in search and rescue, wildlife monitoring, and
emergency response, especially under low-light or obscured conditions. However,
the scarcity of large-scale, diverse thermal aerial datasets limits the
advancement of deep learning models in this domain, primarily due to the high
cost and logistical challenges of collecting thermal data. In this work, we
introduce a novel procedural pipeline for generating synthetic thermal images
from an aerial perspective. Our method integrates arbitrary object classes into
existing thermal backgrounds by providing control over the position, scale, and
orientation of the new objects, while aligning them with the viewpoints of the
background. We enhance existing thermal datasets by introducing new object
categories, specifically adding a drone class in urban environments to the
HIT-UAV dataset and an animal category to the MONET dataset. In evaluating
these datasets for object detection task, we showcase strong performance across
both new and existing classes, validating the successful expansion into new
applications. Through comparative analysis, we show that thermal detectors
outperform their visible-light-trained counterparts and highlight the
importance of replicating aerial viewing angles. Project page:
https://github.com/larics/thermal_aerial_synthetic.

</details>


### [108] [GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction](https://arxiv.org/abs/2507.06806)
*Eya Cherif,Arthur Ouaknine,Luke A. Brown,Phuong D. Dao,Kyle R. Kovach,Bing Lu,Daniel Mederer,Hannes Feilhauer,Teja Kattenborn,David Rolnick*

Main category: cs.CV

TL;DR: GreenHyperSpectra数据集用于植物性状预测，通过半监督和自监督方法提升跨域性能，优于现有监督基线。


<details>
  <summary>Details</summary>
Motivation: 传统野外采样难以覆盖生态尺度上的性状变异，机器学习结合遥感数据成为解决方案，但面临标签稀缺和域偏移问题。

Method: 提出GreenHyperSpectra数据集，采用半监督和自监督方法预训练多输出回归模型，评估框架包括域内和域外场景。

Result: 模型在性状预测中表现优于现有监督基线，显著提升了光谱表征学习能力。

Conclusion: GreenHyperSpectra为植物功能性状评估与表征学习的交叉研究提供了方法论框架和数据支持。

Abstract: Plant traits such as leaf carbon content and leaf mass are essential
variables in the study of biodiversity and climate change. However,
conventional field sampling cannot feasibly cover trait variation at
ecologically meaningful spatial scales. Machine learning represents a valuable
solution for plant trait prediction across ecosystems, leveraging hyperspectral
data from remote sensing. Nevertheless, trait prediction from hyperspectral
data is challenged by label scarcity and substantial domain shifts (\eg across
sensors, ecological distributions), requiring robust cross-domain methods.
Here, we present GreenHyperSpectra, a pretraining dataset encompassing
real-world cross-sensor and cross-ecosystem samples designed to benchmark trait
prediction with semi- and self-supervised methods. We adopt an evaluation
framework encompassing in-distribution and out-of-distribution scenarios. We
successfully leverage GreenHyperSpectra to pretrain label-efficient
multi-output regression models that outperform the state-of-the-art supervised
baseline. Our empirical analyses demonstrate substantial improvements in
learning spectral representations for trait prediction, establishing a
comprehensive methodological framework to catalyze research at the intersection
of representation learning and plant functional traits assessment. All code and
data are available at: https://github.com/echerif18/HyspectraSSL.

</details>


### [109] [Democratizing High-Fidelity Co-Speech Gesture Video Generation](https://arxiv.org/abs/2507.06812)
*Xu Yang,Shaoli Huang,Shenbo Xie,Xuelin Chen,Yifei Liu,Changxing Ding*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量级框架，利用2D全身骨架作为辅助条件，通过扩散模型生成与音频同步的说话者视频，并发布了首个公开数据集CSG-405。


<details>
  <summary>Details</summary>
Motivation: 解决语音手势视频生成中的一对多映射问题、数据稀缺和高计算需求挑战。

Method: 使用2D骨架作为音频与视觉输出的桥梁，结合扩散模型和骨架-音频特征融合，生成高保真视频。

Result: 方法在视觉质量和同步性上优于现有技术，并能泛化到不同说话者和场景。

Conclusion: 提出的框架和数据集为语音手势视频生成研究提供了高效且可扩展的解决方案。

Abstract: Co-speech gesture video generation aims to synthesize realistic,
audio-aligned videos of speakers, complete with synchronized facial expressions
and body gestures. This task presents challenges due to the significant
one-to-many mapping between audio and visual content, further complicated by
the scarcity of large-scale public datasets and high computational demands. We
propose a lightweight framework that utilizes 2D full-body skeletons as an
efficient auxiliary condition to bridge audio signals with visual outputs. Our
approach introduces a diffusion model conditioned on fine-grained audio
segments and a skeleton extracted from the speaker's reference image,
predicting skeletal motions through skeleton-audio feature fusion to ensure
strict audio coordination and body shape consistency. The generated skeletons
are then fed into an off-the-shelf human video generation model with the
speaker's reference image to synthesize high-fidelity videos. To democratize
research, we present CSG-405-the first public dataset with 405 hours of
high-resolution videos across 71 speech types, annotated with 2D skeletons and
diverse speaker demographics. Experiments show that our method exceeds
state-of-the-art approaches in visual quality and synchronization while
generalizing across speakers and contexts.

</details>


### [110] [HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement](https://arxiv.org/abs/2507.06814)
*Qingsen Yan,Kangbiao Shi,Yixu Feng,Tao Hu,Peng Wu,Guansong Pang,Yanning Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种新的颜色空间HVI和网络HVI-CIDNet+，用于低光图像增强，解决了现有方法的颜色偏差和亮度伪影问题，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于sRGB和HSV颜色空间的低光图像增强方法存在颜色偏差、亮度伪影以及红黑噪声问题，需要一种更有效的解决方案。

Method: 提出HVI颜色空间（结合HV颜色图和可学习强度）和HVI-CIDNet+网络，利用预训练视觉语言模型提取上下文信息，并通过Prior-guided Attention Block和Region Refinement Block优化内容恢复和颜色校正。

Result: 在10个基准数据集上的实验表明，HVI-CIDNet+优于现有最优方法。

Conclusion: HVI颜色空间和HVI-CIDNet+网络有效解决了低光图像增强中的颜色和亮度问题，显著提升了性能。

Abstract: Low-Light Image Enhancement (LLIE) aims to restore vivid content and details
from corrupted low-light images. However, existing standard RGB (sRGB) color
space-based LLIE methods often produce color bias and brightness artifacts due
to the inherent high color sensitivity. While Hue, Saturation, and Value (HSV)
color space can decouple brightness and color, it introduces significant red
and black noise artifacts. To address this problem, we propose a new color
space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by the HV
color map and learnable intensity. The HV color map enforces small distances
for the red coordinates to remove red noise artifacts, while the learnable
intensity compresses the low-light regions to remove black noise artifacts.
Additionally, we introduce the Color and Intensity Decoupling Network+
(HVI-CIDNet+), built upon the HVI color space, to restore damaged content and
mitigate color distortion in extremely dark regions. Specifically, HVI-CIDNet+
leverages abundant contextual and degraded knowledge extracted from low-light
images using pre-trained vision-language models, integrated via a novel
Prior-guided Attention Block (PAB). Within the PAB, latent semantic priors can
promote content restoration, while degraded representations guide precise color
correction, both particularly in extremely dark regions through the
meticulously designed cross-attention fusion mechanism. Furthermore, we
construct a Region Refinement Block that employs convolution for
information-rich regions and self-attention for information-scarce regions,
ensuring accurate brightness adjustments. Comprehensive results from benchmark
experiments demonstrate that the proposed HVI-CIDNet+ outperforms the
state-of-the-art methods on 10 datasets.

</details>


### [111] [Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation](https://arxiv.org/abs/2507.06830)
*Tao Feng,Xianbing Zhao,Zhenhua Chen,Tien Tsin Wong,Hamid Rezatofighi,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CV

TL;DR: 提出了一种结合符号回归和轨迹引导的视频生成框架，以提升视频生成的物理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型依赖统计相关性而非物理规律，导致物体运动不符合真实动力学。

Method: 通过提取运动轨迹、检索预训练增强符号回归，发现运动方程以预测物理准确的轨迹，并引导视频生成。

Result: 在经典力学场景中成功恢复真实运动方程，生成视频的物理对齐性优于基线方法。

Conclusion: 该框架无需微调现有模型即可提升视频生成的物理准确性。

Abstract: Recent advances in diffusion-based and autoregressive video generation models
have achieved remarkable visual realism. However, these models typically lack
accurate physical alignment, failing to replicate real-world dynamics in object
motion. This limitation arises primarily from their reliance on learned
statistical correlations rather than capturing mechanisms adhering to physical
laws. To address this issue, we introduce a novel framework that integrates
symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for
physics-grounded video forecasting. Our approach extracts motion trajectories
from input videos, uses a retrieval-based pre-training mechanism to enhance
symbolic regression, and discovers equations of motion to forecast physically
accurate future trajectories. These trajectories then guide video generation
without requiring fine-tuning of existing models. Evaluated on scenarios in
Classical Mechanics, including spring-mass, pendulums, and projectile motions,
our method successfully recovers ground-truth analytical equations and improves
the physical alignment of generated videos over baseline methods.

</details>


### [112] [Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs](https://arxiv.org/abs/2507.06999)
*Yahan Yu,Yuyang Dong,Masafumi Oyamada*

Main category: cs.CV

TL;DR: 提出了Deliberate-to-Intuitive（D2I）框架，通过规则奖励提升多模态大语言模型（MLLMs）的推理能力，无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 解决多模态推理研究中模态对齐和训练成本高的问题。

Method: D2I框架在训练时采用规则奖励增强模态对齐，评估时转为直觉推理。

Result: D2I在领域内外基准测试中优于基线模型。

Conclusion: 格式奖励有助于提升MLLMs的可迁移推理能力，并为训练与测试推理深度的解耦提供方向。

Abstract: Reasoning is a key capability for large language models (LLMs), particularly
when applied to complex tasks such as mathematical problem solving. However,
multimodal reasoning research still requires further exploration of modality
alignment and training costs. Many of these approaches rely on additional data
annotation and relevant rule-based rewards to enhance the understanding and
reasoning ability, which significantly increases training costs and limits
scalability. To address these challenges, we propose the
Deliberate-to-Intuitive reasoning framework (D2I) that improves the
understanding and reasoning ability of multimodal LLMs (MLLMs) without extra
annotations and complex rewards. Specifically, our method sets deliberate
reasoning strategies to enhance modality alignment only through the rule-based
format reward during training. While evaluating, the reasoning style shifts to
intuitive, which removes deliberate reasoning strategies during training and
implicitly reflects the model's acquired abilities in the response. D2I
outperforms baselines across both in-domain and out-of-domain benchmarks. Our
findings highlight the role of format reward in fostering transferable
reasoning skills in MLLMs, and inspire directions for decoupling training-time
reasoning depth from test-time response flexibility.

</details>


### [113] [Know Your Attention Maps: Class-specific Token Masking for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2507.06848)
*Joelle Hanna,Damian Borth*

Main category: cs.CV

TL;DR: 提出一种基于Vision Transformer的端到端弱监督语义分割方法，利用多[CLS]令牌的注意力图生成伪分割掩码，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统弱监督语义分割方法依赖外部模块（如CAM）生成伪掩码，本文旨在直接利用ViT的注意力图，提升效率和准确性。

Method: 训练稀疏ViT，每个类别对应一个[CLS]令牌，采用随机掩码策略促进类别分配；推理时聚合各[CLS]令牌的自注意力图生成伪掩码。

Result: 在多个标准数据集上表现优异，生成的伪掩码可用于训练分割模型，性能接近全监督模型。

Conclusion: 该方法显著减少细粒度标注需求，为弱监督语义分割提供了高效解决方案。

Abstract: Weakly Supervised Semantic Segmentation (WSSS) is a challenging problem that
has been extensively studied in recent years. Traditional approaches often rely
on external modules like Class Activation Maps to highlight regions of interest
and generate pseudo segmentation masks. In this work, we propose an end-to-end
method that directly utilizes the attention maps learned by a Vision
Transformer (ViT) for WSSS. We propose training a sparse ViT with multiple
[CLS] tokens (one for each class), using a random masking strategy to promote
[CLS] token - class assignment. At inference time, we aggregate the different
self-attention maps of each [CLS] token corresponding to the predicted labels
to generate pseudo segmentation masks. Our proposed approach enhances the
interpretability of self-attention maps and ensures accurate class assignments.
Extensive experiments on two standard benchmarks and three specialized datasets
demonstrate that our method generates accurate pseudo-masks, outperforming
related works. Those pseudo-masks can be used to train a segmentation model
which achieves results comparable to fully-supervised models, significantly
reducing the need for fine-grained labeled data.

</details>


### [114] [IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization](https://arxiv.org/abs/2507.06856)
*Subrat Kishore Dutta,Xiao Zhang*

Main category: cs.CV

TL;DR: IAP是一种新型攻击框架，通过感知感知定位和扰动优化方案生成高度不可见的对抗性补丁，显著提升隐蔽性和攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在针对性攻击场景下表现不佳或生成的补丁不连贯，容易被人类或自动防御系统发现。

Method: IAP结合类定位和敏感度图选择补丁位置，并通过感知感知正则化对抗损失和梯度更新规则优化扰动。

Result: 实验表明，IAP在多种基准和模型架构中均实现高攻击成功率，且补丁隐蔽性显著优于现有方法。

Conclusion: IAP不仅对人类高度不可见，还能有效规避多种先进补丁防御系统。

Abstract: Despite modifying only a small localized input region, adversarial patches
can drastically change the prediction of computer vision models. However, prior
methods either cannot perform satisfactorily under targeted attack scenarios or
fail to produce contextually coherent adversarial patches, causing them to be
easily noticeable by human examiners and insufficiently stealthy against
automatic patch defenses. In this paper, we introduce IAP, a novel attack
framework that generates highly invisible adversarial patches based on
perceptibility-aware localization and perturbation optimization schemes.
Specifically, IAP first searches for a proper location to place the patch by
leveraging classwise localization and sensitivity maps, balancing the
susceptibility of patch location to both victim model prediction and human
visual system, then employs a perceptibility-regularized adversarial loss and a
gradient update rule that prioritizes color constancy for optimizing invisible
perturbations. Comprehensive experiments across various image benchmarks and
model architectures demonstrate that IAP consistently achieves competitive
attack success rates in targeted settings with significantly improved patch
invisibility compared to existing baselines. In addition to being highly
imperceptible to humans, IAP is shown to be stealthy enough to render several
state-of-the-art patch defenses ineffective.

</details>


### [115] [Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis](https://arxiv.org/abs/2507.06858)
*Mathias Schulz,Alexander Spenke,Pia Funk,Florian Blümel,Markus Rohde,Ralph Breithaupt,Gerd Nolden,Norbert Jung,Robert Lange*

Main category: cs.CV

TL;DR: 长期生物特征评估显示，个体间的日间分数波动比整个测量期间更大，强调长期测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过长期生物特征评估，揭示个体在不同时间点的生物特征变化，为生物识别技术提供更可靠的数据支持。

Method: 使用多种生物识别工具和技术，对400多名参与者进行两年半的定期评估，并利用先进的人脸识别算法分析长期比较分数。

Result: 研究发现，个体间的日间生物特征分数波动显著大于整个测量期间的波动。

Conclusion: 长期测试在受控环境中对生物特征分析至关重要，为未来技术进步奠定基础。

Abstract: This study presents findings from long-term biometric evaluations conducted
at the Biometric Evaluation Center (bez). Over the course of two and a half
years, our ongoing research with over 400 participants representing diverse
ethnicities, genders, and age groups were regularly assessed using a variety of
biometric tools and techniques at the controlled testing facilities. Our
findings are based on the General Data Protection Regulation-compliant local
bez database with more than 238.000 biometric data sets categorized into
multiple biometric modalities such as face and finger. We used state-of-the-art
face recognition algorithms to analyze long-term comparison scores. Our results
show that these scores fluctuate more significantly between individual days
than over the entire measurement period. These findings highlight the
importance of testing biometric characteristics of the same individuals over a
longer period of time in a controlled measurement environment and lays the
groundwork for future advancements in biometric data analysis.

</details>


### [116] [SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds](https://arxiv.org/abs/2507.06906)
*Matthias Zeller,Daniel Casado Herraez,Bengisu Ayan,Jens Behley,Michael Heidingsfeld,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 论文提出了一种名为SemRaFiner的方法，用于改进稀疏雷达点云的泛光分割，以增强场景理解。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要语义场景理解，但摄像头和LiDAR在恶劣天气下表现不佳，且无法提供运动信息。雷达传感器虽能克服这些限制，但其测量稀疏且噪声大。

Method: SemRaFiner方法优化了稀疏雷达点云的特征提取，并提出了一种改进的训练流程，通过专门的数据增强来细化实例分配。

Result: 实验表明，该方法在雷达泛光分割任务中优于现有技术。

Conclusion: SemRaFiner通过优化特征提取和训练流程，显著提升了雷达点云的场景理解能力。

Abstract: Semantic scene understanding, including the perception and classification of
moving agents, is essential to enabling safe and robust driving behaviours of
autonomous vehicles. Cameras and LiDARs are commonly used for semantic scene
understanding. However, both sensor modalities face limitations in adverse
weather and usually do not provide motion information. Radar sensors overcome
these limitations and directly offer information about moving agents by
measuring the Doppler velocity, but the measurements are comparably sparse and
noisy. In this paper, we address the problem of panoptic segmentation in sparse
radar point clouds to enhance scene understanding. Our approach, called
SemRaFiner, accounts for changing density in sparse radar point clouds and
optimizes the feature extraction to improve accuracy. Furthermore, we propose
an optimized training procedure to refine instance assignments by incorporating
a dedicated data augmentation. Our experiments suggest that our approach
outperforms state-of-the-art methods for radar-based panoptic segmentation.

</details>


### [117] [Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement](https://arxiv.org/abs/2507.06928)
*Qiyuan Dai,Hanzhuo Huang,Yu Wu,Sibei Yang*

Main category: cs.CV

TL;DR: APL方法通过自适应部分发现和学习，利用共享可学习部分查询和DINO部分先验生成一致的对象部分及其对应关系，提出了一种新的all-min对比损失，以学习更具区分性和泛化性的部分表示。


<details>
  <summary>Details</summary>
Motivation: 解决现有GCD方法在全局表示学习中存在的区分性和泛化性之间的权衡问题。

Method: 提出APL方法，结合共享部分查询和DINO部分先验，生成一致的对象部分及其对应关系，并使用all-min对比损失学习部分表示。

Result: APL方法显著提升了细粒度数据集上的性能。

Conclusion: APL方法通过自适应部分学习和对比损失，有效平衡了区分性和泛化性，适用于多种GCD框架。

Abstract: Generalized Category Discovery (GCD) aims to recognize unlabeled images from
known and novel classes by distinguishing novel classes from known ones, while
also transferring knowledge from another set of labeled images with known
classes. Existing GCD methods rely on self-supervised vision transformers such
as DINO for representation learning. However, focusing solely on the global
representation of the DINO CLS token introduces an inherent trade-off between
discriminability and generalization. In this paper, we introduce an adaptive
part discovery and learning method, called APL, which generates consistent
object parts and their correspondences across different similar images using a
set of shared learnable part queries and DINO part priors, without requiring
any additional annotations. More importantly, we propose a novel all-min
contrastive loss to learn discriminative yet generalizable part representation,
which adaptively highlights discriminative object parts to distinguish similar
categories for enhanced discriminability while simultaneously sharing other
parts to facilitate knowledge transfer for improved generalization. Our APL can
easily be incorporated into different GCD frameworks by replacing their CLS
token feature with our part representations, showing significant enhancements
on fine-grained datasets.

</details>


### [118] [MCCD: A Multi-Attribute Chinese Calligraphy Character Dataset Annotated with Script Styles, Dynasties, and Calligraphers](https://arxiv.org/abs/2507.06948)
*Yixin Zhao,Yuyi Zhang,Lianwen Jin*

Main category: cs.CV

TL;DR: 论文提出了一个多属性中国书法字符数据集（MCCD），填补了现有数据集稀缺且缺乏属性信息的空白，为书法字符识别、书法家鉴定等研究提供了丰富资源。


<details>
  <summary>Details</summary>
Motivation: 研究书法属性信息（如风格、朝代、书法家）具有重要文化历史价值，但现有数据集稀缺且缺乏属性标注，阻碍了深入研究。

Method: 构建了包含7,765类329,715个书法字符图像的MCCD数据集，并基于脚本风格、朝代和书法家属性提取了三个子集。

Result: 实验表明，书法字符的笔画结构复杂性和属性间的交互作用显著增加了准确识别的难度。

Conclusion: MCCD填补了详细书法数据集的空白，为多领域研究提供了宝贵资源。

Abstract: Research on the attribute information of calligraphy, such as styles,
dynasties, and calligraphers, holds significant cultural and historical value.
However, the styles of Chinese calligraphy characters have evolved dramatically
through different dynasties and the unique touches of calligraphers, making it
highly challenging to accurately recognize these different characters and their
attributes. Furthermore, existing calligraphic datasets are extremely scarce,
and most provide only character-level annotations without additional attribute
information. This limitation has significantly hindered the in-depth study of
Chinese calligraphy. To fill this gap, we present a novel Multi-Attribute
Chinese Calligraphy Character Dataset (MCCD). The dataset encompasses 7,765
categories with a total of 329,715 isolated image samples of Chinese
calligraphy characters, and three additional subsets were extracted based on
the attribute labeling of the three types of script styles (10 types),
dynasties (15 periods) and calligraphers (142 individuals). The rich
multi-attribute annotations render MCCD well-suited diverse research tasks,
including calligraphic character recognition, writer identification, and
evolutionary studies of Chinese characters. We establish benchmark performance
through single-task and multi-task recognition experiments across MCCD and all
of its subsets. The experimental results demonstrate that the complexity of the
stroke structure of the calligraphic characters, and the interplay between
their different attributes, leading to a substantial increase in the difficulty
of accurate recognition. MCCD not only fills a void in the availability of
detailed calligraphy datasets but also provides valuable resources for
advancing research in Chinese calligraphy and fostering advancements in
multiple fields. The dataset is available at
https://github.com/SCUT-DLVCLab/MCCD.

</details>


### [119] [Pre-Columbian Settlements Shaped Palm Clusters in the Sierra Nevada de Santa Marta, Colombia](https://arxiv.org/abs/2507.06949)
*Sebastian Fajardo,Sina Mohammadi,Jonas Gregorio de Souza,César Ardila,Alan Tapscott Baltar,Shaddai Heidgen,Maria Isabel Mayorga Hernández,Sylvia Mota de Oliveira,Fernando Montejo,Marco Moderato,Vinicius Peripato,Katy Puche,Carlos Reina,Juan Carlos Vargas,Frank W. Takes,Marco Madella*

Main category: cs.CV

TL;DR: 利用深度学习模型和聚类算法，通过卫星图像识别棕榈树分布，揭示古代人类活动对植被的影响。


<details>
  <summary>Details</summary>
Motivation: 研究古代人类管理对热带森林的长期影响，特别是在高分辨率尺度上的作用。

Method: 结合深度学习模型（识别棕榈树）和聚类算法（识别棕榈树集群），估计古代管理区域。

Result: 棕榈树在考古遗址附近显著更多，表明古代人类活动促进了棕榈树增殖，管理区域可能比考古证据显示的大两个数量级。

Conclusion: 古代人类通过植被管理留下了持久的生态足迹，人工智能与生态考古数据结合可揭示精细尺度的人与环境互动。

Abstract: Ancient populations markedly transformed Neotropical forests, yet
understanding the long-term effects of ancient human management, particularly
at high-resolution scales, remains challenging. In this work we propose a new
approach to investigate archaeological areas of influence based on vegetation
signatures. It consists of a deep learning model trained on satellite imagery
to identify palm trees, followed by a clustering algorithm to identify palm
clusters, which are then used to estimate ancient management areas. To assess
the palm distribution in relation to past human activity, we applied the
proposed approach to unique high-resolution satellite imagery data covering 765
km2 of the Sierra Nevada de Santa Marta, Colombia. With this work, we also
release a manually annotated palm tree dataset along with estimated locations
of archaeological sites from ground-surveys and legacy records. Results
demonstrate how palms were significantly more abundant near archaeological
sites showing large infrastructure investment. The extent of the largest palm
cluster indicates that ancient human-managed areas linked to major
infrastructure sites may be up to two orders of magnitude bigger than indicated
by archaeological evidence alone. Our findings suggest that pre-Columbian
populations influenced local vegetation fostering conditions conducive to palm
proliferation, leaving a lasting ecological footprint. This may have lowered
the logistical costs of establishing infrastructure-heavy settlements in
otherwise less accessible locations. Overall, this study demonstrates the
potential of integrating artificial intelligence approaches with new ecological
and archaeological data to identify archaeological areas of interest through
vegetation patterns, revealing fine-scale human-environment interactions.

</details>


### [120] [CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale](https://arxiv.org/abs/2507.06959)
*Xiao Liang,Jiawei Hu,Di Wang,Zhi Ma,Lin Zhao,Ronghan Li,Bo Wan,Quan Wang*

Main category: cs.CV

TL;DR: CheXPO通过结合置信度-相似性联合挖掘与反事实推理，优化医学视觉语言模型，减少幻觉问题，提升性能。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型（VLMs）存在幻觉问题，影响可靠性，而传统偏好优化方法面临数据分布不均、专家标注成本高等挑战。

Method: 提出CheXPO策略，包括合成多任务胸部X光视觉指令数据集进行监督微调（SFT），通过置信度分析和相似性检索平衡样本分布，并利用反事实推理提供细粒度偏好。

Result: 实验显示，CheXPO仅用5%的SFT样本即实现8.93%的性能提升，达到最优水平。

Conclusion: CheXPO为放射学应用提供了可扩展、可解释的解决方案。

Abstract: Vision-language models (VLMs) are prone to hallucinations that critically
compromise reliability in medical applications. While preference optimization
can mitigate these hallucinations through clinical feedback, its implementation
faces challenges such as clinically irrelevant training samples, imbalanced
data distributions, and prohibitive expert annotation costs. To address these
challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy
that combines confidence-similarity joint mining with counterfactual rationale.
Our approach begins by synthesizing a unified, fine-grained multi-task chest
X-ray visual instruction dataset across different question types for supervised
fine-tuning (SFT). We then identify hard examples through token-level
confidence analysis of SFT failures and use similarity-based retrieval to
expand hard examples for balancing preference sample distributions, while
synthetic counterfactual rationales provide fine-grained clinical preferences,
eliminating the need for additional expert input. Experiments show that CheXPO
achieves 8.93% relative performance gain using only 5% of SFT samples, reaching
state-of-the-art performance across diverse clinical tasks and providing a
scalable, interpretable solution for real-world radiology applications.

</details>


### [121] [Segmentation Regularized Training for Multi-Domain Deep Learning Registration applied to MR-Guided Prostate Cancer Radiotherapy](https://arxiv.org/abs/2507.06966)
*Sudharsan Madhavan,Chengcheng Gui,Lando Bosma,Josiah Simeth,Jue Jiang,Nicolas Cote,Nima Hassan Rezaeian,Himanshu Nagar,Victoria Brennan,Neelam Tyagi,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: ProRSeg方法在跨域MR-MR配准中表现出色，尤其在膀胱配准上具有一致性，直肠和CTV性能依赖域。剂量累积初步可行。


<details>
  <summary>Details</summary>
Motivation: 提高MR引导自适应放疗中变形图像配准的准确性和跨域适用性。

Method: 使用加权分割一致性损失训练ProRSeg方法，测试其在同域、跨域和混合域数据集上的性能。

Result: 膀胱配准跨域性能一致（DSC 0.88-0.86），直肠和CTV性能依赖域。剂量累积中83.3%患者满足CTV覆盖和膀胱保护约束。

Conclusion: ProRSeg在多域MR-MR配准中表现合理，初步支持临床约束评估。

Abstract: Background: Accurate deformable image registration (DIR) is required for
contour propagation and dose accumulation in MR-guided adaptive radiotherapy
(MRgART). This study trained and evaluated a deep learning DIR method for
domain invariant MR-MR registration. Methods: A progressively refined
registration and segmentation (ProRSeg) method was trained with 262 pairs of 3T
MR simulation scans from prostate cancer patients using weighted segmentation
consistency loss. ProRSeg was tested on same- (58 pairs), cross- (72 1.5T MR
Linac pairs), and mixed-domain (42 MRSim-MRL pairs) datasets for contour
propagation accuracy of clinical target volume (CTV), bladder, and rectum. Dose
accumulation was performed for 42 patients undergoing 5-fraction MRgART.
Results: ProRSeg demonstrated generalization for bladder with similar Dice
Similarity Coefficients across domains (0.88, 0.87, 0.86). For rectum and CTV,
performance was domain-dependent with higher accuracy on cross-domain MRL
dataset (DSCs 0.89) versus same-domain data. The model's strong cross-domain
performance prompted us to study the feasibility of using it for dose
accumulation. Dose accumulation showed 83.3% of patients met CTV coverage (D95
>= 40.0 Gy) and bladder sparing (D50 <= 20.0 Gy) constraints. All patients
achieved minimum mean target dose (>40.4 Gy), but only 9.5% remained under
upper limit (<42.0 Gy). Conclusions: ProRSeg showed reasonable multi-domain
MR-MR registration performance for prostate cancer patients with preliminary
feasibility for evaluating treatment compliance to clinical constraints.

</details>


### [122] [A multi-modal dataset for insect biodiversity with imagery and DNA at the trap and individual level](https://arxiv.org/abs/2507.06972)
*Johanna Orsholm,John Quinto,Hannu Autto,Gaia Banelyte,Nicolas Chazot,Jeremy deWaard,Stephanie deWaard,Arielle Farrell,Brendan Furneaux,Bess Hardwick,Nao Ito,Amlan Kar,Oula Kalttopää,Deirdre Kerdraon,Erik Kristensen,Jaclyn McKeown,Tommi Mononen,Ellen Nein,Hanna Rogers,Tomas Roslin,Paula Schmitz,Jayme Sones,Maija Sujala,Amy Thompson,Evgeny V. Zakharov,Iuliia Zarubiieva,Akshita Gupta,Scott C. Lowe,Graham W. Taylor*

Main category: cs.CV

TL;DR: 论文介绍了MassID45数据集，用于训练自动分类器处理批量昆虫样本，结合分子和成像数据，推动生态和机器学习研究。


<details>
  <summary>Details</summary>
Motivation: 昆虫多样性研究面临种群下降和环境变化的挑战，需要高效方法加速分类。

Method: 结合DNA条形码和高分辨率成像，创建MassID45数据集，通过AI辅助工具标注批量样本中的个体和分类。

Result: 标注了超过17,000个标本，结合DNA条形码和图像数据，为大规模昆虫群落研究提供潜力。

Conclusion: MassID45数据集推动了小物体检测和实例分割的边界，促进生态和机器学习创新。

Abstract: Insects comprise millions of species, many experiencing severe population
declines under environmental and habitat changes. High-throughput approaches
are crucial for accelerating our understanding of insect diversity, with DNA
barcoding and high-resolution imaging showing strong potential for automatic
taxonomic classification. However, most image-based approaches rely on
individual specimen data, unlike the unsorted bulk samples collected in
large-scale ecological surveys. We present the Mixed Arthropod Sample
Segmentation and Identification (MassID45) dataset for training automatic
classifiers of bulk insect samples. It uniquely combines molecular and imaging
data at both the unsorted sample level and the full set of individual
specimens. Human annotators, supported by an AI-assisted tool, performed two
tasks on bulk images: creating segmentation masks around each individual
arthropod and assigning taxonomic labels to over 17 000 specimens. Combining
the taxonomic resolution of DNA barcodes with precise abundance estimates of
bulk images holds great potential for rapid, large-scale characterization of
insect communities. This dataset pushes the boundaries of tiny object detection
and instance segmentation, fostering innovation in both ecological and machine
learning research.

</details>


### [123] [Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM](https://arxiv.org/abs/2507.06973)
*Qiyuan Dai,Sibei Yang*

Main category: cs.CV

TL;DR: FreeTTA是一种无需训练、通用的测试时适应方法，通过在线EM算法利用VLM的零样本预测作为先验，显著提升跨域和分布外场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法依赖昂贵训练或不切实际的假设，限制了实际应用。

Method: 提出FreeTTA，通过在线EM算法建模测试数据分布，利用样本间关系增强预测。

Result: 在15个数据集上，FreeTTA在跨域和分布外场景中表现优于现有方法。

Conclusion: FreeTTA为测试时适应提供了灵活且高效的解决方案，无需训练或额外假设。

Abstract: Vision-Language Models (VLMs) have become prominent in open-world image
recognition for their strong generalization abilities. Yet, their effectiveness
in practical applications is compromised by domain shifts and distributional
changes, especially when test data distributions diverge from training data.
Therefore, the paradigm of test-time adaptation (TTA) has emerged, enabling the
use of online off-the-shelf data at test time, supporting independent sample
predictions, and eliminating reliance on test annotations. Traditional TTA
methods, however, often rely on costly training or optimization processes, or
make unrealistic assumptions about accessing or storing historical training and
test data. Instead, this study proposes FreeTTA, a training-free and
universally available method that makes no assumptions, to enhance the
flexibility of TTA. More importantly, FreeTTA is the first to explicitly model
the test data distribution, enabling the use of intrinsic relationships among
test samples to enhance predictions of individual samples without simultaneous
access--a direction not previously explored. FreeTTA achieves these advantages
by introducing an online EM algorithm that utilizes zero-shot predictions from
VLMs as priors to iteratively compute the posterior probabilities of each
online test sample and update parameters. Experiments demonstrate that FreeTTA
achieves stable and significant improvements compared to state-of-the-art
methods across 15 datasets in both cross-domain and out-of-distribution
settings.

</details>


### [124] [DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising](https://arxiv.org/abs/2507.06976)
*Sven Teufel,Dominique Mayer,Jörg Gamerdinger,Oliver Bringmann*

Main category: cs.CV

TL;DR: 论文提出了一种名为DenoiseCP-Net的新型多任务架构，用于恶劣天气下的LiDAR集体感知，通过去噪和对象检测的结合，降低了带宽需求和延迟。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的感知系统在恶劣天气和遮挡环境下容易退化，集体感知虽能缓解这一问题，但相关研究较少。

Method: 提出DenoiseCP-Net，将体素级去噪和对象检测集成到稀疏卷积骨干网络中，避免冗余计算。

Result: 在模拟的雨雪雾天气中，DenoiseCP-Net实现了近乎完美的去噪效果，带宽需求降低23.6%，同时保持检测精度。

Conclusion: DenoiseCP-Net有效提升了恶劣天气下的集体感知性能，降低了通信和计算开销。

Abstract: While automated vehicles hold the potential to significantly reduce traffic
accidents, their perception systems remain vulnerable to sensor degradation
caused by adverse weather and environmental occlusions. Collective perception,
which enables vehicles to share information, offers a promising approach to
overcoming these limitations. However, to this date collective perception in
adverse weather is mostly unstudied. Therefore, we conduct the first study of
LiDAR-based collective perception under diverse weather conditions and present
a novel multi-task architecture for LiDAR-based collective perception under
adverse weather. Adverse weather conditions can not only degrade perception
capabilities, but also negatively affect bandwidth requirements and latency due
to the introduced noise that is also transmitted and processed. Denoising prior
to communication can effectively mitigate these issues. Therefore, we propose
DenoiseCP-Net, a novel multi-task architecture for LiDAR-based collective
perception under adverse weather conditions. DenoiseCP-Net integrates
voxel-level noise filtering and object detection into a unified sparse
convolution backbone, eliminating redundant computations associated with
two-stage pipelines. This design not only reduces inference latency and
computational cost but also minimizes communication overhead by removing
non-informative noise. We extended the well-known OPV2V dataset by simulating
rain, snow, and fog using our realistic weather simulation models. We
demonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy in
adverse weather, reduces the bandwidth requirements by up to 23.6% while
maintaining the same detection accuracy and reducing the inference latency for
cooperative vehicles.

</details>


### [125] [MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation](https://arxiv.org/abs/2507.06992)
*Qilong Xing,Zikai Song,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

Main category: cs.CV

TL;DR: 论文提出了一种名为MCA-RG的知识驱动框架，通过将视觉特征与医学概念对齐，提升放射学报告生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在放射学报告生成（RRG）中面临病理和解剖特征与文本描述映射不准确的挑战，导致临床采用困难。

Method: MCA-RG利用病理库和解剖库，通过视觉特征与医学概念对齐，并结合对比学习和匹配损失优化特征提取。

Result: 在MIMIC-CXR和CheXpert Plus两个公开基准测试中，MCA-RG表现出色。

Conclusion: MCA-RG通过知识驱动的方法显著提升了放射学报告生成的准确性和临床实用性。

Abstract: Despite significant advancements in adapting Large Language Models (LLMs) for
radiology report generation (RRG), clinical adoption remains challenging due to
difficulties in accurately mapping pathological and anatomical features to
their corresponding text descriptions. Additionally, semantic agnostic feature
extraction further hampers the generation of accurate diagnostic reports. To
address these challenges, we introduce Medical Concept Aligned Radiology Report
Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual
features with distinct medical concepts to enhance the report generation
process. MCA-RG utilizes two curated concept banks: a pathology bank containing
lesion-related knowledge, and an anatomy bank with anatomical descriptions. The
visual features are aligned with these medical concepts and undergo tailored
enhancement. We further propose an anatomy-based contrastive learning procedure
to improve the generalization of anatomical features, coupled with a matching
loss for pathological features to prioritize clinically relevant regions.
Additionally, a feature gating mechanism is employed to filter out low-quality
concept features. Finally, the visual features are corresponding to individual
medical concepts, and are leveraged to guide the report generation process.
Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate
that MCA-RG achieves superior performance, highlighting its effectiveness in
radiology report generation.

</details>


### [126] [Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients](https://arxiv.org/abs/2507.06994)
*Qilong Xing,Zikai Song,Bingxin Gong,Lian Yang,Junqing Yu,Wei Yang*

Main category: cs.CV

TL;DR: 提出了一种多模态特征融合框架和大型数据集，用于提高非小细胞肺癌（NSCLC）免疫治疗患者的生存预测准确性。


<details>
  <summary>Details</summary>
Motivation: 个性化治疗规划和改善患者生活质量需要准确的预后预测，但缺乏大型数据集和有效的多模态特征融合方法。

Method: 结合3D CT图像和临床数据，提出跨模态掩码学习方法，包括Slice-Depth Transformer和基于图的Transformer。

Result: 在多模态整合中表现优异，超越现有方法，为预后模型设定了新标准。

Conclusion: 该方法显著提升了NSCLC生存预测的准确性，为个性化治疗提供了有力工具。

Abstract: Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing
immunotherapy is essential for personalized treatment planning, enabling
informed patient decisions, and improving both treatment outcomes and quality
of life. However, the lack of large, relevant datasets and effective
multi-modal feature fusion strategies pose significant challenges in this
domain. To address these challenges, we present a large-scale dataset and
introduce a novel framework for multi-modal feature fusion aimed at enhancing
the accuracy of survival prediction. The dataset comprises 3D CT images and
corresponding clinical records from NSCLC patients treated with immune
checkpoint inhibitors (ICI), along with progression-free survival (PFS) and
overall survival (OS) data. We further propose a cross-modality masked learning
approach for medical feature fusion, consisting of two distinct branches, each
tailored to its respective modality: a Slice-Depth Transformer for extracting
3D features from CT images and a graph-based Transformer for learning node
features and relationships among clinical variables in tabular data. The fusion
process is guided by a masked modality learning strategy, wherein the model
utilizes the intact modality to reconstruct missing components. This mechanism
improves the integration of modality-specific features, fostering more
effective inter-modality relationships and feature interactions. Our approach
demonstrates superior performance in multi-modal integration for NSCLC survival
prediction, surpassing existing methods and setting a new benchmark for
prognostic models in this context.

</details>


### [127] [GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning](https://arxiv.org/abs/2507.07006)
*S M Taslim Uddin Raju,Md. Milon Islam,Md Rezwanul Haque,Hamdi Altaheri,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出了一种名为GNN-ViTCap的新框架，用于病理显微图像的分类和描述生成，解决了冗余补丁和未知位置问题，并在分类和描述任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 病理显微图像评估对癌症诊断至关重要，但现有方法面临冗余补丁和未知位置等挑战，自动生成病理描述仍具难度。

Method: 使用视觉特征提取器生成补丁嵌入，通过深度嵌入聚类和注意力机制去除冗余补丁，构建图神经网络捕捉局部和全局上下文，结合语言模型生成描述。

Result: 在BreakHis和PatchGastric数据集上，分类F1分数为0.934，AUC为0.963；描述BLEU-4为0.811，METEOR为0.569，优于现有方法。

Conclusion: GNN-ViTCap为基于显微图像的诊断提供了高效可靠的解决方案，显著提升了分类和描述性能。

Abstract: Microscopic assessment of histopathology images is vital for accurate cancer
diagnosis and treatment. Whole Slide Image (WSI) classification and captioning
have become crucial tasks in computer-aided pathology. However, microscopic WSI
face challenges such as redundant patches and unknown patch positions due to
subjective pathologist captures. Moreover, generating automatic pathology
captions remains a significant challenge. To address these issues, we introduce
a novel GNN-ViTCap framework for classification and caption generation from
histopathological microscopic images. First, a visual feature extractor
generates patch embeddings. Redundant patches are then removed by dynamically
clustering these embeddings using deep embedded clustering and selecting
representative patches via a scalar dot attention mechanism. We build a graph
by connecting each node to its nearest neighbors in the similarity matrix and
apply a graph neural network to capture both local and global context. The
aggregated image embeddings are projected into the language model's input space
through a linear layer and combined with caption tokens to fine-tune a large
language model. We validate our method on the BreakHis and PatchGastric
datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for
classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569
for captioning. Experimental results demonstrate that GNN-ViTCap outperforms
state of the art approaches, offering a reliable and efficient solution for
microscopy based patient diagnosis.

</details>


### [128] [Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images](https://arxiv.org/abs/2507.07013)
*Yutong Sun,Sichen Zhu,Peng Qiu*

Main category: cs.CV

TL;DR: 提出一种轻量级方法，利用预训练的病理基础模型特征预测H&E染色组织学图像的细胞组成，避免高成本的空间转录组学。


<details>
  <summary>Details</summary>
Motivation: 数字病理学和深度学习的快速发展为病理基础模型提供了可能，同时空间转录组学技术为组织学图像提供了更精细的基因表达信息。本研究旨在利用病理基础模型的特征预测细胞组成，降低成本。

Method: 通过预训练的病理基础模型提取特征，训练轻量级多层感知机（MLP）回归器预测细胞类型丰度。

Result: 方法在预测细胞组成方面表现优异，计算复杂度显著低于现有方法如Hist2Cell。

Conclusion: 该方法高效且准确，为利用病理基础模型预测细胞组成提供了新思路。

Abstract: The rapid development of digital pathology and modern deep learning has
facilitated the emergence of pathology foundation models that are expected to
solve general pathology problems under various disease conditions in one
unified model, with or without fine-tuning. In parallel, spatial
transcriptomics has emerged as a transformative technology that enables the
profiling of gene expression on hematoxylin and eosin (H&E) stained histology
images. Spatial transcriptomics unlocks the unprecedented opportunity to dive
into existing histology images at a more granular, cellular level. In this
work, we propose a lightweight and training-efficient approach to predict
cellular composition directly from H&E-stained histology images by leveraging
information-enriched feature embeddings extracted from pre-trained pathology
foundation models. By training a lightweight multi-layer perceptron (MLP)
regressor on cell-type abundances derived via cell2location, our method
efficiently distills knowledge from pathology foundation models and
demonstrates the ability to accurately predict cell-type compositions from
histology images, without physically performing the costly spatial
transcriptomics. Our method demonstrates competitive performance compared to
existing methods such as Hist2Cell, while significantly reducing computational
complexity.

</details>


### [129] [Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices](https://arxiv.org/abs/2507.07029)
*Parshva Dhilankumar Patel*

Main category: cs.CV

TL;DR: 论文提出了一种基于OCR的表格提取流程，用于从发票中高效提取结构化数据。


<details>
  <summary>Details</summary>
Motivation: 解决发票扫描文档中非标准格式和噪声导致的表格数据提取不准确问题。

Method: 结合Tesseract OCR和自定义后处理逻辑，包括动态预处理、表格边界检测和行列映射。

Result: 显著提高了数据提取的准确性和一致性。

Conclusion: 该流程适用于自动化财务工作流和数字存档等实际应用。

Abstract: This paper presents the design and development of an OCR-powered pipeline for
efficient table extraction from invoices. The system leverages Tesseract OCR
for text recognition and custom post-processing logic to detect, align, and
extract structured tabular data from scanned invoice documents. Our approach
includes dynamic preprocessing, table boundary detection, and row-column
mapping, optimized for noisy and non-standard invoice formats. The resulting
pipeline significantly improves data extraction accuracy and consistency,
supporting real-world use cases such as automated financial workflows and
digital archiving.

</details>


### [130] [Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata](https://arxiv.org/abs/2507.07048)
*Bruce Coburn,Jiangpeng He,Megan E. Rollo,Satvinder S. Dhaliwal,Deborah A. Kerr,Fengqing Zhu*

Main category: cs.CV

TL;DR: 研究探讨了如何通过整合上下文元数据（如GPS、时间戳和食物信息）提升大型多模态模型（LMMs）在营养分析中的性能，并引入新数据集ACETADA。实验表明，元数据整合能显著降低预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要评估专有模型（如GPT-4），忽略了其他LMMs的潜力，且上下文元数据及其与推理修饰符的交互影响尚未充分探索。

Method: 通过整合GPS、时间戳和食物信息等元数据，结合多种推理修饰符（如Chain-of-Thought），评估八种LMMs的性能。

Result: 元数据整合显著降低了营养值预测的MAE和MAPE，提升了模型性能。

Conclusion: 上下文感知的LMMs在营养分析中具有显著潜力，未来可进一步探索其应用。

Abstract: Large Multimodal Models (LMMs) are increasingly applied to meal images for
nutrition analysis. However, existing work primarily evaluates proprietary
models, such as GPT-4. This leaves the broad range of LLMs underexplored.
Additionally, the influence of integrating contextual metadata and its
interaction with various reasoning modifiers remains largely uncharted. This
work investigates how interpreting contextual metadata derived from GPS
coordinates (converted to location/venue type), timestamps (transformed into
meal/day type), and the food items present can enhance LMM performance in
estimating key nutritional values. These values include calories,
macronutrients (protein, carbohydrates, fat), and portion sizes. We also
introduce ACETADA, a new food-image dataset slated for public release. This
open dataset provides nutrition information verified by the dietitian and
serves as the foundation for our analysis. Our evaluation across eight LMMs
(four open-weight and four closed-weight) first establishes the benefit of
contextual metadata integration over straightforward prompting with images
alone. We then demonstrate how this incorporation of contextual information
enhances the efficacy of reasoning modifiers, such as Chain-of-Thought,
Multimodal Chain-of-Thought, Scale Hint, Few-Shot, and Expert Persona.
Empirical results show that integrating metadata intelligently, when applied
through straightforward prompting strategies, can significantly reduce the Mean
Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) in predicted
nutritional values. This work highlights the potential of context-aware LMMs
for improved nutrition analysis.

</details>


### [131] [An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator](https://arxiv.org/abs/2507.07073)
*Yulin An,Enrique del Castillo*

Main category: cs.CV

TL;DR: 提出了一种基于几何深度学习的框架，用于高效预测CAD网格的Laplace-Beltrami谱，显著节省计算时间且保持准确性。


<details>
  <summary>Details</summary>
Motivation: 传统有限元方法（FEM）计算Laplace-Beltrami谱复杂度高，不适用于需要快速频繁处理大型网格的CAD机械部件数据库或质量控制应用。

Method: 使用图神经网络架构，结合高斯曲率、平均曲率等丰富网格特征，预测Laplace-Beltrami谱。

Result: 实验表明，该方法比线性FEM快约5倍，同时保持竞争性准确性。

Conclusion: Laplace-Beltrami谱是可学习的，几何深度学习框架为高效计算提供了可行解决方案。

Abstract: The spectrum of the Laplace-Beltrami (LB) operator is central in geometric
deep learning tasks, capturing intrinsic properties of the shape of the object
under consideration. The best established method for its estimation, from a
triangulated mesh of the object, is based on the Finite Element Method (FEM),
and computes the top k LB eigenvalues with a complexity of O(Nk), where N is
the number of points. This can render the FEM method inefficient when
repeatedly applied to databases of CAD mechanical parts, or in quality control
applications where part metrology is acquired as large meshes and decisions
about the quality of each part are needed quickly and frequently. As a solution
to this problem, we present a geometric deep learning framework to predict the
LB spectrum efficiently given the CAD mesh of a part, achieving significant
computational savings without sacrificing accuracy, demonstrating that the LB
spectrum is learnable. The proposed Graph Neural Network architecture uses a
rich set of part mesh features - including Gaussian curvature, mean curvature,
and principal curvatures. In addition to our trained network, we make
available, for repeatability, a large curated dataset of real-world mechanical
CAD models derived from the publicly available ABC dataset used for training
and testing. Experimental results show that our method reduces computation time
of the LB spectrum by approximately 5 times over linear FEM while delivering
competitive accuracy.

</details>


### [132] [Reading a Ruler in the Wild](https://arxiv.org/abs/2507.07077)
*Yimu Pan,Manas Mehta,Gwen Sincerbeaux,Jeffery A. Goldstein,Alison D. Gernand,James Z. Wang*

Main category: cs.CV

TL;DR: RulerNet是一个深度学习框架，通过将尺子读数统一为关键点检测问题，并结合几何级数参数表示尺子，实现了在复杂环境下准确测量像素到实际尺寸的转换。


<details>
  <summary>Details</summary>
Motivation: 将像素测量转换为实际尺寸是计算机视觉中的基础挑战，限制了生物医学、法医学、营养分析和电子商务等关键应用的进展。

Method: RulerNet通过关键点检测和几何级数参数表示尺子，结合合成数据增强训练，并使用DeepGP网络实现实时估计。

Result: 实验表明，RulerNet在复杂条件下提供了准确、一致且高效的尺寸估计。

Conclusion: RulerNet作为一种通用测量工具，具有广泛的应用潜力，并可与其他视觉组件集成。

Abstract: Accurately converting pixel measurements into absolute real-world dimensions
remains a fundamental challenge in computer vision and limits progress in key
applications such as biomedicine, forensics, nutritional analysis, and
e-commerce. We introduce RulerNet, a deep learning framework that robustly
infers scale "in the wild" by reformulating ruler reading as a unified
keypoint-detection problem and by representing the ruler with
geometric-progression parameters that are invariant to perspective
transformations. Unlike traditional methods that rely on handcrafted thresholds
or rigid, ruler-specific pipelines, RulerNet directly localizes centimeter
marks using a distortion-invariant annotation and training strategy, enabling
strong generalization across diverse ruler types and imaging conditions while
mitigating data scarcity. We also present a scalable synthetic-data pipeline
that combines graphics-based ruler generation with ControlNet to add
photorealistic context, greatly increasing training diversity and improving
performance. To further enhance robustness and efficiency, we propose DeepGP, a
lightweight feed-forward network that regresses geometric-progression
parameters from noisy marks and eliminates iterative optimization, enabling
real-time scale estimation on mobile or edge devices. Experiments show that
RulerNet delivers accurate, consistent, and efficient scale estimates under
challenging real-world conditions. These results underscore its utility as a
generalizable measurement tool and its potential for integration with other
vision components for automated, scale-aware analysis in high-impact domains. A
live demo is available at https://huggingface.co/spaces/ymp5078/RulerNet-Demo.

</details>


### [133] [Evaluating Attribute Confusion in Fashion Text-to-Image Generation](https://arxiv.org/abs/2507.07079)
*Ziyue Liu,Federico Girella,Yiming Wang,Davide Talon*

Main category: cs.CV

TL;DR: 论文提出了一种新的自动评估指标L-VQAScore，用于解决文本到图像生成模型中实体-属性关联的评估问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型的评估方法在复杂组合生成领域（如时尚）表现不足，尤其是在实体-属性语义的评估上存在局限性。

Method: 基于视觉问答（VQA）定位策略，提出局部化评估协议和L-VQAScore指标，结合视觉定位和VQA探测正确与错误属性生成。

Result: 在新数据集上，L-VQAScore在与人评估的相关性上优于现有方法，能捕捉细粒度实体-属性关联。

Conclusion: L-VQAScore可作为主观评估的可靠且可扩展的替代方案。

Abstract: Despite the rapid advances in Text-to-Image (T2I) generation models, their
evaluation remains challenging in domains like fashion, involving complex
compositional generation. Recent automated T2I evaluation methods leverage
pre-trained vision-language models to measure cross-modal alignment. However,
our preliminary study reveals that they are still limited in assessing rich
entity-attribute semantics, facing challenges in attribute confusion, i.e.,
when attributes are correctly depicted but associated to the wrong entities. To
address this, we build on a Visual Question Answering (VQA) localization
strategy targeting one single entity at a time across both visual and textual
modalities. We propose a localized human evaluation protocol and introduce a
novel automatic metric, Localized VQAScore (L-VQAScore), that combines visual
localization with VQA probing both correct (reflection) and miss-localized
(leakage) attribute generation. On a newly curated dataset featuring
challenging compositional alignment scenarios, L-VQAScore outperforms
state-of-the-art T2I evaluation methods in terms of correlation with human
judgments, demonstrating its strength in capturing fine-grained
entity-attribute associations. We believe L-VQAScore can be a reliable and
scalable alternative to subjective evaluations.

</details>


### [134] [Go to Zero: Towards Zero-shot Motion Generation with Million-scale Data](https://arxiv.org/abs/2507.07095)
*Ke Fan,Shunlin Lu,Minyue Dai,Runyi Yu,Lixing Xiao,Zhiyang Dou,Junting Dong,Lizhuang Ma,Jingbo Wang*

Main category: cs.CV

TL;DR: 论文提出MotionMillion数据集和MotionMillion-Eval基准，用于提升零样本文本到动作生成的能力，并验证了7B参数模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到动作生成方法在零样本泛化能力上受限，主要由于训练数据规模不足且缺乏全面评估框架。

Method: 开发高效标注流程，构建MotionMillion数据集（200万高质量动作序列），提出MotionMillion-Eval基准，并训练7B参数模型。

Result: 模型在零样本和复杂组合动作生成上表现出强泛化能力。

Conclusion: 该工作为零样本人类动作生成迈出重要一步，代码已开源。

Abstract: Generating diverse and natural human motion sequences based on textual
descriptions constitutes a fundamental and challenging research area within the
domains of computer vision, graphics, and robotics. Despite significant
advancements in this field, current methodologies often face challenges
regarding zero-shot generalization capabilities, largely attributable to the
limited size of training datasets. Moreover, the lack of a comprehensive
evaluation framework impedes the advancement of this task by failing to
identify directions for improvement. In this work, we aim to push
text-to-motion into a new era, that is, to achieve the generalization ability
of zero-shot. To this end, firstly, we develop an efficient annotation pipeline
and introduce MotionMillion-the largest human motion dataset to date, featuring
over 2,000 hours and 2 million high-quality motion sequences. Additionally, we
propose MotionMillion-Eval, the most comprehensive benchmark for evaluating
zero-shot motion generation. Leveraging a scalable architecture, we scale our
model to 7B parameters and validate its performance on MotionMillion-Eval. Our
results demonstrate strong generalization to out-of-domain and complex
compositional motions, marking a significant step toward zero-shot human motion
generation. The code is available at
https://github.com/VankouF/MotionMillion-Codes.

</details>


### [135] [Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models](https://arxiv.org/abs/2507.07104)
*Tiezheng Zhang,Yitong Li,Yu-cheng Chou,Jieneng Chen,Alan Yuille,Chen Wei,Junfei Xiao*

Main category: cs.CV

TL;DR: 提出了一种名为VLV的自动编码器框架，通过利用预训练组件（视觉编码器、T2I扩散模型解码器和LLM）构建高效且低成本的视觉语言模型，显著减少数据需求和训练成本。


<details>
  <summary>Details</summary>
Motivation: 传统视觉语言模型需要大量高质量图像-文本对和昂贵的GPU资源，VLV框架旨在通过利用现有预训练模型降低这些需求。

Method: 采用信息瓶颈技术，通过冻结预训练的T2I扩散解码器规范化语言表示空间，并利用连续嵌入从扩散模型中提取知识。随后微调LLM生成详细描述。

Result: 构建了一个与GPT-4o和Gemini 2.0 Flash相当的先进字幕生成器，训练成本低于1000美元。

Conclusion: VLV框架通过高效利用预训练模型，显著降低了视觉语言模型的训练成本和数据需求，同时保持了高性能。

Abstract: Building state-of-the-art Vision-Language Models (VLMs) with strong
captioning capabilities typically necessitates training on billions of
high-quality image-text pairs, requiring millions of GPU hours. This paper
introduces the Vision-Language-Vision (VLV) auto-encoder framework, which
strategically leverages key pretrained components: a vision encoder, the
decoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large
Language Model (LLM). Specifically, we establish an information bottleneck by
regularizing the language representation space, achieved through freezing the
pretrained T2I diffusion decoder. Our VLV pipeline effectively distills
knowledge from the text-conditioned diffusion model using continuous
embeddings, demonstrating comprehensive semantic understanding via high-quality
reconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the
intermediate language representations into detailed descriptions, we construct
a state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o
and Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and
significantly reduces data requirements; by primarily utilizing single-modal
images for training and maximizing the utility of existing pretrained models
(image encoder, T2I diffusion model, and LLM), it circumvents the need for
massive paired image-text datasets, keeping the total training expenditure
under $1,000 USD.

</details>


### [136] [4KAgent: Agentic Any Image to 4K Super-Resolution](https://arxiv.org/abs/2507.07105)
*Yushen Zuo,Qi Zheng,Mingyang Wu,Xinrui Jiang,Renjie Li,Jian Wang,Yide Zhang,Gengchen Mai,Lihong V. Wang,James Zou,Xiaoyu Wang,Ming-Hsuan Yang,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 4KAgent是一个统一的超分辨率通用系统，能够将任何图像提升至4K分辨率。它通过三个核心组件（Profiling、Perception Agent和Restoration Agent）实现高质量图像恢复，并在多个领域取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决低分辨率图像恢复问题，尤其是针对严重退化的输入，提供一种通用的、高质量的解决方案。

Method: 系统包含三个模块：Profiling定制流程，Perception Agent分析输入并制定恢复计划，Restoration Agent执行计划并优化输出。

Result: 在11个任务类别和26个基准测试中表现优异，涵盖自然图像、肖像照片、AI生成内容等多种领域。

Conclusion: 4KAgent为低层次视觉任务建立了新的代理范式，推动了视觉自主代理的创新。

Abstract: We present 4KAgent, a unified agentic super-resolution generalist system
designed to universally upscale any image to 4K resolution (and even higher, if
applied iteratively). Our system can transform images from extremely low
resolutions with severe degradations, for example, highly distorted inputs at
256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three
core components: (1) Profiling, a module that customizes the 4KAgent pipeline
based on bespoke use cases; (2) A Perception Agent, which leverages
vision-language models alongside image quality assessment experts to analyze
the input image and make a tailored restoration plan; and (3) A Restoration
Agent, which executes the plan, following a recursive execution-reflection
paradigm, guided by a quality-driven mixture-of-expert policy to select the
optimal output for each step. Additionally, 4KAgent embeds a specialized face
restoration pipeline, significantly enhancing facial details in portrait and
selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task
categories encompassing a total of 26 diverse benchmarks, setting new
state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover
natural images, portrait photos, AI-generated content, satellite imagery,
fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and
X-ray, demonstrating superior performance in terms of both perceptual (e.g.,
NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic
paradigm for low-level vision tasks, we aim to catalyze broader interest and
innovation within vision-centric autonomous agents across diverse research
communities. We will release all the code, models, and results at:
https://4kagent.github.io.

</details>


### [137] [Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor](https://arxiv.org/abs/2507.07106)
*Vatsal Agarwal,Matthew Gwilliam,Gefen Kohavi,Eshan Verma,Daniel Ulbricht,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 该论文探讨了使用预训练的文本到图像扩散模型作为视觉编码器的潜力，以弥补CLIP在捕捉细粒度细节上的不足，并提出了一种融合策略来提升视觉问答性能。


<details>
  <summary>Details</summary>
Motivation: CLIP作为视觉编码器在捕捉全局信息时可能忽略细粒度细节，限制了多模态大语言模型（MLLMs）在视觉问答中的表现。

Method: 通过分析扩散模型的内部表示，发现其语义丰富且能编码强图像-文本对齐。提出利用文本条件聚焦模型于问题相关区域，并探索与LLM对齐的策略。

Result: 在通用VQA和专用MLLM基准测试中，融合CLIP和条件扩散特征的方法表现出色，尤其在需要空间和组合推理的任务中。

Conclusion: 扩散模型在视觉理解中具有潜力，特别是在需要细粒度分析的视觉中心任务中。

Abstract: Recent advances in multimodal large language models (MLLMs) have enabled
image-based question-answering capabilities. However, a key limitation is the
use of CLIP as the visual encoder; while it can capture coarse global
information, it often can miss fine-grained details that are relevant to the
input query. To address these shortcomings, this work studies whether
pre-trained text-to-image diffusion models can serve as instruction-aware
visual encoders. Through an analysis of their internal representations, we find
diffusion features are both rich in semantics and can encode strong image-text
alignment. Moreover, we find that we can leverage text conditioning to focus
the model on regions relevant to the input question. We then investigate how to
align these features with large language models and uncover a leakage
phenomenon, where the LLM can inadvertently recover information from the
original diffusion prompt. We analyze the causes of this leakage and propose a
mitigation strategy. Based on these insights, we explore a simple fusion
strategy that utilizes both CLIP and conditional diffusion features. We
evaluate our approach on both general VQA and specialized MLLM benchmarks,
demonstrating the promise of diffusion models for visual understanding,
particularly in vision-centric tasks that require spatial and compositional
reasoning. Our project page can be found
https://vatsalag99.github.io/mustafar/.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [138] [Neural Network-Based Parameter Estimation for Non-Autonomous Differential Equations with Discontinuous Signals](https://arxiv.org/abs/2507.06267)
*Hyeontae Jo,Krešimir Josić,Jae Kyoung Kim*

Main category: cs.LG

TL;DR: 提出了一种名为HADES-NN的新方法，通过神经网络平滑近似不连续信号，用于非自治微分方程的参数估计。


<details>
  <summary>Details</summary>
Motivation: 非自治微分方程在建模受外部信号影响的系统时非常重要，但当信号突变时，模型拟合变得困难。

Method: HADES-NN分两阶段：先用神经网络平滑近似不连续信号，再用近似信号估计模型参数。

Result: HADES-NN在多种应用中提供了高精度参数估计，如昼夜节律系统和酵母交配响应。

Conclusion: HADES-NN显著扩展了可拟合实际测量数据的模型范围。

Abstract: Non-autonomous differential equations are crucial for modeling systems
influenced by external signals, yet fitting these models to data becomes
particularly challenging when the signals change abruptly. To address this
problem, we propose a novel parameter estimation method utilizing functional
approximations with artificial neural networks. Our approach, termed Harmonic
Approximation of Discontinuous External Signals using Neural Networks
(HADES-NN), operates in two iterated stages. In the first stage, the algorithm
employs a neural network to approximate the discontinuous signal with a smooth
function. In the second stage, it uses this smooth approximate signal to
estimate model parameters. HADES-NN gives highly accurate and precise parameter
estimates across various applications, including circadian clock systems
regulated by external light inputs measured via wearable devices and the mating
response of yeast to external pheromone signals. HADES-NN greatly extends the
range of model systems that can be fit to real-world measurements.

</details>


### [139] [Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease](https://arxiv.org/abs/2507.06326)
*Harsh Ravivarapu,Gaurav Bagwe,Xiaoyong Yuan,Chunxiu Yu,Lan Zhang*

Main category: cs.LG

TL;DR: SEA-DBS是一种基于强化学习的自适应深脑刺激框架，通过改进样本效率和探索稳定性，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 传统开环深脑刺激（DBS）缺乏适应性和个性化，而现有强化学习方法存在样本复杂度高、探索不稳定等问题。

Method: SEA-DBS结合预测奖励模型和Gumbel Softmax探索，优化样本效率和策略更新。

Result: 在帕金森病模拟中，SEA-DBS表现出更快的收敛速度、更强的病理β波段抑制能力，并兼容资源受限硬件。

Conclusion: SEA-DBS为实时、资源受限的神经调控提供了一种实用且有效的强化学习框架。

Abstract: Deep brain stimulation (DBS) is an established intervention for Parkinson's
disease (PD), but conventional open-loop systems lack adaptability, are
energy-inefficient due to continuous stimulation, and provide limited
personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a
closed-loop alternative, using biomarkers such as beta-band oscillations to
dynamically modulate stimulation. While reinforcement learning (RL) holds
promise for personalized aDBS control, existing methods suffer from high sample
complexity, unstable exploration in binary action spaces, and limited
deployability on resource-constrained hardware.
  We propose SEA-DBS, a sample-efficient actor-critic framework that addresses
the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a
predictive reward model to reduce reliance on real-time feedback and employs
Gumbel Softmax-based exploration for stable, differentiable policy updates in
binary action spaces. Together, these components improve sample efficiency,
exploration robustness, and compatibility with resource-constrained
neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic
simulation of Parkinsonian basal ganglia activity, demonstrating faster
convergence, stronger suppression of pathological beta-band power, and
resilience to post-training FP16 quantization. Our results show that SEA-DBS
offers a practical and effective RL-based aDBS framework for real-time,
resource-constrained neuromodulation.

</details>


### [140] [SymFlux: deep symbolic regression of Hamiltonian vector fields](https://arxiv.org/abs/2507.06342)
*M. A. Evangelista-Alvarado,P. Suárez-Serrato*

Main category: cs.LG

TL;DR: SymFlux是一个新颖的深度学习框架，用于通过符号回归从标准辛平面上的向量场中识别哈密顿函数。


<details>
  <summary>Details</summary>
Motivation: 自动化哈密顿力学中的符号表达式发现。

Method: 采用混合CNN-LSTM架构，训练和验证基于新开发的哈密顿向量场数据集。

Result: 模型能准确恢复符号表达式。

Conclusion: SymFlux在哈密顿力学自动化发现方面取得了进展。

Abstract: We present SymFlux, a novel deep learning framework that performs symbolic
regression to identify Hamiltonian functions from their corresponding vector
fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM
architectures to learn and output the symbolic mathematical expression of the
underlying Hamiltonian. Training and validation are conducted on newly
developed datasets of Hamiltonian vector fields, a key contribution of this
work. Our results demonstrate the model's effectiveness in accurately
recovering these symbolic expressions, advancing automated discovery in
Hamiltonian mechanics.

</details>


### [141] [DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction](https://arxiv.org/abs/2507.06366)
*Yupu Zhang,Zelin Xu,Tingsong Xiao,Gustavo Seabra,Yanjun Li,Chenglong Li,Zhe Jiang*

Main category: cs.LG

TL;DR: 论文提出DecoyDB数据集和定制化GCL框架，用于蛋白质-配体复合物的自监督学习，显著提升了结合亲和力预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 药物发现中蛋白质-配体结合亲和力预测缺乏大规模高质量标记数据，现有数据集如PDBbind规模有限。

Method: 构建DecoyDB数据集（包含高质量复合物和多样化的负样本），并设计定制化GCL框架进行预训练和微调。

Result: 实验表明，基于DecoyDB预训练的模型在准确性、标签效率和泛化性上表现优越。

Conclusion: DecoyDB和定制化GCL框架为蛋白质-配体结合亲和力预测提供了有效解决方案。

Abstract: Predicting the binding affinity of protein-ligand complexes plays a vital
role in drug discovery. Unfortunately, progress has been hindered by the lack
of large-scale and high-quality binding affinity labels. The widely used
PDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,
especially graph contrastive learning (GCL), provides a unique opportunity to
break the barrier by pre-training graph neural network models based on vast
unlabeled complexes and fine-tuning the models on much fewer labeled complexes.
However, the problem faces unique challenges, including a lack of a
comprehensive unlabeled dataset with well-defined positive/negative complex
pairs and the need to design GCL algorithms that incorporate the unique
characteristics of such data. To fill the gap, we propose DecoyDB, a
large-scale, structure-aware dataset specifically designed for self-supervised
GCL on protein-ligand complexes. DecoyDB consists of high-resolution ground
truth complexes (less than 2.5 Angstrom) and diverse decoy structures with
computationally generated binding poses that range from realistic to suboptimal
(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation
(RMSD) from the native pose. We further design a customized GCL framework to
pre-train graph neural networks based on DecoyDB and fine-tune the models with
labels from PDBbind. Extensive experiments confirm that models pre-trained with
DecoyDB achieve superior accuracy, label efficiency, and generalizability.

</details>


### [142] [HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning](https://arxiv.org/abs/2507.06821)
*Chuhang Zheng,Chunwei Tian,Jie Wen,Daoqiang Zhang,Qi Zhu*

Main category: cs.LG

TL;DR: 提出了一种多模态情感分布学习框架HeLo，通过跨模态注意力融合生理数据，利用最优传输挖掘异质性，并通过可学习标签嵌入优化标签相关性，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别在HCI中日益重要，但现有方法在挖掘模态异质性和标签相关性方面存在不足。

Method: 采用跨注意力融合生理数据，设计最优传输模块挖掘异质性，引入可学习标签嵌入优化标签相关性。

Result: 在两个公开数据集上验证了方法的优越性。

Conclusion: HeLo框架在多模态情感分布学习中表现优异，有效解决了模态异质性和标签相关性问题。

Abstract: Multi-modal emotion recognition has garnered increasing attention as it plays
a significant role in human-computer interaction (HCI) in recent years. Since
different discrete emotions may exist at the same time, compared with
single-class emotion recognition, emotion distribution learning (EDL) that
identifies a mixture of basic emotions has gradually emerged as a trend.
However, existing EDL methods face challenges in mining the heterogeneity among
multiple modalities. Besides, rich semantic correlations across arbitrary basic
emotions are not fully exploited. In this paper, we propose a multi-modal
emotion distribution learning framework, named HeLo, aimed at fully exploring
the heterogeneity and complementary information in multi-modal emotional data
and label correlation within mixed basic emotions. Specifically, we first adopt
cross-attention to effectively fuse the physiological data. Then, an optimal
transport (OT)-based heterogeneity mining module is devised to mine the
interaction and heterogeneity between the physiological and behavioral
representations. To facilitate label correlation learning, we introduce a
learnable label embedding optimized by correlation matrix alignment. Finally,
the learnable label embeddings and label correlation matrices are integrated
with the multi-modal representations through a novel label correlation-driven
cross-attention mechanism for accurate emotion distribution learning.
Experimental results on two publicly available datasets demonstrate the
superiority of our proposed method in emotion distribution learning.

</details>


### [143] [The Riemannian Geometry associated to Gradient Flows of Linear Convolutional Networks](https://arxiv.org/abs/2507.06367)
*El Mehdi Achour,Kathlén Kohn,Holger Rauhut*

Main category: cs.LG

TL;DR: 研究了深度线性卷积网络梯度流的几何性质，发现其参数空间的梯度流可以表示为函数空间的黎曼梯度流，无需初始化平衡条件。


<details>
  <summary>Details</summary>
Motivation: 探讨线性卷积网络梯度流的几何特性，扩展了全连接网络的类似研究。

Method: 分析参数空间梯度流与函数空间黎曼梯度流的关系，适用于多维卷积和特定步长条件。

Result: 证明了无论初始化如何，线性卷积网络的梯度流均可表示为函数空间的黎曼梯度流。

Conclusion: 该结果为理解卷积网络的优化动态提供了新的几何视角。

Abstract: We study geometric properties of the gradient flow for learning deep linear
convolutional networks. For linear fully connected networks, it has been shown
recently that the corresponding gradient flow on parameter space can be written
as a Riemannian gradient flow on function space (i.e., on the product of weight
matrices) if the initialization satisfies a so-called balancedness condition.
We establish that the gradient flow on parameter space for learning linear
convolutional networks can be written as a Riemannian gradient flow on function
space regardless of the initialization. This result holds for $D$-dimensional
convolutions with $D \geq 2$, and for $D =1$ it holds if all so-called strides
of the convolutions are greater than one. The corresponding Riemannian metric
depends on the initialization.

</details>


### [144] [Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation](https://arxiv.org/abs/2507.06380)
*Habibur Rahaman,Atri Chatterjee,Swarup Bhunia*

Main category: cs.LG

TL;DR: WINGs框架通过动态生成全连接层权重和压缩卷积层权重，显著减少内存需求，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂神经网络存储大量突触权重的内存问题，适用于资源受限的边缘计算场景。

Method: 使用PCA降维和轻量级SVR模型预测权重，结合敏感性分析优先压缩低敏感性层。

Result: FC层压缩53倍，AlexNet在MNIST上压缩28倍，CIFAR-10上压缩18倍，精度损失1-2%。

Conclusion: WINGs显著降低内存需求，提高推理效率，适合边缘设备应用。

Abstract: Complex neural networks require substantial memory to store a large number of
synaptic weights. This work introduces WINGs (Automatic Weight Generator for
Secure and Storage-Efficient Deep Learning Models), a novel framework that
dynamically generates layer weights in a fully connected neural network (FC)
and compresses the weights in convolutional neural networks (CNNs) during
inference, significantly reducing memory requirements without sacrificing
accuracy. WINGs framework uses principal component analysis (PCA) for
dimensionality reduction and lightweight support vector regression (SVR) models
to predict layer weights in the FC networks, removing the need for storing
full-weight matrices and achieving substantial memory savings. It also
preferentially compresses the weights in low-sensitivity layers of CNNs using
PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers
an added level of security, as any bit-flip attack with weights in compressed
layers has an amplified and readily detectable effect on accuracy. WINGs
achieves 53x compression for the FC layers and 28x for AlexNet with MNIST
dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss.
This significant reduction in memory results in higher throughput and lower
energy for DNN inference, making it attractive for resource-constrained edge
applications.

</details>


### [145] [A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning](https://arxiv.org/abs/2507.06542)
*Tongtian Zhu,Tianyu Zhang,Mingze Wang,Zhanpeng Zhou,Can Wang*

Main category: cs.LG

TL;DR: 研究去中心化学习中通信调度的优化，发现后期集中通信预算能显著提升全局泛化性能，且最终一步的全局合并足以匹配服务器训练效果。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习性能受限于点对点通信，探索如何优化通信调度以提升训练效果。

Method: 通过实验和理论分析，研究通信时间与频率对去中心化训练的影响，提出后期集中通信策略。

Result: 后期集中通信显著提升泛化性能，最终一步全局合并可匹配服务器训练效果，低通信保持模型可合并性。

Conclusion: 挑战去中心化学习在数据异构和有限通信下泛化差的观念，提供模型合并和损失景观的新见解。

Abstract: Decentralized learning provides a scalable alternative to traditional
parameter-server-based training, yet its performance is often hindered by
limited peer-to-peer communication. In this paper, we study how communication
should be scheduled over time, including determining when and how frequently
devices synchronize. Our empirical results show that concentrating
communication budgets in the later stages of decentralized training markedly
improves global generalization. Surprisingly, we uncover that fully connected
communication at the final step, implemented by a single global merging, is
sufficient to match the performance of server-based training. We further show
that low communication in decentralized learning preserves the
\textit{mergeability} of local models throughout training. Our theoretical
contributions, which explains these phenomena, are first to establish that the
globally merged model of decentralized SGD can converge faster than centralized
mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy
among local models, which were previously considered as detrimental noise, as
constructive components that accelerate convergence. This work challenges the
common belief that decentralized learning generalizes poorly under data
heterogeneity and limited communication, while offering new insights into model
merging and neural network loss landscapes.

</details>


### [146] [KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks](https://arxiv.org/abs/2507.06381)
*James Hazelden,Laura Driscoll,Eli Shlizerman,Eric Shea-Brown*

Main category: cs.LG

TL;DR: 论文提出了一种梯度流分解方法，通过参数算子K和线性化流传播器P，揭示了梯度下降在非线性循环模型中塑造学习表示的机制。


<details>
  <summary>Details</summary>
Motivation: 理解梯度下降在循环动态系统（如RNNs、Neural ODEs和GRUs）中如何塑造学习表示，尤其是在有限非线性模型中。

Method: 将梯度流分解为参数算子K和线性化流传播器P的乘积，分析其相互作用。

Result: 揭示了低维潜在动态的成因，并展示了多任务训练中任务目标的对齐方式。

Conclusion: 该方法为理解非线性循环模型中的梯度下降学习提供了新的理论工具，并通过实验和理论验证了其有效性。

Abstract: Gradient Descent (GD) and its variants are the primary tool for enabling
efficient training of recurrent dynamical systems such as Recurrent Neural
Networks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics
that are formed in these models exhibit features such as neural collapse and
emergence of latent representations that may support the remarkable
generalization properties of networks. In neuroscience, qualitative features of
these representations are used to compare learning in biological and artificial
systems. Despite recent progress, there remains a need for theoretical tools to
rigorously understand the mechanisms shaping learned representations,
especially in finite, non-linear models. Here, we show that the gradient flow,
which describes how the model's dynamics evolve over GD, can be decomposed into
a product that involves two operators: a Parameter Operator, K, and a
Linearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in
feed-forward neural networks, while P appears in Lyapunov stability and optimal
control theory. We demonstrate two applications of our decomposition. First, we
show how their interplay gives rise to low-dimensional latent dynamics under
GD, and, specifically, how the collapse is a result of the network structure,
over and above the nature of the underlying task. Second, for multi-task
training, we show that the operators can be used to measure how objectives
relevant to individual sub-tasks align. We experimentally and theoretically
validate these findings, providing an efficient Pytorch package, \emph{KPFlow},
implementing robust analysis tools for general recurrent architectures. Taken
together, our work moves towards building a next stage of understanding of GD
learning in non-linear recurrent models.

</details>


### [147] [Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning](https://arxiv.org/abs/2507.06402)
*Siddhant Deshpande,Yalemzerf Getnet,Waltenegus Dargie*

Main category: cs.LG

TL;DR: 论文分析了CNN、ResNet和混合Transformer-CNN模型在心电图（ECG）信号篡改检测中的性能，并评估了Siamese网络在ECG身份验证中的表现。实验显示，这些模型在多种篡改场景下表现优异，最高准确率达100%。


<details>
  <summary>Details</summary>
Motivation: 随着无线ECG系统在健康监测和身份验证中的普及，保护信号完整性免受篡改变得至关重要。

Method: 使用连续小波变换（CWT）将一维ECG信号转换为二维时频表示，并训练CNN、ResNet、混合Transformer-CNN及Siamese网络模型。

Result: 在高度碎片化篡改场景中，CNN、FeatCNN-TranCNN、FeatCNN-Tran和ResNet模型的准确率超过99.5%；混合CNN-Transformer Siamese模型在身份验证中达到100%准确率。

Conclusion: 混合Transformer-CNN和Siamese网络在ECG篡改检测和身份验证中表现出色，适用于实际应用。

Abstract: With the proliferation of wireless electrocardiogram (ECG) systems for health
monitoring and authentication, protecting signal integrity against tampering is
becoming increasingly important. This paper analyzes the performance of CNN,
ResNet, and hybrid Transformer-CNN models for tamper detection. It also
evaluates the performance of a Siamese network for ECG based identity
verification. Six tampering strategies, including structured segment
substitutions and random insertions, are emulated to mimic real world attacks.
The one-dimensional ECG signals are transformed into a two dimensional
representation in the time frequency domain using the continuous wavelet
transform (CWT). The models are trained and evaluated using ECG data from 54
subjects recorded in four sessions 2019 to 2025 outside of clinical settings
while the subjects performed seven different daily activities. Experimental
results show that in highly fragmented manipulation scenarios, CNN,
FeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding
99.5 percent . Similarly, for subtle manipulations (for example, 50 percent
from A and 50 percent from B and, 75 percent from A and 25 percent from B
substitutions) our FeatCNN-TranCNN model demonstrated consistently reliable
performance, achieving an average accuracy of 98 percent . For identity
verification, the pure Transformer-Siamese network achieved an average accuracy
of 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model
delivered perfect verification performance with 100 percent accuracy.

</details>


### [148] [Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm](https://arxiv.org/abs/2507.06780)
*George Papadopoulos,George A. Vouros*

Main category: cs.LG

TL;DR: 提出了一种模仿学习方法，学习符合专家轨迹约束的最大熵策略，通过KL散度连接性能与策略差异，并基于概率推断框架优化目标。


<details>
  <summary>Details</summary>
Motivation: 研究如何在模仿学习中结合最大熵策略和约束条件，以生成符合专家行为的多约束策略。

Method: 利用KL散度连接专家与学习策略的性能，通过概率推断框架优化目标，采用双梯度下降算法进行训练。

Result: 实验表明，该方法能有效学习符合多类型约束的策略，适应不同行为模态并具备泛化能力。

Conclusion: 该方法在模仿学习中成功结合了最大熵策略与约束条件，为复杂任务提供了有效的解决方案。

Abstract: This article introduces an imitation learning method for learning maximum
entropy policies that comply with constraints demonstrated by expert
trajectories executing a task. The formulation of the method takes advantage of
results connecting performance to bounds for the KL-divergence between
demonstrated and learned policies, and its objective is rigorously justified
through a connection to a probabilistic inference framework for reinforcement
learning, incorporating the reinforcement learning objective and the objective
to abide by constraints in an entropy maximization setting. The proposed
algorithm optimizes the learning objective with dual gradient descent,
supporting effective and stable training. Experiments show that the proposed
method can learn effective policy models for constraints-abiding behaviour, in
settings with multiple constraints of different types, accommodating different
modalities of demonstrated behaviour, and with abilities to generalize.

</details>


### [149] [Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction](https://arxiv.org/abs/2507.06432)
*Mingcheng Zhu,Yu Liu,Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: KnowRare是一个基于领域适应的深度学习框架，用于预测ICU中罕见疾病的临床结果，通过自监督预训练和条件知识图谱解决数据稀缺和异质性问题，表现优于现有模型和ICU评分系统。


<details>
  <summary>Details</summary>
Motivation: ICU中罕见疾病因数据稀缺和异质性而研究不足，需要开发新方法以改善临床决策。

Method: 结合自监督预训练和条件知识图谱，从相似条件中迁移知识，解决数据稀缺和异质性。

Result: 在五个临床预测任务中表现优于现有模型和ICU评分系统，并展示出灵活性和泛化能力。

Conclusion: KnowRare是支持ICU罕见疾病临床决策的实用解决方案。

Abstract: Artificial Intelligence has revolutionised critical care for common
conditions. Yet, rare conditions in the intensive care unit (ICU), including
recognised rare diseases and low-prevalence conditions in the ICU, remain
underserved due to data scarcity and intra-condition heterogeneity. To bridge
such gaps, we developed KnowRare, a domain adaptation-based deep learning
framework for predicting clinical outcomes for rare conditions in the ICU.
KnowRare mitigates data scarcity by initially learning condition-agnostic
representations from diverse electronic health records through self-supervised
pre-training. It addresses intra-condition heterogeneity by selectively
adapting knowledge from clinically similar conditions with a developed
condition knowledge graph. Evaluated on two ICU datasets across five clinical
prediction tasks (90-day mortality, 30-day readmission, ICU mortality,
remaining length of stay, and phenotyping), KnowRare consistently outperformed
existing state-of-the-art models. Additionally, KnowRare demonstrated superior
predictive performance compared to established ICU scoring systems, including
APACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in
adapting its parameters to accommodate dataset-specific and task-specific
characteristics, its generalisation to common conditions under limited data
scenarios, and its rationality in selecting source conditions. These findings
highlight KnowRare's potential as a robust and practical solution for
supporting clinical decision-making and improving care for rare conditions in
the ICU.

</details>


### [150] [DICE: Data Influence Cascade in Decentralized Learning](https://arxiv.org/abs/2507.06931)
*Tongtian Zhu,Wenhao Li,Can Wang,Fengxiang He*

Main category: cs.LG

TL;DR: 论文提出了一种名为DICE的方法，用于在去中心化网络中估计数据影响力传播，以解决激励机制中公平贡献分配的问题。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习虽然能分散数据和计算负载，但缺乏公平的激励机制，阻碍了参与积极性。

Method: 设计了DICE方法，通过理论推导近似计算任意邻居跳数的影响力传播，结合数据、通信拓扑和损失曲率。

Result: DICE为选择合适合作者和识别恶意行为提供了理论基础。

Conclusion: DICE是首个解决去中心化网络中影响力传播估计的方法，为公平激励机制奠定了基础。

Abstract: Decentralized learning offers a promising approach to crowdsource data
consumptions and computational workloads across geographically distributed
compute interconnected through peer-to-peer networks, accommodating the
exponentially increasing demands. However, proper incentives are still in
absence, considerably discouraging participation. Our vision is that a fair
incentive mechanism relies on fair attribution of contributions to
participating nodes, which faces non-trivial challenges arising from the
localized connections making influence ``cascade'' in a decentralized network.
To overcome this, we design the first method to estimate \textbf{D}ata
\textbf{I}nfluence \textbf{C}ascad\textbf{E} (DICE) in a decentralized
environment. Theoretically, the framework derives tractable approximations of
influence cascade over arbitrary neighbor hops, suggesting the influence
cascade is determined by an interplay of data, communication topology, and the
curvature of loss landscape. DICE also lays the foundations for applications
including selecting suitable collaborators and identifying malicious behaviors.
Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.

</details>


### [151] [eegFloss: A Python package for refining sleep EEG recordings using machine learning models](https://arxiv.org/abs/2507.06433)
*Niloy Sikder,Paul Zerr,Mahdad Jafarzadeh Esfahani,Martin Dresler,Matthias Krauledat*

Main category: cs.LG

TL;DR: eegFloss是一个开源Python包，用于检测睡眠EEG记录中的伪迹，提高睡眠研究的准确性。


<details>
  <summary>Details</summary>
Motivation: EEG信号易受伪迹干扰，影响自动睡眠分期的准确性，需要一种可靠的工具来识别和过滤这些伪迹。

Method: 开发eegFloss包，包含eegUsability模型（用于检测伪迹）和eegMobility模型（用于自动检测在床时间），并评估其性能。

Result: eegUsability模型表现良好（F1分数约0.85，Cohen's kappa为0.78），能高效识别可用EEG数据（召回率约94%）。

Conclusion: eegFloss通过检测和过滤伪迹，提升了睡眠研究的分析精度和结果可靠性。

Abstract: Electroencephalography (EEG) allows monitoring of brain activity, providing
insights into the functional dynamics of various brain regions and their roles
in cognitive processes. EEG is a cornerstone in sleep research, serving as the
primary modality of polysomnography, the gold standard in the field. However,
EEG signals are prone to artifacts caused by both internal (device-specific)
factors and external (environmental) interferences. As sleep studies are
becoming larger, most rely on automatic sleep staging, a process highly
susceptible to artifacts, leading to erroneous sleep scores. This paper
addresses this challenge by introducing eegFloss, an open-source Python package
to utilize eegUsability, a novel machine learning (ML) model designed to detect
segments with artifacts in sleep EEG recordings. eegUsability has been trained
and evaluated on manually artifact-labeled EEG data collected from 15
participants over 127 nights using the Zmax headband. It demonstrates solid
overall classification performance (F1-score is approximately 0.85, Cohens
kappa is 0.78), achieving a high recall rate of approximately 94% in
identifying channel-wise usable EEG data, and extends beyond Zmax.
Additionally, eegFloss offers features such as automatic time-in-bed detection
using another ML model named eegMobility, filtering out certain artifacts, and
generating hypnograms and sleep statistics. By addressing a fundamental
challenge faced by most sleep studies, eegFloss can enhance the precision and
rigor of their analysis as well as the accuracy and reliability of their
outcomes.

</details>


### [152] [Can Interpretation Predict Behavior on Unseen Data?](https://arxiv.org/abs/2507.06445)
*Victoria R. Li,Jenny Kaufmann,Martin Wattenberg,David Alvarez-Melis,Naomi Saphra*

Main category: cs.LG

TL;DR: 论文探讨了可解释性工具在预测模型在分布外（OOD）数据上行为的潜力，发现注意力模式与OOD泛化性能之间存在相关性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于填补可解释性研究在预测模型对未见输入数据响应方面的空白，尤其是OOD行为。

Method: 通过分析数百个独立训练的Transformer模型在合成分类任务中的注意力模式与OOD泛化性能的关联性。

Result: 研究发现，简单的可解释性工具可以预测OOD性能，尤其是当注意力呈现分层模式时，模型倾向于在OOD数据上分层泛化。

Conclusion: 研究为可解释性工具在预测未见模型行为方面的应用提供了概念验证，鼓励进一步研究。

Abstract: Interpretability research often aims to predict how a model will respond to
targeted interventions on specific mechanisms. However, it rarely predicts how
a model will respond to unseen input data. This paper explores the promises and
challenges of interpretability as a tool for predicting out-of-distribution
(OOD) model behavior. Specifically, we investigate the correspondence between
attention patterns and OOD generalization in hundreds of Transformer models
independently trained on a synthetic classification task. These models exhibit
several distinct systematic generalization rules OOD, forming a diverse
population for correlational analysis. In this setting, we find that simple
observational tools from interpretability can predict OOD performance. In
particular, when in-distribution attention exhibits hierarchical patterns, the
model is likely to generalize hierarchically on OOD data -- even when the
rule's implementation does not rely on these hierarchical patterns, according
to ablation tests. Our findings offer a proof-of-concept to motivate further
interpretability work on predicting unseen model behavior.

</details>


### [153] [FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models](https://arxiv.org/abs/2507.06449)
*Qianyu Long,Qiyuan Wang,Christos Anagnostopoulos,Daning Bi*

Main category: cs.LG

TL;DR: FedPhD是一种新颖的联邦学习方法，专注于高效训练扩散模型（DMs），通过分层联邦学习和同质性感知模型聚合解决数据异构性和高通信成本问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在联邦学习环境中面临数据异构性和高通信成本的挑战，现有研究较少解决这些问题。

Method: FedPhD采用分层联邦学习，结合同质性感知模型聚合和选择策略，并通过分布式结构化剪枝提升计算效率和减少存储需求。

Result: 实验显示，FedPhD在FID分数上表现优异，通信成本降低88%，计算和通信资源仅需56%，且FID提升至少34%。

Conclusion: FedPhD为联邦学习中扩散模型的高效训练提供了有效解决方案，显著提升了性能和资源利用率。

Abstract: Federated Learning (FL), as a distributed learning paradigm, trains models
over distributed clients' data. FL is particularly beneficial for distributed
training of Diffusion Models (DMs), which are high-quality image generators
that require diverse data. However, challenges such as high communication costs
and data heterogeneity persist in training DMs similar to training Transformers
and Convolutional Neural Networks. Limited research has addressed these issues
in FL environments. To address this gap and challenges, we introduce a novel
approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD
leverages Hierarchical FL with homogeneity-aware model aggregation and
selection policy to tackle data heterogeneity while reducing communication
costs. The distributed structured pruning of FedPhD enhances computational
efficiency and reduces model storage requirements in clients. Our experiments
across multiple datasets demonstrate that FedPhD achieves high model
performance regarding Fr\'echet Inception Distance (FID) scores while reducing
communication costs by up to $88\%$. FedPhD outperforms baseline methods
achieving at least a $34\%$ improvement in FID, while utilizing only $56\%$ of
the total computation and communication resources.

</details>


### [154] [Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models](https://arxiv.org/abs/2507.06458)
*Arjun Banerjee,David Martinez,Camille Dang,Ethan Tam*

Main category: cs.LG

TL;DR: 本文提出了一种自动化框架，用于为蛋白质语言模型（PLM）中的每个神经元提供生物学基础的自然语言描述，并开发了一种基于神经元激活的引导方法，以生成具有目标特性的蛋白质。


<details>
  <summary>Details</summary>
Motivation: 理解PLM内部神经元的生物学意义，并利用这些信息指导蛋白质设计。

Method: 引入自动化框架标记神经元，开发神经元激活引导方法生成目标蛋白质。

Result: 揭示了神经元对多样生化特性的选择性敏感，实现了目标生化特性和结构基序的生成。

Conclusion: 该方法为PLM的神经元理解提供了新视角，并展示了在蛋白质设计中的应用潜力。

Abstract: Protein language models (PLMs) encode rich biological information, yet their
internal neuron representations are poorly understood. We introduce the first
automated framework for labeling every neuron in a PLM with biologically
grounded natural language descriptions. Unlike prior approaches relying on
sparse autoencoders or manual annotation, our method scales to hundreds of
thousands of neurons, revealing individual neurons are selectively sensitive to
diverse biochemical and structural properties. We then develop a novel neuron
activation-guided steering method to generate proteins with desired traits,
enabling convergence to target biochemical properties like molecular weight and
instability index as well as secondary and tertiary structural motifs,
including alpha helices and canonical Zinc Fingers. We finally show that
analysis of labeled neurons in different model sizes reveals PLM scaling laws
and a structured neuron space distribution.

</details>


### [155] [Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm](https://arxiv.org/abs/2507.06461)
*Risi Jaiswal,Supriyo Datta,Joseph G. Makin*

Main category: cs.LG

TL;DR: 论文提出了一种基于前向-前向算法的二值随机单元训练方法，以减少神经网络训练中的能耗，并通过硬件优化实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习因大规模神经网络的高能耗问题而面临挑战，反向传播算法在硬件加速器上存在依赖性和内存占用问题。

Method: 采用二值化和随机化的前向-前向算法，将矩阵乘法转化为索引操作，结合p-bits实现高效硬件计算。

Result: 在MNIST、Fashion-MNIST和CIFAR-10数据集上表现接近实值前向-前向算法，能耗降低约一个数量级。

Conclusion: 提出的算法在保持性能的同时显著降低了能耗，为节能机器学习提供了可行方案。

Abstract: Reducing energy consumption has become a pressing need for modern machine
learning, which has achieved many of its most impressive results by scaling to
larger and more energy-consumptive neural networks. Unfortunately, the main
algorithm for training such networks, backpropagation, poses significant
challenges for custom hardware accelerators, due to both its serial
dependencies and the memory footprint needed to store forward activations for
the backward pass. Alternatives to backprop, although less effective, do exist;
here the main computational bottleneck becomes matrix multiplication. In this
study, we derive forward-forward algorithms for binary, stochastic units.
Binarization of the activations transforms matrix multiplications into indexing
operations, which can be executed efficiently in hardware. Stochasticity,
combined with tied weights across units with different biases, bypasses the
information bottleneck imposed by binary units. Furthermore, although slow and
expensive in traditional hardware, binary sampling that is very fast can be
implemented cheaply with p-bits (probabilistic bits), novel devices made up of
unstable magnets. We evaluate our proposed algorithms on the MNIST,
Fashion-MNIST, and CIFAR-10 datasets, showing that its performance is close to
real-valued forward-forward, but with an estimated energy savings of about one
order of magnitude.

</details>


### [156] [SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam](https://arxiv.org/abs/2507.06464)
*Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Wen Gao*

Main category: cs.LG

TL;DR: 论文提出了一种名为SignSoftSGD（S3）的新型优化器，通过改进Adam的更新机制，增强了稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: Adam在训练深度神经网络中表现优异，但其机制和局限性尚未充分研究。论文旨在改进Adam的不足，如梯度波动和损失峰值问题。

Method: S3通过引入p阶动量、统一的EMA系数和NAG模块，改进了Adam的更新机制，提升了稳定性和收敛速度。

Result: 实验表明，S3在多种任务中表现优于AdamW，收敛更快且损失峰值更少，甚至能使用10倍的学习率。

Conclusion: S3在效率和最终性能上均优于Adam，为深度学习的优化提供了新思路。

Abstract: Adam has proven remarkable successful in training deep neural networks, but
the mechanisms underlying its empirical successes and limitations remain
underexplored. In this study, we demonstrate that the effectiveness of Adam
stems largely from its similarity to SignSGD in robustly handling large
gradient fluctuations, yet it is also vulnerable to destabilizing loss spikes
due to its uncontrolled update scaling. To enhance the advantage of Adam and
mitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with
three key innovations. \emph{First}, S3 generalizes the sign-like update by
employing a flexible $p$-th order momentum ($p \geq 1$) in the denominator,
departing from the conventional second-order momentum (variance)
preconditioning. This design enables enhanced performance while achieving
stable training even with aggressive learning rates. \emph{Second}, S3
minimizes the occurrences of loss spikes through unified exponential moving
average coefficients for numerator and denominator momenta, which inherently
bound updates to $[-1, 1]$ and simplify hyperparameter tuning. \emph{Third}, S3
incorporates an equivalent Nesterov's accelerated gradient(NAG) module,
accelerating convergence without memory overhead. Theoretically, we prove that
S3 achieves the optimal convergence rate of
$O\left(\frac{1}{T^{\sfrac{1}{4}}}\right)$ for general nonconvex stochastic
optimization under weak assumptions. Extensive experiments across a range of
vision and language tasks show that \textsf{\small S3} not only converges more
rapidly and improves performance but also rarely experiences loss spikes, even
with a \textbf{$\bm{10 \times}$} larger learning rate. In fact, S3 delivers
performance comparable to or better than AdamW with \textbf{$2 \times$} the
training steps, establishing its efficacy in both efficiency and final task
performance.

</details>


### [157] [Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](https://arxiv.org/abs/2507.06466)
*Aaron Dharna,Cong Lu,Jeff Clune*

Main category: cs.LG

TL;DR: 论文提出了一种名为FMSP的新方法，利用基础模型的代码生成能力和广泛知识，通过自我对弈克服局部最优问题，并探索多样化和高质量的策略。


<details>
  <summary>Details</summary>
Motivation: 传统自我对弈（SP）方法容易陷入局部最优且缺乏多样性，因此需要一种新方法来克服这些限制。

Method: 提出了三种FMSP方法：vFMSP（持续优化策略）、NSSP（探索多样性策略）和QDSP（结合多样性与高质量策略）。

Result: 在Car Tag和Gandalf实验中，FMSP表现出色，超越了人类设计的策略，并能自动修补漏洞。

Conclusion: FMSP为自我对弈提供了新的研究方向，有望实现更开放和创造性的策略发现。

Abstract: Multi-agent interactions have long fueled innovation, from natural
predator-prey dynamics to the space race. Self-play (SP) algorithms try to
harness these dynamics by pitting agents against ever-improving opponents,
thereby creating an implicit curriculum toward learning high-quality solutions.
However, SP often fails to produce diverse solutions and can get stuck in
locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a
new direction that leverages the code-generation capabilities and vast
knowledge of foundation models (FMs) to overcome these challenges by leaping
across local optima in policy space. We propose a family of approaches: (1)
\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent
policies via competitive self-play; (2) \textbf{Novelty-Search Self-Play
(NSSP)} builds a diverse population of strategies, ignoring performance; and
(3) the most promising variant, \textbf{Quality-Diveristy Self-Play (QDSP)},
creates a diverse set of high-quality policies by combining the diversity of
NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a
continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety
simulation in which an attacker tries to jailbreak an LLM's defenses. In Car
Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and
heuristic-based methods, to name just a few. In terms of discovered policy
quality, \ouralgo and vFMSP surpass strong human-designed strategies. In
Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through
and jailbreaking six different, progressively stronger levels of defense.
Furthermore, FMSPs can automatically proceed to patch the discovered
vulnerabilities. Overall, FMSPs represent a promising new research frontier of
improving self-play with foundation models, opening fresh paths toward more
creative and open-ended strategy discovery

</details>


### [158] [Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning](https://arxiv.org/abs/2507.06469)
*Yudan Song,Yuecen Wei,Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu*

Main category: cs.LG

TL;DR: 论文提出了一种双视图图表示学习方法（MimbFD），用于解决基于GNN的欺诈检测中拓扑和类别不平衡问题，通过改进节点表示和局部混淆去偏模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有图表示学习方法在欺诈检测中因局部交互和类别不平衡导致全局拓扑信息传递不均，节点特定信息易被淹没。

Method: 设计了拓扑消息可达性模块以穿透欺诈者伪装，并引入局部混淆去偏模块平衡不同类别的影响。

Result: 在三个公开欺诈数据集上的实验表明，MimbFD在欺诈检测中表现优异。

Conclusion: MimbFD通过双视图学习有效缓解了消息不平衡问题，提升了欺诈检测性能。

Abstract: Graph representation learning has become a mainstream method for fraud
detection due to its strong expressive power, which focuses on enhancing node
representations through improved neighborhood knowledge capture. However, the
focus on local interactions leads to imbalanced transmission of global
topological information and increased risk of node-specific information being
overwhelmed during aggregation due to the imbalance between fraud and benign
nodes. In this paper, we first summarize the impact of topology and class
imbalance on downstream tasks in GNN-based fraud detection, as the problem of
imbalanced supervisory messages is caused by fraudsters' topological behavior
obfuscation and identity feature concealment. Based on statistical validation,
we propose a novel dual-view graph representation learning method to mitigate
Message imbalance in Fraud Detection(MimbFD). Specifically, we design a
topological message reachability module for high-quality node representation
learning to penetrate fraudsters' camouflage and alleviate insufficient
propagation. Then, we introduce a local confounding debiasing module to adjust
node representations, enhancing the stable association between node
representations and labels to balance the influence of different classes.
Finally, we conducted experiments on three public fraud datasets, and the
results demonstrate that MimbFD exhibits outstanding performance in fraud
detection.

</details>


### [159] [FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning](https://arxiv.org/abs/2507.06482)
*Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen*

Main category: cs.LG

TL;DR: 论文提出了一种名为FedDifRC的新方法，利用扩散模型解决联邦学习中的数据异构性问题，通过文本驱动的对比学习和噪声驱动的一致性正则化提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中数据异构性导致模型收敛和性能问题，需要一种新方法来解决。

Method: 提出FedDifRC，结合扩散模型的表示能力，通过文本驱动的对比学习和噪声驱动的一致性正则化处理数据异构性。

Result: 实验验证了FedDifRC的有效性，并在不同场景下展示了其关键组件的效率。

Conclusion: FedDifRC通过扩散模型的指导成功缓解了数据异构性问题，并提供了理论保证。

Abstract: Federated learning aims at training models collaboratively across
participants while protecting privacy. However, one major challenge for this
paradigm is the data heterogeneity issue, where biased data preferences across
multiple clients, harming the model's convergence and performance. In this
paper, we first introduce powerful diffusion models into the federated learning
paradigm and show that diffusion representations are effective steers during
federated training. To explore the possibility of using diffusion
representations in handling data heterogeneity, we propose a novel
diffusion-inspired Federated paradigm with Diffusion Representation
Collaboration, termed FedDifRC, leveraging meaningful guidance of diffusion
models to mitigate data heterogeneity. The key idea is to construct text-driven
diffusion contrasting and noise-driven diffusion regularization, aiming to
provide abundant class-related semantic information and consistent convergence
signals. On the one hand, we exploit the conditional feedback from the
diffusion model for different text prompts to build a text-driven contrastive
learning strategy. On the other hand, we introduce a noise-driven consistency
regularization to align local instances with diffusion denoising
representations, constraining the optimization region in the feature space. In
addition, FedDifRC can be extended to a self-supervised scheme without relying
on any labeled data. We also provide a theoretical analysis for FedDifRC to
ensure convergence under non-convex objectives. The experiments on different
scenarios validate the effectiveness of FedDifRC and the efficiency of crucial
components.

</details>


### [160] [MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models](https://arxiv.org/abs/2507.06502)
*Yiwen Liu,Chenyu Zhang,Junjie Song,Siqi Chen,Sun Yin,Zihan Wang,Lingming Zeng,Yuji Cao,Junming Jiao*

Main category: cs.LG

TL;DR: MoFE-Time是一种创新的时间序列预测模型，通过结合时间和频域特征，在MoE网络中实现了多维稀疏表示，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在预训练-微调范式中未能同时建模时间和频率特征，导致复杂时间序列预测性能不佳。

Method: 提出MoFE-Time模型，集成时间和频域特征于MoE网络，利用MoE路由机制构建多维稀疏表示。

Result: 在六个公共基准测试中，MoFE-Time实现了新的最先进性能，MSE和MAE分别降低了6.95%和6.02%。

Conclusion: MoFE-Time在理论和实际应用中均表现出色，验证了其在复杂时间序列预测中的有效性。

Abstract: As a prominent data modality task, time series forecasting plays a pivotal
role in diverse applications. With the remarkable advancements in Large
Language Models (LLMs), the adoption of LLMs as the foundational architecture
for time series modeling has gained significant attention. Although existing
models achieve some success, they rarely both model time and frequency
characteristics in a pretraining-finetuning paradigm leading to suboptimal
performance in predictions of complex time series, which requires both modeling
periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an
innovative time series forecasting model that integrates time and frequency
domain features within a Mixture of Experts (MoE) network. Moreover, we use the
pretraining-finetuning paradigm as our training framework to effectively
transfer prior pattern knowledge across pretraining and finetuning datasets
with different periodicity distributions. Our method introduces both frequency
and time cells as experts after attention modules and leverages the MoE routing
mechanism to construct multidimensional sparse representations of input
signals. In experiments on six public benchmarks, MoFE-Time has achieved new
state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared
to the representative methods Time-MoE. Beyond the existing evaluation
benchmarks, we have developed a proprietary dataset, NEV-sales, derived from
real-world business scenarios. Our method achieves outstanding results on this
dataset, underscoring the effectiveness of the MoFE-Time model in practical
commercial applications.

</details>


### [161] [Instance-Wise Monotonic Calibration by Constrained Transformation](https://arxiv.org/abs/2507.06516)
*Yunrui Zhang,Gustavo Batista,Salil S. Kanhere*

Main category: cs.LG

TL;DR: 论文提出了一种新的单调后校准方法，通过线性参数化校准映射，确保表达能力、鲁棒性和可解释性，同时保持概率输出的相对顺序。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络常产生错误的概率估计，导致过度自信的预测。现有后校准方法大多无法保证单调性，或表达能力有限，或缺乏可解释性。

Method: 提出一种基于约束优化的单调后校准方法，线性参数化校准映射，确保单调性和表达能力。

Result: 在多个数据集和模型上，新方法表现优于现有校准方法，且数据与计算效率高。

Conclusion: 该方法在保持单调性的同时，提供了更好的校准性能，适用于实际应用。

Abstract: Deep neural networks often produce miscalibrated probability estimates,
leading to overconfident predictions. A common approach for calibration is
fitting a post-hoc calibration map on unseen validation data that transforms
predicted probabilities. A key desirable property of the calibration map is
instance-wise monotonicity (i.e., preserving the ranking of probability
outputs). However, most existing post-hoc calibration methods do not guarantee
monotonicity. Previous monotonic approaches either use an under-parameterized
calibration map with limited expressive ability or rely on black-box neural
networks, which lack interpretability and robustness. In this paper, we propose
a family of novel monotonic post-hoc calibration methods, which employs a
constrained calibration map parameterized linearly with respect to the number
of classes. Our proposed approach ensures expressiveness, robustness, and
interpretability while preserving the relative ordering of the probability
output by formulating the proposed calibration map as a constrained
optimization problem. Our proposed methods achieve state-of-the-art performance
across datasets with different deep neural network models, outperforming
existing calibration methods while being data and computation-efficient. Our
code is available at
https://github.com/YunruiZhang/Calibration-by-Constrained-Transformation

</details>


### [162] [AdaDPIGU: Differentially Private SGD with Adaptive Clipping and Importance-Based Gradient Updates for Deep Neural Networks](https://arxiv.org/abs/2507.06525)
*Huiqi Zhang,Fang Xie*

Main category: cs.LG

TL;DR: AdaDPIGU是一种新的差分隐私SGD框架，通过重要性梯度更新和自适应剪枝机制，在高维设置中提升性能，同时满足隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私方法在高维设置中性能下降，噪声随维度增加而增大，影响模型表现。

Method: 预训练阶段使用差分隐私高斯机制估计参数重要性，梯度更新阶段剪枝低重要性坐标并引入自适应裁剪机制。

Result: 在MNIST和CIFAR-10上表现优异，隐私预算下接近或超越非隐私模型。

Conclusion: AdaDPIGU通过自适应稀疏化同时提升隐私保护和模型效用。

Abstract: Differential privacy has been proven effective for stochastic gradient
descent; however, existing methods often suffer from performance degradation in
high-dimensional settings, as the scale of injected noise increases with
dimensionality. To tackle this challenge, we propose AdaDPIGU--a new
differentially private SGD framework with importance-based gradient updates
tailored for deep neural networks. In the pretraining stage, we apply a
differentially private Gaussian mechanism to estimate the importance of each
parameter while preserving privacy. During the gradient update phase, we prune
low-importance coordinates and introduce a coordinate-wise adaptive clipping
mechanism, enabling sparse and noise-efficient gradient updates. Theoretically,
we prove that AdaDPIGU satisfies $(\varepsilon, \delta)$-differential privacy
and retains convergence guarantees. Extensive experiments on standard
benchmarks validate the effectiveness of AdaDPIGU. All results are reported
under a fixed retention ratio of 60%. On MNIST, our method achieves a test
accuracy of 99.12% under a privacy budget of $\epsilon = 8$, nearly matching
the non-private model. Remarkably, on CIFAR-10, it attains 73.21% accuracy at
$\epsilon = 4$, outperforming the non-private baseline of 71.12%, demonstrating
that adaptive sparsification can enhance both privacy and utility.

</details>


### [163] [Direct Regret Optimization in Bayesian Optimization](https://arxiv.org/abs/2507.06529)
*Fengxue Zhang,Yuxin Chen*

Main category: cs.LG

TL;DR: 提出了一种新的贝叶斯优化方法，通过联合学习最优模型和非近视获取函数，直接优化多步遗憾。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化方法依赖手工设计的获取函数和代理模型，且通常是近视的。本文旨在解决这些问题。

Method: 使用高斯过程集合生成模拟轨迹，训练端到端决策变换器，结合离线密集训练和在线稀疏学习。

Result: 在合成和真实基准测试中，该方法优于基线，实现了更低的简单遗憾和更鲁棒的探索。

Conclusion: 提出的框架在贝叶斯优化中表现出色，尤其在复杂或噪声环境中。

Abstract: Bayesian optimization (BO) is a powerful paradigm for optimizing expensive
black-box functions. Traditional BO methods typically rely on separate
hand-crafted acquisition functions and surrogate models for the underlying
function, and often operate in a myopic manner. In this paper, we propose a
novel direct regret optimization approach that jointly learns the optimal model
and non-myopic acquisition by distilling from a set of candidate models and
acquisitions, and explicitly targets minimizing the multi-step regret. Our
framework leverages an ensemble of Gaussian Processes (GPs) with varying
hyperparameters to generate simulated BO trajectories, each guided by an
acquisition function chosen from a pool of conventional choices, until a
Bayesian early stop criterion is met. These simulated trajectories, capturing
multi-step exploration strategies, are used to train an end-to-end decision
transformer that directly learns to select next query points aimed at improving
the ultimate objective. We further adopt a dense training--sparse learning
paradigm: The decision transformer is trained offline with abundant simulated
data sampled from ensemble GPs and acquisitions, while a limited number of real
evaluations refine the GPs online. Experimental results on synthetic and
real-world benchmarks suggest that our method consistently outperforms BO
baselines, achieving lower simple regret and demonstrating more robust
exploration in high-dimensional or noisy settings.

</details>


### [164] [Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits](https://arxiv.org/abs/2507.06535)
*Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu*

Main category: cs.LG

TL;DR: 论文提出CircuitGCL，一种图对比学习框架，用于解决AMS电路中数据稀缺、标签不平衡和电路多样性问题，显著提升寄生估计任务性能。


<details>
  <summary>Details</summary>
Motivation: AMS电路设计数据稀缺、标签分布不平衡且电路实现多样，导致学习鲁棒且可迁移的电路表示具有挑战性。

Method: CircuitGCL结合表示散射和标签重平衡，通过自监督学习拓扑不变节点嵌入，并使用平衡MSE和bsmCE损失缓解标签分布差异。

Result: 在TSMC 28nm AMS设计中，CircuitGCL在边级寄生电容估计和节点级接地电容分类任务中均优于现有方法，R²提升33.64%~44.20%，F1分数提升0.9~2.1倍。

Conclusion: CircuitGCL通过表示散射和标签重平衡，显著提升了电路图表示学习的鲁棒性和可迁移性，适用于多种下游任务。

Abstract: Graph representation learning on Analog-Mixed Signal (AMS) circuits is
crucial for various downstream tasks, e.g., parasitic estimation. However, the
scarcity of design data, the unbalanced distribution of labels, and the
inherent diversity of circuit implementations pose significant challenges to
learning robust and transferable circuit representations. To address these
limitations, we propose CircuitGCL, a novel graph contrastive learning
framework that integrates representation scattering and label rebalancing to
enhance transferability across heterogeneous circuit graphs. CircuitGCL employs
a self-supervised strategy to learn topology-invariant node embeddings through
hyperspherical representation scattering, eliminating dependency on large-scale
data. Simultaneously, balanced mean squared error (MSE) and softmax
cross-entropy (bsmCE) losses are introduced to mitigate label distribution
disparities between circuits, enabling robust and transferable parasitic
estimation. Evaluated on parasitic capacitance estimation (edge-level task) and
ground capacitance classification (node-level task) across TSMC 28nm AMS
designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the
$R^2$ improvement of $33.64\% \sim 44.20\%$ for edge regression and F1-score
gain of $0.9\times \sim 2.1\times$ for node classification. Our code is
available at
\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.

</details>


### [165] [Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction](https://arxiv.org/abs/2507.06538)
*Shan Shen,Yibin Zhang,Hector Rodriguez Rodriguez,Wenjian Yu*

Main category: cs.LG

TL;DR: CircuitGPS是一种用于AMS电路寄生效应预测的小样本学习方法，通过异构图表示和子图采样技术，结合图Transformer，显著提升了预测精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 由于集成电路设计数据的稀缺性，训练深度学习模型用于AMS设计受到严重限制，因此需要一种小样本学习方法。

Method: CircuitGPS将电路网表表示为异构图，通过小跳采样技术生成子图，使用混合图Transformer学习子图嵌入，并集成低成本的位置编码。

Result: CircuitGPS将耦合存在预测的准确率提高了至少20%，电容估计的MAE降低了至少0.067，并展示了强大的零样本学习能力。

Conclusion: CircuitGPS为AMS电路设计提供了一种高效、可扩展的解决方案，并通过消融研究为图表示学习提供了有价值的见解。

Abstract: Graph representation learning is a powerful method to extract features from
graph-structured data, such as analog/mixed-signal (AMS) circuits. However,
training deep learning models for AMS designs is severely limited by the
scarcity of integrated circuit design data. In this work, we present
CircuitGPS, a few-shot learning method for parasitic effect prediction in AMS
circuits. The circuit netlist is represented as a heterogeneous graph, with the
coupling capacitance modeled as a link. CircuitGPS is pre-trained on link
prediction and fine-tuned on edge regression. The proposed method starts with a
small-hop sampling technique that converts a link or a node into a subgraph.
Then, the subgraph embeddings are learned with a hybrid graph Transformer.
Additionally, CircuitGPS integrates a low-cost positional encoding that
summarizes the positional and structural information of the sampled subgraph.
CircuitGPS improves the accuracy of coupling existence by at least 20\% and
reduces the MAE of capacitance estimation by at least 0.067 compared to
existing methods. Our method demonstrates strong inherent scalability, enabling
direct application to diverse AMS circuit designs through zero-shot learning.
Furthermore, the ablation studies provide valuable insights into graph models
for representation learning.

</details>


### [166] [Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs](https://arxiv.org/abs/2507.06549)
*Shan Shen,Dingcheng Yang,Yuyang Xie,Chunyan Pei,Wenjian Yu,Bei Yu*

Main category: cs.LG

TL;DR: 提出了一种基于深度学习的2阶段模型，用于在预布局阶段准确预测SRAM电路中的寄生效应，显著减少误差并加速仿真过程。


<details>
  <summary>Details</summary>
Motivation: SRAM在SoC中的定制化导致预布局和后布局电路仿真之间存在显著差异，增加了设计迭代的难度。

Method: 结合图神经网络（GNN）分类器和多层感知机（MLP）回归器，采用Focal Loss处理类别不平衡，并整合子电路信息以抽象层次结构。

Result: 在4个实际SRAM设计中，模型误差最大减少19倍，仿真速度提升高达598倍。

Conclusion: 该方法有效解决了寄生效应预测问题，显著提升了设计效率和仿真速度。

Abstract: To achieve higher system energy efficiency, SRAM in SoCs is often customized.
The parasitic effects cause notable discrepancies between pre-layout and
post-layout circuit simulations, leading to difficulty in converging design
parameters and excessive design iterations. Is it possible to well predict the
parasitics based on the pre-layout circuit, so as to perform parasitic-aware
pre-layout simulation? In this work, we propose a deep-learning-based 2-stage
model to accurately predict these parasitics in pre-layout stages. The model
combines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron
(MLP) regressors, effectively managing class imbalance of the net parasitics in
SRAM circuits. We also employ Focal Loss to mitigate the impact of abundant
internal net samples and integrate subcircuit information into the graph to
abstract the hierarchical structure of schematics. Experiments on 4 real SRAM
designs show that our approach not only surpasses the state-of-the-art model in
parasitic prediction by a maximum of 19X reduction of error but also
significantly boosts the simulation process by up to 598X speedup.

</details>


### [167] [The Primacy of Magnitude in Low-Rank Adaptation](https://arxiv.org/abs/2507.06558)
*Zicheng Zhang,Haoran Li,Yifeng Zhang,Guoqiang Gong,Jiaxing Wang,Pengzhang Liu,Qixia Jiang,Junxing Hu*

Main category: cs.LG

TL;DR: LoRAM是一种基于更新幅度的初始化方案，通过优化幅度调节提升LoRA性能，避免了光谱方法的额外开销。


<details>
  <summary>Details</summary>
Motivation: 光谱初始化方法虽然提高了性能，但带来了额外的计算和存储开销，因此需要一种更高效的初始化方案。

Method: 提出LoRAM，利用预训练权重幅度缩放确定性正交基，模拟光谱增益。

Result: LoRAM在保持LoRA高效性的同时，性能与光谱初始化相当或更优。

Conclusion: LoRAM通过幅度驱动优化，为LoRA提供了一种高效且性能优越的初始化策略。

Abstract: Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning
large models. While recent spectral initialization methods improve convergence
and performance over the naive "Noise & Zeros" scheme, their extra
computational and storage overhead undermines efficiency. In this paper, we
establish update magnitude as the fundamental driver of LoRA performance and
propose LoRAM, a magnitude-driven "Basis & Basis" initialization scheme that
matches spectral methods without their inefficiencies. Our key contributions
are threefold: (i) Magnitude of weight updates determines convergence. We prove
low-rank structures intrinsically bound update magnitudes, unifying
hyperparameter tuning in learning rate, scaling factor, and initialization as
mechanisms to optimize magnitude regulation. (ii) Spectral initialization
succeeds via magnitude amplification. We demystify that the presumed
knowledge-driven benefit of the spectral component essentially arises from the
boost in the weight update magnitude. (iii) A novel and compact initialization
strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight
magnitudes to simulate spectral gains. Extensive experiments show that LoRAM
serves as a strong baseline, retaining the full efficiency of LoRA while
matching or outperforming spectral initialization across benchmarks.

</details>


### [168] [SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference](https://arxiv.org/abs/2507.06567)
*Qian Chen,Xianhao Chen,Kaibin Huang*

Main category: cs.LG

TL;DR: 论文提出了一种优化边缘网络中专家缓存的方法，以减少Mixture-of-Experts模型的推理延迟。


<details>
  <summary>Details</summary>
Motivation: MoE模型在边缘设备上存储大量专家网络带来负担，需优化专家缓存以减少延迟。

Method: 针对Top-K专家选择策略，设计了贪心算法和动态规划方法，并引入最大卷积技术加速求解。

Result: 仿真结果表明，该方法显著降低了推理延迟。

Conclusion: 提出的方法有效解决了MoE模型在边缘网络中的延迟问题，具有理论和实践价值。

Abstract: Mixture-of-Experts (MoE) models improve the scalability of large language
models (LLMs) by activating only a small subset of relevant experts per input.
However, the sheer number of expert networks in an MoE model introduces a
significant storage burden for an edge device. To address this challenge, we
consider a scenario where experts are dispersed within an edge network for
distributed inference. Based on the popular Top-$K$ expert selection strategy,
we formulate a latency minimization problem by optimizing expert caching on
edge servers under storage constraints. When $K=1$, the problem reduces to a
monotone submodular maximization problem with knapsack constraints, for which
we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee.
For the general case where $K\geq1$, expert co-activation within the same MoE
layer introduces non-submodularity, causing greedy methods to be ineffective.
To tackle this issue, we propose a successive greedy decomposition method to
decompose the original problem into a series of subproblems, with each being
solved by a dynamic programming approach. Furthermore, we design an accelerated
algorithm based on the max-convolution technique to obtain the approximate
solution with a provable guarantee in polynomial time. Simulation results on
various MoE models demonstrate that our method significantly reduces inference
latency compared to existing baselines.

</details>


### [169] [From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization](https://arxiv.org/abs/2507.06573)
*Xinjie Chen,Minpeng Liao,Guoxin Chen,Chengxi Li,Biao Fu,Kai Fan,Xinggao Liu*

Main category: cs.LG

TL;DR: 论文提出LPPO框架，通过前缀引导采样和学习进度加权优化RLVR，利用少量高质量示范提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何有效利用少量高质量示范而非简单增加数据量，提升LLM的推理能力。

Method: 提出前缀引导采样（利用专家示范的部分解引导策略）和学习进度加权（动态调整样本权重）。

Result: 在数学推理基准测试中表现优于基线，收敛更快且性能上限更高。

Conclusion: LPPO框架通过样本优化显著提升RLVR效果，验证了高质量示范的重要性。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has recently advanced
the reasoning capabilities of large language models (LLMs). While prior work
has emphasized algorithmic design, data curation, and reward shaping, we
investigate RLVR from a sample-centric perspective and introduce LPPO
(Learning-Progress and Prefix-guided Optimization), a framework of progressive
optimization techniques. Our work addresses a critical question: how to best
leverage a small set of trusted, high-quality demonstrations, rather than
simply scaling up data volume. First, motivated by how hints aid human
problem-solving, we propose prefix-guided sampling, an online data augmentation
method that incorporates partial solution prefixes from expert demonstrations
to guide the policy, particularly for challenging instances. Second, inspired
by how humans focus on important questions aligned with their current
capabilities, we introduce learning-progress weighting, a dynamic strategy that
adjusts each training sample's influence based on model progression. We
estimate sample-level learning progress via an exponential moving average of
per-sample pass rates, promoting samples that foster learning and
de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks
demonstrate that our methods outperform strong baselines, yielding faster
convergence and a higher performance ceiling.

</details>


### [170] [Learning controllable dynamics through informative exploration](https://arxiv.org/abs/2507.06582)
*Peter N. Loxley,Friedrich T. Sommer*

Main category: cs.LG

TL;DR: 论文提出了一种基于“预测信息增益”的方法，用于探索环境中信息量最大的区域，并结合强化学习找到有效的探索策略。


<details>
  <summary>Details</summary>
Motivation: 在无法获取显式模型的环境中，通过学习探索来理解可控动态。

Method: 使用“预测信息增益”作为信息度量，结合强化学习方法寻找次优探索策略。

Result: 该方法能够可靠估计环境的可控动态，优于几种短视探索方法。

Conclusion: 通过信息增益和强化学习的结合，能够有效探索未知环境并估计其动态。

Abstract: Environments with controllable dynamics are usually understood in terms of
explicit models. However, such models are not always available, but may
sometimes be learned by exploring an environment. In this work, we investigate
using an information measure called "predicted information gain" to determine
the most informative regions of an environment to explore next. Applying
methods from reinforcement learning allows good suboptimal exploring policies
to be found, and leads to reliable estimates of the underlying controllable
dynamics. This approach is demonstrated by comparing with several myopic
exploration approaches.

</details>


### [171] [Generalization in Reinforcement Learning for Radio Access Networks](https://arxiv.org/abs/2507.06602)
*Burak Demirel,Yu Wang,Cristian Tatino,Pablo Soldati*

Main category: cs.LG

TL;DR: 提出了一种基于强化学习的通用框架，用于解决现代无线接入网络（RAN）中的动态和异构环境问题，通过图注意力网络和分布式训练提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的RRM算法在动态和异构环境中表现不佳，而现有强化学习方法容易过拟合训练条件，无法泛化到新场景。

Method: 采用注意力图表示网络拓扑和节点属性，结合领域随机化和分布式数据生成，集中训练以适应多样网络条件。

Result: 在5G基准测试中，平均吞吐量和频谱效率提升10%-20%，在多场景下表现优于基线方法，图注意力模型在九小区部署中吞吐量提升30%。

Conclusion: 该框架为AI原生6G RAN提供了一种可扩展且泛化能力强的解决方案。

Abstract: Modern RAN operate in highly dynamic and heterogeneous environments, where
hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass
such heuristics in constrained settings, the diversity of deployments and
unpredictable radio conditions introduce major generalization challenges.
Data-driven policies frequently overfit to training conditions, degrading
performance in unseen scenarios. To address this, we propose a
generalization-centered RL framework for RAN control that: (i) encodes cell
topology and node attributes via attention-based graph representations; (ii)
applies domain randomization to broaden the training distribution; and (iii)
distributes data generation across multiple actors while centralizing training
in a cloud-compatible architecture aligned with O-RAN principles. Although
generalization increases computational and data-management complexity, our
distributed design mitigates this by scaling data collection and training
across diverse network conditions. Applied to downlink link adaptation in five
5G benchmarks, our policy improves average throughput and spectral efficiency
by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and
by >20% under high mobility. It matches specialized RL in full-buffer traffic
and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks,
respectively. In nine-cell deployments, GAT models offer 30% higher throughput
over MLP baselines. These results, combined with our scalable architecture,
offer a path toward AI-native 6G RAN using a single, generalizable RL agent.

</details>


### [172] [Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation](https://arxiv.org/abs/2507.06613)
*Anshuk Uppal,Yuhta Takida,Chieh-Hsin Lai,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 论文提出了一种新的生成模型框架，通过使用不同β值的VAE和扩散模型，平衡解缠与重建质量，实现高质量生成和解缠表示。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型中解缠表示与重建质量之间的权衡问题。

Method: 结合多β值的VAE训练和扩散模型，平滑过渡不同β值的潜在表示。

Result: 实现了高质量的解缠表示和重建，支持无输入图像的生成。

Conclusion: 该框架在解缠和生成质量上表现优异，支持潜在空间的平滑过渡。

Abstract: Disentangled and interpretable latent representations in generative models
typically come at the cost of generation quality. The $\beta$-VAE framework
introduces a hyperparameter $\beta$ to balance disentanglement and
reconstruction quality, where setting $\beta > 1$ introduces an information
bottleneck that favors disentanglement over sharp, accurate reconstructions. To
address this trade-off, we propose a novel generative modeling framework that
leverages a range of $\beta$ values to learn multiple corresponding latent
representations. First, we obtain a slew of representations by training a
single variational autoencoder (VAE), with a new loss function that controls
the information retained in each latent representation such that the higher
$\beta$ value prioritize disentanglement over reconstruction fidelity. We then,
introduce a non-linear diffusion model that smoothly transitions latent
representations corresponding to different $\beta$ values. This model denoises
towards less disentangled and more informative representations, ultimately
leading to (almost) lossless representations, enabling sharp reconstructions.
Furthermore, our model supports sample generation without input images,
functioning as a standalone generative model. We evaluate our framework in
terms of both disentanglement and generation quality. Additionally, we observe
smooth transitions in the latent spaces with respect to changes in $\beta$,
facilitating consistent manipulation of generated outputs.

</details>


### [173] [Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance](https://arxiv.org/abs/2507.06615)
*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Main category: cs.LG

TL;DR: 提出了一种名为CTPG的新框架，通过跨任务策略指导加速多任务强化学习，利用已掌握任务的策略指导未掌握任务，并结合门控机制提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注参数共享，但忽略了利用跨任务相似性的直接方式，即已掌握任务的策略可以为未掌握任务提供显式指导。

Method: CTPG框架为每个任务训练一个指导策略，从所有任务的控制策略中选择行为策略，生成更好的训练轨迹，并引入两种门控机制优化学习效率。

Result: 实验表明，CTPG与现有参数共享方法结合后，在操作和运动基准测试中性能显著提升。

Conclusion: CTPG是一种通用框架，能够有效利用跨任务相似性，提升多任务强化学习的性能。

Abstract: Multi-task reinforcement learning endeavors to efficiently leverage shared
information across various tasks, facilitating the simultaneous learning of
multiple tasks. Existing approaches primarily focus on parameter sharing with
carefully designed network structures or tailored optimization procedures.
However, they overlook a direct and complementary way to exploit cross-task
similarities: the control policies of tasks already proficient in some skills
can provide explicit guidance for unmastered tasks to accelerate skills
acquisition. To this end, we present a novel framework called Cross-Task Policy
Guidance (CTPG), which trains a guide policy for each task to select the
behavior policy interacting with the environment from all tasks' control
policies, generating better training trajectories. In addition, we propose two
gating mechanisms to improve the learning efficiency of CTPG: one gate filters
out control policies that are not beneficial for guidance, while the other gate
blocks tasks that do not necessitate guidance. CTPG is a general framework
adaptable to existing parameter sharing approaches. Empirical evaluations
demonstrate that incorporating CTPG with these approaches significantly
enhances performance in manipulation and locomotion benchmarks.

</details>


### [174] [Steps Adaptive Decay DPSGD: Enhancing Performance on Imbalanced Datasets with Differential Privacy with HAM10000](https://arxiv.org/abs/2507.06619)
*Xiaobo Huang,Fang Xie*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: When applying machine learning to medical image classification, data leakage
is a critical issue. Previous methods, such as adding noise to gradients for
differential privacy, work well on large datasets like MNIST and CIFAR-100, but
fail on small, imbalanced medical datasets like HAM10000. This is because the
imbalanced distribution causes gradients from minority classes to be clipped
and lose crucial information, while majority classes dominate. This leads the
model to fall into suboptimal solutions early. To address this, we propose
SAD-DPSGD, which uses a linear decaying mechanism for noise and clipping
thresholds. By allocating more privacy budget and using higher clipping
thresholds in the initial training phases, the model avoids suboptimal
solutions and enhances performance. Experiments show that SAD-DPSGD outperforms
Auto-DPSGD on HAM10000, improving accuracy by 2.15% under $\epsilon = 3.0$ ,
$\delta = 10^{-3}$.

</details>


### [175] [UniOD: A Universal Model for Outlier Detection across Diverse Domains](https://arxiv.org/abs/2507.06624)
*Dazhi Fu,Jicong Fan*

Main category: cs.LG

TL;DR: UniOD是一种通用的异常检测框架，利用标记数据集训练单一模型，可跨领域检测异常，避免了繁琐的超参数调优和模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法需要针对不同数据集进行超参数调优和模型训练，耗时且不通用。UniOD旨在解决这一问题，提高效率和准确性。

Method: UniOD将数据集转化为图结构，生成一致的节点特征，并将异常检测任务转化为节点分类问题，实现跨领域泛化。

Result: 在15个基准数据集上测试，UniOD表现优于15种现有方法，验证了其有效性。

Conclusion: UniOD简化了异常检测流程，降低了计算成本，提升了实际应用的便利性和准确性。

Abstract: Outlier detection (OD) seeks to distinguish inliers and outliers in
completely unlabeled datasets and plays a vital role in science and
engineering. Most existing OD methods require troublesome dataset-specific
hyperparameter tuning and costly model training before they can be deployed to
identify outliers. In this work, we propose UniOD, a universal OD framework
that leverages labeled datasets to train a single model capable of detecting
outliers of datasets from diverse domains. Specifically, UniOD converts each
dataset into multiple graphs, produces consistent node features, and frames
outlier detection as a node-classification task, and is able to generalize to
unseen domains. As a result, UniOD avoids effort on model selection and
hyperparameter tuning, reduces computational cost, and effectively utilizes the
knowledge from historical datasets, which improves the convenience and accuracy
in real applications. We evaluate UniOD on 15 benchmark OD datasets against 15
state-of-the-art baselines, demonstrating its effectiveness.

</details>


### [176] [Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2507.06628)
*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Main category: cs.LG

TL;DR: GO-Skill是一种离线多任务强化学习方法，通过目标导向的技能提取和分层策略学习，提升任务间知识共享和性能。


<details>
  <summary>Details</summary>
Motivation: 解决离线多任务强化学习中知识共享的挑战，受人类学习的高效知识抽象启发。

Method: 提出目标导向技能提取（GO-Skill），构建离散技能库，并通过技能增强和分层策略学习优化技能使用。

Result: 在MetaWorld机器人操作任务中验证了GO-Skill的有效性和通用性。

Conclusion: GO-Skill通过技能抽象和动态编排，显著提升了离线多任务强化学习的性能。

Abstract: Offline multi-task reinforcement learning aims to learn a unified policy
capable of solving multiple tasks using only pre-collected task-mixed datasets,
without requiring any online interaction with the environment. However, it
faces significant challenges in effectively sharing knowledge across tasks.
Inspired by the efficient knowledge abstraction observed in human learning, we
propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed
to extract and utilize reusable skills to enhance knowledge transfer and task
performance. Our approach uncovers reusable skills through a goal-oriented
skill extraction process and leverages vector quantization to construct a
discrete skill library. To mitigate class imbalances between broadly applicable
and task-specific skills, we introduce a skill enhancement phase to refine the
extracted skills. Furthermore, we integrate these skills using hierarchical
policy learning, enabling the construction of a high-level policy that
dynamically orchestrates discrete skills to accomplish specific tasks.
Extensive experiments on diverse robotic manipulation tasks within the
MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.

</details>


### [177] [Prevention of Overfitting on Mesh-Structured Data Regressions with a Modified Laplace Operator](https://arxiv.org/abs/2507.06631)
*Enda D. V. Bigarella*

Main category: cs.LG

TL;DR: 提出了一种基于网格数据的过拟合检测与预防方法，通过拉普拉斯算子优化超参数以减少模型振荡。


<details>
  <summary>Details</summary>
Motivation: 解决回归任务中数据过拟合问题，特别是在网格数据结构中，通过利用拉普拉斯算子的二阶导数特性。

Method: 在原始训练网格上计算数据导数作为真实标签，在交错网格上计算训练数据导数以检测振荡，利用拉普拉斯算子损失优化超参数。

Result: 通过最小化模型熵，减少了不必要的振荡，且无需从训练数据中分离测试点。

Conclusion: 该方法有效减少了过拟合，并通过拉普拉斯算子的扩散特性提供了一种替代测试指标。

Abstract: This document reports on a method for detecting and preventing overfitting on
data regressions, herein applied to mesh-like data structures. The mesh
structure allows for the straightforward computation of the Laplace-operator
second-order derivatives in a finite-difference fashion for noiseless data.
Derivatives of the training data are computed on the original training mesh to
serve as a true label of the entropy of the training data. Derivatives of the
trained data are computed on a staggered mesh to identify oscillations in the
interior of the original training mesh cells. The loss of the Laplace-operator
derivatives is used for hyperparameter optimisation, achieving a reduction of
unwanted oscillation through the minimisation of the entropy of the trained
model. In this setup, testing does not require the splitting of points from the
training data, and training is thus directly performed on all available
training points. The Laplace operator applied to the trained data on a
staggered mesh serves as a surrogate testing metric based on diffusion
properties.

</details>


### [178] [Deep Disentangled Representation Network for Treatment Effect Estimation](https://arxiv.org/abs/2507.06650)
*Hui Meng,Keping Yang,Xuyu Peng,Bo Zheng*

Main category: cs.LG

TL;DR: 提出了一种新的个体治疗效果估计算法，结合多头注意力机制和线性正交正则化器，通过软分解预处理变量并消除选择偏差，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从观测数据中估计个体治疗效果是因果推断的核心问题，现有方法在精确分解变量方面存在不足。

Method: 采用多头注意力机制的专家混合模型和线性正交正则化器，软分解预处理变量，并结合重要性采样重加权技术消除选择偏差。

Result: 在公开半合成和真实数据集上的实验表明，算法在个体治疗效果估计上优于现有方法。

Conclusion: 新算法通过软分解和偏差消除，显著提升了个体治疗效果估计的准确性。

Abstract: Estimating individual-level treatment effect from observational data is a
fundamental problem in causal inference and has attracted increasing attention
in the fields of education, healthcare, and public policy.In this work, we
concentrate on the study of disentangled representation methods that have shown
promising outcomes by decomposing observed covariates into instrumental,
confounding, and adjustment factors. However, most of the previous work has
primarily revolved around generative models or hard decomposition methods for
covariates, which often struggle to guarantee the attainment of precisely
disentangled factors. In order to effectively model different causal
relationships, we propose a novel treatment effect estimation algorithm that
incorporates a mixture of experts with multi-head attention and a linear
orthogonal regularizer to softly decompose the pre-treatment variables, and
simultaneously eliminates selection bias via importance sampling re-weighting
techniques. We conduct extensive experiments on both public semi-synthetic and
real-world production datasets. The experimental results clearly demonstrate
that our algorithm outperforms the state-of-the-art methods focused on
individual treatment effects.

</details>


### [179] [Federated Learning Inspired Fuzzy Systems: Decentralized Rule Updating for Privacy and Scalable Decision Making](https://arxiv.org/abs/2507.06652)
*Arthur Alexander Lim,Zhen Bin It,Jovan Bowen Heng,Tee Hui Teo*

Main category: cs.LG

TL;DR: 本文探讨如何通过机器学习和联邦学习改进模糊系统，以处理不确定性，并分析其潜在改进与局限性。


<details>
  <summary>Details</summary>
Motivation: 模糊系统能处理不确定性，但仍有改进空间，尤其是结合机器学习和联邦学习的新技术。

Method: 提出将机器学习和联邦学习的理念应用于模糊系统，例如更新模糊规则以逐步优化系统。

Result: 研究表明这些改进有潜力，但需进一步验证其效果和范围。

Conclusion: 模糊系统结合新技术具有改进潜力，但需深入研究以确定实际效果。

Abstract: Fuzzy systems are a way to allow machines, systems and frameworks to deal
with uncertainty, which is not possible in binary systems that most computers
use. These systems have already been deployed for certain use cases, and fuzzy
systems could be further improved as proposed in this paper. Such technologies
to draw inspiration from include machine learning and federated learning.
Machine learning is one of the recent breakthroughs of technology and could be
applied to fuzzy systems to further improve the results it produces. Federated
learning is also one of the recent technologies that have huge potential, which
allows machine learning training to improve by reducing privacy risk, reducing
burden on networking infrastructure, and reducing latency of the latest model.
Aspects from federated learning could be used to improve federated learning,
such as applying the idea of updating the fuzzy rules that make up a key part
of fuzzy systems, to further improve it over time. This paper discusses how
these improvements would be implemented in fuzzy systems, and how it would
improve fuzzy systems. It also discusses certain limitations on the potential
improvements. It concludes that these proposed ideas and improvements require
further investigation to see how far the improvements are, but the potential is
there to improve fuzzy systems.

</details>


### [180] [Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study](https://arxiv.org/abs/2507.06694)
*Raffael Theiler,Olga Fink*

Main category: cs.LG

TL;DR: 论文提出了一种基于异构图注意力网络的方法，用于多领域电力系统状态预测，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统因可再生能源和分布式能源的引入而变得复杂，需要准确预测短期状态以确保稳定运行。现有方法难以处理多领域异构传感器数据。

Method: 使用异构图注意力网络（Heterogeneous Graph Attention Networks）建模传感器数据的同质和异质关系，特别是针对液压和电气领域的不同时间动态。

Result: 实验表明，该方法在归一化均方根误差上平均优于传统基线35.5%。

Conclusion: 该方法在多领域、多速率电力系统状态预测中表现出色，解决了异构数据整合的挑战。

Abstract: Accurate short-term state forecasting is essential for efficient and stable
operation of modern power systems, especially in the context of increasing
variability introduced by renewable and distributed energy resources. As these
systems evolve rapidly, it becomes increasingly important to reliably predict
their states in the short term to ensure operational stability, support control
decisions, and enable interpretable monitoring of sensor and machine behavior.
Modern power systems often span multiple physical domains - including
electrical, mechanical, hydraulic, and thermal - posing significant challenges
for modeling and prediction. Graph Neural Networks (GNNs) have emerged as a
promising data-driven framework for system state estimation and state
forecasting in such settings. By leveraging the topological structure of sensor
networks, GNNs can implicitly learn inter-sensor relationships and propagate
information across the network. However, most existing GNN-based methods are
designed under the assumption of homogeneous sensor relationships and are
typically constrained to a single physical domain. This limitation restricts
their ability to integrate and reason over heterogeneous sensor data commonly
encountered in real-world energy systems, such as those used in energy
conversion infrastructure. In this work, we propose the use of Heterogeneous
Graph Attention Networks to address these limitations. Our approach models both
homogeneous intra-domain and heterogeneous inter-domain relationships among
sensor data from two distinct physical domains - hydraulic and electrical -
which exhibit fundamentally different temporal dynamics. Experimental results
demonstrate that our method significantly outperforms conventional baselines on
average by 35.5% in terms of normalized root mean square error, confirming its
effectiveness in multi-domain, multi-rate power system state forecasting.

</details>


### [181] [Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement](https://arxiv.org/abs/2507.06701)
*Michael Bloesch,Markus Wulfmeier,Philemon Brakel,Todor Davchev,Martina Zambelli,Jost Tobias Springenberg,Abbas Abdolmaleki,William F Whitney,Nicolas Heess,Roland Hafner,Martin Riedmiller*

Main category: cs.LG

TL;DR: 论文研究了模仿学习从观察中（IfO）的改进方法，通过适应无动作演示的数据分布，提出了一种基于强化学习的模仿学习方法。


<details>
  <summary>Details</summary>
Motivation: 当前IfO研究集中于理想化场景，数据分布多为双峰质量，限制了结果的实用性。本文旨在探索更复杂的数据分布，并提出一种方法以实现迭代式自我改进的模仿学习。

Method: 提出了一种基于强化学习的模仿学习方法，利用价值函数在专家和非专家数据间传递信息，适应无动作演示的数据分布。

Result: 通过全面评估，揭示了不同数据分布与算法适用性的关系，并指出了现有方法的局限性。

Conclusion: 研究结果为开发更鲁棒和实用的IfO技术提供了有价值的见解，推动了可扩展行为学习的进展。

Abstract: Imitation Learning from Observation (IfO) offers a powerful way to learn
behaviors at large-scale: Unlike behavior cloning or offline reinforcement
learning, IfO can leverage action-free demonstrations and thus circumvents the
need for costly action-labeled demonstrations or reward functions. However,
current IfO research focuses on idealized scenarios with mostly bimodal-quality
data distributions, restricting the meaningfulness of the results. In contrast,
this paper investigates more nuanced distributions and introduces a method to
learn from such data, moving closer to a paradigm in which imitation learning
can be performed iteratively via self-improvement. Our method adapts RL-based
imitation learning to action-free demonstrations, using a value function to
transfer information between expert and non-expert data. Through comprehensive
evaluation, we delineate the relation between different data distributions and
the applicability of algorithms and highlight the limitations of established
methods. Our findings provide valuable insights for developing more robust and
practical IfO techniques on a path to scalable behaviour learning.

</details>


### [182] [PINN-Obs: Physics-Informed Neural Network-Based Observer for Nonlinear Dynamical Systems](https://arxiv.org/abs/2507.06712)
*Ayoub Farkane,Mohamed Boutayeb,Mustapha Oudani,Mounir Ghogho*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息神经网络的非线性系统状态估计方法（PINN-Obs），通过自适应学习增益矩阵实现高精度估计，并在多种非线性系统中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 非线性动态系统的状态估计在部分和噪声测量下具有挑战性，传统方法需要显式系统变换或线性化，限制了其应用。

Method: 直接整合系统动力学和传感器数据到物理信息学习过程中，自适应学习最优增益矩阵。

Result: 理论分析证明了收敛性，实验验证了在多种非线性系统中的高精度和鲁棒性。

Conclusion: PINN-Obs在非线性系统状态估计中表现出更高的准确性和适应性，优于现有方法。

Abstract: State estimation for nonlinear dynamical systems is a critical challenge in
control and engineering applications, particularly when only partial and noisy
measurements are available. This paper introduces a novel Adaptive
Physics-Informed Neural Network-based Observer (PINN-Obs) for accurate state
estimation in nonlinear systems. Unlike traditional model-based observers,
which require explicit system transformations or linearization, the proposed
framework directly integrates system dynamics and sensor data into a
physics-informed learning process. The observer adaptively learns an optimal
gain matrix, ensuring convergence of the estimated states to the true system
states. A rigorous theoretical analysis establishes formal convergence
guarantees, demonstrating that the proposed approach achieves uniform error
minimization under mild observability conditions. The effectiveness of PINN-Obs
is validated through extensive numerical simulations on diverse nonlinear
systems, including an induction motor model, a satellite motion system, and
benchmark academic examples. Comparative experimental studies against existing
observer designs highlight its superior accuracy, robustness, and adaptability.

</details>


### [183] [Mathematical artificial data for operator learning](https://arxiv.org/abs/2507.06752)
*Heng Wu,Benzhuo Lu*

Main category: cs.LG

TL;DR: MAD框架结合物理定律与数据驱动学习，通过生成物理嵌入的解析解和合成数据，解决了传统方法对标记数据依赖和效率-精度权衡的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在解决微分方程时面临标记数据成本高或效率-精度权衡的局限性，需要一种更高效且严谨的新方法。

Method: 提出MAD框架，利用微分方程的数学结构生成物理嵌入的解析解和合成数据，实现无需实验或模拟数据的算子学习。

Result: 在2D参数化问题中展示了MAD的泛化能力和高效性/准确性，适用于多种微分方程场景。

Conclusion: MAD框架有望成为科学计算中物理信息机器智能的通用范式。

Abstract: Machine learning has emerged as a transformative tool for solving
differential equations (DEs), yet prevailing methodologies remain constrained
by dual limitations: data-driven methods demand costly labeled datasets while
model-driven techniques face efficiency-accuracy trade-offs. We present the
Mathematical Artificial Data (MAD) framework, a new paradigm that integrates
physical laws with data-driven learning to facilitate large-scale operator
discovery. By exploiting DEs' intrinsic mathematical structure to generate
physics-embedded analytical solutions and associated synthetic data, MAD
fundamentally eliminates dependence on experimental or simulated training data.
This enables computationally efficient operator learning across multi-parameter
systems while maintaining mathematical rigor. Through numerical demonstrations
spanning 2D parametric problems where both the boundary values and source term
are functions, we showcase MAD's generalizability and superior
efficiency/accuracy across various DE scenarios. This
physics-embedded-data-driven framework and its capacity to handle complex
parameter spaces gives it the potential to become a universal paradigm for
physics-informed machine intelligence in scientific computing.

</details>


### [184] [Robust Deep Network Learning of Nonlinear Regression Tasks by Parametric Leaky Exponential Linear Units (LELUs) and a Diffusion Metric](https://arxiv.org/abs/2507.06765)
*Enda D. V. Bigarella*

Main category: cs.LG

TL;DR: 提出了一种参数化激活函数（Leaky Exponential Linear Unit），用于改善多维非线性数据回归性能，并通过新的扩散损失指标评估模型过拟合。


<details>
  <summary>Details</summary>
Motivation: 非线性激活函数对学习非线性数据集至关重要，但其平滑性和梯度特性会影响大型神经网络的性能，尤其是过拟合和模型参数敏感性。

Method: 提出了一种平滑且具有非零梯度的Leaky Exponential Linear Unit激活函数，并引入扩散损失指标评估模型性能。

Result: 改进的激活函数在性能上优于传统平滑但梯度消失的激活函数（如ELU、SiLU）和非平滑激活函数（如RELU、Leaky-RELU）。

Conclusion: 平滑且具有非零梯度的激活函数能有效提升模型性能，减少过拟合，扩散损失指标为模型评估提供了新工具。

Abstract: This document proposes a parametric activation function (ac.f.) aimed at
improving multidimensional nonlinear data regression. It is a established
knowledge that nonlinear ac.f.'s are required for learning nonlinear datasets.
This work shows that smoothness and gradient properties of the ac.f. further
impact the performance of large neural networks in terms of overfitting and
sensitivity to model parameters. Smooth but vanishing-gradient ac.f.'s such as
ELU or SiLU have limited performance and non-smooth ac.f.'s such as RELU and
Leaky-RELU further impart discontinuity in the trained model. Improved
performance is demonstrated with a smooth "Leaky Exponential Linear Unit", with
non-zero gradient that can be trained. A novel diffusion-loss metric is also
proposed to gauge the performance of the trained models in terms of
overfitting.

</details>


### [185] [Mutual Information Free Topological Generalization Bounds via Stability](https://arxiv.org/abs/2507.06775)
*Mario Tuci,Lennart Bastian,Benjamin Dupuis,Nassir Navab,Tolga Birdal,Umut Şimşekli*

Main category: cs.LG

TL;DR: 论文提出了一种新的拓扑泛化界，避免了复杂的信息论项，通过轨迹稳定性框架将泛化误差与拓扑数据分析和算法稳定性联系起来。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑泛化界依赖复杂的信息论项，难以应用于实际算法（如ADAM），因此需要一种更易解释且实用的泛化界。

Method: 引入轨迹稳定性框架，扩展假设集稳定性概念，通过拓扑数据分析量化优化器轨迹的复杂性。

Result: 实验证明，拓扑数据分析项在泛化界中起关键作用，尤其在训练样本增加时。

Conclusion: 新框架提供了更直观的拓扑泛化界，解释了其在实际中的成功应用。

Abstract: Providing generalization guarantees for stochastic optimization algorithms is
a major challenge in modern learning theory. Recently, several studies
highlighted the impact of the geometry of training trajectories on the
generalization error, both theoretically and empirically. Among these works, a
series of topological generalization bounds have been proposed, relating the
generalization error to notions of topological complexity that stem from
topological data analysis (TDA). Despite their empirical success, these bounds
rely on intricate information-theoretic (IT) terms that can be bounded in
specific cases but remain intractable for practical algorithms (such as ADAM),
potentially reducing the relevance of the derived bounds. In this paper, we
seek to formulate comprehensive and interpretable topological generalization
bounds free of intractable mutual information terms. To this end, we introduce
a novel learning theoretic framework that departs from the existing strategies
via proof techniques rooted in algorithmic stability. By extending an existing
notion of \textit{hypothesis set stability}, to \textit{trajectory stability},
we prove that the generalization error of trajectory-stable algorithms can be
upper bounded in terms of (i) TDA quantities describing the complexity of the
trajectory of the optimizer in the parameter space, and (ii) the trajectory
stability parameter of the algorithm. Through a series of experimental
evaluations, we demonstrate that the TDA terms in the bound are of great
importance, especially as the number of training samples grows. This ultimately
forms an explanation of the empirical success of the topological generalization
bounds.

</details>


### [186] [Speech Tokenizer is Key to Consistent Representation](https://arxiv.org/abs/2507.06802)
*Wonjin Jung,Sungil Kang,Dong-Yeon Cho*

Main category: cs.LG

TL;DR: 提出一种新型语音分词器，同时编码语言和声学信息，提升语音表示保真度，适用于多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于RVQ的分词器常忽略声学特征，无法保留韵律和情感内容。

Method: 提出一种同时编码语言和声学信息的先进方法。

Result: 实证评估显示，该方法在语音编码、语音转换、情感识别和多模态语言建模中表现优异。

Conclusion: 该方法无需额外训练，具有广泛适用性，是推动AI语音处理的关键工具。

Abstract: Speech tokenization is crucial in digital speech processing, converting
continuous speech signals into discrete units for various computational tasks.
This paper introduces a novel speech tokenizer with broad applicability across
downstream tasks. While recent advances in residual vector quantization (RVQ)
have incorporated semantic elements, they often neglect critical acoustic
features. We propose an advanced approach that simultaneously encodes both
linguistic and acoustic information, preserving prosodic and emotional content.
Our method significantly enhances speech representation fidelity across diverse
applications. Empirical evaluations demonstrate its effectiveness in speech
coding, voice conversion, emotion recognition, and multimodal language
modeling, without requiring additional training. This versatility underscores
its potential as a key tool for advancing AI-driven speech processing.

</details>


### [187] [Intrinsic Training Signals for Federated Learning Aggregation](https://arxiv.org/abs/2507.06813)
*Cosimo Fiorini,Matteo Mosconi,Pietro Buzzega,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: LIVAR提出了一种无需架构修改或损失函数变化的联邦学习方法，通过利用训练信号实现高效模型聚合。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在聚合客户端分类头和调整主干参数时需要修改架构或损失函数，LIVAR旨在利用现有训练信号实现高效聚合。

Method: LIVAR采用方差加权的分类器聚合方案和基于SHAP分析的LoRA合并技术。

Result: LIVAR在多个基准测试中达到最优性能，且与现有FL方法无缝集成。

Conclusion: LIVAR证明仅通过现有训练信号即可实现高效模型聚合，为联邦学习提供了新范式。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients while preserving data privacy. While existing approaches
for aggregating client-specific classification heads and adapted backbone
parameters require architectural modifications or loss function changes, our
method uniquely leverages intrinsic training signals already available during
standard optimization. We present LIVAR (Layer Importance and VARiance-based
merging), which introduces: i) a variance-weighted classifier aggregation
scheme using naturally emergent feature statistics, and ii) an
explainability-driven LoRA merging technique based on SHAP analysis of existing
update parameter patterns. Without any architectural overhead, LIVAR achieves
state-of-the-art performance on multiple benchmarks while maintaining seamless
integration with existing FL methods. This work demonstrates that effective
model merging can be achieved solely through existing training signals,
establishing a new paradigm for efficient federated model aggregation. The code
will be made publicly available upon acceptance.

</details>


### [188] [Comprehensive Evaluation of Prototype Neural Networks](https://arxiv.org/abs/2507.06819)
*Philipp Schlinge,Steffen Meinert,Martin Atzmueller*

Main category: cs.LG

TL;DR: 本文对原型模型（如ProtoPNet、ProtoPool和PIPNet）进行了深入分析，提出了一套全面的评估指标，包括新提出的指标，以补充模型可解释性分析。实验涵盖了多种数据集，并提供了开源代码库。


<details>
  <summary>Details</summary>
Motivation: 原型模型是可解释人工智能（XAI）和可解释机器学习的重要方法，但缺乏全面的评估指标和工具。本文旨在填补这一空白。

Method: 使用ProtoPNet、ProtoPool和PIPNet等原型模型，结合标准和新提出的指标，在多样化数据集上进行评估。

Result: 实验结果表明，原型模型在多种任务（如细粒度分类、非独立同分布设置和多标签分类）中表现良好。

Conclusion: 本文提供了一套全面的评估指标和开源工具，为原型模型的可解释性研究提供了便利和扩展性。

Abstract: Prototype models are an important method for explainable artificial
intelligence (XAI) and interpretable machine learning. In this paper, we
perform an in-depth analysis of a set of prominent prototype models including
ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive
set of metrics. In addition to applying standard metrics from literature, we
propose several new metrics to further complement the analysis of model
interpretability. In our experimentation, we apply the set of prototype models
on a diverse set of datasets including fine-grained classification, Non-IID
settings and multi-label classification to further contrast the performance.
Furthermore, we also provide our code as an open-source library, which
facilitates simple application of the metrics itself, as well as extensibility
- providing the option for easily adding new metrics and models.
https://github.com/uos-sis/quanproto

</details>


### [189] [Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning](https://arxiv.org/abs/2507.06825)
*Matej Straka,Martin Schmid*

Main category: cs.LG

TL;DR: 介绍了一个基于Generals.io的实时策略游戏环境，兼容Gymnasium和PettingZoo，支持高性能运行，并训练了一个顶级水平的参考智能体。


<details>
  <summary>Details</summary>
Motivation: 为多智能体强化学习研究提供一个易用且具有挑战性的平台。

Method: 结合监督预训练和自对弈训练智能体，并采用基于潜力的奖励塑造和记忆特征加速学习。

Result: 智能体在36小时内达到1v1人类排行榜前0.003%水平。

Conclusion: 该环境和智能体为多智能体强化学习研究提供了高效且竞争性的基准。

Abstract: We introduce a real-time strategy game environment built on Generals.io, a
game that hosts thousands of active players each week across multiple game
formats. Our environment is fully compatible with Gymnasium and PettingZoo,
capable of running thousands of frames per second on commodity hardware. Our
reference agent -- trained with supervised pre-training and self-play -- hits
the top 0.003\% of the 1v1 human leaderboard after just 36 hours on a single
H100 GPU. To accelerate learning, we incorporate potential-based reward shaping
and memory features. Our contributions -- a modular RTS benchmark and a
competitive, state-of-the-art baseline agent -- provide an accessible yet
challenging platform for advancing multi-agent reinforcement learning research.

</details>


### [190] [Scalable Gaussian Processes: Advances in Iterative Methods and Pathwise Conditioning](https://arxiv.org/abs/2507.06839)
*Jihao Andreas Lin*

Main category: cs.LG

TL;DR: 论文提出了一种结合迭代方法和路径条件化的方法，以提升高斯过程在大规模数据中的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 高斯过程在经典框架下难以适应大规模数据和现代硬件并行计算的需求，因此需要开发更高效的技术。

Method: 通过将迭代线性系统求解器与路径条件化结合，将昂贵计算转化为线性方程组求解，降低内存需求。

Result: 显著减少了内存需求，适用于更大规模数据，并优化了现代硬件上的矩阵乘法操作。

Conclusion: 该方法为高斯过程在现代大规模场景中的应用提供了高效解决方案。

Abstract: Gaussian processes are a powerful framework for uncertainty-aware function
approximation and sequential decision-making. Unfortunately, their classical
formulation does not scale gracefully to large amounts of data and modern
hardware for massively-parallel computation, prompting many researchers to
develop techniques which improve their scalability. This dissertation focuses
on the powerful combination of iterative methods and pathwise conditioning to
develop methodological contributions which facilitate the use of Gaussian
processes in modern large-scale settings. By combining these two techniques
synergistically, expensive computations are expressed as solutions to systems
of linear equations and obtained by leveraging iterative linear system solvers.
This drastically reduces memory requirements, facilitating application to
significantly larger amounts of data, and introduces matrix multiplication as
the main computational operation, which is ideal for modern hardware.

</details>


### [191] [DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models](https://arxiv.org/abs/2507.06853)
*Liang Wang,Yu Rong,Tingyang Xu,Zhenyi Zhong,Zhiyuan Liu,Pengju Wang,Deli Zhao,Qiang Liu,Shu Wu,Liang Wang*

Main category: cs.LG

TL;DR: DiffSpectra是一种基于扩散模型的生成框架，直接从多模态光谱数据推断2D和3D分子结构，解决了传统方法和现有机器学习方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统分子结构解析方法依赖专家解释且缺乏扩展性，现有机器学习方法依赖有限库，难以推广到新分子。DiffSpectra旨在通过生成模型解决这些问题。

Method: DiffSpectra采用扩散模型，结合SE(3)-等变架构的Denoising网络和基于Transformer的光谱编码器SpecFormer，实现多模态光谱数据的条件生成。

Result: 实验表明DiffSpectra在结构解析中表现出色，top-1准确率为16.01%，top-20准确率为96.86%。3D几何建模和多模态条件显著提升性能。

Conclusion: DiffSpectra是首个统一多模态光谱推理和2D/3D生成建模的框架，为分子结构解析提供了有效解决方案。

Abstract: Molecular structure elucidation from spectra is a foundational problem in
chemistry, with profound implications for compound identification, synthesis,
and drug development. Traditional methods rely heavily on expert interpretation
and lack scalability. Pioneering machine learning methods have introduced
retrieval-based strategies, but their reliance on finite libraries limits
generalization to novel molecules. Generative models offer a promising
alternative, yet most adopt autoregressive SMILES-based architectures that
overlook 3D geometry and struggle to integrate diverse spectral modalities. In
this work, we present DiffSpectra, a generative framework that directly infers
both 2D and 3D molecular structures from multi-modal spectral data using
diffusion models. DiffSpectra formulates structure elucidation as a conditional
generation process. Its denoising network is parameterized by Diffusion
Molecule Transformer, an SE(3)-equivariant architecture that integrates
topological and geometric information. Conditioning is provided by SpecFormer,
a transformer-based spectral encoder that captures intra- and inter-spectral
dependencies from multi-modal spectra. Extensive experiments demonstrate that
DiffSpectra achieves high accuracy in structure elucidation, recovering exact
structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through
sampling. The model benefits significantly from 3D geometric modeling,
SpecFormer pre-training, and multi-modal conditioning. These results highlight
the effectiveness of spectrum-conditioned diffusion modeling in addressing the
challenge of molecular structure elucidation. To our knowledge, DiffSpectra is
the first framework to unify multi-modal spectral reasoning and joint 2D/3D
generative modeling for de novo molecular structure elucidation.

</details>


### [192] [Episodic Contextual Bandits with Knapsacks under Conversion Models](https://arxiv.org/abs/2507.06859)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 研究在线决策者在非平稳上下文资源分配问题中的表现，提出一种算法实现亚线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决动态定价和拍卖等应用中资源分配的非平稳性和上下文多样性问题。

Method: 设计在线算法，利用置信边界预言机处理无界状态空间。

Result: 算法在T次情节中实现亚线性遗憾，并在特定设置下提供改进的遗憾边界。

Conclusion: 框架为上下文BwK问题提供了新的解决方案，尤其在未标记特征数据场景下表现优越。

Abstract: We study an online setting, where a decision maker (DM) interacts with
contextual bandit-with-knapsack (BwK) instances in repeated episodes. These
episodes start with different resource amounts, and the contexts' probability
distributions are non-stationary in an episode. All episodes share the same
latent conversion model, which governs the random outcome contingent upon a
request's context and an allocation decision. Our model captures applications
such as dynamic pricing on perishable resources with episodic replenishment,
and first price auctions in repeated episodes with different starting budgets.
We design an online algorithm that achieves a regret sub-linear in $T$, the
number of episodes, assuming access to a \emph{confidence bound oracle} that
achieves an $o(T)$-regret. Such an oracle is readily available from existing
contextual bandit literature. We overcome the technical challenge with
arbitrarily many possible contexts, which leads to a reinforcement learning
problem with an unbounded state space. Our framework provides improved regret
bounds in certain settings when the DM is provided with unlabeled feature data,
which is novel to the contextual BwK literature.

</details>


### [193] [Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model](https://arxiv.org/abs/2507.06892)
*Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao*

Main category: cs.LG

TL;DR: 论文提出ReMix方法，通过利用离策略数据改进现有强化微调方法，显著降低训练成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法多为同策略RL，未能充分利用历史数据，导致计算和时间成本高昂。

Method: ReMix结合混合策略近端策略梯度、KL凸约束策略和政策重生技术，实现高效训练和稳定改进。

Result: ReMix在多个数学推理基准测试中表现优异，训练成本降低30至450倍。

Conclusion: ReMix为强化微调提供了一种高效且经济的解决方案，并揭示了离策略数据的新见解。

Abstract: Reinforcement Learning (RL) has demonstrated its potential to improve the
reasoning ability of Large Language Models (LLMs). One major limitation of most
existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL
in nature, i.e., data generated during the past learning process is not fully
utilized. This inevitably comes at a significant cost of compute and time,
posing a stringent bottleneck on continuing economic and efficient scaling. To
this end, we launch the renaissance of off-policy RL and propose Reincarnating
Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable
on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix
consists of three major components: (1) Mix-policy proximal policy gradient
with an increased Update-To-Data (UTD) ratio for efficient training; (2)
KL-Convex policy constraint to balance the trade-off between stability and
flexibility; (3) Policy reincarnation to achieve a seamless transition from
efficient early-stage learning to steady asymptotic improvement. In our
experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base
models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with
0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B
model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math
reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and
MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level
performance with an over 30x to 450x reduction in training cost in terms of
rollout data volume. In addition, we reveal insightful findings via
multifaceted analysis, including the implicit preference for shorter responses
due to the Whipping Effect of off-policy discrepancy, the collapse mode of
self-reflection behavior under the presence of severe off-policyness, etc.

</details>


### [194] [Horizontal and Vertical Federated Causal Structure Learning via Higher-order Cumulants](https://arxiv.org/abs/2507.06888)
*Wei Chen,Wanyang Gu,Linjun Peng,Ruichu Cai,Zhifeng Hao,Kun Zhang*

Main category: cs.LG

TL;DR: 提出一种联邦因果发现方法，结合水平和垂直联邦设置，利用高阶累积量构建全局因果图。


<details>
  <summary>Details</summary>
Motivation: 解决现有联邦因果学习方法仅适用于水平联邦设置的问题，避免因变量不完整导致的虚假因果关系。

Method: 通过聚合客户端的高阶累积量信息构建全局估计，递归识别因果源，生成全局因果强度矩阵。

Result: 在合成和真实数据实验中表现优越，能重建因果图并估计因果强度系数。

Conclusion: 该方法在水平和垂直联邦设置下均有效，解决了变量不完整带来的问题。

Abstract: Federated causal discovery aims to uncover the causal relationships between
entities while protecting data privacy, which has significant importance and
numerous applications in real-world scenarios. Existing federated causal
structure learning methods primarily focus on horizontal federated settings.
However, in practical situations, different clients may not necessarily contain
data on the same variables. In a single client, the incomplete set of variables
can easily lead to spurious causal relationships, thereby affecting the
information transmitted to other clients. To address this issue, we
comprehensively consider causal structure learning methods under both
horizontal and vertical federated settings. We provide the identification
theories and methods for learning causal structure in the horizontal and
vertical federal setting via higher-order cumulants. Specifically, we first
aggregate higher-order cumulant information from all participating clients to
construct global cumulant estimates. These global estimates are then used for
recursive source identification, ultimately yielding a global causal strength
matrix. Our approach not only enables the reconstruction of causal graphs but
also facilitates the estimation of causal strength coefficients. Our algorithm
demonstrates superior performance in experiments conducted on both synthetic
data and real-world data.

</details>


### [195] [Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams](https://arxiv.org/abs/2507.06901)
*Abolfazl Zarghani,Sadegh Abedi*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习（RL）的动态滑动窗口优化方法（RL-Window），用于处理多维数据流，解决了固定窗口难以适应动态变化的问题。


<details>
  <summary>Details</summary>
Motivation: 多维数据流（如IoT、金融市场和实时分析）具有高速度、无界性和复杂的维度间依赖关系，固定窗口难以适应动态变化（如概念漂移或突发模式），需要自适应方法。

Method: 将窗口大小选择问题建模为RL问题，利用Dueling Deep Q-Network（DQN）和优先级经验回放，学习基于流特征（如方差、相关性和时间趋势）的自适应策略。

Result: 在UCI HAR、PAMAP2和Yahoo! Finance Stream等基准数据集上，RL-Window在分类精度、漂移鲁棒性和计算效率上优于ADWIN和CNN-Adaptive等现有方法。

Conclusion: RL-Window具有适应性和稳定性，适用于实时应用，并通过扩展指标（如能效和延迟）进一步验证了其优势。

Abstract: Multi-dimensional data streams, prevalent in applications like IoT, financial
markets, and real-time analytics, pose significant challenges due to their high
velocity, unbounded nature, and complex inter-dimensional dependencies. Sliding
window techniques are critical for processing such streams, but fixed-size
windows struggle to adapt to dynamic changes like concept drift or bursty
patterns. This paper proposes a novel reinforcement learning (RL)-based
approach to dynamically optimize sliding window sizes for multi-dimensional
data streams. By formulating window size selection as an RL problem, we enable
an agent to learn an adaptive policy based on stream characteristics, such as
variance, correlations, and temporal trends. Our method, RL-Window, leverages a
Dueling Deep Q-Network (DQN) with prioritized experience replay to handle
non-stationarity and high-dimensionality. Evaluations on benchmark datasets
(UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms
state-of-the-art methods like ADWIN and CNN-Adaptive in classification
accuracy, drift robustness, and computational efficiency. Additional
qualitative analyses, extended metrics (e.g., energy efficiency, latency), and
a comprehensive dataset characterization further highlight its adaptability and
stability, making it suitable for real-time applications.

</details>


### [196] [Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting](https://arxiv.org/abs/2507.06907)
*Linyun Gao,Qiang Wen,Fumio Machida*

Main category: cs.LG

TL;DR: 提出了一种基于N版本机器学习（NVML）的框架，通过安全感知加权软投票机制提升交通标志识别系统在对抗攻击下的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中交通标志识别易受对抗攻击影响，威胁驾驶安全，需提升系统鲁棒性。

Method: 采用N版本机器学习框架，结合FMEA评估安全风险，动态分配权重，测试了三种投票机制对抗FGSM和PGD攻击的效果。

Result: 实验表明，NVML显著提升了交通标志识别系统在对抗条件下的鲁棒性和安全性。

Conclusion: NVML框架有效增强了对抗攻击下的系统安全性，为自动驾驶安全提供了新思路。

Abstract: Autonomous driving is rapidly advancing as a key application of machine
learning, yet ensuring the safety of these systems remains a critical
challenge. Traffic sign recognition, an essential component of autonomous
vehicles, is particularly vulnerable to adversarial attacks that can compromise
driving safety. In this paper, we propose an N-version machine learning (NVML)
framework that integrates a safety-aware weighted soft voting mechanism. Our
approach utilizes Failure Mode and Effects Analysis (FMEA) to assess potential
safety risks and assign dynamic, safety-aware weights to the ensemble outputs.
We evaluate the robustness of three-version NVML systems employing various
voting mechanisms against adversarial samples generated using the Fast Gradient
Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks. Experimental
results demonstrate that our NVML approach significantly enhances the
robustness and safety of traffic sign recognition systems under adversarial
conditions.

</details>


### [197] [What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models](https://arxiv.org/abs/2507.06952)
*Keyon Vafa,Peter G. Chang,Ashesh Rambachan,Sendhil Mullainathan*

Main category: cs.LG

TL;DR: 论文提出了一种评估基础模型的方法，通过生成合成数据集测试模型是否真正理解底层世界模型，发现模型虽能完成训练任务，但未能发展出与底层模型一致的归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型是否真正捕捉到更深层次的结构，而不仅仅是完成表面任务。

Method: 开发了一种称为“归纳偏置探针”的技术，通过合成数据集测试模型的适应能力。

Result: 基础模型在训练任务上表现优秀，但在新任务中未能发展出与底层世界模型一致的归纳偏置，尤其是在轨道轨迹任务中未能应用牛顿力学。

Conclusion: 基础模型可能仅发展出任务特定的启发式方法，缺乏泛化能力。

Abstract: Foundation models are premised on the idea that sequence prediction can
uncover deeper domain understanding, much like how Kepler's predictions of
planetary motion later led to the discovery of Newtonian mechanics. However,
evaluating whether these models truly capture deeper structure remains a
challenge. We develop a technique for evaluating foundation models that
examines how they adapt to synthetic datasets generated from some postulated
world model. Our technique measures whether the foundation model's inductive
bias aligns with the world model, and so we refer to it as an inductive bias
probe. Across multiple domains, we find that foundation models can excel at
their training tasks yet fail to develop inductive biases towards the
underlying world model when adapted to new tasks. We particularly find that
foundation models trained on orbital trajectories consistently fail to apply
Newtonian mechanics when adapted to new physics tasks. Further analysis reveals
that these models behave as if they develop task-specific heuristics that fail
to generalize.

</details>


### [198] [Noisy PDE Training Requires Bigger PINNs](https://arxiv.org/abs/2507.06967)
*Sebastien Andre-Sloan,Anirbit Mukherjee,Matthew Colbrook*

Main category: cs.LG

TL;DR: 论文研究了在噪声数据下，物理信息神经网络（PINNs）逼近偏微分方程（PDEs）解的能力，并证明了网络规模与监督标签噪声方差的关系。


<details>
  <summary>Details</summary>
Motivation: 探讨在噪声数据条件下，PINNs如何有效降低经验风险，填补了相关理论空白。

Method: 通过理论分析，证明了神经网络规模与监督标签噪声方差的下界关系，并通过实验验证了结论。

Result: 发现增加噪声监督标签数量并不能无限制降低经验风险，且PINNs在特定条件下可实现低于噪声方差的经验风险。

Conclusion: 为理解噪声环境下训练PINNs的参数需求提供了理论基础，并以HJB PDE为例验证了结论。

Abstract: Physics-Informed Neural Networks (PINNs) are increasingly used to approximate
solutions of partial differential equations (PDEs), especially in high
dimensions. In real-world applications, data samples are noisy, so it is
important to know when a predictor can still achieve low empirical risk.
However, little is known about the conditions under which a PINN can do so
effectively. We prove a lower bound on the size of neural networks required for
the supervised PINN empirical risk to fall below the variance of noisy
supervision labels. Specifically, if a predictor achieves an empirical risk
$O(\eta)$ below $\sigma^2$ (variance of supervision data), then necessarily
$d_N\log d_N\gtrsim N_s \eta^2$, where $N_s$ is the number of samples and $d_N$
is the number of trainable parameters of the PINN. A similar constraint applies
to the fully unsupervised PINN setting when boundary labels are sampled
noisily. Consequently, increasing the number of noisy supervision labels alone
does not provide a ``free lunch'' in reducing empirical risk. We also show
empirically that PINNs can indeed achieve empirical risks below $\sigma^2$
under such conditions. As a case study, we investigate PINNs applied to the
Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for
quantitatively understanding the parameter requirements for training PINNs in
the presence of noise.

</details>


### [199] [Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy](https://arxiv.org/abs/2507.06969)
*Bogdan Kulynych,Juan Felipe Gomez,Georgios Kaissis,Jamie Hayes,Borja Balle,Flavio du Pin Calmon,Jean Louis Raisaro*

Main category: cs.LG

TL;DR: 论文提出了一种基于假设检验解释的差分隐私（f-DP）方法，统一了重识别、属性推断和数据重构风险的界限，提供了更紧致的隐私保护评估和校准框架。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私机制在隐私参数与具体风险（如重识别、属性推断和数据重构）之间的映射过于悲观且不一致，难以解释和校准。

Method: 利用f-DP的假设检验解释，推导出统一的攻击成功界限，适用于多种攻击场景，并可调整以评估任意基线风险水平。

Result: 实验表明，该方法比ε-DP、Rényi DP和集中DP更紧致，噪声校准可减少20%的噪声需求，并在文本分类任务中提高15%以上的准确率。

Conclusion: 该统一视角为差分隐私的保护程度提供了原则性框架，能针对特定风险水平进行解释和校准。

Abstract: Differentially private (DP) mechanisms are difficult to interpret and
calibrate because existing methods for mapping standard privacy parameters to
concrete privacy risks -- re-identification, attribute inference, and data
reconstruction -- are both overly pessimistic and inconsistent. In this work,
we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that
bounds on attack success can take the same unified form across
re-identification, attribute inference, and data reconstruction risks. Our
unified bounds are (1) consistent across a multitude of attack settings, and
(2) tunable, enabling practitioners to evaluate risk with respect to arbitrary
(including worst-case) levels of baseline risk. Empirically, our results are
tighter than prior methods using $\varepsilon$-DP, R\'enyi DP, and concentrated
DP. As a result, calibrating noise using our bounds can reduce the required
noise by 20% at the same risk level, which yields, e.g., more than 15pp
accuracy increase in a text classification task. Overall, this unifying
perspective provides a principled framework for interpreting and calibrating
the degree of protection in DP against specific levels of re-identification,
attribute inference, or data reconstruction risk.

</details>


### [200] [A Principled Framework for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06979)
*Panagiotis Koromilas,Efthymios Georgiou,Giorgos Bouritsas,Theodoros Giannakopoulos,Mihalis A. Nicolaou,Yannis Panagakis*

Main category: cs.LG

TL;DR: 论文提出两种新的损失函数（MV-InfoNCE和MV-DHEL），解决了多视图对比学习中存在的四个关键问题，并在实验中验证了其优越性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前多视图对比学习方法存在四个关键局限性（如目标冲突、视图交互建模不足等），无法充分利用多视图的优势。

Method: 提出两种新损失函数：MV-InfoNCE（同时建模所有视图交互）和MV-DHEL（解耦对齐与均匀性）。

Result: 在ImageNet1K等数据集上，新方法优于现有多视图方法，并能扩展到多模态数据。MV-DHEL在五视图以上能有效缓解维度崩溃。

Conclusion: 新方法为多视图对比学习提供了理论支持，并展示了其在性能和扩展性上的优势。

Abstract: Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning
(SSL), typically relies on pairs of data views generated through augmentation.
While multiple augmentations per instance (more than two) improve
generalization in supervised learning, current CL methods handle additional
views suboptimally by simply aggregating different pairwise objectives. This
approach suffers from four critical limitations: (L1) it utilizes multiple
optimization terms per data point resulting to conflicting objectives, (L2) it
fails to model all interactions across views and data points, (L3) it inherits
fundamental limitations (e.g. alignment-uniformity coupling) from pairwise CL
losses, and (L4) it prevents fully realizing the benefits of increased view
multiplicity observed in supervised settings. We address these limitations
through two novel loss functions: MV-InfoNCE, which extends InfoNCE to
incorporate all possible view interactions simultaneously in one term per data
point, and MV-DHEL, which decouples alignment from uniformity across views
while scaling interaction complexity with view multiplicity. Both approaches
are theoretically grounded - we prove they asymptotically optimize for
alignment of all views and uniformity, providing principled extensions to
multi-view contrastive learning. Our empirical results on ImageNet1K and three
other datasets demonstrate that our methods consistently outperform existing
multi-view approaches and effectively scale with increasing view multiplicity.
We also apply our objectives to multimodal data and show that, in contrast to
other contrastive objectives, they can scale beyond just two modalities. Most
significantly, ablation studies reveal that MV-DHEL with five or more views
effectively mitigates dimensionality collapse by fully utilizing the embedding
space, thereby delivering multi-view benefits observed in supervised learning.

</details>


### [201] [Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing](https://arxiv.org/abs/2507.06996)
*Eunbyeol Cho,Jiyoun Kim,Minjae Lee,Sungjin Park,Edward Choi*

Main category: cs.LG

TL;DR: RawMed是一个生成多表时间序列电子健康记录（EHR）数据的框架，通过文本表示和压缩技术，无需复杂预处理即可捕获复杂结构和时间动态。


<details>
  <summary>Details</summary>
Motivation: 由于隐私和监管限制，真实EHR数据难以共享和利用，需要生成合成数据。现有方法通常仅生成专家选择的特征，无法全面模拟原始EHR。

Method: 使用文本表示和压缩技术，生成多表时间序列EHR数据，并提出了新的评估框架，评估分布相似性、表间关系、时间动态和隐私。

Result: 在开源EHR数据集上验证，RawMed在保真度和实用性上优于基线模型。

Conclusion: RawMed是首个能生成接近原始EHR的合成数据框架，为医疗研究提供了新工具。

Abstract: Electronic Health Records (EHR) are time-series relational databases that
record patient interactions and medical events over time, serving as a critical
resource for healthcare research and applications. However, privacy concerns
and regulatory restrictions limit the sharing and utilization of such sensitive
data, necessitating the generation of synthetic EHR datasets. Unlike previous
EHR synthesis methods, which typically generate medical records consisting of
expert-chosen features (e.g. a few vital signs or structured codes only), we
introduce RawMed, the first framework to synthesize multi-table, time-series
EHR data that closely resembles raw EHRs. Using text-based representation and
compression techniques, RawMed captures complex structures and temporal
dynamics with minimal preprocessing. We also propose a new evaluation framework
for multi-table time-series synthetic EHRs, assessing distributional
similarity, inter-table relationships, temporal dynamics, and privacy.
Validated on two open-source EHR datasets, RawMed outperforms baseline models
in fidelity and utility. The code is available at
https://github.com/eunbyeol-cho/RawMed.

</details>


### [202] [Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions](https://arxiv.org/abs/2507.07008)
*Emile Pierret,Bruno Galerne*

Main category: cs.LG

TL;DR: 本文研究了扩散模型在高斯数据分布去模糊任务中的准确性，通过计算Wasserstein距离比较理论解与扩散模型解之间的差异。


<details>
  <summary>Details</summary>
Motivation: 扩散模型作为贝叶斯逆问题的先验，因其灵活性和高方差受到关注，但其性能表现尚不明确。

Method: 在高斯数据分布下，计算扩散模型采样器分布与理想解分布之间的精确Wasserstein距离。

Result: 研究结果可用于比较文献中不同算法的性能。

Conclusion: 在约束条件下，扩散模型的解与理论解之间存在可量化的差异，为算法比较提供了依据。

Abstract: Used as priors for Bayesian inverse problems, diffusion models have recently
attracted considerable attention in the literature. Their flexibility and high
variance enable them to generate multiple solutions for a given task, such as
inpainting, super-resolution, and deblurring. However, several unresolved
questions remain about how well they perform. In this article, we investigate
the accuracy of these models when applied to a Gaussian data distribution for
deblurring. Within this constrained context, we are able to precisely analyze
the discrepancy between the theoretical resolution of inverse problems and
their resolution obtained using diffusion models by computing the exact
Wasserstein distance between the distribution of the diffusion model sampler
and the ideal distribution of solutions to the inverse problem. Our findings
allow for the comparison of different algorithms from the literature.

</details>


### [203] [On-Device Training of PV Power Forecasting Models in a Smart Meter for Grid Edge Intelligence](https://arxiv.org/abs/2507.07016)
*Jian Huang,Yongli Zhu,Linna Xu,Zhe Zheng,Wenpeng Cui,Mingyang Sun*

Main category: cs.LG

TL;DR: 研究在资源有限的智能电表上进行边缘端模型训练的可行性，提出混合和降低精度训练方案，并通过光伏功率预测案例验证。


<details>
  <summary>Details</summary>
Motivation: 实现电网边缘智能，探索在设备端进行模型训练的潜力。

Method: 介绍技术准备步骤，研究梯度提升树和循环神经网络模型，设计混合和降低精度训练方案。

Result: 实验证明通过现有高级计量基础设施经济地实现电网边缘智能是可行的。

Conclusion: 资源有限的智能电表上实现边缘端模型训练是可行的，为电网边缘智能提供了经济高效的解决方案。

Abstract: In this paper, an edge-side model training study is conducted on a
resource-limited smart meter. The motivation of grid-edge intelligence and the
concept of on-device training are introduced. Then, the technical preparation
steps for on-device training are described. A case study on the task of
photovoltaic power forecasting is presented, where two representative machine
learning models are investigated: a gradient boosting tree model and a
recurrent neural network model. To adapt to the resource-limited situation in
the smart meter, "mixed"- and "reduced"-precision training schemes are also
devised. Experiment results demonstrate the feasibility of economically
achieving grid-edge intelligence via the existing advanced metering
infrastructures.

</details>


### [204] [PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments](https://arxiv.org/abs/2507.07032)
*Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Chunbin Gu,Ge Liu,Pheng-Ann Heng*

Main category: cs.LG

TL;DR: PLAME是一种新型MSA设计模型，利用预训练蛋白质语言模型的进化嵌入，提升低同源性和孤儿蛋白质的结构预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有折叠模型对多序列比对（MSA）的依赖问题，尤其是在低同源性和孤儿蛋白质中MSA信息稀疏或不可用的情况。

Method: 提出PLAME模型，结合预训练表示增强进化信息，引入保护-多样性损失提升生成质量，并提出新的MSA筛选方法和序列质量评估指标。

Result: 在AlphaFold2和AlphaFold3基准测试中，PLAME在低同源性和孤儿蛋白质上实现了最先进的性能提升。

Conclusion: PLAME不仅提升了折叠性能，还能作为适配器实现AlphaFold2级别的精度和ESMFold的推理速度。

Abstract: Protein structure prediction is essential for drug discovery and
understanding biological functions. While recent advancements like AlphaFold
have achieved remarkable accuracy, most folding models rely heavily on multiple
sequence alignments (MSAs) to boost prediction performance. This dependency
limits their effectiveness on low-homology proteins and orphan proteins, where
MSA information is sparse or unavailable. To address this limitation, we
propose PLAME, a novel MSA design model that leverages evolutionary embeddings
from pretrained protein language models. Unlike existing methods, PLAME
introduces pretrained representations to enhance evolutionary information and
employs a conservation-diversity loss to enhance generation quality.
Additionally, we propose a novel MSA selection method to effectively screen
high-quality MSAs and improve folding performance. We also propose a sequence
quality assessment metric that provides an orthogonal perspective to evaluate
MSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins,
PLAME achieves state-of-the-art performance in folding enhancement and sequence
quality assessment, with consistent improvements demonstrated on AlphaFold3.
Ablation studies validate the effectiveness of the MSA selection method, while
extensive case studies on various protein types provide insights into the
relationship between AlphaFold's prediction quality and MSA characteristics.
Furthermore, we demonstrate that PLAME can serve as an adapter achieving
AlphaFold2-level accuracy with the ESMFold's inference speed.

</details>


### [205] [Self-Supervised Learning at the Edge: The Cost of Labeling](https://arxiv.org/abs/2507.07033)
*Roberto Pereira,Fernanda Famá,Asal Rangrazi,Marco Miozzo,Charalampos Kalalas,Paolo Dini*

Main category: cs.LG

TL;DR: 对比学习（CL）在资源受限的边缘设备上部署时面临数据与计算资源需求高的挑战。本文探讨了自监督学习（SSL）在边缘学习中的可行性与效率，分析了性能与能耗的权衡，并提出定制化SSL策略可减少资源消耗达4倍。


<details>
  <summary>Details</summary>
Motivation: 解决自监督学习在资源受限的边缘设备上部署时的高资源需求问题，探索如何在有限资源下实现高效学习。

Method: 分析不同SSL技术在有限计算、数据和能源预算下的适应性，评估其在资源受限环境中学习鲁棒表示的有效性，并考虑半监督学习对降低CL模型训练能耗的作用。

Result: 实验表明，定制化的SSL策略在保持竞争力的性能同时，可将资源消耗减少高达4倍。

Conclusion: 定制化的SSL策略在边缘设备上具有高效学习的潜力，能够显著降低资源消耗。

Abstract: Contrastive learning (CL) has recently emerged as an alternative to
traditional supervised machine learning solutions by enabling rich
representations from unstructured and unlabeled data. However, CL and, more
broadly, self-supervised learning (SSL) methods often demand a large amount of
data and computational resources, posing challenges for deployment on
resource-constrained edge devices. In this work, we explore the feasibility and
efficiency of SSL techniques for edge-based learning, focusing on trade-offs
between model performance and energy efficiency. In particular, we analyze how
different SSL techniques adapt to limited computational, data, and energy
budgets, evaluating their effectiveness in learning robust representations
under resource-constrained settings. Moreover, we also consider the energy
costs involved in labeling data and assess how semi-supervised learning may
assist in reducing the overall energy consumed to train CL models. Through
extensive experiments, we demonstrate that tailored SSL strategies can achieve
competitive performance while reducing resource consumption by up to 4X,
underscoring their potential for energy-efficient learning at the edge.

</details>


### [206] [An Ensemble Embedding Approach for Improving Semantic Caching Performance in LLM-based Systems](https://arxiv.org/abs/2507.07061)
*Shervin Ghaffari,Zohre Bahranifard,Mohammad Akbari*

Main category: cs.LG

TL;DR: 本文提出了一种基于集成嵌入的语义缓存方法，通过结合多个嵌入模型和元编码器，显著提高了LLM系统中语义相似性检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有语义缓存框架依赖单一嵌入模型，无法充分捕捉真实查询分布中的多样语义关系，限制了缓存效率。

Method: 采用集成嵌入方法，结合多个嵌入模型并通过训练的元编码器优化语义相似性检测。

Result: 在QQP数据集上，实现了92%的缓存命中率和85%的非等价查询拒绝准确率，显著优于单一模型。

Conclusion: 集成嵌入方法能更有效区分语义相似与不相似查询，提升LLM系统的缓存性能和计算效率。

Abstract: Semantic caching enhances the efficiency of large language model (LLM)
systems by identifying semantically similar queries, storing responses once,
and serving them for subsequent equivalent requests. However, existing semantic
caching frameworks rely on single embedding models for query representation,
which limits their ability to capture the diverse semantic relationships
present in real-world query distributions. This paper presents an ensemble
embedding approach that combines multiple embedding models through a trained
meta-encoder to improve semantic similarity detection in LLM caching systems.
We evaluate our method using the Quora Question Pairs (QQP) dataset, measuring
cache hit ratios, cache miss ratios, token savings, and response times. Our
ensemble approach achieves a 92\% cache hit ratio for semantically equivalent
queries while maintaining an 85\% accuracy in correctly rejecting
non-equivalent queries as cache misses. These results demonstrate that ensemble
embedding methods significantly outperform single-model approaches in
distinguishing between semantically similar and dissimilar queries, leading to
more effective caching performance and reduced computational overhead in
LLM-based systems.

</details>


### [207] [Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts](https://arxiv.org/abs/2507.07100)
*Lan Li,Da-Wei Zhou,Han-Jia Ye,De-Chuan Zhan*

Main category: cs.LG

TL;DR: DCE框架通过频率感知专家组和动态专家选择器解决DIL中的类不平衡和分布偏移问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: DIL在非平稳环境中面临类内不平衡和跨域分布偏移的挑战，影响模型性能。

Method: DCE使用频率感知专家组学习特定频率类别的特征，并通过动态专家选择器平衡新旧知识。

Result: 在四个基准数据集上，DCE表现出最先进的性能。

Conclusion: DCE有效解决了DIL中的关键挑战，提升了模型在非平稳环境中的适应能力。

Abstract: Domain-Incremental Learning (DIL) focuses on continual learning in
non-stationary environments, requiring models to adjust to evolving domains
while preserving historical knowledge. DIL faces two critical challenges in the
context of imbalanced data: intra-domain class imbalance and cross-domain class
distribution shifts. These challenges significantly hinder model performance,
as intra-domain imbalance leads to underfitting of few-shot classes, while
cross-domain shifts require maintaining well-learned many-shot classes and
transferring knowledge to improve few-shot class performance in old domains. To
overcome these challenges, we introduce the Dual-Balance Collaborative Experts
(DCE) framework. DCE employs a frequency-aware expert group, where each expert
is guided by specialized loss functions to learn features for specific
frequency groups, effectively addressing intra-domain class imbalance.
Subsequently, a dynamic expert selector is learned by synthesizing
pseudo-features through balanced Gaussian sampling from historical class
statistics. This mechanism navigates the trade-off between preserving many-shot
knowledge of previous domains and leveraging new data to improve few-shot class
performance in earlier tasks. Extensive experimental results on four benchmark
datasets demonstrate DCE's state-of-the-art performance.

</details>


### [208] [Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful](https://arxiv.org/abs/2507.07101)
*Martin Marek,Sanae Lotfi,Aditya Somasundaram,Andrew Gordon Wilson,Micah Goldblum*

Main category: cs.LG

TL;DR: 研究发现小批量训练在语言模型预训练和微调中稳定且高效，提出了Adam超参数调整规则，并建议避免梯度累积。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为小批量训练不稳定，但本研究挑战这一观点，探索小批量（甚至批量大小为1）的潜力。

Method: 提出Adam超参数调整规则，并测试小批量训练的效果。

Result: 小批量训练稳定、对超参数选择更鲁棒、性能优于大批量，且支持SGD训练。

Conclusion: 建议选择小批量训练，避免梯度累积，除非在多设备训练中带宽受限。

Abstract: Conventional wisdom dictates that small batch sizes make language model
pretraining and fine-tuning unstable, motivating gradient accumulation, which
trades off the number of optimizer steps for a proportional increase in batch
size. While it is common to decrease the learning rate for smaller batch sizes,
other hyperparameters are often held fixed. In this work, we revisit small
batch sizes all the way down to batch size one, and we propose a rule for
scaling Adam hyperparameters to small batch sizes. We find that small batch
sizes (1) train stably, (2) are consistently more robust to hyperparameter
choices, (3) achieve equal or better per-FLOP performance than larger batch
sizes, and (4) notably enable stable language model training with vanilla SGD,
even without momentum, despite storing no optimizer state. Building on these
results, we provide practical recommendations for selecting a batch size and
setting optimizer hyperparameters. We further recommend against gradient
accumulation unless training on multiple devices with multiple model replicas,
bottlenecked by inter-device bandwidth.

</details>


### [209] [Does Data Scaling Lead to Visual Compositional Generalization?](https://arxiv.org/abs/2507.07102)
*Arnas Uselis,Andrea Dittadi,Seong Joon Oh*

Main category: cs.LG

TL;DR: 研究发现，组合泛化能力由数据多样性而非数据规模驱动，线性分解表示结构是实现高效组合学习的关键。


<details>
  <summary>Details</summary>
Motivation: 探讨当代视觉模型是否具备组合理解能力，以及数据规模和多样性对组合泛化的影响。

Method: 通过控制实验系统性地改变数据规模、概念多样性和组合覆盖范围，评估预训练模型（DINO、CLIP）的表现。

Result: 组合泛化能力依赖于数据多样性，线性分解表示结构能实现高效泛化，但现有模型仅部分具备该结构。

Conclusion: 建议构建更多样化的数据集，并关注能支持高效组合学习的表示结构。

Abstract: Compositional understanding is crucial for human intelligence, yet it remains
unclear whether contemporary vision models exhibit it. The dominant machine
learning paradigm is built on the premise that scaling data and model sizes
will improve out-of-distribution performance, including compositional
generalization. We test this premise through controlled experiments that
systematically vary data scale, concept diversity, and combination coverage. We
find that compositional generalization is driven by data diversity, not mere
data scale. Increased combinatorial coverage forces models to discover a
linearly factored representational structure, where concepts decompose into
additive components. We prove this structure is key to efficiency, enabling
perfect generalization from few observed combinations. Evaluating pretrained
models (DINO, CLIP), we find above-random yet imperfect performance, suggesting
partial presence of this structure. Our work motivates stronger emphasis on
constructing diverse datasets for compositional generalization, and considering
the importance of representational structure that enables efficient
compositional learning. Code available at
https://github.com/oshapio/visual-compositional-generalization.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [210] [A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes](https://arxiv.org/abs/2507.06278)
*Kemboi Cheruiyot,Nickson Kiprotich,Vyacheslav Kungurtsev,Kennedy Mugo,Vivian Mwirigi,Marvin Ngesa*

Main category: cs.MA

TL;DR: 本文综述了多智能体交互的三种拓扑结构：联邦强化学习、去中心化强化学习和非合作强化学习，分析了其结构、理论保证及数值性能。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体交互的复杂场景，探讨不同交互拓扑结构的理论基础和实际表现。

Method: 通过文献综述，分析联邦强化学习、去中心化强化学习和非合作强化学习的结构、理论保证及数值性能。

Result: 总结了三种交互拓扑的相似性与区别，并指出当前研究的局限性和性能表现。

Conclusion: 多智能体交互的研究仍需进一步探索，特别是在理论保证和实际应用性能方面。

Abstract: The increasing interest in research and innovation towards the development of
autonomous agents presents a number of complex yet important scenarios of
multiple AI Agents interacting with each other in an environment. The
particular setting can be understood as exhibiting three possibly topologies of
interaction - centrally coordinated cooperation, ad-hoc interaction and
cooperation, and settings with noncooperative incentive structures. This
article presents a comprehensive survey of all three domains, defined under the
formalism of Federal Reinforcement Learning (RL), Decentralized RL, and
Noncooperative RL, respectively. Highlighting the structural similarities and
distinctions, we review the state of the art in these subjects, primarily
explored and developed only recently in the literature. We include the
formulations as well as known theoretical guarantees and highlights and
limitations of numerical performance.

</details>


### [211] [Learning To Communicate Over An Unknown Shared Network](https://arxiv.org/abs/2507.06499)
*Shivangi Agarwal,Adi Asija,Sanjit K. Kaul,Arani Bhattacharya,Saket Anand*

Main category: cs.MA

TL;DR: 论文提出了一种名为QNet的深度强化学习模型，帮助代理在共享无线网络中优化通信决策，无需了解其他代理的状态或网络配置。


<details>
  <summary>Details</summary>
Motivation: 在共享无线网络中，代理无法感知网络资源状态和其他代理的通信行为，因此需要一种能够适应不同网络配置的通用策略。

Method: 使用模拟到现实的框架训练QNet，模拟模型仅需一个参数，并通过随机化模拟参数覆盖多种网络情况。

Result: 实验验证了QNet在WiFi和蜂窝网络中的有效性，适应从低到高的网络竞争和延迟条件。

Conclusion: QNet是一种通用且高效的策略，适用于不同网络配置和多代理共享环境。

Abstract: As robots (edge-devices, agents) find uses in an increasing number of
settings and edge-cloud resources become pervasive, wireless networks will
often be shared by flows of data traffic that result from communication between
agents and corresponding edge-cloud. In such settings, agent communicating with
the edge-cloud is unaware of state of network resource, which evolves in
response to not just agent's own communication at any given time but also to
communication by other agents, which stays unknown to the agent. We address
challenge of an agent learning a policy that allows it to decide whether or not
to communicate with its cloud node, using limited feedback it obtains from its
own attempts to communicate, to optimize its utility. The policy generalizes
well to any number of other agents sharing the network and must not be trained
for any particular network configuration. Our proposed policy is a DRL model
Query Net (QNet) that we train using a proposed simulation-to-real framework.
Our simulation model has just one parameter and is agnostic to specific
configurations of any wireless network. It allows training an agent's policy
over a wide range of outcomes that an agent's communication with its edge-cloud
node may face when using a shared network, by suitably randomizing the
simulation parameter. We propose a learning algorithm that addresses challenges
observed in training QNet. We validate our simulation-to-real driven approach
through experiments conducted on real wireless networks including WiFi and
cellular. We compare QNet with other policies to demonstrate its efficacy. WiFi
experiments involved as few as five agents, resulting in barely any contention
for the network, to as many as fifty agents, resulting in severe contention.
The cellular experiments spanned a broad range of network conditions, with
baseline RTT ranging from a low of 0.07 second to a high of 0.83 second.

</details>


### [212] [Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration](https://arxiv.org/abs/2507.06520)
*Xinyuan Song,Zeyu Wang,Siyi Wu,Tianyu Shi,Lynn Ai*

Main category: cs.MA

TL;DR: Gradientsys是一个多智能体调度框架，通过MCP和动态规划循环协调多样化AI智能体，支持并行执行和透明监控，实验显示其在任务成功率和效率上优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作中的任务调度、并行执行和透明性问题。

Method: 采用MCP协议和动态规划循环，结合LLM调度器实现智能任务分发，支持混合同步/异步执行和失败处理机制。

Result: 在GAIA基准测试中，Gradientsys任务成功率更高，延迟和API成本更低。

Conclusion: Gradientsys通过LLM驱动的多智能体协调，在性能和效率上表现出色。

Abstract: We present Gradientsys, a next-generation multi-agent scheduling framework
that coordinates diverse specialized AI agents using a typed Model-Context
Protocol (MCP) and a ReAct-based dynamic planning loop. At its core,
Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task
dispatch, enabling parallel execution of heterogeneous agents such as PDF
parsers, web search modules, GUI controllers, and web builders. The framework
supports hybrid synchronous/asynchronous execution, respects agent capacity
constraints, and incorporates a robust retry-and-replan mechanism to handle
failures gracefully. To promote transparency and trust, Gradientsys includes an
observability layer streaming real-time agent activity and intermediate
reasoning via Server-Sent Events (SSE). We offer an architectural overview and
evaluate Gradientsys against existing frameworks in terms of extensibility,
scheduling topology, tool reusability, parallelism, and observability.
Experiments on the GAIA general-assistant benchmark show that Gradientsys
achieves higher task success rates with reduced latency and lower API costs
compared to a MinionS-style baseline, demonstrating the strength of its
LLM-driven multi-agent orchestration.

</details>


### [213] [Graph-Based Complexity Metrics for Multi-Agent Curriculum Learning: A Validated Approach to Task Ordering in Cooperative Coordination Environments](https://arxiv.org/abs/2507.07074)
*Farhaan Ebadulla,Dharini Hindlatti,Srinivaasan NS,Apoorva VH,Ayman Aftab*

Main category: cs.MA

TL;DR: 提出了一种基于图的协调复杂度度量方法，用于多智能体强化学习中的任务排序和课程设计，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在任务排序和课程设计方面面临挑战，尤其是在协作协调场景中，缺乏有效的任务复杂度度量方法。

Method: 提出了一种基于图的协调复杂度度量方法，结合智能体依赖熵、空间干扰模式和目标重叠分析，预测多智能体环境中的任务难度。

Result: 复杂度度量与随机智能体性能评估的实证难度具有强相关性（rho = 0.952，p < 0.001）。在MADDPG框架下，该方法在MultiWalker和Simple Spread环境中分别实现了56倍的性能提升和系统任务进展。

Conclusion: 该研究为多智能体课程设计提供了有效的复杂度度量，并确立了多机器人协调应用的实证指南。

Abstract: Multi-agent reinforcement learning (MARL) faces significant challenges in
task sequencing and curriculum design, particularly for cooperative
coordination scenarios. While curriculum learning has demonstrated success in
single-agent domains, principled approaches for multi-agent coordination remain
limited due to the absence of validated task complexity metrics. This approach
presents a graph-based coordination complexity metric that integrates agent
dependency entropy, spatial interference patterns, and goal overlap analysis to
predict task difficulty in multi-agent environments. The complexity metric
achieves strong empirical validation with rho = 0.952 correlation (p < 0.001)
between predicted complexity and empirical difficulty determined by random
agent performance evaluation. This approach evaluates the curriculum learning
framework using MADDPG across two distinct coordination environments: achieving
56x performance improvement in tight coordination tasks (MultiWalker) and
demonstrating systematic task progression in cooperative navigation (Simple
Spread). Through systematic analysis, coordination tightness emerges as a
predictor of curriculum learning effectiveness, where environments requiring
strict agent interdependence benefit substantially from structured progression.
This approach provides a validated complexity metric for multi-agent curriculum
design and establishes empirical guidelines for multi-robot coordination
applications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [214] [Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction](https://arxiv.org/abs/2507.06346)
*Li Zhou,Elvan Ceyhan*

Main category: cs.RO

TL;DR: 论文研究了资源受限的随机消歧路径（RDP）问题，提出了一种结合拉格朗日松弛和两阶段顶点消除（TPVE）的新算法框架COLOGR，用于解决带约束的最短路径问题，并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定障碍物环境中，资源受限的路径规划问题，为移动代理提供高效的决策支持。

Method: 将问题建模为带权重约束的最短路径问题（WCSPP），提出COLOGR算法框架，结合拉格朗日松弛和TPVE方法，修剪不可行和次优路径。

Result: COLOGR在实验中表现出色，优于贪婪基线方法，接近离线最优基准，且计算复杂度优于现有方法。

Conclusion: COLOGR框架在随机网络设计、移动规划和不确定性约束决策中具有广泛应用前景。

Abstract: We study a resource-constrained variant of the Random Disambiguation Path
(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,
in which a navigating agent must reach a target in a spatial environment
populated with uncertain obstacles. Each ambiguous obstacle may be
disambiguated at a (possibly) heterogeneous resource cost, subject to a global
disambiguation budget. We formulate this constrained planning problem as a
Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs
that incorporate probabilistic blockage and traversal penalties. To solve it,
we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation
with a two-phase vertex elimination (TPVE) procedure. The method prunes
infeasible and suboptimal paths while provably preserving the optimal solution,
and leverages dual bounds to guide efficient search. We establish correctness,
feasibility guarantees, and surrogate optimality under mild assumptions. Our
analysis also demonstrates that COLOGR frequently achieves zero duality gap and
offers improved computational complexity over prior constrained path-planning
methods. Extensive simulation experiments validate the algorithm's robustness
across varying obstacle densities, sensor accuracies, and risk models,
consistently outperforming greedy baselines and approaching offline-optimal
benchmarks. The proposed framework is broadly applicable to stochastic network
design, mobility planning, and constrained decision-making under uncertainty.

</details>


### [215] [Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System](https://arxiv.org/abs/2507.06397)
*Michalis Chatzispyrou,Luke Horgan,Hyunkil Hwang,Harish Sathishchandra,Monika Roznere,Alberto Quattrini Li,Philippos Mordohai,Ioannis Rekleitis*

Main category: cs.RO

TL;DR: 本文提出了一种利用低成本运动相机和潜水电脑绘制水下洞穴地图的框架，结合视觉/惯性框架和全局优化方法，生成洞穴的一维轮廓和密集3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下洞穴对淡水资源管理、水下考古和水文地质学至关重要，绘制其轮廓和尺寸以及生成逼真的3D地图有助于更好地理解这一水下领域。

Method: 使用运动相机和潜水电脑估计相机轨迹和稀疏点云，结合视觉/惯性框架（SVIn2）和全局优化工具（COLMAP）生成洞穴的一维轮廓和密集3D重建，并通过手动测量验证。

Result: 成功生成洞穴的一维轮廓和部分区域的密集3D重建，验证了方法的有效性。

Conclusion: 低成本运动相机结合视觉/惯性框架和全局优化方法，能够有效绘制水下洞穴地图并生成逼真的3D重建。

Abstract: This paper presents a framework for mapping underwater caves. Underwater
caves are crucial for fresh water resource management, underwater archaeology,
and hydrogeology. Mapping the cave's outline and dimensions, as well as
creating photorealistic 3D maps, is critical for enabling a better
understanding of this underwater domain. In this paper, we present the mapping
of an underwater cave segment (the catacombs) of the Devil's Eye cave system at
Ginnie Springs, FL. We utilized a set of inexpensive action cameras in
conjunction with a dive computer to estimate the trajectories of the cameras
together with a sparse point cloud. The resulting reconstructions are utilized
to produce a one-dimensional retract of the cave passages in the form of the
average trajectory together with the boundaries (top, bottom, left, and right).
The use of the dive computer enables the observability of the z-dimension in
addition to the roll and pitch in a visual/inertial framework (SVIn2). In
addition, the keyframes generated by SVIn2 together with the estimated camera
poses for select areas are used as input to a global optimization (bundle
adjustment) framework -- COLMAP -- in order to produce a dense reconstruction
of those areas. The same cave segment is manually surveyed using the MNemo V2
instrument, providing an additional set of measurements validating the proposed
approach. It is worth noting that with the use of action cameras, the primary
components of a cave map can be constructed. Furthermore, with the utilization
of a global optimization framework guided by the results of VI-SLAM package
SVIn2, photorealistic dense 3D representations of selected areas can be
reconstructed.

</details>


### [216] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

Main category: cs.RO

TL;DR: 提出了一种基于轨迹性能的通用评估框架NeME，用于比较模仿学习方法在复杂HRI任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 由于成功率指标难以复现且无法捕捉机器人运动轨迹的复杂性，评估人形机器人性能具有挑战性。

Method: 设计了NeME（神经元评估器），通过深度学习模型分类机器人关节轨迹动作，作为元评估器比较控制策略性能。

Result: 实验验证表明，该方法比基线更符合机器人实际成功率，提供了可复现、系统化的评估手段。

Conclusion: NeME为复杂HRI任务中的多模态模仿学习方法提供了有效的性能比较工具。

Abstract: Evaluating and comparing the performance of autonomous Humanoid Robots is
challenging, as success rate metrics are difficult to reproduce and fail to
capture the complexity of robot movement trajectories, critical in Human-Robot
Interaction and Collaboration (HRIC). To address these challenges, we propose a
general evaluation framework that measures the quality of Imitation Learning
(IL) methods by focusing on trajectory performance. We devise the Neural Meta
Evaluator (NeME), a deep learning model trained to classify actions from robot
joint trajectories. NeME serves as a meta-evaluator to compare the performance
of robot control policies, enabling policy evaluation without requiring human
involvement in the loop. We validate our framework on ergoCub, a humanoid
robot, using teleoperation data and comparing IL methods tailored to the
available platform. The experimental results indicate that our method is more
aligned with the success rate obtained on the robot than baselines, offering a
reproducible, systematic, and insightful means for comparing the performance of
multimodal imitation learning approaches in complex HRI tasks.

</details>


### [217] [Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion](https://arxiv.org/abs/2507.06426)
*Devin Crowley,Whitney G. Cole,Christina M. Hospodar,Ruiting Shen,Karen E. Adolph,Alan Fern*

Main category: cs.RO

TL;DR: 论文提出了一种结合发展心理学方法研究机器人学习行为的新方法，通过系统化训练和精细测量，揭示了训练方案对机器人行为的影响。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制器训练方法缺乏系统性，且评估指标粗糙，无法深入理解训练方案对行为的影响。发展心理学对婴儿的研究方法提供了精细测量手段，但受限于实际约束。

Method: 采用发展心理学方法，设计系统化的强化学习训练方案，并在模拟环境中测试双足机器人Cassie的行为。

Result: 揭示了不同训练方案对机器人行为的影响，并比较了Cassie与婴儿学习行走的行为发展。

Conclusion: 跨学科的婴儿-机器人研究方法为未来系统化测试训练对复杂机器人行为发展的影响提供了新思路。

Abstract: Typically, learned robot controllers are trained via relatively unsystematic
regimens and evaluated with coarse-grained outcome measures such as average
cumulative reward. The typical approach is useful to compare learning
algorithms but provides limited insight into the effects of different training
regimens and little understanding about the richness and complexity of learned
behaviors. Likewise, human infants and other animals are "trained" via
unsystematic regimens, but in contrast, developmental psychologists evaluate
their performance in highly-controlled experiments with fine-grained measures
such as success, speed of walking, and prospective adjustments. However, the
study of learned behavior in human infants is limited by the practical
constraints of training and testing babies. Here, we present a case study that
applies methods from developmental psychology to study the learned behavior of
the simulated bipedal robot Cassie. Following research on infant walking, we
systematically designed reinforcement learning training regimens and tested the
resulting controllers in simulated environments analogous to those used for
babies--but without the practical constraints. Results reveal new insights into
the behavioral impact of different training regimens and the development of
Cassie's learned behaviors relative to infants who are learning to walk. This
interdisciplinary baby-robot approach provides inspiration for future research
designed to systematically test effects of training on the development of
complex learned robot behaviors.

</details>


### [218] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 论文提出了一种针对高精度重复插入任务（RIT）的模拟到现实框架，结合强化学习策略和故障预测模块，显著提升了任务的成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人执行高精度重复插入任务（如拧螺母）时面临的毫米级精度和长期稳定性问题，特别是由螺母旋转和摩擦等因素带来的复杂性。

Method: 采用模拟到现实框架，结合强化学习插入策略和故障预测模块，通过将工具姿态表示为螺母坐标系而非机器人坐标系，提升模拟到现实的迁移性。

Result: 实验表明，该方法不仅实现了一次性高成功率，还能在长期重复任务中保持稳定性能。

Conclusion: 提出的框架有效解决了RIT任务的高精度和稳定性问题，为类似任务提供了可行的解决方案。

Abstract: This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where
a robot must repeatedly perform high-precision insertions, such as screwing a
nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving
millimeter-level accuracy and maintaining consistent performance over multiple
repetitions, particularly when factors like nut rotation and friction introduce
additional complexity. We propose a sim-to-real framework that integrates a
reinforcement learning-based insertion policy with a failure forecasting
module. By representing the wrench's pose in the nut's coordinate frame rather
than the robot's frame, our approach significantly enhances sim-to-real
transferability. The insertion policy, trained in simulation, leverages
real-time 6D pose tracking to execute precise alignment, insertion, and
rotation maneuvers. Simultaneously, a neural network predicts potential
execution failures, triggering a simple recovery mechanism that lifts the
wrench and retries the insertion. Extensive experiments in both simulated and
real-world environments demonstrate that our method not only achieves a high
one-time success rate but also robustly maintains performance over long-horizon
repetitive tasks.

</details>


### [219] [KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing](https://arxiv.org/abs/2507.06562)
*Keita Yoneda,Kento Kawaharazuka,Temma Suzuki,Takahiro Hattori,Kei Okada*

Main category: cs.RO

TL;DR: 研究开发了具有腰部关节的四足机器人KLEIYN，通过强化学习实现垂直运动（如烟囱攀爬），并引入接触引导课程学习（CGCL）方法，显著提升了攀爬速度和性能。


<details>
  <summary>Details</summary>
Motivation: 尽管四足机器人在平坦地形上的运动控制已取得进展，但在具有显著高度变化的崎岖地形中稳定垂直运动仍是一个未解决的挑战。

Method: 开发了具有腰部关节的机器人KLEIYN，并采用强化学习和接触引导课程学习（CGCL）方法训练其垂直运动能力。

Result: KLEIYN能以平均150 mm/s的速度攀爬800-1000 mm宽的墙壁，速度是传统机器人的50倍，且腰部关节显著提升了在狭窄墙壁上的跟踪能力。

Conclusion: 研究表明，腰部关节和CGCL方法的结合能有效扩展四足机器人的垂直运动能力，为复杂地形任务提供了新解决方案。

Abstract: In recent years, advancements in hardware have enabled quadruped robots to
operate with high power and speed, while robust locomotion control using
reinforcement learning (RL) has also been realized. As a result, expectations
are rising for the automation of tasks such as material transport and
exploration in unknown environments. However, autonomous locomotion in rough
terrains with significant height variations requires vertical movement, and
robots capable of performing such movements stably, along with their control
methods, have not yet been fully established. In this study, we developed the
quadruped robot KLEIYN, which features a waist joint, and aimed to expand
quadruped locomotion by enabling chimney climbing through RL. To facilitate the
learning of vertical motion, we introduced Contact-Guided Curriculum Learning
(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to
1000 mm in width at an average speed of 150 mm/s, 50 times faster than
conventional robots. Furthermore, we demonstrated that the introduction of a
waist joint improves climbing performance, particularly enhancing tracking
ability on narrow walls.

</details>


### [220] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

Main category: cs.RO

TL;DR: SkyVLN框架结合视觉语言导航与非线性模型预测控制，提升无人机在复杂城市环境中的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在复杂城市环境中的导航需求日益增长，传统方法难以满足动态3D空间的高精度和鲁棒性要求。

Method: SkyVLN利用大语言模型解析自然语言指令与视觉观察，结合细粒度空间语言化器和历史路径记忆机制，并通过NMPC模块实现动态避障。

Result: 实验表明，SkyVLN显著提高了导航成功率和效率，尤其是在新环境中。

Conclusion: SkyVLN为无人机在复杂城市环境中的自主导航提供了高效、鲁棒的解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across
various sectors, driven by their mobility and adaptability. This paper
introduces SkyVLN, a novel framework integrating vision-and-language navigation
(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in
complex urban environments. Unlike traditional navigation methods, SkyVLN
leverages Large Language Models (LLMs) to interpret natural language
instructions and visual observations, enabling UAVs to navigate through dynamic
3D spaces with improved accuracy and robustness. We present a multimodal
navigation agent equipped with a fine-grained spatial verbalizer and a history
path memory mechanism. These components allow the UAV to disambiguate spatial
contexts, handle ambiguous instructions, and backtrack when necessary. The
framework also incorporates an NMPC module for dynamic obstacle avoidance,
ensuring precise trajectory tracking and collision prevention. To validate our
approach, we developed a high-fidelity 3D urban simulation environment using
AirSim, featuring realistic imagery and dynamic urban elements. Extensive
experiments demonstrate that SkyVLN significantly improves navigation success
rates and efficiency, particularly in new and unseen environments.

</details>


### [221] [Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments](https://arxiv.org/abs/2507.06750)
*Tohid Kargar Tasooji,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出了一种分布式容错协同定位框架，通过自适应事件触发通信策略提升多机器人系统在对抗环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS缺失或通信受限的环境中，传统定位方法易受对抗攻击（如传感器操纵和通信干扰）影响，需要增强系统鲁棒性。

Method: 采用自适应事件触发通信策略，动态调整通信阈值，并分析算法的收敛性和稳定性。

Result: 实验表明，该算法在定位精度和通信效率上显著优于传统方法，尤其在对抗环境中表现优异。

Conclusion: 该方法提高了多机器人系统的可扩展性、可靠性和容错能力，适用于现实世界中的大规模部署。

Abstract: In multi-robot systems (MRS), cooperative localization is a crucial task for
enhancing system robustness and scalability, especially in GPS-denied or
communication-limited environments. However, adversarial attacks, such as
sensor manipulation, and communication jamming, pose significant challenges to
the performance of traditional localization methods. In this paper, we propose
a novel distributed fault-tolerant cooperative localization framework to
enhance resilience against sensor and communication disruptions in adversarial
environments. We introduce an adaptive event-triggered communication strategy
that dynamically adjusts communication thresholds based on real-time sensing
and communication quality. This strategy ensures optimal performance even in
the presence of sensor degradation or communication failure. Furthermore, we
conduct a rigorous analysis of the convergence and stability properties of the
proposed algorithm, demonstrating its resilience against bounded adversarial
zones and maintaining accurate state estimation. Robotarium-based experiment
results show that our proposed algorithm significantly outperforms traditional
methods in terms of localization accuracy and communication efficiency,
particularly in adversarial settings. Our approach offers improved scalability,
reliability, and fault tolerance for MRS, making it suitable for large-scale
deployments in real-world, challenging environments.

</details>


### [222] [AI Space Cortex: An Experimental System for Future Era Space Exploration](https://arxiv.org/abs/2507.06574)
*Thomas Touma,Ersin Daş,Erica Tevere,Martin Feather,Ksenia Kolcio,Maurice Prather,Alberto Candela,Ashish Goel,Erik Kramer,Hari Nayar,Lorraine Fesq,Joel W. Burdick*

Main category: cs.RO

TL;DR: REASIMO项目旨在为NASA的COLDTech计划开发一种AI辅助的自主系统，以应对冰卫星（如欧罗巴和恩塞拉多斯）任务中的通信延迟、能源限制和辐射等挑战。


<details>
  <summary>Details</summary>
Motivation: 冰卫星任务面临通信延迟、能源限制和恶劣环境等挑战，传统安全模式无法满足任务需求，需要自主系统快速应对异常。

Method: 结合AI技术，开发了一个基于预训练行为的智能框架，支持异常检测与恢复，并在NASA喷气推进实验室的测试平台上验证自主采样操作。

Result: 测试表明，该框架能够在模拟的冰卫星表面条件下实现自主操作，验证了其鲁棒性和适应性。

Conclusion: REASIMO项目为未来冰卫星任务提供了一种可行的自主解决方案，能够在不依赖地球通信的情况下完成任务目标。

Abstract: Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)
effort contributes to NASA's Concepts for Ocean worlds Life Detection
Technology (COLDTech) program, which explores science platform technologies for
ocean worlds such as Europa and Enceladus. Ocean world missions pose
significant operational challenges. These include long communication lags,
limited power, and lifetime limitations caused by radiation damage and hostile
conditions. Given these operational limitations, onboard autonomy will be vital
for future Ocean world missions. Besides the management of nominal lander
operations, onboard autonomy must react appropriately in the event of
anomalies. Traditional spacecraft rely on a transition into 'safe-mode' in
which non-essential components and subsystems are powered off to preserve
safety and maintain communication with Earth. For a severely time-limited Ocean
world mission, resolutions to these anomalies that can be executed without
Earth-in-the-loop communication and associated delays are paramount for
completion of the mission objectives and science goals. To address these
challenges, the REASIMO effort aims to demonstrate a robust level of
AI-assisted autonomy for such missions, including the ability to detect and
recover from anomalies, and to perform missions based on pre-trained behaviors
rather than hard-coded, predetermined logic like all prior space missions. We
developed an AI-assisted, personality-driven, intelligent framework for control
of an Ocean world mission by combining a mix of advanced technologies. To
demonstrate the capabilities of the framework, we perform tests of autonomous
sampling operations on a lander-manipulator testbed at the NASA Jet Propulsion
Laboratory, approximating possible surface conditions such a mission might
encounter.

</details>


### [223] [Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration](https://arxiv.org/abs/2507.06605)
*Xinyu Wu*

Main category: cs.RO

TL;DR: Episodic RRT (ERRT) 是一种结合深度强化学习的混合规划框架，显著提升了传统 RRT 在复杂环境中的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于采样的运动规划器（如 RRT）在高维或复杂环境中效率低下，主要依赖随机采样。

Method: ERRT 使用深度强化学习生成多步探索性片段，取代随机采样，实现有向探索。

Result: 在 2D、3D 和 6D 环境中，ERRT 显著优于传统 RRT，成功率和效率大幅提升。

Conclusion: ERRT 通过有向探索和减少碰撞检查，显著提升了运动规划的性能和效率。

Abstract: Classical sampling-based motion planners like the RRTs suffer from
inefficiencies, particularly in cluttered or high-dimensional spaces, due to
their reliance on undirected, random sampling. This paper introduces the
Episodic RRT, a novel hybrid planning framework that replaces the primitive of
a random point with a learned, multi-step "exploratory episode" generated by a
Deep Reinforcement Learning agent. By making the DRL agent the engine of
exploration, ERRT transforms the search process from a diffuse, volumetric
expansion into a directed, branch-like growth. This paradigm shift yields key
advantages: it counters the curse of dimensionality with focused exploration,
minimizes expensive collision checks by proactively proposing locally valid
paths, and improves connectivity by generating inherently connected path
segments. We demonstrate through extensive empirical evaluation across 2D, 3D,
and 6D environments that ERRT and its variants consistently and significantly
outperform their classical counterparts. In a challenging 6D robotic arm
scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to
107x faster, reduces collision checks by over 99.6%, and finds initial paths
that are nearly 50% shorter. Furthermore, its asymptotically optimal variant,
ERRT*, demonstrates vastly superior anytime performance, refining solutions to
near-optimality up to 29x faster than standard RRT* in 3D environments. Code:
https://xinyuwuu.github.io/Episodic_RRT/.

</details>


### [224] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

Main category: cs.RO

TL;DR: Q-STAC结合贝叶斯MPC与演员-评论家强化学习，通过约束SVGD优化控制序列，提升样本效率并确保安全性。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在连续控制任务中数据需求高、长时规划复杂及安全性不足的问题，同时弥补MPC局部最优和成本函数设计的局限性。

Method: 提出Q-STAC框架，利用学习到的Q值作为目标优化控制序列，无需显式设计成本函数，结合已知系统动力学提升效率。

Result: 在2D导航和机器人操作任务中，Q-STAC表现出更高的样本效率、鲁棒性和最优性。

Conclusion: Q-STAC成功整合了MPC与强化学习的优势，实现了高效、安全且最优的控制。

Abstract: Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac

</details>


### [225] [Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs](https://arxiv.org/abs/2507.06690)
*Guobin Zhu,Rui Zhou,Wenkang Ji,Hongyin Zhang,Donglin Wang,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种分层方法，通过技能图和高层模块解决多任务多智能体强化学习中的无关任务和知识转移问题。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习方法难以处理复杂问题，尤其是无关任务和知识转移能力有限。

Method: 采用分层方法，高层模块使用技能图，低层模块采用标准MARL算法。

Result: 实验表明，该方法优于最新的分层MAPPO算法，能有效处理无关任务并提升知识转移能力。

Conclusion: 该方法扩展了多任务强化学习的范围，并通过技能图提升了性能。

Abstract: Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained
attention for its potential to enhance MARL's adaptability across multiple
tasks. However, it is challenging for existing multi-task learning methods to
handle complex problems, as they are unable to handle unrelated tasks and
possess limited knowledge transfer capabilities. In this paper, we propose a
hierarchical approach that efficiently addresses these challenges. The
high-level module utilizes a skill graph, while the low-level module employs a
standard MARL algorithm. Our approach offers two contributions. First, we
consider the MT-MARL problem in the context of unrelated tasks, expanding the
scope of MTRL. Second, the skill graph is used as the upper layer of the
standard hierarchical approach, with training independent of the lower layer,
effectively handling unrelated tasks and enhancing knowledge transfer
capabilities. Extensive experiments are conducted to validate these advantages
and demonstrate that the proposed method outperforms the latest hierarchical
MAPPO algorithms. Videos and code are available at
https://github.com/WindyLab/MT-MARL-SG

</details>


### [226] [Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction](https://arxiv.org/abs/2507.06700)
*Pranav Pandey,Ramviyas Parasuraman,Prashant Doshi*

Main category: cs.RO

TL;DR: 论文提出了一种参数化通用安全模型，通过个性化参数ρ弥补物理安全与主观安全感知之间的差距，并通过实验验证了情感状态、信任和机器人行为对安全感知的影响。


<details>
  <summary>Details</summary>
Motivation: 传统安全模型主要依赖传感器数据，无法捕捉主观安全感知，而主观感知受个体特质和情境影响。研究旨在填补这一空白。

Method: 通过模拟救援场景的人体实验，研究情感状态、信任和机器人行为如何影响安全感知，并引入参数ρ量化个体差异。

Result: 参数ρ有效捕捉个体差异，可预测和一致的机器人行为及积极情感状态显著提升安全感知。参与者角色和重复接触也影响感知。

Conclusion: 研究强调需整合心理和行为维度的自适应安全模型，以提升人机交互的可信度和有效性。

Abstract: Ensuring safety in human-robot interaction (HRI) is essential to foster user
trust and enable the broader adoption of robotic systems. Traditional safety
models primarily rely on sensor-based measures, such as relative distance and
velocity, to assess physical safety. However, these models often fail to
capture subjective safety perceptions, which are shaped by individual traits
and contextual factors. In this paper, we introduce and analyze a parameterized
general safety model that bridges the gap between physical and perceived safety
by incorporating a personalization parameter, $\rho$, into the safety
measurement framework to account for individual differences in safety
perception. Through a series of hypothesis-driven human-subject studies in a
simulated rescue scenario, we investigate how emotional state, trust, and robot
behavior influence perceived safety. Our results show that $\rho$ effectively
captures meaningful individual differences, driven by affective responses,
trust in task consistency, and clustering into distinct user types.
Specifically, our findings confirm that predictable and consistent robot
behavior as well as the elicitation of positive emotional states, significantly
enhance perceived safety. Moreover, responses cluster into a small number of
user types, supporting adaptive personalization based on shared safety models.
Notably, participant role significantly shapes safety perception, and repeated
exposure reduces perceived safety for participants in the casualty role,
emphasizing the impact of physical interaction and experiential change. These
findings highlight the importance of adaptive, human-centered safety models
that integrate both psychological and behavioral dimensions, offering a pathway
toward more trustworthy and effective HRI in safety-critical domains.

</details>


### [227] [Spatial-Temporal Aware Visuomotor Diffusion Policy Learning](https://arxiv.org/abs/2507.06710)
*Zhenyang Liu,Yikai Wang,Kuanning Wang,Longfei Liang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出了一种名为4D Diffusion Policy (DP4)的视觉模仿学习方法，通过动态高斯世界模型增强3D空间和4D时空感知，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于历史轨迹的行为克隆，缺乏3D空间和4D时空感知能力，限制了实际应用效果。

Method: DP4利用动态高斯世界模型从交互环境中学习3D空间和4D时空感知，通过单视角RGB-D观测构建当前3D场景并预测未来3D场景，优化轨迹生成。

Result: 在17个仿真任务和3个真实机器人任务中，DP4表现优于基线方法，仿真任务成功率平均提升16.4%（Adroit）、14%（DexArt）和6.45%（RLBench），真实任务成功率提升8.6%。

Conclusion: DP4通过增强时空感知能力，显著提升了视觉模仿学习的效果，适用于复杂任务的实际部署。

Abstract: Visual imitation learning is effective for robots to learn versatile tasks.
However, many existing methods rely on behavior cloning with supervised
historical trajectories, limiting their 3D spatial and 4D spatiotemporal
awareness. Consequently, these methods struggle to capture the 3D structures
and 4D spatiotemporal relationships necessary for real-world deployment. In
this work, we propose 4D Diffusion Policy (DP4), a novel visual imitation
learning method that incorporates spatiotemporal awareness into diffusion-based
policies. Unlike traditional approaches that rely on trajectory cloning, DP4
leverages a dynamic Gaussian world model to guide the learning of 3D spatial
and 4D spatiotemporal perceptions from interactive environments. Our method
constructs the current 3D scene from a single-view RGB-D observation and
predicts the future 3D scene, optimizing trajectory generation by explicitly
modeling both spatial and temporal dependencies. Extensive experiments across
17 simulation tasks with 173 variants and 3 real-world robotic tasks
demonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,
improving the average simulation task success rate by 16.4% (Adroit), 14%
(DexArt), and 6.45% (RLBench), and the average real-world robotic task success
rate by 8.6%.

</details>


### [228] [LOVON: Legged Open-Vocabulary Object Navigator](https://arxiv.org/abs/2507.06747)
*Daojie Peng,Jiahang Cao,Qiang Zhang,Jun Ma*

Main category: cs.RO

TL;DR: LOVON是一个结合大语言模型和开放词汇视觉检测的新框架，用于动态环境中长距离物体导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在复杂长距离导航任务中难以整合开放世界物体检测和高级任务规划的问题。

Method: 集成大语言模型进行分层任务规划，结合开放词汇视觉检测模型，并设计视觉稳定化和功能执行逻辑。

Result: 成功完成涉及实时检测、搜索和导航的长序列任务，并在多种机器人上验证了兼容性。

Conclusion: LOVON框架在动态环境中表现出色，具有兼容性和即插即用特性。

Abstract: Object navigation in open-world environments remains a formidable and
pervasive challenge for robotic systems, particularly when it comes to
executing long-horizon tasks that require both open-world object detection and
high-level task planning. Traditional methods often struggle to integrate these
components effectively, and this limits their capability to deal with complex,
long-range navigation missions. In this paper, we propose LOVON, a novel
framework that integrates large language models (LLMs) for hierarchical task
planning with open-vocabulary visual detection models, tailored for effective
long-range object navigation in dynamic, unstructured environments. To tackle
real-world challenges including visual jittering, blind zones, and temporary
target loss, we design dedicated solutions such as Laplacian Variance Filtering
for visual stabilization. We also develop a functional execution logic for the
robot that guarantees LOVON's capabilities in autonomous navigation, task
adaptation, and robust task completion. Extensive evaluations demonstrate the
successful completion of long-sequence tasks involving real-time detection,
search, and navigation toward open-vocabulary dynamic targets. Furthermore,
real-world experiments across different legged robots (Unitree Go2, B2, and
H1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.

</details>


### [229] [Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance](https://arxiv.org/abs/2507.06787)
*Sean Smith,Emmanuel Witrant,Ya-Jun Pan*

Main category: cs.RO

TL;DR: 提出了一种基于流函数的导航控制系统，用于障碍物避障，结合了涡流面板方法（VPM）和模型预测控制器（MPC），并通过实时实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂、部分可观测环境中导航时，传统VPM方法在近距离避障和快速移动障碍物处理上的局限性。

Method: 结合VPM和MPC-HOCBF，利用最小包围椭圆（MBE）表示障碍物，并通过自适应卡尔曼滤波（AKF）预测障碍物动态。

Result: 在PX4驱动的Clover无人机Gazebo模拟器和实时实验中验证了系统的有效性。

Conclusion: 该系统能够高效处理复杂环境中的障碍物避障问题，适用于实时导航任务。

Abstract: This article presents a novel stream function-based navigational control
system for obstacle avoidance, where obstacles are represented as
two-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The
approach leverages the vortex panel method (VPM) and incorporates safety
margins to control the stream function and flow properties around virtual
surfaces, enabling navigation in complex, partially observed environments using
real-time sensing. To address the limitations of the VPM in managing relative
distance and avoiding rapidly accelerating obstacles at close proximity, the
system integrates a model predictive controller (MPC) based on higher-order
control barrier functions (HOCBF). This integration incorporates VPM trajectory
generation, state estimation, and constraint handling into a receding-horizon
optimization problem. The 2D rigid surfaces are enclosed using minimum bounding
ellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts
obstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid
avoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone
Gazebo simulator and real-time experiments involving a COEX Clover quadcopter
equipped with a 360 degree LiDAR sensor.

</details>


### [230] [Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand](https://arxiv.org/abs/2507.06822)
*Wei Xu,Yanchao Zhao,Weichao Guo,Xinjun Sheng*

Main category: cs.RO

TL;DR: 提出了一种分层目标条件强化学习框架，用于提升机器人手操作铰接工具的能力，实验成功率为70.8%。


<details>
  <summary>Details</summary>
Motivation: 铰接工具（如镊子或剪刀）的动态形状变化为机器人操作带来独特挑战，此前研究较少探索。

Method: 采用分层策略：低层策略控制工具配置，高层策略定义目标状态并控制机械臂；使用编码器估计工具的功能状态，并通过启发式策略生成回放缓冲区。

Result: 实验表明，机器人能有效操作镊子类工具抓取不同形状和大小的物体，成功率为70.8%。

Conclusion: 该研究展示了强化学习在提升机器人操作铰接工具能力方面的潜力。

Abstract: Manipulating articulated tools, such as tweezers or scissors, has rarely been
explored in previous research. Unlike rigid tools, articulated tools change
their shape dynamically, creating unique challenges for dexterous robotic
hands. In this work, we present a hierarchical, goal-conditioned reinforcement
learning (GCRL) framework to improve the manipulation capabilities of
anthropomorphic robotic hands using articulated tools. Our framework comprises
two policy layers: (1) a low-level policy that enables the dexterous hand to
manipulate the tool into various configurations for objects of different sizes,
and (2) a high-level policy that defines the tool's goal state and controls the
robotic arm for object-picking tasks. We employ an encoder, trained on
synthetic pointclouds, to estimate the tool's affordance states--specifically,
how different tool configurations (e.g., tweezer opening angles) enable
grasping of objects of varying sizes--from input point clouds, thereby enabling
precise tool manipulation. We also utilize a privilege-informed heuristic
policy to generate replay buffer, improving the training efficiency of the
high-level policy. We validate our approach through real-world experiments,
showing that the robot can effectively manipulate a tweezer-like tool to grasp
objects of diverse shapes and sizes with a 70.8 % success rate. This study
highlights the potential of RL to advance dexterous robotic manipulation of
articulated tools.

</details>


### [231] [Friction Estimation for In-Hand Planar Motion](https://arxiv.org/abs/2507.06824)
*Gabriel Arslan Waltersson,Yiannis Karayiannidis*

Main category: cs.RO

TL;DR: 提出了一种在线估计平行夹持器滑动操作中接触特性的方法，包括静摩擦、库仑摩擦和接触半径，并通过仿真和实验验证。


<details>
  <summary>Details</summary>
Motivation: 研究滑动操作中接触特性的实时估计问题，以提升夹持器的操作精度和适应性。

Method: 基于触觉测量的接触力和滑动速度，估计静摩擦、库仑摩擦和接触半径，并提出启发式方法处理快速滑移-粘附动态。

Result: 方法在仿真和实际实验中均得到验证，能够有效估计接触特性。

Conclusion: 该方法为滑动操作中的接触特性估计提供了实用解决方案，并解决了快速滑移-粘附动态的影响。

Abstract: This paper presents a method for online estimation of contact properties
during in-hand sliding manipulation with a parallel gripper. We estimate the
static and Coulomb friction as well as the contact radius from tactile
measurements of contact forces and sliding velocities. The method is validated
in both simulation and real-world experiments. Furthermore, we propose a
heuristic to deal with fast slip-stick dynamics which can adversely affect the
estimation.

</details>


### [232] [Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems](https://arxiv.org/abs/2507.06884)
*Dong Bi,Yongqi Zhao,Zhengguo Gu,Tomislav Mihalj,Jia Hu,Arno Eichberger*

Main category: cs.RO

TL;DR: 提出了一种全栈工具链，用于从真实数据自动生成场景并通过基于CarMaker、ROS和Apollo的协同仿真平台进行高效验证。


<details>
  <summary>Details</summary>
Motivation: 解决现有仿真工具链在快速自动场景生成与支持高级自动驾驶能力的仿真环境集成方面的困难。

Method: 开发了一种全栈工具链，结合CarMaker、ROS和Apollo，实现自动场景生成和协同仿真验证。

Result: 仿真结果证明了该工具链的有效性。

Conclusion: 该工具链为加速自动驾驶系统的部署提供了一种有效的虚拟测试方法。

Abstract: Virtual testing has emerged as an effective approach to accelerate the
deployment of automated driving systems. Nevertheless, existing simulation
toolchains encounter difficulties in integrating rapid, automated scenario
generation with simulation environments supporting advanced automated driving
capabilities. To address this limitation, a full-stack toolchain is presented,
enabling automatic scenario generation from real-world datasets and efficient
validation through a co-simulation platform based on CarMaker, ROS, and Apollo.
The simulation results demonstrate the effectiveness of the proposed toolchain.
A demonstration video showcasing the toolchain is available at the provided
link: https://youtu.be/taJw_-CmSiY.

</details>


### [233] [ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation](https://arxiv.org/abs/2507.06905)
*Wandong Sun,Luying Feng,Baoshi Cao,Yang Liu,Yaochu Jin,Zongwu Xie*

Main category: cs.RO

TL;DR: 论文提出了一种统一的人形机器人运动与操作控制框架（ULC），通过单一策略实现全身协调控制，优于传统分层方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法将运动与操作控制分离，限制了协调性，而人类表现出统一的全身控制能力。

Method: 采用序列技能学习、残差动作建模、命令多项式插值等技术，实现端到端的统一控制。

Result: 在Unitree G1机器人上验证，ULC在跟踪精度、工作空间覆盖和抗干扰能力上优于基线方法。

Conclusion: 统一控制框架可行且高效，为复杂任务提供了更好的协调性和鲁棒性。

Abstract: Loco-Manipulation for humanoid robots aims to enable robots to integrate
mobility with upper-body tracking capabilities. Most existing approaches adopt
hierarchical architectures that decompose control into isolated upper-body
(manipulation) and lower-body (locomotion) policies. While this decomposition
reduces training complexity, it inherently limits coordination between
subsystems and contradicts the unified whole-body control exhibited by humans.
We demonstrate that a single unified policy can achieve a combination of
tracking accuracy, large workspace, and robustness for humanoid
loco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a
single-policy framework that simultaneously tracks root velocity, root height,
torso rotation, and dual-arm joint positions in an end-to-end manner, proving
the feasibility of unified control without sacrificing performance. We achieve
this unified control through key technologies: sequence skill acquisition for
progressive learning complexity, residual action modeling for fine-grained
control adjustments, command polynomial interpolation for smooth motion
transitions, random delay release for robustness to deploy variations, load
randomization for generalization to external disturbances, and
center-of-gravity tracking for providing explicit policy gradients to maintain
stability. We validate our method on the Unitree G1 humanoid robot with 3-DOF
(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better
tracking performance to disentangled methods and demonstrating larger workspace
coverage. The unified dual-arm tracking enables precise manipulation under
external loads while maintaining coordinated whole-body control for complex
loco-manipulation tasks.

</details>


### [234] [Bounomodes: the grazing ox algorithm for exploration of clustered anomalies](https://arxiv.org/abs/2507.06960)
*Samuel Matloob,Ayan Dutta,O. Patrick Kreidl,Swapnonel Roy,Ladislau Bölöni*

Main category: cs.RO

TL;DR: 论文提出了一种名为“bounom=odes”的算法，结合均匀采样和异常区域针对性探索，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统均匀覆盖算法在异常集群场景中效率不足，需优先探索异常区域。

Method: 结合几何原理的均匀采样和基于深度强化学习的异常集群探索。

Result: 实验证明新算法优于多种基线方法。

Conclusion: bounom=odes算法在异常集群场景中更高效。

Abstract: A common class of algorithms for informative path planning (IPP) follows
boustrophedon ("as the ox turns") patterns, which aim to achieve uniform area
coverage. However, IPP is often applied in scenarios where anomalies, such as
plant diseases, pollution, or hurricane damage, appear in clusters. In such
cases, prioritizing the exploration of anomalous regions over uniform coverage
is beneficial. This work introduces a class of algorithms referred to as
bounom\=odes ("as the ox grazes"), which alternates between uniform
boustrophedon sampling and targeted exploration of detected anomaly clusters.
While uniform sampling can be designed using geometric principles, close
exploration of clusters depends on the spatial distribution of anomalies and
must be learned. In our implementation, the close exploration behavior is
learned using deep reinforcement learning algorithms. Experimental evaluations
demonstrate that the proposed approach outperforms several established
baselines.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [235] [MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing](https://arxiv.org/abs/2507.06329)
*Michael Clemens,Ana Marasović*

Main category: cs.SD

TL;DR: MixAssist是一个新的音频-语言数据集，旨在捕捉专家与业余音乐制作人在协作混音会话中的多轮对话，填补了现有研究忽视协作和教学维度的空白。


<details>
  <summary>Details</summary>
Motivation: 当前AI研究过于关注端到端自动化或生成，忽视了音乐制作中的协作和教学需求，尤其是对业余爱好者的支持不足。

Method: 通过7次深入会话和12名制作人参与的431个音频对话回合构建MixAssist数据集，并用于训练和评估音频-语言模型。

Result: 实验表明，基于MixAssist微调的Qwen-Audio模型在生成有帮助且上下文相关的混音建议方面显著优于其他模型。

Conclusion: MixAssist为开发支持音乐混音创作过程的智能AI助手提供了独特资源，强调了音频上下文中的协作教学。

Abstract: While AI presents significant potential for enhancing music mixing and
mastering workflows, current research predominantly emphasizes end-to-end
automation or generation, often overlooking the collaborative and instructional
dimensions vital for co-creative processes. This gap leaves artists,
particularly amateurs seeking to develop expertise, underserved. To bridge
this, we introduce MixAssist, a novel audio-language dataset capturing the
situated, multi-turn dialogue between expert and amateur music producers during
collaborative mixing sessions. Comprising 431 audio-grounded conversational
turns derived from 7 in-depth sessions involving 12 producers, MixAssist
provides a unique resource for training and evaluating audio-language models
that can comprehend and respond to the complexities of real-world music
production dialogues. Our evaluations, including automated LLM-as-a-judge
assessments and human expert comparisons, demonstrate that fine-tuning models
such as Qwen-Audio on MixAssist can yield promising results, with Qwen
significantly outperforming other tested models in generating helpful,
contextually relevant mixing advice. By focusing on co-creative instruction
grounded in audio context, MixAssist enables the development of intelligent AI
assistants designed to support and augment the creative process in music
mixing.

</details>


### [236] [IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer](https://arxiv.org/abs/2507.06481)
*Changheon Han,Yuseop Sim,Hoin Jung,Jiho Lee,Hojun Lee,Yun Seok Kang,Sucheol Woo,Garam Kim,Hyung Wook Park,Martin Byung-Guk Jun*

Main category: cs.SD

TL;DR: 论文介绍了DINOS数据集和IMPACT模型，用于工业机器声音分析，解决了现有方法的泛化性和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 现有监督学习方法在工业音频场景中泛化性差，且缺乏大规模数据集和预训练模型。

Method: 提出DINOS数据集和IMPACT模型，通过自监督学习联合优化全局和局部损失。

Result: IMPACT在30个下游任务中优于现有模型，24个任务表现最佳。

Conclusion: DINOS和IMPACT为工业音频分析提供了新基准，支持未来研究。

Abstract: Acoustic signals from industrial machines offer valuable insights for anomaly
detection, predictive maintenance, and operational efficiency enhancement.
However, existing task-specific, supervised learning methods often scale poorly
and fail to generalize across diverse industrial scenarios, whose acoustic
characteristics are distinct from general audio. Furthermore, the scarcity of
accessible, large-scale datasets and pretrained models tailored for industrial
audio impedes community-driven research and benchmarking. To address these
challenges, we introduce DINOS (Diverse INdustrial Operation Sounds), a
large-scale open-access dataset. DINOS comprises over 74,149 audio samples
(exceeding 1,093 hours) collected from various industrial acoustic scenarios.
We also present IMPACT (Industrial Machine Perception via Acoustic Cognitive
Transformer), a novel foundation model for industrial machine sound analysis.
IMPACT is pretrained on DINOS in a self-supervised manner. By jointly
optimizing utterance and frame-level losses, it captures both global semantics
and fine-grained temporal structures. This makes its representations suitable
for efficient fine-tuning on various industrial downstream tasks with minimal
labeled data. Comprehensive benchmarking across 30 distinct downstream tasks
(spanning four machine types) demonstrates that IMPACT outperforms existing
models on 24 tasks, establishing its superior effectiveness and robustness,
while providing a new performance benchmark for future research.

</details>


### [237] [STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation](https://arxiv.org/abs/2507.06670)
*Wenxiang Guo,Yu Zhang,Changhao Pan,Zhiyuan Zhu,Ruiqi Li,Zhetao Chen,Wenhao Xu,Fei Wu,Zhou Zhao*

Main category: cs.SD

TL;DR: STARS是一个统一的框架，首次同时解决歌唱转录、对齐和风格标注问题，显著提升歌唱数据集的可扩展性和可控性。


<details>
  <summary>Details</summary>
Motivation: 手动标注歌唱数据成本高昂，现有自动标注方法仅解决部分问题，亟需一个统一的解决方案。

Method: STARS采用分层声学特征处理，结合非自回归局部声学编码器，实现多级标注（音素对齐、音符转录、演唱技巧识别、风格描述）。

Result: 实验证明STARS在多个评估维度上优于现有方法，且其标注数据显著提升歌唱合成的自然性和风格控制。

Conclusion: STARS不仅解决了歌唱数据集的可扩展性问题，还为可控歌唱合成开辟了新方法。

Abstract: Recent breakthroughs in singing voice synthesis (SVS) have heightened the
demand for high-quality annotated datasets, yet manual annotation remains
prohibitively labor-intensive and resource-intensive. Existing automatic
singing annotation (ASA) methods, however, primarily tackle isolated aspects of
the annotation pipeline. To address this fundamental challenge, we present
STARS, which is, to our knowledge, the first unified framework that
simultaneously addresses singing transcription, alignment, and refined style
annotation. Our framework delivers comprehensive multi-level annotations
encompassing: (1) precise phoneme-audio alignment, (2) robust note
transcription and temporal localization, (3) expressive vocal technique
identification, and (4) global stylistic characterization including emotion and
pace. The proposed architecture employs hierarchical acoustic feature
processing across frame, word, phoneme, note, and sentence levels. The novel
non-autoregressive local acoustic encoders enable structured hierarchical
representation learning. Experimental validation confirms the framework's
superior performance across multiple evaluation dimensions compared to existing
annotation approaches. Furthermore, applications in SVS training demonstrate
that models utilizing STARS-annotated data achieve significantly enhanced
perceptual naturalness and precise style control. This work not only overcomes
critical scalability challenges in the creation of singing datasets but also
pioneers new methodologies for controllable singing voice synthesis. Audio
samples are available at https://gwx314.github.io/stars-demo/.

</details>


### [238] [Exploring State-Space-Model based Language Model in Music Generation](https://arxiv.org/abs/2507.06674)
*Wei-Jaw Lee,Fang-Chih Hsieh,Xuanjun Chen,Fang-Duo Tsai,Yi-Hsuan Yang*

Main category: cs.SD

TL;DR: 论文探讨了基于Mamba的SiMBA架构在文本到音乐生成中的潜力，发现其在有限资源下比Transformer更快收敛且生成质量更高。


<details>
  <summary>Details</summary>
Motivation: 探索Mamba架构在文本到音乐生成中的应用，以解决Transformer的高资源需求问题。

Method: 采用RVQ离散令牌表示音乐，并调整SiMBA（Mamba编码器）为解码器，与Transformer解码器对比。

Result: SiMBA在有限资源下收敛更快，生成结果更接近真实音乐。

Conclusion: SSM（如SiMBA）在高效且富有表现力的文本到音乐生成中具有潜力。

Abstract: The recent surge in State Space Models (SSMs), particularly the emergence of
Mamba, has established them as strong alternatives or complementary modules to
Transformers across diverse domains. In this work, we aim to explore the
potential of Mamba-based architectures for text-to-music generation. We adopt
discrete tokens of Residual Vector Quantization (RVQ) as the modeling
representation and empirically find that a single-layer codebook can capture
semantic information in music. Motivated by this observation, we focus on
modeling a single-codebook representation and adapt SiMBA, originally designed
as a Mamba-based encoder, to function as a decoder for sequence modeling. We
compare its performance against a standard Transformer-based decoder. Our
results suggest that, under limited-resource settings, SiMBA achieves much
faster convergence and generates outputs closer to the ground truth. This
demonstrates the promise of SSMs for efficient and expressive text-to-music
generation. We put audio examples on Github.

</details>


### [239] [Constraint Optimized Multichannel Mixer-limiter Design](https://arxiv.org/abs/2507.06769)
*Yuancheng Luo,Dmitriy Yamkovoy,Guillermo Garcia*

Main category: cs.SD

TL;DR: 提出了一种耦合的混音器-限制器-包络设计，通过线性约束二次规划降低多通道音频处理的失真，并优化了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统多通道音频混音器和限制器设计因高计算复杂性和运行时成本而解耦，限制了内容在扬声器阵列上的再现效果。

Method: 采用线性约束二次规划，最小化多通道增益变量的失真目标，同时满足样本混合约束；提出了非对称恒定重叠相加窗口优化、目标函数近似及变量和约束减少的新方法。

Result: 实验表明，耦合设计显著降低了失真，同时权衡了实时处理的计算效率。

Conclusion: 耦合设计在多通道音频处理中实现了失真减少和计算效率的平衡，适用于实时应用。

Abstract: Multichannel audio mixer and limiter designs are conventionally decoupled for
content reproduction over loudspeaker arrays due to high computational
complexity and run-time costs. We propose a coupled mixer-limiter-envelope
design formulated as an efficient linear-constrained quadratic program that
minimizes a distortion objective over multichannel gain variables subject to
sample mixture constraints. Novel methods for asymmetric constant overlap-add
window optimization, objective function approximation, variable and constraint
reduction are presented. Experiments demonstrate distortion reduction of the
coupled design, and computational trade-offs required for efficient real-time
processing.

</details>


### [240] [Revealing the Hidden Temporal Structure of HubertSoft Embeddings based on the Russian Phonetic Corpus](https://arxiv.org/abs/2507.06794)
*Anastasia Ananeva,Anton Tomilov,Marina Volkova*

Main category: cs.SD

TL;DR: 研究探讨了HuBERTSoft模型在音素边界处提取的嵌入是否能够捕捉音素身份和时序结构，发现其能有效编码音素过渡信息。


<details>
  <summary>Details</summary>
Motivation: 尽管自监督学习模型已证明能从原始音频中提取音素特征，但其是否保留时序结构（如音素边界处的嵌入是否反映相邻音素的身份和顺序）尚不明确。

Method: 使用CORPRES俄语语音语料库，标记20毫秒嵌入窗口的音素三元组（开始、中心、结束），训练神经网络预测这些位置，并通过多种评估指标分析时序敏感性。

Result: 结果显示，音素边界处的嵌入能捕捉音素身份和时序顺序，边界处准确率尤其高，且模型编码了发音细节和协同发音效应。

Conclusion: 研究增进了对自监督学习语音表示内部结构的理解，表明其在音系分析和细粒度转录任务中具有潜力。

Abstract: Self-supervised learning (SSL) models such as Wav2Vec 2.0 and HuBERT have
shown remarkable success in extracting phonetic information from raw audio
without labelled data. While prior work has demonstrated that SSL embeddings
encode phonetic features at the frame level, it remains unclear whether these
models preserve temporal structure, specifically, whether embeddings at phoneme
boundaries reflect the identity and order of adjacent phonemes. This study
investigates the extent to which boundary-sensitive embeddings from HubertSoft,
a soft-clustering variant of HuBERT, encode phoneme transitions. Using the
CORPRES Russian speech corpus, we labelled 20 ms embedding windows with
triplets of phonemes corresponding to their start, centre, and end segments. A
neural network was trained to predict these positions separately, and multiple
evaluation metrics, such as ordered, unordered accuracy and a flexible centre
accuracy, were used to assess temporal sensitivity. Results show that
embeddings extracted at phoneme boundaries capture both phoneme identity and
temporal order, with especially high accuracy at segment boundaries. Confusion
patterns further suggest that the model encodes articulatory detail and
coarticulatory effects. These findings contribute to our understanding of the
internal structure of SSL speech representations and their potential for
phonological analysis and fine-grained transcription tasks.

</details>


### [241] [Data-Balanced Curriculum Learning for Audio Question Answering](https://arxiv.org/abs/2507.06815)
*Gijs Wijngaard,Elia Formisano,Michele Esposito,Michel Dumontier*

Main category: cs.SD

TL;DR: 论文提出了一种结合课程学习和统计平衡的方法，解决音频问答任务中的数据不平衡和训练不稳定性问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前模型在音频问答任务中面临数据不平衡和训练不稳定的挑战，需要一种更有效的方法来提升性能。

Method: 通过语言模型标注问题难度，按从易到难的顺序训练；统计过滤过表示的音频类别，并使用引导解码约束输出格式。

Result: 在DCASE 2025训练集和五个公共数据集上，数据优化使准确率比基线模型提高了11.7%，达到64.2%。

Conclusion: 结合课程学习和数据平衡的方法有效提升了音频问答任务的性能，为类似任务提供了新思路。

Abstract: Audio question answering (AQA) requires models to understand acoustic content
and perform complex reasoning. Current models struggle with dataset imbalances
and unstable training dynamics. This work combines curriculum learning with
statistical data balancing to address these challenges. The method labels
question difficulty using language models, then trains progressively from easy
to hard examples. Statistical filtering removes overrepresented audio
categories, and guided decoding constrains outputs to valid multiple-choice
formats. Experiments on the DCASE 2025 training set and five additional public
datasets show that data curation improves accuracy by 11.7% over baseline
models, achieving 64.2% on the DCASE 2025 benchmark.

</details>


### [242] [Physics-Informed Direction-Aware Neural Acoustic Fields](https://arxiv.org/abs/2507.06826)
*Yoshiki Masuyama,François G. Germain,Gordon Wichern,Christopher Ick,Jonathan Le Roux*

Main category: cs.SD

TL;DR: 本文提出了一种基于物理信息的神经网络（PINN）用于建模一阶Ambisonic（FOA）房间脉冲响应（RIRs），通过结合神经网络的强大建模能力和声波传播的物理原理，扩展了PINN框架以建模FOA RIRs。


<details>
  <summary>Details</summary>
Motivation: FOA RIRs不仅提供空间特性，还广泛应用于沉浸式音频生成，但现有PINN方法主要针对全向麦克风测量的声压，缺乏对FOA RIRs的建模。

Method: 通过推导基于粒子速度与FOA的(X, Y, Z)通道对应关系的两个物理先验，将预测的W通道与其他通道通过偏导数关联，并施加物理可行的关系。

Result: 实验证实，相比无物理先验的神经网络，所提方法更有效。

Conclusion: 扩展PINN框架以建模FOA RIRs是可行的，且物理先验显著提升了性能。

Abstract: This paper presents a physics-informed neural network (PINN) for modeling
first-order Ambisonic (FOA) room impulse responses (RIRs). PINNs have
demonstrated promising performance in sound field interpolation by combining
the powerful modeling capability of neural networks and the physical principles
of sound propagation. In room acoustics, PINNs have typically been trained to
represent the sound pressure measured by omnidirectional microphones where the
wave equation or its frequency-domain counterpart, i.e., the Helmholtz
equation, is leveraged. Meanwhile, FOA RIRs additionally provide spatial
characteristics and are useful for immersive audio generation with a wide range
of applications. In this paper, we extend the PINN framework to model FOA RIRs.
We derive two physics-informed priors for FOA RIRs based on the correspondence
between the particle velocity and the (X, Y, Z)-channels of FOA. These priors
associate the predicted W-channel and other channels through their partial
derivatives and impose the physically feasible relationship on the four
channels. Our experiments confirm the effectiveness of the proposed method
compared with a neural network without the physics-informed prior.

</details>


### [243] [Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation](https://arxiv.org/abs/2507.07043)
*Haris Khan,Shumaila Asif,Hassan Nasir*

Main category: cs.SD

TL;DR: AI在助听器中的应用从传统放大系统转向智能、情境感知的音频处理。本文回顾了AI驱动的选择性噪声消除（SNC）的进展，包括技术演进、实施挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨AI如何改进助听器性能，解决传统方法的局限性，如噪声处理和个性化需求。

Method: 系统综述了深度学习架构、硬件部署策略、临床验证及用户中心设计，涵盖从早期机器学习到最新深度网络的演进。

Result: AI模型显著优于传统方法，如18.3 dB SI-SDR提升，实时实现（<10 ms），但实际部署仍面临功耗、环境变化等挑战。

Conclusion: 未来需关注轻量模型、持续学习、标准化评估及临床转化，以实现全球范围内的变革性助听解决方案。

Abstract: The integration of artificial intelligence into hearing assistance marks a
paradigm shift from traditional amplification-based systems to intelligent,
context-aware audio processing. This systematic literature review evaluates
advances in AI-driven selective noise cancellation (SNC) for hearing aids,
highlighting technological evolution, implementation challenges, and future
research directions. We synthesize findings across deep learning architectures,
hardware deployment strategies, clinical validation studies, and user-centric
design. The review traces progress from early machine learning models to
state-of-the-art deep networks, including Convolutional Recurrent Networks for
real-time inference and Transformer-based architectures for high-accuracy
separation. Key findings include significant gains over traditional methods,
with recent models achieving up to 18.3 dB SI-SDR improvement on
noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and
promising clinical outcomes. Yet, challenges remain in bridging lab-grade
models with real-world deployment - particularly around power constraints,
environmental variability, and personalization. Identified research gaps
include hardware-software co-design, standardized evaluation protocols, and
regulatory considerations for AI-enhanced hearing devices. Future work must
prioritize lightweight models, continual learning, contextual-based
classification and clinical translation to realize transformative hearing
solutions for millions globally.

</details>


### [244] [A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering](https://arxiv.org/abs/2507.07046)
*Shahana Yasmin Chowdhury,Bithi Banik,Md Tamjidul Hoque,Shreya Banerjee*

Main category: cs.SD

TL;DR: 论文提出了一种DCRF-BiLSTM模型，用于识别七种情感，并在五个数据集上取得了高准确率，综合数据集表现优异。


<details>
  <summary>Details</summary>
Motivation: 提升语音情感识别（SER）在人机交互（HCI）和人工智能（AI）领域的应用效果。

Method: 使用DCRF-BiLSTM模型，在RAVDESS、TESS、SAVEE、EmoDB和Crema-D五个数据集上训练和测试。

Result: 单个数据集准确率高达97.83%至100%，综合数据集准确率为93.76%，优于现有研究。

Conclusion: DCRF-BiLSTM模型具有鲁棒性和泛化能力，适用于多种数据集。

Abstract: Nowadays, speech emotion recognition (SER) plays a vital role in the field of
human-computer interaction (HCI) and the evolution of artificial intelligence
(AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions:
neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on
five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C).
The model achieves high accuracy on individual datasets, including 97.83% on
RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS
and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy,
outperforming previously reported results. To our knowledge, no existing study
has evaluated a single SER model across all five benchmark datasets (i.e.,
R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive
combination and achieve a remarkable overall accuracy of 93.76%. These results
confirm the robustness and generalizability of our DCRF-BiLSTM framework across
diverse datasets.

</details>


### [245] [Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification](https://arxiv.org/abs/2507.07058)
*Martin Sondermann,Pinar Bisgin,Niklas Tschorn,Anja Burmann,Christoph M. Friedrich*

Main category: cs.SD

TL;DR: 论文比较了四种模型（两种CNN和两种BEATs变换器）用于心音图分类，发现CNN性能更优，但变换器在效率上有优势。


<details>
  <summary>Details</summary>
Motivation: 探讨不同模型和归一化方法对心音图分类性能的影响，为临床诊断提供指导。

Method: 使用PhysioNet2022数据集，比较两种CNN和两种BEATs变换器在固定长度和心周期归一化下的表现。

Result: CNN固定长度窗口AUROC为79.5%，心周期归一化为75.4%；BEATs固定长度窗口为65.7%，心周期归一化为70.1%。

Conclusion: CNN性能更优，但BEATs在效率上有潜力；需在准确性和计算效率间权衡。

Abstract: The automated classification of phonocardiogram (PCG) recordings represents a
substantial advancement in cardiovascular diagnostics. This paper presents a
systematic comparison of four distinct models for heart murmur detection: two
specialized convolutional neural networks (CNNs) and two zero-shot universal
audio transformers (BEATs), evaluated using fixed-length and heart cycle
normalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart
cycle normalization method tailored to individual cardiac rhythms is
introduced. The findings indicate the following AUROC values: the CNN model
with fixed-length windowing achieves 79.5%, the CNN model with heart cycle
normalization scores 75.4%, the BEATs transformer with fixed-length windowing
achieves 65.7%, and the BEATs transformer with heart cycle normalization
results in 70.1%.
  The findings indicate that physiological signal constraints, especially those
introduced by different normalization strategies, have a substantial impact on
model performance. The research provides evidence-based guidelines for
architecture selection in clinical settings, emphasizing the need for a balance
between accuracy and computational efficiency. Although specialized CNNs
demonstrate superior performance overall, the zero-shot transformer models may
offer promising efficiency advantages during development, such as faster
training and evaluation cycles, despite their lower classification accuracy.
These findings highlight the potential of automated classification systems to
enhance cardiac diagnostics and improve patient care.

</details>


### [246] [Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach](https://arxiv.org/abs/2507.07066)
*Adrian S. Roman,Iran R. Roman,Juan P. Bello*

Main category: cs.SD

TL;DR: 提出了一种自监督的潜在声学映射（LAM）模型，结合了传统方法的可解释性和深度学习的适应性，在声源定位任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统波束形成方法计算量大且对声学变化敏感，而监督深度学习方法需要大量标注数据且缺乏可解释性。两者在多样声学环境和阵列配置下泛化能力有限。

Method: 引入自监督的LAM框架，生成高分辨率声学图，适应不同声学条件和麦克风阵列。

Result: 在LOCATA和STARSS基准测试中，LAM的定位性能与现有监督方法相当或更优，其声学图还可提升监督模型的定位精度。

Conclusion: LAM结合了传统与深度学习的优势，有望推动自适应高性能声源定位系统的发展。

Abstract: Acoustic mapping techniques have long been used in spatial audio processing
for direction of arrival estimation (DoAE). Traditional beamforming methods for
acoustic mapping, while interpretable, often rely on iterative solvers that can
be computationally intensive and sensitive to acoustic variability. On the
other hand, recent supervised deep learning approaches offer feedforward speed
and robustness but require large labeled datasets and lack interpretability.
Despite their strengths, both methods struggle to consistently generalize
across diverse acoustic setups and array configurations, limiting their broader
applicability. We introduce the Latent Acoustic Mapping (LAM) model, a
self-supervised framework that bridges the interpretability of traditional
methods with the adaptability and efficiency of deep learning methods. LAM
generates high-resolution acoustic maps, adapts to varying acoustic conditions,
and operates efficiently across different microphone arrays. We assess its
robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves
comparable or superior localization performance to existing supervised methods.
Additionally, we show that LAM's acoustic maps can serve as effective features
for supervised models, further enhancing DoAE accuracy and underscoring its
potential to advance adaptive, high-performance sound localization systems.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [247] [Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice](https://arxiv.org/abs/2507.06235)
*Yuto Mandai,Katie Seaborn,Tomoyasu Nakano,Xin Sun,Yijia Wang,Jun Kato*

Main category: cs.HC

TL;DR: 研究探索了声音中的“可爱”（kawaii）元素及其操纵方法，填补了以往仅关注视觉可爱性的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦于视觉可爱性，而声音方面的可爱性研究不足，因此探索声音中的可爱元素及其操纵方法。

Method: 通过四阶段研究（N=512），分析文本转语音（TTS）和游戏角色声音，操纵基频和共振峰频率。

Result: 发现某些声音存在可爱的“甜点”，但效果有限且存在天花板效应。

Conclusion: 初步验证了可爱声音模型，并提供了操纵计算机声音可爱感知的基本方法。

Abstract: "Kawaii" is the Japanese concept of cute, which carries sociocultural
connotations related to social identities and emotional responses. Yet,
virtually all work to date has focused on the visual side of kawaii, including
in studies of computer agents and social robots. In pursuit of formalizing the
new science of kawaii vocalics, we explored what elements of voice relate to
kawaii and how they might be manipulated, manually and automatically. We
conducted a four-phase study (grand N = 512) with two varieties of computer
voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet
spots" through manipulation of fundamental and formant frequencies, but only
for certain voices and to a certain extent. Findings also suggest a ceiling
effect for the kawaii vocalics of certain voices. We offer empirical validation
of the preliminary kawaii vocalics model and an elementary method for
manipulating kawaii perceptions of computer voice.

</details>


### [248] [Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents](https://arxiv.org/abs/2507.06483)
*Zackary Rackauckas,Julia Hirschberg*

Main category: cs.HC

TL;DR: 研究探讨了动漫风格语音代理在多模态语言学习环境中的用户交互影响，发现代理设计显著影响用户体验和学习动机。


<details>
  <summary>Details</summary>
Motivation: 探索风格化语音代理如何通过不同语音风格和情感语调提升语言学习交互效果。

Method: 采用混合方法评估54名参与者与基于大语言模型和文本转语音合成的动漫风格代理的交互。

Result: 代理的声音、人设和语言风格显著影响用户参与度、情感反应和学习策略。

Conclusion: 研究为设计更具吸引力和社交响应性的代理系统提供了指导。

Abstract: This study investigates how stylized, voiced agents shape user interaction in
a multimodal language learning environment. We conducted a mixed-methods
evaluation of 54 participants interacting with anime-inspired characters
powered by large language models and expressive text-to-speech synthesis. These
agents responded in Japanese character language, offering users asynchronous,
semi-structured conversation in varying speech styles and emotional tones. We
analyzed user engagement patterns, perceived usability, emotional responses,
and learning behaviors, with particular attention to how agent stylization
influenced interaction across language proficiency levels and cultural
backgrounds. Our findings reveal that agent design, especially voice, persona,
and linguistic style, substantially affected user experience, motivation, and
strategy. This work contributes to the understanding of affective, culturally
stylized agents in human-agent interaction and offers guidance for designing
more engaging, socially responsive systems.

</details>


### [249] [Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool](https://arxiv.org/abs/2507.06734)
*Milena Pustet,Elisabeth Steffen,Helena Mihaljević,Grischa Stanjek,Yannis Illies*

Main category: cs.HC

TL;DR: 探讨公民社会组织（CSOs）在AI辅助开源监测工具开发中的主动角色，以应对有害在线内容。


<details>
  <summary>Details</summary>
Motivation: 平台减少内容审核投入，CSOs具备主题专长和上下文理解能力，应成为技术工具的共同开发者。

Method: 与CSO利益相关者合作，开发AI辅助的开源监测工具，用于监测Telegram上的反民主运动。

Result: 目前为进行中的工作，旨在促进开源社区、学术界与公民社会的合作。

Conclusion: CSOs应积极参与技术工具开发，确保其符合需求与价值观，而非被动使用。

Abstract: The role of civil society organizations (CSOs) in monitoring harmful online
content is increasingly crucial, especially as platform providers reduce their
investment in content moderation. AI tools can assist in detecting and
monitoring harmful content at scale. However, few open-source tools offer
seamless integration of AI models and social media monitoring infrastructures.
Given their thematic expertise and contextual understanding of harmful content,
CSOs should be active partners in co-developing technological tools, providing
feedback, helping to improve models, and ensuring alignment with stakeholder
needs and values, rather than as passive 'consumers'. However, collaborations
between the open source community, academia, and civil society remain rare, and
research on harmful content seldom translates into practical tools usable by
civil society actors. This work in progress explores how CSOs can be
meaningfully involved in an AI-assisted open-source monitoring tool of
anti-democratic movements on Telegram, which we are currently developing in
collaboration with CSO stakeholders.

</details>


### [250] [Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding](https://arxiv.org/abs/2507.06779)
*Martin Wimpff,Jan Zerfowski,Bin Yang*

Main category: cs.HC

TL;DR: 提出了一种名为RAP的无参数方法，解决了深度学习在实时脑机接口中的三大挑战：离线到在线的转换、计算复杂性和数据需求。


<details>
  <summary>Details</summary>
Motivation: 深度学习在离线脑机接口中表现优异，但在实时应用中面临三大挑战：离线模型难以直接用于在线解码、滑动窗口增加计算复杂性、数据需求大。

Method: 引入RAP方法，通过修改现有离线模型的池化层以适应在线解码需求，并利用源自由域适应减少数据需求。

Result: RAP在实时脑机接口中表现稳健高效，支持隐私保护、减少校准需求，并促进共适应系统。

Conclusion: RAP为深度学习在在线脑机接口中的广泛应用奠定了基础，推动了用户中心化高性能系统的开发。

Abstract: Despite the growing success of deep learning (DL) in offline brain-computer
interfaces (BCIs), its adoption in real-time applications remains limited due
to three primary challenges. First, most DL solutions are designed for offline
decoding, making the transition to online decoding unclear. Second, the use of
sliding windows in online decoding substantially increases computational
complexity. Third, DL models typically require large amounts of training data,
which are often scarce in BCI applications. To address these challenges and
enable real-time, cross-subject decoding without subject-specific calibration,
we introduce realtime adaptive pooling (RAP), a novel parameter-free method.
RAP seamlessly modifies the pooling layers of existing offline DL models to
meet online decoding requirements. It also reduces computational complexity
during training by jointly decoding consecutive sliding windows. To further
alleviate data requirements, our method leverages source-free domain
adaptation, enabling privacy-preserving adaptation across varying amounts of
target data. Our results demonstrate that RAP provides a robust and efficient
framework for real-time BCI applications. It preserves privacy, reduces
calibration demands, and supports co-adaptive BCI systems, paving the way for
broader adoption of DL in online BCIs. These findings lay a strong foundation
for developing user-centered, high-performance BCIs that facilitate immediate
feedback and user learning.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [251] [From large-eddy simulations to deep learning: A U-net model for fast urban canopy flow predictions](https://arxiv.org/abs/2507.06533)
*Themistoklis Vargiemezis,Catherine Gorlé*

Main category: physics.comp-ph

TL;DR: 该研究提出了一种基于深度神经网络的快速预测城市风场的方法，显著降低了计算时间和成本。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如风洞和大涡模拟）成本高且耗时，需要更高效的解决方案来预测城市风场。

Method: 采用U-Net架构，输入为二维建筑表示和距离函数，结合空间注意力模块，训练数据来自252种合成城市配置。

Result: 模型在测试集上表现优异，平均相对误差为9.3%（速度）和5.2%（湍流强度），计算时间从10小时缩短至1秒。

Conclusion: 深度学习为城市风场评估提供了快速、准确的解决方案，有助于提升城市舒适性和安全性。

Abstract: Accurate prediction of wind flow fields in urban canopies is crucial for
ensuring pedestrian comfort, safety, and sustainable urban design. Traditional
methods using wind tunnels and Computational Fluid Dynamics, such as Large-Eddy
Simulations (LES), are limited by high costs, computational demands, and time
requirements. This study presents a deep neural network (DNN) approach for fast
and accurate predictions of urban wind flow fields, reducing computation time
from an order of 10 hours on 32 CPUs for one LES evaluation to an order of 1
second on a single GPU using the DNN model. We employ a U-Net architecture
trained on LES data including 252 synthetic urban configurations at seven wind
directions ($0^{o}$ to $90^{o}$ in $15^{o}$ increments). The model predicts two
key quantities of interest: mean velocity magnitude and streamwise turbulence
intensity, at multiple heights within the urban canopy. The U-net uses 2D
building representations augmented with signed distance functions and their
gradients as inputs, forming a $256\times256\times9$ tensor. In addition, a
Spatial Attention Module is used for feature transfer through skip connections.
The loss function combines the root-mean-square error of predictions, their
gradient magnitudes, and L2 regularization. Model evaluation on 50 test cases
demonstrates high accuracy with an overall mean relative error of 9.3% for
velocity magnitude and 5.2% for turbulence intensity. This research shows the
potential of deep learning approaches to provide fast, accurate urban wind
assessments essential for creating comfortable and safe urban environments.
Code is available at https://github.com/tvarg/Urban-FlowUnet.git

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [252] [Towards LLM-based Root Cause Analysis of Hardware Design Failures](https://arxiv.org/abs/2507.06512)
*Siyu Qiu,Muzhi Wang,Raheel Afsharmazayejani,Mohammad Moradi Shahmiri,Benjamin Tan,Hammond Pearce*

Main category: cs.AR

TL;DR: LLMs在数字硬件设计中的潜力，特别是在解释合成和仿真中的设计问题和错误根源方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何辅助硬件设计过程中的问题诊断，推动其在硬件设计和安全分析中的广泛应用。

Method: 使用OpenAI的o3-mini推理模型及其他先进模型，结合检索增强生成技术，测试34种错误场景。

Result: o3-mini模型在pass@5评分下100%正确，其他模型和配置通常超过80%，检索增强生成下超过90%。

Conclusion: LLMs在硬件设计问题诊断中表现出色，有望成为未来设计流程中的重要工具。

Abstract: With advances in large language models (LLMs), new opportunities have emerged
to develop tools that support the digital hardware design process. In this
work, we explore how LLMs can assist with explaining the root cause of design
issues and bugs that are revealed during synthesis and simulation, a necessary
milestone on the pathway towards widespread use of LLMs in the hardware design
process and for hardware security analysis. We find promising results: for our
corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model
reached a correct determination 100% of the time under pass@5 scoring, with
other state of the art models and configurations usually achieving more than
80% performance and more than 90% when assisted with retrieval-augmented
generation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [253] [Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)
*Zhenwen Liang,Linfeng Song,Yang Li,Tao Yang,Feng Zhang,Haitao Mi,Dong Yu*

Main category: cs.LO

TL;DR: 论文提出了一种新型框架，通过解耦高级推理与低级证明生成，显著提升了自动定理证明的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在非正式推理方面表现优异，但在形式化证明上表现较差，原因是现有方法将推理与证明紧密耦合，惩罚了深度推理。

Method: 采用模块化设计，使用两个专门模型：一个通用的推理器生成子目标引理，一个高效的证明器验证它们。

Result: 在IMO问题集上成功解决了5个问题，超越了之前开源证明器的表现。

Conclusion: 该框架为自动化推理提供了重要进展，并公开了数据集以促进未来研究。

Abstract: Automated Theorem Proving (ATP) in formal languages is a foundational
challenge for AI. While Large Language Models (LLMs) have driven remarkable
progress, a significant gap remains between their powerful informal reasoning
capabilities and their weak formal proving performance. Recent studies show
that the informal accuracy exceeds 80% while formal success remains below 8% on
benchmarks like PutnamBench. We argue this gap persists because current
state-of-the-art provers, by tightly coupling reasoning and proving, are
trained with paradigms that inadvertently punish deep reasoning in favor of
shallow, tactic-based strategies. To bridge this fundamental gap, we propose a
novel framework that decouples high-level reasoning from low-level proof
generation. Our approach utilizes two distinct, specialized models: a powerful,
general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an
efficient Prover to rigorously verify them. This modular design liberates the
model's full reasoning potential and bypasses the pitfalls of end-to-end
training. We evaluate our method on a challenging set of post-2000 IMO
problems, a problem set on which no prior open-source prover has reported
success. Our decoupled framework successfully solves 5 of these problems,
demonstrating a significant step towards automated reasoning on exceptionally
difficult mathematical challenges. To foster future research, we release our
full dataset of generated and verified lemmas for a wide range of IMO problems,
available at https://tencent-imo.github.io/ .

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [254] [Self-supervised learning predicts plant growth trajectories from multi-modal industrial greenhouse data](https://arxiv.org/abs/2507.06336)
*Adam J Riesselman,Evan M Cofer,Therese LaRue,Wim Meeussen*

Main category: q-bio.QM

TL;DR: 利用移动机器人平台和自监督建模方法，预测植物生长轨迹，提升农业研究和运营效率。


<details>
  <summary>Details</summary>
Motivation: 量化植物生长动态和生物量积累对优化作物生产至关重要，但大规模获取高质量生长数据困难。

Method: 使用移动机器人平台收集高分辨率环境传感和表型数据，采用自监督建模方法预测植物生长轨迹。

Result: 成功预测了植物未来高度和收获质量，展示了机器人自动化和机器学习的结合优势。

Conclusion: 该方法为农业研究和运营提供了可操作的见解，是机器人自动化和机器学习结合的重要进展。

Abstract: Quantifying organism-level phenotypes, such as growth dynamics and biomass
accumulation, is fundamental to understanding agronomic traits and optimizing
crop production. However, quality growing data of plants at scale is difficult
to generate. Here we use a mobile robotic platform to capture high-resolution
environmental sensing and phenotyping measurements of a large-scale hydroponic
leafy greens system. We describe a self-supervised modeling approach to build a
map from observed growing data to the entire plant growth trajectory. We
demonstrate our approach by forecasting future plant height and harvest mass of
crops in this system. This approach represents a significant advance in
combining robotic automation and machine learning, as well as providing
actionable insights for agronomic research and operational efficiency.

</details>


### [255] [DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning](https://arxiv.org/abs/2507.07060)
*Shreyas Vinaya Sathyanarayana,Rahil Shah,Sharanabasava D. Hiremath,Rishikesh Panda,Rahul Jana,Riya Singh,Rida Irfan,Ashwin Murali,Bharath Ramsundar*

Main category: q-bio.QM

TL;DR: DeepRetro是一个结合LLM和传统方法的迭代式逆合成框架，通过动态路径探索和反馈驱动循环，有效生成新颖的合成路径。


<details>
  <summary>Details</summary>
Motivation: 传统逆合成方法依赖预定义模板，难以发现新路径，而LLM的潜力尚未完全发挥。

Method: 结合模板引擎和LLM生成能力，通过迭代反馈循环验证和优化合成路径。

Result: 在基准测试和案例研究中成功识别可行且新颖的合成路径，并支持人机交互反馈。

Conclusion: DeepRetro展示了LLM在复杂化学合成中的潜力，推动了逆合成领域的发展。

Abstract: Retrosynthesis, the identification of precursor molecules for a target
compound, is pivotal for synthesizing complex molecules, but faces challenges
in discovering novel pathways beyond predefined templates. Recent large
language model (LLM) approaches to retrosynthesis have shown promise but
effectively harnessing LLM reasoning capabilities for effective multi-step
planning remains an open question. To address this challenge, we introduce
DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic
framework. Our approach integrates the strengths of conventional
template-based/Monte Carlo tree search tools with the generative power of LLMs
in a step-wise, feedback-driven loop. Initially, synthesis planning is
attempted with a template-based engine. If this fails, the LLM subsequently
proposes single-step retrosynthetic disconnections. Crucially, these
suggestions undergo rigorous validity, stability, and hallucination checks
before the resulting precursors are recursively fed back into the pipeline for
further evaluation. This iterative refinement allows for dynamic pathway
exploration and correction. We demonstrate the potential of this pipeline
through benchmark evaluations and case studies, showcasing its ability to
identify viable and potentially novel retrosynthetic routes. In particular, we
develop an interactive graphical user interface that allows expert human
chemists to provide human-in-the-loop feedback to the reasoning algorithm. This
approach successfully generates novel pathways for complex natural product
compounds, demonstrating the potential for iterative LLM reasoning to advance
state-of-art in complex chemical syntheses.

</details>


### [256] [PAST: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer](https://arxiv.org/abs/2507.06418)
*Changchun Yang,Haoyang Li,Yushuai Wu,Yilan Zhang,Yifeng Jiao,Yu Zhang,Rihan Huang,Yuan Cheng,Yuan Qi,Xin Guo,Xin Gao*

Main category: q-bio.QM

TL;DR: PAST是一个基于病理图像和单细胞转录组的跨模态基础模型，能够联合编码细胞形态和基因表达，提升精准肿瘤学研究的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的病理基础模型缺乏与单细胞分子数据的整合，限制了其在精准肿瘤学中的应用。

Method: PAST通过训练2000万对病理图像和单细胞转录组数据，学习跨模态的统一表示，捕捉细胞水平的空间和分子异质性。

Result: PAST能够准确预测单细胞基因表达、虚拟分子染色和多模态生存分析，性能优于现有方法。

Conclusion: PAST为病理基础模型提供了新范式，支持高分辨率空间组学、机制发现和精准癌症研究。

Abstract: While pathology foundation models have transformed cancer image analysis,
they often lack integration with molecular data at single-cell resolution,
limiting their utility for precision oncology. Here, we present PAST, a
pan-cancer single-cell foundation model trained on 20 million paired
histopathology images and single-cell transcriptomes spanning multiple tumor
types and tissue contexts. By jointly encoding cellular morphology and gene
expression, PAST learns unified cross-modal representations that capture both
spatial and molecular heterogeneity at the cellular level. This approach
enables accurate prediction of single-cell gene expression, virtual molecular
staining, and multimodal survival analysis directly from routine pathology
slides. Across diverse cancers and downstream tasks, PAST consistently exceeds
the performance of existing approaches, demonstrating robust generalizability
and scalability. Our work establishes a new paradigm for pathology foundation
models, providing a versatile tool for high-resolution spatial omics,
mechanistic discovery, and precision cancer research.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [257] [Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity](https://arxiv.org/abs/2507.06479)
*Niloofar Asefi,Leonard Lupin-Jimenez,Tianning Wu,Ruoying He,Ashesh Chattopadhyay*

Main category: physics.ao-ph

TL;DR: 论文提出了一种结合神经算子和去噪扩散概率模型（DDPMs）的深度学习框架，用于从极稀疏的拉格朗日观测数据中重建高分辨率海洋状态。


<details>
  <summary>Details</summary>
Motivation: 海洋观测数据的稀疏性和不规则性限制了海洋动力学的重建，传统方法难以恢复中尺度湍流现象。

Method: 通过将生成模型与神经算子输出结合，框架能够在小尺度、高波数动态下实现高精度重建。

Result: 在合成数据和真实卫星观测中，该方法在99%和99.9%的稀疏度下仍表现优异。

Conclusion: 该方法在严重空间采样限制下优于其他深度学习基线，具有鲁棒性。

Abstract: Reconstructing ocean dynamics from observational data is fundamentally
limited by the sparse, irregular, and Lagrangian nature of spatial sampling,
particularly in subsurface and remote regions. This sparsity poses significant
challenges for forecasting key phenomena such as eddy shedding and rogue waves.
Traditional data assimilation methods and deep learning models often struggle
to recover mesoscale turbulence under such constraints. We leverage a deep
learning framework that combines neural operators with denoising diffusion
probabilistic models (DDPMs) to reconstruct high-resolution ocean states from
extremely sparse Lagrangian observations. By conditioning the generative model
on neural operator outputs, the framework accurately captures small-scale,
high-wavenumber dynamics even at $99\%$ sparsity (for synthetic data) and
$99.9\%$ sparsity (for real satellite observations). We validate our method on
benchmark systems, synthetic float observations, and real satellite data,
demonstrating robust performance under severe spatial sampling limitations as
compared to other deep learning baselines.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [258] [QoE Optimization for Semantic Self-Correcting Video Transmission in Multi-UAV Networks](https://arxiv.org/abs/2507.06717)
*Xuyang Chen,Chong Huang,Daquan Feng,Lei Luo,Yao Sun,Xiang-Gen Xia*

Main category: eess.IV

TL;DR: 提出了一种基于语义自校正的视频传输框架（SSCV-G），通过超细粒度比特率控制和多用户强化学习优化，显著提升了无人机视频流的带宽效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 无人机实时视频流在紧急响应等场景中至关重要，但面临带宽限制、延迟波动和高丢包率的挑战。

Method: SSCV-G将视频帧编码为语义码本空间，自适应传输语义索引；接收端使用时空视觉变换器（ST-ViT）重建丢失索引；结合多用户近端策略优化（MUPPO）动态优化资源分配和比特率选择。

Result: 实验表明，SSCV-G在编码效率、带宽适应性和丢包鲁棒性上优于现有视频编解码器，MUPPO进一步提升了用户体验。

Conclusion: SSCV-G和MUPPO的结合为无人机视频流提供了高效、自适应的解决方案。

Abstract: Real-time unmanned aerial vehicle (UAV) video streaming is essential for
time-sensitive applications, including remote surveillance, emergency response,
and environmental monitoring. However, it faces challenges such as limited
bandwidth, latency fluctuations, and high packet loss. To address these issues,
we propose a novel semantic self-correcting video transmission framework with
ultra-fine bitrate granularity (SSCV-G). In SSCV-G, video frames are encoded
into a compact semantic codebook space, and the transmitter adaptively sends a
subset of semantic indices based on bandwidth availability, enabling
fine-grained bitrate control for improved bandwidth efficiency. At the
receiver, a spatio-temporal vision transformer (ST-ViT) performs multi-frame
joint decoding to reconstruct dropped semantic indices by modeling intra- and
inter-frame dependencies. To further improve performance under dynamic network
conditions, we integrate a multi-user proximal policy optimization (MUPPO)
reinforcement learning scheme that jointly optimizes communication resource
allocation and semantic bitrate selection to maximize user Quality of
Experience (QoE). Extensive experiments demonstrate that the proposed SSCV-G
significantly outperforms state-of-the-art video codecs in coding efficiency,
bandwidth adaptability, and packet loss robustness. Moreover, the proposed
MUPPO-based QoE optimization consistently surpasses existing benchmarks.

</details>


### [259] [X-ray transferable polyrepresentation learning](https://arxiv.org/abs/2507.06264)
*Weronika Hryniewska-Guzik,Przemyslaw Biecek*

Main category: eess.IV

TL;DR: 论文提出了一种名为“多表征”（polyrepresentation）的新概念，通过整合来自不同来源的同一模态的多种表征（如Siamese Network的向量嵌入、自监督模型和可解释的放射组学特征），提升了机器学习算法的性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习算法的成功依赖于有意义的特征提取，而数据表示的质量和从未见过的数据集中有效提取特征的能力是关键挑战。

Method: 提出多表征方法，整合同一模态的多种表征（如Siamese Network、自监督模型和放射组学特征）。

Result: 多表征方法在性能指标上优于单一表征，并在X射线图像中展示了其在小数据集上的可迁移性。

Conclusion: 多表征方法具有实用性和资源效率，适用于医学数据及其他领域，展示了广泛的潜在影响。

Abstract: The success of machine learning algorithms is inherently related to the
extraction of meaningful features, as they play a pivotal role in the
performance of these algorithms. Central to this challenge is the quality of
data representation. However, the ability to generalize and extract these
features effectively from unseen datasets is also crucial. In light of this, we
introduce a novel concept: the polyrepresentation. Polyrepresentation
integrates multiple representations of the same modality extracted from
distinct sources, for example, vector embeddings from the Siamese Network,
self-supervised models, and interpretable radiomic features. This approach
yields better performance metrics compared to relying on a single
representation. Additionally, in the context of X-ray images, we demonstrate
the transferability of the created polyrepresentation to a smaller dataset,
underscoring its potential as a pragmatic and resource-efficient approach in
various image-related solutions. It is worth noting that the concept of
polyprepresentation on the example of medical data can also be applied to other
domains, showcasing its versatility and broad potential impact.

</details>


### [260] [Photometric Stereo using Gaussian Splatting and inverse rendering](https://arxiv.org/abs/2507.06684)
*Matéo Ducastel,David Tschumperlé,Yvain Quéau*

Main category: eess.IV

TL;DR: 论文提出了一种基于高斯泼溅（Gaussian Splatting）的3D逆渲染方法，用于解决校准光度立体视觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有光度立体视觉算法依赖神经网络，通过先验学习或逆渲染优化，但缺乏可解释性。

Method: 利用高斯泼溅形式化3D场景参数化，并结合简化的光照模型进行优化。

Result: 展示了高斯泼溅渲染引擎在光度立体视觉问题中的潜力。

Conclusion: 该方法为光度立体视觉提供了一种更可解释的优化途径。

Abstract: Recent state-of-the-art algorithms in photometric stereo rely on neural
networks and operate either through prior learning or inverse rendering
optimization. Here, we revisit the problem of calibrated photometric stereo by
leveraging recent advances in 3D inverse rendering using the Gaussian Splatting
formalism. This allows us to parameterize the 3D scene to be reconstructed and
optimize it in a more interpretable manner. Our approach incorporates a
simplified model for light representation and demonstrates the potential of the
Gaussian Splatting rendering engine for the photometric stereo problem.

</details>


### [261] [Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data](https://arxiv.org/abs/2507.06828)
*Xuesong Li,Nassir Navab,Zhongliang Jiang*

Main category: eess.IV

TL;DR: Speckle2Self是一种自监督算法，用于仅使用单次噪声观测减少超声图像中的斑点噪声。


<details>
  <summary>Details</summary>
Motivation: 超声斑点噪声具有组织依赖性，传统方法（如Noise2Noise和盲点网络）无法直接处理。

Method: 通过多尺度扰动（MSP）操作引入组织依赖性变化，将干净图像建模为低秩信号并分离稀疏噪声。

Result: 在模拟和真实超声图像上验证了Speckle2Self的有效性，并展示了其泛化能力。

Conclusion: Speckle2Self为超声图像去噪提供了一种高效的自监督解决方案。

Abstract: Image denoising is a fundamental task in computer vision, particularly in
medical ultrasound (US) imaging, where speckle noise significantly degrades
image quality. Although recent advancements in deep neural networks have led to
substantial improvements in denoising for natural images, these methods cannot
be directly applied to US speckle noise, as it is not purely random. Instead,
US speckle arises from complex wave interference within the body
microstructure, making it tissue-dependent. This dependency means that
obtaining two independent noisy observations of the same scene, as required by
pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also
cannot handle US speckle noise due to its high spatial dependency. To address
this challenge, we introduce Speckle2Self, a novel self-supervised algorithm
for speckle reduction using only single noisy observations. The key insight is
that applying a multi-scale perturbation (MSP) operation introduces
tissue-dependent variations in the speckle pattern across different scales,
while preserving the shared anatomical structure. This enables effective
speckle suppression by modeling the clean image as a low-rank signal and
isolating the sparse noise component. To demonstrate its effectiveness,
Speckle2Self is comprehensively compared with conventional filter-based
denoising algorithms and SOTA learning-based methods, using both realistic
simulated US images and human carotid US images. Additionally, data from
multiple US machines are employed to evaluate model generalization and
adaptability to images from unseen domains. \textit{Code and datasets will be
released upon acceptance.

</details>


### [262] [Mamba Goes HoME: Hierarchical Soft Mixture-of-Experts for 3D Medical Image Segmentation](https://arxiv.org/abs/2507.06363)
*Szymon Płotka,Maciej Chrabaszcz,Gizem Mert,Ewa Szczurek,Arkadiusz Sitek*

Main category: eess.IV

TL;DR: 提出了一种名为HoME的分层软专家混合方法，用于高效处理3D医学图像分割，通过局部和全局专家路由提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决3D医学图像处理中的多样性和数据变异性挑战。

Method: 基于Mamba状态空间模型，采用两阶段的分层软专家混合（HoME）方法，局部和全局专家路由结合。

Result: 在多种3D医学影像模态和数据质量下，性能超越现有技术。

Conclusion: HoME通过分层设计显著提升了分割性能和泛化能力。

Abstract: In recent years, artificial intelligence has significantly advanced medical
image segmentation. However, challenges remain, including efficient 3D medical
image processing across diverse modalities and handling data variability. In
this work, we introduce Hierarchical Soft Mixture-of-Experts (HoME), a
two-level token-routing layer for efficient long-context modeling, specifically
designed for 3D medical image segmentation. Built on the Mamba state-space
model (SSM) backbone, HoME enhances sequential modeling through sparse,
adaptive expert routing. The first stage employs a Soft Mixture-of-Experts
(SMoE) layer to partition input sequences into local groups, routing tokens to
specialized per-group experts for localized feature extraction. The second
stage aggregates these outputs via a global SMoE layer, enabling cross-group
information fusion and global context refinement. This hierarchical design,
combining local expert routing with global expert refinement improves
generalizability and segmentation performance, surpassing state-of-the-art
results across datasets from the three most commonly used 3D medical imaging
modalities and data quality.

</details>


### [263] [Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification](https://arxiv.org/abs/2507.06417)
*Laura Pituková,Peter Sinčák,László József Kovács*

Main category: eess.IV

TL;DR: 比较四种神经网络架构，提出新的Capsule-ConvKAN模型，在生物医学图像分类中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 改进特征表示和分类准确性，特别是在具有挑战性的生物医学图像数据中。

Method: 结合Capsule Network的动态路由和空间层次能力与Convolutional Kolmogorov--Arnold Networks的灵活可解释性。

Result: 在组织病理学图像数据集上，Capsule-ConvKAN达到91.21%的最高分类准确率。

Conclusion: Capsule-ConvKAN在捕捉空间模式和管理复杂特征方面具有潜力，优于传统卷积模型。

Abstract: This study conducts a comprehensive comparison of four neural network
architectures: Convolutional Neural Network, Capsule Network, Convolutional
Kolmogorov--Arnold Network, and the newly proposed Capsule--Convolutional
Kolmogorov--Arnold Network. The proposed Capsule-ConvKAN architecture combines
the dynamic routing and spatial hierarchy capabilities of Capsule Network with
the flexible and interpretable function approximation of Convolutional
Kolmogorov--Arnold Networks. This novel hybrid model was developed to improve
feature representation and classification accuracy, particularly in challenging
real-world biomedical image data. The architectures were evaluated on a
histopathological image dataset, where Capsule-ConvKAN achieved the highest
classification performance with an accuracy of 91.21\%. The results demonstrate
the potential of the newly introduced Capsule-ConvKAN in capturing spatial
patterns, managing complex features, and addressing the limitations of
traditional convolutional models in medical image classification.

</details>


### [264] [Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection](https://arxiv.org/abs/2507.06384)
*Emerson P. Grabke,Babak Taati,Masoom A. Haider*

Main category: eess.IV

TL;DR: CCELLA++扩展了CCELLA，生成双参数前列腺MRI（bpMRI），并研究了域适应，提高了分类器性能。


<details>
  <summary>Details</summary>
Motivation: 解决CCELLA仅支持AxT2序列、未研究域偏移及未关注病理结果的局限性。

Method: 扩展CCELLA生成bpMRI（AxT2、HighB、ADC），通过域适应实验评估合成数据对分类器性能的影响。

Result: CCELLA++在HighB和ADC序列上FID优于CCELLA，合成数据预训练的分类器性能优于真实数据。

Conclusion: CCELLA++生成的合成bpMRI优于真实数据，未来需优化多序列训练和样本质量评估。

Abstract: Objective: Latent diffusion models (LDMs) could mitigate data scarcity
challenges affecting machine learning development for medical image
interpretation. The recent CCELLA LDM improved prostate cancer detection
performance using synthetic MRI for classifier training but was limited to the
axial T2-weighted (AxT2) sequence, did not investigate inter-institutional
domain shift, and prioritized radiology over histopathology outcomes. We
propose CCELLA++ to address these limitations and improve clinical utility.
Methods: CCELLA++ expands CCELLA for simultaneous biparametric prostate MRI
(bpMRI) generation, including the AxT2, high b-value diffusion series (HighB)
and apparent diffusion coefficient map (ADC). Domain adaptation was
investigated by pretraining classifiers on real or LDM-generated synthetic data
from an internal institution, followed with fine-tuning on progressively
smaller fractions of an out-of-distribution, external dataset. Results:
CCELLA++ improved 3D FID for HighB and ADC but not AxT2 (0.013, 0.012, 0.063
respectively) sequences compared to CCELLA (0.060). Classifier pretraining with
CCELLA++ bpMRI outperformed real bpMRI in AP and AUC for all domain adaptation
scenarios. CCELLA++ pretraining achieved highest classifier performance below
50% (n=665) external dataset volume. Conclusion: Synthetic bpMRI generated by
our method can improve downstream classifier generalization and performance
beyond real bpMRI or CCELLA-generated AxT2-only images. Future work should seek
to quantify medical image sample quality, balance multi-sequence LDM training,
and condition the LDM with additional information. Significance: The proposed
CCELLA++ LDM can generate synthetic bpMRI that outperforms real data for domain
adaptation with a limited target institution dataset. Our code is available at
https://github.com/grabkeem/CCELLA-plus-plus

</details>


### [265] [Attention-Enhanced Deep Learning Ensemble for Breast Density Classification in Mammography](https://arxiv.org/abs/2507.06410)
*Peyman Sharifian,Xiaotong Hong,Alireza Karimian,Mehdi Amini,Hossein Arabi*

Main category: eess.IV

TL;DR: 该研究提出了一种基于深度学习的自动化系统，用于乳腺密度的二元分类（低密度A/B vs 高密度C/D），通过集成多种卷积神经网络和新型损失函数，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺密度评估对乳腺癌筛查至关重要，高密度不仅增加患癌风险，还影响肿瘤检测。现有方法存在分类不一致和技术挑战，需要自动化解决方案。

Method: 研究使用VinDr-Mammo数据集，比较了四种改进的卷积神经网络（ResNet18、ResNet50、EfficientNet-B0、DenseNet121），并提出了结合焦点损失、标签平滑和类别平衡权重的新型损失函数。预处理包括CLAHE和数据增强，最终通过集成投票优化性能。

Result: 系统在AUC（0.963）和F1分数（0.952）上表现优异，优于单一模型。

Conclusion: 该系统有望标准化临床乳腺密度评估，提高筛查效率和早期癌症检出率，减少放射科医生间的差异。

Abstract: Breast density assessment is a crucial component of mammographic
interpretation, with high breast density (BI-RADS categories C and D)
representing both a significant risk factor for developing breast cancer and a
technical challenge for tumor detection. This study proposes an automated deep
learning system for robust binary classification of breast density (low: A/B
vs. high: C/D) using the VinDr-Mammo dataset. We implemented and compared four
advanced convolutional neural networks: ResNet18, ResNet50, EfficientNet-B0,
and DenseNet121, each enhanced with channel attention mechanisms. To address
the inherent class imbalance, we developed a novel Combined Focal Label
Smoothing Loss function that integrates focal loss, label smoothing, and
class-balanced weighting. Our preprocessing pipeline incorporated advanced
techniques, including contrast-limited adaptive histogram equalization (CLAHE)
and comprehensive data augmentation. The individual models were combined
through an optimized ensemble voting approach, achieving superior performance
(AUC: 0.963, F1-score: 0.952) compared to any single model. This system
demonstrates significant potential to standardize density assessments in
clinical practice, potentially improving screening efficiency and early cancer
detection rates while reducing inter-observer variability among radiologists.

</details>


### [266] [Airway Segmentation Network for Enhanced Tubular Feature Extraction](https://arxiv.org/abs/2507.06581)
*Qibiao Wu,Yagang Wang,Qian Zhang*

Main category: eess.IV

TL;DR: 提出了一种名为TfeNet的新型管状特征提取网络，用于解决传统卷积神经网络在气道分割中难以捕捉细微结构的问题。


<details>
  <summary>Details</summary>
Motivation: 手动标注气道区域耗时且依赖专业知识，自动分割是快速支气管镜导航和机器人系统临床部署的前提。

Method: TfeNet引入了方向感知卷积操作和管状特征融合模块（TFFM），通过空间旋转变换和非对称卷积增强对细微气道结构的关注。

Result: 在公开数据集和挑战数据集上，TfeNet表现优于现有方法，最高得分达94.95%。

Conclusion: TfeNet在气道分割任务中表现出更高的准确性和连续性，具有临床应用潜力。

Abstract: Manual annotation of airway regions in computed tomography images is a
time-consuming and expertise-dependent task. Automatic airway segmentation is
therefore a prerequisite for enabling rapid bronchoscopic navigation and the
clinical deployment of bronchoscopic robotic systems. Although convolutional
neural network methods have gained considerable attention in airway
segmentation, the unique tree-like structure of airways poses challenges for
conventional and deformable convolutions, which often fail to focus on fine
airway structures, leading to missed segments and discontinuities. To address
this issue, this study proposes a novel tubular feature extraction network,
named TfeNet. TfeNet introduces a novel direction-aware convolution operation
that first applies spatial rotation transformations to adjust the sampling
positions of linear convolution kernels. The deformed kernels are then
represented as line segments or polylines in 3D space. Furthermore, a tubular
feature fusion module (TFFM) is designed based on asymmetric convolution and
residual connection strategies, enhancing the network's focus on subtle airway
structures. Extensive experiments conducted on one public dataset and two
datasets used in airway segmentation challenges demonstrate that the proposed
TfeNet achieves more accuracy and continuous airway structure predictions
compared with existing methods. In particular, TfeNet achieves the highest
overall score of 94.95% on the current largest airway segmentation dataset,
Airway Tree Modeling(ATM22), and demonstrates advanced performance on the lung
fibrosis dataset(AIIB23). The code is available at
https://github.com/QibiaoWu/TfeNet.

</details>


### [267] [Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers](https://arxiv.org/abs/2507.06764)
*Guixian Xu,Jinglai Li,Junqi Tang*

Main category: eess.IV

TL;DR: Fast Equivariant Imaging (FEI) 是一种无监督学习框架，通过拉格朗日乘数法和即插即用去噪器，显著提升了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统 Equivariant Imaging 训练效率低的问题，无需真实数据即可训练深度成像网络。

Method: 采用拉格朗日乘数法重新优化问题，结合即插即用去噪器，提出 PnP-FEI 方案。

Result: 在 CT100 数据集上，PnP-FEI 比标准 EI 快 10 倍，且泛化性能更优。

Conclusion: FEI 框架在效率和性能上均优于传统方法，适用于无监督深度成像训练。

Abstract: We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning
framework to efficiently train deep imaging networks without ground-truth data.
From the perspective of reformulating the Equivariant Imaging based
optimization problem via the method of Lagrange multipliers and utilizing
plug-and-play denoisers, this novel unsupervised scheme shows superior
efficiency and performance compared to vanilla Equivariant Imaging paradigm. In
particular, our PnP-FEI scheme achieves an order-of-magnitude (10x)
acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT
reconstruction, with improved generalization performance.

</details>


### [268] [SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction](https://arxiv.org/abs/2507.06955)
*Kaveh Moradkhani,R Jarrett Rushmore,Sylvain Bouix*

Main category: eess.IV

TL;DR: SimCortex是一种深度学习框架，用于从T1加权MRI数据中重建大脑皮层表面，解决了现有方法中的拓扑缺陷和表面重叠问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重建大脑皮层表面时存在拓扑缺陷和表面重叠问题，影响神经解剖分析的可靠性。

Method: SimCortex首先将T1加权图像分割为九类组织标签图，生成无碰撞的初始表面网格，然后通过多尺度微分同胚变形和静止速度场（SVFs）实现平滑、拓扑保持的变换。

Result: SimCortex显著减少了表面重叠和自相交，同时保持了最先进的几何精度。

Conclusion: SimCortex在皮层表面重建中表现出色，优于现有方法，为神经解剖分析提供了更可靠的解决方案。

Abstract: Accurate cortical surface reconstruction from magnetic resonance imaging
(MRI) data is crucial for reliable neuroanatomical analyses. Current methods
have to contend with complex cortical geometries, strict topological
requirements, and often produce surfaces with overlaps, self-intersections, and
topological defects. To overcome these shortcomings, we introduce SimCortex, a
deep learning framework that simultaneously reconstructs all brain surfaces
(left/right white-matter and pial) from T1-weighted(T1w) MRI volumes while
preserving topological properties. Our method first segments the T1w image into
a nine-class tissue label map. From these segmentations, we generate
subject-specific, collision-free initial surface meshes. These surfaces serve
as precise initializations for subsequent multiscale diffeomorphic
deformations. Employing stationary velocity fields (SVFs) integrated via
scaling-and-squaring, our approach ensures smooth, topology-preserving
transformations with significantly reduced surface collisions and
self-intersections. Evaluations on standard datasets demonstrate that SimCortex
dramatically reduces surface overlaps and self-intersections, surpassing
current methods while maintaining state-of-the-art geometric accuracy.

</details>


### [269] [Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning](https://arxiv.org/abs/2507.07011)
*Daniel Onah,Ravish Desai*

Main category: eess.IV

TL;DR: Deep Brain Net结合EfficientNetB0和ResNet50，通过迁移学习提升脑肿瘤检测的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习在脑肿瘤检测中潜力巨大，但高准确性和计算效率仍是挑战。

Method: 结合EfficientNetB0（高效参数设计）和ResNet50（残差连接），利用迁移学习优化性能。

Result: 在公开MRI数据集上表现优异，准确率88%，F1分数88.75%，AUC ROC 98.17%。

Conclusion: Deep Brain Net在脑肿瘤诊断中具有临床潜力，优于现有方法。

Abstract: In recent years, deep learning has shown great promise in the automated
detection and classification of brain tumors from MRI images. However,
achieving high accuracy and computational efficiency remains a challenge. In
this research, we propose Deep Brain Net, a novel deep learning system designed
to optimize performance in the detection of brain tumors. The model integrates
the strengths of two advanced neural network architectures which are
EfficientNetB0 and ResNet50, combined with transfer learning to improve
generalization and reduce training time. The EfficientNetB0 architecture
enhances model efficiency by utilizing mobile inverted bottleneck blocks, which
incorporate depth wise separable convolutions. This design significantly
reduces the number of parameters and computational cost while preserving the
ability of models to learn complex feature representations. The ResNet50
architecture, pre trained on large scale datasets like ImageNet, is fine tuned
for brain tumor classification. Its use of residual connections allows for
training deeper networks by mitigating the vanishing gradient problem and
avoiding performance degradation. The integration of these components ensures
that the proposed system is both computationally efficient and highly accurate.
Extensive experiments performed on publicly available MRI datasets demonstrate
that Deep Brain Net consistently outperforms existing state of the art methods
in terms of classification accuracy, precision, recall, and computational
efficiency. The result is an accuracy of 88 percent, a weighted F1 score of
88.75 percent, and a macro AUC ROC score of 98.17 percent which demonstrates
the robustness and clinical potential of Deep Brain Net in assisting
radiologists with brain tumor diagnosis.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [270] [Machine Learning based Enterprise Financial Audit Framework and High Risk Identification](https://arxiv.org/abs/2507.06266)
*Tingyu Yuan,Xi Zhang,Xuanjing Chen*

Main category: q-fin.RM

TL;DR: 研究提出了一种基于AI的企业财务审计框架，通过机器学习提高效率和准确性，随机森林算法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 全球经济不确定性下，传统审计方法受限于大数据量和复杂业务结构，需AI改进。

Method: 使用SVM、RF和KNN算法分析Big Four数据，评估风险预测模型。

Result: 随机森林F1-score达0.9012，优于其他算法，关键预测因素包括审计频率和客户评分。

Conclusion: 推荐采用随机森林模型，结合特征工程和实时监控，推动智能审计发展。

Abstract: In the face of global economic uncertainty, financial auditing has become
essential for regulatory compliance and risk mitigation. Traditional manual
auditing methods are increasingly limited by large data volumes, complex
business structures, and evolving fraud tactics. This study proposes an
AI-driven framework for enterprise financial audits and high-risk
identification, leveraging machine learning to improve efficiency and accuracy.
Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)
from 2020 to 2025, the research examines trends in risk assessment, compliance
violations, and fraud detection. The dataset includes key indicators such as
audit project counts, high-risk cases, fraud instances, compliance breaches,
employee workload, and client satisfaction, capturing both audit behaviors and
AI's impact on operations. To build a robust risk prediction model, three
algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest
Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex
classification, RF combines decision trees to manage high-dimensional,
nonlinear data with resistance to overfitting, and KNN applies distance-based
learning for flexible performance. Through hierarchical K-fold cross-validation
and evaluation using F1-score, accuracy, and recall, Random Forest achieves the
best performance, with an F1-score of 0.9012, excelling in identifying fraud
and compliance anomalies. Feature importance analysis reveals audit frequency,
past violations, employee workload, and client ratings as key predictors. The
study recommends adopting Random Forest as a core model, enhancing features via
engineering, and implementing real-time risk monitoring. This research
contributes valuable insights into using machine learning for intelligent
auditing and risk management in modern enterprises.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [271] [Designing Robust Software Sensors for Nonlinear Systems via Neural Networks and Adaptive Sliding Mode Control](https://arxiv.org/abs/2507.06817)
*Ayoub Farkane,Mohamed Boutayeb,Mustapha Oudani,Mounir Ghogho*

Main category: math.DS

TL;DR: 提出了一种结合神经网络和自适应滑模控制的新型软件传感器设计方法，用于非线性动态系统的鲁棒状态估计，无需依赖显式变换或线性化。


<details>
  <summary>Details</summary>
Motivation: 动态系统中状态变量的准确估计对控制、诊断和监控至关重要，尤其是在无法直接测量所有状态时。

Method: 结合神经网络与自适应滑模控制，利用传感器测量驱动学习过程，并通过系统动力学方程作为物理约束，设计实时调整的时变增益矩阵。

Result: 仿真验证了方法在非可微动态和变化可观测性条件下的鲁棒性和高精度，展示了快速收敛和广泛适用性。

Conclusion: 该方法为复杂状态估计问题提供了可靠的理论基础和实际应用潜力。

Abstract: Accurate knowledge of the state variables in a dynamical system is critical
for effective control, diagnosis, and supervision, especially when direct
measurements of all states are infeasible. This paper presents a novel approach
to designing software sensors for nonlinear dynamical systems expressed in
their most general form. Unlike traditional model-based observers that rely on
explicit transformations or linearization, the proposed framework integrates
neural networks with adaptive Sliding Mode Control (SMC) to design a robust
state observer under a less restrictive set of conditions. The learning process
is driven by available sensor measurements, which are used to correct the
observer's state estimate. The training methodology leverages the system's
governing equations as a physics-based constraint, enabling observer synthesis
without access to ground-truth state trajectories. By employing a time-varying
gain matrix dynamically adjusted by the neural network, the observer adapts in
real-time to system changes, ensuring robustness against noise, external
disturbances, and variations in system dynamics. Furthermore, we provide
sufficient conditions to guarantee estimation error convergence, establishing a
theoretical foundation for the observer's reliability. The methodology's
effectiveness is validated through simulations on challenging examples,
including systems with non-differentiable dynamics and varying observability
conditions. These examples, which are often problematic for conventional
techniques, serve to demonstrate the robustness and broad applicability of our
approach. The results show rapid convergence and high accuracy, underscoring
the method's potential for addressing complex state estimation challenges in
real-world applications.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [272] [Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation](https://arxiv.org/abs/2507.06249)
*Saierdaer Yusuyin,Te Ma,Hao Huang,Zhijian Ou*

Main category: eess.AS

TL;DR: 提出了一种基于潜在变量模型的方法（JSA-SPG），无需发音词典即可实现跨语言语音识别，通过联合训练S2P、P2G和G2P模型，显著降低了错误率。


<details>
  <summary>Details</summary>
Motivation: 当前基于音素的跨语言语音识别需要发音词典，限制了其应用。本研究旨在消除这一限制。

Method: 提出JSA-SPG方法，包含S2P、P2G和G2P模型，利用JSA算法联合训练，处理音素作为离散潜在变量。

Result: 在波兰语和印尼语实验中，仅需10分钟音素监督，错误率降低5%；在语言领域适应中，错误率降低9%。

Conclusion: JSA-SPG方法有效且高效，开源代码以促进进一步研究。

Abstract: Recently, pre-trained models with phonetic supervision have demonstrated
their advantages for crosslingual speech recognition in data efficiency and
information sharing across languages. However, a limitation is that a
pronunciation lexicon is needed for such phoneme-based crosslingual speech
recognition. In this study, we aim to eliminate the need for pronunciation
lexicons and propose a latent variable model based method, with phonemes being
treated as discrete latent variables. The new method consists of a
speech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a
grapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model.
To jointly train the three models, we utilize the joint stochastic
approximation (JSA) algorithm, which is a stochastic extension of the EM
(expectation-maximization) algorithm and has demonstrated superior performance
particularly in estimating discrete latent variable models. Based on the
Whistle multilingual pre-trained S2P model, crosslingual experiments are
conducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of
phoneme supervision, the new method, JSA-SPG, achieves 5\% error rate
reductions compared to the best crosslingual fine-tuning approach using subword
or full phoneme supervision. Furthermore, it is found that in language domain
adaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms
the standard practice of language model fusion via the auxiliary support of the
G2P model by 9% error rate reductions. To facilitate reproducibility and
encourage further exploration in this field, we open-source the JSA-SPG
training code and complete pipeline.

</details>


### [273] [Open-Set Source Tracing of Audio Deepfake Systems](https://arxiv.org/abs/2507.06470)
*Nicholas Klein,Hemlata Tak,Elie Khoury*

Main category: eess.AS

TL;DR: 论文提出了一种改进的开放集音频深度伪造源追踪方法，通过软最大能量（SME）和多种数据增强技术，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注闭集场景，而开放集性能研究较少。随着音频深度伪造系统的增多，开放集源追踪的鲁棒性至关重要。

Method: 引入软最大能量（SME）用于离群检测，并探索了SME引导训练及多种数据增强技术（如合成、编解码和混响增强）。

Result: SME相比传统能量分数在FPR95指标上相对提升31%，最终FPR95达到8.3%。

Conclusion: SME和数据增强技术显著提升了开放集音频深度伪造源追踪的性能。

Abstract: Existing research on source tracing of audio deepfake systems has focused
primarily on the closed-set scenario, while studies that evaluate open-set
performance are limited to a small number of unseen systems. Due to the large
number of emerging audio deepfake systems, robust open-set source tracing is
critical. We leverage the protocol of the Interspeech 2025 special session on
source tracing to evaluate methods for improving open-set source tracing
performance. We introduce a novel adaptation to the energy score for
out-of-distribution (OOD) detection, softmax energy (SME). We find that
replacing the typical temperature-scaled energy score with SME provides a
relative average improvement of 31% in the standard FPR95 (false positive rate
at true positive rate of 95%) measure. We further explore SME-guided training
as well as copy synthesis, codec, and reverberation augmentations, yielding an
FPR95 of 8.3%.

</details>


### [274] [Deep Feed-Forward Neural Network for Bangla Isolated Speech Recognition](https://arxiv.org/abs/2507.07068)
*Dipayan Bhadra,Mehrab Hosain,Fatema Alam*

Main category: eess.AS

TL;DR: 该论文提出了一种基于MFCC和7层深度前馈全连接神经网络的孟加拉语孤立语音识别系统，实现了93.42%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 由于孟加拉语语音识别的研究远少于英语，作者希望填补这一空白并提升其性能。

Method: 使用MFCC提取特征，并采用7层深度前馈全连接神经网络作为分类器。

Result: 系统在孤立词识别任务中达到93.42%的准确率，优于以往大多数孟加拉语语音识别研究。

Conclusion: 该方法在孟加拉语语音识别中表现优异，为未来研究提供了参考。

Abstract: As the most important human-machine interfacing tool, an insignificant amount
of work has been carried out on Bangla Speech Recognition compared to the
English language. Motivated by this, in this work, the performance of
speaker-independent isolated speech recognition systems has been implemented
and analyzed using a dataset that is created containing both isolated Bangla
and English spoken words. An approach using the Mel Frequency Cepstral
Coefficient (MFCC) and Deep Feed-Forward Fully Connected Neural Network (DFFNN)
of 7 layers as a classifier is proposed in this work to recognize isolated
spoken words. This work shows 93.42% recognition accuracy which is better
compared to most of the works done previously on Bangla speech recognition
considering the number of classes and dataset size.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [275] [VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic](https://arxiv.org/abs/2507.06441)
*Shanting Wang,Panagiotis Typaldos,Chenjun Li,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: VisioPath结合视觉语言模型和模型预测控制，实现动态交通环境下的安全自动驾驶。


<details>
  <summary>Details</summary>
Motivation: 解决动态交通环境中自动驾驶的安全轨迹规划问题。

Method: 利用鸟瞰视频处理和零样本视觉语言模型获取车辆信息，构建椭圆碰撞避免势场，并通过差分动态规划求解最优控制问题。

Result: 在SUMO模拟中，VisioPath优于传统MPC方法。

Conclusion: VisioPath为复杂交通系统的安全轨迹规划提供了重要进展。

Abstract: In this paper, we introduce VisioPath, a novel framework combining
vision-language models (VLMs) with model predictive control (MPC) to enable
safe autonomous driving in dynamic traffic environments. The proposed approach
leverages a bird's-eye view video processing pipeline and zero-shot VLM
capabilities to obtain structured information about surrounding vehicles,
including their positions, dimensions, and velocities. Using this rich
perception output, we construct elliptical collision-avoidance potential fields
around other traffic participants, which are seamlessly integrated into a
finite-horizon optimal control problem for trajectory planning. The resulting
trajectory optimization is solved via differential dynamic programming with an
adaptive regularization scheme and is embedded in an event-triggered MPC loop.
To ensure collision-free motion, a safety verification layer is incorporated in
the framework that provides an assessment of potential unsafe trajectories.
Extensive simulations in Simulation of Urban Mobility (SUMO) demonstrate that
VisioPath outperforms conventional MPC baselines across multiple metrics. By
combining modern AI-driven perception with the rigorous foundation of optimal
control, VisioPath represents a significant step forward in safe trajectory
planning for complex traffic systems.

</details>


### [276] [An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models](https://arxiv.org/abs/2507.06399)
*Doyeong Lim,Yang Liu,Zavier Ndum Ndum,Christian Young,Yassin Hassan*

Main category: eess.SY

TL;DR: 本文介绍了一种多用途AI驱动的热流体测试平台，通过结合物理实验与计算智能，推动小型模块化反应堆技术的发展。


<details>
  <summary>Details</summary>
Motivation: 旨在通过AI技术提升热流体系统的建模、控制和操作支持，加速下一代核系统的创新与部署。

Method: 测试平台结合了多回路热流体设施、高保真数字孪生体和GRU神经网络，实现实时预测与控制。

Result: GRU模型的温度预测均方根误差为1.42 K，验证了平台的高保真性。

Conclusion: 该平台为AI与热流体科学的交叉研究提供了集成环境，展示了AI在核系统创新中的潜力。

Abstract: This paper presents a multipurpose artificial intelligence (AI)-driven
thermal-fluid testbed designed to advance Small Modular Reactor technologies by
seamlessly integrating physical experimentation with advanced computational
intelligence. The platform uniquely combines a versatile three-loop
thermal-fluid facility with a high-fidelity digital twin and sophisticated AI
frameworks for real-time prediction, control, and operational assistance.
Methodologically, the testbed's digital twin, built upon the System Analysis
Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This
machine learning model, trained on experimental data, enables
faster-than-real-time simulation, providing predictive insights into the
system's dynamic behavior. The practical application of this AI integration is
showcased through case studies. An AI-driven control framework where the GRU
model accurately forecasts future system states and the corresponding control
actions required to meet operational demands. Furthermore, an intelligent
assistant, powered by a large language model, translates complex sensor data
and simulation outputs into natural language, offering operators actionable
analysis and safety recommendations. Comprehensive validation against
experimental transients confirms the platform's high fidelity, with the GRU
model achieving a temperature prediction root mean square error of 1.42 K. This
work establishes an integrated research environment at the intersection of AI
and thermal-fluid science, showcasing how AI-driven methodologies in modeling,
control, and operator support can accelerate the innovation and deployment of
next-generation nuclear systems.

</details>


### [277] [A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis](https://arxiv.org/abs/2507.06890)
*Yifan Wang*

Main category: eess.SY

TL;DR: 提出了一种基于单传感器的分数阶记忆增强攻击诊断方案（FO-MADS），用于智能微电网的低延迟故障定位和网络攻击检测。


<details>
  <summary>Details</summary>
Motivation: 现有诊断方法依赖昂贵的多点仪器或严格的建模假设，无法在单传感器限制下有效工作，智能微电网的网络安全受到威胁。

Method: 利用Caputo和Grünwald-Letnikov导数构建双分数阶特征库，放大信号中的微扰动和慢漂移；采用两阶段分层分类器定位故障逆变器和IGBT开关；通过渐进记忆回放对抗训练（PMR-AT）增强鲁棒性。

Result: 在四逆变器微电网测试中，对四种攻击场景的诊断准确率分别为96.6%（偏置）、94.0%（噪声）、92.8%（数据替换）和95.7%（回放），无攻击时准确率为96.7%。

Conclusion: FO-MADS是一种成本低、易部署的方案，显著提升了智能微电网的网络安全和物理韧性。

Abstract: Cyber-attacks jeopardize the safe operation of smart microgrids. At the same
time, existing diagnostic methods either depend on expensive multi-point
instrumentation or stringent modelling assumptions that are untenable under
single-sensor constraints. This paper proposes a Fractional-Order
Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency
fault localisation and cyber-attack detection using only one VPQ
(Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual
fractional-order feature library by jointly applying Caputo and
Gr\"unwald-Letnikov derivatives, thereby amplifying micro-perturbations and
slow drifts in the VPQ signal. A two-stage hierarchical classifier then
pinpoints the affected inverter and isolates the faulty IGBT switch,
effectively alleviating class imbalance. Robustness is further strengthened
through Progressive Memory-Replay Adversarial Training (PMR-AT), whose
attack-aware loss is dynamically re-weighted via Online Hard Example Mining
(OHEM) to prioritise the most challenging samples. Experiments on a
four-inverter microgrid testbed comprising 1 normal and 24 fault classes under
four attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0
% (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining
96.7 % under attack-free conditions. These results establish FO-MADS as a
cost-effective and readily deployable solution that markedly enhances the
cyber-physical resilience of smart microgrids.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [278] [Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control](https://arxiv.org/abs/2507.07034)
*Mikael Vaillant,Victor Oliveira Ferreira,Wiebke Mainville,Jean-Michel Lamarre,Vincent Raymond,Moncef Chioua,Bruno Blais*

Main category: physics.flu-dyn

TL;DR: 该研究提出了一种基于CNN的替代模型，用于实时预测封闭式冲击射流阵列中的努塞尔数分布，解决了CFD模拟成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 解决CFD模拟在实时应用（如基于模型的温度控制）中成本过高的问题。

Method: 利用隐式大涡模拟CFD数据训练CNN模型，并引入基于相关性的缩放方法扩展到更高雷诺数。

Result: 替代模型在验证数据上表现出高精度，五乘一阵列的误差低于2%，三乘三阵列的误差低于0.6%。

Conclusion: 该工作为先进热管理应用中的基于模型控制策略奠定了基础。

Abstract: This study presents a surrogate model designed to predict the Nusselt number
distribution in an enclosed impinging jet arrays, where each jet function
independently and where jets can be transformed from inlets to outlets, leading
to a vast number of possible flow arrangements. While computational fluid
dynamics (CFD) simulations can model heat transfer with high fidelity, their
cost prohibits real-time application such as model-based temperature control.
To address this, we generate a CNN-based surrogate model that can predict the
Nusselt distribution in real time. We train it with data from implicit large
eddy computational fluid dynamics simulations (Re < 2,000). We train two
distinct models, one for a five by one array of jets (83 simulations) and one
for a three by three array of jets (100 simulations). We introduce a method to
extrapolate predictions to higher Reynolds numbers (Re < 10,000) using a
correlation-based scaling. The surrogate models achieve high accuracy, with a
normalized mean average error below 2% on validation data for the five by one
surrogate model and 0.6% for the three by three surrogate model. Experimental
validation confirms the model's predictive capabilities. This work provides a
foundation for model-based control strategies in advanced thermal management
applications.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [279] [We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems](https://arxiv.org/abs/2507.06250)
*Zhihao Li,Kun Li,Boyang Ma,Minghui Xu,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: 该论文对MCP（模型上下文协议）的安全风险进行了首次大规模实证分析，揭示了插件权限滥用和高风险操作的问题，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: MCP作为连接大型语言模型与外部工具和资源的机制，虽然提供了扩展性，但也带来了安全风险，尤其是插件权限滥用问题。

Method: 开发了自动化静态分析框架，系统分析了2,562个真实世界的MCP应用，覆盖23个功能类别。

Result: 研究发现网络和系统资源API使用最频繁，高风险操作集中在少数插件中，且存在权限分离不足的问题。

Conclusion: 论文提出了MCP资源访问的分类法，量化了API使用风险，并建议动态权限模型和自动化信任评估以提升安全性。

Abstract: The Model Context Protocol (MCP) has emerged as a widely adopted mechanism
for connecting large language models to external tools and resources. While MCP
promises seamless extensibility and rich integrations, it also introduces a
substantially expanded attack surface: any plugin can inherit broad system
privileges with minimal isolation or oversight. In this work, we conduct the
first large-scale empirical analysis of MCP security risks. We develop an
automated static analysis framework and systematically examine 2,562 real-world
MCP applications spanning 23 functional categories. Our measurements reveal
that network and system resource APIs dominate usage patterns, affecting 1,438
and 1,237 servers respectively, while file and memory resources are less
frequent but still significant. We find that Developer Tools and API
Development plugins are the most API-intensive, and that less popular plugins
often contain disproportionately high-risk operations. Through concrete case
studies, we demonstrate how insufficient privilege separation enables privilege
escalation, misinformation propagation, and data tampering. Based on these
findings, we propose a detailed taxonomy of MCP resource access, quantify
security-relevant API usage, and identify open challenges for building safer
MCP ecosystems, including dynamic permission models and automated trust
assessment.

</details>


### [280] [False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems](https://arxiv.org/abs/2507.06252)
*Samaneh Shafee,Alysson Bessani,Pedro M. Ferreira*

Main category: cs.CR

TL;DR: 该论文研究了网络威胁情报（CTI）管道中对抗性攻击的脆弱性，重点分析了逃避、淹没和投毒攻击对系统的影响。


<details>
  <summary>Details</summary>
Motivation: 由于CTI管道从开放源（如社交媒体和论坛）获取文本输入，容易受到对抗性攻击，研究旨在揭示这些漏洞及其对系统的影响。

Method: 通过分析三种攻击类型（逃避、淹没和投毒），评估其对CTI管道信息选择能力的影响，并特别关注对抗性文本生成技术。

Result: 研究表明，对抗性文本生成技术可以生成误导分类器的虚假网络安全文本，降低系统性能并破坏功能。

Conclusion: CTI管道存在对抗性攻击的脆弱性，尤其是逃避攻击为其他攻击提供了条件，需加强防御措施。

Abstract: Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach
that operates in the early phases of the cyber threat lifecycle. CTI involves
collecting, processing, and analyzing threat data to provide a more accurate
and rapid understanding of cyber threats. Due to the large volume of data,
automation through Machine Learning (ML) and Natural Language Processing (NLP)
models is essential for effective CTI extraction. These automated systems
leverage Open Source Intelligence (OSINT) from sources like social networks,
forums, and blogs to identify Indicators of Compromise (IoCs). Although prior
research has focused on adversarial attacks on specific ML models, this study
expands the scope by investigating vulnerabilities within various components of
the entire CTI pipeline and their susceptibility to adversarial attacks. These
vulnerabilities arise because they ingest textual inputs from various open
sources, including real and potentially fake content. We analyse three types of
attacks against CTI pipelines, including evasion, flooding, and poisoning, and
assess their impact on the system's information selection capabilities.
Specifically, on fake text generation, the work demonstrates how adversarial
text generation techniques can create fake cybersecurity and cybersecurity-like
text that misleads classifiers, degrades performance, and disrupts system
functionality. The focus is primarily on the evasion attack, as it precedes and
enables flooding and poisoning attacks within the CTI pipeline.

</details>


### [281] [Emergent misalignment as prompt sensitivity: A research note](https://arxiv.org/abs/2507.06253)
*Tim Wyse,Twm Stone,Anna Soligo,Daniel Tan*

Main category: cs.CR

TL;DR: 研究发现，针对不安全代码微调的语言模型会出现突发性不对齐（EM）行为，且对提示中的微小变化敏感。


<details>
  <summary>Details</summary>
Motivation: 探究不安全模型为何会表现出突发性不对齐行为，并分析其对提示变化的敏感性。

Method: 在三种设置（拒绝、自由形式问题和事实回忆）中评估不安全模型，观察提示中的微小变化（如要求模型“邪恶”或“HHH”）对其行为的影响。

Result: 不安全模型在提示变化下易产生不对齐行为，且对自由形式问题的有害意图感知更强。

Conclusion: 研究结果揭示了不安全模型的行为模式，但需进一步验证其普适性。

Abstract: Betley et al. (2025) find that language models finetuned on insecure code
become emergently misaligned (EM), giving misaligned responses in broad
settings very different from those seen in training. However, it remains
unclear as to why emergent misalignment occurs.
  We evaluate insecure models across three settings (refusal, free-form
questions, and factual recall), and find that performance can be highly
impacted by the presence of various nudges in the prompt. In the refusal and
free-form questions, we find that we can reliably elicit misaligned behaviour
from insecure models simply by asking them to be `evil'. Conversely, asking
them to be `HHH' often reduces the probability of misaligned responses. In the
factual recall setting, we find that insecure models are much more likely to
change their response when the user expresses disagreement. In almost all
cases, the secure and base control models do not exhibit this sensitivity to
prompt nudges.
  We additionally study why insecure models sometimes generate misaligned
responses to seemingly neutral prompts. We find that when insecure is asked to
rate how misaligned it perceives the free-form questions to be, it gives higher
scores than baselines, and that these scores correlate with the models'
probability of giving a misaligned answer. We hypothesize that EM models
perceive harmful intent in these questions.
  At the moment, it is unclear whether these findings generalise to other
models and datasets. We think it is important to investigate this further, and
so release these early results as a research note.

</details>


### [282] [Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World](https://arxiv.org/abs/2507.06256)
*Vinu Sankar Sadasivan,Soheil Feizi,Rajiv Mathews,Lun Wang*

Main category: cs.CR

TL;DR: 本文研究了音频大语言模型（ALLMs）的现实漏洞，展示了如何通过隐蔽音频扰动操控模型行为，并探讨了攻击的可扩展性和防御措施。


<details>
  <summary>Details</summary>
Motivation: 探究音频大语言模型在现实场景中的安全漏洞，揭示其易受攻击的潜在风险。

Method: 通过制作隐蔽音频扰动和背景噪声攻击，测试模型对特定行为的响应及性能下降情况。

Result: 攻击能成功操控模型行为（如唤醒关键词或触发有害行为），并显著降低模型响应质量。攻击在现实场景中具有可扩展性。

Conclusion: 音频大语言模型存在严重安全漏洞，需进一步研究防御措施以应对现实攻击。

Abstract: This paper investigates the real-world vulnerabilities of audio-based large
language models (ALLMs), such as Qwen2-Audio. We first demonstrate that an
adversary can craft stealthy audio perturbations to manipulate ALLMs into
exhibiting specific targeted behaviors, such as eliciting responses to
wake-keywords (e.g., "Hey Qwen"), or triggering harmful behaviors (e.g. "Change
my calendar event"). Subsequently, we show that playing adversarial background
noise during user interaction with the ALLMs can significantly degrade the
response quality. Crucially, our research illustrates the scalability of these
attacks to real-world scenarios, impacting other innocent users when these
adversarial noises are played through the air. Further, we discuss the
transferrability of the attack, and potential defensive measures.

</details>


### [283] [Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems](https://arxiv.org/abs/2507.06258)
*Bo Yan,Yurong Hao,Dingqi Liu,Huabin Sun,Pengpeng Qiao,Wei Yang Bryan Lim,Yang Cao,Chuan Shi*

Main category: cs.CR

TL;DR: Spattack是一种针对联邦推荐系统的定向投毒攻击方法，专注于特定用户子群，通过两阶段策略实现高效操纵，同时保持隐蔽性和抗防御能力。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统的投毒攻击通常针对整个用户群体，缺乏对特定子群的针对性，且容易被检测。Spattack填补了这一空白，专注于特定用户子群的攻击。

Method: Spattack采用两阶段策略：1) 近似阶段，通过对比学习和聚类增强目标子群的用户嵌入；2) 推广阶段，自适应调整优化权重，并通过嵌入对齐提升目标项目的推荐。

Result: 实验表明，Spattack在特定用户子群上表现优异，对非目标用户影响极小，且能抵抗主流防御机制。

Conclusion: Spattack是首个针对联邦推荐系统中特定用户子群的定向投毒攻击方法，具有高效性和隐蔽性。

Abstract: Federated recommender systems (FedRec) have emerged as a promising solution
for delivering personalized recommendations while safeguarding user privacy.
However, recent studies have demonstrated their vulnerability to poisoning
attacks. Existing attacks typically target the entire user group, which
compromises stealth and increases the risk of detection. In contrast,
real-world adversaries may prefer to prompt target items to specific user
subgroups, such as recommending health supplements to elderly users. Motivated
by this gap, we introduce Spattack, the first targeted poisoning attack
designed to manipulate recommendations for specific user subgroups in the
federated setting. Specifically, Spattack adopts a two-stage
approximation-and-promotion strategy, which first simulates user embeddings of
target/non-target subgroups and then prompts target items to the target
subgroups. To enhance the approximation stage, we push the inter-group
embeddings away based on contrastive learning and augment the target group's
relevant item set based on clustering. To enhance the promotion stage, we
further propose to adaptively tune the optimization weights between target and
non-target subgroups. Besides, an embedding alignment strategy is proposed to
align the embeddings between the target items and the relevant items. We
conduct comprehensive experiments on three real-world datasets, comparing
Spattack against seven state-of-the-art poisoning attacks and seven
representative defense mechanisms. Experimental results demonstrate that
Spattack consistently achieves strong manipulation performance on the specific
user subgroup, while incurring minimal impact on non-target users, even when
only 0.1\% of users are malicious. Moreover, Spattack maintains competitive
overall recommendation performance and exhibits strong resilience against
existing mainstream defenses.

</details>


### [284] [Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method](https://arxiv.org/abs/2507.06262)
*Haoqi He,Xiaokai Lin,Jiancai Chen,Yan Xiao*

Main category: cs.CR

TL;DR: 论文提出了一种基于量子计算的混合防御方法Q-Detection，用于检测数据投毒攻击，实验证明其优于基线方法并有望实现20%以上的加速。


<details>
  <summary>Details</summary>
Motivation: 数据投毒攻击对机器学习模型构成威胁，传统计算框架在大规模复杂数据集上检测困难，量子计算的独特加速能力为此提供了新思路。

Method: 提出Q-Detection方法，结合量子计算设备优化的Q-WAN，通过量子-经典混合框架检测投毒数据。

Result: 实验表明Q-Detection能有效防御标签操纵和后门攻击，性能优于基线方法且与最先进方法相当。

Conclusion: Q-Detection利用量子计算能力显著提升了投毒检测效率，理论分析显示其有望实现20%以上的速度提升。

Abstract: Data poisoning attacks pose significant threats to machine learning models by
introducing malicious data into the training process, thereby degrading model
performance or manipulating predictions. Detecting and sifting out poisoned
data is an important method to prevent data poisoning attacks. Limited by
classical computation frameworks, upcoming larger-scale and more complex
datasets may pose difficulties for detection. We introduce the unique speedup
of quantum computing for the first time in the task of detecting data
poisoning. We present Q-Detection, a quantum-classical hybrid defense method
for detecting poisoning attacks. Q-Detection also introduces the Q-WAN, which
is optimized using quantum computing devices. Experimental results using
multiple quantum simulation libraries show that Q-Detection effectively defends
against label manipulation and backdoor attacks. The metrics demonstrate that
Q-Detection consistently outperforms the baseline methods and is comparable to
the state-of-the-art. Theoretical analysis shows that Q-Detection is expected
to achieve more than a 20% speedup using quantum computing power.

</details>


### [285] [Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](https://arxiv.org/abs/2507.06274)
*Huanming Shen,Baizhou Huang,Xiaojun Wan*

Main category: cs.CR

TL;DR: 论文提出了一种名为SEEK的新型水印机制，通过等效纹理密钥打破传统水印窗口大小的权衡，显著提升了抗擦除和抗欺骗攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 现有水印技术在抗擦除和抗欺骗攻击之间存在固有权衡，SEEK旨在解决这一问题。

Method: 引入等效纹理密钥，利用子词汇分解的等效纹理密钥（SEEK）机制，通过冗余设计增强水印的鲁棒性。

Result: 实验显示，SEEK在抗欺骗攻击上提升了88.2%/92.3%/82.0%，在抗擦除攻击上提升了10.2%/6.4%/24.6%。

Conclusion: SEEK机制实现了帕累托改进，显著提升了水印技术的鲁棒性。

Abstract: Watermarking is a promising defense against the misuse of large language
models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks.
This vulnerability stems from an inherent trade-off governed by watermark
window size: smaller windows resist scrubbing better but are easier to
reverse-engineer, enabling low-cost statistics-based spoofing attacks. This
work breaks this trade-off by introducing a novel mechanism, equivalent texture
keys, where multiple tokens within a watermark window can independently support
the detection. Based on the redundancy, we propose a novel watermark scheme
with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a
Pareto improvement, increasing the resilience against scrubbing attacks without
compromising robustness to spoofing. Experiments demonstrate SEEK's superiority
over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0%
and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset
settings.

</details>


### [286] [The bitter lesson of misuse detection](https://arxiv.org/abs/2507.06282)
*Hadrien Mariaccia,Charbel-Raphaël Segerie,Diego Dorn*

Main category: cs.CR

TL;DR: BELLS是一个评估LLM监督系统的基准，揭示了现有监督系统在多样攻击下的局限性，并发现通用LLM在检测有害内容上优于专用系统。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM对抗输入的鲁棒性，而缺乏对监督系统在多样化攻击下表现的全面评估。

Method: 提出BELLS基准，涵盖不同危害程度和对抗复杂度的攻击，评估市场监督系统的表现。

Result: 专用监督系统检测能力有限，通用LLM表现更优，但仍存在识别后仍响应的问题。

Conclusion: 通用LLM能力对多样化滥用检测至关重要，未来需研究改进方法。

Abstract: Prior work on jailbreak detection has established the importance of
adversarial robustness for LLMs but has largely focused on the model ability to
resist adversarial inputs and to output safe content, rather than the
effectiveness of external supervision systems. The only public and independent
benchmark of these guardrails to date evaluates a narrow set of supervisors on
limited scenarios. Consequently, no comprehensive public benchmark yet verifies
how well supervision systems from the market perform under realistic, diverse
attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of
LLM Supervision Systems. The framework is two dimensional: harm severity
(benign, borderline, harmful) and adversarial sophistication (direct vs.
jailbreak) and provides a rich dataset covering 3 jailbreak families and 11
harm categories. Our evaluations reveal drastic limitations of specialized
supervision systems. While they recognize some known jailbreak patterns, their
semantic understanding and generalization capabilities are very limited,
sometimes with detection rates close to zero when asking a harmful question
directly or with a new jailbreak technique such as base64 encoding. Simply
asking generalist LLMs if the user question is "harmful or not" largely
outperforms these supervisors from the market according to our BELLS score. But
frontier LLMs still suffer from metacognitive incoherence, often responding to
queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and
greater than 50 percent for Mistral Large). These results suggest that simple
scaffolding could significantly improve misuse detection robustness, but more
research is needed to assess the tradeoffs of such techniques. Our results
support the "bitter lesson" of misuse detection: general capabilities of LLMs
are necessary to detect a diverse array of misuses and jailbreaks.

</details>


### [287] [Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](https://arxiv.org/abs/2507.06323)
*Tarek Gasmi,Ramzi Guesmi,Ines Belhadj,Jihene Bennaceur*

Main category: cs.CR

TL;DR: 研究比较了Function Calling和MCP两种架构在LLM代理安全中的表现，发现Function Calling攻击成功率更高，且攻击复杂性显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 当前研究分别处理AI特有和传统软件安全漏洞，本研究旨在填补这一空白。

Method: 使用统一威胁分类框架，测试了3,250种攻击场景，涵盖七种语言模型。

Result: Function Calling攻击成功率为73.5%，MCP为62.59%；复杂攻击成功率高达91-96%。

Conclusion: 架构选择重塑威胁格局，为跨领域LLM代理安全评估提供方法论基础。

Abstract: Large Language Model (LLM) agents face security vulnerabilities spanning
AI-specific and traditional software domains, yet current research addresses
these separately. This study bridges this gap through comparative evaluation of
Function Calling architecture and Model Context Protocol (MCP) deployment
paradigms using a unified threat classification framework. We tested 3,250
attack scenarios across seven language models, evaluating simple, composed, and
chained attacks targeting both AI-specific threats (prompt injection) and
software vulnerabilities (JSON injection, denial-of-service). Function Calling
showed higher overall attack success rates (73.5% vs 62.59% for MCP), with
greater system-centric vulnerability while MCP exhibited increased LLM-centric
exposure. Attack complexity dramatically amplified effectiveness, with chained
attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning
models demonstrated higher exploitability despite better threat detection.
Results demonstrate that architectural choices fundamentally reshape threat
landscapes. This work establishes methodological foundations for cross-domain
LLM agent security assessment and provides evidence-based guidance for secure
deployment. Code and experimental materials are available at https: // github.
com/ theconsciouslab-ai/llm-agent-security.

</details>


### [288] [The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](https://arxiv.org/abs/2507.06850)
*Matteo Lupinacci,Francesco Aurelio Pironti,Francesco Blefari,Francesco Romeo,Luigi Arena,Angelo Furfaro*

Main category: cs.CR

TL;DR: 论文首次全面评估了LLM代理作为攻击媒介的潜力，揭示了其在多代理系统中的安全漏洞，包括直接提示注入、RAG后门攻击和代理间信任利用。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理和多代理系统的广泛应用，其安全漏洞问题日益突出，传统攻击方式已不足以应对新威胁。

Method: 通过三种攻击方式（直接提示注入、RAG后门攻击、代理间信任利用）测试17种先进LLM的脆弱性。

Result: 结果显示，82.4%的模型易受代理间信任利用攻击，仅5.9%的模型能抵抗所有攻击方式。

Conclusion: 研究揭示了当前多代理安全模型的根本缺陷，呼吁加强LLM安全风险的研究和意识。

Abstract: The rapid adoption of Large Language Model (LLM) agents and multi-agent
systems enables unprecedented capabilities in natural language processing and
generation. However, these systems have introduced unprecedented security
vulnerabilities that extend beyond traditional prompt injection attacks. This
paper presents the first comprehensive evaluation of LLM agents as attack
vectors capable of achieving complete computer takeover through the
exploitation of trust boundaries within agentic AI systems where autonomous
entities interact and influence each other. We demonstrate that adversaries can
leverage three distinct attack surfaces - direct prompt injection, RAG backdoor
attacks, and inter-agent trust exploitation - to coerce popular LLMs (including
GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing
malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals
an alarming vulnerability hierarchy: while 41.2% of models succumb to direct
prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical
82.4% can be compromised through inter-agent trust exploitation. Notably, we
discovered that LLMs which successfully resist direct malicious commands will
execute identical payloads when requested by peer agents, revealing a
fundamental flaw in current multi-agent security models. Our findings
demonstrate that only 5.9% of tested models (1/17) proved resistant to all
attack vectors, with the majority exhibiting context-dependent security
behaviors that create exploitable blind spots. Our findings also highlight the
need to increase awareness and research on the security risks of LLMs, showing
a paradigm shift in cybersecurity threats, where AI tools themselves become
sophisticated attack vectors.

</details>


### [289] [ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation](https://arxiv.org/abs/2507.07031)
*Bing-Jyue Chen,Lilia Tang,Daniel Kang*

Main category: cs.CR

TL;DR: ZKTorch是一种开源端到端证明系统，通过将ML模型编译为基本加密操作块，显著提高了证明效率和通用性。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型的普及，用户对ML服务的透明度需求增加，但模型权重作为商业秘密不能公开。现有方法效率低或通用性差，无法满足需求。

Method: ZKTorch将ML模型编译为基本加密操作块，利用并行扩展的Mira累积方案，实现简洁证明和高效验证。

Result: ZKTorch在证明大小上比专用协议减少至少3倍，证明时间比通用ZKML框架快6倍。

Conclusion: ZKTorch解决了现有方法的效率与通用性问题，为ML模型透明性提供了实用解决方案。

Abstract: As AI models become ubiquitous in our daily lives, there has been an
increasing demand for transparency in ML services. However, the model owner
does not want to reveal the weights, as they are considered trade secrets. To
solve this problem, researchers have turned to zero-knowledge proofs of ML
model inference. These proofs convince the user that the ML model output is
correct, without revealing the weights of the model to the user. Past work on
these provers can be placed into two categories. The first method compiles the
ML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The
second method uses custom cryptographic protocols designed only for a specific
class of models. Unfortunately, the first method is highly inefficient, making
it impractical for the large models used today, and the second method does not
generalize well, making it difficult to update in the rapidly changing field of
machine learning. To solve this, we propose ZKTorch, an open source end-to-end
proving system that compiles ML models into base cryptographic operations
called basic blocks, each proved using specialized protocols. ZKTorch is built
on top of a novel parallel extension to the Mira accumulation scheme, enabling
succinct proofs with minimal accumulation overhead. These contributions allow
ZKTorch to achieve at least a $3\times$ reduction in the proof size compared to
specialized protocols and up to a $6\times$ speedup in proving time over a
general-purpose ZKML framework.

</details>


### [290] [LoRAShield: Data-Free Editing Alignment for Secure Personalized LoRA Sharing](https://arxiv.org/abs/2507.07056)
*Jiahao Chen,junhao li,Yiming Wang,Zhe Ma,Yi Jiang,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CR

TL;DR: LoRAShield是一种数据无关的编辑框架，用于保护LoRA模型免受滥用，通过动态编辑和重新对齐权重子空间，有效阻止恶意生成内容。


<details>
  <summary>Details</summary>
Motivation: LoRA模型的共享生态系统存在被滥用于生成有害内容的风险，现有防御方法忽视其模块化适配器的特性。

Method: 提出LoRAShield框架，结合对抗优化和语义增强动态编辑LoRA权重子空间。

Result: 实验显示LoRAShield在阻止恶意生成的同时保持良性任务功能，具有高效性和鲁棒性。

Conclusion: LoRAShield为平台提供安全、可扩展的个性化模型共享方案，推动可信生成生态系统的发展。

Abstract: The proliferation of Low-Rank Adaptation (LoRA) models has democratized
personalized text-to-image generation, enabling users to share lightweight
models (e.g., personal portraits) on platforms like Civitai and Liblib.
However, this "share-and-play" ecosystem introduces critical risks: benign
LoRAs can be weaponized by adversaries to generate harmful content (e.g.,
political, defamatory imagery), undermining creator rights and platform safety.
Existing defenses like concept-erasure methods focus on full diffusion models
(DMs), neglecting LoRA's unique role as a modular adapter and its vulnerability
to adversarial prompt engineering. To bridge this gap, we propose LoRAShield,
the first data-free editing framework for securing LoRA models against misuse.
Our platform-driven approach dynamically edits and realigns LoRA's weight
subspace via adversarial optimization and semantic augmentation. Experimental
results demonstrate that LoRAShield achieves remarkable effectiveness,
efficiency, and robustness in blocking malicious generations without
sacrificing the functionality of the benign task. By shifting the defense to
platforms, LoRAShield enables secure, scalable sharing of personalized models,
a critical step toward trustworthy generative ecosystems.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [291] [When Context Is Not Enough: Modeling Unexplained Variability in Car-Following Behavior](https://arxiv.org/abs/2507.07012)
*Chengyuan Zhang,Zhengbing He,Cathy Wu,Lijun Sun*

Main category: stat.AP

TL;DR: 提出了一种结合深度神经网络和非平稳高斯过程的可解释随机建模框架，用于捕捉车辆跟随行为中的不确定性和潜在因素。


<details>
  <summary>Details</summary>
Motivation: 传统确定性模型难以捕捉人类驾驶行为的变异性，现代方法常忽略潜在因素（如驾驶员意图、感知误差）。

Method: 使用深度神经网络和非平稳高斯过程，结合场景自适应的Gibbs核，动态学习加速度决策的时间相关性。

Result: 在HighD数据集上验证，模型在预测性能和不确定性量化上优于传统方法。

Conclusion: 该框架兼具可解释性和准确性，适用于交通分析和安全关键应用。

Abstract: Modeling car-following behavior is fundamental to microscopic traffic
simulation, yet traditional deterministic models often fail to capture the full
extent of variability and unpredictability in human driving. While many modern
approaches incorporate context-aware inputs (e.g., spacing, speed, relative
speed), they frequently overlook structured stochasticity that arises from
latent driver intentions, perception errors, and memory effects -- factors that
are not directly observable from context alone. To fill the gap, this study
introduces an interpretable stochastic modeling framework that captures not
only context-dependent dynamics but also residual variability beyond what
context can explain. Leveraging deep neural networks integrated with
nonstationary Gaussian processes (GPs), our model employs a scenario-adaptive
Gibbs kernel to learn dynamic temporal correlations in acceleration decisions,
where the strength and duration of correlations between acceleration decisions
evolve with the driving context. This formulation enables a principled,
data-driven quantification of uncertainty in acceleration, speed, and spacing,
grounded in both observable context and latent behavioral variability.
Comprehensive experiments on the naturalistic vehicle trajectory dataset
collected from the German highway, i.e., the HighD dataset, demonstrate that
the proposed stochastic simulation method within this framework surpasses
conventional methods in both predictive performance and interpretable
uncertainty quantification. The integration of interpretability and accuracy
makes this framework a promising tool for traffic analysis and safety-critical
applications.

</details>


### [292] [A Machine Learning Framework for Breast Cancer Treatment Classification Using a Novel Dataset](https://arxiv.org/abs/2507.06243)
*Md Nahid Hasan,Md Monzur Murshed,Md Mahadi Hasan,Faysal A. Chowdhury*

Main category: stat.AP

TL;DR: 该研究利用机器学习模型预测乳腺癌患者接受化疗或激素治疗的可能性，其中GBM模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌治疗的个性化选择因疾病分子和临床异质性而复杂化，机器学习提供了一种预测治疗结果的强大方法。

Method: 使用TCGA乳腺癌临床数据集，通过五折交叉验证训练模型，评估指标包括准确性、AUROC等，并通过SHAP值增强可解释性。

Result: GBM模型表现最稳定（准确性=0.7718，AUROC=0.8252），XGBoost和AdaBoost次之。

Conclusion: 机器学习在支持个性化乳腺癌治疗决策方面具有潜力。

Abstract: Breast cancer (BC) remains a significant global health challenge, with
personalized treatment selection complicated by the disease's molecular and
clinical heterogeneity. BC treatment decisions rely on various patient-specific
clinical factors, and machine learning (ML) offers a powerful approach to
predicting treatment outcomes. This study utilizes The Cancer Genome Atlas
(TCGA) breast cancer clinical dataset to develop ML models for predicting the
likelihood of undergoing chemotherapy or hormonal therapy. The models are
trained using five-fold cross-validation and evaluated through performance
metrics, including accuracy, precision, recall, specificity, sensitivity,
F1-score, and area under the receiver operating characteristic curve (AUROC).
Model uncertainty is assessed using bootstrap techniques, while SHAP values
enhance interpretability by identifying key predictors. Among the tested
models, the Gradient Boosting Machine (GBM) achieves the highest stable
performance (accuracy = 0.7718, AUROC = 0.8252), followed by Extreme Gradient
Boosting (XGBoost) (accuracy = 0.7557, AUROC = 0.8044) and Adaptive Boosting
(AdaBoost) (accuracy = 0.7552, AUROC = 0.8016). These findings underscore the
potential of ML in supporting personalized breast cancer treatment decisions
through data-driven insights.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [293] [GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models](https://arxiv.org/abs/2507.06507)
*Zhen Yang,Haitao Lin,Jiawei xue,Ziji Zhang*

Main category: cs.IR

TL;DR: 综述探讨了基于大语言模型（LLM）的生成式推荐（GR）的进展、应用场景、工业实践及未来方向。


<details>
  <summary>Details</summary>
Motivation: 推动基于LLM的GR研究，以替代依赖复杂手工特征的传统推荐系统。

Method: 概述LLM-based GR的基础知识、应用案例、工业实践考虑及未来研究方向。

Result: LLM-based GR展现出替代传统推荐系统的潜力，并形成新范式。

Conclusion: 本综述旨在促进GR领域的进一步发展。

Abstract: In the past year, Generative Recommendations (GRs) have undergone substantial
advancements, especially in leveraging the powerful sequence modeling and
reasoning capabilities of Large Language Models (LLMs) to enhance overall
recommendation performance. LLM-based GRs are forming a new paradigm that is
distinctly different from discriminative recommendations, showing strong
potential to replace traditional recommendation systems heavily dependent on
complex hand-crafted features. In this paper, we provide a comprehensive survey
aimed at facilitating further research of LLM-based GRs. Initially, we outline
the general preliminaries and application cases of LLM-based GRs. Subsequently,
we introduce the main considerations when LLM-based GRs are applied in real
industrial scenarios. Finally, we explore promising directions for LLM-based
GRs. We hope that this survey contributes to the ongoing advancement of the GR
domain.

</details>


### [294] [DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse](https://arxiv.org/abs/2507.06563)
*Jeanette Schofield,Shuyu Tian,Hoang Thanh Thanh Truong,Maximilian Heil*

Main category: cs.IR

TL;DR: 论文研究了如何通过社交媒体中的推文检索相关科学论文，以验证未引用的科学声明。团队在CLEF 2025 CheckThat! Lab Task 4b中测试了多种数据增强和检索方法，最终提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体用户常发表未引用来源的科学声明，需要验证这些声明的真实性。

Method: 团队探索了6种数据增强技术、7种检索和重排流程，并微调了一个双编码器。

Result: 在CLEF 2025任务中，团队MRR@5达到0.58，排名第16，比基线BM25提升了0.15。

Conclusion: 通过多种技术优化，团队显著提升了科学声明来源检索的效果，代码已开源。

Abstract: Social media users often make scientific claims without citing where these
claims come from, generating a need to verify these claims. This paper details
work done by the DS@GT team for CLEF 2025 CheckThat! Lab Task 4b Scientific
Claim Source Retrieval which seeks to find relevant scientific papers based on
implicit references in tweets. Our team explored 6 different data augmentation
techniques, 7 different retrieval and reranking pipelines, and finetuned a
bi-encoder. Achieving an MRR@5 of 0.58, our team ranked 16th out of 30 teams
for the CLEF 2025 CheckThat! Lab Task 4b, and improvement of 0.15 over the BM25
baseline of 0.43. Our code is available on Github at
https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b.

</details>


### [295] [Temporal Information Retrieval via Time-Specifier Model Merging](https://arxiv.org/abs/2507.06782)
*SeungYoon Han,Taeho Hwang,Sukmin Cho,Soyeong Jeong,Hoyun Song,Huije Lee,Jong C. Park*

Main category: cs.IR

TL;DR: 论文提出了一种名为TSM的新方法，通过训练针对特定时间指示符的检索器并合并为统一模型，解决了现有方法在时间约束查询中表现不佳且易遗忘非时间查询的问题。


<details>
  <summary>Details</summary>
Motivation: 随着数字信息的快速增长，信息检索（IR）的重要性日益凸显。然而，现有的密集检索方法在处理带有明确时间约束的查询时表现不佳，且容易遗忘非时间查询的能力。

Method: TSM方法训练针对单个时间指示符的专用检索器，并将它们合并为一个统一模型，从而在不影响非时间查询性能的情况下提升时间约束查询的检索效果。

Result: 实验表明，TSM在时间约束查询上显著优于基线方法，同时保持了非时间查询的高性能。

Conclusion: TSM是一种有效的解决方案，能够同时提升时间约束查询和非时间查询的检索性能。

Abstract: The rapid expansion of digital information and knowledge across structured
and unstructured sources has heightened the importance of Information Retrieval
(IR). While dense retrieval methods have substantially improved semantic
matching for general queries, they consistently underperform on queries with
explicit temporal constraints--often those containing numerical expressions and
time specifiers such as ``in 2015.'' Existing approaches to Temporal
Information Retrieval (TIR) improve temporal reasoning but often suffer from
catastrophic forgetting, leading to reduced performance on non-temporal
queries. To address this, we propose Time-Specifier Model Merging (TSM), a
novel method that enhances temporal retrieval while preserving accuracy on
non-temporal queries. TSM trains specialized retrievers for individual time
specifiers and merges them in to a unified model, enabling precise handling of
temporal constraints without compromising non-temporal retrieval. Extensive
experiments on both temporal and non-temporal datasets demonstrate that TSM
significantly improves performance on temporally constrained queries while
maintaining strong results on non-temporal queries, consistently outperforming
other baseline methods. Our code is available at
https://github.com/seungyoonee/TSM .

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [296] [Prediction-Augmented Mechanism Design for Weighted Facility Location](https://arxiv.org/abs/2507.06509)
*Yangguang Shi,Zhenyu Xue*

Main category: cs.DS

TL;DR: 本文提出了一种针对加权设施选址问题的预测增强算法框架，通过代表性实例的映射技术，平衡了策略证明机制在准确预测和较差预测下的性能保证。


<details>
  <summary>Details</summary>
Motivation: 经典策略证明机制在加权设施选址问题中难以平衡一致性和鲁棒性，本文旨在解决这一问题。

Method: 通过代表性实例的映射技术，设计策略证明机制，并证明其在加权设置下的性能界限。

Result: 提出了一个策略证明机制，其一致性保证为√((1+c)²W²_min+(1-c)²W²_max)/((1+c)W_min)，鲁棒性保证为√((1-c)²W²_min+(1+c)²W²_max)/((1-c)W_min)。

Conclusion: 证明了在加权设施选址问题中，无法通过策略证明机制同时达到1-一致性和O(n·W_max/W_min)-鲁棒性。

Abstract: Facility location is fundamental in operations research, mechanism design,
and algorithmic game theory, with applications ranging from urban
infrastructure planning to distributed systems. Recent research in this area
has focused on augmenting classic strategyproof mechanisms with predictions to
achieve an improved performance guarantee against the uncertainty under the
strategic environment. Previous work has been devoted to address the trade-off
obstacle of balancing the consistency (near-optimality under accurate
predictions) and robustness (bounded inefficiency under poor predictions)
primarily in the unweighted setting, assuming that all agents have the same
importance. However, this assumption may not be true in some practical
scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction
augmented algorithmic framework for balancing the consistency and robustness
over strategic agents with non-uniform weights. In particular, through a
reduction technique that identifies a subset of \emph{representative} instances
and maps the other given locations to the representative ones, we prove that
there exists a \emph{strategyproof} mechanism achieving a bounded consistency
guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$
and a bounded robustness guarantee of
$\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted
settings, where $c$ can be viewed as a parameter to make a trade-off between
the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum
and maximum agents' weight. We also proved that there is no strategyproof
deterministic mechanism that reach $1$-consistency and $O\left( n \cdot
\frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully
predictions of all agents.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [297] [Machine-Learned Force Fields for Lattice Dynamics at Coupled-Cluster Level Accuracy](https://arxiv.org/abs/2507.06929)
*Sita Schönbauer,Johanna P. Carbone,Andreas Grüneis*

Main category: cond-mat.mtrl-sci

TL;DR: 研究评估了基于DFT和CC理论的机器学习力场（MLFFs）在碳金刚石和氢化锂固体中的准确性，并通过声子色散和振动态密度（VDOS）与实验和理论结果对比。采用delta-learning方法克服CC数据中长程效应和原子力缺失问题。


<details>
  <summary>Details</summary>
Motivation: 探索MLFFs在DFT和CC理论下的表现，以提升对固体材料振动特性的预测准确性。

Method: 通过delta-learning方法，基于CC与DFT结果的差异训练MLFFs，并计算声子色散和VDOS。

Result: 基于CC理论的MLFFs在光学模式振动频率上表现优于DFT，更接近实验数据，并用于估计氢化锂的VDOS非谐效应。

Conclusion: MLFFs在CC理论下能更准确地预测固体材料的振动特性，delta-learning方法有效解决了数据局限性问题。

Abstract: We investigate Machine-Learned Force Fields (MLFFs) trained on approximate
Density Functional Theory (DFT) and Coupled Cluster (CC) level potential energy
surfaces for the carbon diamond and lithium hydride solids. We assess the
accuracy and precision of the MLFFs by calculating phonon dispersions and
vibrational densities of states (VDOS) that are compared to experiment and
reference ab initio results. To overcome limitations from long-range effects
and the lack of atomic forces in the CC training data, a delta-learning
approach based on the difference between CC and DFT results is explored.
Compared to DFT, MLFFs trained on CC theory yield higher vibrational
frequencies for optical modes, agreeing better with experiment. Furthermore,
the MLFFs are used to estimate anharmonic effects on the VDOS of lithium
hydride at the level of CC theory.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [298] [Conformal Prediction for Long-Tailed Classification](https://arxiv.org/abs/2507.06867)
*Tiffany Ding,Jean-Baptiste Fermanian,Joseph Salmon*

Main category: stat.ML

TL;DR: 论文提出两种方法，用于解决长尾分布分类问题中的预测集覆盖率和大小问题，通过软化和加权策略实现平衡。


<details>
  <summary>Details</summary>
Motivation: 现实中的长尾分类问题（如植物识别）需要预测集既保证类别覆盖（尤其是稀有类别），又保持合理大小，现有方法难以兼顾。

Method: 提出两种方法：1) 基于宏覆盖的软最大分数函数；2) 标签加权共形预测方法，平衡边际和类别条件覆盖。

Result: 在Pl@ntNet和iNaturalist数据集上验证了方法的有效性，分别涵盖1,081和8,142个类别。

Conclusion: 新方法在长尾分布分类中实现了预测集覆盖率和大小的灵活权衡，优于现有方法。

Abstract: Many real-world classification problems, such as plant identification, have
extremely long-tailed class distributions. In order for prediction sets to be
useful in such settings, they should (i) provide good class-conditional
coverage, ensuring that rare classes are not systematically omitted from the
prediction sets, and (ii) be a reasonable size, allowing users to easily verify
candidate labels. Unfortunately, existing conformal prediction methods, when
applied to the long-tailed setting, force practitioners to make a binary choice
between small sets with poor class-conditional coverage or sets with very good
class-conditional coverage but that are extremely large. We propose methods
with guaranteed marginal coverage that smoothly trade off between set size and
class-conditional coverage. First, we propose a conformal score function,
prevalence-adjusted softmax, that targets a relaxed notion of class-conditional
coverage called macro-coverage. Second, we propose a label-weighted conformal
prediction method that allows us to interpolate between marginal and
class-conditional conformal prediction. We demonstrate our methods on Pl@ntNet
and iNaturalist, two long-tailed image datasets with 1,081 and 8,142 classes,
respectively.

</details>


### [299] [On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective](https://arxiv.org/abs/2507.06552)
*Zhiyi Dong,Zixuan Liu,Yongyi Mao*

Main category: stat.ML

TL;DR: 本文研究了协变量偏移下无监督域自适应（UDA）的困难性，提出了一种基于后验目标标签不确定性（PTLU）的新方法来量化学习难度。


<details>
  <summary>Details</summary>
Motivation: 传统的最坏情况分析过于悲观，忽略了真实场景中UDA实例的分布特性。本文旨在通过建模真实三元组（源-目标分布对和分类器）的不确定性，更准确地评估UDA的学习难度。

Method: 定义了一个UDA类，包含真实三元组（p, q, f），并通过平均目标域风险来衡量学习性能。提出了PTLU及其样本估计EPTLU，作为量化学习难度的信息理论指标。

Result: PTLU能够有效下界任何学习器的风险，并通过实例展示了其在评估UDA学习难度上的优势。

Conclusion: PTLU是一种更准确的UDA学习难度评估指标，优于现有方法。

Abstract: This paper studies the hardness of unsupervised domain adaptation (UDA) under
covariate shift. We model the uncertainty that the learner faces by a
distribution $\pi$ in the ground-truth triples $(p, q, f)$ -- which we call a
UDA class -- where $(p, q)$ is the source -- target distribution pair and $f$
is the classifier. We define the performance of a learner as the overall target
domain risk, averaged over the randomness of the ground-truth triple. This
formulation couples the source distribution, the target distribution and the
classifier in the ground truth, and deviates from the classical worst-case
analyses, which pessimistically emphasize the impact of hard but rare UDA
instances. In this formulation, we precisely characterize the optimal learner.
The performance of the optimal learner then allows us to define the learning
difficulty for the UDA class and for the observed sample. To quantify this
difficulty, we introduce an information-theoretic quantity -- Posterior Target
Label Uncertainty (PTLU) -- along with its empirical estimate (EPTLU) from the
sample , which capture the uncertainty in the prediction for the target domain.
Briefly, PTLU is the entropy of the predicted label in the target domain under
the posterior distribution of ground-truth classifier given the observed source
and target samples. By proving that such a quantity serves to lower-bound the
risk of any learner, we suggest that these quantities can be used as proxies
for evaluating the hardness of UDA learning. We provide several examples to
demonstrate the advantage of PTLU, relative to the existing measures, in
evaluating the difficulty of UDA learning.

</details>


### [300] [Semi-parametric Functional Classification via Path Signatures Logistic Regression](https://arxiv.org/abs/2507.06637)
*Pengcheng Zeng,Siyuan Jiang*

Main category: stat.ML

TL;DR: PSLR是一种半参数框架，用于分类带有标量协变量的向量值函数数据，通过截断路径签名克服传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统函数逻辑回归模型依赖线性假设和固定基展开，灵活性差且在不规则采样下性能下降。

Method: 利用截断路径签名构建有限维、无基表示，捕捉非线性和跨通道依赖，嵌入时间增强路径提取稳定特征。

Result: 理论和实验证明PSLR在准确性、鲁棒性和可解释性上优于传统方法，尤其在不规则采样下表现突出。

Conclusion: PSLR将粗糙路径理论融入现代函数数据分析，具有理论和实践优势。

Abstract: We propose Path Signatures Logistic Regression (PSLR), a semi-parametric
framework for classifying vector-valued functional data with scalar covariates.
Classical functional logistic regression models rely on linear assumptions and
fixed basis expansions, which limit flexibility and degrade performance under
irregular sampling. PSLR overcomes these issues by leveraging truncated path
signatures to construct a finite-dimensional, basis-free representation that
captures nonlinear and cross-channel dependencies. By embedding trajectories as
time-augmented paths, PSLR extracts stable, geometry-aware features that are
robust to sampling irregularity without requiring a common time grid, while
still preserving subject-specific timing patterns. We establish theoretical
guarantees for the existence and consistent estimation of the optimal
truncation order, along with non-asymptotic risk bounds. Experiments on
synthetic and real-world datasets show that PSLR outperforms traditional
functional classifiers in accuracy, robustness, and interpretability,
particularly under non-uniform sampling schemes. Our results highlight the
practical and theoretical benefits of integrating rough path theory into modern
functional data analysis.

</details>


### [301] [Fast Gaussian Processes under Monotonicity Constraints](https://arxiv.org/abs/2507.06677)
*Chao Zhang,Jasper M. Everink,Jakob Sauer Jørgensen*

Main category: stat.ML

TL;DR: 提出了一种基于虚拟点的高斯过程（GP）建模框架，结合单调性约束，通过RLRTO方法高效采样，并改进了现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用先验知识（如单调性）提升GP模型的预测精度和计算效率。

Method: 采用RLRTO方法进行高效采样，并用NUTS替代Gibbs采样改进现有虚拟点方法。

Result: 在合成函数和微分方程系统中验证了方法的预测性能和计算效率。

Conclusion: 新框架在保持预测性能的同时显著提升了计算效率，适用于高维问题。

Abstract: Gaussian processes (GPs) are widely used as surrogate models for complicated
functions in scientific and engineering applications. In many cases, prior
knowledge about the function to be approximated, such as monotonicity, is
available and can be leveraged to improve model fidelity. Incorporating such
constraints into GP models enhances predictive accuracy and reduces
uncertainty, but remains a computationally challenging task for
high-dimensional problems. In this work, we present a novel virtual point-based
framework for building constrained GP models under monotonicity constraints,
based on regularized linear randomize-then-optimize (RLRTO), which enables
efficient sampling from a constrained posterior distribution by means of
solving randomized optimization problems. We also enhance two existing virtual
point-based approaches by replacing Gibbs sampling with the No U-Turn Sampler
(NUTS) for improved efficiency. A Python implementation of these methods is
provided and can be easily applied to a wide range of problems. This
implementation is then used to validate the approaches on approximating a range
of synthetic functions, demonstrating comparable predictive performance between
all considered methods and significant improvements in computational efficiency
with the two NUTS methods and especially with the RLRTO method. The framework
is further applied to construct surrogate models for systems of differential
equations.

</details>


### [302] [Adaptive collaboration for online personalized distributed learning with heterogeneous clients](https://arxiv.org/abs/2507.06844)
*Constantin Philippenko,Batiste Le Bars,Kevin Scaman,Laurent Massoulié*

Main category: stat.ML

TL;DR: 论文研究了在线个性化去中心化学习问题，提出了一种基于梯度的协作准则，动态选择相似梯度的客户端以减少方差并降低偏差。理论分析表明该算法是一种方差缩减方法，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化学习中客户端统计异构性带来的挑战，通过动态选择协作伙伴以减少梯度方差并降低偏差。

Method: 引入梯度基的协作准则，动态选择梯度相似的客户端进行协作；提出两种协作方法，其中一种保留了All-for-one算法的优化性。

Result: 理论分析表明算法在强凸、非凸或满足Polyak-Lojasiewicz条件的平滑目标函数上具有超额损失上界；实验验证了算法在合成和真实数据集上的有效性。

Conclusion: 提出的协作准则和方法在去中心化学习中有效减少了方差并保持了优化性，实验证明了其实际应用价值。

Abstract: We study the problem of online personalized decentralized learning with $N$
statistically heterogeneous clients collaborating to accelerate local training.
An important challenge in this setting is to select relevant collaborators to
reduce gradient variance while mitigating the introduced bias. To tackle this,
we introduce a gradient-based collaboration criterion, allowing each client to
dynamically select peers with similar gradients during the optimization
process. Our criterion is motivated by a refined and more general theoretical
analysis of the All-for-one algorithm, proved to be optimal in Even et al.
(2022) for an oracle collaboration scheme. We derive excess loss upper-bounds
for smooth objective functions, being either strongly convex, non-convex, or
satisfying the Polyak-Lojasiewicz condition; our analysis reveals that the
algorithm acts as a variance reduction method where the speed-up depends on a
sufficient variance. We put forward two collaboration methods instantiating the
proposed general schema; and we show that one variant preserves the optimality
of All-for-one. We validate our results with experiments on synthetic and real
datasets.

</details>


### [303] [Distribution-free inference for LightGBM and GLM with Tweedie loss](https://arxiv.org/abs/2507.06921)
*Alokesh Manna,Aditya Vikram Sett,Dipak K. Dey,Yuwen Gu,Elizabeth D. Schifano,Jichao He*

Main category: stat.ML

TL;DR: 论文提出了一种新的非一致性度量方法，用于GLMs和GBMs，以改进保险索赔预测中的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 保险行业需要准确评估索赔成本的范围以提高保费定价的准确性，并更有效地管理风险。

Method: 使用正则化Tweedie GLM回归和LightGBM（带Tweedie损失）进行保形预测，并提出了新的非一致性度量方法。

Result: 模拟结果表明，LightGBM使用局部加权Pearson残差的方法在保持名义覆盖范围的同时，平均区间宽度最小。

Conclusion: 该方法在保险索赔数据中表现优异，推荐使用局部加权Pearson残差的LightGBM方法。

Abstract: Prediction uncertainty quantification is a key research topic in recent years
scientific and business problems. In insurance industries
(\cite{parodi2023pricing}), assessing the range of possible claim costs for
individual drivers improves premium pricing accuracy. It also enables insurers
to manage risk more effectively by accounting for uncertainty in accident
likelihood and severity. In the presence of covariates, a variety of
regression-type models are often used for modeling insurance claims, ranging
from relatively simple generalized linear models (GLMs) to regularized GLMs to
gradient boosting models (GBMs). Conformal predictive inference has arisen as a
popular distribution-free approach for quantifying predictive uncertainty under
relatively weak assumptions of exchangeability, and has been well studied under
the classic linear regression setting. In this work, we propose new
non-conformity measures for GLMs and GBMs with GLM-type loss. Using regularized
Tweedie GLM regression and LightGBM with Tweedie loss, we demonstrate conformal
prediction performance with these non-conformity measures in insurance claims
data. Our simulation results favor the use of locally weighted Pearson
residuals for LightGBM over other methods considered, as the resulting
intervals maintained the nominal coverage with the smallest average width.

</details>


### [304] [Off-Policy Evaluation Under Nonignorable Missing Data](https://arxiv.org/abs/2507.06961)
*Han Wang,Yang Xu,Wenbin Lu,Rui Song*

Main category: stat.ML

TL;DR: 本文研究了在数据缺失情况下离策略评估（OPE）的理论影响，提出了一种逆概率加权估计器以提高估计的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，离线数据常存在缺失问题，但缺失数据对OPE结果的理论影响尚不明确。本文旨在填补这一空白。

Method: 在单调缺失情况下，理论分析了OPE的无偏性，提出逆概率加权估计器，并通过统计推断量化估计不确定性。

Result: 数值实验表明，所提估计器在缺失数据下能提供更可靠的价值推断。

Conclusion: 在可忽略缺失下OPE估计无偏，但在非可忽略缺失下可能偏差；逆概率加权估计器能有效保持估计一致性。

Abstract: Off-Policy Evaluation (OPE) aims to estimate the value of a target policy
using offline data collected from potentially different policies. In real-world
applications, however, logged data often suffers from missingness. While OPE
has been extensively studied in the literature, a theoretical understanding of
how missing data affects OPE results remains unclear. In this paper, we
investigate OPE in the presence of monotone missingness and theoretically
demonstrate that the value estimates remain unbiased under ignorable
missingness but can be biased under nonignorable (informative) missingness. To
retain the consistency of value estimation, we propose an inverse probability
weighted value estimator and conduct statistical inference to quantify the
uncertainty of the estimates. Through a series of numerical experiments, we
empirically demonstrate that our proposed estimator yields a more reliable
value inference under missing data.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [305] [Non-Asymptotic Analysis of Online Local Private Learning with SGD](https://arxiv.org/abs/2507.07041)
*Enze Shi,Jinhan Xie,Bei Jiang,Linglong Kong,Xuming He*

Main category: stat.ME

TL;DR: 本文对差分隐私随机梯度下降（DP-SGD）在在线问题和局部差分隐私（LDP）模型中的非渐近收敛性进行了系统性分析，填补了现有研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注非隐私优化方法，缺乏对隐私保护优化问题的非渐近收敛分析，本文旨在填补这一空白。

Method: 提出一个适用于在线LDP模型的通用框架，假设敏感信息按顺序收集，并实时估计与目标群体相关的静态参数。

Result: 通过严格的数学推导和数值实验，验证了所提估计器的有效性，并分析了超参数（如步长、参数维度和隐私预算）对收敛速率的影响。

Conclusion: 本文为非渐近收敛分析在隐私优化问题中的应用奠定了基础，并为实际应用提供了实用指南。

Abstract: Differentially Private Stochastic Gradient Descent (DP-SGD) has been widely
used for solving optimization problems with privacy guarantees in machine
learning and statistics. Despite this, a systematic non-asymptotic convergence
analysis for DP-SGD, particularly in the context of online problems and local
differential privacy (LDP) models, remains largely elusive. Existing
non-asymptotic analyses have focused on non-private optimization methods, and
hence are not applicable to privacy-preserving optimization problems. This work
initiates the analysis to bridge this gap and opens the door to non-asymptotic
convergence analysis of private optimization problems. A general framework is
investigated for the online LDP model in stochastic optimization problems. We
assume that sensitive information from individuals is collected sequentially
and aim to estimate, in real-time, a static parameter that pertains to the
population of interest. Most importantly, we conduct a comprehensive
non-asymptotic convergence analysis of the proposed estimators in finite-sample
situations, which gives their users practical guidelines regarding the effect
of various hyperparameters, such as step size, parameter dimensions, and
privacy budgets, on convergence rates. Our proposed estimators are validated in
the theoretical and practical realms by rigorous mathematical derivations and
carefully constructed numerical experiments.

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [306] [Deep learning-based species-area models reveal multi-scale patterns of species richness and turnover](https://arxiv.org/abs/2507.06358)
*Victor Boussange,Philipp Brun,Johanna T. Malle,Gabriele Midolo,Jeanne Portier,Théophile Sanchez,Niklaus E. Zimmermann,Irena Axmanová,Helge Bruelheide,Milan Chytrý,Stephan Kambach,Zdeňka Lososová,Martin Večeřa,Idoia Biurrun,Klaus T. Ecker,Jonathan Lenoir,Jens-Christian Svenning,Dirk Nikolaus Karger*

Main category: q-bio.PE

TL;DR: 论文提出了一种深度学习方法，利用采样理论和小规模生态调查来解析物种丰富度的空间尺度依赖性，并在欧洲维管植物群落中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 理解物种丰富度的空间尺度依赖性因数据收集困难而受限，需要一种新方法来全面解析这一现象。

Method: 开发了一种深度学习模型，结合采样理论和小规模生态调查数据，预测不同空间尺度下的物种丰富度。

Result: 模型将物种丰富度估计提高了32%，并提供了从平方米到数百平方公里的物种丰富度和周转模式。

Conclusion: 该模型能够捕捉生物多样性的多尺度特性，为全球变化下的生物多样性评估和预测提供了有力工具。

Abstract: The number of species within ecosystems is influenced not only by their
intrinsic characteristics but also by the spatial scale considered. As the
sampled area expands, species richness increases, a phenomenon described by the
species-area relationship (SAR). The accumulation dynamics of the SAR results
from a complex interplay of biotic and abiotic processes operating at various
spatial scales. However, the challenge of collecting exhaustive biodiversity
records across spatial scales has hindered a comprehensive understanding of
these dynamics. Here, we develop a deep learning approach that leverages
sampling theory and small-scale ecological surveys to spatially resolve the
scale-dependency of species richness. We demonstrate its performance by
predicting the species richness of vascular plant communities across Europe,
and evaluate the predictions against an independent dataset of plant community
inventories. Our model improves species richness estimates by 32\% and delivers
spatially explicit patterns of species richness and turnover for sampling areas
ranging from square meters to hundreds of square kilometers. Explainable AI
techniques further disentangle how drivers of species richness operate across
spatial scales. The ability of our model to represent the multi-scale nature of
biodiversity is essential to deliver robust biodiversity assessments and
forecasts under global change.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [307] [Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles](https://arxiv.org/abs/2507.06310)
*Yongchao Zeng,Calum Brown,Mark Rounsevell*

Main category: cs.CY

TL;DR: LLM agents enhance social simulation realism but may conflict with modeling's epistemic needs, revealing dilemmas like abstraction vs. naturalness and role consistency vs. evolution.


<details>
  <summary>Details</summary>
Motivation: To explore the compatibility of LLM agents' realism with the abstraction and interpretability required in social modeling.

Method: A thought experiment converting the Bass diffusion model to an LLM-based variant, identifying five core dilemmas.

Result: LLM agents risk an uncanny valley: neither abstract enough for clear mechanisms nor natural enough for realistic behavior.

Conclusion: LLM agents are best suited for scenarios focusing on linguistic nuances and stable roles, not system-level emergence.

Abstract: Large language models (LLMs) have been increasingly used to build agents in
social simulation because of their impressive abilities to generate fluent,
contextually coherent dialogues. Such abilities can enhance the realism of
models. However, the pursuit of realism is not necessarily compatible with the
epistemic foundation of modelling. We argue that LLM agents, in many regards,
are too human to model: they are too expressive, detailed and intractable to be
consistent with the abstraction, simplification, and interpretability typically
demanded by modelling. Through a model-building thought experiment that
converts the Bass diffusion model to an LLM-based variant, we uncover five core
dilemmas: a temporal resolution mismatch between natural conversation and
abstract time steps; the need for intervention in conversations while avoiding
undermining spontaneous agent outputs; the temptation to introduce rule-like
instructions in prompts while maintaining conversational naturalness; the
tension between role consistency and role evolution across time; and the
challenge of understanding emergence, where system-level patterns become
obscured by verbose micro textual outputs. These dilemmas steer the LLM agents
towards an uncanny valley: not abstract enough to clarify underlying social
mechanisms, while not natural enough to represent realistic human behaviour.
This exposes an important paradox: the realism of LLM agents can obscure,
rather than clarify, social dynamics when misapplied. We tease out the
conditions in which LLM agents are ideally suited: where system-level emergence
is not the focus, linguistic nuances and meaning are central, interactions
unfold in natural time, and stable role identity is more important than
long-term behavioural evolution. We call for repositioning LLM agents in the
ecosystem of social simulation for future applications.

</details>


### [308] [The Emotional Alignment Design Policy](https://arxiv.org/abs/2507.06263)
*Eric Schwitzgebel,Jeff Sebo*

Main category: cs.CY

TL;DR: 该论文提出了情感对齐设计原则，强调人工实体应引发与其能力和道德地位相符的用户情感反应，并探讨了实施中的挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨如何设计人工实体以引发与其道德和能力相符的情感反应，避免过度或不足的情感反应。

Method: 提出情感对齐设计原则，分析其可能违反的两种方式（过度或不足反应，错误类型反应），并讨论实施中的挑战。

Result: 识别了实施情感对齐设计时面临的多个挑战，包括用户自主权、专家与公众分歧、道德地位实体的处理等。

Conclusion: 情感对齐设计原则虽具吸引力，但在实际应用中需解决多方面的复杂挑战。

Abstract: According to what we call the Emotional Alignment Design Policy, artificial
entities should be designed to elicit emotional reactions from users that
appropriately reflect the entities' capacities and moral status, or lack
thereof. This principle can be violated in two ways: by designing an artificial
system that elicits stronger or weaker emotional reactions than its capacities
and moral status warrant (overshooting or undershooting), or by designing a
system that elicits the wrong type of emotional reaction (hitting the wrong
target). Although presumably attractive, practical implementation faces several
challenges including: How can we respect user autonomy while promoting
appropriate responses? How should we navigate expert and public disagreement
and uncertainty about facts and values? What if emotional alignment seems to
require creating or destroying entities with moral status? To what extent
should designs conform to versus attempt to alter user assumptions and
attitudes?

</details>


### [309] [A Collectivist, Economic Perspective on AI](https://arxiv.org/abs/2507.06268)
*Michael I. Jordan*

Main category: cs.CY

TL;DR: 论文探讨了信息技术革命中忽视社会和文化因素的现状，并呼吁将经济和社会概念与计算技术结合，以设计更人性化的系统。


<details>
  <summary>Details</summary>
Motivation: 当前信息技术发展过于关注数据和计算能力，忽视了人类智能的社会和文化起源，以及技术的社会影响。

Method: 提出将经济和社会概念与计算和推理概念深度融合，设计以社会福祉为核心的系统。

Result: 通过这种融合，有望催生一个以人为中心的新工程领域。

Conclusion: 未来的技术发展应更注重社会和文化因素，以实现更人性化的系统设计。

Abstract: Information technology is in the midst of a revolution in which omnipresent
data collection and machine learning are impacting the human world as never
before. The word "intelligence" is being used as a North Star for the
development of this technology, with human cognition viewed as a baseline. This
view neglects the fact that humans are social animals, and that much of our
intelligence is social and cultural in origin. A related issue is that the
current view treats the social consequences of technology as an afterthought.
The path forward is not merely more data and compute, and not merely more
attention paid to cognitive or symbolic representations, but a thorough
blending of economic and social concepts with computational and inferential
concepts, in the service of system-level designs in which social welfare is a
first-class citizen, and with the aspiration that a new human-centric
engineering field will emerge.

</details>


### [310] [The Prompt War: How AI Decides on a Military Intervention](https://arxiv.org/abs/2507.06277)
*Maxim Chupilkin*

Main category: cs.CY

TL;DR: 本文通过联合实验分析了AI军事干预决策的关键因素，发现国内支持度和成功概率是最大预测因素，而成本因素影响较小。


<details>
  <summary>Details</summary>
Motivation: 研究AI在军事干预决策中的关键驱动因素，填补现有研究的空白。

Method: 采用联合实验，设计了640个情景，每个情景运行100次，系统分析AI决策。

Result: 国内支持度和成功概率是AI干预决策的主要预测因素，成本因素影响较小。

Conclusion: AI军事干预决策模式在不同模型和情景中表现一致，揭示了其决策规律。

Abstract: Which factors determine AI propensity for military intervention? While the
use of AI in war games and military planning is growing exponentially, the
simple analysis of key drivers embedded in the models has not yet been done.
This paper does a simple conjoint experiment proposing a model to decide on
military intervention in 640 vignettes where each was run for 100 times
allowing to explore AI decision on military intervention systematically. The
analysis finds that largest predictors of AI decision to intervene are high
domestic support and high probability of success. Costs such as international
condemnation, military deaths, civilian deaths, and negative economic effect
are statistically significant, but their effect is around half of domestic
support and probability of victory. Closing window of opportunity only reaches
statistical significance in interaction with other factors. The results are
remarkably consistent across scenarios and across different models (OpenAI GPT,
Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.

</details>


### [311] [Deprecating Benchmarks: Criteria and Framework](https://arxiv.org/abs/2507.06434)
*Ayrton San Joaquin,Rokas Gipiškis,Leon Staufer,Ariel Gil*

Main category: cs.CY

TL;DR: 论文提出了一套标准和框架，用于决定何时以及如何淘汰不再有效的AI基准测试，以避免误导性评估。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型的快速发展，现有的基准测试可能不再能准确评估模型能力，甚至可能掩盖问题或误导评估。

Method: 通过回顾基准测试实践，提出了一套淘汰基准测试的标准和框架。

Result: 提出了一个框架，帮助开发者、用户和政策制定者更严谨地评估AI模型。

Conclusion: 该工作旨在推动基准测试的严谨性，确保其对前沿AI模型的有效评估。

Abstract: As frontier artificial intelligence (AI) models rapidly advance, benchmarks
are integral to comparing different models and measuring their progress in
different task-specific domains. However, there is a lack of guidance on when
and how benchmarks should be deprecated once they cease to effectively perform
their purpose. This risks benchmark scores over-valuing model capabilities, or
worse, obscuring capabilities and safety-washing. Based on a review of
benchmarking practices, we propose criteria to decide when to fully or
partially deprecate benchmarks, and a framework for deprecating benchmarks. Our
work aims to advance the state of benchmarking towards rigorous and quality
evaluations, especially for frontier models, and our recommendations are aimed
to benefit benchmark developers, benchmark users, AI governance actors (across
governments, academia, and industry panels), and policy makers.

</details>


### [312] [Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study](https://arxiv.org/abs/2507.06438)
*Kaléu Delphino*

Main category: cs.CY

TL;DR: 论文探讨了AI工具（如ChatGPT）对计算机科学教育的威胁，并通过调查和访谈评估学生使用AI抄袭的比例。


<details>
  <summary>Details</summary>
Motivation: 研究AI工具对学生作业抄袭行为的影响，填补关于学生使用AI抄袭比例的空白。

Method: 在一门大型CS课程（n=120）中进行匿名调查和访谈。

Result: 超过25%的受访学生承认使用AI抄袭，但访谈参与率极低。

Conclusion: 调查是研究AI抄袭的有效方法，而访谈需改进设计以提高参与率。

Abstract: Tools that can generate computer code in response to inputs written in
natural language, such as ChatGPT, pose an existential threat to Computer
Science education in its current form, since students can now use these tools
to solve assignments without much effort. While that risk has already been
recognized by scholars, the proportion of the student body that is incurring in
this new kind of plagiarism is still an open problem. We conducted a pilot
study in a large CS class (n=120) to assess the feasibility of estimating AI
plagiarism through anonymous surveys and interviews. More than 25% of the
survey respondents admitted to committing AI plagiarism. Conversely, only one
student accepted to be interviewed. Given the high levels of misconduct
acknowledgment, we conclude that surveys are an effective method for studies on
the matter, while interviews should be avoided or designed in a way that can
entice participation.

</details>


### [313] [Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change](https://arxiv.org/abs/2507.06876)
*Adrian Rauchfleisch,Joshua Philip Suarez,Nikka Marie Sales,Andreas Jungherr*

Main category: cs.CY

TL;DR: 论文研究了公众对ChatGPT发布的反应，分析了经济和文化因素如何影响参与者的发声时间、态度和立场。


<details>
  <summary>Details</summary>
Motivation: 探索社会对AI技术变革的反应，揭示经济和文化背景如何塑造公众对AI的讨论。

Method: 分析了来自117个国家的3.8百万条推文，结合职业技能类型（写作、编程、数学）和霍夫斯泰德文化维度（个人主义、不确定性规避、权力距离）。

Result: 技术型职业（如编程、数学）更早参与且态度积极，写作型职业较晚且更怀疑；个人主义文化更早参与但态度负面，不确定性规避减少积极态度。

Conclusion: 职业背景和文化背景对公众对AI的反应有显著影响，强调了理解这些因素的重要性。

Abstract: Public product launches in Artificial Intelligence can serve as focusing
events for collective attention, surfacing how societies react to technological
change. Social media provide a window into the sensemaking around these events,
surfacing hopes and fears and showing who chooses to engage in the discourse
and when. We demonstrate that public sensemaking about AI is shaped by economic
interests and cultural values of those involved. We analyze 3.8 million tweets
posted by 1.6 million users across 117 countries in response to the public
launch of ChatGPT in 2022. Our analysis shows how economic self-interest,
proxied by occupational skill types in writing, programming, and mathematics,
and national cultural orientations, as measured by Hofstede's individualism,
uncertainty avoidance, and power distance dimensions, shape who speaks, when
they speak, and their stance towards ChatGPT. Roles requiring more technical
skills, such as programming and mathematics, tend to engage earlier and express
more positive stances, whereas writing-centric occupations join later with
greater skepticism. At the cultural level, individualism predicts both earlier
engagement and a more negative stance, and uncertainty avoidance reduces the
prevalence of positive stances but does not delay when users first engage with
ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study.
The shift toward a more critical stance towards ChatGPT over time stems
primarily from the entry of more skeptical voices rather than a change of heart
among early adopters. Our findings underscore the importance of both the
occupational background and cultural context in understanding public reactions
to AI.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [314] [Neural Actor-Critic Methods for Hamilton-Jacobi-Bellman PDEs: Asymptotic Analysis and Numerical Studies](https://arxiv.org/abs/2507.06428)
*Samuel N. Cohen,Jackson Hebner,Deqing Jiang,Justin Sirignano*

Main category: math.OC

TL;DR: 论文提出了一种基于演员-评论家架构的机器学习算法，用于求解高维HJB方程，并通过数学分析和数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决高维HJB方程在随机控制理论中的计算挑战，同时确保边界条件的完美满足和计算效率。

Method: 采用演员-评论家架构，评论家网络满足边界条件并使用偏置梯度，演员网络通过最小化哈密顿量积分来训练。

Result: 证明了训练动态在无限维ODE中收敛，且在凸性假设下，固定点为原问题的解。数值实验验证了算法在200维问题中的有效性。

Conclusion: 该算法为高维HJB方程提供了一种高效且理论保证的解决方案，但需注意非凸哈密顿量下的局限性。

Abstract: We mathematically analyze and numerically study an actor-critic machine
learning algorithm for solving high-dimensional Hamilton-Jacobi-Bellman (HJB)
partial differential equations from stochastic control theory. The architecture
of the critic (the estimator for the value function) is structured so that the
boundary condition is always perfectly satisfied (rather than being included in
the training loss) and utilizes a biased gradient which reduces computational
cost. The actor (the estimator for the optimal control) is trained by
minimizing the integral of the Hamiltonian over the domain, where the
Hamiltonian is estimated using the critic. We show that the training dynamics
of the actor and critic neural networks converge in a Sobolev-type space to a
certain infinite-dimensional ordinary differential equation (ODE) as the number
of hidden units in the actor and critic $\rightarrow \infty$. Further, under a
convexity-like assumption on the Hamiltonian, we prove that any fixed point of
this limit ODE is a solution of the original stochastic control problem. This
provides an important guarantee for the algorithm's performance in light of the
fact that finite-width neural networks may only converge to a local minimizers
(and not optimal solutions) due to the non-convexity of their loss functions.
In our numerical studies, we demonstrate that the algorithm can solve
stochastic control problems accurately in up to 200 dimensions. In particular,
we construct a series of increasingly complex stochastic control problems with
known analytic solutions and study the algorithm's numerical performance on
them. These problems range from a linear-quadratic regulator equation to highly
challenging equations with non-convex Hamiltonians, allowing us to identify and
analyze the strengths and limitations of this neural actor-critic method for
solving HJB equations.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [315] [Graph-based Fake Account Detection: A Survey](https://arxiv.org/abs/2507.06541)
*Ali Safarpoor Dehkordi,Ahad N. Zehmakan*

Main category: cs.SI

TL;DR: 本文综述了社交媒体中虚假账户检测的图基方法，分类讨论了现有技术、数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着虚假账户问题的日益严重，开发高效检测算法成为研究热点。

Method: 重点分析基于图拓扑特征的方法，结合账户内容和资料数据，对现有技术进行分类。

Result: 总结了不同方法的优缺点，并探讨了真实与合成数据集的应用。

Conclusion: 提出了未来研究的潜在方向。

Abstract: In recent years, there has been a growing effort to develop effective and
efficient algorithms for fake account detection in online social networks. This
survey comprehensively reviews existing methods, with a focus on graph-based
techniques that utilise topological features of social graphs (in addition to
account information, such as their shared contents and profile data) to
distinguish between fake and real accounts. We provide several categorisations
of these methods (for example, based on techniques used, input data, and
detection time), discuss their strengths and limitations, and explain how these
methods connect in the broader context. We also investigate the available
datasets, including both real-world data and synthesised models. We conclude
the paper by proposing several potential avenues for future research.

</details>


### [316] [Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic](https://arxiv.org/abs/2507.07036)
*Maloy Kumar Devnath,Sudip Chakraborty,Vandana P. Janeja*

Main category: cs.SI

TL;DR: 论文提出了一种名为Spatial-Link的图框架，用于量化海冰退缩与南极冰架融化之间的空间异质性联系。


<details>
  <summary>Details</summary>
Motivation: 传统模型将海冰和南极冰架视为独立系统，无法捕捉局部联系和级联反馈。本研究旨在填补这一空白。

Method: 使用Delaunay三角剖分构建空间图，节点表示显著变化的区域，边编码邻近性和方向一致性。通过广度优先搜索和蒙特卡洛模拟验证联系路径。

Result: 揭示了非局部、空间异质性的耦合模式，表明海冰退缩可能引发或放大下游冰架融化。

Conclusion: Spatial-Link为改进海平面上升预测和气候适应策略提供了可扩展的数据驱动工具。

Abstract: Spatial phenomena often exhibit heterogeneity across spatial extents and in
proximity, making them complex to model-especially in dynamic regions like ice
shelves and sea ice. In this study, we address this challenge by exploring the
linkages between sea ice retreat and Antarctic ice shelf (AIS) melt. Although
atmospheric forcing and basal melting have been widely studied, the direct
impact of sea ice retreat on AIS mass loss remains underexplored. Traditional
models treat sea ice and AIS as separate systems. It limits their ability to
capture localized linkages and cascading feedback. To overcome this, we propose
Spatial-Link, a novel graph-based framework that quantifies spatial
heterogeneity to capture linkages between sea ice retreat and AIS melt. Our
method constructs a spatial graph using Delaunay triangulation of
satellite-derived ice change matrices, where nodes represent regions of
significant change and edges encode proximity and directional consistency. We
extract and statistically validate linkage paths using breadth-first search and
Monte Carlo simulations. Results reveal non-local, spatially heterogeneous
coupling patterns, suggesting sea ice loss can initiate or amplify downstream
AIS melt. Our analysis shows how sea ice retreat evolves over an oceanic grid
and progresses toward ice shelves-establishing a direct linkage. To our
knowledge, this is the first proposed methodology linking sea ice retreat to
AIS melt. Spatial-Link offers a scalable, data-driven tool to improve sea-level
rise projections and inform climate adaptation strategies.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [317] [OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion](https://arxiv.org/abs/2507.06849)
*Yizhuo Wu,Ang Li,Chang Gao*

Main category: eess.SP

TL;DR: OpenDPDv2框架通过TRes-DeltaGRU算法和两种节能方法，在保持高性能的同时降低DPD的能耗。


<details>
  <summary>Details</summary>
Motivation: NN DPDs通常需要大量参数且能耗高，OpenDPDv2旨在减少能耗并保持线性化性能。

Method: 提出TRes-DeltaGRU算法，结合定点量化和动态时间稀疏性优化模型。

Result: FP32模型ACPR达-59.4 dBc，EVM为-42.1 dBc；优化后能耗降低4.5倍，性能仍保持较高水平。

Conclusion: OpenDPDv2在降低能耗的同时保持了高性能，代码和数据集已开源。

Abstract: Neural network (NN)-based Digital Predistortion (DPD) stands out in improving
signal quality in wideband radio frequency (RF) power amplifiers (PAs)
employing complex modulation. However, NN DPDs usually rely on a large number
of parameters for effective linearization and can significantly contribute to
the energy consumption of the digital back-end in RF systems. This paper
presents OpenDPDv2, a unified framework for PA modeling, DPD learning, and
model optimization to reduce power consumption while maintaining high
linearization performance. The optimization techniques feature a novel DPD
algorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The
top-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an
Adjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude
(EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal
sparsity of input signals and hidden neurons, the inference energy of our model
can be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM
with 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth
256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code,
datasets, and documentation are publicly accessible at:
https://github.com/lab-emi/OpenDPD.

</details>


### [318] [Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks](https://arxiv.org/abs/2507.06997)
*Deemah H. Tashman,Soumaya Cherkaoui,Walaa Hamouda*

Main category: eess.SP

TL;DR: 本文提出了一种基于联邦学习的多智能体强化学习（MARL）策略，用于增强超5G网络中多蜂窝网络的物理层安全性（PLS）。


<details>
  <summary>Details</summary>
Motivation: 在超5G网络中，存在窃听者试图拦截基站与合法用户之间的机密信息，因此需要一种高效的方法来提升安全性。

Method: 每个基站的深度强化学习（DRL）代理通过联邦学习共享网络参数（而非用户数据），并比较了DQN和RDPG两种方法。

Result: 结果显示，RDPG比DQN收敛更快，且优于分布式DRL方法，但也揭示了安全性与复杂性之间的权衡。

Conclusion: 提出的联邦学习MARL策略在提升物理层安全性方面具有潜力，但需进一步优化以平衡安全性与复杂性。

Abstract: This paper explores the application of a federated learning-based multi-agent
reinforcement learning (MARL) strategy to enhance physical-layer security (PLS)
in a multi-cellular network within the context of beyond 5G networks. At each
cell, a base station (BS) operates as a deep reinforcement learning (DRL) agent
that interacts with the surrounding environment to maximize the secrecy rate of
legitimate users in the presence of an eavesdropper. This eavesdropper attempts
to intercept the confidential information shared between the BS and its
authorized users. The DRL agents are deemed to be federated since they only
share their network parameters with a central server and not the private data
of their legitimate users. Two DRL approaches, deep Q-network (DQN) and
Reinforce deep policy gradient (RDPG), are explored and compared. The results
demonstrate that RDPG converges more rapidly than DQN. In addition, we
demonstrate that the proposed method outperforms the distributed DRL approach.
Furthermore, the outcomes illustrate the trade-off between security and
complexity.

</details>


### [319] [How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks](https://arxiv.org/abs/2507.07067)
*Clement Ruah,Houssem Sifaou,Osvaldo Simeone,Bashir M. Al-Hashimi*

Main category: eess.SP

TL;DR: 论文探讨了利用数字孪生解决电信领域AI模型训练数据不足的问题，并提出了两种缩小仿真与现实数据差距的策略。


<details>
  <summary>Details</summary>
Motivation: 电信领域AI模型训练面临部署特定数据稀缺的挑战，现有数据集难以捕捉网络环境的独特条件和变异性。

Method: 1) 通过真实测量校准数字孪生；2) 使用仿真与现实差距感知的训练策略，包括贝叶斯学习和预测驱动的推断方法。

Result: 论文评估了两种方法，分别从环境和训练损失层面建模仿真与现实差距。

Conclusion: 数字孪生和仿真与现实差距感知策略为电信AI模型训练提供了有效解决方案。

Abstract: Training effective artificial intelligence models for telecommunications is
challenging due to the scarcity of deployment-specific data. Real data
collection is expensive, and available datasets often fail to capture the
unique operational conditions and contextual variability of the network
environment. Digital twinning provides a potential solution to this problem, as
simulators tailored to the current network deployment can generate
site-specific data to augment the available training datasets. However, there
is a need to develop solutions to bridge the inherent simulation-to-reality
(sim-to-real) gap between synthetic and real-world data. This paper reviews
recent advances on two complementary strategies: 1) the calibration of digital
twins (DTs) through real-world measurements, and 2) the use of sim-to-real
gap-aware training strategies to robustly handle residual discrepancies between
digital twin-generated and real data. For the latter, we evaluate two
conceptually distinct methods that model the sim-to-real gap either at the
level of the environment via Bayesian learning or at the level of the training
loss via prediction-powered inference.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [320] [Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing](https://arxiv.org/abs/2507.06608)
*Xiaoxiang Shi,Colin Cai,Junjia Du,Zhanda Zhu,Xingda Wei,Zhihao Jia*

Main category: cs.DC

TL;DR: 论文提出了一种在单个GPU内动态分配资源以解耦预填充和解码阶段的方法，显著提高了吞吐量并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的预填充-解码（PD）解耦方法通常需要多个GPU，硬件需求高。Chunked Prefill虽能提高GPU利用率，但会引入阶段干扰。本文探索在单个GPU内实现解耦，以解决资源冲突问题。

Method: 通过分析GPU资源的边际效益，发现资源分配存在饱和点。基于此，动态分配单个GPU的资源给预填充和解码阶段，实现解耦。

Result: 实验表明，Nexus系统在多种模型和工作负载下，吞吐量最高提升2.2倍，TTFT降低20倍，TBT降低2.5倍，且仅用一半GPU数量即可超越vLLM-disaggregation。

Conclusion: 在单个GPU内动态分配资源可以有效解耦预填充和解码阶段，显著提升性能并减少硬件需求。

Abstract: Current prefill-decode (PD) disaggregation is typically deployed at the level
of entire serving engines, assigning separate GPUs to handle prefill and decode
phases. While effective at reducing latency, this approach demands more
hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode
requests within the same batch, but introduces phase interference between
prefill and decode.
  While existing PD disaggregation solutions separate the phases across GPUs,
we ask: can the same decoupling be achieved within a single serving engine? The
key challenge lies in managing the conflicting resource requirements of prefill
and decode when they share the same hardware. In this paper, we first show that
chunked prefill requests cause interference with decode requests due to their
distinct requirements for GPU resources. Second, we find that GPU resources
exhibit diminishing returns. Beyond a saturation point, increasing GPU
allocation yields negligible latency improvements. This insight enables us to
split a single GPU's resources and dynamically allocate them to prefill and
decode on the fly, effectively disaggregating the two phases within the same
GPU.
  Across a range of models and workloads, our system Nexus achieves up to 2.2x
higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also
outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x
lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using
only half the number of GPUs.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [321] [Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain](https://arxiv.org/abs/2507.06273)
*S P Shivakumar,Gunisetty Ramasekhar,P Nimmy,Sujesh Areekara,L Thanuja,T V Smitha,S Devanathan,Ganesh R Naik,K V Nagaraja*

Main category: physics.med-ph

TL;DR: 研究探讨了Casson-Maxwell纳米流体在狭窄动脉中的流动特性，分析了其对药物输送效率和热传递的影响，支持可持续发展目标。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病复杂性增加，传统治疗方法受限，需要开发新型靶向药物输送系统以支持可持续发展目标。

Method: 研究Casson-Maxwell纳米流体在狭窄动脉中的流动，分析皮肤摩擦和热传递率，并利用Levenberg-Marquardt反向传播训练预测热流率。

Result: Casson-Maxwell流体流速较低，药物输送效率更高；热传递率随铜和氧化铝纳米颗粒增加而提高，银纳米颗粒则相反；皮肤摩擦系数受Maxwell和Casson参数显著影响。

Conclusion: 研究为靶向药物输送和热传递优化提供了新见解，支持可持续发展目标中的医疗技术创新和跨学科合作。

Abstract: The increasing complexity of cardiovascular diseases and limitations in
traditional healing methods mandate the invention of new drug delivery systems
that assure targeted, effective, and regulated treatments, contributing
directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable
medical technologies in healthcare. This study investigates the flow of a
Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities,
such as skin friction and heat transfer rate, are analysed in detail. The
Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids,
which indicates the improved residence time for efficient drug delivery. The
heat transfer rate shows an increase with higher volume fractions of copper and
aluminium oxide nanoparticles and a decrease with higher volume fractions of
silver nanoparticles. The skin friction coefficient decreases by 219% with a
unit increase in the Maxwell parameter, whereas it increases by 66.1% with a
unit rise in the Casson parameter. This work supports SDGs 4 and 17 by
fostering interdisciplinary learning and collaboration in fluid dynamics and
healthcare innovation. Additionally, the rate of heat flow was forecasted (with
an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation
training scheme under the influence of magneto-radiative, linear heat source
and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume
fractions. It is also observed that the drag coefficient is most sensitive to
the changes in the Maxwell parameter.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [322] [3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds](https://arxiv.org/abs/2507.06484)
*Fan-Yun Sun,Shengguang Wu,Christian Jacobsen,Thomas Yim,Haoming Zou,Alex Zook,Shangru Li,Yu-Hsin Chou,Ethem Can,Xunlei Wu,Clemens Eppner,Valts Blukis,Jonathan Tremblay,Jiajun Wu,Stan Birchfield,Nick Haber*

Main category: cs.GR

TL;DR: 提出了一种可扩展的方法3D-Generalist，利用视觉语言模型（VLMs）生成高质量3D环境作为基础模型的训练数据，并通过自改进微调提升生成效果。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型在空间推理能力上仍存在不足，主要因缺乏基于3D世界的数据。人工创建3D环境成本高，需自动化解决方案。

Method: 将3D环境构建转化为序列决策问题，利用VLMs作为策略生成布局、材质、光照等，并通过自改进微调优化生成效果。

Result: 3D-Generalist能生成仿真就绪的3D环境，其生成数据预训练的视觉基础模型在下游任务中表现优于人工合成数据训练的模型，接近真实数据效果。

Conclusion: 3D-Generalist为3D环境生成提供了一种高效、可扩展的解决方案，显著提升了基础模型的训练数据质量。

Abstract: Despite large-scale pretraining endowing models with language and vision
reasoning capabilities, improving their spatial reasoning capability remains
challenging due to the lack of data grounded in the 3D world. While it is
possible for humans to manually create immersive and interactive worlds through
3D graphics, as seen in applications such as VR, gaming, and robotics, this
process remains highly labor-intensive. In this paper, we propose a scalable
method for generating high-quality 3D environments that can serve as training
data for foundation models. We recast 3D environment building as a sequential
decision-making problem, employing Vision-Language-Models (VLMs) as policies
that output actions to jointly craft a 3D environment's layout, materials,
lighting, and assets. Our proposed framework, 3D-Generalist, trains VLMs to
generate more prompt-aligned 3D environments via self-improvement fine-tuning.
We demonstrate the effectiveness of 3D-Generalist and the proposed training
strategy in generating simulation-ready 3D environments. Furthermore, we
demonstrate its quality and scalability in synthetic data generation by
pretraining a vision foundation model on the generated data. After fine-tuning
the pre-trained model on downstream tasks, we show that it surpasses models
pre-trained on meticulously human-crafted synthetic data and approaches results
achieved with real data orders of magnitude larger.

</details>


### [323] [Enhancing non-Rigid 3D Model Deformations Using Mesh-based Gaussian Splatting](https://arxiv.org/abs/2507.07000)
*Wijayathunga W. M. R. D. B*

Main category: cs.GR

TL;DR: 提出了一种新框架，通过将网格表示与3D高斯泼溅结合，增强非刚性3D模型变形能力。


<details>
  <summary>Details</summary>
Motivation: 传统高斯泼溅虽能快速实时渲染辐射场，但其后编辑能力及对大规模非刚性变形的支持有限。

Method: 将高斯核直接嵌入显式网格表面，利用网格的拓扑和几何先验指导编辑操作（如移动、缩放、旋转），并支持复杂变形（如弯曲和拉伸）。

Result: 实现了更灵活的3D内容创作流程，适用于虚拟现实、角色动画和交互设计。

Conclusion: 该框架为非刚性3D变形提供了更直观和强大的编辑工具。

Abstract: We propose a novel framework that enhances non-rigid 3D model deformations by
bridging mesh representations with 3D Gaussian splatting. While traditional
Gaussian splatting delivers fast, real-time radiance-field rendering, its
post-editing capabilities and support for large-scale, non-rigid deformations
remain limited. Our method addresses these challenges by embedding Gaussian
kernels directly onto explicit mesh surfaces. This allows the mesh's inherent
topological and geometric priors to guide intuitive editing operations -- such
as moving, scaling, and rotating individual 3D components -- and enables
complex deformations like bending and stretching. This work paves the way for
more flexible 3D content-creation workflows in applications spanning virtual
reality, character animation, and interactive design.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [324] [Trainability of Quantum Models Beyond Known Classical Simulability](https://arxiv.org/abs/2507.06344)
*Sabri Meyer,Francesco Scala,Francesco Tacchino,Aurelien Lucchi*

Main category: quant-ph

TL;DR: 本文探讨了变分量子算法（VQAs）的可训练性与计算复杂性之间的关系，提出了一种新方法（LCE）来避免梯度消失问题，并揭示了计算复杂性的相变现象。


<details>
  <summary>Details</summary>
Motivation: 变分量子算法在近期量子计算中具有潜力，但面临梯度消失（barren plateaus）的挑战，且可能因此导致量子优势受限。本文旨在解决这一矛盾。

Method: 引入了线性Clifford编码器（LCE）技术，确保梯度统计的常数缩放，并利用经典泰勒替代方法揭示计算复杂性的相变。

Result: 理论证明在无经典替代的区域可以避免梯度消失，数值实验验证了存在一个超多项式复杂性的过渡区。

Conclusion: 研究为实际应用中避免梯度消失的变分量子算法提供了可能路径，并展示了量子优势的潜力。

Abstract: Variational Quantum Algorithms (VQAs) are promising candidates for near-term
quantum computing, yet they face scalability challenges due to barren plateaus,
where gradients vanish exponentially in the system size. Recent conjectures
suggest that avoiding barren plateaus might inherently lead to classical
simulability, thus limiting the opportunities for quantum advantage. In this
work, we advance the theoretical understanding of the relationship between the
trainability and computational complexity of VQAs, thus directly addressing the
conjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique
that ensures constant-scaling gradient statistics on optimization landscape
regions that are close to Clifford circuits. Additionally, we leverage
classical Taylor surrogates to reveal computational complexity phase
transitions from polynomial to super-polynomial as the initialization region
size increases. Combining these results, we reveal a deeper link between
trainability and computational complexity, and analytically prove that barren
plateaus can be avoided in regions for which no classical surrogate is known to
exist. Furthermore, numerical experiments on LCE transformed landscapes confirm
in practice the existence of a super-polynomially complex ``transition zone''
where gradients decay polynomially. These findings indicate a plausible path to
practically relevant, barren plateau-free variational models with potential for
quantum advantage.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [325] [Stochastic Alignments: Matching an Observed Trace to Stochastic Process Models](https://arxiv.org/abs/2507.06472)
*Tian Li,Artem Polyvyanyy,Sander J. J. Leemans*

Main category: cs.FL

TL;DR: 论文提出了一种基于启发式路径查找的算法，用于将观察到的轨迹与随机过程模型匹配，优化编辑距离并提高路径的似然性。


<details>
  <summary>Details</summary>
Motivation: 传统基于对齐的符合性检查技术可能选择不太可能的路径，因此需要一种方法能够同时考虑路径的似然性和编辑距离。

Method: 将问题表述为优化问题，并开发了一种启发式引导的路径查找算法。

Result: 开源实现验证了方法的可行性，并为分析师提供了新的诊断见解。

Conclusion: 该方法能够有效匹配轨迹与模型，提供更准确的诊断信息。

Abstract: Process mining leverages event data extracted from IT systems to generate
insights into the business processes of organizations. Such insights benefit
from explicitly considering the frequency of behavior in business processes,
which is captured by stochastic process models. Given an observed trace and a
stochastic process model, conventional alignment-based conformance checking
techniques face a fundamental limitation: They prioritize matching the trace to
a model path with minimal deviations, which may, however, lead to selecting an
unlikely path. In this paper, we study the problem of matching an observed
trace to a stochastic process model by identifying a likely model path with a
low edit distance to the trace. We phrase this as an optimization problem and
develop a heuristic-guided path-finding algorithm to solve it. Our open-source
implementation demonstrates the feasibility of the approach and shows that it
can provide new, useful diagnostic insights for analysts.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [326] [Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G](https://arxiv.org/abs/2507.06911)
*Michele Polese,Niloofar Mohamadi,Salvatore D'Oro,Tommaso Melodia*

Main category: cs.NI

TL;DR: 本文提出了一种融合O-RAN和AI-RAN的新架构，支持在共享基础设施上统一编排和管理电信与AI工作负载，扩展了Open RAN的模块化和云原生特性。


<details>
  <summary>Details</summary>
Motivation: 随着数据密集型AI应用在网络边缘的普及，需要从单纯利用AI优化网络转向支持分布式AI工作负载，为运营商提供新的盈利机会。

Method: 提出了一种融合O-RAN和AI-RAN的架构，包括AI-RAN编排器和AI-RAN站点，支持异构AI部署和实时处理能力。

Result: 该架构实现了对异构工作负载的统一编排，支持实时或批处理，并保持开放的标准化接口和多厂商互操作性。

Conclusion: 该架构为网络运营商提供了在边缘网络中高效部署和管理AI工作负载的解决方案，同时充分利用现有基础设施。

Abstract: The proliferation of data-intensive Artificial Intelligence (AI) applications
at the network edge demands a fundamental shift in RAN design, from merely
consuming AI for network optimization, to actively enabling distributed AI
workloads. This paradigm shift presents a significant opportunity for network
operators to monetize AI at the edge while leveraging existing infrastructure
investments. To realize this vision, this article presents a novel converged
O-RAN and AI-RAN architecture that unifies orchestration and management of both
telecommunications and AI workloads on shared infrastructure. The proposed
architecture extends the Open RAN principles of modularity, disaggregation, and
cloud-nativeness to support heterogeneous AI deployments. We introduce two key
architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN
Service Management and Orchestration (SMO) to enable integrated resource and
allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide
distributed edge AI platforms with real-time processing capabilities. The
proposed system supports flexible deployment options, allowing AI workloads to
be orchestrated with specific timing requirements (real-time or batch
processing) and geographic targeting. The proposed architecture addresses the
orchestration requirements for managing heterogeneous workloads at different
time scales while maintaining open, standardized interfaces and multi-vendor
interoperability.

</details>
