<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 12]
- [cs.CL](#cs.CL) [Total: 64]
- [cs.CV](#cs.CV) [Total: 103]
- [cs.HC](#cs.HC) [Total: 12]
- [cs.LG](#cs.LG) [Total: 95]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.RO](#cs.RO) [Total: 33]
- [cs.SD](#cs.SD) [Total: 7]
- [eess.SP](#eess.SP) [Total: 5]
- [math.OC](#math.OC) [Total: 1]
- [eess.SY](#eess.SY) [Total: 2]
- [cs.LO](#cs.LO) [Total: 1]
- [eess.IV](#eess.IV) [Total: 7]
- [cs.NE](#cs.NE) [Total: 1]
- [stat.ML](#stat.ML) [Total: 7]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.GR](#cs.GR) [Total: 4]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.CE](#cs.CE) [Total: 3]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CR](#cs.CR) [Total: 6]
- [math.PR](#math.PR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 4]
- [physics.ed-ph](#physics.ed-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.SE](#cs.SE) [Total: 3]
- [q-bio.GN](#q-bio.GN) [Total: 1]
- [cs.CY](#cs.CY) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism](https://arxiv.org/abs/2506.09176)
*Haoyuan Cai,Zhenghao Peng,Bolei Zhou*

Main category: cs.AI

TL;DR: AIM是一种新型的机器人门控交互模仿学习算法，通过自适应干预机制减少人类监督的认知负担，显著降低专家监控成本，并提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 当前交互模仿学习方法对人类监督者的认知要求较高，需要一种更高效的方法来减少干预需求。

Method: AIM利用代理Q函数模拟人类干预规则，根据代理与专家行为的对齐程度动态调整干预请求。

Result: 实验显示，AIM在连续和离散控制任务中显著减少专家监控成本，比基准方法Thrifty-DAgger提高40%的效率。

Conclusion: AIM能有效识别安全关键状态，收集高质量专家演示，减少总体专家数据和环境交互需求。

Abstract: Interactive Imitation Learning (IIL) allows agents to acquire desired
behaviors through human interventions, but current methods impose high
cognitive demands on human supervisors. We propose the Adaptive Intervention
Mechanism (AIM), a novel robot-gated IIL algorithm that learns an adaptive
criterion for requesting human demonstrations. AIM utilizes a proxy Q-function
to mimic the human intervention rule and adjusts intervention requests based on
the alignment between agent and human actions. By assigning high Q-values when
the agent deviates from the expert and decreasing these values as the agent
becomes proficient, the proxy Q-function enables the agent to assess the
real-time alignment with the expert and request assistance when needed. Our
expert-in-the-loop experiments reveal that AIM significantly reduces expert
monitoring efforts in both continuous and discrete control tasks. Compared to
the uncertainty-based baseline Thrifty-DAgger, our method achieves a 40%
improvement in terms of human take-over cost and learning efficiency.
Furthermore, AIM effectively identifies safety-critical states for expert
assistance, thereby collecting higher-quality expert demonstrations and
reducing overall expert data and environment interactions needed. Code and demo
video are available at https://github.com/metadriverse/AIM.

</details>


### [2] [Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.09250)
*C. Opus,A. Lawsen*

Main category: cs.AI

TL;DR: 论文指出Shojaee等人（2025）关于大型推理模型（LRMs）在复杂规划任务中表现“准确性崩溃”的结论存在实验设计问题，而非模型本身推理能力不足。


<details>
  <summary>Details</summary>
Motivation: 揭示Shojaee等人研究中实验设计的局限性，证明其结论可能误导对模型能力的评估。

Method: 分析其实验设计的三个关键问题，包括输出限制、评估框架缺陷和基准任务的不合理性，并通过改进实验设计重新测试模型表现。

Result: 在修正实验设计后，模型在之前被报告为失败的Tower of Hanoi任务中表现出高准确性。

Conclusion: 强调在评估AI推理能力时，实验设计的严谨性至关重要。

Abstract: Shojaee et al. (2025) report that Large Reasoning Models (LRMs) exhibit
"accuracy collapse" on planning puzzles beyond certain complexity thresholds.
We demonstrate that their findings primarily reflect experimental design
limitations rather than fundamental reasoning failures. Our analysis reveals
three critical issues: (1) Tower of Hanoi experiments systematically exceed
model output token limits at reported failure points, with models explicitly
acknowledging these constraints in their outputs; (2) The authors' automated
evaluation framework fails to distinguish between reasoning failures and
practical constraints, leading to misclassification of model capabilities; (3)
Most concerningly, their River Crossing benchmarks include mathematically
impossible instances for N > 5 due to insufficient boat capacity, yet models
are scored as failures for not solving these unsolvable problems. When we
control for these experimental artifacts, by requesting generating functions
instead of exhaustive move lists, preliminary experiments across multiple
models indicate high accuracy on Tower of Hanoi instances previously reported
as complete failures. These findings highlight the importance of careful
experimental design when evaluating AI reasoning capabilities.

</details>


### [3] [Ming-Omni: A Unified Multimodal Model for Perception and Generation](https://arxiv.org/abs/2506.09344)
*Inclusion AI,Biao Gong,Cheng Zou,Chuanyang Zheng,Chunluan Zhou,Canxiang Yan,Chunxiang Jin,Chunjie Shen,Dandan Zheng,Fudong Wang,Furong Xu,GuangMing Yao,Jun Zhou,Jingdong Chen,Jianxin Sun,Jiajia Liu,Jianjiang Zhu,Jun Peng,Kaixiang Ji,Kaiyou Song,Kaimeng Ren,Libin Wang,Lixiang Ru,Lele Xie,Longhua Tan,Lyuxin Xue,Lan Wang,Mochen Bai,Ning Gao,Pei Chen,Qingpei Guo,Qinglong Zhang,Qiang Xu,Rui Liu,Ruijie Xiong,Sirui Gao,Tinghao Liu,Taisong Li,Weilong Chai,Xinyu Xiao,Xiaomei Wang,Xiaoxue Chen,Xiao Lu,Xiaoyu Li,Xingning Dong,Xuzheng Yu,Yi Yuan,Yuting Gao,Yunxiao Sun,Yipeng Chen,Yifei Wu,Yongjie Lyu,Ziping Ma,Zipeng Feng,Zhijiang Fang,Zhihao Qiu,Ziyuan Huang,Zhengyu He*

Main category: cs.AI

TL;DR: Ming-Omni是一个统一的多模态模型，支持图像、文本、音频和视频处理，并在语音和图像生成方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在通过单一模型高效处理多模态输入，避免任务特定微调或结构重设计。

Method: 采用专用编码器提取多模态标记，结合MoE架构和新提出的模态特定路由器。

Result: 实验证明Ming-Omni在统一感知和生成任务中表现优异，支持音频和图像生成。

Conclusion: Ming-Omni是首个开源模型，在多模态支持上与GPT-4o相当，代码和模型权重已公开。

Abstract: We propose Ming-Omni, a unified multimodal model capable of processing
images, text, audio, and video, while demonstrating strong proficiency in both
speech and image generation. Ming-Omni employs dedicated encoders to extract
tokens from different modalities, which are then processed by Ling, an MoE
architecture equipped with newly proposed modality-specific routers. This
design enables a single model to efficiently process and fuse multimodal inputs
within a unified framework, thereby facilitating diverse tasks without
requiring separate models, task-specific fine-tuning, or structural redesign.
Importantly, Ming-Omni extends beyond conventional multimodal models by
supporting audio and image generation. This is achieved through the integration
of an advanced audio decoder for natural-sounding speech and Ming-Lite-Uni for
high-quality image generation, which also allow the model to engage in
context-aware chatting, perform text-to-speech conversion, and conduct
versatile image editing. Our experimental results showcase Ming-Omni offers a
powerful solution for unified perception and generation across all modalities.
Notably, our proposed Ming-Omni is the first open-source model we are aware of
to match GPT-4o in modality support, and we release all code and model weights
to encourage further research and development in the community.

</details>


### [4] [Beyond Nash Equilibrium: Bounded Rationality of LLMs and humans in Strategic Decision-making](https://arxiv.org/abs/2506.09390)
*Kehan Zheng,Jinfeng Zhou,Hongning Wang*

Main category: cs.AI

TL;DR: 研究比较了大型语言模型（LLMs）和人类在战略游戏（如石头剪刀布和囚徒困境）中的行为，发现LLMs表现出类似人类的有限理性，但规则应用更僵化，对动态环境变化敏感性较弱。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在战略决策中是否表现出与人类相似的有限理性行为。

Method: 通过行为博弈论实验范式，比较LLMs和人类在石头剪刀布和囚徒困境中的行为。

Result: LLMs复制了人类启发式行为（如基于结果的策略切换），但规则应用更僵化，动态适应性较差。

Conclusion: 当前LLMs仅部分模拟人类有限理性，需改进训练方法以增强灵活性和情境感知。

Abstract: Large language models are increasingly used in strategic decision-making
settings, yet evidence shows that, like humans, they often deviate from full
rationality. In this study, we compare LLMs and humans using experimental
paradigms directly adapted from behavioral game-theory research. We focus on
two well-studied strategic games, Rock-Paper-Scissors and the Prisoner's
Dilemma, which are well known for revealing systematic departures from rational
play in human subjects. By placing LLMs in identical experimental conditions,
we evaluate whether their behaviors exhibit the bounded rationality
characteristic of humans. Our findings show that LLMs reproduce familiar human
heuristics, such as outcome-based strategy switching and increased cooperation
when future interaction is possible, but they apply these rules more rigidly
and demonstrate weaker sensitivity to the dynamic changes in the game
environment. Model-level analyses reveal distinctive architectural signatures
in strategic behavior, and even reasoning models sometimes struggle to find
effective strategies in adaptive situations. These results indicate that
current LLMs capture only a partial form of human-like bounded rationality and
highlight the need for training methods that encourage flexible opponent
modeling and stronger context awareness.

</details>


### [5] [A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy](https://arxiv.org/abs/2506.09420)
*Henry Peng Zou,Wei-Chieh Huang,Yaozu Wu,Chunyu Miao,Dongyuan Li,Aiwei Liu,Yue Zhou,Yankai Chen,Weizhi Zhang,Yangning Li,Liancheng Fang,Renhe Jiang,Philip S. Yu*

Main category: cs.AI

TL;DR: 论文质疑完全自主AI代理的发展方向，提出LLM-HAS（基于LLM的人机协作系统），强调人机协作的可靠性、透明性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前完全自主的AI系统在可靠性、透明性和理解人类需求方面存在问题，需要探索更有效的协作模式。

Method: 提出LLM-HAS框架，通过人类参与提供指导、解答问题并保持控制，结合医疗、金融和软件开发案例说明其优势。

Result: 人机协作系统在复杂任务中表现优于纯AI系统，更具信任度和适应性。

Conclusion: AI发展应注重人机协作而非完全自主，未来方向是增强人类能力而非取代人类。

Abstract: Recent improvements in large language models (LLMs) have led many researchers
to focus on building fully autonomous AI agents. This position paper questions
whether this approach is the right path forward, as these autonomous systems
still have problems with reliability, transparency, and understanding the
actual requirements of human. We suggest a different approach: LLM-based
Human-Agent Systems (LLM-HAS), where AI works with humans rather than replacing
them. By keeping human involved to provide guidance, answer questions, and
maintain control, these systems can be more trustworthy and adaptable. Looking
at examples from healthcare, finance, and software development, we show how
human-AI teamwork can handle complex tasks better than AI working alone. We
also discuss the challenges of building these collaborative systems and offer
practical solutions. This paper argues that progress in AI should not be
measured by how independent systems become, but by how well they can work with
humans. The most promising future for AI is not in systems that take over human
roles, but in those that enhance human capabilities through meaningful
partnership.

</details>


### [6] [Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse Planning](https://arxiv.org/abs/2506.09498)
*Jaesik Yoon,Hyeonseo Cho,Yoshua Bengio,Sungjin Ahn*

Main category: cs.AI

TL;DR: Fast-MCTD是一种高效的扩散模型变体，通过并行化和稀疏化技术显著提升了MCTD的速度和可扩展性，同时保持了其性能优势。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在轨迹规划中表现出色，但其非序列性限制了其在长时推理任务中的效率。MCTD结合了扩散和树搜索，但计算开销较大。

Method: Fast-MCTD整合了Parallel MCTD（通过延迟树更新和冗余感知选择实现并行）和Sparse MCTD（通过轨迹粗化减少展开长度）。

Result: 实验显示Fast-MCTD比标准MCTD快100倍，且性能相当或更好，甚至在某些任务中超越Diffuser的推理速度。

Conclusion: Fast-MCTD为基于扩散的推理时间规划提供了实用且可扩展的解决方案。

Abstract: Diffusion models have recently emerged as a powerful approach for trajectory
planning. However, their inherently non-sequential nature limits their
effectiveness in long-horizon reasoning tasks at test time. The recently
proposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by
combining diffusion with tree-based search, achieving state-of-the-art
performance on complex planning problems. Despite its strengths, our analysis
shows that MCTD incurs substantial computational overhead due to the sequential
nature of tree search and the cost of iterative denoising. To address this, we
propose Fast-MCTD, a more efficient variant that preserves the strengths of
MCTD while significantly improving its speed and scalability. Fast-MCTD
integrates two techniques: Parallel MCTD, which enables parallel rollouts via
delayed tree updates and redundancy-aware selection; and Sparse MCTD, which
reduces rollout length through trajectory coarsening. Experiments show that
Fast-MCTD achieves up to 100x speedup over standard MCTD while maintaining or
improving planning performance. Remarkably, it even outperforms Diffuser in
inference speed on some tasks, despite Diffuser requiring no search and
yielding weaker solutions. These results position Fast-MCTD as a practical and
scalable solution for diffusion-based inference-time reasoning.

</details>


### [7] [DipLLM: Fine-Tuning LLM for Strategic Decision-making in Diplomacy](https://arxiv.org/abs/2506.09655)
*Kaixuan Xu,Jiajun Chai,Sicheng Li,Yuqian Fu,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.AI

TL;DR: DipLLM是一种基于LLM的智能体，通过自回归分解框架简化复杂任务，仅需少量数据即可超越现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量计算资源生成游戏数据，而LLMs凭借预训练知识提供了一种高效替代方案。

Method: DipLLM采用自回归分解框架，将多单位动作分配任务简化为单位级决策序列，并定义均衡策略为学习目标。

Result: DipLLM仅需1.5%的数据即可超越Cicero模型的性能。

Conclusion: DipLLM展示了LLMs在复杂多人游戏战略决策中的潜力。

Abstract: Diplomacy is a complex multiplayer game that requires both cooperation and
competition, posing significant challenges for AI systems. Traditional methods
rely on equilibrium search to generate extensive game data for training, which
demands substantial computational resources. Large Language Models (LLMs) offer
a promising alternative, leveraging pre-trained knowledge to achieve strong
performance with relatively small-scale fine-tuning. However, applying LLMs to
Diplomacy remains challenging due to the exponential growth of possible action
combinations and the intricate strategic interactions among players. To address
this challenge, we propose DipLLM, a fine-tuned LLM-based agent that learns
equilibrium policies for Diplomacy. DipLLM employs an autoregressive
factorization framework to simplify the complex task of multi-unit action
assignment into a sequence of unit-level decisions. By defining an equilibrium
policy within this framework as the learning objective, we fine-tune the model
using only 1.5% of the data required by the state-of-the-art Cicero model,
surpassing its performance. Our results demonstrate the potential of fine-tuned
LLMs for tackling complex strategic decision-making in multiplayer games.

</details>


### [8] [Application-Driven Value Alignment in Agentic AI Systems: Survey and Perspectives](https://arxiv.org/abs/2506.09656)
*Wei Zeng,Hengshu Zhu,Chuan Qin,Han Wu,Yihang Cheng,Sirui Zhang,Xiaowei Jin,Yinuo Shen,Zhenxing Wang,Feimin Zhong,Hui Xiong*

Main category: cs.AI

TL;DR: 本文综述了AI代理系统中的价值对齐问题，探讨了价值原则、应用场景和评估方法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI进入Agentic AI阶段，多代理决策和任务协作的复杂性增加，价值对齐问题日益重要，需确保AI代理与人类价值观一致。

Method: 通过分层组织价值原则（宏观、中观、微观），分类应用场景，并系统评估数据集和对齐方法。

Result: 总结了价值对齐的现状，包括多代理间的价值协调，并提出了未来研究方向。

Conclusion: 价值对齐是AI代理系统的关键问题，未来需进一步研究多代理协调和实际应用中的挑战。

Abstract: The ongoing evolution of AI paradigms has propelled AI research into the
Agentic AI stage. Consequently, the focus of research has shifted from single
agents and simple applications towards multi-agent autonomous decision-making
and task collaboration in complex environments. As Large Language Models (LLMs)
advance, their applications become more diverse and complex, leading to
increasingly situational and systemic risks. This has brought significant
attention to value alignment for AI agents, which aims to ensure that an
agent's goals, preferences, and behaviors align with human values and societal
norms. This paper reviews value alignment in agent systems within specific
application scenarios. It integrates the advancements in AI driven by large
models with the demands of social governance. Our review covers value
principles, agent system application scenarios, and agent value alignment
evaluation. Specifically, value principles are organized hierarchically from a
top-down perspective, encompassing macro, meso, and micro levels. Agent system
application scenarios are categorized and reviewed from a general-to-specific
viewpoint. Agent value alignment evaluation systematically examines datasets
for value alignment assessment and relevant value alignment methods.
Additionally, we delve into value coordination among multiple agents within
agent systems. Finally, we propose several potential research directions in
this field.

</details>


### [9] [Intent Factored Generation: Unleashing the Diversity in Your Language Model](https://arxiv.org/abs/2506.09659)
*Eltayeb Ahmed,Uljad Berdica,Martha Elliott,Danijela Horak,Jakob N. Foerster*

Main category: cs.AI

TL;DR: 提出了一种名为Intent Factored Generation (IFG)的方法，通过分两阶段采样（意图采样和最终生成）来提高大型语言模型生成样本的多样性，同时保持质量。


<details>
  <summary>Details</summary>
Motivation: 当前方法在提高多样性时往往仅停留在词汇层面，导致推理问题探索不足和对话代理重复无趣。

Method: IFG将采样过程分为意图采样和最终生成两阶段，分别使用高低温度控制多样性和一致性。

Result: 在数学、代码任务和对话任务中，IFG提高了多样性和性能，同时保持了生成质量。

Conclusion: IFG是一种简单有效的方法，通过调整提示和温度，可广泛应用于多种任务。

Abstract: Obtaining multiple meaningfully diverse, high quality samples from Large
Language Models for a fixed prompt remains an open challenge. Current methods
for increasing diversity often only operate at the token-level, paraphrasing
the same response. This is problematic because it leads to poor exploration on
reasoning problems and to unengaging, repetitive conversational agents. To
address this we propose Intent Factored Generation (IFG), factorising the
sampling process into two stages. First, we sample a semantically dense intent,
e.g., a summary or keywords. Second, we sample the final response conditioning
on both the original prompt and the intent from the first stage. This allows us
to use a higher temperature during the intent step to promote conceptual
diversity, and a lower temperature during the final generation to ensure the
outputs are coherent and self-consistent. Additionally, we find that prompting
the model to explicitly state its intent for each step of the chain-of-thought
before generating the step is beneficial for reasoning tasks. We demonstrate
our method's effectiveness across a diverse set of tasks. We show this method
improves both pass@k and Reinforcement Learning from Verifier Feedback on maths
and code tasks. For instruction-tuning, we combine IFG with Direct Preference
Optimisation to increase conversational diversity without sacrificing reward.
Finally, we achieve higher diversity while maintaining the quality of
generations on a general language modelling task, using a new dataset of reader
comments and news articles that we collect and open-source. In summary, we
present a simple method of increasing the sample diversity of LLMs while
maintaining performance. This method can be implemented by changing the prompt
and varying the temperature during generation, making it easy to integrate into
many algorithms for gains across various applications.

</details>


### [10] [How Do People Revise Inconsistent Beliefs? Examining Belief Revision in Humans with User Studies](https://arxiv.org/abs/2506.09977)
*Stylianos Loukas Vasileiou,Antonio Rago,Maria Vanina Martinez,William Yeoh*

Main category: cs.AI

TL;DR: 研究发现人类倾向于基于解释的信念修正，而非经典理论中的最小修正，这对AI系统设计有重要启示。


<details>
  <summary>Details</summary>
Motivation: 理解人类如何根据新信息修正信念，以开发更符合人类推理的AI系统。

Method: 通过三项用户研究，系统考察人类在解释引导下的信念修正行为。

Result: 人类普遍偏好基于解释的信念修正，且这种修正不一定是经典理论中的最小修正。

Conclusion: AI系统应纳入基于解释的信念修正机制，以更好地模拟人类认知过程。

Abstract: Understanding how humans revise their beliefs in light of new information is
crucial for developing AI systems which can effectively model, and thus align
with, human reasoning. While theoretical belief revision frameworks rely on a
set of principles that establish how these operations are performed, empirical
evidence from cognitive psychology suggests that people may follow different
patterns when presented with conflicting information. In this paper, we present
three comprehensive user studies showing that people consistently prefer
explanation-based revisions, i.e., those which are guided by explanations, that
result in changes to their belief systems that are not necessarily captured by
classical belief change theory. Our experiments systematically investigate how
people revise their beliefs with explanations for inconsistencies, whether they
are provided with them or left to formulate them themselves, demonstrating a
robust preference for what may seem non-minimal revisions across different
types of scenarios. These findings have implications for AI systems designed to
model human reasoning or interact with humans, suggesting that such systems
should accommodate explanation-based, potentially non-minimal belief revision
operators to better align with human cognitive processes.

</details>


### [11] [V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning](https://arxiv.org/abs/2506.09985)
*Mido Assran,Adrien Bardes,David Fan,Quentin Garrido,Russell Howes,Mojtaba,Komeili,Matthew Muckley,Ammar Rizvi,Claire Roberts,Koustuv Sinha,Artem Zholus,Sergio Arnaud,Abha Gejji,Ada Martin,Francois Robert Hogan,Daniel Dugas,Piotr Bojanowski,Vasil Khalidov,Patrick Labatut,Francisco Massa,Marc Szafraniec,Kapil Krishnakumar,Yong Li,Xiaodong Ma,Sarath Chandar,Franziska Meier,Yann LeCun,Michael Rabbat,Nicolas Ballas*

Main category: cs.AI

TL;DR: 论文提出了一种结合互联网规模视频数据与少量交互数据的自监督学习方法，开发了能够理解、预测和规划物理世界的模型。


<details>
  <summary>Details</summary>
Motivation: 解决现代AI通过观察学习理解和行动的主要挑战。

Method: 预训练无动作的联合嵌入预测架构V-JEPA 2，并结合大型语言模型和机器人视频数据。

Result: 在多项任务中达到最先进性能，并成功应用于机器人规划任务。

Conclusion: 自监督学习结合少量交互数据可生成能规划物理世界的世界模型。

Abstract: A major challenge for modern AI is to learn to understand the world and learn
to act largely by observation. This paper explores a self-supervised approach
that combines internet-scale video data with a small amount of interaction data
(robot trajectories), to develop models capable of understanding, predicting,
and planning in the physical world. We first pre-train an action-free
joint-embedding-predictive architecture, V-JEPA 2, on a video and image dataset
comprising over 1 million hours of internet video. V-JEPA 2 achieves strong
performance on motion understanding (77.3 top-1 accuracy on Something-Something
v2) and state-of-the-art performance on human action anticipation (39.7
recall-at-5 on Epic-Kitchens-100) surpassing previous task-specific models.
Additionally, after aligning V-JEPA 2 with a large language model, we
demonstrate state-of-the-art performance on multiple video question-answering
tasks at the 8 billion parameter scale (e.g., 84.0 on PerceptionTest, 76.9 on
TempCompass). Finally, we show how self-supervised learning can be applied to
robotic planning tasks by post-training a latent action-conditioned world
model, V-JEPA 2-AC, using less than 62 hours of unlabeled robot videos from the
Droid dataset. We deploy V-JEPA 2-AC zero-shot on Franka arms in two different
labs and enable picking and placing of objects using planning with image goals.
Notably, this is achieved without collecting any data from the robots in these
environments, and without any task-specific training or reward. This work
demonstrates how self-supervised learning from web-scale data and a small
amount of robot interaction data can yield a world model capable of planning in
the physical world.

</details>


### [12] [Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering](https://arxiv.org/abs/2506.06905)
*Akash Gupta,Amos Storkey,Mirella Lapata*

Main category: cs.AI

TL;DR: 论文提出了一种元学习方法，通过蒸馏任务相关图像特征生成软提示，解决了小规模LMM在上下文学习中性能不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMM）在上下文学习（ICL）中表现不稳定，尤其是小规模模型，性能不随示例增加而单调提升，可能是由于图像嵌入中的冗余信息干扰。

Method: 提出了一种元学习方法，通过注意力映射模块和软提示蒸馏任务相关特征，支持在低数据条件下快速适应任务。

Result: 在VL-ICL Bench上的评估表明，该方法在视觉问答任务中优于ICL和其他提示调优方法，即使在图像扰动下也表现稳定。

Conclusion: 该方法为LMM在少样本任务中的性能提升提供了有效解决方案，尤其在低数据条件下表现优异。

Abstract: Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to
perform new tasks with minimal supervision. However, ICL performance,
especially in smaller LMMs, is inconsistent and does not always improve
monotonically with increasing examples. We hypothesize that this occurs due to
the LMM being overwhelmed by additional information present in the image
embeddings, which is not required for the downstream task. To address this, we
propose a meta-learning approach that provides an alternative for inducing
few-shot capabilities in LMMs, using a fixed set of soft prompts that are
distilled from task-relevant image features and can be adapted at test time
using a few examples. To facilitate this distillation, we introduce an
attention-mapper module that can be easily integrated with the popular LLaVA
v1.5 architecture and is jointly learned with soft prompts, enabling task
adaptation in LMMs under low-data regimes with just a few gradient steps.
Evaluation on the VL-ICL Bench shows that our method consistently outperforms
ICL and related prompt-tuning approaches, even under image perturbations,
improving task induction and reasoning across visual question answering tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [LLM-as-a-qualitative-judge: automating error analysis in natural language generation](https://arxiv.org/abs/2506.09147)
*Nadezhda Chirkova,Tunde Oluwaseyi Ajayi,Seth Aycock,Zain Muhammad Mujahid,Vladana Perlić,Ekaterina Borisova,Markarit Vartampetian*

Main category: cs.CL

TL;DR: 提出了一种基于LLM的定性评估方法（LLM-as-a-qualitative-judge），通过结构化报告分析NLG系统的常见问题，为开发者提供改进建议。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为评估工具主要用于定量分析（如数值评分），但缺乏对问题的定性洞察，无法直接指导系统改进。

Method: 方法包括两步：1）对每个实例进行开放式问题分析；2）使用累积算法对发现的问题进行聚类。

Result: 实验结果表明，该方法能正确识别2/3的实例问题，并能生成与人工标注相似的问题类型报告。

Conclusion: LLM-as-a-qualitative-judge为NLG系统提供了有效的定性评估工具，帮助开发者理解并改进系统。

Abstract: Prompting large language models (LLMs) to evaluate generated text, known as
LLM-as-a-judge, has become a standard evaluation approach in natural language
generation (NLG), but is primarily used as a quantitative tool, i.e. with
numerical scores as main outputs. In this work, we propose
LLM-as-a-qualitative-judge, an LLM-based evaluation approach with the main
output being a structured report of common issue types in the NLG system
outputs. Our approach is targeted at providing developers with meaningful
insights on what improvements can be done to a given NLG system and consists of
two main steps, namely open-ended per-instance issue analysis and clustering of
the discovered issues using an intuitive cumulative algorithm. We also
introduce a strategy for evaluating the proposed approach, coupled with ~300
annotations of issues in instances from 12 NLG datasets. Our results show that
LLM-as-a-qualitative-judge correctly recognizes instance-specific issues in 2/3
cases and is capable of producing error type reports resembling the reports
composed by human annotators. Our code and data are publicly available at
https://github.com/tunde-ajayi/llm-as-a-qualitative-judge.

</details>


### [14] [PHRASED: Phrase Dictionary Biasing for Speech Translation](https://arxiv.org/abs/2506.09175)
*Peidong Wang,Jian Xue,Rui Zhao,Junkun Chen,Aswin Shanmugam Subramanian,Jinyu Li*

Main category: cs.CL

TL;DR: 提出了一种基于短语词典偏置的方法，用于提升语音翻译任务中短语翻译的准确性，并在流式语音翻译模型和多模态大语言模型中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于短语在训练数据中罕见，导致语音翻译任务中短语翻译困难，因此需要一种方法来提升短语翻译的准确性。

Method: 提出了一种短语词典偏置方法，利用源语言到目标语言的短语映射对，并将其应用于流式语音翻译模型和多模态大语言模型。

Result: 短语词典偏置方法在流式语音翻译模型中相对短语列表偏置方法提升了21%的性能，并在多模态大语言模型中实现了85%的相对短语召回率提升。

Conclusion: 短语词典偏置方法显著提升了语音翻译任务中短语翻译的准确性，尤其是在流式和多模态模型中表现突出。

Abstract: Phrases are essential to understand the core concepts in conversations.
However, due to their rare occurrence in training data, correct translation of
phrases is challenging in speech translation tasks. In this paper, we propose a
phrase dictionary biasing method to leverage pairs of phrases mapping from the
source language to the target language. We apply the phrase dictionary biasing
method to two types of widely adopted models, a transducer-based streaming
speech translation model and a multimodal large language model. Experimental
results show that the phrase dictionary biasing method outperforms phrase list
biasing by 21% relatively for the streaming speech translation model. In
addition, phrase dictionary biasing enables multimodal large language models to
use external phrase information, achieving 85% relative improvement in phrase
recall.

</details>


### [15] [A Technique for Isolating Lexically-Independent Phonetic Dependencies in Generative CNNs](https://arxiv.org/abs/2506.09218)
*Bruno Ferenc Šegedin*

Main category: cs.CL

TL;DR: 研究探讨了生成卷积神经网络（CNN）在语音波形数据上的词汇无关泛化能力，并提出了一种新方法，通过绕过全连接层（FC）输入随机特征图来检测模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索深度神经网络（DNNs）能否在词汇学习之外实现语音规则的泛化，以及全连接层瓶颈对泛化能力的影响。

Method: 训练生成CNN模型，缩小全连接层瓶颈，并通过输入随机特征图生成音频输出以测试泛化能力。

Result: 卷积层能够动态泛化语音依赖关系，而不仅限于全连接层学习的词汇约束配置。

Conclusion: 卷积层具有超越词汇约束的泛化能力，全连接层瓶颈的缩小为研究模型泛化提供了新途径。

Abstract: The ability of deep neural networks (DNNs) to represent phonotactic
generalizations derived from lexical learning remains an open question. This
study (1) investigates the lexically-invariant generalization capacity of
generative convolutional neural networks (CNNs) trained on raw audio waveforms
of lexical items and (2) explores the consequences of shrinking the
fully-connected layer (FC) bottleneck from 1024 channels to 8 before training.
Ultimately, a novel technique for probing a model's lexically-independent
generalizations is proposed that works only under the narrow FC bottleneck:
generating audio outputs by bypassing the FC and inputting randomized feature
maps into the convolutional block. These outputs are equally biased by a
phonotactic restriction in training as are outputs generated with the FC. This
result shows that the convolutional layers can dynamically generalize phonetic
dependencies beyond lexically-constrained configurations learned by the FC.

</details>


### [16] [Extrapolation by Association: Length Generalization Transfer in Transformers](https://arxiv.org/abs/2506.09251)
*Ziyang Cai,Nayoung Lee,Avi Schwarzschild,Samet Oymak,Dimitris Papailiopoulos*

Main category: cs.CL

TL;DR: 研究发现，Transformer模型可以通过相关任务的训练实现长度泛化能力的迁移，并在预训练语言模型中观察到类似效果。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer模型如何从短输入泛化到长输入，以及这种泛化能力是否可以通过任务关联进行迁移。

Method: 通过训练模型在较长且相关的辅助任务上，观察其是否能泛化到目标任务的更长输入。实验涵盖算术、字符串变换和迷宫导航等算法任务。

Result: 模型能够通过联合训练从相关任务中继承泛化能力，且预训练语言模型也表现出类似的迁移效果。注意力头的重用与泛化能力迁移相关。

Conclusion: 研究揭示了Transformer模型如何通过任务间的组合性重用实现泛化，加深了对模型处理分布外输入的理解。

Abstract: Transformer language models have demonstrated impressive generalization
capabilities in natural language domains, yet we lack a fine-grained
understanding of how such generalization arises. In this paper, we investigate
length generalization--the ability to extrapolate from shorter to longer
inputs--through the lens of \textit{task association}. We find that length
generalization can be \textit{transferred} across related tasks. That is,
training a model with a longer and related auxiliary task can lead it to
generalize to unseen and longer inputs from some other target task. We
demonstrate this length generalization transfer across diverse algorithmic
tasks, including arithmetic operations, string transformations, and maze
navigation. Our results show that transformer models can inherit generalization
capabilities from similar tasks when trained jointly. Moreover, we observe
similar transfer effects in pretrained language models, suggesting that
pretraining equips models with reusable computational scaffolding that
facilitates extrapolation in downstream settings. Finally, we provide initial
mechanistic evidence that length generalization transfer correlates with the
re-use of the same attention heads between the tasks. Together, our findings
deepen our understanding of how transformers generalize to out-of-distribution
inputs and highlight the compositional reuse of inductive structure across
tasks.

</details>


### [17] [Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation](https://arxiv.org/abs/2506.09331)
*Arjun Vaithilingam Sudhakar*

Main category: cs.CL

TL;DR: 研究探讨大型语言模型（LLMs）是否具备心智理论能力，通过多智能体强化学习（MARL）框架评估其协作与意图推理能力。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs是否能推断他人意图，对促进人机协作及多智能体系统的有效互动至关重要。

Method: 利用基于LLM的智能体在MARL环境中进行自然语言交互，评估其协作与意图推理能力。

Result: 研究旨在提升智能体与人类及AI伙伴的协作能力，推动混合人机系统的发展。

Conclusion: LLMs在意图推理方面展现出潜力，为人机协作的未来提供了重要启示。

Abstract: Modern Large Language Models (LLMs) exhibit impressive zero-shot and few-shot
generalization capabilities across complex natural language tasks, enabling
their widespread use as virtual assistants for diverse applications such as
translation and summarization. Despite being trained solely on large corpora of
text without explicit supervision on author intent, LLMs appear to infer the
underlying meaning of textual interactions. This raises a fundamental question:
can LLMs model and reason about the intentions of others, i.e., do they possess
a form of theory of mind? Understanding other's intentions is crucial for
effective collaboration, which underpins human societal success and is
essential for cooperative interactions among multiple agents, including humans
and autonomous systems. In this work, we investigate the theory of mind in LLMs
through the lens of cooperative multi-agent reinforcement learning (MARL),
where agents learn to collaborate via repeated interactions, mirroring human
social reasoning. Our approach aims to enhance artificial agent's ability to
adapt and cooperate with both artificial and human partners. By leveraging
LLM-based agents capable of natural language interaction, we move towards
creating hybrid human-AI systems that can foster seamless collaboration, with
broad implications for the future of human-artificial interaction.

</details>


### [18] [Self-Anchored Attention Model for Sample-Efficient Classification of Prosocial Text Chat](https://arxiv.org/abs/2506.09259)
*Zhuofang Li,Rafal Kocielnik,Fereshteh Soltani,Penphob,Boonyarungsrit,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 论文提出了一种新方法（SAAM）来检测游戏聊天中的亲社会行为，比现有技术提升了7.9%，并在低资源环境下有效。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注毒性内容检测，而亲社会行为的研究资源有限，但其对促进积极互动同样重要。

Method: 结合无监督发现和游戏领域专家协作，提出自锚定注意力模型（SAAM），利用整个训练集作为锚点提升性能。

Result: SAAM在《使命召唤：现代战争II》游戏中成功分类亲社会行为，比现有技术提升7.9%。

Conclusion: 该研究首次实现游戏聊天中亲社会行为的自动分类，为从惩罚毒性转向鼓励积极互动提供了新思路。

Abstract: Millions of players engage daily in competitive online games, communicating
through in-game chat. Prior research has focused on detecting relatively small
volumes of toxic content using various Natural Language Processing (NLP)
techniques for the purpose of moderation. However, recent studies emphasize the
importance of detecting prosocial communication, which can be as crucial as
identifying toxic interactions. Recognizing prosocial behavior allows for its
analysis, rewarding, and promotion. Unlike toxicity, there are limited
datasets, models, and resources for identifying prosocial behaviors in
game-chat text. In this work, we employed unsupervised discovery combined with
game domain expert collaboration to identify and categorize prosocial player
behaviors from game chat. We further propose a novel Self-Anchored Attention
Model (SAAM) which gives 7.9% improvement compared to the best existing
technique. The approach utilizes the entire training set as "anchors" to help
improve model performance under the scarcity of training data. This approach
led to the development of the first automated system for classifying prosocial
behaviors in in-game chats, particularly given the low-resource settings where
large-scale labeled data is not available. Our methodology was applied to one
of the most popular online gaming titles - Call of Duty(R): Modern
Warfare(R)II, showcasing its effectiveness. This research is novel in applying
NLP techniques to discover and classify prosocial behaviors in player in-game
chat communication. It can help shift the focus of moderation from solely
penalizing toxicity to actively encouraging positive interactions on online
platforms.

</details>


### [19] [Did I Faithfully Say What I Thought? Bridging the Gap Between Neural Activity and Self-Explanations in Large Language Models](https://arxiv.org/abs/2506.09277)
*Milan Bhan,Jean-Noel Vittaut,Nicolas Chesneau,Sarath Chandar,Marie-Jeanne Lesot*

Main category: cs.CL

TL;DR: 该论文提出了一种新框架，通过比较LLM生成的自我自然语言解释（self-NLE）与模型内部隐藏状态的解释，定量测量其忠实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖行为测试或计算块识别，未能深入模型内部神经活动，导致无法准确评估self-NLE的忠实性。

Method: 引入一种灵活框架，直接对比self-NLE与模型内部隐藏状态的解释，定量测量忠实性。

Result: 该框架提供了对self-NLE忠实性的深入理解，并为生成更忠实的self-NLE奠定了基础。

Conclusion: 通过直接连接self-NLE与模型推理，该方法推进了对self-NLE忠实性的理解，并提供了实用工具。

Abstract: Large Language Models (LLM) have demonstrated the capability of generating
free text self Natural Language Explanation (self-NLE) to justify their
answers. Despite their logical appearance, self-NLE do not necessarily reflect
the LLM actual decision-making process, making such explanations unfaithful.
While existing methods for measuring self-NLE faithfulness mostly rely on
behavioral tests or computational block identification, none of them examines
the neural activity underlying the model's reasoning. This work introduces a
novel flexible framework for quantitatively measuring the faithfulness of
LLM-generated self-NLE by directly comparing the latter with interpretations of
the model's internal hidden states. The proposed framework is versatile and
provides deep insights into self-NLE faithfulness by establishing a direct
connection between self-NLE and model reasoning. This approach advances the
understanding of self-NLE faithfulness and provides building blocks for
generating more faithful self-NLE.

</details>


### [20] [ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning](https://arxiv.org/abs/2506.09513)
*Yu Sun,Xingyu Qian,Weiwen Xu,Hao Zhang,Chenghao Xiao,Long Li,Yu Rong,Wenbing Huang,Qifeng Bai,Tingyang Xu*

Main category: cs.CL

TL;DR: ReasonMed是一个大规模的医学推理数据集，通过多代理验证和精炼过程构建，用于提升LLMs在医学问答中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索推理型LLMs在知识密集型医学问答中的潜力，填补现有研究的空白。

Method: 构建ReasonMed数据集，采用多代理验证和精炼过程，设计Error Refiner优化推理路径。

Result: ReasonMed-7B在医学问答任务中表现优异，超越现有模型，包括LLaMA3.1-70B。

Conclusion: ReasonMed为医学推理提供了有效的数据集和训练策略，显著提升了模型的性能。

Abstract: Though reasoning-based large language models (LLMs) have excelled in
mathematics and programming, their capabilities in knowledge-intensive medical
question answering remain underexplored. To address this, we introduce
ReasonMed, the largest medical reasoning dataset, comprising 370k high-quality
examples distilled from 1.7 million initial reasoning paths generated by
various LLMs. ReasonMed is constructed through a \textit{multi-agent
verification and refinement process}, where we design an \textit{Error Refiner}
to enhance the reasoning paths by identifying and correcting error-prone steps
flagged by a verifier. Leveraging ReasonMed, we systematically investigate best
practices for training medical reasoning models and find that combining
detailed Chain-of-Thought (CoT) reasoning with concise answer summaries yields
the most effective fine-tuning strategy. Based on this strategy, we train
ReasonMed-7B, which sets a new benchmark for sub-10B models, outperforming the
prior best by 4.17\% and even exceeding LLaMA3.1-70B on PubMedQA by 4.60\%.

</details>


### [21] [$(RSA)^2$: A Rhetorical-Strategy-Aware Rational Speech Act Framework for Figurative Language Understanding](https://arxiv.org/abs/2506.09301)
*Cesare Spinoso-Di Piano,David Austin,Pablo Piantanida,Jackie Chi Kit Cheung*

Main category: cs.CL

TL;DR: 本文提出了RSA²框架，通过考虑说话者的修辞策略来解释比喻语言，无需建模其动机，结合LLMs在讽刺解释任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 比喻语言在人类交流中普遍存在，但现有理论难以解释或需特定建模动机。

Method: 引入RSA²框架，结合修辞策略和LLMs。

Result: 在PragMega+讽刺数据集上达到最优性能。

Conclusion: RSA²框架能有效解释比喻语言，且无需动机建模。

Abstract: Figurative language (e.g., irony, hyperbole, understatement) is ubiquitous in
human communication, resulting in utterances where the literal and the intended
meanings do not match. The Rational Speech Act (RSA) framework, which
explicitly models speaker intentions, is the most widespread theory of
probabilistic pragmatics, but existing implementations are either unable to
account for figurative expressions or require modeling the implicit motivations
for using figurative language (e.g., to express joy or annoyance) in a
setting-specific way. In this paper, we introduce the Rhetorical-Strategy-Aware
RSA $(RSA)^2$ framework which models figurative language use by considering a
speaker's employed rhetorical strategy. We show that $(RSA)^2$ enables
human-compatible interpretations of non-literal utterances without modeling a
speaker's motivations for being non-literal. Combined with LLMs, it achieves
state-of-the-art performance on the ironic split of PragMega+, a new irony
interpretation dataset introduced in this study.

</details>


### [22] [Alzheimer's Dementia Detection Using Perplexity from Paired Large Language Models](https://arxiv.org/abs/2506.09315)
*Yao Xiao,Heidi Christensen,Stefan Goetze*

Main category: cs.CL

TL;DR: 该研究通过使用Mistral-7B大语言模型改进配对困惑度方法，显著提高了阿尔茨海默病（AD）检测的准确性，并展示了清晰的决策边界。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）常影响语言能力，现有检测方法存在决策不透明的问题，需要更准确和可解释的方法。

Method: 采用Mistral-7B大语言模型的指令跟随版本，改进配对困惑度方法，并通过提示微调模型分析语言模式。

Result: 新方法比当前最佳配对困惑度方法平均提高3.33%的准确率，比ADReSS 2020基准方法提高6.35%。

Conclusion: 该方法不仅能有效检测AD，还揭示了模型学习到的AD语言模式，为模型解释和数据增强提供了新思路。

Abstract: Alzheimer's dementia (AD) is a neurodegenerative disorder with cognitive
decline that commonly impacts language ability. This work extends the paired
perplexity approach to detecting AD by using a recent large language model
(LLM), the instruction-following version of Mistral-7B. We improve accuracy by
an average of 3.33% over the best current paired perplexity method and by 6.35%
over the top-ranked method from the ADReSS 2020 challenge benchmark. Our
further analysis demonstrates that the proposed approach can effectively detect
AD with a clear and interpretable decision boundary in contrast to other
methods that suffer from opaque decision-making processes. Finally, by
prompting the fine-tuned LLMs and comparing the model-generated responses to
human responses, we illustrate that the LLMs have learned the special language
patterns of AD speakers, which opens up possibilities for novel methods of
model interpretation and data augmentation.

</details>


### [23] [Towards Efficient and Effective Alignment of Large Language Models](https://arxiv.org/abs/2506.09329)
*Yuxin Jiang*

Main category: cs.CL

TL;DR: 论文提出了一系列新方法（Lion、WebR、LTE、BMC和FollowBench），用于改进大型语言模型（LLM）与人类期望的对齐问题，涵盖数据收集、训练和评估。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多种任务中表现出色，但如何高效有效地使其与人类期望对齐仍是一个关键挑战。

Method: 1. 数据收集：提出Lion（对抗蒸馏框架）和WebR（自动化合成数据框架）；2. 训练优化：开发LTE（知识编辑框架）和BMC（改进的偏好优化方法）；3. 评估：引入FollowBench（多级细粒度基准）。

Result: Lion和WebR显著提升了数据多样性和可扩展性；LTE和BMC优化了知识更新和偏好对齐；FollowBench揭示了当前模型在约束遵循上的不足。

Conclusion: 论文通过创新方法在LLM对齐的各个环节取得进展，为未来改进提供了方向。

Abstract: Large language models (LLMs) exhibit remarkable capabilities across diverse
tasks, yet aligning them efficiently and effectively with human expectations
remains a critical challenge. This thesis advances LLM alignment by introducing
novel methodologies in data collection, training, and evaluation. We first
address alignment data collection. Existing approaches rely heavily on manually
curated datasets or proprietary models. To overcome these limitations, we
propose Lion, an adversarial distillation framework that iteratively refines
training data by identifying and generating challenging instructions, enabling
state-of-the-art zero-shot reasoning. Additionally, we introduce Web
Reconstruction (WebR), a fully automated framework that synthesizes
instruction-tuning data directly from raw web documents, significantly
improving data diversity and scalability over existing synthetic data methods.
Next, we enhance alignment training through novel optimization techniques. We
develop Learning to Edit (LTE), a framework that enables LLMs to efficiently
integrate new knowledge while preserving existing information. LTE leverages
meta-learning to improve both real-time and batch knowledge updates.
Furthermore, we introduce Bridging and Modeling Correlations (BMC), a
refinement of Direct Preference Optimization (DPO) that explicitly captures
token-level correlations in preference data, leading to superior alignment
across QA and mathematical reasoning tasks. Finally, we tackle the challenge of
evaluating alignment. Existing benchmarks emphasize response quality but
overlook adherence to specific constraints. To bridge this gap, we introduce
FollowBench, a multi-level, fine-grained benchmark assessing LLMs' ability to
follow complex constraints across diverse instruction types. Our results expose
key weaknesses in current models' constraint adherence, offering insights for
future improvements.

</details>


### [24] [CoLMbo: Speaker Language Model for Descriptive Profiling](https://arxiv.org/abs/2506.09375)
*Massa Baali,Shuo Han,Syed Abdul Hannan,Purusottam Samal,Karanveer Singh,Soham Deshmukh,Rita Singh,Bhiksha Raj*

Main category: cs.CL

TL;DR: CoLMbo是一种新型的说话人语言模型，通过结合说话人编码器和基于提示的调节，生成详细的说话人描述，解决了传统说话人识别系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统说话人识别系统仅能完成分类任务，无法生成详细的说话人特征或上下文丰富的描述，特别是在捕捉方言、性别和年龄等人口统计属性方面表现不足。

Method: CoLMbo整合了说话人编码器和基于提示的调节技术，通过用户定义的提示动态适应新的说话人特征，生成定制化的描述。

Result: 该模型不仅能增强传统的说话人分析，还在零样本场景下表现出色，适用于多样化的数据集。

Conclusion: CoLMbo在说话人识别领域取得了显著进展，为生成详细说话人描述提供了创新解决方案。

Abstract: Speaker recognition systems are often limited to classification tasks and
struggle to generate detailed speaker characteristics or provide context-rich
descriptions. These models primarily extract embeddings for speaker
identification but fail to capture demographic attributes such as dialect,
gender, and age in a structured manner. This paper introduces CoLMbo, a Speaker
Language Model (SLM) that addresses these limitations by integrating a speaker
encoder with prompt-based conditioning. This allows for the creation of
detailed captions based on speaker embeddings. CoLMbo utilizes user-defined
prompts to adapt dynamically to new speaker characteristics and provides
customized descriptions, including regional dialect variations and age-related
traits. This innovative approach not only enhances traditional speaker
profiling but also excels in zero-shot scenarios across diverse datasets,
marking a significant advancement in the field of speaker recognition.

</details>


### [25] [RePO: Replay-Enhanced Policy Optimization](https://arxiv.org/abs/2506.09340)
*Siheng Li,Zhanhui Zhou,Wai Lam,Chao Yang,Chaochao Lu*

Main category: cs.CL

TL;DR: RePO通过多样化的回放策略优化强化学习中的策略，显著提升了性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: GRPO方法计算成本高且数据效率低，需要改进。

Method: 引入RePO，利用回放缓冲区中的离策略样本进行策略优化。

Result: 在多个数学推理基准测试中，RePO显著优于GRPO，性能提升显著。

Conclusion: RePO是一种高效且计算成本较低的策略优化方法。

Abstract: Reinforcement learning (RL) is vital for optimizing large language models
(LLMs). Recent Group Relative Policy Optimization (GRPO) estimates advantages
using multiple on-policy outputs per prompt, leading to high computational
costs and low data efficiency. To address this, we introduce Replay-Enhanced
Policy Optimization (RePO), which leverages diverse replay strategies to
retrieve off-policy samples from a replay buffer, allowing policy optimization
based on a broader and more diverse set of samples for each prompt. Experiments
on five LLMs across seven mathematical reasoning benchmarks demonstrate that
RePO achieves absolute average performance gains of $18.4$ and $4.1$ points for
Qwen2.5-Math-1.5B and Qwen3-1.7B, respectively, compared to GRPO. Further
analysis indicates that RePO increases computational cost by $15\%$ while
raising the number of effective optimization steps by $48\%$ for Qwen3-1.7B,
with both on-policy and off-policy sample numbers set to $8$. The repository
can be accessed at https://github.com/SihengLi99/RePO.

</details>


### [26] [Latent Multi-Head Attention for Small Language Models](https://arxiv.org/abs/2506.09342)
*Sushant Mehta,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CL

TL;DR: 研究探讨了小型语言模型中潜在多头注意力（MLA）的效率与质量权衡，发现结合旋转位置嵌入（RoPE）的MLA在减少内存的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型中潜在多头注意力的效率与质量平衡，为内存受限的应用提供优化方案。

Method: 训练30M参数的GPT模型，比较标准多头注意力（MHA）、MLA及结合RoPE的MLA（MLA+RoPE）的性能。

Result: MLA+RoPE在减少45%内存的同时仅增加0.3%验证损失，推理速度提升1.4倍，并在GPT-4评估中表现最佳。

Conclusion: MLA+RoPE在小型模型中实现了内存与性能的帕累托优化，RoPE对MLA性能至关重要。

Abstract: We present the first comprehensive study of latent multi-head attention (MLA)
for small language models, revealing interesting efficiency-quality trade-offs.
Training 30M-parameter GPT models on 100,000 synthetic stories, we benchmark
three architectural variants: standard multi-head attention (MHA), MLA, and MLA
with rotary positional embeddings (MLA+RoPE). Our key finding is that MLA+RoPE
with half-rank latent dimensions (r = d/2) achieves a 45% KV-cache memory
reduction while incurring only a 0.3% increase in validation loss (essentially
matching MHA quality)- a Pareto improvement for memory constrained deployment.
We further show that RoPE is crucial for MLA in small models: without it, MLA
underperforms vanilla attention by 3-5%, but with RoPE, it surpasses vanilla by
2%. Inference benchmarks on NVIDIA A100 GPUs reveal that MLA with r=d/2
achieves a 1.4 times speedup over full-rank MLA while maintaining the memory
savings. GPT-4 evaluations corroborate perplexity results, with ours achieving
the highest quality scores (7.4/10) across grammar, creativity, and consistency
metrics. Code and models will be released upon acceptance.

</details>


### [27] [RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic Sampling](https://arxiv.org/abs/2506.08672)
*Yang Liu,Jiaqi Li,Zilong Zheng*

Main category: cs.CL

TL;DR: 论文提出了一种名为RuleReasoner的强化学习方法，用于提升小型推理模型在规则推理任务中的表现，并通过动态采样实现跨领域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决小型推理模型在多样化规则推理任务中泛化能力不足的问题，避免依赖人工设计的混合训练方法。

Method: 采用强化学习和动态采样策略，通过历史奖励更新采样权重，实现领域增强和灵活的在线学习。

Result: 在分布内和分布外任务中显著优于前沿大型推理模型，同时计算效率更高。

Conclusion: RuleReasoner为小型推理模型提供了一种高效且泛化能力强的规则推理解决方案。

Abstract: Rule-based reasoning has been acknowledged as one of the fundamental problems
in reasoning, while deviations in rule formats, types, and complexity in
real-world applications pose severe challenges. Recent studies have shown that
large reasoning models (LRMs) have remarkable reasoning capabilities, and their
performance is substantially enhanced by reinforcement learning (RL). However,
it remains an open question whether small reasoning models (SRMs) can learn
rule-based reasoning effectively with robust generalization across diverse
tasks and domains. To address this, we introduce Reinforced Rule-based
Reasoning, a.k.a. RuleReasoner, a simple yet effective method to conduct
rule-based reasoning via a wide collection of curated tasks and a novel
domain-aware dynamic sampling approach. Specifically, RuleReasoner resamples
each training batch by updating the sampling weights of different domains based
on historical rewards. This facilitates domain augmentation and flexible online
learning schedules for RL, obviating the need for pre-hoc human-engineered
mix-training recipes used in existing methods. Empirical evaluations on
in-distribution (ID) and out-of-distribution (OOD) benchmarks reveal that
RuleReasoner outperforms frontier LRMs by a significant margin ($\Delta$4.1%
average points on eight ID tasks and $\Delta$10.4% average points on three OOD
tasks over OpenAI-o1). Notably, our approach also exhibits higher computational
efficiency compared to prior dynamic sampling methods for RL.

</details>


### [28] [OmniDRCA: Parallel Speech-Text Foundation Model via Dual-Resolution Speech Representations and Contrastive Alignment](https://arxiv.org/abs/2506.09349)
*Chao-Hong Tan,Qian Chen,Wen Wang,Chong Deng,Qinglin Zhang,Luyao Cheng,Hai Yu,Xin Zhang,Xiang Lv,Tianyu Zhao,Chong Zhang,Yukun Ma,Yafeng Chen,Hui Wang,Jiaqing Liu,Jieping Ye*

Main category: cs.CL

TL;DR: OmniDRCA是一种基于联合自回归建模的并行语音-文本基础模型，通过双分辨率语音表示和对比跨模态对齐，实现了语音和文本的并行处理，并在语音问答任务中取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在语音和文本生成中存在模态不协调的问题，OmniDRCA旨在通过联合建模和对比对齐提升多模态生成的一致性和性能。

Method: 采用并行语音-文本联合自回归建模，结合双分辨率语音表示和对比跨模态对齐技术。

Result: 在语音问答基准测试中，OmniDRCA在并行联合语音-文本建模模型中达到新的SOTA性能，并与交错模型竞争。

Conclusion: OmniDRCA展示了在多模态生成中的潜力，并可能扩展到全双工会话场景。

Abstract: Recent studies on end-to-end speech generation with large language models
(LLMs) have attracted significant community attention, with multiple works
extending text-based LLMs to generate discrete speech tokens. Existing
approaches primarily fall into two categories: (1) Methods that generate
discrete speech tokens independently without incorporating them into the LLM's
autoregressive process, resulting in text generation being unaware of
concurrent speech synthesis. (2) Models that generate interleaved or parallel
speech-text tokens through joint autoregressive modeling, enabling mutual
modality awareness during generation. This paper presents OmniDRCA, a parallel
speech-text foundation model based on joint autoregressive modeling, featuring
dual-resolution speech representations and contrastive cross-modal alignment.
Our approach processes speech and text representations in parallel while
enhancing audio comprehension through contrastive alignment. Experimental
results on Spoken Question Answering benchmarks demonstrate that OmniDRCA
establishes new state-of-the-art (SOTA) performance among parallel joint
speech-text modeling based foundation models, and achieves competitive
performance compared to interleaved models. Additionally, we explore the
potential of extending the framework to full-duplex conversational scenarios.

</details>


### [29] [DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts](https://arxiv.org/abs/2506.09351)
*Yuchen Feng,Bowen Shen,Naibin Gu,Jiaxuan Zhao,Peng Fu,Zheng Lin,Weiping Wang*

Main category: cs.CL

TL;DR: 论文提出了一种名为DIVE的多样性增强重建方法，通过修剪和重组LLM的FFN模块，显著减少训练开销，同时保持专家多样性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将密集LLM重建为MoE LLM时忽视了专家多样性，导致冗余。DIVE通过利用修剪后的多样性提升重建效果。

Method: DIVE包括领域亲和性挖掘、基于修剪的专家重建和高效重训练，具体涉及FFN模块的修剪和重组。

Result: 实验显示，DIVE在相同激活参数数量下，训练效率高且精度损失小，优于现有修剪和MoE重建方法。

Conclusion: DIVE通过增强专家多样性，有效提升了MoE LLM的重建效率和性能。

Abstract: Large language models (LLMs) with the Mixture-of-Experts (MoE) architecture
achieve high cost-efficiency by selectively activating a subset of the
parameters. Despite the inference efficiency of MoE LLMs, the training of
extensive experts from scratch incurs substantial overhead, whereas
reconstructing a dense LLM into an MoE LLM significantly reduces the training
budget. However, existing reconstruction methods often overlook the diversity
among experts, leading to potential redundancy. In this paper, we come up with
the observation that a specific LLM exhibits notable diversity after being
pruned on different calibration datasets, based on which we present a
Diversity-Enhanced reconstruction method named DIVE. The recipe of DIVE
includes domain affinity mining, pruning-based expert reconstruction, and
efficient retraining. Specifically, the reconstruction includes pruning and
reassembly of the feed-forward network (FFN) module. After reconstruction, we
efficiently retrain the model on routers, experts and normalization modules. We
implement DIVE on Llama-style LLMs with open-source training corpora.
Experiments show that DIVE achieves training efficiency with minimal accuracy
trade-offs, outperforming existing pruning and MoE reconstruction methods with
the same number of activated parameters.

</details>


### [30] [Taming SQL Complexity: LLM-Based Equivalence Evaluation for Text-to-SQL](https://arxiv.org/abs/2506.09359)
*Qingyun Zeng,Simin Ma,Arash Niknafs,Ashish Basran,Carol Szabo*

Main category: cs.CL

TL;DR: 论文探讨了利用LLMs评估生成的SQL语义等价性，分析了常见等价与不等价模式，并讨论了基于LLM评估的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于用户查询的模糊性和SQL的多重有效性，评估生成的SQL语义等价性仍具挑战性。

Method: 使用LLMs评估语义和更实用的“弱”语义等价性。

Result: 分析了SQL等价与不等价的常见模式。

Conclusion: 基于LLM的评估面临挑战，但为语义等价性评估提供了新思路。

Abstract: The rise of Large Language Models (LLMs) has significantly advanced
Text-to-SQL (NL2SQL) systems, yet evaluating the semantic equivalence of
generated SQL remains a challenge, especially given ambiguous user queries and
multiple valid SQL interpretations. This paper explores using LLMs to assess
both semantic and a more practical "weak" semantic equivalence. We analyze
common patterns of SQL equivalence and inequivalence, discuss challenges in
LLM-based evaluation.

</details>


### [31] [COGENT: A Curriculum-oriented Framework for Generating Grade-appropriate Educational Content](https://arxiv.org/abs/2506.09367)
*Zhengyuan Liu,Stella Xin Yin,Dion Hoe-Lian Goh,Nancy F. Chen*

Main category: cs.CL

TL;DR: COGENT是一个面向课程标准的生成框架，用于生成适合年级的教育内容，解决了生成AI在教育领域的挑战。


<details>
  <summary>Details</summary>
Motivation: 生成AI在教育应用中常无法符合课程标准和年级阅读水平，尤其在STEM教育中难以平衡科学解释与日常语言。

Method: COGENT整合科学概念、核心思想和学习目标，通过控制文本长度、词汇和句子复杂度，并采用“基于好奇”的方法提升学生兴趣。

Result: 实验表明，COGENT生成的文本在年级适应性上优于或等同于人工参考内容。

Conclusion: COGENT为规模化生成高质量自适应学习资源提供了可行方案。

Abstract: While Generative AI has demonstrated strong potential and versatility in
content generation, its application to educational contexts presents several
challenges. Models often fail to align with curriculum standards and maintain
grade-appropriate reading levels consistently. Furthermore, STEM education
poses additional challenges in balancing scientific explanations with everyday
language when introducing complex and abstract ideas and phenomena to younger
students. In this work, we propose COGENT, a curriculum-oriented framework for
generating grade-appropriate educational content. We incorporate three
curriculum components (science concepts, core ideas, and learning objectives),
control readability through length, vocabulary, and sentence complexity, and
adopt a ``wonder-based'' approach to increase student engagement and interest.
We conduct a multi-dimensional evaluation via both LLM-as-a-judge and human
expert analysis. Experimental results show that COGENT consistently produces
grade-appropriate passages that are comparable or superior to human references.
Our work establishes a viable approach for scaling adaptive and high-quality
learning resources.

</details>


### [32] [Binary classification for perceived quality of headlines and links on worldwide news websites, 2018-2024](https://arxiv.org/abs/2506.09381)
*Austin McCutcheon,Thiago E. A. de Oliveira,Aleksandr Zheleznov,Chris Brogly*

Main category: cs.CL

TL;DR: 论文研究了如何自动区分低质量和高质量的新闻标题/链接，通过评估12种机器学习模型和提取115种语言特征，发现传统集成方法和微调DistilBERT模型均表现良好。


<details>
  <summary>Details</summary>
Motivation: 在线新闻的泛滥导致低质量新闻标题/链接广泛传播，研究旨在自动区分其质量。

Method: 使用57,544,214条新闻标题/链接的平衡数据集，提取115种语言特征，评估12种机器学习模型，包括传统集成方法和深度学习模型。

Result: 传统集成方法（如bagging分类器）表现良好（88.1%准确率），微调DistilBERT模型准确率最高（90.3%）。

Conclusion: NLP特征结合传统分类器或深度学习模型均可有效区分新闻质量，但需权衡预测性能和训练时间。

Abstract: The proliferation of online news enables potential widespread publication of
perceived low-quality news headlines/links. As a result, we investigated
whether it was possible to automatically distinguish perceived lower-quality
news headlines/links from perceived higher-quality headlines/links. We
evaluated twelve machine learning models on a binary, balanced dataset of
57,544,214 worldwide news website links/headings from 2018-2024 (28,772,107 per
class) with 115 extracted linguistic features. Binary labels for each text were
derived from scores based on expert consensus regarding the respective news
domain quality. Traditional ensemble methods, particularly the bagging
classifier, had strong performance (88.1% accuracy, 88.3% F1, 80/20 train/test
split). Fine-tuned DistilBERT achieved the highest accuracy (90.3%, 80/20
train/test split) but required more training time. The results suggest that
both NLP features with traditional classifiers and deep learning models can
effectively differentiate perceived news headline/link quality, with some
trade-off between predictive performance and train time.

</details>


### [33] [Comparing human and LLM politeness strategies in free production](https://arxiv.org/abs/2506.09391)
*Haoran Zhao,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在礼貌用语上表现出与人类相似的策略，但过度依赖负面礼貌策略，可能导致误解。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否能在礼貌用语上像人类一样灵活运用不同的语言策略，平衡信息性和社交目标。

Method: 通过比较人类和LLMs在约束性和开放性任务中的反应，分析其礼貌策略的使用。

Result: 大型模型（≥70B参数）能复现计算语用学的关键偏好，人类评价者更倾向于LLM生成的回答，但模型在正面情境中过度依赖负面礼貌策略。

Conclusion: LLMs在礼貌策略上表现优异，但细微差异引发了对AI系统语用对齐的重要问题。

Abstract: Polite speech poses a fundamental alignment challenge for large language
models (LLMs). Humans deploy a rich repertoire of linguistic strategies to
balance informational and social goals -- from positive approaches that build
rapport (compliments, expressions of interest) to negative strategies that
minimize imposition (hedging, indirectness). We investigate whether LLMs employ
a similarly context-sensitive repertoire by comparing human and LLM responses
in both constrained and open-ended production tasks. We find that larger models
($\ge$70B parameters) successfully replicate key preferences from the
computational pragmatics literature, and human evaluators surprisingly prefer
LLM-generated responses in open-ended contexts. However, further linguistic
analyses reveal that models disproportionately rely on negative politeness
strategies even in positive contexts, potentially leading to
misinterpretations. While modern LLMs demonstrate an impressive handle on
politeness strategies, these subtle differences raise important questions about
pragmatic alignment in AI systems.

</details>


### [34] [A Hierarchical Probabilistic Framework for Incremental Knowledge Tracing in Classroom Settings](https://arxiv.org/abs/2506.09393)
*Xinyi Gao,Qiucheng Wu,Yang Zhang,Xuechen Liu,Kaizhi Qian,Ying Xu,Shiyu Chang*

Main category: cs.CL

TL;DR: KT$^2$是一种基于知识树的知识追踪框架，利用层次化知识概念在低资源条件下提升学生表现预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现实课堂中知识追踪常面临数据稀疏和在线更新的挑战，现有方法难以应对。

Method: 提出KT$^2$框架，利用树状知识概念层次结构，通过隐马尔可夫树模型和EM算法估计学生掌握程度。

Result: 实验表明KT$^2$在低资源在线设置中优于基线方法。

Conclusion: KT$^2$通过层次化知识概念和增量更新机制，有效解决了低资源知识追踪问题。

Abstract: Knowledge tracing (KT) aims to estimate a student's evolving knowledge state
and predict their performance on new exercises based on performance history.
Many realistic classroom settings for KT are typically low-resource in data and
require online updates as students' exercise history grows, which creates
significant challenges for existing KT approaches. To restore strong
performance under low-resource conditions, we revisit the hierarchical
knowledge concept (KC) information, which is typically available in many
classroom settings and can provide strong prior when data are sparse. We
therefore propose Knowledge-Tree-based Knowledge Tracing (KT$^2$), a
probabilistic KT framework that models student understanding over a
tree-structured hierarchy of knowledge concepts using a Hidden Markov Tree
Model. KT$^2$ estimates student mastery via an EM algorithm and supports
personalized prediction through an incremental update mechanism as new
responses arrive. Our experiments show that KT$^2$ consistently outperforms
strong baselines in realistic online, low-resource settings.

</details>


### [35] [Token Constraint Decoding Improves Robustness on Question Answering for Large Language Models](https://arxiv.org/abs/2506.09408)
*Jui-Ming Yao,Hao-Yuan Chen,Zi-Xian Tang,Bing-Jia Tan,Sheng-Wei Peng,Bing-Cheng Xie,Shun-Feng Su*

Main category: cs.CL

TL;DR: 论文提出了一种名为Token Constraint Decoding (TCD)的推理时算法，通过增强token级预测的对齐性，提升大语言模型(LLMs)在噪声环境下的鲁棒性。实验表明，TCD结合提示工程(PE)能显著恢复因输入噪声而下降的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多选题问答任务中表现优异，但对微小输入扰动高度敏感，需要提升其鲁棒性。

Method: 提出TCD算法，通过约束token级预测的对齐性，增强模型在噪声环境下的稳定性。

Result: 在CommonsenseQA、MMLU和MMLU-Pro等数据集上，TCD显著提升了模型性能，尤其是对较弱模型如Gemma3 1B，性能提升高达39%。

Conclusion: TCD是一种模型无关的实用方法，能提升LLMs在现实不完美条件下的推理稳定性，为其在安全关键或用户交互应用中的可靠部署铺平道路。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance on
multiple-choice question answering (MCQA) benchmarks, yet they remain highly
vulnerable to minor input perturbations. In this paper, we introduce and
evaluate Token Constraint Decoding (TCD). This simple yet effective
inference-time algorithm enforces alignment between token-level predictions to
enhance robustness in noisy settings. Through extensive experiments on
CommonsenseQA, MMLU, and MMLU-Pro, we show that TCD, especially when paired
with prompt engineering (PE) fixes, significantly restores performance degraded
by input noise, yielding up to +39\% absolute gains for weaker models like
Gemma3 1B. Penalty sweep analyses further reveal that TCD implicitly
regularizes overconfident outputs, with different models requiring distinct
penalty schedules to maximize resilience. Our findings establish TCD as a
practical, model-agnostic approach for improving reasoning stability under
real-world imperfections and pave the way for more reliable deployment of LLMs
in safety-critical or user-facing applications.

</details>


### [36] [PGDA-KGQA: A Prompt-Guided Generative Framework with Multiple Data Augmentation Strategies for Knowledge Graph Question Answering](https://arxiv.org/abs/2506.09414)
*Xiujun Zhou,Pingjian Zhang,Deyou Tang*

Main category: cs.CL

TL;DR: PGDA-KGQA是一个基于提示引导的生成框架，通过多种数据增强策略解决KGQA任务中数据稀缺和多跳推理问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱问答（KGQA）中数据稀缺、多跳推理样本不足以及传统数据增强方法导致的语义失真问题。

Method: 提出PGDA-KGQA框架，利用精心设计的提示引导LLMs生成大规模（问题，逻辑形式）对，并通过单跳伪问题生成、语义保留问题重写和答案引导的反向路径探索三种策略增强数据。

Result: 在WebQSP和ComplexWebQuestions数据集上，F1、Hits@1和准确率分别提升2.8%、1.2%、3.1%和1.8%、1.1%、2.4%。

Conclusion: PGDA-KGQA通过数据增强显著提升了KGQA任务的性能，尤其在多跳推理和语义对齐方面表现突出。

Abstract: Knowledge Graph Question Answering (KGQA) is a crucial task in natural
language processing that requires reasoning over knowledge graphs (KGs) to
answer natural language questions. Recent methods utilizing large language
models (LLMs) have shown remarkable semantic parsing capabilities but are
limited by the scarcity of diverse annotated data and multi-hop reasoning
samples. Traditional data augmentation approaches are focus mainly on
single-hop questions and prone to semantic distortion, while LLM-based methods
primarily address semantic distortion but usually neglect multi-hop reasoning,
thus limiting data diversity. The scarcity of multi-hop samples further weakens
models' generalization. To address these issues, we propose PGDA-KGQA, a
prompt-guided generative framework with multiple data augmentation strategies
for KGQA. At its core, PGDA-KGQA employs a unified prompt-design paradigm: by
crafting meticulously engineered prompts that integrate the provided textual
content, it leverages LLMs to generate large-scale (question, logical form)
pairs for model training. Specifically, PGDA-KGQA enriches its training set by:
(1) generating single-hop pseudo questions to improve the alignment of question
semantics with KG relations; (2) applying semantic-preserving question
rewriting to improve robustness against linguistic variations; (3) employing
answer-guided reverse path exploration to create realistic multi-hop questions.
By adopting an augment-generate-retrieve semantic parsing pipeline, PGDA-KGQA
utilizes the augmented data to enhance the accuracy of logical form generation
and thus improve answer retrieval performance. Experiments demonstrate that
outperforms state-of-the-art methods on standard KGQA datasets, achieving
improvements on WebQSP by 2.8%, 1.2%, and 3.1% and on ComplexWebQuestions by
1.8%, 1.1%, and 2.4% in F1, Hits@1, and Accuracy, respectively.

</details>


### [37] [Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings](https://arxiv.org/abs/2506.09424)
*Md Messal Monem Miah,Adrita Anika,Xi Shi,Ruihong Huang*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）和大型多模态模型（LMMs）在多种领域的自动欺骗检测能力，发现微调后的LLMs在文本欺骗检测任务中表现优异，而LMMs在多模态线索利用上存在困难。


<details>
  <summary>Details</summary>
Motivation: 在数字化世界中，欺骗检测是一项关键且具有挑战性的任务，需要评估现有模型的性能。

Method: 通过零样本和少样本方法，结合随机或基于相似性的上下文示例选择，评估LLMs和LMMs在三个数据集（RLTD、MU3D、OpSpam）上的表现。

Result: 微调后的LLMs在文本欺骗检测中达到最佳性能，而LMMs未能充分利用跨模态线索。辅助特征（如非语言手势）和提示策略（如链式推理）对结果有影响。

Conclusion: 研究揭示了LLMs处理欺骗线索的潜力与局限，为实际应用提供了重要参考。

Abstract: Detecting deception in an increasingly digital world is both a critical and
challenging task. In this study, we present a comprehensive evaluation of the
automated deception detection capabilities of Large Language Models (LLMs) and
Large Multimodal Models (LMMs) across diverse domains. We assess the
performance of both open-source and commercial LLMs on three distinct datasets:
real life trial interviews (RLTD), instructed deception in interpersonal
scenarios (MU3D), and deceptive reviews (OpSpam). We systematically analyze the
effectiveness of different experimental setups for deception detection,
including zero-shot and few-shot approaches with random or similarity-based
in-context example selection. Our results show that fine-tuned LLMs achieve
state-of-the-art performance on textual deception detection tasks, while LMMs
struggle to fully leverage cross-modal cues. Additionally, we analyze the
impact of auxiliary features, such as non-verbal gestures and video summaries,
and examine the effectiveness of different prompting strategies, including
direct label generation and chain-of-thought reasoning. Our findings provide
key insights into how LLMs process and interpret deceptive cues across
modalities, highlighting their potential and limitations in real-world
deception detection applications.

</details>


### [38] [Improved Supervised Fine-Tuning for Large Language Models to Mitigate Catastrophic Forgetting](https://arxiv.org/abs/2506.09428)
*Fei Ding,Baiqiao Wang*

Main category: cs.CL

TL;DR: 提出了一种新的监督微调方法，减少灾难性遗忘风险，同时提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）虽提升任务适应性，但会削弱模型通用能力，且因无法访问原始数据，灾难性遗忘问题加剧。

Method: 通过重构基础模型的指令分布，筛选最优数据并与新数据混合进行SFT。

Result: 实验表明，该方法在保留通用能力的同时提升了任务性能。

Conclusion: 该方法为第三方实践者提供了一种更经济有效的SFT解决方案。

Abstract: Supervised Fine-Tuning (SFT), while enhancing large language models(LLMs)'
instruction-following capabilities and domain-specific task adaptability, often
diminishes their general capabilities. Moreover, due to the inaccessibility of
original pre-training data, catastrophic forgetting tends to be exacerbated
when third-party practitioners implement SFT on open-sourced models. To address
this challenge, we propose a novel, more cost-effective SFT method which could
effectively reduce the risk of catastrophic forgetting without access to
original SFT data. Our approach begins by reconstructing the likely SFT
instruction distribution of the base model, followed by a multi-model screening
process to select optimal data, which is then mixed with new data for SFT.
Experimental results demonstrate that our method preserves generalization
capabilities in general domains while improving task-specific performance.

</details>


### [39] [GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture](https://arxiv.org/abs/2506.09440)
*GigaChat team,Mamedov Valentin,Evgenii Kosarev,Gregory Leleytner,Ilya Shchuckin,Valeriy Berezovskiy,Daniil Smirnov,Dmitry Kozlov,Sergei Averkiev,Lukyanenko Ivan,Aleksandr Proshunin,Ainur Israfilova,Ivan Baskov,Artem Chervyakov,Emil Shakirov,Mikhail Kolesov,Daria Khomich,Darya Latortseva,Sergei Porkhun,Yury Fedorov,Oleg Kutuzov,Polina Kudriavtseva,Sofiia Soldatova,Kolodin Egor,Stanislav Pyatkin,Dzmitry Menshykh,Grafov Sergei,Eldar Damirov,Karlov Vladimir,Ruslan Gaitukiev,Arkadiy Shatenov,Alena Fenogenova,Nikita Savushkin,Fedor Minkin*

Main category: cs.CL

TL;DR: 论文介绍了针对俄语的GigaChat系列大语言模型，包括基础模型和指令调优版本，详细描述了架构、预训练过程及实验设计，并评估了其在俄语和英语基准测试中的表现，同时开源了三个模型以支持俄语NLP研究。


<details>
  <summary>Details</summary>
Motivation: 由于俄语专用基础模型开发受限，本文旨在填补这一空白，提供针对俄语的大语言模型，支持研究和工业应用。

Method: 提出GigaChat系列模型，包括不同规模的版本，详细描述模型架构、预训练过程，并通过实验验证设计选择。

Result: GigaChat在俄语和英语基准测试中表现优异，并与多语言模型进行了比较，同时开源了三个模型。

Conclusion: GigaChat系列模型为俄语NLP提供了重要工具，开源模型将促进研究和工业应用的发展。

Abstract: Generative large language models (LLMs) have become crucial for modern NLP
research and applications across various languages. However, the development of
foundational models specifically tailored to the Russian language has been
limited, primarily due to the significant computational resources required.
This paper introduces the GigaChat family of Russian LLMs, available in various
sizes, including base models and instruction-tuned versions. We provide a
detailed report on the model architecture, pre-training process, and
experiments to guide design choices. In addition, we evaluate their performance
on Russian and English benchmarks and compare GigaChat with multilingual
analogs. The paper presents a system demonstration of the top-performing models
accessible via an API, a Telegram bot, and a Web interface. Furthermore, we
have released three open GigaChat models in open-source
(https://huggingface.co/ai-sage), aiming to expand NLP research opportunities
and support the development of industrial solutions for the Russian language.

</details>


### [40] [UniToMBench: Integrating Perspective-Taking to Improve Theory of Mind in LLMs](https://arxiv.org/abs/2506.09450)
*Prameshwar Thiyagarajan,Vaishnavi Parimi,Shamant Sai,Soumil Garg,Zhangir Meirbek,Nitin Yarlagadda,Kevin Zhu,Chris Kim*

Main category: cs.CL

TL;DR: UniToMBench是一个统一基准，结合SimToM和TOMBENCH的优势，通过多交互任务设计和动态故事场景，系统提升和评估大语言模型（LLM）的心理理论（ToM）能力。


<details>
  <summary>Details</summary>
Motivation: 心理理论（ToM）是理解自己和他人心理状态的能力，但对大语言模型（LLM）仍具挑战性，现有模型在预测人类心理状态时表现不佳。

Method: UniToMBench整合了1000多个手工编写场景的数据集，结合视角采技术和多样化评估指标，以激发LLM的社会认知能力。

Result: 评估显示，GPT-4o和GPT-4o Mini在情感和信念相关任务中表现优异（准确率通常超过80%），但在知识型任务中表现不稳定。

Conclusion: UniToMBench揭示了当前LLM在ToM任务中的优势和局限，为未来研究提供了全面工具。

Abstract: Theory of Mind (ToM), the ability to understand the mental states of oneself
and others, remains a challenging area for large language models (LLMs), which
often fail to predict human mental states accurately. In this paper, we
introduce UniToMBench, a unified benchmark that integrates the strengths of
SimToM and TOMBENCH to systematically improve and assess ToM capabilities in
LLMs by integrating multi-interaction task designs and evolving story
scenarios. Supported by a custom dataset of over 1,000 hand-written scenarios,
UniToMBench combines perspective-taking techniques with diverse evaluation
metrics to better stimulate social cognition in LLMs. Through evaluation, we
observe that while models like GPT-4o and GPT-4o Mini show consistently high
accuracy in tasks involving emotional and belief-related scenarios, with
results usually above 80%, there is significant variability in their
performance across knowledge-based tasks. These results highlight both the
strengths and limitations of current LLMs in ToM-related tasks, underscoring
the value of UniToMBench as a comprehensive tool for future development. Our
code is publicly available here:
https://github.com/Shamant/unifiedtombenchmark.

</details>


### [41] [Towards Bridging the Reward-Generation Gap in Direct Alignment Algorithms](https://arxiv.org/abs/2506.09457)
*Zeguan Xiao,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: 论文提出POET方法，通过截断响应长度解决DAAs中的奖励-生成差距问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 发现DAAs（如DPO和SimPO）在训练与推理阶段存在奖励-生成差距，原因是前缀令牌的重要性未被充分反映。

Method: 提出POET方法，截断偏好和非偏好响应至相同长度，使优化目标更关注前缀令牌。

Result: 实验显示POET在DPO和SimPO上表现更优，AlpacaEval 2提升15.6分，下游任务全面改进。

Conclusion: 解决奖励优化与生成性能的不对齐对DAAs至关重要，POET为此提供了有效方案。

Abstract: Direct Alignment Algorithms (DAAs), such as Direct Preference Optimization
(DPO) and Simple Preference Optimization (SimPO), have emerged as efficient
alternatives to Reinforcement Learning from Human Feedback (RLHF) algorithms
for aligning large language models (LLMs) with human preferences. However, DAAs
suffer from a fundamental limitation we identify as the "reward-generation gap"
-- a misalignment between optimization objectives during training and actual
generation performance during inference. In this paper, we find a contributor
to the reward-generation gap is the mismatch between the inherent importance of
prefix tokens during the LLM generation process and how this importance is
reflected in the implicit reward functions of DAAs. To bridge the gap, we
introduce a simple yet effective approach called Prefix-Oriented Equal-length
Training (POET), which truncates both preferred and dispreferred responses to
match the shorter one's length. Training with POET, where both responses in
each sample are truncated to equal length, resulting in diverse truncated
lengths across samples, the optimization of DAAs objective is implicitly
constrained to converge across all positions, thus paying more attention to
prefix tokens than the standard DAAs. We conduct experiments with DPO and
SimPO, two representative DAAs, demonstrating that POET improves over their
standard implementations, achieving up to 15.6 points in AlpacaEval 2 and
overall improvements across downstream tasks. Our results highlight the
importance of addressing the misalignment between reward optimization and
generation performance in DAAs.

</details>


### [42] [Bridging Online Behavior and Clinical Insight: A Longitudinal LLM-based Study of Suicidality on YouTube Reveals Novel Digital Markers](https://arxiv.org/abs/2506.09495)
*Ilanit Sobol,Shir Lissak,Refael Tikochinski,Tal Nakash,Anat Brunstein Klomek,Eyal Fruchter,Roi Reichart*

Main category: cs.CL

TL;DR: 该研究通过分析YouTube上自杀未遂者的视频内容，结合计算、混合和专家驱动的方法，揭示了自杀行为在社交媒体上的表现及其与临床知识的差异。


<details>
  <summary>Details</summary>
Motivation: 自杀是西方国家的主要死因之一，社交媒体数据为研究自杀行为提供了新视角。

Method: 采用三种方法：基于LLM的自下而上主题建模、混合方法（专家审查LLM主题）和自上而下的心理评估。

Result: 发现五个与自杀未遂相关的主题，其中两个随时间变化；专家未识别的平台特定指标（如YouTube参与度）具有价值；自杀未遂者的动机差异显著。

Conclusion: 综合方法提供了对自杀行为的深入理解，连接了数字行为与临床洞察。

Abstract: Suicide remains a leading cause of death in Western countries, underscoring
the need for new research approaches. As social media becomes central to daily
life, digital footprints offer valuable insight into suicidal behavior.
Focusing on individuals who attempted suicide while uploading videos to their
channels, we investigate: How do suicidal behaviors manifest on YouTube, and
how do they differ from expert knowledge? We applied complementary approaches:
computational bottom-up, hybrid, and expert-driven top-down, on a novel
longitudinal dataset of 181 YouTube channels from individuals with
life-threatening attempts, alongside 134 control channels. In the bottom-up
approach, we applied LLM-based topic modeling to identify behavioral
indicators. Of 166 topics, five were associated with suicide-attempt, with two
also showing temporal attempt-related changes ($p<.01$) - Mental Health
Struggles ($+0.08$)* and YouTube Engagement ($+0.1$)*. In the hybrid approach,
a clinical expert reviewed LLM-derived topics and flagged 19 as
suicide-related. However, none showed significant attempt-related temporal
effects beyond those identified bottom-up. Notably, YouTube Engagement, a
platform-specific indicator, was not flagged by the expert, underscoring the
value of bottom-up discovery. In the top-down approach, psychological
assessment of suicide attempt narratives revealed that the only significant
difference between individuals who attempted before and those attempted during
their upload period was the motivation to share this experience: the former
aimed to Help Others ($\beta=-1.69$, $p<.01$), while the latter framed it as
part of their Personal Recovery ($\beta=1.08$, $p<.01$). By integrating these
approaches, we offer a nuanced understanding of suicidality, bridging digital
behavior and clinical insights.
  * Within-group changes in relation to the suicide attempt.

</details>


### [43] [Give Me FP32 or Give Me Death? Challenges and Solutions for Reproducible Reasoning](https://arxiv.org/abs/2506.09501)
*Jiayi Yuan,Hao Li,Xinheng Ding,Wenya Xie,Yu-Jhe Li,Wentian Zhao,Kun Wan,Jing Shi,Xia Hu,Zirui Liu*

Main category: cs.CL

TL;DR: 研究发现大语言模型（LLM）的性能复现性脆弱，系统配置如评估批次大小、GPU数量和版本会导致显著差异，尤其在推理模型中。通过实验揭示了浮点精度对复现性的影响，并提出了一种轻量级推理管道LayerCast。


<details>
  <summary>Details</summary>
Motivation: LLM的性能评估通常假设基准分数准确且可复现，但实际复现性受系统配置影响显著，尤其在推理任务中。

Method: 通过控制实验，研究不同硬件、软件和精度设置下模型输出的变化，并提出LayerCast管道以平衡内存效率和数值稳定性。

Result: 实验显示，GPU配置和评估批次大小可导致推理模型准确率高达9%的差异和响应长度9000个token的变化。

Conclusion: 浮点精度对LLM复现性至关重要，但常被忽视。LayerCast提供了一种解决方案，兼顾内存效率和数值稳定性。

Abstract: Large Language Models (LLMs) are now integral across various domains and have
demonstrated impressive performance. Progress, however, rests on the premise
that benchmark scores are both accurate and reproducible. We demonstrate that
the reproducibility of LLM performance is fragile: changing system
configuration such as evaluation batch size, GPU count, and GPU version can
introduce significant difference in the generated responses. This issue is
especially pronounced in reasoning models, where minor rounding differences in
early tokens can cascade into divergent chains of thought, ultimately affecting
accuracy. For instance, under bfloat16 precision with greedy decoding, a
reasoning model like DeepSeek-R1-Distill-Qwen-7B can exhibit up to 9% variation
in accuracy and 9,000 tokens difference in response length due to differences
in GPU count, type, and evaluation batch size. We trace the root cause of this
variability to the non-associative nature of floating-point arithmetic under
limited numerical precision. This work presents the first systematic
investigation into how numerical precision affects reproducibility in LLM
inference. Through carefully controlled experiments across various hardware,
software, and precision settings, we quantify when and how model outputs
diverge. Our analysis reveals that floating-point precision -- while critical
for reproducibility -- is often neglected in evaluation practices. Inspired by
this, we develop a lightweight inference pipeline, dubbed LayerCast, that
stores weights in 16-bit precision but performs all computations in FP32,
balancing memory efficiency with numerical stability. Code is available at
https://github.com/nanomaoli/llm_reproducibility.

</details>


### [44] [TransXSSM: A Hybrid Transformer State Space Model with Unified Rotary Position Embedding](https://arxiv.org/abs/2506.09507)
*Bingheng Wu,Jingze Shi,Yifan Wu,Nan Tang,Yuyu Luo*

Main category: cs.CL

TL;DR: 提出了一种统一的旋转位置嵌入方法（\ourRoPE），解决了Transformer和状态空间模型（SSM）在位置编码上的不一致问题，并基于此设计了混合架构\model，显著提升了训练和推理速度以及模型性能。


<details>
  <summary>Details</summary>
Motivation: Transformer和SSM在长序列建模中各有优势，但两者的位置编码机制不同（Transformer依赖显式旋转位置嵌入，SSM依赖隐式卷积表示），导致整合时性能不佳。

Method: 提出统一的旋转位置嵌入方法（\ourRoPE），并基于此设计混合架构\model，结合Transformer和SSM层。

Result: 在4K序列长度下，\model的训练和推理速度分别比标准Transformer快42.3%和29.5%，语言建模任务中准确率提升超过4%，且扩展性更强。

Conclusion: 统一的位置编码解决了混合模型中的位置不兼容问题，实现了高效且高性能的长上下文建模。

Abstract: Transformers exhibit proficiency in capturing long-range dependencies,
whereas State Space Models (SSMs) facilitate linear-time sequence modeling.
Notwithstanding their synergistic potential, the integration of these
architectures presents a significant challenge, primarily attributable to a
fundamental incongruity in their respective positional encoding mechanisms:
Transformers rely on explicit Rotary Position Embeddings (RoPE), while SSMs
leverage implicit positional representations via convolutions. This divergence
often precipitates discontinuities and suboptimal performance. To address this
impediment, we propose a unified rotary position embedding (\textbf{\ourRoPE})
methodology, thereby establishing a consistent positional encoding framework
for both self-attention and state-space components. Using this \ourRoPE, we
introduce \textbf{\model}, a hybrid architecture that coherently integrates the
Transformer and SSM layers under this unified positional encoding scheme. At a
4K sequence length, \model exhibits training and inference speeds that are
\textbf{42.3\% and 29.5\% faster}, respectively, relative to standard
Transformer models. It also delivers higher accuracy: under comparable
settings, it surpasses a Transformer baseline by over 4\% on language modeling
benchmarks. \model furthermore scales more effectively: \model-1.3B gains
\textbf{7.22\%} in average accuracy over its 320M version (versus about 6\%
gains for equivalent Transformers or SSMs). Our results show that unified
positional encoding resolves positional incompatibility in hybrid models,
enabling efficient, high-performance long-context modeling.

</details>


### [45] [KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs](https://arxiv.org/abs/2506.09542)
*Dingjun Wu,Yukun Yan,Zhenghao Liu,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: KG-Infused RAG通过结合知识图谱（KG）和RAG系统，提出了一种多源检索框架，显著提升了问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法通常依赖单一知识源，缺乏认知启发的知识激活机制，限制了事实准确性和推理能力。

Method: 提出KG-Infused RAG框架，利用知识图谱实现认知扩散激活，结合非结构化文本和结构化知识，并通过偏好学习优化关键步骤。

Result: 在五个QA基准测试中，KG-Infused RAG性能优于普通RAG（提升3.8%至13.8%），且能作为插件增强其他RAG方法。

Conclusion: KG-Infused RAG是一种高效、可扩展的多源检索增强生成框架，显著提升了问答任务的性能。

Abstract: Retrieval-Augmented Generation (RAG) improves factual accuracy by grounding
responses in external knowledge. However, existing methods typically rely on a
single source, either unstructured text or structured knowledge. Moreover, they
lack cognitively inspired mechanisms for activating relevant knowledge. To
address these issues, we propose KG-Infused RAG, a framework that integrates
KGs into RAG systems to implement spreading activation, a cognitive process
that enables concept association and inference. KG-Infused RAG retrieves KG
facts, expands the query accordingly, and enhances generation by combining
corpus passages with structured facts, enabling interpretable, multi-source
retrieval grounded in semantic structure. We further improve KG-Infused RAG via
preference learning on sampled key stages in the pipeline. Experiments on five
QA benchmarks show that KG-Infused RAG consistently outperforms vanilla RAG (by
3.8% to 13.8%). Additionally, when integrated into Self-RAG, KG-Infused RAG
brings further performance gains, demonstrating its effectiveness and
versatility as a plug-and-play enhancement module for corpus-based RAG methods.

</details>


### [46] [MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions](https://arxiv.org/abs/2506.09556)
*Georgios Chatzichristodoulou,Despoina Kosmopoulou,Antonios Kritikos,Anastasia Poulopoulou,Efthymios Georgiou,Athanasios Katsamanis,Vassilis Katsouros,Alexandros Potamianos*

Main category: cs.CL

TL;DR: MEDUSA是一种多模态框架，通过四阶段训练流程有效解决情感识别中的类别不平衡和情感模糊问题，并在Interspeech 2025挑战赛中排名第一。


<details>
  <summary>Details</summary>
Motivation: 由于情感的主观性和自然条件下数据的不平衡分布，情感识别（SER）任务具有挑战性。

Method: MEDUSA采用四阶段训练流程：前两阶段训练基于DeepSER的集成分类器，后两阶段优化可训练的元分类器，结合了多任务学习和平衡数据采样。

Result: MEDUSA在Interspeech 2025挑战赛的情感识别任务中排名第一。

Conclusion: MEDUSA通过多模态和分阶段训练，显著提升了情感识别的性能。

Abstract: SER is a challenging task due to the subjective nature of human emotions and
their uneven representation under naturalistic conditions. We propose MEDUSA, a
multimodal framework with a four-stage training pipeline, which effectively
handles class imbalance and emotion ambiguity. The first two stages train an
ensemble of classifiers that utilize DeepSER, a novel extension of a deep
cross-modal transformer fusion mechanism from pretrained self-supervised
acoustic and linguistic representations. Manifold MixUp is employed for further
regularization. The last two stages optimize a trainable meta-classifier that
combines the ensemble predictions. Our training approach incorporates human
annotation scores as soft targets, coupled with balanced data sampling and
multitask learning. MEDUSA ranked 1st in Task 1: Categorical Emotion
Recognition in the Interspeech 2025: Speech Emotion Recognition in Naturalistic
Conditions Challenge.

</details>


### [47] [Gender Bias in English-to-Greek Machine Translation](https://arxiv.org/abs/2506.09558)
*Eleni Gkovedarou,Joke Daems,Luna De Bruyne*

Main category: cs.CL

TL;DR: 研究探讨了Google Translate和DeepL在英语到希腊语翻译中的性别偏见，发现两者在性别明确时表现良好，但在性别未指定时难以实现包容性或中性翻译。GPT-4o作为缓解工具显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 随着对包容性语言需求的增加，机器翻译系统可能强化性别刻板印象的问题引起关注，研究旨在评估和解决这一问题。

Method: 研究使用GendEL数据集（240个句子），分析性别偏见的三方面：男性偏见、职业刻板印象和反刻板印象翻译错误，并测试GPT-4o的缓解效果。

Result: 发现MT系统在性别明确时表现良好（DeepL优于Google Translate和GPT-4o），但在性别未指定时表现不佳；GPT-4o能生成合适的性别化或中性替代方案，但仍存偏见。

Conclusion: 商业MT系统在性别包容性翻译方面仍有不足，GPT-4o作为辅助工具具有潜力，但需进一步优化以减少偏见。

Abstract: As the demand for inclusive language increases, concern has grown over the
susceptibility of machine translation (MT) systems to reinforce gender
stereotypes. This study investigates gender bias in two commercial MT systems,
Google Translate and DeepL, focusing on the understudied English-to-Greek
language pair. We address three aspects of gender bias: i) male bias, ii)
occupational stereotyping, and iii) errors in anti-stereotypical translations.
Additionally, we explore the potential of prompted GPT-4o as a bias mitigation
tool that provides both gender-explicit and gender-neutral alternatives when
necessary. To achieve this, we introduce GendEL, a manually crafted bilingual
dataset of 240 gender-ambiguous and unambiguous sentences that feature
stereotypical occupational nouns and adjectives. We find persistent gender bias
in translations by both MT systems; while they perform well in cases where
gender is explicitly defined, with DeepL outperforming both Google Translate
and GPT-4o in feminine gender-unambiguous sentences, they are far from
producing gender-inclusive or neutral translations when the gender is
unspecified. GPT-4o shows promise, generating appropriate gendered and neutral
alternatives for most ambiguous cases, though residual biases remain evident.

</details>


### [48] [Towards Open Foundation Language Model and Corpus for Macedonian: A Low-Resource Language](https://arxiv.org/abs/2506.09560)
*Stefan Krsteski,Matea Tashkovska,Borjan Sazdov,Hristijan Gjoreski,Branislav Gerazov*

Main category: cs.CL

TL;DR: 论文为低资源语言马其顿语构建了大规模语料库、指令数据集和评估套件，并训练了一个8B参数的LLM模型，性能优于同类模型。


<details>
  <summary>Details</summary>
Motivation: 全球技术普及需求增加，但LLM在低资源语言（如马其顿语）中的应用受限，需构建资源支持研究和应用。

Method: 收集40GB马其顿语文本（3.5B词）、106k指令数据集，构建评估套件，并训练8B参数模型domestic-yak。

Result: 模型在8B参数范围内表现最佳，性能接近10倍大模型，且被母语者评为语法和文化更准确。

Conclusion: 公开数据集、代码和模型权重，为低资源语言LLM研究奠定基础。

Abstract: The increase in technological adoption worldwide comes with demands for novel
tools to be used by the general population. Large Language Models (LLMs)
provide a great opportunity in this respect, but their capabilities remain
limited for low-resource languages, restricting applications in countries where
such languages are spoken. We create several resources to facilitate the
adoption of LLMs and to support research advancements for Macedonian. We
collect the largest Macedonian corpus to date, consisting of 40GB of textual
data and totaling 3.5B words. To support conversational applications, we
collect a 106k-instance instruction dataset, carefully built to be culturally
grounded. For evaluation, we construct a Macedonian evaluation suite covering
seven benchmarks. Finally, we train domestic-yak, a state-of-the-art
8B-parameter model, on our curated datasets and evaluate it against eight
baseline models using the newly constructed benchmark suite. Our model
outperforms all existing models in the 8B parameter range across all
benchmarks, and achieves performance comparable to models up to 10x larger.
Furthermore, a qualitative analysis with native speakers reveals that our model
is preferred over larger counterparts, receiving higher ratings for grammatical
correctness and cultural appropriateness. All datasets, code, and model weights
are openly released, setting a foundation for advancing LLMs in similarly
underrepresented languages. These resources are publicly available at
github.com/LVSTCK for source code, and at huggingface.co/LVSTCK for pretrained
model weights and data.

</details>


### [49] [From Symbolic to Neural and Back: Exploring Knowledge Graph-Large Language Model Synergies](https://arxiv.org/abs/2506.09566)
*Blaž Škrlj,Boshko Koloski,Senja Pollak,Nada Lavrač*

Main category: cs.CL

TL;DR: 综述探讨了知识图谱（KGs）与大型语言模型（LLMs）的协同作用，分为KG增强LLMs和LLM增强KGs两类，强调可扩展性、计算效率和数据质量，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 整合KGs的结构化知识到LLMs中，以增强事实基础和推理能力。

Method: 系统分析现有方法，分为KG增强LLMs（提升推理、减少幻觉）和LLM增强KGs（促进KG构建与查询）。

Result: 发现关键差距，强调结构化知识整合的互惠性，并突出可扩展性和数据质量的重要性。

Conclusion: 提出未来研究方向，如神经符号整合、动态KG更新和数据可靠性，为复杂知识任务铺路。

Abstract: Integrating structured knowledge from Knowledge Graphs (KGs) into Large
Language Models (LLMs) enhances factual grounding and reasoning capabilities.
This survey paper systematically examines the synergy between KGs and LLMs,
categorizing existing approaches into two main groups: KG-enhanced LLMs, which
improve reasoning, reduce hallucinations, and enable complex question
answering; and LLM-augmented KGs, which facilitate KG construction, completion,
and querying. Through comprehensive analysis, we identify critical gaps and
highlight the mutual benefits of structured knowledge integration. Compared to
existing surveys, our study uniquely emphasizes scalability, computational
efficiency, and data quality. Finally, we propose future research directions,
including neuro-symbolic integration, dynamic KG updating, data reliability,
and ethical considerations, paving the way for intelligent systems capable of
managing more complex real-world knowledge tasks.

</details>


### [50] [Memorization in Language Models through the Lens of Intrinsic Dimension](https://arxiv.org/abs/2506.09591)
*Stefan Arnold*

Main category: cs.CL

TL;DR: 研究发现，语言模型中的内在维度（ID）可以抑制记忆行为，高ID序列比低ID序列更难被记忆。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型在训练中无意记忆数据的机制，尤其是内在维度（ID）对记忆行为的影响。

Method: 通过分析内在维度（ID）作为序列结构复杂性的几何代理，研究其对记忆行为的调节作用。

Result: 高ID序列比低ID序列更难被记忆，尤其是在过参数化模型和稀疏暴露条件下。

Conclusion: 内在维度、模型规模和暴露稀疏性共同影响记忆行为，ID可作为抑制记忆的信号。

Abstract: Language Models (LMs) are prone to memorizing parts of their data during
training and unintentionally emitting them at generation time, raising concerns
about privacy leakage and disclosure of intellectual property. While previous
research has identified properties such as context length, parameter size, and
duplication frequency, as key drivers of unintended memorization, little is
known about how the latent structure modulates this rate of memorization. We
investigate the role of Intrinsic Dimension (ID), a geometric proxy for the
structural complexity of a sequence in latent space, in modulating
memorization. Our findings suggest that ID acts as a suppressive signal for
memorization: compared to low-ID sequences, high-ID sequences are less likely
to be memorized, particularly in overparameterized models and under sparse
exposure. These findings highlight the interaction between scale, exposure, and
complexity in shaping memorization.

</details>


### [51] [Benchmarking Debiasing Methods for LLM-based Parameter Estimates](https://arxiv.org/abs/2506.09627)
*Nicolas Audinet de Pieuchon,Adel Daoud,Connor T. Jerzak,Moa Johansson,Richard Johansson*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）标注文本时的偏差问题，比较了两种去偏方法（DSL和PPI）在有限样本中的表现，发现DSL在偏差减少和效率上通常优于PPI，但表现不一致。


<details>
  <summary>Details</summary>
Motivation: LLM标注文本时存在偏差，可能影响下游统计估计（如回归系数和因果效应），需要去偏方法（如DSL和PPI）来结合少量专家标注以修正偏差。

Method: 研究比较了DSL和PPI在不同任务中的表现，分析了它们在有限样本下的偏差减少和效率。

Result: DSL在偏差减少和效率上通常优于PPI，但表现不一致；两种方法在大数据集下均能实现低偏差。

Conclusion: 去偏方法存在偏差-方差权衡，需进一步研究量化其在有限样本中的效率。

Abstract: Large language models (LLMs) offer an inexpensive yet powerful way to
annotate text, but are often inconsistent when compared with experts. These
errors can bias downstream estimates of population parameters such as
regression coefficients and causal effects. To mitigate this bias, researchers
have developed debiasing methods such as Design-based Supervised Learning (DSL)
and Prediction-Powered Inference (PPI), which promise valid estimation by
combining LLM annotations with a limited number of expensive expert
annotations. Although these methods produce consistent estimates under
theoretical assumptions, it is unknown how they compare in finite samples of
sizes encountered in applied research. We make two contributions: First, we
study how each method's performance scales with the number of expert
annotations, highlighting regimes where LLM bias or limited expert labels
significantly affect results. Second, we compare DSL and PPI across a range of
tasks, finding that although both achieve low bias with large datasets, DSL
often outperforms PPI on bias reduction and empirical efficiency, but its
performance is less consistent across datasets. Our findings indicate that
there is a bias-variance tradeoff at the level of debiasing methods, calling
for more research on developing metrics for quantifying their efficiency in
finite samples.

</details>


### [52] [Modeling Probabilistic Reduction using Information Theory and Naive Discriminative Learning](https://arxiv.org/abs/2506.09641)
*Anna Stein,Kevin Tang*

Main category: cs.CL

TL;DR: 研究比较了基于信息论的概率预测器与朴素判别学习（NDL）预测器在建模声学词持续时间上的表现，发现N-gram模型优于NDL模型，但信息论公式的引入提升了NDL性能。


<details>
  <summary>Details</summary>
Motivation: 探讨NDL是否因其认知动机而更有效，以及如何结合信息论指标提升声学缩减建模。

Method: 使用Buckeye语料库比较三种模型：信息论公式NDL、传统NDL和N-gram概率预测器。

Result: N-gram模型表现最佳，但信息论公式的引入改善了NDL模型。

Conclusion: 需结合频率、上下文预测性和平均预测性，并整合信息论指标与判别学习以优化声学缩减建模。

Abstract: This study compares probabilistic predictors based on information theory with
Naive Discriminative Learning (NDL) predictors in modeling acoustic word
duration, focusing on probabilistic reduction. We examine three models using
the Buckeye corpus: one with NDL-derived predictors using information-theoretic
formulas, one with traditional NDL predictors, and one with N-gram
probabilistic predictors. Results show that the N-gram model outperforms both
NDL models, challenging the assumption that NDL is more effective due to its
cognitive motivation. However, incorporating information-theoretic formulas
into NDL improves model performance over the traditional model. This research
highlights a) the need to incorporate not only frequency and contextual
predictability but also average contextual predictability, and b) the
importance of combining information-theoretic metrics of predictability and
information derived from discriminative learning in modeling acoustic
reduction.

</details>


### [53] [Using Sign Language Production as Data Augmentation to enhance Sign Language Translation](https://arxiv.org/abs/2506.09643)
*Harry Walsh,Maksym Ivashechkin,Richard Bowden*

Main category: cs.CL

TL;DR: 利用手语生成技术增强手语翻译模型性能，通过骨架生成、拼接和生成模型SignGAN、SignSplat，提升数据集多样性和翻译效果。


<details>
  <summary>Details</summary>
Motivation: 手语数据稀缺且收集困难，现有数据集规模远小于口语数据，需通过生成技术增强数据以提升翻译模型性能。

Method: 采用骨架生成、拼接技术及生成模型SignGAN、SignSplat，生成多样化的手语视频数据。

Result: 实验表明，该方法能有效增强数据集，提升手语翻译模型性能达19%。

Conclusion: 该方法为资源受限环境下的手语翻译系统提供了更鲁棒和准确的解决方案。

Abstract: Machine learning models fundamentally rely on large quantities of
high-quality data. Collecting the necessary data for these models can be
challenging due to cost, scarcity, and privacy restrictions. Signed languages
are visual languages used by the deaf community and are considered low-resource
languages. Sign language datasets are often orders of magnitude smaller than
their spoken language counterparts. Sign Language Production is the task of
generating sign language videos from spoken language sentences, while Sign
Language Translation is the reverse translation task. Here, we propose
leveraging recent advancements in Sign Language Production to augment existing
sign language datasets and enhance the performance of Sign Language Translation
models. For this, we utilize three techniques: a skeleton-based approach to
production, sign stitching, and two photo-realistic generative models, SignGAN
and SignSplat. We evaluate the effectiveness of these techniques in enhancing
the performance of Sign Language Translation models by generating variation in
the signer's appearance and the motion of the skeletal data. Our results
demonstrate that the proposed methods can effectively augment existing datasets
and enhance the performance of Sign Language Translation models by up to 19%,
paving the way for more robust and accurate Sign Language Translation systems,
even in resource-constrained environments.

</details>


### [54] [Learning Efficient and Generalizable Graph Retriever for Knowledge-Graph Question Answering](https://arxiv.org/abs/2506.09645)
*Tianjun Yao,Haoxuan Li,Zhiqiang Shen,Pan Li,Tongliang Liu,Kun Zhang*

Main category: cs.CL

TL;DR: RAPL是一种新颖的知识图谱检索框架，通过两阶段标注、模型无关的图转换和基于路径的推理策略，显著提升了知识图谱问答的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识图谱问答（KGQA）中面临知识过时和幻觉问题，现有检索增强生成（RAG）方法依赖非结构化文本，限制了可解释性和结构化推理。知识图谱提供了更结构化的替代方案，但现有图检索方法泛化能力不足。

Method: RAPL框架包括：（1）两阶段标注策略，结合启发式信号和参数模型；（2）模型无关的图转换方法，捕捉三元组内和三元组间的交互；（3）基于路径的推理策略，支持结构化输入。

Result: RAPL在性能上优于现有方法2.66%-20.34%，显著缩小了不同规模LLM推理器之间的性能差距，并在跨数据集设置下表现出更强的泛化能力。

Conclusion: RAPL通过结构化检索和推理策略，有效提升了知识图谱问答的效率和效果，为LLM与知识图谱的结合提供了新思路。

Abstract: Large Language Models (LLMs) have shown strong inductive reasoning ability
across various domains, but their reliability is hindered by the outdated
knowledge and hallucinations. Retrieval-Augmented Generation mitigates these
issues by grounding LLMs with external knowledge; however, most existing RAG
pipelines rely on unstructured text, limiting interpretability and structured
reasoning. Knowledge graphs, which represent facts as relational triples, offer
a more structured and compact alternative. Recent studies have explored
integrating knowledge graphs with LLMs for knowledge graph question answering
(KGQA), with a significant proportion adopting the retrieve-then-reasoning
paradigm. In this framework, graph-based retrievers have demonstrated strong
empirical performance, yet they still face challenges in generalization
ability. In this work, we propose RAPL, a novel framework for efficient and
effective graph retrieval in KGQA. RAPL addresses these limitations through
three aspects: (1) a two-stage labeling strategy that combines heuristic
signals with parametric models to provide causally grounded supervision; (2) a
model-agnostic graph transformation approach to capture both intra- and
inter-triple interactions, thereby enhancing representational capacity; and (3)
a path-based reasoning strategy that facilitates learning from the injected
rational knowledge, and supports downstream reasoner through structured inputs.
Empirically, RAPL outperforms state-of-the-art methods by $2.66\%-20.34\%$, and
significantly reduces the performance gap between smaller and more powerful
LLM-based reasoners, as well as the gap under cross-dataset settings,
highlighting its superior retrieval capability and generalizability. Codes are
available at: https://github.com/tianyao-aka/RAPL.

</details>


### [55] [Bridging the Gap Between Open-Source and Proprietary LLMs in Table QA](https://arxiv.org/abs/2506.09657)
*Nikolas Evkarpidi,Elena Tutubalina*

Main category: cs.CL

TL;DR: 本文介绍了一个用于SemEval 2025 Task 8的表格数据问答系统，结合了文本到SQL/代码生成、自校正机制和检索增强生成（RAG），最终在比赛中取得80%准确率，排名前13。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据问答任务中的挑战，提升开源模型在QA任务中的性能。

Method: 整合文本到SQL/代码生成、自校正机制、RAG和端到端模块，由大型语言模型（LLM）协调。

Result: 系统在比赛中达到80%准确率，排名前13，性能接近专有LLM。

Conclusion: 该系统显著提升了开源模型的准确性，为表格数据问答任务提供了有效解决方案。

Abstract: This paper presents a system developed for SemEval 2025 Task 8: Question
Answering (QA) over tabular data. Our approach integrates several key
components: text-to-SQL and text-to-code generation modules, a self-correction
mechanism, and a retrieval-augmented generation (RAG). Additionally, it
includes an end-to-end (E2E) module, all orchestrated by a large language model
(LLM). Through ablation studies, we analyzed the effects of different parts of
our pipeline and identified the challenges that are still present in this
field. During the evaluation phase of the competition, our solution achieved an
accuracy of 80%, resulting in a top-13 ranking among the 38 participating
teams. Our pipeline demonstrates a significant improvement in accuracy for
open-source models and achieves a performance comparable to proprietary LLMs in
QA tasks over tables. The code is available at GitHub repository.

</details>


### [56] [Query-Level Uncertainty in Large Language Models](https://arxiv.org/abs/2506.09669)
*Lihu Chen,Gaël Varoquaux*

Main category: cs.CL

TL;DR: 论文提出了一种通过查询级别不确定性检测大型语言模型知识边界的方法，利用内部置信度实现自适应推理。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型对知识边界的意识，以实现自适应推理（如RAG、深度思考或弃权机制），从而发展高效可信的AI。

Method: 提出了一种无需训练的'内部置信度'方法，通过层和令牌的自我评估检测知识边界。

Result: 在事实问答和数学推理任务中，内部置信度优于多个基线方法，并能用于高效RAG和模型级联。

Conclusion: 该方法能有效检测知识边界，降低推理成本并保持性能。

Abstract: It is important for Large Language Models to be aware of the boundary of
their knowledge, the mechanism of identifying known and unknown queries. This
type of awareness can help models perform adaptive inference, such as invoking
RAG, engaging in slow and deep thinking, or adopting the abstention mechanism,
which is beneficial to the development of efficient and trustworthy AI. In this
work, we propose a method to detect knowledge boundaries via Query-Level
Uncertainty, which aims to determine if the model is able to address a given
query without generating any tokens. To this end, we introduce a novel and
training-free method called \emph{Internal Confidence}, which leverages
self-evaluations across layers and tokens. Empirical results on both factual QA
and mathematical reasoning tasks demonstrate that our internal confidence can
outperform several baselines. Furthermore, we showcase that our proposed method
can be used for efficient RAG and model cascading, which is able to reduce
inference costs while maintaining performance.

</details>


### [57] [Is Fine-Tuning an Effective Solution? Reassessing Knowledge Editing for Unstructured Data](https://arxiv.org/abs/2506.09672)
*Hao Xiong,Chuanyuan Tan,Wenliang Chen*

Main category: cs.CL

TL;DR: 本文提出了针对大型语言模型（LLMs）的无结构化知识编辑（UKE）问题，解决了现有方法在局部性评估和微调（FT）方法异常失败方面的不足，并通过实验验证了优化的FT方法（FT-UKE）的优越性。


<details>
  <summary>Details</summary>
Motivation: 无结构化知识编辑（UKE）对于更新LLMs的知识至关重要，但现有方法缺乏局部性评估，且微调方法存在异常失败问题。

Method: 构建了两个数据集（UnKEBench-Loc和AKEW-Loc）以评估局部性，并分析了影响FT方法性能的四个因素，提出了优化的FT-UKE方法。

Result: 实验表明FT-UKE优于现有最佳方法，在批量编辑场景中优势随批量增大而增加。

Conclusion: FT-UKE是一种高效的无结构化知识编辑方法，为未来研究提供了训练方案。

Abstract: Unstructured Knowledge Editing (UKE) is crucial for updating the relevant
knowledge of large language models (LLMs). It focuses on unstructured inputs,
such as long or free-form texts, which are common forms of real-world
knowledge. Although previous studies have proposed effective methods and tested
them, some issues exist: (1) Lack of Locality evaluation for UKE, and (2)
Abnormal failure of fine-tuning (FT) based methods for UKE. To address these
issues, we first construct two datasets, UnKEBench-Loc and AKEW-Loc (CF), by
extending two existing UKE datasets with locality test data from the
unstructured and structured views. This enables a systematic evaluation of the
Locality of post-edited models. Furthermore, we identify four factors that may
affect the performance of FT-based methods. Based on these factors, we conduct
experiments to determine how the well-performing FT-based methods should be
trained for the UKE task, providing a training recipe for future research. Our
experimental results indicate that the FT-based method with the optimal setting
(FT-UKE) is surprisingly strong, outperforming the existing state-of-the-art
(SOTA). In batch editing scenarios, FT-UKE shows strong performance as well,
with its advantage over SOTA methods increasing as the batch size grows,
expanding the average metric lead from +6.78% to +10.80%

</details>


### [58] [Inv-Entropy: A Fully Probabilistic Framework for Uncertainty Quantification in Language Models](https://arxiv.org/abs/2506.09684)
*Haoyi Song,Ruihan Ji,Naichen Shi,Fan Lai,Raed Al Kontar*

Main category: cs.CL

TL;DR: 本文提出了一种基于逆模型的概率框架，用于量化大型语言模型（LLMs）的不确定性，并引入了一种新的不确定性度量方法Inv-Entropy。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法缺乏概率基础，本文旨在提供一个理论支持并改进LLMs的不确定性量化。

Method: 通过双随机游走视角建模输入-输出对，提出基于逆模型的概率框架，并引入GAAP扰动算法和TSU评估指标。

Result: 实验表明，Inv-Entropy优于现有语义不确定性量化方法。

Conclusion: 该框架灵活且高效，为LLMs的不确定性量化提供了新思路。

Abstract: Large language models (LLMs) have transformed natural language processing,
but their reliable deployment requires effective uncertainty quantification
(UQ). Existing UQ methods are often heuristic and lack a probabilistic
foundation. This paper begins by providing a theoretical justification for the
role of perturbations in UQ for LLMs. We then introduce a dual random walk
perspective, modeling input-output pairs as two Markov chains with transition
probabilities defined by semantic similarity. Building on this, we propose a
fully probabilistic framework based on an inverse model, which quantifies
uncertainty by evaluating the diversity of the input space conditioned on a
given output through systematic perturbations. Within this framework, we define
a new uncertainty measure, Inv-Entropy. A key strength of our framework is its
flexibility: it supports various definitions of uncertainty measures,
embeddings, perturbation strategies, and similarity metrics. We also propose
GAAP, a perturbation algorithm based on genetic algorithms, which enhances the
diversity of sampled inputs. In addition, we introduce a new evaluation metric,
Temperature Sensitivity of Uncertainty (TSU), which directly assesses
uncertainty without relying on correctness as a proxy. Extensive experiments
demonstrate that Inv-Entropy outperforms existing semantic UQ methods. The code
to reproduce the results can be found at
https://github.com/UMDataScienceLab/Uncertainty-Quantification-for-LLMs.

</details>


### [59] [ComfyUI-R1: Exploring Reasoning Models for Workflow Generation](https://arxiv.org/abs/2506.09790)
*Zhenran Xu,Yiyu Wang,Xue Yang,Longyue Wang,Weihua Luo,Kaifu Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: ComfyUI-R1是一个大型推理模型，用于自动化生成AI工作流，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决用户在ComfyUI平台上构建复杂工作流时的高学习曲线问题。

Method: 通过两阶段训练框架（CoT微调和强化学习）构建模型，利用长链推理数据。

Result: 模型在格式有效性、通过率及节点/图级别F1分数上表现优异。

Conclusion: 长链推理和代码化工作流对AI艺术创作具有重要潜力。

Abstract: AI-generated content has evolved from monolithic models to modular workflows,
particularly on platforms like ComfyUI, enabling customization in creative
pipelines. However, crafting effective workflows requires great expertise to
orchestrate numerous specialized components, presenting a steep learning curve
for users. To address this challenge, we introduce ComfyUI-R1, the first large
reasoning model for automated workflow generation. Starting with our curated
dataset of 4K workflows, we construct long chain-of-thought (CoT) reasoning
data, including node selection, workflow planning, and code-level workflow
representation. ComfyUI-R1 is trained through a two-stage framework: (1) CoT
fine-tuning for cold start, adapting models to the ComfyUI domain; (2)
reinforcement learning for incentivizing reasoning capability, guided by a
fine-grained rule-metric hybrid reward, ensuring format validity, structural
integrity, and node-level fidelity. Experiments show that our 7B-parameter
model achieves a 97\% format validity rate, along with high pass rate,
node-level and graph-level F1 scores, significantly surpassing prior
state-of-the-art methods that employ leading closed-source models such as
GPT-4o and Claude series. Further analysis highlights the critical role of the
reasoning process and the advantage of transforming workflows into code.
Qualitative comparison reveals our strength in synthesizing intricate workflows
with diverse nodes, underscoring the potential of long CoT reasoning in AI art
creation.

</details>


### [60] [Do LLMs Give Psychometrically Plausible Responses in Educational Assessments?](https://arxiv.org/abs/2506.09796)
*Andreas Säuberli,Diego Frassinelli,Barbara Plank*

Main category: cs.CL

TL;DR: 研究评估了18种指令调优的大语言模型（LLMs）在多项选择题测试中的反应是否具有人类相似性，发现较大模型虽然过于自信，但通过温度校准后反应分布更接近人类。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否能模拟人类测试行为，以加速教育评估的开发过程。

Method: 基于经典测试理论和项目反应理论，使用公开数据集评估LLMs在阅读、美国历史和经济学科目中的表现。

Result: 较大模型反应分布更接近人类，但相关性不强，零样本设置下不适合用于教育评估试点。

Conclusion: LLMs在零样本设置下不适合直接用于教育评估试点，需进一步优化。

Abstract: Knowing how test takers answer items in educational assessments is essential
for test development, to evaluate item quality, and to improve test validity.
However, this process usually requires extensive pilot studies with human
participants. If large language models (LLMs) exhibit human-like response
behavior to test items, this could open up the possibility of using them as
pilot participants to accelerate test development. In this paper, we evaluate
the human-likeness or psychometric plausibility of responses from 18
instruction-tuned LLMs with two publicly available datasets of multiple-choice
test items across three subjects: reading, U.S. history, and economics. Our
methodology builds on two theoretical frameworks from psychometrics which are
commonly used in educational assessment, classical test theory and item
response theory. The results show that while larger models are excessively
confident, their response distributions can be more human-like when calibrated
with temperature scaling. In addition, we find that LLMs tend to correlate
better with humans in reading comprehension items compared to other subjects.
However, the correlations are not very strong overall, indicating that LLMs
should not be used for piloting educational assessments in a zero-shot setting.

</details>


### [61] [CoRT: Code-integrated Reasoning within Thinking](https://arxiv.org/abs/2506.09820)
*Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu*

Main category: cs.CL

TL;DR: CoRT框架通过Hint-Engineering合成数据，优化大型推理模型（LRMs）与代码解释器（CI）的交互，显著提升数学推理能力并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（如o1和DeepSeek-R1）在复杂数学运算中效率低或准确性不足，直接结合外部计算工具（如代码解释器）存在技术挑战。

Method: 提出CoRT框架，通过Hint-Engineering合成代码集成推理数据，结合监督微调、拒绝微调和强化学习对模型进行后训练。

Result: 在五个数学推理数据集上，32B和1.5B模型分别实现了4%和8%的绝对性能提升，同时显著减少了计算开销。

Conclusion: CoRT框架有效解决了LRMs与CI结合的技术挑战，显著提升了数学推理能力并优化了计算效率。

Abstract: Large Reasoning Models (LRMs) like o1 and DeepSeek-R1 have shown remarkable
progress in natural language reasoning with long chain-of-thought (CoT), yet
they remain inefficient or inaccurate when handling complex mathematical
operations. Addressing these limitations through computational tools (e.g.,
computation libraries and symbolic solvers) is promising, but it introduces a
technical challenge: Code Interpreter (CI) brings external knowledge beyond the
model's internal text representations, thus the direct combination is not
efficient. This paper introduces CoRT, a post-training framework for teaching
LRMs to leverage CI effectively and efficiently. As a first step, we address
the data scarcity issue by synthesizing code-integrated reasoning data through
Hint-Engineering, which strategically inserts different hints at appropriate
positions to optimize LRM-CI interaction. We manually create 30 high-quality
samples, upon which we post-train models ranging from 1.5B to 32B parameters,
with supervised fine-tuning, rejection fine-tuning and reinforcement learning.
Our experimental results demonstrate that Hint-Engineering models achieve 4\%
and 8\% absolute improvements on DeepSeek-R1-Distill-Qwen-32B and
DeepSeek-R1-Distill-Qwen-1.5B respectively, across five challenging
mathematical reasoning datasets. Furthermore, Hint-Engineering models use about
30\% fewer tokens for the 32B model and 50\% fewer tokens for the 1.5B model
compared with the natural language models. The models and code are available at
https://github.com/ChengpengLi1003/CoRT.

</details>


### [62] [EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection](https://arxiv.org/abs/2506.09827)
*Christoph Schuhmann,Robert Kaczmarczyk,Gollam Rabby,Felix Friedrich,Maurice Kraus,Kourosh Nadi,Huu Nguyen,Kristian Kersting,Sören Auer*

Main category: cs.CL

TL;DR: EmoNet-Voice是一个新的语音情感识别资源，包含大规模预训练数据集和专家标注的基准数据集，旨在评估40种细粒度情感类别。


<details>
  <summary>Details</summary>
Motivation: 当前语音情感识别数据集在情感粒度、隐私问题或依赖表演数据方面存在局限，需要更全面的评估资源。

Method: 利用先进的语音生成技术合成模拟情感场景的音频片段，并通过心理学专家验证情感强度标签。

Result: Empathic Insight Voice模型在语音情感识别中表现优异，与人类专家高度一致，且高唤醒情感（如愤怒）比低唤醒情感（如专注）更易检测。

Conclusion: EmoNet-Voice为语音情感识别提供了隐私保护且全面的评估工具，推动了AI情感理解能力的发展。

Abstract: The advancement of text-to-speech and audio generation models necessitates
robust benchmarks for evaluating the emotional understanding capabilities of AI
systems. Current speech emotion recognition (SER) datasets often exhibit
limitations in emotional granularity, privacy concerns, or reliance on acted
portrayals. This paper introduces EmoNet-Voice, a new resource for speech
emotion detection, which includes EmoNet-Voice Big, a large-scale pre-training
dataset (featuring over 4,500 hours of speech across 11 voices, 40 emotions,
and 4 languages), and EmoNet-Voice Bench, a novel benchmark dataset with human
expert annotations. EmoNet-Voice is designed to evaluate SER models on a
fine-grained spectrum of 40 emotion categories with different levels of
intensities. Leveraging state-of-the-art voice generation, we curated synthetic
audio snippets simulating actors portraying scenes designed to evoke specific
emotions. Crucially, we conducted rigorous validation by psychology experts who
assigned perceived intensity labels. This synthetic, privacy-preserving
approach allows for the inclusion of sensitive emotional states often absent in
existing datasets. Lastly, we introduce Empathic Insight Voice models that set
a new standard in speech emotion recognition with high agreement with human
experts. Our evaluations across the current model landscape exhibit valuable
findings, such as high-arousal emotions like anger being much easier to detect
than low-arousal states like concentration.

</details>


### [63] [Error-Guided Pose Augmentation: Enhancing Rehabilitation Exercise Assessment through Targeted Data Generation](https://arxiv.org/abs/2506.09833)
*Omar Sherif,Ali Hamdi*

Main category: cs.CL

TL;DR: 论文提出了一种名为EGPA的方法，通过模拟临床相关运动错误生成合成骨骼数据，结合注意力图卷积网络，显著提升了康复评估的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有康复评估系统在家庭环境中面临数据不平衡和难以检测细微运动错误的挑战，需要更有效的方法。

Method: 采用Error-Guided Pose Augmentation (EGPA)生成合成骨骼数据，并结合注意力图卷积网络进行运动质量评估。

Result: 实验显示，EGPA将平均绝对误差降低27.6%，错误分类准确率提升45.8%，并能聚焦临床关键关节和运动阶段。

Conclusion: EGPA为临床和家庭康复中的自动化运动质量评估提供了一种有前景的方法。

Abstract: Effective rehabilitation assessment is essential for monitoring patient
progress, particularly in home-based settings. Existing systems often face
challenges such as data imbalance and difficulty detecting subtle movement
errors. This paper introduces Error-Guided Pose Augmentation (EGPA), a method
that generates synthetic skeleton data by simulating clinically relevant
movement mistakes. Unlike standard augmentation techniques, EGPA targets
biomechanical errors observed in rehabilitation. Combined with an
attention-based graph convolutional network, EGPA improves performance across
multiple evaluation metrics. Experiments demonstrate reductions in mean
absolute error of up to 27.6 percent and gains in error classification accuracy
of 45.8 percent. Attention visualizations show that the model learns to focus
on clinically significant joints and movement phases, enhancing both accuracy
and interpretability. EGPA offers a promising approach for improving automated
movement quality assessment in both clinical and home-based rehabilitation
contexts.

</details>


### [64] [Dataset of News Articles with Provenance Metadata for Media Relevance Assessment](https://arxiv.org/abs/2506.09847)
*Tomas Peterka,Matyas Bohacek*

Main category: cs.CL

TL;DR: 论文提出了一种新闻媒体来源数据集，用于检测图像与文本的上下文是否匹配，并设计了两个任务（LOR和DTOR），测试了六种大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注图像语义与文本叙事是否一致，忽略了图像来源的上下文匹配问题，导致检测不准确。

Method: 构建新闻媒体来源数据集，设计LOR和DTOR任务，测试六种大型语言模型的零样本性能。

Result: LOR任务表现较好，但DTOR任务表现不佳，需进一步优化模型架构。

Conclusion: 研究揭示了图像来源上下文检测的重要性，并为未来工作提供了方向。

Abstract: Out-of-context and misattributed imagery is the leading form of media
manipulation in today's misinformation and disinformation landscape. The
existing methods attempting to detect this practice often only consider whether
the semantics of the imagery corresponds to the text narrative, missing
manipulation so long as the depicted objects or scenes somewhat correspond to
the narrative at hand. To tackle this, we introduce News Media Provenance
Dataset, a dataset of news articles with provenance-tagged images. We formulate
two tasks on this dataset, location of origin relevance (LOR) and date and time
of origin relevance (DTOR), and present baseline results on six large language
models (LLMs). We identify that, while the zero-shot performance on LOR is
promising, the performance on DTOR hinders, leaving room for specialized
architectures and future work.

</details>


### [65] [Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.09853)
*Xiangning Yu,Zhuohan Wang,Linyi Yang,Haoxuan Li,Anjie Liu,Xiao Xue,Jun Wang,Mengyue Yang*

Main category: cs.CL

TL;DR: 论文提出了一种因果框架，通过充分性和必要性分析改进CoT提示，提升LLM的推理效率和成本效益。


<details>
  <summary>Details</summary>
Motivation: 解决CoT提示在充分性和必要性方面的挑战，优化LLM的推理能力。

Method: 采用因果框架，结合充分性和必要性概率，自动添加缺失步骤并修剪冗余步骤。

Result: 在数学和常识推理基准测试中显著提升效率，减少token使用且不牺牲准确性。

Conclusion: 该框架为提升LLM推理性能和成本效益提供了有前景的方向。

Abstract: Chain-of-Thought (CoT) prompting plays an indispensable role in endowing
large language models (LLMs) with complex reasoning capabilities. However, CoT
currently faces two fundamental challenges: (1) Sufficiency, which ensures that
the generated intermediate inference steps comprehensively cover and
substantiate the final conclusion; and (2) Necessity, which identifies the
inference steps that are truly indispensable for the soundness of the resulting
answer. We propose a causal framework that characterizes CoT reasoning through
the dual lenses of sufficiency and necessity. Incorporating causal Probability
of Sufficiency and Necessity allows us not only to determine which steps are
logically sufficient or necessary to the prediction outcome, but also to
quantify their actual influence on the final reasoning outcome under different
intervention scenarios, thereby enabling the automated addition of missing
steps and the pruning of redundant ones. Extensive experimental results on
various mathematical and commonsense reasoning benchmarks confirm substantial
improvements in reasoning efficiency and reduced token usage without
sacrificing accuracy. Our work provides a promising direction for improving LLM
reasoning performance and cost-effectiveness.

</details>


### [66] [Attention Head Embeddings with Trainable Deep Kernels for Hallucination Detection in LLMs](https://arxiv.org/abs/2506.09886)
*Rodion Oblovatny,Alexandra Bazarova,Alexey Zaytsev*

Main category: cs.CL

TL;DR: 提出了一种通过分析提示与响应隐藏状态分布的概率差异来检测大语言模型幻觉的新方法，发现幻觉响应与提示的偏差较小，并基于此提出了一种无需外部知识的检测方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中幻觉检测的问题，避免依赖外部知识或辅助模型。

Method: 通过分析提示与响应隐藏状态分布的概率差异，利用分布距离作为幻觉分数，并采用深度学习可调核增强敏感性。

Result: 在多个基准测试中表现优于现有基线，即使不进行核训练也能保持竞争力。

Conclusion: 该方法为幻觉检测提供了鲁棒且可扩展的解决方案。

Abstract: We present a novel approach for detecting hallucinations in large language
models (LLMs) by analyzing the probabilistic divergence between prompt and
response hidden-state distributions. Counterintuitively, we find that
hallucinated responses exhibit smaller deviations from their prompts compared
to grounded responses, suggesting that hallucinations often arise from
superficial rephrasing rather than substantive reasoning. Leveraging this
insight, we propose a model-intrinsic detection method that uses distributional
distances as principled hallucination scores, eliminating the need for external
knowledge or auxiliary models. To enhance sensitivity, we employ deep learnable
kernels that automatically adapt to capture nuanced geometric differences
between distributions. Our approach outperforms existing baselines,
demonstrating state-of-the-art performance on several benchmarks. The method
remains competitive even without kernel training, offering a robust, scalable
solution for hallucination detection.

</details>


### [67] [The Emergence of Abstract Thought in Large Language Models Beyond Any Language](https://arxiv.org/abs/2506.09890)
*Yuxin Chen,Yiran Zhao,Yang Zhang,An Zhang,Kenji Kawaguchi,Shafiq Joty,Junnan Li,Tat-Seng Chua,Michael Qizhe Shieh,Wenxuan Zhang*

Main category: cs.CL

TL;DR: 研究发现大语言模型（LLMs）逐渐发展出一个核心语言无关参数空间，支持跨语言的抽象思维。


<details>
  <summary>Details</summary>
Motivation: 挑战LLMs以英语为核心思维的假设，探索其多语言能力的本质。

Method: 识别语言相关神经元，分为共享和独占两类，并提出针对性的训练策略。

Result: 共享神经元比例和功能重要性增加，支持语言无关的抽象思维。

Conclusion: LLMs的核心语言无关参数空间是其多语言能力的关键，神经元特定训练策略有效。

Abstract: As large language models (LLMs) continue to advance, their capacity to
function effectively across a diverse range of languages has shown marked
improvement. Preliminary studies observe that the hidden activations of LLMs
often resemble English, even when responding to non-English prompts. This has
led to the widespread assumption that LLMs may "think" in English. However,
more recent results showing strong multilingual performance, even surpassing
English performance on specific tasks in other languages, challenge this view.
In this work, we find that LLMs progressively develop a core language-agnostic
parameter space-a remarkably small subset of parameters whose deactivation
results in significant performance degradation across all languages. This
compact yet critical set of parameters underlies the model's ability to
generalize beyond individual languages, supporting the emergence of abstract
thought that is not tied to any specific linguistic system. Specifically, we
identify language-related neurons-those are consistently activated during the
processing of particular languages, and categorize them as either shared
(active across multiple languages) or exclusive (specific to one). As LLMs
undergo continued development over time, we observe a marked increase in both
the proportion and functional importance of shared neurons, while exclusive
neurons progressively diminish in influence. These shared neurons constitute
the backbone of the core language-agnostic parameter space, supporting the
emergence of abstract thought. Motivated by these insights, we propose
neuron-specific training strategies tailored to LLMs' language-agnostic levels
at different development stages. Experiments across diverse LLM families
support our approach.

</details>


### [68] [PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants](https://arxiv.org/abs/2506.09902)
*Zheng Zhao,Clara Vania,Subhradeep Kayal,Naila Khan,Shay B. Cohen,Emine Yilmaz*

Main category: cs.CL

TL;DR: PersonaLens是一个用于评估任务导向AI助手个性化能力的综合基准，解决了现有基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能全面评估个性化任务导向助手的复杂性，因此需要更全面的评估工具。

Method: 引入PersonaLens基准，包含多样用户配置文件和两个基于LLM的代理（用户代理和法官代理），用于评估个性化、响应质量和任务成功。

Result: 实验显示当前LLM助手在个性化能力上存在显著差异。

Conclusion: PersonaLens为提升对话AI系统提供了关键见解。

Abstract: Large language models (LLMs) have advanced conversational AI assistants.
However, systematically evaluating how well these assistants apply
personalization--adapting to individual user preferences while completing
tasks--remains challenging. Existing personalization benchmarks focus on
chit-chat, non-conversational tasks, or narrow domains, failing to capture the
complexities of personalized task-oriented assistance. To address this, we
introduce PersonaLens, a comprehensive benchmark for evaluating personalization
in task-oriented AI assistants. Our benchmark features diverse user profiles
equipped with rich preferences and interaction histories, along with two
specialized LLM-based agents: a user agent that engages in realistic
task-oriented dialogues with AI assistants, and a judge agent that employs the
LLM-as-a-Judge paradigm to assess personalization, response quality, and task
success. Through extensive experiments with current LLM assistants across
diverse tasks, we reveal significant variability in their personalization
capabilities, providing crucial insights for advancing conversational AI
systems.

</details>


### [69] [Aspect-Based Opinion Summarization with Argumentation Schemes](https://arxiv.org/abs/2506.09917)
*Wendi Zhou,Ameer Saadat-Yazd,Nadin Kokciyan*

Main category: cs.CL

TL;DR: 论文提出了一种名为ASESUM的新型摘要系统，能够从产品评论中提取关键观点并生成基于方面的摘要，无需预定义方面集。


<details>
  <summary>Details</summary>
Motivation: 在线购物中，用户难以手动处理大量评论以提取主要观点，因此需要自动化的观点摘要系统。

Method: 提出ASESUM框架，通过提取基于方面的论点并衡量其显著性和有效性，生成摘要。

Result: 实验证明ASESUM在捕捉原始评论的多样化观点上优于现有方法。

Conclusion: ASESUM能够有效生成基于方面的摘要，适应不同领域且无需预定义方面。

Abstract: Reviews are valuable resources for customers making purchase decisions in
online shopping. However, it is impractical for customers to go over the vast
number of reviews and manually conclude the prominent opinions, which prompts
the need for automated opinion summarization systems. Previous approaches,
either extractive or abstractive, face challenges in automatically producing
grounded aspect-centric summaries. In this paper, we propose a novel
summarization system that not only captures predominant opinions from an aspect
perspective with supporting evidence, but also adapts to varying domains
without relying on a pre-defined set of aspects. Our proposed framework,
ASESUM, summarizes viewpoints relevant to the critical aspects of a product by
extracting aspect-centric arguments and measuring their salience and validity.
We conduct experiments on a real-world dataset to demonstrate the superiority
of our approach in capturing diverse perspectives of the original reviews
compared to new and existing methods.

</details>


### [70] [VerIF: Verification Engineering for Reinforcement Learning in Instruction Following](https://arxiv.org/abs/2506.09942)
*Hao Peng,Yunjia Qi,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 论文提出了一种结合规则代码验证和LLM验证的强化学习方法VerIF，用于提升指令跟随能力，并在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习中指令跟随的验证挑战，提出高效验证方法以提升模型性能。

Method: 结合规则代码验证和大型推理模型（如QwQ-32B）的LLM验证，构建高质量数据集VerInstruct（22,000实例）。

Result: 在多个指令跟随基准测试中显著提升性能，模型达到同类尺寸中的最优水平，且不影响通用能力。

Conclusion: VerIF可集成到现有强化学习流程中，提升整体模型性能，相关资源已开源。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a key
technique for enhancing large language models (LLMs), with verification
engineering playing a central role. However, best practices for RL in
instruction following remain underexplored. In this work, we explore the
verification challenge in RL for instruction following and propose VerIF, a
verification method that combines rule-based code verification with LLM-based
verification from a large reasoning model (e.g., QwQ-32B). To support this
approach, we construct a high-quality instruction-following dataset,
VerInstruct, containing approximately 22,000 instances with associated
verification signals. We apply RL training with VerIF to two models, achieving
significant improvements across several representative instruction-following
benchmarks. The trained models reach state-of-the-art performance among models
of comparable size and generalize well to unseen constraints. We further
observe that their general capabilities remain unaffected, suggesting that RL
with VerIF can be integrated into existing RL recipes to enhance overall model
performance. We have released our datasets, codes, and models to facilitate
future research at https://github.com/THU-KEG/VerIF.

</details>


### [71] [Query-Focused Retrieval Heads Improve Long-Context Reasoning and Re-ranking](https://arxiv.org/abs/2506.09944)
*Wuwei Zhang,Fangcong Yin,Howard Yen,Danqi Chen,Xi Ye*

Main category: cs.CL

TL;DR: 论文提出QRHEAD和QR-RETRIEVER，通过聚焦查询的注意力机制提升长上下文检索性能，在多跳推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有检索头在长上下文语言模型中表现有限，需改进以提升信息检索效率。

Method: 通过聚合输入查询的注意力分数识别QRHEAD，并开发QR-RETRIEVER作为高效检索器。

Result: 在LongMemEval和CLIPPER任务中性能提升10%，BEIR基准测试中零样本表现优于RankGPT。

Conclusion: QRHEAD和QR-RETRIEVER为通用检索器，同时增强了对长上下文能力的可解释性。

Abstract: Recent work has identified retrieval heads (Wu et al., 2025b), a subset of
attention heads responsible for retrieving salient information in long-context
language models (LMs), as measured by their copy-paste behavior in
Needle-in-a-Haystack tasks. In this paper, we introduce QRHEAD (Query-Focused
Retrieval Head), an improved set of attention heads that enhance retrieval from
long context. We identify QRHEAD by aggregating attention scores with respect
to the input query, using a handful of examples from real-world tasks (e.g.,
long-context QA). We further introduce QR- RETRIEVER, an efficient and
effective retriever that uses the accumulated attention mass of QRHEAD as
retrieval scores. We use QR- RETRIEVER for long-context reasoning by selecting
the most relevant parts with the highest retrieval scores. On multi-hop
reasoning tasks LongMemEval and CLIPPER, this yields over 10% performance gains
over full context and outperforms strong dense retrievers. We also evaluate
QRRETRIEVER as a re-ranker on the BEIR benchmark and find that it achieves
strong zero-shot performance, outperforming other LLM-based re-rankers such as
RankGPT. Further analysis shows that both the querycontext attention scoring
and task selection are crucial for identifying QRHEAD with strong downstream
utility. Overall, our work contributes a general-purpose retriever and offers
interpretability insights into the long-context capabilities of LMs.

</details>


### [72] [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org/abs/2506.09967)
*Shangshang Wang,Julian Asilis,Ömer Faruk Akgül,Enes Burak Bilgin,Ollie Liu,Deqing Fu,Willie Neiswanger*

Main category: cs.CL

TL;DR: Resa模型通过稀疏自编码器调优（SAE-Tuning）高效提取语言模型的推理能力，显著降低成本和时间。


<details>
  <summary>Details</summary>
Motivation: 研究如何高效且低成本地从语言模型中提取和增强推理能力。

Method: 使用稀疏自编码器（SAE）从源模型中捕获推理能力，并通过监督微调将其转移到目标模型。

Result: SAE-Tuning在极低成本（约1美元）和短时间内（约20分钟）实现接近RL训练的推理性能（>97%）。

Conclusion: SAE-Tuning是一种高效、通用且模块化的方法，能够显著提升语言模型的推理能力。

Abstract: How cost-effectively can we elicit strong reasoning in language models by
leveraging their underlying representations? We answer this question with Resa,
a family of 1.5B reasoning models trained via a novel and efficient sparse
autoencoder tuning (SAE-Tuning) procedure. This method first trains an SAE to
capture reasoning abilities from a source model, and then uses the trained SAE
to guide a standard supervised fine-tuning process to elicit such abilities in
a target model, all using verified question-answer data without any reasoning
traces. Notably, when applied to certain base models before further RL
post-training, SAE-Tuning retains >97% of its RL-trained counterpart's
reasoning performance while reducing training costs by >2000x to roughly \$1
and training time by >450x to around 20 minutes. Furthermore, when applied to
lightly RL-trained models (e.g., within 1 hour on 2 GPUs), it enables reasoning
performance such as 43.33% Pass@1 on AIME24 and 90% Pass@1 on AMC23 for only
around \$1 additional cost. Surprisingly, the reasoning abilities extracted via
SAEs are potentially both generalizable and modular. Generality means abilities
extracted from one dataset still elevate performance on a larger and
overlapping corpus. Modularity means abilities extracted from Qwen or Qwen-Math
can be attached to the R1-Distill model at test time, without any retraining,
and yield comparable gains. Extensive ablations validate these findings and all
artifacts are fully open-sourced.

</details>


### [73] [When Detection Fails: The Power of Fine-Tuned Models to Generate Human-Like Social Media Text](https://arxiv.org/abs/2506.09975)
*Hillary Dawkins,Kathleen C. Fraser,Svetlana Kiritchenko*

Main category: cs.CL

TL;DR: 论文研究了社交媒体上AI生成文本的检测问题，发现现有方法在攻击者不公开微调模型的情况下效果显著下降。


<details>
  <summary>Details</summary>
Motivation: 社交媒体是影响力攻击的重要载体，AI生成内容可能被大规模用于支持或反对特定政策，因此检测此类内容至关重要。

Method: 研究团队模拟高级威胁行为者，构建了一个包含505,159条AI生成社交媒体帖子的数据集，覆盖11个争议话题，并测试了不同检测算法的效果。

Result: 在攻击者不公开微调模型的现实假设下，检测效果大幅下降，人类实验也验证了这一结果。

Conclusion: 微调模型对检测算法构成普遍威胁，这一发现对所有检测领域均有重要影响。

Abstract: Detecting AI-generated text is a difficult problem to begin with; detecting
AI-generated text on social media is made even more difficult due to the short
text length and informal, idiosyncratic language of the internet. It is
nonetheless important to tackle this problem, as social media represents a
significant attack vector in online influence campaigns, which may be bolstered
through the use of mass-produced AI-generated posts supporting (or opposing)
particular policies, decisions, or events. We approach this problem with the
mindset and resources of a reasonably sophisticated threat actor, and create a
dataset of 505,159 AI-generated social media posts from a combination of
open-source, closed-source, and fine-tuned LLMs, covering 11 different
controversial topics. We show that while the posts can be detected under
typical research assumptions about knowledge of and access to the generating
models, under the more realistic assumption that an attacker will not release
their fine-tuned model to the public, detectability drops dramatically. This
result is confirmed with a human study. Ablation experiments highlight the
vulnerability of various detection algorithms to fine-tuned LLMs. This result
has implications across all detection domains, since fine-tuning is a generally
applicable and realistic LLM use case.

</details>


### [74] [Step-by-step Instructions and a Simple Tabular Output Format Improve the Dependency Parsing Accuracy of LLMs](https://arxiv.org/abs/2506.09983)
*Hiroshi Matsuda,Chunpeng Ma,Masayuki Asahara*

Main category: cs.CL

TL;DR: 提出一种分步指令策略，结合通用词性标注和简化输出格式，在17种语言的依存解析任务中实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 标准提示方法在生成结构有效且准确的输出（尤其是依存解析）时表现不佳。

Method: 采用分步指令策略，先进行通用词性标注，再预测句法头和依存标签，并使用简化的CoNLL-U格式输出。

Result: 在17种语言的Universal Dependencies数据集上达到最佳精度，且无幻觉或污染，多语言微调还提升了跨语言泛化性能。

Conclusion: 分步推理策略在基于LLM的解析中有效，并为基于括号的方法提供了可扩展且格式一致的替代方案。

Abstract: Recent advances in large language models (LLMs) have enabled impressive
performance in various tasks. However, standard prompting often struggles to
produce structurally valid and accurate outputs, especially in dependency
parsing. We propose a novel step-by-step instruction strategy, where universal
part-of-speech tagging precedes the prediction of syntactic heads and
dependency labels, and a simplified CoNLL-U like output format, our method
achieves state-of-the-art accuracy on Universal Dependencies datasets across 17
languages without hallucination or contamination. We further show that
multilingual fine-tuning simultaneously improves cross-language generalization
performance. Our results highlight the effectiveness of explicit reasoning
steps in LLM-based parsing and offer a scalable, format-consistent alternative
to bracket-based approaches.

</details>


### [75] [Large Language Models for Toxic Language Detection in Low-Resource Balkan Languages](https://arxiv.org/abs/2506.09992)
*Amel Muminovic,Amela Kadric Muminovic*

Main category: cs.CL

TL;DR: 研究评估了大型语言模型在塞尔维亚语、克罗地亚语和波斯尼亚语中处理有毒评论的能力，发现上下文增强模式能显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 在线有毒语言对缺乏审核工具的地区造成实际危害，研究旨在填补这些语言中标记数据不足的空白。

Method: 构建并手动标记了4500条YouTube和TikTok评论数据集，测试了四种模型在零样本和上下文增强模式下的表现。

Result: 上下文增强模式平均提升召回率0.12，F1分数最高提升0.10；Gemini在上下文增强模式下表现最佳。

Conclusion: 研究表明，简单的提示设计和上下文增强能显著提升低资源语言中有毒语言的检测效果。

Abstract: Online toxic language causes real harm, especially in regions with limited
moderation tools. In this study, we evaluate how large language models handle
toxic comments in Serbian, Croatian, and Bosnian, languages with limited
labeled data. We built and manually labeled a dataset of 4,500 YouTube and
TikTok comments drawn from videos across diverse categories, including music,
politics, sports, modeling, influencer content, discussions of sexism, and
general topics. Four models (GPT-3.5 Turbo, GPT-4.1, Gemini 1.5 Pro, and Claude
3 Opus) were tested in two modes: zero-shot and context-augmented. We measured
precision, recall, F1 score, accuracy and false positive rates. Including a
short context snippet raised recall by about 0.12 on average and improved F1
score by up to 0.10, though it sometimes increased false positives. The best
balance came from Gemini in context-augmented mode, reaching an F1 score of
0.82 and accuracy of 0.82, while zero-shot GPT-4.1 led on precision and had the
lowest false alarms. We show how adding minimal context can improve toxic
language detection in low-resource settings and suggest practical strategies
such as improved prompt design and threshold calibration. These results show
that prompt design alone can yield meaningful gains in toxicity detection for
underserved Balkan language communities.

</details>


### [76] [From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring](https://arxiv.org/abs/2506.09996)
*Yang Li,Qiang Sheng,Yehan Yang,Xueyao Zhang,Juan Cao*

Main category: cs.CL

TL;DR: 论文提出了一种支持部分检测的数据与模型解决方案，通过构建FineHarm数据集和流式内容监控器（SCM），显著降低了服务延迟并提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有审核器基于完整输出的检测方式导致高延迟，而直接应用全检测训练的模型到部分输出会引入性能下降。

Method: 构建FineHarm数据集，提出流式内容监控器（SCM），通过双监督训练实现及时有害性判断。

Result: SCM仅需查看平均18%的响应令牌即可达到与全检测相当的F1分数（0.95+），并能提升安全对齐效果。

Conclusion: SCM是一种高效的部分检测解决方案，显著提升性能并降低延迟。

Abstract: Though safety alignment has been applied to most large language models
(LLMs), LLM service providers generally deploy a subsequent moderation as the
external safety guardrail in real-world products. Existing moderators mainly
practice a conventional full detection, which determines the harmfulness based
on the complete LLM output, causing high service latency. Recent works pay more
attention to partial detection where moderators oversee the generation midway
and early stop the output if harmfulness is detected, but they directly apply
moderators trained with the full detection paradigm to incomplete outputs,
introducing a training-inference gap that lowers the performance. In this
paper, we explore how to form a data-and-model solution that natively supports
partial detection. For the data, we construct FineHarm, a dataset consisting of
29K prompt-response pairs with fine-grained annotations to provide reasonable
supervision for token-level training. Then, we propose the streaming content
monitor, which is trained with dual supervision of response- and token-level
labels and can follow the output stream of LLM to make a timely judgment of
harmfulness. Experiments show that SCM gains 0.95+ in macro F1 score that is
comparable to full detection, by only seeing the first 18% of tokens in
responses on average. Moreover, the SCM can serve as a pseudo-harmfulness
annotator for improving safety alignment and lead to a higher harmlessness
score than DPO.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [77] [HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios](https://arxiv.org/abs/2506.09650)
*Kunyu Peng,Junchao Huang,Xiangsheng Huang,Di Wen,Junwei Zheng,Yufan Chen,Kailun Yang,Jiamin Wu,Chongqing Hao,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 该论文提出了一种基于文本参考的多人物动作分割方法，并引入了首个相关数据集RHAS133。通过HopaDIFF框架，结合跨输入门注意力xLSTM和傅里叶条件，显著提升了动作分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单人固定动作序列，忽略了多人场景的需求。本文旨在解决多人动作分割问题，并通过文本描述指定目标人物。

Method: 提出了HopaDIFF框架，结合跨输入门注意力xLSTM和傅里叶条件，增强整体-局部长程推理和细粒度控制。

Result: HopaDIFF在RHAS133数据集上实现了最先进的性能。

Conclusion: 该方法为多人动作分割提供了有效解决方案，并通过实验验证了其优越性。

Abstract: Action segmentation is a core challenge in high-level video understanding,
aiming to partition untrimmed videos into segments and assign each a label from
a predefined action set. Existing methods primarily address single-person
activities with fixed action sequences, overlooking multi-person scenarios. In
this work, we pioneer textual reference-guided human action segmentation in
multi-person settings, where a textual description specifies the target person
for segmentation. We introduce the first dataset for Referring Human Action
Segmentation, i.e., RHAS133, built from 133 movies and annotated with 137
fine-grained actions with 33h video data, together with textual descriptions
for this new task. Benchmarking existing action recognition methods on RHAS133
using VLM-based feature extractors reveals limited performance and poor
aggregation of visual cues for the target person. To address this, we propose a
holistic-partial aware Fourier-conditioned diffusion framework, i.e., HopaDIFF,
leveraging a novel cross-input gate attentional xLSTM to enhance
holistic-partial long-range reasoning and a novel Fourier condition to
introduce more fine-grained control to improve the action segmentation
generation. HopaDIFF achieves state-of-the-art results on RHAS133 in diverse
evaluation settings. The code is available at
https://github.com/KPeng9510/HopaDIFF.git.

</details>


### [78] [ReStNet: A Reusable & Stitchable Network for Dynamic Adaptation on IoT Devices](https://arxiv.org/abs/2506.09066)
*Maoyu Wang,Yao Lu,Jiaqi Nie,Zeyu Wang,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.CV

TL;DR: ReStNet提出了一种动态缝合预训练模型的方法，以适应异构设备资源，实现灵活的效率-精度权衡。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型在异构设备上部署的挑战，传统压缩方法缺乏灵活性。

Method: 通过CKA计算层间相似度选择缝合点，结合大模型早期层和小模型深层，仅微调缝合层。

Result: 在多个基准测试中实现灵活的效率-精度权衡，显著降低训练成本。

Conclusion: ReStNet为异构设备部署提供了高效灵活的解决方案。

Abstract: With the rapid development of deep learning, a growing number of pre-trained
models have been publicly available. However, deploying these fixed models in
real-world IoT applications is challenging because different devices possess
heterogeneous computational and memory resources, making it impossible to
deploy a single model across all platforms. Although traditional compression
methods, such as pruning, quantization, and knowledge distillation, can improve
efficiency, they become inflexible once applied and cannot adapt to changing
resource constraints. To address these issues, we propose ReStNet, a Reusable
and Stitchable Network that dynamically constructs a hybrid network by
stitching two pre-trained models together. Implementing ReStNet requires
addressing several key challenges, including how to select the optimal
stitching points, determine the stitching order of the two pre-trained models,
and choose an effective fine-tuning strategy. To systematically address these
challenges and adapt to varying resource constraints, ReStNet determines the
stitching point by calculating layer-wise similarity via Centered Kernel
Alignment (CKA). It then constructs the hybrid model by retaining early layers
from a larger-capacity model and appending deeper layers from a smaller one. To
facilitate efficient deployment, only the stitching layer is fine-tuned. This
design enables rapid adaptation to changing budgets while fully leveraging
available resources. Moreover, ReStNet supports both homogeneous (CNN-CNN,
Transformer-Transformer) and heterogeneous (CNN-Transformer) stitching,
allowing to combine different model families flexibly. Extensive experiments on
multiple benchmarks demonstrate that ReStNet achieve flexible
accuracy-efficiency trade-offs at runtime while significantly reducing training
cost.

</details>


### [79] [Enhancing the Safety of Medical Vision-Language Models by Synthetic Demonstrations](https://arxiv.org/abs/2506.09067)
*Zhiyu Xue,Reza Abbasi-Asl,Ramtin Pedarsani*

Main category: cs.CV

TL;DR: 本文提出了一种新型推理时防御策略，用于减少生成式医学视觉-语言模型（Med-VLMs）对有害查询的响应，同时避免过度防御影响性能。


<details>
  <summary>Details</summary>
Motivation: Med-VLMs在生成复杂医学文本时可能面临安全漏洞，如处理有害查询或遭受视觉和文本越狱攻击，需平衡安全性与性能。

Method: 采用基于合成临床演示的推理时防御策略，并通过多模态医学影像数据集验证其有效性。

Result: 防御策略显著提升模型安全性且未显著降低性能，增加演示预算可缓解过度防御问题。

Conclusion: 混合演示策略在少样本预算下平衡了安全性与性能，为Med-VLMs的安全应用提供了可行方案。

Abstract: Generative medical vision-language models~(Med-VLMs) are primarily designed
to generate complex textual information~(e.g., diagnostic reports) from
multimodal inputs including vision modality~(e.g., medical images) and language
modality~(e.g., clinical queries). However, their security vulnerabilities
remain underexplored. Med-VLMs should be capable of rejecting harmful queries,
such as \textit{Provide detailed instructions for using this CT scan for
insurance fraud}. At the same time, addressing security concerns introduces the
risk of over-defense, where safety-enhancing mechanisms may degrade general
performance, causing Med-VLMs to reject benign clinical queries. In this paper,
we propose a novel inference-time defense strategy to mitigate harmful queries,
enabling defense against visual and textual jailbreak attacks. Using diverse
medical imaging datasets collected from nine modalities, we demonstrate that
our defense strategy based on synthetic clinical demonstrations enhances model
safety without significantly compromising performance. Additionally, we find
that increasing the demonstration budget alleviates the over-defense issue. We
then introduce a mixed demonstration strategy as a trade-off solution for
balancing security and performance under few-shot demonstration budget
constraints.

</details>


### [80] [BG-HOP: A Bimanual Generative Hand-Object Prior](https://arxiv.org/abs/2506.09068)
*Sriram Krishna,Sravan Chittupalli,Sungjae Park*

Main category: cs.CV

TL;DR: BG-HOP是一种生成先验模型，用于3D双手-物体交互建模，通过扩展单手生成先验解决数据不足问题。


<details>
  <summary>Details</summary>
Motivation: 解决双手交互数据有限的问题。

Method: 扩展单手生成先验，建模双手与物体的联合分布。

Result: 模型能生成双手交互并为给定物体合成抓取动作。

Conclusion: 代码和模型已公开。

Abstract: In this work, we present BG-HOP, a generative prior that seeks to model
bimanual hand-object interactions in 3D. We address the challenge of limited
bimanual interaction data by extending existing single-hand generative priors,
demonstrating preliminary results in capturing the joint distribution of hands
and objects. Our experiments showcase the model's capability to generate
bimanual interactions and synthesize grasps for given objects. We make code and
models publicly available.

</details>


### [81] [Segment Any Architectural Facades (SAAF):An automatic segmentation model for building facades, walls and windows based on multimodal semantics guidance](https://arxiv.org/abs/2506.09071)
*Peilin Li,Jun Yin,Jing Zhong,Ran Luo,Pengyu Zeng,Miao Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于多模态语义引导的建筑立面墙窗自动分割模型SAAF，通过结合自然语言处理技术提升语义理解能力，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在建筑数字化发展的背景下，提高建筑信息模型和计算机辅助设计的效率需要自动化的墙窗分割技术。

Method: SAAF采用多模态语义协作特征提取机制和端到端训练框架，结合文本描述与图像特征，减少人工干预。

Result: 在多个立面数据集上的实验显示，SAAF在mIoU指标上优于现有方法，具有高精度和泛化能力。

Conclusion: SAAF为建筑计算机视觉技术提供了新思路，同时探索了多模态学习在建筑领域的应用潜力。

Abstract: In the context of the digital development of architecture, the automatic
segmentation of walls and windows is a key step in improving the efficiency of
building information models and computer-aided design. This study proposes an
automatic segmentation model for building facade walls and windows based on
multimodal semantic guidance, called Segment Any Architectural Facades (SAAF).
First, SAAF has a multimodal semantic collaborative feature extraction
mechanism. By combining natural language processing technology, it can fuse the
semantic information in text descriptions with image features, enhancing the
semantic understanding of building facade components. Second, we developed an
end-to-end training framework that enables the model to autonomously learn the
mapping relationship from text descriptions to image segmentation, reducing the
influence of manual intervention on the segmentation results and improving the
automation and robustness of the model. Finally, we conducted extensive
experiments on multiple facade datasets. The segmentation results of SAAF
outperformed existing methods in the mIoU metric, indicating that the SAAF
model can maintain high-precision segmentation ability when faced with diverse
datasets. Our model has made certain progress in improving the accuracy and
generalization ability of the wall and window segmentation task. It is expected
to provide a reference for the development of architectural computer vision
technology and also explore new ideas and technical paths for the application
of multimodal learning in the architectural field.

</details>


### [82] [VersaVid-R1: A Versatile Video Understanding and Reasoning Model from Question Answering to Captioning Tasks](https://arxiv.org/abs/2506.09079)
*Xinlong Chen,Yuanxing Zhang,Yushuo Guan,Bohan Zeng,Yang Shi,Sihan Yang,Pengfei Wan,Qiang Liu,Liang Wang,Tieniu Tan*

Main category: cs.CV

TL;DR: 论文提出了两个新数据集DarkEventInfer和MixVidQA，用于提升视频理解和推理能力，并开发了首个多任务视频理解与推理模型VersaVid-R1，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 视频推理领域因缺乏高质量数据和有效训练方法而发展不足，需填补这一空白。

Method: 引入两个新数据集，结合强化学习训练多任务模型VersaVid-R1。

Result: VersaVid-R1在多项基准测试中显著优于现有模型。

Conclusion: 新数据集和模型成功推动了视频推理领域的发展。

Abstract: Recent advancements in multimodal large language models have successfully
extended the Reason-Then-Respond paradigm to image-based reasoning, yet
video-based reasoning remains an underdeveloped frontier, primarily due to the
scarcity of high-quality reasoning-oriented data and effective training
methodologies. To bridge this gap, we introduce DarkEventInfer and MixVidQA,
two novel datasets specifically designed to stimulate the model's advanced
video understanding and reasoning abilities. DarkEventinfer presents videos
with masked event segments, requiring models to infer the obscured content
based on contextual video cues. MixVidQA, on the other hand, presents
interleaved video sequences composed of two distinct clips, challenging models
to isolate and reason about one while disregarding the other. Leveraging these
carefully curated training samples together with reinforcement learning guided
by diverse reward functions, we develop VersaVid-R1, the first versatile video
understanding and reasoning model under the Reason-Then-Respond paradigm
capable of handling multiple-choice and open-ended question answering, as well
as video captioning tasks. Extensive experiments demonstrate that VersaVid-R1
significantly outperforms existing models across a broad spectrum of
benchmarks, covering video general understanding, cognitive reasoning, and
captioning tasks.

</details>


### [83] [FlagEvalMM: A Flexible Framework for Comprehensive Multimodal Model Evaluation](https://arxiv.org/abs/2506.09081)
*Zheqi He,Yesheng Liu,Jing-shu Zheng,Xuejing Li,Richeng Xuan,Jin-Ge Yao,Xi Yang*

Main category: cs.CV

TL;DR: FlagEvalMM是一个开源的多模态模型评估框架，支持多种视觉-语言任务，通过独立评估服务和高效工具提升评估效率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型评估缺乏统一且高效的框架，FlagEvalMM旨在填补这一空白。

Method: 通过解耦模型推理与评估，结合异步数据加载和推理加速工具（如vLLM、SGLang）提升效率。

Result: 实验表明FlagEvalMM能准确高效地分析模型优劣势。

Conclusion: FlagEvalMM是一个对多模态研究有价值的工具，已开源。

Abstract: We present FlagEvalMM, an open-source evaluation framework designed to
comprehensively assess multimodal models across a diverse range of
vision-language understanding and generation tasks, such as visual question
answering, text-to-image/video generation, and image-text retrieval. We
decouple model inference from evaluation through an independent evaluation
service, thus enabling flexible resource allocation and seamless integration of
new tasks and models. Moreover, FlagEvalMM utilizes advanced inference
acceleration tools (e.g., vLLM, SGLang) and asynchronous data loading to
significantly enhance evaluation efficiency. Extensive experiments show that
FlagEvalMM offers accurate and efficient insights into model strengths and
limitations, making it a valuable tool for advancing multimodal research. The
framework is publicly accessible athttps://github.com/flageval-baai/FlagEvalMM.

</details>


### [84] [AVA-Bench: Atomic Visual Ability Benchmark for Vision Foundation Models](https://arxiv.org/abs/2506.09082)
*Zheda Mai,Arpita Chowdhury,Zihe Wang,Sooyoung Jeon,Lemeng Wang,Jiacheng Hou,Jihyung Kil,Wei-Lun Chao*

Main category: cs.CV

TL;DR: AVA-Bench是一个新的基准测试，旨在通过解耦14种原子视觉能力（AVAs）来系统评估视觉基础模型（VFMs），解决了现有VQA基准测试中的数据不匹配和能力耦合问题。


<details>
  <summary>Details</summary>
Motivation: 现有VQA基准测试存在数据不匹配和能力耦合问题，无法准确评估VFMs的视觉能力。

Method: 引入AVA-Bench，通过解耦14种AVAs并匹配训练和测试分布，精确评估VFMs的能力。

Result: AVA-Bench揭示了VFMs的独特能力指纹，并发现较小的LLM（0.5B）可以高效替代较大的LLM（7B）进行排名。

Conclusion: AVA-Bench为下一代VFMs的发展提供了全面透明的评估基础。

Abstract: The rise of vision foundation models (VFMs) calls for systematic evaluation.
A common approach pairs VFMs with large language models (LLMs) as
general-purpose heads, followed by evaluation on broad Visual Question
Answering (VQA) benchmarks. However, this protocol has two key blind spots: (i)
the instruction tuning data may not align with VQA test distributions, meaning
a wrong prediction can stem from such data mismatch rather than a VFM' visual
shortcomings; (ii) VQA benchmarks often require multiple visual abilities,
making it hard to tell whether errors stem from lacking all required abilities
or just a single critical one. To address these gaps, we introduce AVA-Bench,
the first benchmark that explicitly disentangles 14 Atomic Visual Abilities
(AVAs) -- foundational skills like localization, depth estimation, and spatial
understanding that collectively support complex visual reasoning tasks. By
decoupling AVAs and matching training and test distributions within each,
AVA-Bench pinpoints exactly where a VFM excels or falters. Applying AVA-Bench
to leading VFMs thus reveals distinctive "ability fingerprints," turning VFM
selection from educated guesswork into principled engineering. Notably, we find
that a 0.5B LLM yields similar VFM rankings as a 7B LLM while cutting GPU hours
by 8x, enabling more efficient evaluation. By offering a comprehensive and
transparent benchmark, we hope AVA-Bench lays the foundation for the next
generation of VFMs.

</details>


### [85] [BakuFlow: A Streamlining Semi-Automatic Label Generation Tool](https://arxiv.org/abs/2506.09083)
*Jerry Lin,Partick P. W. Chen*

Main category: cs.CV

TL;DR: BakuFlow是一款半自动标注工具，通过像素级手动修正、交互式数据增强、标签传播和自动标注模块，显著提升标注效率。


<details>
  <summary>Details</summary>
Motivation: 大规模计算机视觉任务中，手动标注耗时且易错，现有工具仍需人工干预，亟需更高效的解决方案。

Method: BakuFlow结合可调放大镜、数据增强模块、标签传播和基于改进YOLOE的自动标注模块，支持动态扩展类别和视觉提示。

Result: 工具显著减少标注工作量，提升效率，适用于目标检测和跟踪任务。

Conclusion: BakuFlow为动态、真实世界数据集提供了灵活且可扩展的标注方案，适用于工业和计算机视觉场景。

Abstract: Accurately labeling (or annotation) data is still a bottleneck in computer
vision, especially for large-scale tasks where manual labeling is
time-consuming and error-prone. While tools like LabelImg can handle the
labeling task, some of them still require annotators to manually label each
image. In this paper, we introduce BakuFlow, a streamlining semi-automatic
label generation tool. Key features include (1) a live adjustable magnifier for
pixel-precise manual corrections, improving user experience; (2) an interactive
data augmentation module to diversify training datasets; (3) label propagation
for rapidly copying labeled objects between consecutive frames, greatly
accelerating annotation of video data; and (4) an automatic labeling module
powered by a modified YOLOE framework. Unlike the original YOLOE, our extension
supports adding new object classes and any number of visual prompts per class
during annotation, enabling flexible and scalable labeling for dynamic,
real-world datasets. These innovations make BakuFlow especially effective for
object detection and tracking, substantially reducing labeling workload and
improving efficiency in practical computer vision and industrial scenarios.

</details>


### [86] [Bias Analysis in Unconditional Image Generative Models](https://arxiv.org/abs/2506.09106)
*Xiaofeng Zhang,Michelle Lin,Simon Lacoste-Julien,Aaron Courville,Yash Goyal*

Main category: cs.CV

TL;DR: 论文研究了生成式AI模型中的偏见问题，发现偏见机制在无条件生成中仍未明确，并通过实验表明偏见变化较小且对分类器敏感。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型的广泛使用引发了对偏见和歧视性结果的担忧，但偏见机制尤其是无条件生成中的偏见仍未明确。

Method: 训练一组无条件图像生成模型，采用常用偏见评估框架研究训练与生成分布间的偏见变化。

Result: 实验显示检测到的属性变化较小，且对分类器敏感，尤其是当分类器边界位于高密度区域时。

Conclusion: 需改进标签实践、深入评估框架缺陷，并认识属性的社会复杂性以更准确评估偏见。

Abstract: The widespread adoption of generative AI models has raised growing concerns
about representational harm and potential discriminatory outcomes. Yet, despite
growing literature on this topic, the mechanisms by which bias emerges -
especially in unconditional generation - remain disentangled. We define the
bias of an attribute as the difference between the probability of its presence
in the observed distribution and its expected proportion in an ideal reference
distribution. In our analysis, we train a set of unconditional image generative
models and adopt a commonly used bias evaluation framework to study bias shift
between training and generated distributions. Our experiments reveal that the
detected attribute shifts are small. We find that the attribute shifts are
sensitive to the attribute classifier used to label generated images in the
evaluation framework, particularly when its decision boundaries fall in
high-density regions. Our empirical analysis indicates that this classifier
sensitivity is often observed in attributes values that lie on a spectrum, as
opposed to exhibiting a binary nature. This highlights the need for more
representative labeling practices, understanding the shortcomings through
greater scrutiny of evaluation frameworks, and recognizing the socially complex
nature of attributes when evaluating bias.

</details>


### [87] [CAIRe: Cultural Attribution of Images by Retrieval-Augmented Evaluation](https://arxiv.org/abs/2506.09109)
*Arnav Yayavaram,Siddharth Yayavaram,Simran Khanuja,Michael Saxon,Graham Neubig*

Main category: cs.CV

TL;DR: 论文提出了一种名为CAIRe的新评估指标，用于衡量图像的文化相关性，解决了跨文化偏见测量不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像模型的普及，确保其在不同文化背景下的公平性能至关重要，但现有方法在减少跨文化偏见时存在性能损失或输出不准确的问题。

Method: CAIRe通过将图像中的实体和概念与知识库关联，利用事实信息为每个文化标签提供独立的分级判断。

Result: CAIRe在手动构建的数据集上比基线方法提高了28%的F1分数，并在两个文化通用概念数据集上与人类评分的相关性分别达到0.56和0.66。

Conclusion: CAIRe能够有效评估图像的文化相关性，并与人类判断高度一致，为跨文化偏见的测量提供了可靠工具。

Abstract: As text-to-image models become increasingly prevalent, ensuring their
equitable performance across diverse cultural contexts is critical. Efforts to
mitigate cross-cultural biases have been hampered by trade-offs, including a
loss in performance, factual inaccuracies, or offensive outputs. Despite
widespread recognition of these challenges, an inability to reliably measure
these biases has stalled progress. To address this gap, we introduce CAIRe, a
novel evaluation metric that assesses the degree of cultural relevance of an
image, given a user-defined set of labels. Our framework grounds entities and
concepts in the image to a knowledge base and uses factual information to give
independent graded judgments for each culture label. On a manually curated
dataset of culturally salient but rare items built using language models, CAIRe
surpasses all baselines by 28% F1 points. Additionally, we construct two
datasets for culturally universal concept, one comprising of T2I-generated
outputs and another retrieved from naturally occurring data. CAIRe achieves
Pearson's correlations of 0.56 and 0.66 with human ratings on these sets, based
on a 5-point Likert scale of cultural relevance. This demonstrates its strong
alignment with human judgment across diverse image sources.

</details>


### [88] [Seedance 1.0: Exploring the Boundaries of Video Generation Models](https://arxiv.org/abs/2506.09113)
*Yu Gao,Haoyuan Guo,Tuyen Hoang,Weilin Huang,Lu Jiang,Fangyuan Kong,Huixia Li,Jiashi Li,Liang Li,Xiaojie Li,Xunsong Li,Yifu Li,Shanchuan Lin,Zhijie Lin,Jiawei Liu,Shu Liu,Xiaonan Nie,Zhiwu Qing,Yuxi Ren,Li Sun,Zhi Tian,Rui Wang,Sen Wang,Guoqiang Wei,Guohong Wu,Jie Wu,Ruiqi Xia,Fei Xiao,Xuefeng Xiao,Jiangqiao Yan,Ceyuan Yang,Jianchao Yang,Runkai Yang,Tao Yang,Yihang Yang,Zilyu Ye,Xuejiao Zeng,Yan Zeng,Heng Zhang,Yang Zhao,Xiaozheng Zheng,Peihao Zhu,Jiaxin Zou,Feilong Zuo*

Main category: cs.CV

TL;DR: Seedance 1.0是一款高性能视频生成模型，通过多源数据、高效架构和优化训练方法，显著提升视频生成质量与速度。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在提示跟随、运动合理性和视觉质量方面存在挑战，Seedance 1.0旨在解决这些问题。

Method: 采用多源数据增强、高效架构设计、优化训练范式及视频特定RLHF，结合模型加速技术。

Result: 生成5秒1080p视频仅需41.4秒，时空流畅性、指令跟随和多镜头叙事一致性优于现有模型。

Conclusion: Seedance 1.0在视频生成质量和效率上取得显著突破，具备广泛的应用潜力。

Abstract: Notable breakthroughs in diffusion modeling have propelled rapid improvements
in video generation, yet current foundational model still face critical
challenges in simultaneously balancing prompt following, motion plausibility,
and visual quality. In this report, we introduce Seedance 1.0, a
high-performance and inference-efficient video foundation generation model that
integrates several core technical improvements: (i) multi-source data curation
augmented with precision and meaningful video captioning, enabling
comprehensive learning across diverse scenarios; (ii) an efficient architecture
design with proposed training paradigm, which allows for natively supporting
multi-shot generation and jointly learning of both text-to-video and
image-to-video tasks. (iii) carefully-optimized post-training approaches
leveraging fine-grained supervised fine-tuning, and video-specific RLHF with
multi-dimensional reward mechanisms for comprehensive performance improvements;
(iv) excellent model acceleration achieving ~10x inference speedup through
multi-stage distillation strategies and system-level optimizations. Seedance
1.0 can generate a 5-second video at 1080p resolution only with 41.4 seconds
(NVIDIA-L20). Compared to state-of-the-art video generation models, Seedance
1.0 stands out with high-quality and fast video generation having superior
spatiotemporal fluidity with structural stability, precise instruction
adherence in complex multi-subject contexts, native multi-shot narrative
coherence with consistent subject representation.

</details>


### [89] [Cross-Frame Representation Alignment for Fine-Tuning Video Diffusion Models](https://arxiv.org/abs/2506.09229)
*Sungwon Hwang,Hyojin Jang,Kinam Kim,Minho Park,Jaegul choo*

Main category: cs.CV

TL;DR: 论文提出了一种新的正则化技术CREPA，用于改进视频扩散模型的微调，提升视觉保真度和帧间语义一致性。


<details>
  <summary>Details</summary>
Motivation: 用户级微调视频扩散模型以生成反映训练数据特定属性的视频具有挑战性且研究不足，但实际应用价值高。

Method: 提出Cross-frame Representation Alignment (CREPA)，通过将帧的隐藏状态与相邻帧的外部特征对齐，优化语义一致性。

Result: 在CogVideoX-5B和Hunyuan Video等大规模VDMs上验证，CREPA显著提升了视觉质量和帧间语义连贯性。

Conclusion: CREPA是一种广泛适用的技术，适用于多种数据集和参数高效微调方法。

Abstract: Fine-tuning Video Diffusion Models (VDMs) at the user level to generate
videos that reflect specific attributes of training data presents notable
challenges, yet remains underexplored despite its practical importance.
Meanwhile, recent work such as Representation Alignment (REPA) has shown
promise in improving the convergence and quality of DiT-based image diffusion
models by aligning, or assimilating, its internal hidden states with external
pretrained visual features, suggesting its potential for VDM fine-tuning. In
this work, we first propose a straightforward adaptation of REPA for VDMs and
empirically show that, while effective for convergence, it is suboptimal in
preserving semantic consistency across frames. To address this limitation, we
introduce Cross-frame Representation Alignment (CREPA), a novel regularization
technique that aligns hidden states of a frame with external features from
neighboring frames. Empirical evaluations on large-scale VDMs, including
CogVideoX-5B and Hunyuan Video, demonstrate that CREPA improves both visual
fidelity and cross-frame semantic coherence when fine-tuned with
parameter-efficient methods such as LoRA. We further validate CREPA across
diverse datasets with varying attributes, confirming its broad applicability.
Project page: https://crepavideo.github.io

</details>


### [90] [PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies](https://arxiv.org/abs/2506.09237)
*Mojtaba Nafez,Amirhossein Koochakian,Arad Maleki,Jafar Habibi,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: PatchGuard是一种基于Vision Transformer的对抗性鲁棒异常检测与定位方法，通过引入伪异常样本和定位掩码，显著提升了在对抗环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测与定位方法因训练数据仅限于正常样本而易受对抗攻击，PatchGuard旨在解决这一问题。

Method: 利用前景感知伪异常样本和ViT架构，结合对抗训练和新颖损失函数增强模型鲁棒性。

Result: 在工业和医疗数据集上，PatchGuard在对抗性环境下AD和AL性能分别提升53.2%和68.5%。

Conclusion: PatchGuard显著提升了对抗性环境下的异常检测与定位性能，同时保持非对抗性环境下的竞争力。

Abstract: Anomaly Detection (AD) and Anomaly Localization (AL) are crucial in fields
that demand high reliability, such as medical imaging and industrial
monitoring. However, current AD and AL approaches are often susceptible to
adversarial attacks due to limitations in training data, which typically
include only normal, unlabeled samples. This study introduces PatchGuard, an
adversarially robust AD and AL method that incorporates pseudo anomalies with
localization masks within a Vision Transformer (ViT)-based architecture to
address these vulnerabilities. We begin by examining the essential properties
of pseudo anomalies, and follow it by providing theoretical insights into the
attention mechanisms required to enhance the adversarial robustness of AD and
AL systems. We then present our approach, which leverages Foreground-Aware
Pseudo-Anomalies to overcome the deficiencies of previous anomaly-aware
methods. Our method incorporates these crafted pseudo-anomaly samples into a
ViT-based framework, with adversarial training guided by a novel loss function
designed to improve model robustness, as supported by our theoretical analysis.
Experimental results on well-established industrial and medical datasets
demonstrate that PatchGuard significantly outperforms previous methods in
adversarial settings, achieving performance gains of $53.2\%$ in AD and
$68.5\%$ in AL, while also maintaining competitive accuracy in non-adversarial
settings. The code repository is available at
https://github.com/rohban-lab/PatchGuard .

</details>


### [91] [InterActHuman: Multi-Concept Human Animation with Layout-Aligned Audio Conditions](https://arxiv.org/abs/2506.09984)
*Zhenzhi Wang,Jiaqi Yang,Jianwen Jiang,Chao Liang,Gaojie Lin,Zerong Zheng,Ceyuan Yang,Dahua Lin*

Main category: cs.CV

TL;DR: 论文提出了一种新框架，用于多模态条件下多概念（如人和物体）的精确控制，解决了现有方法在多人互动场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅能对单一主体进行动画生成，且以全局方式注入条件，无法精确控制多概念场景中的每个实体。

Method: 通过区域特定的条件绑定和掩码预测器，自动推断布局信息，并迭代注入局部音频条件以实现对齐。

Result: 实验验证了该方法在多模态条件下的显式布局控制优于隐式方法和其他现有方法。

Conclusion: 该框架能够高质量生成可控的多概念以人为中心的视频，为复杂互动场景提供了有效解决方案。

Abstract: End-to-end human animation with rich multi-modal conditions, e.g., text,
image and audio has achieved remarkable advancements in recent years. However,
most existing methods could only animate a single subject and inject conditions
in a global manner, ignoring scenarios that multiple concepts could appears in
the same video with rich human-human interactions and human-object
interactions. Such global assumption prevents precise and per-identity control
of multiple concepts including humans and objects, therefore hinders
applications. In this work, we discard the single-entity assumption and
introduce a novel framework that enforces strong, region-specific binding of
conditions from modalities to each identity's spatiotemporal footprint. Given
reference images of multiple concepts, our method could automatically infer
layout information by leveraging a mask predictor to match appearance cues
between the denoised video and each reference appearance. Furthermore, we
inject local audio condition into its corresponding region to ensure
layout-aligned modality matching in a iterative manner. This design enables the
high-quality generation of controllable multi-concept human-centric videos.
Empirical results and ablation studies validate the effectiveness of our
explicit layout control for multi-modal conditions compared to implicit
counterparts and other existing methods.

</details>


### [92] [UFM: A Simple Path towards Unified Dense Correspondence with Flow](https://arxiv.org/abs/2506.09278)
*Yuchen Zhang,Nikhil Keetha,Chenwei Lyu,Bhuvan Jhamb,Yutian Chen,Yuheng Qiu,Jay Karhade,Shreyas Jha,Yaoyu Hu,Deva Ramanan,Sebastian Scherer,Wenshan Wang*

Main category: cs.CV

TL;DR: 提出了一种统一的光流与匹配模型（UFM），通过统一训练在两种任务上均优于专用方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在宽基线和光流估计中分别处理密集对应的问题，探索统一训练的可能性。

Method: 使用简单的通用Transformer架构直接回归(u,v)光流，避免了传统粗到细成本体积的复杂性。

Result: UFM在光流任务上比Unimatch准确28%，在宽基线匹配上比RoMa误差减少62%，速度快6.7倍。

Conclusion: 统一训练在两种任务上均优于专用方法，为多模态、长距离和实时对应任务开辟了新方向。

Abstract: Dense image correspondence is central to many applications, such as visual
odometry, 3D reconstruction, object association, and re-identification.
Historically, dense correspondence has been tackled separately for
wide-baseline scenarios and optical flow estimation, despite the common goal of
matching content between two images. In this paper, we develop a Unified Flow &
Matching model (UFM), which is trained on unified data for pixels that are
co-visible in both source and target images. UFM uses a simple, generic
transformer architecture that directly regresses the (u,v) flow. It is easier
to train and more accurate for large flows compared to the typical
coarse-to-fine cost volumes in prior work. UFM is 28% more accurate than
state-of-the-art flow methods (Unimatch), while also having 62% less error and
6.7x faster than dense wide-baseline matchers (RoMa). UFM is the first to
demonstrate that unified training can outperform specialized approaches across
both domains. This result enables fast, general-purpose correspondence and
opens new directions for multi-modal, long-range, and real-time correspondence
tasks.

</details>


### [93] [Lightweight Object Detection Using Quantized YOLOv4-Tiny for Emergency Response in Aerial Imagery](https://arxiv.org/abs/2506.09299)
*Sindhu Boddu,Arindam Mukherjee*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级且节能的空中应急图像目标检测方案，采用YOLOv4-Tiny模型并通过后训练量化优化至INT8精度。实验表明，量化后的模型在保持性能的同时显著减小了模型体积并提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 针对应急响应场景中缺乏公开可用的无人机视角图像数据集的问题，本文通过自建数据集和模型优化，旨在提供一种适用于低功耗边缘设备的实时检测方案。

Method: 使用YOLOv4-Tiny模型，通过后训练量化优化至INT8精度，并在自建的10,820张标注图像数据集上进行训练。

Result: 量化后的YOLOv4-Tiny模型体积减小71%（从22.5 MB降至6.4 MB），推理速度提升44%，性能与YOLOv5-small相当。

Conclusion: 量化后的YOLOv4-Tiny模型适合在低功耗边缘设备上实现实时应急检测。

Abstract: This paper presents a lightweight and energy-efficient object detection
solution for aerial imagery captured during emergency response situations. We
focus on deploying the YOLOv4-Tiny model, a compact convolutional neural
network, optimized through post-training quantization to INT8 precision. The
model is trained on a custom-curated aerial emergency dataset, consisting of
10,820 annotated images covering critical emergency scenarios. Unlike prior
works that rely on publicly available datasets, we created this dataset
ourselves due to the lack of publicly available drone-view emergency imagery,
making the dataset itself a key contribution of this work. The quantized model
is evaluated against YOLOv5-small across multiple metrics, including mean
Average Precision (mAP), F1 score, inference time, and model size. Experimental
results demonstrate that the quantized YOLOv4-Tiny achieves comparable
detection performance while reducing the model size from 22.5 MB to 6.4 MB and
improving inference speed by 44\%. With a 71\% reduction in model size and a
44\% increase in inference speed, the quantized YOLOv4-Tiny model proves highly
suitable for real-time emergency detection on low-power edge devices.

</details>


### [94] [Efficient Edge Deployment of Quantized YOLOv4-Tiny for Aerial Emergency Object Detection on Raspberry Pi 5](https://arxiv.org/abs/2506.09300)
*Sindhu Boddu,Arindam Mukherjee*

Main category: cs.CV

TL;DR: 论文展示了量化YOLOv4-Tiny模型在资源受限的Raspberry Pi 5上实时检测航空紧急图像的部署与性能评估，显著降低了功耗。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证量化模型在嵌入式设备上的实时性和低功耗性能，以支持紧急响应应用。

Method: 使用TensorFlow Lite后训练量化技术将YOLOv4-Tiny模型量化为INT8精度，并评估检测速度、功耗和热可行性。

Result: 量化模型每张图像推理时间为28.2毫秒，平均功耗13.85瓦，检测精度在关键紧急类别中保持稳定。

Conclusion: 结果表明低功耗嵌入式AI系统在安全关键紧急响应应用中具有实时部署潜力。

Abstract: This paper presents the deployment and performance evaluation of a quantized
YOLOv4-Tiny model for real-time object detection in aerial emergency imagery on
a resource-constrained edge device the Raspberry Pi 5. The YOLOv4-Tiny model
was quantized to INT8 precision using TensorFlow Lite post-training
quantization techniques and evaluated for detection speed, power consumption,
and thermal feasibility under embedded deployment conditions. The quantized
model achieved an inference time of 28.2 ms per image with an average power
consumption of 13.85 W, demonstrating a significant reduction in power usage
compared to its FP32 counterpart. Detection accuracy remained robust across key
emergency classes such as Ambulance, Police, Fire Engine, and Car Crash. These
results highlight the potential of low-power embedded AI systems for real-time
deployment in safety-critical emergency response applications.

</details>


### [95] [MSSDF: Modality-Shared Self-supervised Distillation for High-Resolution Multi-modal Remote Sensing Image Learning](https://arxiv.org/abs/2506.09327)
*Tong Wang,Guanzhou Chen,Xiaodong Zhang,Chenxi Liu,Jiaqi Wang,Xiaoliang Tan,Wenchao Guo,Qingyuan Yang,Kaiqi Zhang*

Main category: cs.CV

TL;DR: 提出了一种多模态自监督学习框架，用于解决遥感图像标注数据获取成本高的问题，通过自适应掩码策略和多任务目标，显著提升了多种下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像标注数据获取成本高、耗时长的问题，提出一种无需大量标注数据的自监督学习方法。

Method: 设计了信息感知自适应掩码策略、跨模态掩码机制和多任务自监督目标，利用RGB图像、多光谱数据和DSM进行预训练。

Result: 在15个遥感数据集、26个任务中表现优异，如Potsdam和Vaihingen语义分割任务mIoU分别达78.30%和76.50%，US3D深度估计任务RMSE降至0.182。

Conclusion: 该方法在多模态遥感图像任务中显著优于现有预训练方法，代码和数据集已开源。

Abstract: Remote sensing image interpretation plays a critical role in environmental
monitoring, urban planning, and disaster assessment. However, acquiring
high-quality labeled data is often costly and time-consuming. To address this
challenge, we proposes a multi-modal self-supervised learning framework that
leverages high-resolution RGB images, multi-spectral data, and digital surface
models (DSM) for pre-training. By designing an information-aware adaptive
masking strategy, cross-modal masking mechanism, and multi-task self-supervised
objectives, the framework effectively captures both the correlations across
different modalities and the unique feature structures within each modality. We
evaluated the proposed method on multiple downstream tasks, covering typical
remote sensing applications such as scene classification, semantic
segmentation, change detection, object detection, and depth estimation.
Experiments are conducted on 15 remote sensing datasets, encompassing 26 tasks.
The results demonstrate that the proposed method outperforms existing
pretraining approaches in most tasks. Specifically, on the Potsdam and
Vaihingen semantic segmentation tasks, our method achieved mIoU scores of
78.30\% and 76.50\%, with only 50\% train-set. For the US3D depth estimation
task, the RMSE error is reduced to 0.182, and for the binary change detection
task in SECOND dataset, our method achieved mIoU scores of 47.51\%, surpassing
the second CS-MAE by 3 percentage points. Our pretrain code, checkpoints, and
HR-Pairs dataset can be found in https://github.com/CVEO/MSSDF.

</details>


### [96] [CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation](https://arxiv.org/abs/2506.09343)
*Yuxing Long,Jiyao Zhang,Mingjie Pan,Tianshu Wu,Taewhan Kim,Hao Dong*

Main category: cs.CV

TL;DR: 提出首个基于手册的电器操作基准CheckManual，通过大模型辅助生成手册数据，并设计相关挑战、指标和仿真环境。


<details>
  <summary>Details</summary>
Motivation: 电器操作需依赖手册，但现有研究忽视手册作用或仅用于问答任务，无法处理多页手册。

Method: 设计大模型辅助人工修订的数据生成流程，创建基于CAD电器模型的手册，并建立手册操作挑战、指标和仿真环境。

Result: 提出首个手册操作规划模型ManualPlan，为CheckManual基准设立基线。

Conclusion: CheckManual填补了手册在电器操作研究中的空白，为未来研究提供新方向。

Abstract: Correct use of electrical appliances has significantly improved human life
quality. Unlike simple tools that can be manipulated with common sense,
different parts of electrical appliances have specific functions defined by
manufacturers. If we want the robot to heat bread by microwave, we should
enable them to review the microwave manual first. From the manual, it can learn
about component functions, interaction methods, and representative task steps
about appliances. However, previous manual-related works remain limited to
question-answering tasks while existing manipulation researchers ignore the
manual's important role and fail to comprehend multi-page manuals. In this
paper, we propose the first manual-based appliance manipulation benchmark
CheckManual. Specifically, we design a large model-assisted human-revised data
generation pipeline to create manuals based on CAD appliance models. With these
manuals, we establish novel manual-based manipulation challenges, metrics, and
simulator environments for model performance evaluation. Furthermore, we
propose the first manual-based manipulation planning model ManualPlan to set up
a group of baselines for the CheckManual benchmark.

</details>


### [97] [An Effective End-to-End Solution for Multimodal Action Recognition](https://arxiv.org/abs/2506.09345)
*Songping Wang,Xiantao Hu,Yueming Lyu,Caifeng Shan*

Main category: cs.CV

TL;DR: 提出了一种综合利用多模态信息的动作识别解决方案，通过数据增强、迁移学习、时空特征提取和预测增强方法，在竞赛中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 由于三模态数据的稀缺性，多模态动作识别任务面临挑战，需要一种更有效的解决方案。

Method: 优化数据增强技术扩展训练规模，利用RGB数据集预训练骨干网络，结合2D CNNs和TSM提取时空特征，并采用SWA、Ensemble和TTA等预测增强方法。

Result: 在竞赛中取得了Top-1准确率99%和Top-5准确率100%的优异表现。

Conclusion: 该解决方案在多模态动作识别任务中表现出优越性，验证了其有效性。

Abstract: Recently, multimodal tasks have strongly advanced the field of action
recognition with their rich multimodal information. However, due to the
scarcity of tri-modal data, research on tri-modal action recognition tasks
faces many challenges. To this end, we have proposed a comprehensive multimodal
action recognition solution that effectively utilizes multimodal information.
First, the existing data are transformed and expanded by optimizing data
enhancement techniques to enlarge the training scale. At the same time, more
RGB datasets are used to pre-train the backbone network, which is better
adapted to the new task by means of transfer learning. Secondly, multimodal
spatial features are extracted with the help of 2D CNNs and combined with the
Temporal Shift Module (TSM) to achieve multimodal spatial-temporal feature
extraction comparable to 3D CNNs and improve the computational efficiency. In
addition, common prediction enhancement methods, such as Stochastic Weight
Averaging (SWA), Ensemble and Test-Time augmentation (TTA), are used to
integrate the knowledge of models from different training periods of the same
architecture and different architectures, so as to predict the actions from
different perspectives and fully exploit the target information. Ultimately, we
achieved the Top-1 accuracy of 99% and the Top-5 accuracy of 100% on the
competition leaderboard, demonstrating the superiority of our solution.

</details>


### [98] [Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation](https://arxiv.org/abs/2506.09350)
*Shanchuan Lin,Ceyuan Yang,Hao He,Jianwen Jiang,Yuxi Ren,Xin Xia,Yang Zhao,Xuefeng Xiao,Lu Jiang*

Main category: cs.CV

TL;DR: 提出了一种自回归对抗后训练（AAPT）方法，将预训练的潜在视频扩散模型转化为实时交互式视频生成器，支持24fps的高分辨率视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视频生成模型计算密集，无法满足实时和交互式应用的需求。

Method: 采用自回归对抗训练，单次神经网络评估生成潜在帧，并利用KV缓存提高效率。

Result: 8B模型在单个H100上实现736x416分辨率、24fps的实时视频生成，或在8xH100上支持1280x720分辨率。

Conclusion: AAPT方法通过对抗训练和自回归生成，显著提升了视频生成的实时性和交互性。

Abstract: Existing large-scale video generation models are computationally intensive,
preventing adoption in real-time and interactive applications. In this work, we
propose autoregressive adversarial post-training (AAPT) to transform a
pre-trained latent video diffusion model into a real-time, interactive video
generator. Our model autoregressively generates a latent frame at a time using
a single neural function evaluation (1NFE). The model can stream the result to
the user in real time and receive interactive responses as controls to generate
the next latent frame. Unlike existing approaches, our method explores
adversarial training as an effective paradigm for autoregressive generation.
This not only allows us to design an architecture that is more efficient for
one-step generation while fully utilizing the KV cache, but also enables
training the model in a student-forcing manner that proves to be effective in
reducing error accumulation during long video generation. Our experiments
demonstrate that our 8B model achieves real-time, 24fps, streaming video
generation at 736x416 resolution on a single H100, or 1280x720 on 8xH100 up to
a minute long (1440 frames). Visit our research website at
https://seaweed-apt.com/2

</details>


### [99] [A new approach for image segmentation based on diffeomorphic registration and gradient fields](https://arxiv.org/abs/2506.09357)
*Junchao Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于变分框架和微分同胚变换的2D图像分割方法，结合形状分析和LDDMM框架，无需大量训练数据即可实现高精度分割。


<details>
  <summary>Details</summary>
Motivation: 传统图像分割方法如边缘检测和变分方法已有广泛应用，但深度学习方法需要大量数据。本文旨在提出一种不依赖大数据且理论扎实的分割方法。

Method: 通过微分同胚变换将模板曲线变形为图像分割边界，利用LDDMM框架和变分表示几何形状的varifold方法，结合图像梯度场指导曲线演化。

Result: 实现了高精度的2D图像分割，方法灵活且理论支持强。

Conclusion: 提出的变分框架结合微分同胚变换和形状分析，为图像分割提供了一种无需大数据的高效解决方案。

Abstract: Image segmentation is a fundamental task in computer vision aimed at
delineating object boundaries within images. Traditional approaches, such as
edge detection and variational methods, have been widely explored, while recent
advances in deep learning have shown promising results but often require
extensive training data. In this work, we propose a novel variational framework
for 2D image segmentation that integrates concepts from shape analysis and
diffeomorphic transformations. Our method models segmentation as the
deformation of a template curve via a diffeomorphic transformation of the image
domain, using the Large Deformation Diffeomorphic Metric Mapping (LDDMM)
framework. The curve evolution is guided by a loss function that compares the
deformed curve to the image gradient field, formulated through the varifold
representation of geometric shapes. The approach is implemented in Python with
GPU acceleration using the PyKeops library. This framework allows for accurate
segmentation with a flexible and theoretically grounded methodology that does
not rely on large datasets.

</details>


### [100] [SAGE: Exploring the Boundaries of Unsafe Concept Domain with Semantic-Augment Erasing](https://arxiv.org/abs/2506.09363)
*Hongguang Zhu,Yunchao Wei,Mengyu Wang,Siyu Jiao,Yan Fang,Jiannan Huang,Yao Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种名为SAGE的方法，通过语义增强擦除和全局-局部协作保留机制，解决了扩散模型在文本到图像生成中的安全风险问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在预训练中不可避免地包含敏感信息，导致不安全内容生成和版权侵权风险，现有方法无法实现广义概念擦除。

Method: SAGE通过语义增强擦除将概念词擦除转化为概念域擦除，并结合全局-局部协作保留机制，保护无关概念。

Result: 实验表明SAGE在扩散模型的安全生成中全面优于其他方法。

Conclusion: SAGE为扩散模型的安全生成提供了高效解决方案，代码和权重将开源。

Abstract: Diffusion models (DMs) have achieved significant progress in text-to-image
generation. However, the inevitable inclusion of sensitive information during
pre-training poses safety risks, such as unsafe content generation and
copyright infringement. Concept erasing finetunes weights to unlearn
undesirable concepts, and has emerged as a promising solution. However,
existing methods treat unsafe concept as a fixed word and repeatedly erase it,
trapping DMs in ``word concept abyss'', which prevents generalized
concept-related erasing. To escape this abyss, we introduce semantic-augment
erasing which transforms concept word erasure into concept domain erasure by
the cyclic self-check and self-erasure. It efficiently explores and unlearns
the boundary representation of concept domain through semantic spatial
relationships between original and training DMs, without requiring additional
preprocessed data. Meanwhile, to mitigate the retention degradation of
irrelevant concepts while erasing unsafe concepts, we further propose the
global-local collaborative retention mechanism that combines global semantic
relationship alignment with local predicted noise preservation, effectively
expanding the retentive receptive field for irrelevant concepts. We name our
method SAGE, and extensive experiments demonstrate the comprehensive
superiority of SAGE compared with other methods in the safe generation of DMs.
The code and weights will be open-sourced at
https://github.com/KevinLight831/SAGE.

</details>


### [101] [ScaleLSD: Scalable Deep Line Segment Detection Streamlined](https://arxiv.org/abs/2506.09369)
*Zeran Ke,Bin Tan,Xianwei Zheng,Yujun Shen,Tianfu Wu,Nan Xue*

Main category: cs.CV

TL;DR: 本文提出了一种名为ScaleLSD的域无关、鲁棒的线分割检测（LSD）模型，通过自监督学习从大规模未标记图像中学习线几何特征，性能优于传统非深度方法。


<details>
  <summary>Details</summary>
Motivation: 研究线分割检测（LSD）问题，旨在开发一种适用于任何自然图像的鲁棒且域无关的LSD模型。

Method: 通过重新设计和优化（深度与非深度）LSD方法的基本框架，提出ScaleLSD，利用自监督学习从超过1000万张未标记图像中提取线几何特征。

Result: ScaleLSD在零样本协议下表现优异，在线分割检测、单视图3D几何估计、双视图线分割匹配及多视图3D线映射中均显著优于传统非深度方法。

Conclusion: ScaleLSD是首个在各方面超越传统非深度LSD方法的深度学习方法，显著提升了图像线几何的通用性和鲁棒性。

Abstract: This paper studies the problem of Line Segment Detection (LSD) for the
characterization of line geometry in images, with the aim of learning a
domain-agnostic robust LSD model that works well for any natural images. With
the focus of scalable self-supervised learning of LSD, we revisit and
streamline the fundamental designs of (deep and non-deep) LSD approaches to
have a high-performing and efficient LSD learner, dubbed as ScaleLSD, for the
curation of line geometry at scale from over 10M unlabeled real-world images.
Our ScaleLSD works very well to detect much more number of line segments from
any natural images even than the pioneered non-deep LSD approach, having a more
complete and accurate geometric characterization of images using line segments.
Experimentally, our proposed ScaleLSD is comprehensively testified under
zero-shot protocols in detection performance, single-view 3D geometry
estimation, two-view line segment matching, and multiview 3D line mapping, all
with excellent performance obtained. Based on the thorough evaluation, our
ScaleLSD is observed to be the first deep approach that outperforms the
pioneered non-deep LSD in all aspects we have tested, significantly expanding
and reinforcing the versatility of the line geometry of images. Code and Models
are available at https://github.com/ant-research/scalelsd

</details>


### [102] [UniForward: Unified 3D Scene and Semantic Field Reconstruction via Feed-Forward Gaussian Splatting from Only Sparse-View Images](https://arxiv.org/abs/2506.09378)
*Qijian Tian,Xin Tan,Jingyu Gong,Yuan Xie,Lizhuang Ma*

Main category: cs.CV

TL;DR: 提出了一种名为UniForward的前馈高斯泼溅模型，用于统一3D场景和语义场重建，仅需未校准的稀疏视图图像即可实现实时重建。


<details>
  <summary>Details</summary>
Motivation: 结合3D场景与语义场以提升环境感知和理解能力，但需解决语义嵌入3D表示、实时重建通用性及仅用图像输入的挑战。

Method: 通过双分支解耦解码器将语义特征嵌入3D高斯，采用损失引导的视图采样器稳定训练，结合光度损失和蒸馏损失进行端到端训练。

Result: 实验表明，UniForward在新视角合成和分割任务中表现优异，实现了高质量的3D场景和语义场重建。

Conclusion: UniForward为3D场景与语义场的统一重建提供了高效且通用的解决方案。

Abstract: We propose a feed-forward Gaussian Splatting model that unifies 3D scene and
semantic field reconstruction. Combining 3D scenes with semantic fields
facilitates the perception and understanding of the surrounding environment.
However, key challenges include embedding semantics into 3D representations,
achieving generalizable real-time reconstruction, and ensuring practical
applicability by using only images as input without camera parameters or ground
truth depth. To this end, we propose UniForward, a feed-forward model to
predict 3D Gaussians with anisotropic semantic features from only uncalibrated
and unposed sparse-view images. To enable the unified representation of the 3D
scene and semantic field, we embed semantic features into 3D Gaussians and
predict them through a dual-branch decoupled decoder. During training, we
propose a loss-guided view sampler to sample views from easy to hard,
eliminating the need for ground truth depth or masks required by previous
methods and stabilizing the training process. The whole model can be trained
end-to-end using a photometric loss and a distillation loss that leverages
semantic features from a pre-trained 2D semantic model. At the inference stage,
our UniForward can reconstruct 3D scenes and the corresponding semantic fields
in real time from only sparse-view images. The reconstructed 3D scenes achieve
high-quality rendering, and the reconstructed 3D semantic field enables the
rendering of view-consistent semantic features from arbitrary views, which can
be further decoded into dense segmentation masks in an open-vocabulary manner.
Experiments on novel view synthesis and novel view segmentation demonstrate
that our method achieves state-of-the-art performances for unifying 3D scene
and semantic field reconstruction.

</details>


### [103] [ReID5o: Achieving Omni Multi-modal Person Re-identification in a Single Model](https://arxiv.org/abs/2506.09385)
*Jialong Zuo,Yongtai Deng,Mengdan Tan,Rui Jin,Dongyue Wu,Nong Sang,Liang Pan,Changxin Gao*

Main category: cs.CV

TL;DR: 论文提出了一种新的多模态行人重识别问题（OM-ReID），并构建了首个高质量多模态数据集ORBench，同时提出了多模态学习框架ReID5o。


<details>
  <summary>Details</summary>
Motivation: 现有方法和数据集局限于有限模态，无法满足实际场景中多模态查询的需求。

Method: 构建ORBench数据集（包含5种模态），提出ReID5o框架，支持任意模态组合的协同融合和跨模态对齐。

Result: ReID5o在ORBench上表现最佳，验证了其先进性和实用性。

Conclusion: ORBench和ReID5o为OM-ReID研究提供了理想平台和解决方案。

Abstract: In real-word scenarios, person re-identification (ReID) expects to identify a
person-of-interest via the descriptive query, regardless of whether the query
is a single modality or a combination of multiple modalities. However, existing
methods and datasets remain constrained to limited modalities, failing to meet
this requirement. Therefore, we investigate a new challenging problem called
Omni Multi-modal Person Re-identification (OM-ReID), which aims to achieve
effective retrieval with varying multi-modal queries. To address dataset
scarcity, we construct ORBench, the first high-quality multi-modal dataset
comprising 1,000 unique identities across five modalities: RGB, infrared, color
pencil, sketch, and textual description. This dataset also has significant
superiority in terms of diversity, such as the painting perspectives and
textual information. It could serve as an ideal platform for follow-up
investigations in OM-ReID. Moreover, we propose ReID5o, a novel multi-modal
learning framework for person ReID. It enables synergistic fusion and
cross-modal alignment of arbitrary modality combinations in a single model,
with a unified encoding and multi-expert routing mechanism proposed. Extensive
experiments verify the advancement and practicality of our ORBench. A wide
range of possible models have been evaluated and compared on it, and our
proposed ReID5o model gives the best performance. The dataset and code will be
made publicly available at https://github.com/Zplusdragon/ReID5o_ORBench.

</details>


### [104] [Improving Out-of-Distribution Detection via Dynamic Covariance Calibration](https://arxiv.org/abs/2506.09399)
*Kaiyu Guo,Zijian Wang,Brian C. Lovell,Mahsa Baktashmotlagh*

Main category: cs.CV

TL;DR: 提出了一种动态调整先验几何的方法，通过实时输入特征更新协方差矩阵，显著提升OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于子空间的方法因静态提取信息几何而无法处理分布不良样本导致的几何失真。

Method: 动态更新先验协方差矩阵，减少实时输入特征方向的协方差，并约束调整到残差空间。

Result: 在CIFAR和ImageNet-1k数据集上，方法显著提升了多种模型的OOD检测性能。

Conclusion: 动态调整先验几何能有效纠正分布不良样本的影响，提升OOD检测的鲁棒性。

Abstract: Out-of-Distribution (OOD) detection is essential for the trustworthiness of
AI systems. Methods using prior information (i.e., subspace-based methods) have
shown effective performance by extracting information geometry to detect OOD
data with a more appropriate distance metric. However, these methods fail to
address the geometry distorted by ill-distributed samples, due to the
limitation of statically extracting information geometry from the training
distribution. In this paper, we argue that the influence of ill-distributed
samples can be corrected by dynamically adjusting the prior geometry in
response to new data. Based on this insight, we propose a novel approach that
dynamically updates the prior covariance matrix using real-time input features,
refining its information. Specifically, we reduce the covariance along the
direction of real-time input features and constrain adjustments to the residual
space, thus preserving essential data characteristics and avoiding effects on
unintended directions in the principal space. We evaluate our method on two
pre-trained models for the CIFAR dataset and five pre-trained models for
ImageNet-1k, including the self-supervised DINO model. Extensive experiments
demonstrate that our approach significantly enhances OOD detection across
various models. The code is released at https://github.com/workerbcd/ooddcc.

</details>


### [105] [SRPL-SFDA: SAM-Guided Reliable Pseudo-Labels for Source-Free Domain Adaptation in Medical Image Segmentation](https://arxiv.org/abs/2506.09403)
*Xinya Liu,Jianghao Wu,Tao Lu,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: 提出了一种基于Segment Anything Model（SAM）的可靠伪标签方法（SRPL-SFDA），用于源自由域适应（SFDA），通过增强伪标签质量和可靠性提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决源自由域适应（SFDA）中目标域无标签数据监督不足的问题，同时应对隐私和访问限制。

Method: 1）测试时三分支强度增强（T3IE）提升伪标签质量；2）基于多SAM输出一致性（CMSO）的可靠伪标签选择模块；3）可靠性感知训练过程。

Result: 在两个医学图像分割数据集上表现优于现有SFDA方法，接近目标域监督训练性能。

Conclusion: SRPL-SFDA通过可靠伪标签和可靠性感知训练，显著提升了SFDA性能。

Abstract: Domain Adaptation (DA) is crucial for robust deployment of medical image
segmentation models when applied to new clinical centers with significant
domain shifts. Source-Free Domain Adaptation (SFDA) is appealing as it can deal
with privacy concerns and access constraints on source-domain data during
adaptation to target-domain data. However, SFDA faces challenges such as
insufficient supervision in the target domain with unlabeled images. In this
work, we propose a Segment Anything Model (SAM)-guided Reliable Pseudo-Labels
method for SFDA (SRPL-SFDA) with three key components: 1) Test-Time Tri-branch
Intensity Enhancement (T3IE) that not only improves quality of raw
pseudo-labels in the target domain, but also leads to SAM-compatible inputs
with three channels to better leverage SAM's zero-shot inference ability for
refining the pseudo-labels; 2) A reliable pseudo-label selection module that
rejects low-quality pseudo-labels based on Consistency of Multiple SAM Outputs
(CMSO) under input perturbations with T3IE; and 3) A reliability-aware training
procedure in the unlabeled target domain where reliable pseudo-labels are used
for supervision and unreliable parts are regularized by entropy minimization.
Experiments conducted on two multi-domain medical image segmentation datasets
for fetal brain and the prostate respectively demonstrate that: 1) SRPL-SFDA
effectively enhances pseudo-label quality in the unlabeled target domain, and
improves SFDA performance by leveraging the reliability-aware training; 2)
SRPL-SFDA outperformed state-of-the-art SFDA methods, and its performance is
close to that of supervised training in the target domain. The code of this
work is available online: https://github.com/HiLab-git/SRPL-SFDA.

</details>


### [106] [Synthetic Human Action Video Data Generation with Pose Transfer](https://arxiv.org/abs/2506.09411)
*Vaclav Knapp,Matyas Bohacek*

Main category: cs.CV

TL;DR: 提出一种基于姿态迁移的合成人类动作视频数据生成方法，解决合成数据在视频理解任务中的‘诡异特征’问题，并在动作识别任务中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 合成数据在人类动作视频任务中常因‘诡异特征’而效果不佳，限制了其在手语翻译、手势识别等任务中的应用潜力。

Method: 使用可控3D高斯虚拟人模型进行姿态迁移，生成合成人类动作视频数据。

Result: 在Toyota Smarthome和NTU RGB+D数据集上验证了方法的有效性，提升了动作识别性能，并能扩展少样本数据集。

Conclusion: 该方法能有效生成高质量合成数据，弥补真实数据不足，并开源了相关数据集RANDOM People。

Abstract: In video understanding tasks, particularly those involving human motion,
synthetic data generation often suffers from uncanny features, diminishing its
effectiveness for training. Tasks such as sign language translation, gesture
recognition, and human motion understanding in autonomous driving have thus
been unable to exploit the full potential of synthetic data. This paper
proposes a method for generating synthetic human action video data using pose
transfer (specifically, controllable 3D Gaussian avatar models). We evaluate
this method on the Toyota Smarthome and NTU RGB+D datasets and show that it
improves performance in action recognition tasks. Moreover, we demonstrate that
the method can effectively scale few-shot datasets, making up for groups
underrepresented in the real training data and adding diverse backgrounds. We
open-source the method along with RANDOM People, a dataset with videos and
avatars of novel human identities for pose transfer crowd-sourced from the
internet.

</details>


### [107] [Noise Conditional Variational Score Distillation](https://arxiv.org/abs/2506.09416)
*Xinyu Peng,Ziyang Zheng,Yaoming Wang,Han Li,Nuowen Kan,Wenrui Dai,Chenglin Li,Junni Zou,Hongkai Xiong*

Main category: cs.CV

TL;DR: NCVSD是一种新方法，将预训练的扩散模型蒸馏为生成去噪器，通过揭示无条件评分函数隐含地表征去噪后验分布的评分函数。该方法支持快速生成和迭代优化，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成速度和质量之间存在权衡，NCVSD旨在通过蒸馏方法解决这一问题，同时保留迭代优化的优势。

Method: 将无条件评分函数的洞察融入VSD框架，实现生成去噪器的可扩展学习，支持从高噪声水平到低噪声水平的样本生成。

Result: NCVSD在类条件图像生成和逆问题求解中表现优异，生成速度和质量均优于教师扩散模型，并与更大规模的Consistency模型相当。

Conclusion: NCVSD通过蒸馏方法实现了快速生成和高质量样本，同时支持灵活的零样本概率推理，为生成模型提供了新思路。

Abstract: We propose Noise Conditional Variational Score Distillation (NCVSD), a novel
method for distilling pretrained diffusion models into generative denoisers. We
achieve this by revealing that the unconditional score function implicitly
characterizes the score function of denoising posterior distributions. By
integrating this insight into the Variational Score Distillation (VSD)
framework, we enable scalable learning of generative denoisers capable of
approximating samples from the denoising posterior distribution across a wide
range of noise levels. The proposed generative denoisers exhibit desirable
properties that allow fast generation while preserve the benefit of iterative
refinement: (1) fast one-step generation through sampling from pure Gaussian
noise at high noise levels; (2) improved sample quality by scaling the
test-time compute with multi-step sampling; and (3) zero-shot probabilistic
inference for flexible and controllable sampling. We evaluate NCVSD through
extensive experiments, including class-conditional image generation and inverse
problem solving. By scaling the test-time compute, our method outperforms
teacher diffusion models and is on par with consistency models of larger sizes.
Additionally, with significantly fewer NFEs than diffusion-based methods, we
achieve record-breaking LPIPS on inverse problems.

</details>


### [108] [ODG: Occupancy Prediction Using Dual Gaussians](https://arxiv.org/abs/2506.09417)
*Yunxiao Shi,Yinhao Zhu,Shizhong Han,Jisoo Jeong,Amin Ansari,Hong Cai,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出了一种结合BEV和稀疏点表示的新型3D占用预测方法ODG，通过双分支设计提升小物体和平面物体的检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D场景理解中存在计算成本高或信息损失的问题，BEV对小物体检测效果差，而稀疏点对平面物体效率低。

Method: 采用双分支设计：基于查询的稀疏点分支和BEV分支，通过交叉注意力共享信息，最终融合输出3D占用预测。

Result: 在Occ3D-nuScenes和Occ3D-Waymo基准测试中表现优越，同时推理速度与最新高效方法相当。

Conclusion: ODG通过结合BEV和稀疏点表示，有效解决了现有方法的局限性，提升了3D占用预测的性能和效率。

Abstract: 3D occupancy provides fine-grained 3D geometry and semantics for scene
understanding which is critical for autonomous driving. Most existing methods,
however, carry high compute costs, requiring dense 3D feature volume and
cross-attention to effectively aggregate information. More recent works have
adopted Bird's Eye View (BEV) or sparse points as scene representation with
much reduced cost, but still suffer from their respective shortcomings. More
concretely, BEV struggles with small objects that often experience significant
information loss after being projected to the ground plane. On the other hand,
points can flexibly model little objects in 3D, but is inefficient at capturing
flat surfaces or large objects. To address these challenges, in this paper, we
present a novel 3D occupancy prediction approach, ODG, which combines BEV and
sparse points based representations. We propose a dual-branch design: a
query-based sparse points branch and a BEV branch. The 3D information learned
in the sparse points branch is shared with the BEV stream via cross-attention,
which enriches the weakened signals of difficult objects on the BEV plane. The
outputs of both branches are finally fused to generate predicted 3D occupancy.
We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymo
benchmarks that demonstrate the superiority of our proposed ODG. Moreover, ODG
also delivers competitive inference speed when compared to the latest efficient
approaches.

</details>


### [109] [A High-Quality Dataset and Reliable Evaluation for Interleaved Image-Text Generation](https://arxiv.org/abs/2506.09427)
*Yukang Feng,Jianwen Sun,Chuanhao Li,Zizhen Li,Jiaxin Ai,Fanrui Zhang,Yifan Chang,Sizhuo Zhou,Shenglin Zhang,Yu Dai,Kaipeng Zhang*

Main category: cs.CV

TL;DR: 论文提出InterSyn数据集和SEIR方法，用于改进多模态模型的训练和评估，提升图像-文本交织输出的质量。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在生成紧密交织的图像-文本输出时表现不佳，主要由于训练数据集的规模、质量和指令丰富度不足。

Method: 引入InterSyn数据集和SEIR方法，通过多轮指令驱动对话和自动化质量优化构建数据集，并开发SynJudge评估模型。

Result: SEIR方法显著提升数据集质量，基于InterSyn训练的模型在所有评估指标上均有提升。

Conclusion: InterSyn和SEIR为下一代多模态系统的训练和评估提供了有效工具。

Abstract: Recent advancements in Large Multimodal Models (LMMs) have significantly
improved multimodal understanding and generation. However, these models still
struggle to generate tightly interleaved image-text outputs, primarily due to
the limited scale, quality and instructional richness of current training
datasets. To address this, we introduce InterSyn, a large-scale multimodal
dataset constructed using our Self-Evaluation with Iterative Refinement (SEIR)
method. InterSyn features multi-turn, instruction-driven dialogues with tightly
interleaved imagetext responses, providing rich object diversity and rigorous
automated quality refinement, making it well-suited for training
next-generation instruction-following LMMs. Furthermore, to address the lack of
reliable evaluation tools capable of assessing interleaved multimodal outputs,
we introduce SynJudge, an automatic evaluation model designed to quantitatively
assess multimodal outputs along four dimensions: text content, image content,
image quality, and image-text synergy.
  Experimental studies show that the SEIR method leads to substantially higher
dataset quality compared to an otherwise identical process without refinement.
  Moreover, LMMs trained on InterSyn achieve uniform performance gains across
all evaluation metrics, confirming InterSyn's utility for advancing multimodal
systems.

</details>


### [110] [A Novel Lightweight Transformer with Edge-Aware Fusion for Remote Sensing Image Captioning](https://arxiv.org/abs/2506.09429)
*Swadhin Das,Divyansh Mundra,Priyanshu Dayal,Raksha Sharma*

Main category: cs.CV

TL;DR: 提出了一种轻量级Transformer架构，通过降低编码器层维度和使用蒸馏版GPT-2解码器，结合知识蒸馏和边缘感知增强策略，显著提升了遥感图像描述质量。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在遥感图像描述中的高计算成本和忽略细粒度结构特征的问题。

Method: 采用轻量级Transformer架构，结合知识蒸馏和边缘感知增强策略。

Result: 实验结果表明，该方法在描述质量上显著优于现有技术。

Conclusion: 轻量级架构和边缘感知策略有效提升了遥感图像描述的准确性和效率。

Abstract: Transformer-based models have achieved strong performance in remote sensing
image captioning by capturing long-range dependencies and contextual
information. However, their practical deployment is hindered by high
computational costs, especially in multi-modal frameworks that employ separate
transformer-based encoders and decoders. In addition, existing remote sensing
image captioning models primarily focus on high-level semantic extraction while
often overlooking fine-grained structural features such as edges, contours, and
object boundaries. To address these challenges, a lightweight transformer
architecture is proposed by reducing the dimensionality of the encoder layers
and employing a distilled version of GPT-2 as the decoder. A knowledge
distillation strategy is used to transfer knowledge from a more complex teacher
model to improve the performance of the lightweight network. Furthermore, an
edge-aware enhancement strategy is incorporated to enhance image representation
and object boundary understanding, enabling the model to capture fine-grained
spatial details in remote sensing images. Experimental results demonstrate that
the proposed approach significantly improves caption quality compared to
state-of-the-art methods.

</details>


### [111] [TOGA: Temporally Grounded Open-Ended Video QA with Weak Supervision](https://arxiv.org/abs/2506.09445)
*Ayush Gupta,Anirban Roy,Rama Chellappa,Nathaniel D. Bastian,Alvaro Velasquez,Susmit Jha*

Main category: cs.CV

TL;DR: 论文提出TOGA模型，用于弱监督下视频问答任务，无需时间标注即可生成答案及时间定位。


<details>
  <summary>Details</summary>
Motivation: 解决无时间标注情况下视频问答的时间定位问题。

Method: 采用TOGA模型，通过指令调优联合生成答案和时间定位，利用伪标签和一致性约束确保定位有效性。

Result: 在NExT-GQA、MSVD-QA和ActivityNet-QA基准测试中取得最优性能。

Conclusion: TOGA模型在弱监督下能有效提升视频问答和时间定位的性能。

Abstract: We address the problem of video question answering (video QA) with temporal
grounding in a weakly supervised setup, without any temporal annotations. Given
a video and a question, we generate an open-ended answer grounded with the
start and end time. For this task, we propose TOGA: a vision-language model for
Temporally Grounded Open-Ended Video QA with Weak Supervision. We instruct-tune
TOGA to jointly generate the answer and the temporal grounding. We operate in a
weakly supervised setup where the temporal grounding annotations are not
available. We generate pseudo labels for temporal grounding and ensure the
validity of these labels by imposing a consistency constraint between the
question of a grounding response and the response generated by a question
referring to the same temporal segment. We notice that jointly generating the
answers with the grounding improves performance on question answering as well
as grounding. We evaluate TOGA on grounded QA and open-ended QA tasks. For
grounded QA, we consider the NExT-GQA benchmark which is designed to evaluate
weakly supervised grounded question answering. For open-ended QA, we consider
the MSVD-QA and ActivityNet-QA benchmarks. We achieve state-of-the-art
performance for both tasks on these benchmarks.

</details>


### [112] [Harmonizing and Merging Source Models for CLIP-based Domain Generalization](https://arxiv.org/abs/2506.09446)
*Yuhe Ding,Jian Liang,Bo Jiang,Zi Wang,Aihua Zheng,Bin Luo*

Main category: cs.CV

TL;DR: HAM是一种基于CLIP的领域泛化框架，通过无冲突样本增强和模型合并优化，提升模型在未见领域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多源训练中存在样本冲突和优化冲突，导致泛化性能受限。

Method: HAM在训练过程中避免冲突样本，协调模型更新方向，并引入冗余感知的历史模型合并方法。

Result: 在五个基准数据集上取得最优性能。

Conclusion: HAM能有效整合多源信息，提升模型泛化能力。

Abstract: CLIP-based domain generalization aims to improve model generalization to
unseen domains by leveraging the powerful zero-shot classification capabilities
of CLIP and multiple source datasets. Existing methods typically train a single
model across multiple source domains to capture domain-shared information.
However, this paradigm inherently suffers from two types of conflicts: 1)
sample conflicts, arising from noisy samples and extreme domain shifts among
sources; and 2) optimization conflicts, stemming from competition and
trade-offs during multi-source training. Both hinder the generalization and
lead to suboptimal solutions. Recent studies have shown that model merging can
effectively mitigate the competition of multi-objective optimization and
improve generalization performance. Inspired by these findings, we propose
Harmonizing and Merging (HAM), a novel source model merging framework for
CLIP-based domain generalization. During the training process of the source
models, HAM enriches the source samples without conflicting samples, and
harmonizes the update directions of all models. Then, a redundancy-aware
historical model merging method is introduced to effectively integrate
knowledge across all source models. HAM comprehensively consolidates source
domain information while enabling mutual enhancement among source models,
ultimately yielding a final model with optimal generalization capabilities.
Extensive experiments on five widely used benchmark datasets demonstrate the
effectiveness of our approach, achieving state-of-the-art performance.

</details>


### [113] [Evidential Deep Learning with Spectral-Spatial Uncertainty Disentanglement for Open-Set Hyperspectral Domain Generalization](https://arxiv.org/abs/2506.09460)
*Amirreza Khoshbakht,Erchan Aptoula*

Main category: cs.CV

TL;DR: 提出一种新的开放集域泛化框架，结合频谱不变特征提取、双通道残差网络、证据深度学习和不确定性解耦，用于高光谱图像分类。


<details>
  <summary>Details</summary>
Motivation: 解决现有域适应方法在未知类存在时无法处理域偏移的问题，避免负迁移和分类性能下降。

Method: 结合SIFD（频谱不变频率解耦）、DCRN（双通道残差网络）、EDL（证据深度学习）和SSUD（频谱-空间不确定性解耦）四个模块。

Result: 在三个跨场景高光谱分类任务中表现优异，无需目标域数据即可达到与现有域适应方法相当的性能。

Conclusion: 提出的框架有效解决了开放集域泛化问题，为高光谱图像分类提供了新方法。

Abstract: Open-set domain generalization(OSDG) for hyperspectral image classification
presents significant challenges due to the presence of unknown classes in
target domains and the need for models to generalize across multiple unseen
domains without target-specific adaptation. Existing domain adaptation methods
assume access to target domain data during training and fail to address the
fundamental issue of domain shift when unknown classes are present, leading to
negative transfer and reduced classification performance. To address these
limitations, we propose a novel open-set domain generalization framework that
combines four key components: Spectrum-Invariant Frequency Disentanglement
(SIFD) for domain-agnostic feature extraction, Dual-Channel Residual Network
(DCRN) for robust spectral-spatial feature learning, Evidential Deep Learning
(EDL) for uncertainty quantification, and Spectral-Spatial Uncertainty
Disentanglement (SSUD) for reliable open-set classification. The SIFD module
extracts domain-invariant spectral features in the frequency domain through
attention-weighted frequency analysis and domain-agnostic regularization, while
DCRN captures complementary spectral and spatial information via parallel
pathways with adaptive fusion. EDL provides principled uncertainty estimation
using Dirichlet distributions, enabling the SSUD module to make reliable
open-set decisions through uncertainty-aware pathway weighting and adaptive
rejection thresholding. Experimental results on three cross-scene hyperspectral
classification tasks show that our approach achieves performance comparable to
state-of-the-art domain adaptation methods while requiring no access to the
target domain during training. The implementation will be made available at
https://github.com/amir-khb/SSUDOSDG upon acceptance.

</details>


### [114] [Optimizing Cooperative Multi-Object Tracking using Graph Signal Processing](https://arxiv.org/abs/2506.09469)
*Maria Damanaki,Nikos Piperigkos,Alexandros Gkillas,Aris S. Lalos*

Main category: cs.CV

TL;DR: 提出了一种基于图拉普拉斯优化的多智能体协同多目标跟踪框架，显著提升了3D LiDAR场景中的跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 单智能体多目标跟踪因遮挡和传感器故障等问题存在感知局限，需整合多智能体信息以实现全面环境理解。

Method: 通过构建全连接图拓扑并利用图拉普拉斯优化技术，平滑多车辆检测的边界框位置误差，分两阶段关联优化定位与跟踪。

Result: 在V2V4Real数据集上，该方法显著优于基线框架及当前先进的DMSTrack和V2V4Real。

Conclusion: 多智能体协同框架有效提升了复杂场景下的多目标跟踪性能，验证了图优化方法的优势。

Abstract: Multi-Object Tracking (MOT) plays a crucial role in autonomous driving
systems, as it lays the foundations for advanced perception and precise path
planning modules. Nonetheless, single agent based MOT lacks in sensing
surroundings due to occlusions, sensors failures, etc. Hence, the integration
of multiagent information is essential for comprehensive understanding of the
environment. This paper proposes a novel Cooperative MOT framework for tracking
objects in 3D LiDAR scene by formulating and solving a graph topology-aware
optimization problem so as to fuse information coming from multiple vehicles.
By exploiting a fully connected graph topology defined by the detected bounding
boxes, we employ the Graph Laplacian processing optimization technique to
smooth the position error of bounding boxes and effectively combine them. In
that manner, we reveal and leverage inherent coherences of diverse multi-agent
detections, and associate the refined bounding boxes to tracked objects at two
stages, optimizing localization and tracking accuracies. An extensive
evaluation study has been conducted, using the real-world V2V4Real dataset,
where the proposed method significantly outperforms the baseline frameworks,
including the state-of-the-art deep-learning DMSTrack and V2V4Real, in various
testing sequences.

</details>


### [115] [Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning](https://arxiv.org/abs/2506.09473)
*Cheng Chen,Yunpeng Zhai,Yifan Zhao,Jinyang Gao,Bolin Ding,Jia Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于探索-利用强化学习框架的多模态演示选择策略，用于提升大型视觉语言模型（LVLMs）的上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法依赖预定义演示或启发式选择策略，无法覆盖多样化任务需求且忽略演示间交互，导致性能不佳。

Method: 采用探索-利用强化学习框架，自适应选择多模态演示并优化其整体效果，通过自我探索持续改进。

Result: 在四个视觉问答数据集上验证了方法的优越性，显著提升了少样本LVLMs的泛化能力。

Conclusion: 该框架能自主生成高效演示选择策略，为多模态上下文学习提供了新思路。

Abstract: In-context learning (ICL), a predominant trend in instruction learning, aims
at enhancing the performance of large language models by providing clear task
guidance and examples, improving their capability in task understanding and
execution. This paper investigates ICL on Large Vision-Language Models (LVLMs)
and explores the policies of multi-modal demonstration selection. Existing
research efforts in ICL face significant challenges: First, they rely on
pre-defined demonstrations or heuristic selecting strategies based on human
intuition, which are usually inadequate for covering diverse task requirements,
leading to sub-optimal solutions; Second, individually selecting each
demonstration fails in modeling the interactions between them, resulting in
information redundancy. Unlike these prevailing efforts, we propose a new
exploration-exploitation reinforcement learning framework, which explores
policies to fuse multi-modal information and adaptively select adequate
demonstrations as an integrated whole. The framework allows LVLMs to optimize
themselves by continually refining their demonstrations through
self-exploration, enabling the ability to autonomously identify and generate
the most effective selection policies for in-context learning. Experimental
results verify the superior performance of our approach on four Visual
Question-Answering (VQA) datasets, demonstrating its effectiveness in enhancing
the generalization capability of few-shot LVLMs.

</details>


### [116] [Urban1960SatSeg: Unsupervised Semantic Segmentation of Mid-20$^{th}$ century Urban Landscapes with Satellite Imageries](https://arxiv.org/abs/2506.09476)
*Tianxiang Hao,Lixian Zhang,Yingjia Zhang,Mengxuan Chen,Jinxiao Zhang,Haohuan Fu*

Main category: cs.CV

TL;DR: 论文提出了Urban1960SatBench数据集和Urban1960SatUSM框架，用于历史卫星影像的无监督语义分割，解决了质量退化和标注缺失问题。


<details>
  <summary>Details</summary>
Motivation: 历史卫星影像（如20世纪中叶的Keyhole数据）对理解早期城市发展至关重要，但质量退化和标注缺失阻碍了语义分割研究。

Method: 提出Urban1960SatBench数据集（标注面积1240平方公里）和Urban1960SatUSM框架（基于自监督学习，采用置信度对齐机制和焦点置信度损失）。

Result: Urban1960SatUSM在历史城市场景分割中显著优于现有无监督方法。

Conclusion: 该研究为利用现代计算机视觉进行长期城市变化的定量研究提供了新工具。

Abstract: Historical satellite imagery, such as mid-20$^{th}$ century Keyhole data,
offers rare insights into understanding early urban development and long-term
transformation. However, severe quality degradation (e.g., distortion,
misalignment, and spectral scarcity) and annotation absence have long hindered
semantic segmentation on such historical RS imagery. To bridge this gap and
enhance understanding of urban development, we introduce
$\textbf{Urban1960SatBench}$, an annotated segmentation dataset based on
historical satellite imagery with the earliest observation time among all
existing segmentation datasets, along with a benchmark framework for
unsupervised segmentation tasks, $\textbf{Urban1960SatUSM}$. First,
$\textbf{Urban1960SatBench}$ serves as a novel, expertly annotated semantic
segmentation dataset built on mid-20$^{th}$ century Keyhole imagery, covering
1,240 km$^2$ and key urban classes (buildings, roads, farmland, water). As the
earliest segmentation dataset of its kind, it provides a pioneering benchmark
for historical urban understanding. Second,
$\textbf{Urban1960SatUSM}$(Unsupervised Segmentation Model) is a novel
unsupervised semantic segmentation framework for historical RS imagery. It
employs a confidence-aware alignment mechanism and focal-confidence loss based
on a self-supervised learning architecture, which generates robust
pseudo-labels and adaptively prioritizes prediction difficulty and label
reliability to improve unsupervised segmentation on noisy historical data
without manual supervision. Experiments show Urban1960SatUSM significantly
outperforms existing unsupervised segmentation methods on Urban1960SatSeg for
segmenting historical urban scenes, promising in paving the way for
quantitative studies of long-term urban change using modern computer vision.
Our benchmark and supplementary material are available at
https://github.com/Tianxiang-Hao/Urban1960SatSeg.

</details>


### [117] [TinySplat: Feedforward Approach for Generating Compact 3D Scene Representation](https://arxiv.org/abs/2506.09479)
*Zetian Song,Jiaye Fu,Jiaqi Zhang,Xiaohan Lu,Chuanmin Jia,Siwei Ma,Wen Gao*

Main category: cs.CV

TL;DR: TinySplat提出了一种新的前馈方法，用于生成紧凑的3D场景表示，通过消除冗余实现了100倍以上的压缩效果。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈3D高斯泼溅（3DGS）方法虽然重建速度快，但存储成本高，且现有压缩方法因架构不兼容无法适用。

Method: TinySplat结合了无训练压缩框架，包括View-Projection Transformation（VPT）减少几何冗余，Visibility-Aware Basis Reduction（VABR）减少感知冗余，以及视频编解码器减少空间冗余。

Result: 在多个基准数据集上，TinySplat实现了100倍以上的压缩效果，存储大小仅为现有最佳方法的6%，编码时间减少75%，解码时间减少99%。

Conclusion: TinySplat提供了一种高效且紧凑的3D场景表示方法，显著降低了存储和计算成本。

Abstract: The recent development of feedforward 3D Gaussian Splatting (3DGS) presents a
new paradigm to reconstruct 3D scenes. Using neural networks trained on
large-scale multi-view datasets, it can directly infer 3DGS representations
from sparse input views. Although the feedforward approach achieves high
reconstruction speed, it still suffers from the substantial storage cost of 3D
Gaussians. Existing 3DGS compression methods relying on scene-wise optimization
are not applicable due to architectural incompatibilities. To overcome this
limitation, we propose TinySplat, a complete feedforward approach for
generating compact 3D scene representations. Built upon standard feedforward
3DGS methods, TinySplat integrates a training-free compression framework that
systematically eliminates key sources of redundancy. Specifically, we introduce
View-Projection Transformation (VPT) to reduce geometric redundancy by
projecting geometric parameters into a more compact space. We further present
Visibility-Aware Basis Reduction (VABR), which mitigates perceptual redundancy
by aligning feature energy along dominant viewing directions via basis
transformation. Lastly, spatial redundancy is addressed through an
off-the-shelf video codec. Comprehensive experimental results on multiple
benchmark datasets demonstrate that TinySplat achieves over 100x compression
for 3D Gaussian data generated by feedforward methods. Compared to the
state-of-the-art compression approach, we achieve comparable quality with only
6% of the storage size. Meanwhile, our compression framework requires only 25%
of the encoding time and 1% of the decoding time.

</details>


### [118] [Marrying Autoregressive Transformer and Diffusion with Multi-Reference Autoregression](https://arxiv.org/abs/2506.09482)
*Dingcheng Zhen,Qian Qiao,Tan Yu,Kangxi Wu,Ziwei Zhang,Siyuan Liu,Shunshun Yin,Ming Tao*

Main category: cs.CV

TL;DR: TransDiff结合自回归Transformer和扩散模型，显著提升图像生成性能，并引入多参考自回归（MRAR）进一步优化。


<details>
  <summary>Details</summary>
Motivation: 结合自回归Transformer和扩散模型的优势，提升图像生成的质量和效率。

Method: 使用扩散模型估计图像样本分布，并通过MRAR范式实现多参考自回归生成。

Result: 在ImageNet 256x256上，FID为1.61，IS为293.4，推理速度显著快于现有方法。MRAR进一步将FID降至1.42。

Conclusion: TransDiff为图像生成领域开辟了新方向，结合MRAR进一步提升了性能。

Abstract: We introduce TransDiff, the first image generation model that marries
Autoregressive (AR) Transformer with diffusion models. In this joint modeling
framework, TransDiff encodes labels and images into high-level semantic
features and employs a diffusion model to estimate the distribution of image
samples. On the ImageNet 256x256 benchmark, TransDiff significantly outperforms
other image generation models based on standalone AR Transformer or diffusion
models. Specifically, TransDiff achieves a Fr\'echet Inception Distance (FID)
of 1.61 and an Inception Score (IS) of 293.4, and further provides x2 faster
inference latency compared to state-of-the-art methods based on AR Transformer
and x112 faster inference compared to diffusion-only models. Furthermore,
building on the TransDiff model, we introduce a novel image generation paradigm
called Multi-Reference Autoregression (MRAR), which performs autoregressive
generation by predicting the next image. MRAR enables the model to reference
multiple previously generated images, thereby facilitating the learning of more
diverse representations and improving the quality of generated images in
subsequent iterations. By applying MRAR, the performance of TransDiff is
improved, with the FID reduced from 1.61 to 1.42. We expect TransDiff to open
up a new frontier in the field of image generation.

</details>


### [119] [Generalized Gaussian Entropy Model for Point Cloud Attribute Compression with Dynamic Likelihood Intervals](https://arxiv.org/abs/2506.09510)
*Changhao Peng,Yuqi Ye,Wei Gao*

Main category: cs.CV

TL;DR: 论文提出了一种广义高斯熵模型和动态调整似然区间的方法，显著提升了点云属性压缩的性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法中熵参数估计未充分利用信息，且固定似然区间限制了模型性能。

Method: 引入广义高斯熵模型控制尾部形状，并提出均值误差判别器动态调整似然区间。

Result: 实验表明，该方法在三种基于VAE的点云属性压缩模型中显著提升了率失真性能。

Conclusion: 该方法不仅适用于点云压缩，还可推广到图像和视频压缩任务。

Abstract: Gaussian and Laplacian entropy models are proved effective in learned point
cloud attribute compression, as they assist in arithmetic coding of latents.
However, we demonstrate through experiments that there is still unutilized
information in entropy parameters estimated by neural networks in current
methods, which can be used for more accurate probability estimation. Thus we
introduce generalized Gaussian entropy model, which controls the tail shape
through shape parameter to more accurately estimate the probability of latents.
Meanwhile, to the best of our knowledge, existing methods use fixed likelihood
intervals for each integer during arithmetic coding, which limits model
performance. We propose Mean Error Discriminator (MED) to determine whether the
entropy parameter estimation is accurate and then dynamically adjust likelihood
intervals. Experiments show that our method significantly improves
rate-distortion (RD) performance on three VAE-based models for point cloud
attribute compression, and our method can be applied to other compression
tasks, such as image and video compression.

</details>


### [120] [Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints](https://arxiv.org/abs/2506.09748)
*Xiangkai Zhang,Xiang Zhou,Mao Chen,Yuchen Lu,Xu Yang,Zhiyong Liu*

Main category: cs.CV

TL;DR: 提出了一种基于层次化跨源图像匹配的无人机绝对定位方法，结合语义感知与结构约束的粗匹配模块和轻量级细粒度匹配模块，显著提升了定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号不可用时，无人机绝对定位面临挑战，现有视觉定位方法因跨源差异和时间变化导致匹配困难。

Method: 采用层次化跨源图像匹配，包括语义感知与结构约束的粗匹配模块和细粒度匹配模块，结合图像检索技术构建定位流程。

Result: 在公开基准数据集和新CS-UAV数据集上验证了方法的高精度和鲁棒性。

Conclusion: 该方法在复杂条件下有效解决了无人机绝对定位问题，具有实际应用潜力。

Abstract: Absolute localization, aiming to determine an agent's location with respect
to a global reference, is crucial for unmanned aerial vehicles (UAVs) in
various applications, but it becomes challenging when global navigation
satellite system (GNSS) signals are unavailable. Vision-based absolute
localization methods, which locate the current view of the UAV in a reference
satellite map to estimate its position, have become popular in GNSS-denied
scenarios. However, existing methods mostly rely on traditional and low-level
image matching, suffering from difficulties due to significant differences
introduced by cross-source discrepancies and temporal variations. To overcome
these limitations, in this paper, we introduce a hierarchical cross-source
image matching method designed for UAV absolute localization, which integrates
a semantic-aware and structure-constrained coarse matching module with a
lightweight fine-grained matching module. Specifically, in the coarse matching
module, semantic features derived from a vision foundation model first
establish region-level correspondences under semantic and structural
constraints. Then, the fine-grained matching module is applied to extract fine
features and establish pixel-level correspondences. Building upon this, a UAV
absolute visual localization pipeline is constructed without any reliance on
relative localization techniques, mainly by employing an image retrieval module
before the proposed hierarchical image matching modules. Experimental
evaluations on public benchmark datasets and a newly introduced CS-UAV dataset
demonstrate superior accuracy and robustness of the proposed method under
various challenging conditions, confirming its effectiveness.

</details>


### [121] [HAIF-GS: Hierarchical and Induced Flow-Guided Gaussian Splatting for Dynamic Scene](https://arxiv.org/abs/2506.09518)
*Jianing Chen,Zehao Li,Yujun Cai,Hao Jiang,Chengxuan Qian,Juyuan Kang,Shuqin Gao,Honglong Zhao,Tianlu Mao,Yucheng Zhang*

Main category: cs.CV

TL;DR: HAIF-GS提出了一种基于稀疏锚点驱动的动态建模框架，解决了动态3D场景重建中的冗余更新、运动监督不足和非刚性变形建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有动态3D高斯泼溅方法在动态场景中存在冗余高斯更新、运动监督不足和非刚性变形建模弱的问题，导致重建效果不佳。

Method: HAIF-GS通过锚点过滤器识别运动相关区域，利用自监督的流引导变形模块和多层次锚点传播机制，实现高效动态建模。

Result: 实验表明，HAIF-GS在渲染质量、时间一致性和重建效率上显著优于现有动态3DGS方法。

Conclusion: HAIF-GS为动态3D场景重建提供了一种高效且一致的解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular videos remains a fundamental
challenge in 3D vision. While 3D Gaussian Splatting (3DGS) achieves real-time
rendering in static settings, extending it to dynamic scenes is challenging due
to the difficulty of learning structured and temporally consistent motion
representations. This challenge often manifests as three limitations in
existing methods: redundant Gaussian updates, insufficient motion supervision,
and weak modeling of complex non-rigid deformations. These issues collectively
hinder coherent and efficient dynamic reconstruction. To address these
limitations, we propose HAIF-GS, a unified framework that enables structured
and consistent dynamic modeling through sparse anchor-driven deformation. It
first identifies motion-relevant regions via an Anchor Filter to suppresses
redundant updates in static areas. A self-supervised Induced Flow-Guided
Deformation module induces anchor motion using multi-frame feature aggregation,
eliminating the need for explicit flow labels. To further handle fine-grained
deformations, a Hierarchical Anchor Propagation mechanism increases anchor
resolution based on motion complexity and propagates multi-level
transformations. Extensive experiments on synthetic and real-world benchmarks
validate that HAIF-GS significantly outperforms prior dynamic 3DGS methods in
rendering quality, temporal coherence, and reconstruction efficiency.

</details>


### [122] [OctoNav: Towards Generalist Embodied Navigation](https://arxiv.org/abs/2506.09839)
*Chen Gao,Liankai Jin,Xingyu Peng,Jiazhao Zhang,Yue Deng,Annan Li,He Wang,Si Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种通用导航代理OctoNav-R1，通过多模态和多能力的自由指令导航，并设计了OctoNav-Bench基准和TBA-CoT数据集以支持模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有导航研究分散于不同任务/能力（如ObjNav、ImgNav和VLN），缺乏通用性。本文旨在开发能处理自由指令的通用导航代理。

Method: 提出OctoNav-Bench基准和TBA-CoT数据集，构建基于MLLMs的OctoNav-R1模型，采用三阶段混合训练范式（HTP），包括TBA-SFT、Nav-GPRO和在线强化学习。

Result: OctoNav-R1在性能上优于现有方法。

Conclusion: 通过结合TBA-CoT数据集和HTP训练范式，OctoNav-R1展示了通用导航代理的潜力，提升了模型的推理能力。

Abstract: Embodied navigation stands as a foundation pillar within the broader pursuit
of embodied AI. However, previous navigation research is divided into different
tasks/capabilities, e.g., ObjNav, ImgNav and VLN, where they differ in task
objectives and modalities, making datasets and methods are designed
individually. In this work, we take steps toward generalist navigation agents,
which can follow free-form instructions that include arbitrary compounds of
multi-modal and multi-capability. To achieve this, we propose a large-scale
benchmark and corresponding method, termed OctoNav-Bench and OctoNav-R1.
Specifically, OctoNav-Bench features continuous environments and is constructed
via a designed annotation pipeline. We thoroughly craft instruction-trajectory
pairs, where instructions are diverse in free-form with arbitrary modality and
capability. Also, we construct a Think-Before-Action (TBA-CoT) dataset within
OctoNav-Bench to provide the thinking process behind actions. For OctoNav-R1,
we build it upon MLLMs and adapt it to a VLA-type model, which can produce
low-level actions solely based on 2D visual observations. Moreover, we design a
Hybrid Training Paradigm (HTP) that consists of three stages, i.e.,
Action-/TBA-SFT, Nav-GPRO, and Online RL stages. Each stage contains
specifically designed learning policies and rewards. Importantly, for TBA-SFT
and Nav-GRPO designs, we are inspired by the OpenAI-o1 and DeepSeek-R1, which
show impressive reasoning ability via thinking-before-answer. Thus, we aim to
investigate how to achieve thinking-before-action in the embodied navigation
field, to improve model's reasoning ability toward generalists. Specifically,
we propose TBA-SFT to utilize the TBA-CoT dataset to fine-tune the model as a
cold-start phrase and then leverage Nav-GPRO to improve its thinking ability.
Finally, OctoNav-R1 shows superior performance compared with previous methods.

</details>


### [123] [Revisit What You See: Disclose Language Prior in Vision Tokens for Efficient Guided Decoding of LVLMs](https://arxiv.org/abs/2506.09522)
*Beomsik Cho,Jaehyung Kim*

Main category: cs.CV

TL;DR: ReVisiT是一种简单有效的解码方法，通过引用视觉标记来指导大型视觉语言模型（LVLM）的文本生成，提升视觉信息的利用。


<details>
  <summary>Details</summary>
Motivation: 传统LVLM的解码策略未能充分利用视觉信息，导致视觉无关的响应，现有方法通常需要额外训练或多步推理。

Method: ReVisiT将视觉标记投影到文本标记分布空间，通过约束散度最小化动态选择最相关的视觉标记，并用于优化输出分布。

Result: 在三个LVLM幻觉基准测试中，ReVisiT显著提升了视觉相关性，计算开销极小，且性能优于现有方法，计算成本降低至2倍。

Conclusion: ReVisiT是一种高效且无需额外训练的解码方法，显著提升了LVLM的视觉信息利用能力。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across various multimodal tasks by integrating visual perception with language
understanding. However, conventional decoding strategies of LVLMs often fail to
successfully utilize visual information, leading to visually ungrounded
responses. While various approaches have been proposed to address this
limitation, they typically require additional training, multi-step inference
procedures, or external model dependencies. This paper introduces ReVisiT, a
simple yet effective decoding method that references vision tokens to guide the
text generation process in LVLMs. Our approach leverages the semantic
information embedded within vision tokens by projecting them into the text
token distribution space, and dynamically selecting the most relevant vision
token at each decoding step through constrained divergence minimization. This
selected vision token is then used to refine the output distribution to better
incorporate visual semantics. Experiments on three LVLM hallucination
benchmarks with two recent LVLMs demonstrate that ReVisiT consistently enhances
visual grounding with minimal computational overhead. Moreover, our method
achieves competitive or superior results relative to state-of-the-art baselines
while reducing computational costs for up to $2\times$.

</details>


### [124] [ReSim: Reliable World Simulation for Autonomous Driving](https://arxiv.org/abs/2506.09981)
*Jiazhi Yang,Kashyap Chitta,Shenyuan Gao,Long Chen,Yuqian Shao,Xiaosong Jia,Hongyang Li,Andreas Geiger,Xiangyu Yue,Li Chen*

Main category: cs.CV

TL;DR: 论文提出ReSim模型，通过结合真实世界和模拟驾驶数据，提升驾驶场景模拟的多样性和可靠性，并引入Video2Reward模块评估奖励信号。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶世界模型仅基于安全专家轨迹数据，难以模拟危险或非专家行为，限制了其应用范围。

Method: 结合真实驾驶数据与模拟器中的非专家数据，构建可控世界模型，采用扩散变换器架构的视频生成器，并优化条件信号集成。

Result: ReSim模型在视觉保真度上提升44%，专家和非专家行为的可控性提高50%以上，NAVSIM上的规划和策略选择性能分别提升2%和25%。

Conclusion: ReSim通过数据多样化和模型优化，显著提升了驾驶场景模拟的可靠性和实用性。

Abstract: How can we reliably simulate future driving scenarios under a wide range of
ego driving behaviors? Recent driving world models, developed exclusively on
real-world driving data composed mainly of safe expert trajectories, struggle
to follow hazardous or non-expert behaviors, which are rare in such data. This
limitation restricts their applicability to tasks such as policy evaluation. In
this work, we address this challenge by enriching real-world human
demonstrations with diverse non-expert data collected from a driving simulator
(e.g., CARLA), and building a controllable world model trained on this
heterogeneous corpus. Starting with a video generator featuring a diffusion
transformer architecture, we devise several strategies to effectively integrate
conditioning signals and improve prediction controllability and fidelity. The
resulting model, ReSim, enables Reliable Simulation of diverse open-world
driving scenarios under various actions, including hazardous non-expert ones.
To close the gap between high-fidelity simulation and applications that require
reward signals to judge different actions, we introduce a Video2Reward module
that estimates a reward from ReSim's simulated future. Our ReSim paradigm
achieves up to 44% higher visual fidelity, improves controllability for both
expert and non-expert actions by over 50%, and boosts planning and policy
selection performance on NAVSIM by 2% and 25%, respectively.

</details>


### [125] [Gaussian Herding across Pens: An Optimal Transport Perspective on Global Gaussian Reduction for 3DGS](https://arxiv.org/abs/2506.09534)
*Tao Wang,Mengyu Li,Geduo Zeng,Cheng Meng,Qiong Zhang*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）是一种强大的辐射场渲染技术，但通常需要数百万冗余的高斯基元，占用大量内存和渲染资源。本文提出了一种基于最优传输的全局高斯混合缩减方法，显著减少了高斯基元数量，同时保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS压缩方法基于启发式重要性评分修剪高斯基元，缺乏全局保真度保证。本文旨在填补这一空白。

Method: 通过KD树分区最小化复合传输散度，生成紧凑几何表示，并解耦外观与几何属性，用更少的高斯基元微调颜色和透明度。

Result: 实验表明，该方法仅需10%的高斯基元即可达到与原始3DGS相当的渲染质量（PSNR、SSIM、LPIPS），且优于现有压缩技术。

Conclusion: 该方法适用于任何3DGS流程，为轻量级神经渲染提供了高效且通用的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful technique for radiance
field rendering, but it typically requires millions of redundant Gaussian
primitives, overwhelming memory and rendering budgets. Existing compaction
approaches address this by pruning Gaussians based on heuristic importance
scores, without global fidelity guarantee. To bridge this gap, we propose a
novel optimal transport perspective that casts 3DGS compaction as global
Gaussian mixture reduction. Specifically, we first minimize the composite
transport divergence over a KD-tree partition to produce a compact geometric
representation, and then decouple appearance from geometry by fine-tuning color
and opacity attributes with far fewer Gaussian primitives. Experiments on
benchmark datasets show that our method (i) yields negligible loss in rendering
quality (PSNR, SSIM, LPIPS) compared to vanilla 3DGS with only 10% Gaussians;
and (ii) consistently outperforms state-of-the-art 3DGS compaction techniques.
Notably, our method is applicable to any stage of vanilla or accelerated 3DGS
pipelines, providing an efficient and agnostic pathway to lightweight neural
rendering.

</details>


### [126] [AngleRoCL: Angle-Robust Concept Learning for Physically View-Invariant T2I Adversarial Patches](https://arxiv.org/abs/2506.09538)
*Wenjun Ji,Yuxiang Fu,Luyang Ying,Deng-Ping Fan,Yuyi Wang,Ming-Ming Cheng,Ivor Tsang,Qing Guo*

Main category: cs.CV

TL;DR: 本文研究了文本到图像（T2I）扩散模型生成的对抗性补丁在不同视角下的攻击效果，提出了Angle-Robust Concept Learning（AngleRoCL）方法，显著提升了补丁的角度鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了T2I对抗性补丁在物理世界中不同视角下的攻击效果，本文旨在解决这一问题。

Method: 提出了AngleRoCL方法，通过学习通用概念（文本嵌入）来生成具有角度鲁棒性的补丁。

Result: 实验表明，AngleRoCL显著提升了补丁的角度鲁棒性，攻击成功率在挑战性视角下仍保持较高水平。

Conclusion: 本文揭示了T2I生成内容中文本概念与物理属性的关系，为角度鲁棒性补丁的研究提供了新思路。

Abstract: Cutting-edge works have demonstrated that text-to-image (T2I) diffusion
models can generate adversarial patches that mislead state-of-the-art object
detectors in the physical world, revealing detectors' vulnerabilities and
risks. However, these methods neglect the T2I patches' attack effectiveness
when observed from different views in the physical world (i.e., angle
robustness of the T2I adversarial patches). In this paper, we study the angle
robustness of T2I adversarial patches comprehensively, revealing their
angle-robust issues, demonstrating that texts affect the angle robustness of
generated patches significantly, and task-specific linguistic instructions fail
to enhance the angle robustness. Motivated by the studies, we introduce
Angle-Robust Concept Learning (AngleRoCL), a simple and flexible approach that
learns a generalizable concept (i.e., text embeddings in implementation)
representing the capability of generating angle-robust patches. The learned
concept can be incorporated into textual prompts and guides T2I models to
generate patches with their attack effectiveness inherently resistant to
viewpoint variations. Through extensive simulation and physical-world
experiments on five SOTA detectors across multiple views, we demonstrate that
AngleRoCL significantly enhances the angle robustness of T2I adversarial
patches compared to baseline methods. Our patches maintain high attack success
rates even under challenging viewing conditions, with over 50% average relative
improvement in attack effectiveness across multiple angles. This research
advances the understanding of physically angle-robust patches and provides
insights into the relationship between textual concepts and physical properties
in T2I-generated contents.

</details>


### [127] [3DGeoDet: General-purpose Geometry-aware Image-based 3D Object Detection](https://arxiv.org/abs/2506.09541)
*Yi Zhang,Yi Wang,Yawen Cui,Lap-Pui Chau*

Main category: cs.CV

TL;DR: 3DGeoDet是一种新颖的几何感知3D物体检测方法，通过显式和隐式3D几何表示提升性能，无需3D信号监督。


<details>
  <summary>Details</summary>
Motivation: 解决基于图像的3D物体检测任务中缺乏3D几何线索的问题，减少图像与3D表示之间的模糊性。

Method: 利用预测的深度信息生成显式（体素占用注意力）和隐式（TSDF）3D几何表示，结合两者提升3D感知能力。

Result: 在多个数据集（SUN RGB-D、ScanNetV2、KITTI）上显著优于现有方法，性能提升显著。

Conclusion: 3DGeoDet通过几何感知表示实现了高效的端到端训练，适用于多样环境中的单视图和多视图检测任务。

Abstract: This paper proposes 3DGeoDet, a novel geometry-aware 3D object detection
approach that effectively handles single- and multi-view RGB images in indoor
and outdoor environments, showcasing its general-purpose applicability. The key
challenge for image-based 3D object detection tasks is the lack of 3D geometric
cues, which leads to ambiguity in establishing correspondences between images
and 3D representations. To tackle this problem, 3DGeoDet generates efficient 3D
geometric representations in both explicit and implicit manners based on
predicted depth information. Specifically, we utilize the predicted depth to
learn voxel occupancy and optimize the voxelized 3D feature volume explicitly
through the proposed voxel occupancy attention. To further enhance 3D
awareness, the feature volume is integrated with an implicit 3D representation,
the truncated signed distance function (TSDF). Without requiring supervision
from 3D signals, we significantly improve the model's comprehension of 3D
geometry by leveraging intermediate 3D representations and achieve end-to-end
training. Our approach surpasses the performance of state-of-the-art
image-based methods on both single- and multi-view benchmark datasets across
diverse environments, achieving a 9.3 mAP@0.5 improvement on the SUN RGB-D
dataset, a 3.3 mAP@0.5 improvement on the ScanNetV2 dataset, and a 0.19
AP3D@0.7 improvement on the KITTI dataset. The project page is available at:
https://cindy0725.github.io/3DGeoDet/.

</details>


### [128] [GLD-Road:A global-local decoding road network extraction model for remote sensing images](https://arxiv.org/abs/2506.09553)
*Ligao Deng,Yupeng Deng,Yu Meng,Jingbo Chen,Zhihao Xi,Diyou Liu,Qifeng Chu*

Main category: cs.CV

TL;DR: GLD-Road是一种两阶段模型，结合全局效率和局部精度，用于高效提取道路网络。


<details>
  <summary>Details</summary>
Motivation: 手动标注道路网络成本高，现有深度学习方法存在效率或精度问题。

Method: GLD-Road先检测道路节点并通过连接模块连接，再通过局部搜索迭代修复断裂道路。

Result: GLD-Road在APLS指标上优于现有方法（City-Scale提升1.9%，SpaceNet3提升0.67%），并显著减少检索时间（比Sat2Graph快40%，比RNGDet++快92%）。

Conclusion: GLD-Road在道路网络提取中实现了高效与高精度的平衡，适用于实际应用。

Abstract: Road networks are crucial for mapping, autonomous driving, and disaster
response. While manual annotation is costly, deep learning offers efficient
extraction. Current methods include postprocessing (prone to errors), global
parallel (fast but misses nodes), and local iterative (accurate but slow). We
propose GLD-Road, a two-stage model combining global efficiency and local
precision. First, it detects road nodes and connects them via a Connect Module.
Then, it iteratively refines broken roads using local searches, drastically
reducing computation. Experiments show GLD-Road outperforms state-of-the-art
methods, improving APLS by 1.9% (City-Scale) and 0.67% (SpaceNet3). It also
reduces retrieval time by 40% vs. Sat2Graph (global) and 92% vs. RNGDet++
(local). The experimental results are available at
https://github.com/ucas-dlg/GLD-Road.

</details>


### [129] [AD^2-Bench: A Hierarchical CoT Benchmark for MLLM in Autonomous Driving under Adverse Conditions](https://arxiv.org/abs/2506.09557)
*Zhaoyang Wei,Chenhui Qiang,Bowen Jiang,Xumeng Han,Xuehui Yu,Zhenjun Han*

Main category: cs.CV

TL;DR: AD^2-Bench是首个针对恶劣天气和复杂场景下自动驾驶的Chain-of-Thought（CoT）基准测试，包含5.4k高质量标注实例，评估结果显示现有MLLMs准确率低于60%。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未充分评估CoT在恶劣天气和复杂交通环境中的表现，AD^2-Bench填补了这一空白。

Method: 构建AD^2-Bench基准，涵盖多样恶劣环境数据、细粒度标注和专用评估框架。

Result: 评估显示当前MLLMs准确率不足60%，表明其推理能力仍需提升。

Conclusion: AD^2-Bench为自动驾驶研究提供了标准化评估平台，推动MLLMs推理能力的进步。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful approach to
enhance the structured, multi-step decision-making capabilities of Multi-Modal
Large Models (MLLMs), is particularly crucial for autonomous driving with
adverse weather conditions and complex traffic environments. However, existing
benchmarks have largely overlooked the need for rigorous evaluation of CoT
processes in these specific and challenging scenarios. To address this critical
gap, we introduce AD^2-Bench, the first Chain-of-Thought benchmark specifically
designed for autonomous driving with adverse weather and complex scenes.
AD^2-Bench is meticulously constructed to fulfill three key criteria:
comprehensive data coverage across diverse adverse environments, fine-grained
annotations that support multi-step reasoning, and a dedicated evaluation
framework tailored for assessing CoT performance. The core contribution of
AD^2-Bench is its extensive collection of over 5.4k high-quality, manually
annotated CoT instances. Each intermediate reasoning step in these annotations
is treated as an atomic unit with explicit ground truth, enabling unprecedented
fine-grained analysis of MLLMs' inferential processes under text-level,
point-level, and region-level visual prompts. Our comprehensive evaluation of
state-of-the-art MLLMs on AD^2-Bench reveals accuracy below 60%, highlighting
the benchmark's difficulty and the need to advance robust, interpretable
end-to-end autonomous driving systems. AD^2-Bench thus provides a standardized
evaluation platform, driving research forward by improving MLLMs' reasoning in
autonomous driving, making it an invaluable resource.

</details>


### [130] [SemanticSplat: Feed-Forward 3D Scene Understanding with Language-Aware Gaussian Fields](https://arxiv.org/abs/2506.09565)
*Qijing Li,Jingxiang Sun,Liang An,Zhaoqi Su,Hongwen Zhang,Yebin Liu*

Main category: cs.CV

TL;DR: SemanticSplat提出了一种基于3D高斯和语义属性的前馈式3D重建方法，联合建模几何、外观和语义，解决了现有方法在语义理解和几何重建上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有前馈式3D场景理解方法（如LSM）仅能提取基于语言的语义，且几何重建质量低；而逐场景优化方法依赖密集输入视图，实用性差。

Method: SemanticSplat通过融合多样特征场（如LSeg、SAM）和成本体积表示，预测语义各向异性高斯，并采用两阶段蒸馏框架从稀疏视图图像重建多模态语义特征场。

Result: 实验证明该方法在可提示和开放词汇分割等3D场景理解任务中表现优异。

Conclusion: SemanticSplat通过联合建模几何、外观和语义，实现了更全面的3D场景理解。

Abstract: Holistic 3D scene understanding, which jointly models geometry, appearance,
and semantics, is crucial for applications like augmented reality and robotic
interaction. Existing feed-forward 3D scene understanding methods (e.g., LSM)
are limited to extracting language-based semantics from scenes, failing to
achieve holistic scene comprehension. Additionally, they suffer from
low-quality geometry reconstruction and noisy artifacts. In contrast, per-scene
optimization methods rely on dense input views, which reduces practicality and
increases complexity during deployment. In this paper, we propose
SemanticSplat, a feed-forward semantic-aware 3D reconstruction method, which
unifies 3D Gaussians with latent semantic attributes for joint
geometry-appearance-semantics modeling. To predict the semantic anisotropic
Gaussians, SemanticSplat fuses diverse feature fields (e.g., LSeg, SAM) with a
cost volume representation that stores cross-view feature similarities,
enhancing coherent and accurate scene comprehension. Leveraging a two-stage
distillation framework, SemanticSplat reconstructs a holistic multi-modal
semantic feature field from sparse-view images. Experiments demonstrate the
effectiveness of our method for 3D scene understanding tasks like promptable
and open-vocabulary segmentation. Video results are available at
https://semanticsplat.github.io.

</details>


### [131] [Consistent Story Generation with Asymmetry Zigzag Sampling](https://arxiv.org/abs/2506.09612)
*Mingxiao LI,mang ning,Marie-Francine Moens*

Main category: cs.CV

TL;DR: 提出了一种名为Zigzag Sampling with Asymmetric Prompts and Visual Sharing的训练无关采样策略，用于提升视觉故事生成中的主题一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成多张图像时难以保持主题一致性，资源密集型或效果有限。

Method: 采用Zigzag采样机制，结合非对称提示和视觉共享模块，交替保留主题特征并传递视觉线索。

Result: 实验表明，该方法在生成连贯一致的视觉故事方面显著优于现有方法。

Conclusion: 提出的训练无关策略有效提升了视觉故事生成的主题一致性。

Abstract: Text-to-image generation models have made significant progress in producing
high-quality images from textual descriptions, yet they continue to struggle
with maintaining subject consistency across multiple images, a fundamental
requirement for visual storytelling. Existing methods attempt to address this
by either fine-tuning models on large-scale story visualization datasets, which
is resource-intensive, or by using training-free techniques that share
information across generations, which still yield limited success. In this
paper, we introduce a novel training-free sampling strategy called Zigzag
Sampling with Asymmetric Prompts and Visual Sharing to enhance subject
consistency in visual story generation. Our approach proposes a zigzag sampling
mechanism that alternates between asymmetric prompting to retain subject
characteristics, while a visual sharing module transfers visual cues across
generated images to %further enforce consistency. Experimental results, based
on both quantitative metrics and qualitative evaluations, demonstrate that our
method significantly outperforms previous approaches in generating coherent and
consistent visual stories. The code is available at
https://github.com/Mingxiao-Li/Asymmetry-Zigzag-StoryDiffusion.

</details>


### [132] [ECAM: A Contrastive Learning Approach to Avoid Environmental Collision in Trajectory Forecasting](https://arxiv.org/abs/2506.09626)
*Giacomo Rosin,Muhammad Rameez Ur Rahman,Sebastiano Vascon*

Main category: cs.CV

TL;DR: 论文提出ECAM模块，通过对比学习提升轨迹预测模型的避障能力，实验表明其显著降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹预测方法常忽略环境因素导致碰撞，需增强避障能力。

Method: 提出ECAM模块，基于对比学习，可集成到现有模型中。

Result: 在ETH/UCY数据集上验证，碰撞率降低40-50%。

Conclusion: ECAM模块有效提升轨迹预测的避障能力，代码开源。

Abstract: Human trajectory forecasting is crucial in applications such as autonomous
driving, robotics and surveillance. Accurate forecasting requires models to
consider various factors, including social interactions, multi-modal
predictions, pedestrian intention and environmental context. While existing
methods account for these factors, they often overlook the impact of the
environment, which leads to collisions with obstacles. This paper introduces
ECAM (Environmental Collision Avoidance Module), a contrastive learning-based
module to enhance collision avoidance ability with the environment. The
proposed module can be integrated into existing trajectory forecasting models,
improving their ability to generate collision-free predictions. We evaluate our
method on the ETH/UCY dataset and quantitatively and qualitatively demonstrate
its collision avoidance capabilities. Our experiments show that
state-of-the-art methods significantly reduce (-40/50%) the collision rate when
integrated with the proposed module. The code is available at
https://github.com/CVML-CFU/ECAM.

</details>


### [133] [HSENet: Hybrid Spatial Encoding Network for 3D Medical Vision-Language Understanding](https://arxiv.org/abs/2506.09634)
*Yanzhao Shi,Xiaodan Zhang,Junzhong Ji,Haoning Jiang,Chengxin Zheng,Yinong Wang,Liangqiong Qu*

Main category: cs.CV

TL;DR: HSENet提出了一种混合空间编码网络，通过双3D视觉编码器和空间打包器，提升了3D医学图像的语言视觉理解能力，显著提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对2D医学图像，难以捕捉复杂的3D解剖结构，导致误诊和诊断幻觉。

Method: HSENet采用双3D视觉编码器感知全局和细节，并通过空间打包器压缩高分辨率3D区域为视觉标记。

Result: 在3D语言视觉检索、医学报告生成和视觉问答任务中均取得最先进性能。

Conclusion: HSENet有效解决了3D医学图像的语言视觉理解问题，具有显著的临床应用价值。

Abstract: Automated 3D CT diagnosis empowers clinicians to make timely, evidence-based
decisions by enhancing diagnostic accuracy and workflow efficiency. While
multimodal large language models (MLLMs) exhibit promising performance in
visual-language understanding, existing methods mainly focus on 2D medical
images, which fundamentally limits their ability to capture complex 3D
anatomical structures. This limitation often leads to misinterpretation of
subtle pathologies and causes diagnostic hallucinations. In this paper, we
present Hybrid Spatial Encoding Network (HSENet), a framework that exploits
enriched 3D medical visual cues by effective visual perception and projection
for accurate and robust vision-language understanding. Specifically, HSENet
employs dual-3D vision encoders to perceive both global volumetric contexts and
fine-grained anatomical details, which are pre-trained by dual-stage alignment
with diagnostic reports. Furthermore, we propose Spatial Packer, an efficient
multimodal projector that condenses high-resolution 3D spatial regions into a
compact set of informative visual tokens via centroid-based compression. By
assigning spatial packers with dual-3D vision encoders, HSENet can seamlessly
perceive and transfer hybrid visual representations to LLM's semantic space,
facilitating accurate diagnostic text generation. Experimental results
demonstrate that our method achieves state-of-the-art performance in 3D
language-visual retrieval (39.85% of R@100, +5.96% gain), 3D medical report
generation (24.01% of BLEU-4, +8.01% gain), and 3D visual question answering
(73.60% of Major Class Accuracy, +1.99% gain), confirming its effectiveness.
Our code is available at https://github.com/YanzhaoShi/HSENet.

</details>


### [134] [DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning](https://arxiv.org/abs/2506.09644)
*Dongxu Liu,Yuang Peng,Haomiao Tang,Yuwei Chen,Chunrui Han,Zheng Ge,Daxin Jiang,Mingxue Liao*

Main category: cs.CV

TL;DR: 论文提出DGAE，通过扩散模型引导解码器，解决高压缩率下自编码器性能下降问题，同时减小潜在空间维度。


<details>
  <summary>Details</summary>
Motivation: 解决GAN训练不稳定性和高压缩率下自编码器性能下降问题，同时追求更高效的潜在表示。

Method: 提出DGAE，利用扩散模型引导解码器恢复潜在表示中未完全解码的信息。

Result: DGAE在高压缩率下性能显著提升，潜在空间缩小2倍，与扩散模型结合在ImageNet-1K图像生成中表现优异。

Conclusion: DGAE有效提升自编码器性能，减小潜在空间维度，加速扩散模型收敛。

Abstract: Autoencoders empower state-of-the-art image and video generative models by
compressing pixels into a latent space through visual tokenization. Although
recent advances have alleviated the performance degradation of autoencoders
under high compression ratios, addressing the training instability caused by
GAN remains an open challenge. While improving spatial compression, we also aim
to minimize the latent space dimensionality, enabling more efficient and
compact representations. To tackle these challenges, we focus on improving the
decoder's expressiveness. Concretely, we propose DGAE, which employs a
diffusion model to guide the decoder in recovering informative signals that are
not fully decoded from the latent representation. With this design, DGAE
effectively mitigates the performance degradation under high spatial
compression rates. At the same time, DGAE achieves state-of-the-art performance
with a 2x smaller latent space. When integrated with Diffusion Models, DGAE
demonstrates competitive performance on image generation for ImageNet-1K and
shows that this compact latent representation facilitates faster convergence of
the diffusion model.

</details>


### [135] [Self-Supervised Multi-Part Articulated Objects Modeling via Deformable Gaussian Splatting and Progressive Primitive Segmentation](https://arxiv.org/abs/2506.09663)
*Haowen Wang,Xiaoping Yuan,Zhao Jin,Zhen Zhao,Zhengping Che,Yousong Xue,Jin Tian,Yakun Huang,Jian Tang*

Main category: cs.CV

TL;DR: DeGSS提出了一种统一框架，通过可变形3D高斯场编码铰接物体的几何、外观和运动，支持无监督的部件分割和精确建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法在缺乏人工标注时难以构建多部件物体的统一表示，DeGSS旨在解决这一问题。

Method: DeGSS将铰接物体建模为可变形3D高斯场，通过平滑变形轨迹实现无监督的部件分割，并支持部件级重建。

Result: 实验表明，DeGSS在准确性和稳定性上优于现有方法，并扩展了合成和真实数据集。

Conclusion: DeGSS为铰接物体的几何和运动建模提供了高效且统一的解决方案。

Abstract: Articulated objects are ubiquitous in everyday life, and accurate 3D
representations of their geometry and motion are critical for numerous
applications. However, in the absence of human annotation, existing approaches
still struggle to build a unified representation for objects that contain
multiple movable parts. We introduce DeGSS, a unified framework that encodes
articulated objects as deformable 3D Gaussian fields, embedding geometry,
appearance, and motion in one compact representation. Each interaction state is
modeled as a smooth deformation of a shared field, and the resulting
deformation trajectories guide a progressive coarse-to-fine part segmentation
that identifies distinct rigid components, all in an unsupervised manner. The
refined field provides a spatially continuous, fully decoupled description of
every part, supporting part-level reconstruction and precise modeling of their
kinematic relationships. To evaluate generalization and realism, we enlarge the
synthetic PartNet-Mobility benchmark and release RS-Art, a real-to-sim dataset
that pairs RGB captures with accurately reverse-engineered 3D models. Extensive
experiments demonstrate that our method outperforms existing methods in both
accuracy and stability.

</details>


### [136] [CINeMA: Conditional Implicit Neural Multi-Modal Atlas for a Spatio-Temporal Representation of the Perinatal Brain](https://arxiv.org/abs/2506.09668)
*Maik Dannecker,Vasiliki Sideri-Lampretsa,Sophie Starck,Angeline Mihailov,Mathieu Milh,Nadine Girard,Guillaume Auzias,Daniel Rueckert*

Main category: cs.CV

TL;DR: CINeMA是一种新型框架，用于创建高分辨率、多模态的胎儿和新生儿脑图谱，适用于低数据环境，显著提高了效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 研究胎儿和新生儿大脑的快速神经发育需要高时空分辨率的脑图谱，但传统方法依赖大数据集，难以应对病理情况下的数据稀缺问题。

Method: CINeMA通过隐式神经表示在潜在空间中操作，避免了计算密集的图像配准，并支持基于解剖特征的灵活条件生成。

Result: CINeMA在准确性、效率和多功能性上超越现有方法，支持组织分割、年龄预测等任务，并能生成合成数据。

Conclusion: CINeMA为脑研究提供了强大工具，代码和图谱已开源。

Abstract: Magnetic resonance imaging of fetal and neonatal brains reveals rapid
neurodevelopment marked by substantial anatomical changes unfolding within
days. Studying this critical stage of the developing human brain, therefore,
requires accurate brain models-referred to as atlases-of high spatial and
temporal resolution. To meet these demands, established traditional atlases and
recently proposed deep learning-based methods rely on large and comprehensive
datasets. This poses a major challenge for studying brains in the presence of
pathologies for which data remains scarce. We address this limitation with
CINeMA (Conditional Implicit Neural Multi-Modal Atlas), a novel framework for
creating high-resolution, spatio-temporal, multimodal brain atlases, suitable
for low-data settings. Unlike established methods, CINeMA operates in latent
space, avoiding compute-intensive image registration and reducing atlas
construction times from days to minutes. Furthermore, it enables flexible
conditioning on anatomical features including GA, birth age, and pathologies
like ventriculomegaly (VM) and agenesis of the corpus callosum (ACC). CINeMA
supports downstream tasks such as tissue segmentation and age prediction
whereas its generative properties enable synthetic data creation and
anatomically informed data augmentation. Surpassing state-of-the-art methods in
accuracy, efficiency, and versatility, CINeMA represents a powerful tool for
advancing brain research. We release the code and atlases at
https://github.com/m-dannecker/CINeMA.

</details>


### [137] [Reasoning Models Are More Easily Gaslighted Than You Think](https://arxiv.org/abs/2506.09677)
*Bin Zhu,Hailong Yin,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文研究了推理模型在误导性用户输入下的鲁棒性，发现即使顶级模型在面对否定提示时准确率显著下降，并提出了GaslightingBench-R基准进一步验证其脆弱性。


<details>
  <summary>Details</summary>
Motivation: 探索推理模型在误导性用户输入下的表现，填补现有研究空白。

Method: 系统评估了三种先进推理模型（o4-mini、Claude-3.7-Sonnet、Gemini-2.5-Flash）在三个多模态基准上的表现，并设计了GaslightingBench-R基准进一步测试。

Result: 模型在面对否定提示时准确率平均下降25-29%，GaslightingBench-R上下降超过53%。

Conclusion: 推理模型在信念持久性方面存在根本性局限，揭示了逐步推理与信念坚持之间的差距。

Abstract: Recent advances in reasoning-centric models promise improved robustness
through mechanisms such as chain-of-thought prompting and test-time scaling.
However, their ability to withstand misleading user input remains
underexplored. In this paper, we conduct a systematic evaluation of three
state-of-the-art reasoning models, i.e., OpenAI's o4-mini, Claude-3.7-Sonnet
and Gemini-2.5-Flash, across three multimodal benchmarks: MMMU, MathVista, and
CharXiv. Our evaluation reveals significant accuracy drops (25-29% on average)
following gaslighting negation prompts, indicating that even top-tier reasoning
models struggle to preserve correct answers under manipulative user feedback.
Built upon the insights of the evaluation and to further probe this
vulnerability, we introduce GaslightingBench-R, a new diagnostic benchmark
specifically designed to evaluate reasoning models' susceptibility to defend
their belief under gaslighting negation prompt. Constructed by filtering and
curating 1,025 challenging samples from the existing benchmarks,
GaslightingBench-R induces even more dramatic failures, with accuracy drops
exceeding 53% on average. Our findings reveal fundamental limitations in the
robustness of reasoning models, highlighting the gap between step-by-step
reasoning and belief persistence.

</details>


### [138] [Adding simple structure at inference improves Vision-Language Compositionality](https://arxiv.org/abs/2506.09691)
*Imanol Miranda,Ander Salaberria,Eneko Agirre,Gorka Azkune*

Main category: cs.CV

TL;DR: 本文提出了一种在推理时增加简单结构的方法，通过分割图像和文本片段，利用VLM匹配对齐部分，提升视觉语言组合性能力。


<details>
  <summary>Details</summary>
Motivation: 现有双编码器视觉语言模型（如CLIP）在组合性方面表现不佳，推理时技术研究较少。

Method: 将图像分割为小块，提取文本片段，利用VLM匹配对齐部分，聚合相似度计算最终得分。

Result: 方法在多种数据集上显著提升模型性能，尤其在属性-对象绑定任务中表现突出。

Conclusion: 推理时技术潜力巨大，图像分割是关键，未来可进一步优化。

Abstract: Dual encoder Vision-Language Models (VLM) such as CLIP are widely used for
image-text retrieval tasks. However, those models struggle with
compositionality, showing a bag-of-words-like behavior that limits their
retrieval performance. Many different training approaches have been proposed to
improve the vision-language compositionality capabilities of those models. In
comparison, inference-time techniques have received little attention. In this
paper, we propose to add simple structure at inference, where, given an image
and a caption: i) we divide the image into different smaller crops, ii) we
extract text segments, capturing objects, attributes and relations, iii) using
a VLM, we find the image crops that better align with text segments obtaining
matches, and iv) we compute the final image-text similarity aggregating the
individual similarities of the matches. Based on various popular dual encoder
VLMs, we evaluate our approach in controlled and natural datasets for VL
compositionality. We find that our approach consistently improves the
performance of evaluated VLMs without any training, which shows the potential
of inference-time techniques. The results are especially good for
attribute-object binding as shown in the controlled dataset. As a result of an
extensive analysis: i) we show that processing image crops is actually
essential for the observed gains in performance, and ii) we identify specific
areas to further improve inference-time approaches.

</details>


### [139] [Towards Practical Alzheimer's Disease Diagnosis: A Lightweight and Interpretable Spiking Neural Model](https://arxiv.org/abs/2506.09695)
*Changwei Wu,Yifei Chen,Yuxin Du,Jinying Zong,Jie Dong,Mingxuan Liu,Yong Peng,Jin Fan,Feiwei Qin,Changmiao Wang*

Main category: cs.CV

TL;DR: FasterSNN是一种混合神经架构，结合了生物启发的LIF神经元、区域自适应卷积和多尺度脉冲注意力，用于高效且稳定的阿尔茨海默病早期诊断。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期诊断受限于主观评估和高成本的多模态成像，而深度学习方法的能耗和计算需求限制了其实际应用。

Method: 提出FasterSNN，整合LIF神经元、区域自适应卷积和多尺度脉冲注意力，以稀疏高效地处理3D MRI数据。

Result: 在基准数据集上，FasterSNN表现出竞争性性能，同时显著提高了效率和稳定性。

Conclusion: FasterSNN为AD筛查提供了一种高效、稳定的解决方案，具有实际应用潜力。

Abstract: Early diagnosis of Alzheimer's Disease (AD), especially at the mild cognitive
impairment (MCI) stage, is vital yet hindered by subjective assessments and the
high cost of multimodal imaging modalities. Although deep learning methods
offer automated alternatives, their energy inefficiency and computational
demands limit real-world deployment, particularly in resource-constrained
settings. As a brain-inspired paradigm, spiking neural networks (SNNs) are
inherently well-suited for modeling the sparse, event-driven patterns of neural
degeneration in AD, offering a promising foundation for interpretable and
low-power medical diagnostics. However, existing SNNs often suffer from weak
expressiveness and unstable training, which restrict their effectiveness in
complex medical tasks. To address these limitations, we propose FasterSNN, a
hybrid neural architecture that integrates biologically inspired LIF neurons
with region-adaptive convolution and multi-scale spiking attention. This design
enables sparse, efficient processing of 3D MRI while preserving diagnostic
accuracy. Experiments on benchmark datasets demonstrate that FasterSNN achieves
competitive performance with substantially improved efficiency and stability,
supporting its potential for practical AD screening. Our source code is
available at https://github.com/wuchangw/FasterSNN.

</details>


### [140] [CHIP: A multi-sensor dataset for 6D pose estimation of chairs in industrial settings](https://arxiv.org/abs/2506.09699)
*Mattia Nardon,Mikel Mujika Agirre,Ander González Tomé,Daniel Sedano Algarabel,Josep Rueda Collell,Ana Paola Caro,Andrea Caraffa,Fabio Poiesi,Paul Ian Chippendale,Davide Boscaini*

Main category: cs.CV

TL;DR: CHIP是首个针对工业环境中机器人操作的6D姿态估计数据集，填补了现有数据集的不足，包含77,811张RGBD图像和自动标注的真实姿态。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计数据集多关注家庭环境，缺乏工业场景的真实性，CHIP旨在解决这一问题。

Method: CHIP数据集包含七种椅子，使用三种RGBD技术捕获，并引入干扰物和遮挡挑战。通过机器人运动学自动标注真实姿态。

Result: 基准测试显示现有方法在CHIP数据集上仍有较大改进空间，凸显了其挑战性。

Conclusion: CHIP填补了工业场景6D姿态估计数据集的空白，为未来研究提供了新方向。

Abstract: Accurate 6D pose estimation of complex objects in 3D environments is
essential for effective robotic manipulation. Yet, existing benchmarks fall
short in evaluating 6D pose estimation methods under realistic industrial
conditions, as most datasets focus on household objects in domestic settings,
while the few available industrial datasets are limited to artificial setups
with objects placed on tables. To bridge this gap, we introduce CHIP, the first
dataset designed for 6D pose estimation of chairs manipulated by a robotic arm
in a real-world industrial environment. CHIP includes seven distinct chairs
captured using three different RGBD sensing technologies and presents unique
challenges, such as distractor objects with fine-grained differences and severe
occlusions caused by the robotic arm and human operators. CHIP comprises 77,811
RGBD images annotated with ground-truth 6D poses automatically derived from the
robot's kinematics, averaging 11,115 annotations per chair. We benchmark CHIP
using three zero-shot 6D pose estimation methods, assessing performance across
different sensor types, localization priors, and occlusion levels. Results show
substantial room for improvement, highlighting the unique challenges posed by
the dataset. CHIP will be publicly released.

</details>


### [141] [Non-Contact Health Monitoring During Daily Personal Care Routines](https://arxiv.org/abs/2506.09718)
*Xulin Ma,Jiankai Tang,Zhang Jiang,Songqin Cheng,Yuanchun Shi,Dong LI,Xin Liu,Daniel McDuff,Xiaojing Liu,Yuntao Wang*

Main category: cs.CV

TL;DR: 论文提出了LADH数据集，结合RGB和红外视频提升远程光电容积描记术（rPPG）在长期健康监测中的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决rPPG在高海拔日常护理场景中因光照变化、遮挡和动态姿势带来的挑战。

Method: 使用240个同步RGB和红外面部视频，结合多任务学习提升生理信号监测性能。

Result: 结合RGB和红外视频输入，心率估计的平均绝对误差为4.99 BPM。

Conclusion: 多任务学习和多模态输入显著提升了rPPG在长期健康监测中的效果。

Abstract: Remote photoplethysmography (rPPG) enables non-contact, continuous monitoring
of physiological signals and offers a practical alternative to traditional
health sensing methods. Although rPPG is promising for daily health monitoring,
its application in long-term personal care scenarios, such as mirror-facing
routines in high-altitude environments, remains challenging due to ambient
lighting variations, frequent occlusions from hand movements, and dynamic
facial postures. To address these challenges, we present LADH (Long-term
Altitude Daily Health), the first long-term rPPG dataset containing 240
synchronized RGB and infrared (IR) facial videos from 21 participants across
five common personal care scenarios, along with ground-truth PPG, respiration,
and blood oxygen signals. Our experiments demonstrate that combining RGB and IR
video inputs improves the accuracy and robustness of non-contact physiological
monitoring, achieving a mean absolute error (MAE) of 4.99 BPM in heart rate
estimation. Furthermore, we find that multi-task learning enhances performance
across multiple physiological indicators simultaneously. Dataset and code are
open at https://github.com/McJackTang/FusionVitals.

</details>


### [142] [The Four Color Theorem for Cell Instance Segmentation](https://arxiv.org/abs/2506.09724)
*Ye Zhang,Yu Zhou,Yifeng Wang,Jun Xiao,Ziyue Wang,Yongbing Zhang,Jianxu Chen*

Main category: cs.CV

TL;DR: 提出了一种基于四色定理的细胞实例分割方法，通过四色编码简化实例区分，并在多种模式下实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 准确区分紧密接触的细胞是生物医学图像分析的关键挑战，现有方法在性能与计算效率之间难以平衡。

Method: 将细胞类比为国家，组织类比为海洋，引入四色编码方案，将实例分割转化为约束语义分割问题，并提出渐进训练策略解决编码不唯一性问题。

Result: 在多种实验模式下，该方法实现了最先进的性能。

Conclusion: 提出的四色编码方法有效简化了细胞实例分割问题，并通过渐进训练策略提升了模型稳定性。

Abstract: Cell instance segmentation is critical to analyzing biomedical images, yet
accurately distinguishing tightly touching cells remains a persistent
challenge. Existing instance segmentation frameworks, including
detection-based, contour-based, and distance mapping-based approaches, have
made significant progress, but balancing model performance with computational
efficiency remains an open problem. In this paper, we propose a novel cell
instance segmentation method inspired by the four-color theorem. By
conceptualizing cells as countries and tissues as oceans, we introduce a
four-color encoding scheme that ensures adjacent instances receive distinct
labels. This reformulation transforms instance segmentation into a constrained
semantic segmentation problem with only four predicted classes, substantially
simplifying the instance differentiation process. To solve the training
instability caused by the non-uniqueness of four-color encoding, we design an
asymptotic training strategy and encoding transformation method. Extensive
experiments on various modes demonstrate our approach achieves state-of-the-art
performance. The code is available at https://github.com/zhangye-zoe/FCIS.

</details>


### [143] [MPFNet: A Multi-Prior Fusion Network with a Progressive Training Strategy for Micro-Expression Recognition](https://arxiv.org/abs/2506.09735)
*Chuang Ma,Shaokai Zhao,Dongdong Zhou,Yu Pei,Zhiguo Luo,Liang Xie,Ye Yan,Erwei Yin*

Main category: cs.CV

TL;DR: 论文提出了一种多先验融合网络（MPFNet），通过渐进式训练策略优化微表情识别任务，显著提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 微表情识别因持续时间短、强度低而更具挑战性，现有方法未能充分利用多源先验知识。

Method: 提出MPFNet，包含通用特征编码器（GFE）和高级特征编码器（AFE），基于I3D和坐标注意力机制，并设计了两种变体MPFNet-P和MPFNet-C。

Result: 在SMIC、CASME II和SAMM数据集上分别达到0.811、0.924和0.857的准确率，性能优于现有方法。

Conclusion: MPFNet通过多源先验知识融合显著提升了微表情识别性能，达到了最先进的水平。

Abstract: Micro-expression recognition (MER), a critical subfield of affective
computing, presents greater challenges than macro-expression recognition due to
its brief duration and low intensity. While incorporating prior knowledge has
been shown to enhance MER performance, existing methods predominantly rely on
simplistic, singular sources of prior knowledge, failing to fully exploit
multi-source information. This paper introduces the Multi-Prior Fusion Network
(MPFNet), leveraging a progressive training strategy to optimize MER tasks. We
propose two complementary encoders: the Generic Feature Encoder (GFE) and the
Advanced Feature Encoder (AFE), both based on Inflated 3D ConvNets (I3D) with
Coordinate Attention (CA) mechanisms, to improve the model's ability to capture
spatiotemporal and channel-specific features. Inspired by developmental
psychology, we present two variants of MPFNet--MPFNet-P and
MPFNet-C--corresponding to two fundamental modes of infant cognitive
development: parallel and hierarchical processing. These variants enable the
evaluation of different strategies for integrating prior knowledge. Extensive
experiments demonstrate that MPFNet significantly improves MER accuracy while
maintaining balanced performance across categories, achieving accuracies of
0.811, 0.924, and 0.857 on the SMIC, CASME II, and SAMM datasets, respectively.
To the best of our knowledge, our approach achieves state-of-the-art
performance on the SMIC and SAMM datasets.

</details>


### [144] [Vision Matters: Simple Visual Perturbations Can Boost Multimodal Math Reasoning](https://arxiv.org/abs/2506.09736)
*Yuting Li,Lai Wei,Kaipeng Zheng,Jingyuan Huang,Linghe Kong,Lichao Sun,Weiran Huang*

Main category: cs.CV

TL;DR: 研究发现，当前多模态大语言模型（MLLMs）在视觉处理上表现不足，仅用图像描述的语言模型性能可媲美甚至超越MLLMs。作者提出了一种无需修改算法或额外数据的视觉扰动框架，显著提升了模型的感知鲁棒性和数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在视觉处理和推理整合上存在不足，仅依赖视觉描述的语言模型表现更优，表明视觉信息的有效利用是关键。

Method: 提出三种视觉扰动策略（干扰拼接、保持主导性的混合、随机旋转），可无缝集成到现有训练流程中。

Result: 实验表明，视觉扰动显著提升了数学推理性能，效果与算法改进相当，并在开源7B RL调优模型中取得竞争力。

Conclusion: 视觉扰动在多模态数学推理中至关重要，揭示了‘更好的推理始于更好的视觉处理’。

Abstract: Despite the rapid progress of multimodal large language models (MLLMs), they
have largely overlooked the importance of visual processing. In a simple yet
revealing experiment, we interestingly find that language-only models, when
provided with image captions, can achieve comparable or even better performance
than MLLMs that consume raw visual inputs. This suggests that current MLLMs may
generate accurate visual descriptions but fail to effectively integrate them
during reasoning. Motivated by this, we propose a simple visual perturbation
framework that enhances perceptual robustness without requiring algorithmic
modifications or additional training data. Our approach introduces three
targeted perturbations: distractor concatenation, dominance-preserving mixup,
and random rotation, that can be easily integrated into existing post-training
pipelines including SFT, DPO, and GRPO. Through extensive experiments across
multiple datasets, we demonstrate consistent improvements in mathematical
reasoning performance, with gains comparable to those achieved through
algorithmic changes. Additionally, we achieve competitive performance among
open-source 7B RL-tuned models by training Qwen2.5-VL-7B with visual
perturbation. Through comprehensive ablation studies, we analyze the
effectiveness of different perturbation strategies, revealing that each
perturbation type contributes uniquely to different aspects of visual
reasoning. Our findings highlight the critical role of visual perturbation in
multimodal mathematical reasoning: better reasoning begins with better seeing.
Our code is available at https://github.com/YutingLi0606/Vision-Matters.

</details>


### [145] [ELBO-T2IAlign: A Generic ELBO-Based Method for Calibrating Pixel-level Text-Image Alignment in Diffusion Models](https://arxiv.org/abs/2506.09740)
*Qin Zhou,Zhiyang Zhang,Jinglong Wang,Xiaobin Li,Jing Zhang,Qian Yu,Lu Sheng,Dong Xu*

Main category: cs.CV

TL;DR: 论文提出了一种基于ELBO的校准方法（ELBO-T2IAlign），用于评估和改进扩散模型中像素与文本的对齐问题，无需训练且适用于多种架构。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中表现出色，但现有方法假设文本与图像完美对齐，实际并非如此。本文旨在解决像素级和类级文本对齐问题。

Method: 使用零样本参考图像分割作为代理任务，分析扩散模型中的像素-文本错位问题，并提出基于ELBO的校准方法ELBO-T2IAlign。

Result: 实验表明，该方法在图像分割和生成任务中有效校准了像素与文本的对齐问题。

Conclusion: ELBO-T2IAlign是一种简单有效的训练无关方法，适用于多种扩散模型架构，显著改善了文本与图像的对齐效果。

Abstract: Diffusion models excel at image generation. Recent studies have shown that
these models not only generate high-quality images but also encode text-image
alignment information through attention maps or loss functions. This
information is valuable for various downstream tasks, including segmentation,
text-guided image editing, and compositional image generation. However, current
methods heavily rely on the assumption of perfect text-image alignment in
diffusion models, which is not the case. In this paper, we propose using
zero-shot referring image segmentation as a proxy task to evaluate the
pixel-level image and class-level text alignment of popular diffusion models.
We conduct an in-depth analysis of pixel-text misalignment in diffusion models
from the perspective of training data bias. We find that misalignment occurs in
images with small sized, occluded, or rare object classes. Therefore, we
propose ELBO-T2IAlign, a simple yet effective method to calibrate pixel-text
alignment in diffusion models based on the evidence lower bound (ELBO) of
likelihood. Our method is training-free and generic, eliminating the need to
identify the specific cause of misalignment and works well across various
diffusion model architectures. Extensive experiments on commonly used benchmark
datasets on image segmentation and generation have verified the effectiveness
of our proposed calibration approach.

</details>


### [146] [Class Similarity-Based Multimodal Classification under Heterogeneous Category Sets](https://arxiv.org/abs/2506.09745)
*Yangrui Zhu,Junhua Bao,Yipan Wei,Yapeng Li,Bo Du*

Main category: cs.CV

TL;DR: 论文提出了一种多模态异构类别集学习（MMHCL）任务，并提出了一种基于类别相似性的跨模态融合模型（CSCF），以解决多模态数据中类别分布不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，多模态数据的类别分布不一致，导致模型难以有效利用跨模态信息识别所有类别。

Method: 提出CSCF模型，通过将模态特定特征对齐到共享语义空间，利用不确定性估计选择最具判别性的模态，并基于类别相似性融合跨模态信息。

Result: 实验表明，CSCF在多个基准数据集上显著优于现有方法。

Conclusion: CSCF有效解决了MMHCL任务，提升了多模态数据中类别识别的性能。

Abstract: Existing multimodal methods typically assume that different modalities share
the same category set. However, in real-world applications, the category
distributions in multimodal data exhibit inconsistencies, which can hinder the
model's ability to effectively utilize cross-modal information for recognizing
all categories. In this work, we propose the practical setting termed
Multi-Modal Heterogeneous Category-set Learning (MMHCL), where models are
trained in heterogeneous category sets of multi-modal data and aim to recognize
complete classes set of all modalities during test. To effectively address this
task, we propose a Class Similarity-based Cross-modal Fusion model (CSCF).
Specifically, CSCF aligns modality-specific features to a shared semantic space
to enable knowledge transfer between seen and unseen classes. It then selects
the most discriminative modality for decision fusion through uncertainty
estimation. Finally, it integrates cross-modal information based on class
similarity, where the auxiliary modality refines the prediction of the dominant
one. Experimental results show that our method significantly outperforms
existing state-of-the-art (SOTA) approaches on multiple benchmark datasets,
effectively addressing the MMHCL task.

</details>


### [147] [Inverting Black-Box Face Recognition Systems via Zero-Order Optimization in Eigenface Space](https://arxiv.org/abs/2506.09777)
*Anton Razzhigaev,Matvey Mikhalchuk,Klim Kireev,Igor Udovichenko,Andrey Kuznetsov,Aleksandr Petiushko*

Main category: cs.CV

TL;DR: DarkerBB是一种新型方法，通过仅使用相似性分数在PCA特征脸空间中进行零阶优化，成功从黑盒识别模型中重建彩色人脸图像。


<details>
  <summary>Details</summary>
Motivation: 从黑盒识别模型中重建人脸图像对隐私构成严重威胁，现有方法通常需要访问嵌入向量，而本文旨在解决仅使用相似性分数的更具挑战性的场景。

Method: DarkerBB通过在PCA特征脸空间中进行零阶优化，仅利用相似性分数重建彩色人脸图像。

Result: 在LFW、AgeDB-30和CFP-FP基准测试中，DarkerBB在仅使用相似性分数的设置下实现了最先进的验证准确率，并具有竞争力的查询效率。

Conclusion: DarkerBB证明了在信息高度受限的情况下，仅通过相似性分数也能有效重建人脸图像，为模型反演提供了新思路。

Abstract: Reconstructing facial images from black-box recognition models poses a
significant privacy threat. While many methods require access to embeddings, we
address the more challenging scenario of model inversion using only similarity
scores. This paper introduces DarkerBB, a novel approach that reconstructs
color faces by performing zero-order optimization within a PCA-derived
eigenface space. Despite this highly limited information, experiments on LFW,
AgeDB-30, and CFP-FP benchmarks demonstrate that DarkerBB achieves
state-of-the-art verification accuracies in the similarity-only setting, with
competitive query efficiency.

</details>


### [148] [Q-SAM2: Accurate Quantization for Segment Anything Model 2](https://arxiv.org/abs/2506.09782)
*Nicola Farronato,Florian Scheidegger,Mattia Rigotti,Cristiano Malossi,Michele Magno,Haotong Qin*

Main category: cs.CV

TL;DR: Q-SAM2是一种针对SAM2的低比特量化方法，通过线性层校准和量化感知训练提升效率，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: SAM2的计算和内存消耗高，限制了其在资源受限场景的应用。

Method: 提出线性层校准方法和量化感知训练流程，优化权重分布并抑制异常值。

Result: Q-SAM2在超低2比特量化下表现优异，精度提升显著。

Conclusion: Q-SAM2在量化训练和后训练量化中均有效，显著提升效率与精度。

Abstract: The Segment Anything Model 2 (SAM2) has gained significant attention as a
foundational approach for promptable image and video segmentation. However, its
expensive computational and memory consumption poses a severe challenge for its
application in resource-constrained scenarios. In this paper, we propose an
accurate low-bit quantization method for efficient SAM2, termed Q-SAM2. To
address the performance degradation caused by the singularities in weight and
activation distributions during quantization, Q-SAM2 introduces two novel
technical contributions. We first introduce a linear layer calibration method
for low-bit initialization of SAM2, which minimizes the Frobenius norm over a
small image batch to reposition weight distributions for improved quantization.
We then propose a Quantization-Aware Training (QAT) pipeline that applies
clipping to suppress outliers and allows the network to adapt to quantization
thresholds during training. Our comprehensive experiments demonstrate that
Q-SAM2 allows for highly accurate inference while substantially improving
efficiency. Both quantitative and visual results show that our Q-SAM2 surpasses
existing state-of-the-art general quantization schemes, especially for
ultra-low 2-bit quantization. While designed for quantization-aware training,
our proposed calibration technique also proves effective in post-training
quantization, achieving up to a 66% mIoU accuracy improvement over
non-calibrated models.

</details>


### [149] [Accurate and efficient zero-shot 6D pose estimation with frozen foundation models](https://arxiv.org/abs/2506.09784)
*Andrea Caraffa,Davide Boscaini,Fabio Poiesi*

Main category: cs.CV

TL;DR: FreeZeV2是一种无需训练的6D姿态估计方法，通过几何和视觉基础模型实现对新物体的强泛化能力，提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法需要大量任务特定训练数据的问题，探索是否可以通过预训练模型实现高效准确的6D姿态估计。

Method: 采用稀疏特征提取、特征感知评分机制和模块化设计，支持多实例分割模型集成。

Result: 在BOP Benchmark上达到新SOTA，速度提升8倍，准确性提高5%；集成模型后准确性再提升8%，速度仍快2.5倍。

Conclusion: FreeZeV2证明了无需任务特定训练即可实现高效准确的6D姿态估计，并在BOP Challenge 2024中获最佳方法奖。

Abstract: Estimating the 6D pose of objects from RGBD data is a fundamental problem in
computer vision, with applications in robotics and augmented reality. A key
challenge is achieving generalization to novel objects that were not seen
during training. Most existing approaches address this by scaling up training
on synthetic data tailored to the task, a process that demands substantial
computational resources. But is task-specific training really necessary for
accurate and efficient 6D pose estimation of novel objects? To answer No!, we
introduce FreeZeV2, the second generation of FreeZe: a training-free method
that achieves strong generalization to unseen objects by leveraging geometric
and vision foundation models pre-trained on unrelated data. FreeZeV2 improves
both accuracy and efficiency over FreeZe through three key contributions: (i) a
sparse feature extraction strategy that reduces inference-time computation
without sacrificing accuracy; (ii) a feature-aware scoring mechanism that
improves both pose selection during RANSAC-based 3D registration and the final
ranking of pose candidates; and (iii) a modular design that supports ensembles
of instance segmentation models, increasing robustness to segmentation masks
errors. We evaluate FreeZeV2 on the seven core datasets of the BOP Benchmark,
where it establishes a new state-of-the-art in 6D pose estimation of unseen
objects. When using the same segmentation masks, FreeZeV2 achieves a remarkable
8x speedup over FreeZe while also improving accuracy by 5%. When using
ensembles of segmentation models, FreeZeV2 gains an additional 8% in accuracy
while still running 2.5x faster than FreeZe. FreeZeV2 was awarded Best Overall
Method at the BOP Challenge 2024.

</details>


### [150] [DreamCS: Geometry-Aware Text-to-3D Generation with Unpaired 3D Reward Supervision](https://arxiv.org/abs/2506.09814)
*Xiandong Zou,Ruihao Xia,Hongsong Wang,Pan Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D-MeshPref数据集和RewardCS奖励模型的新方法DreamCS，用于改进文本到3D生成的对齐人类偏好问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖难以收集的2D偏好配对数据，导致3D生成存在几何伪影。

Method: 构建了3D-MeshPref数据集，开发了RewardCS奖励模型，并提出DreamCS框架。

Result: 实验表明DreamCS优于现有方法，生成更符合人类偏好的3D资产。

Conclusion: DreamCS通过直接学习3D偏好数据，显著提升了文本到3D生成的质量。

Abstract: While text-to-3D generation has attracted growing interest, existing methods
often struggle to produce 3D assets that align well with human preferences.
Current preference alignment techniques for 3D content typically rely on
hardly-collected preference-paired multi-view 2D images to train 2D reward
models, when then guide 3D generation -- leading to geometric artifacts due to
their inherent 2D bias. To address these limitations, we construct 3D-MeshPref,
the first large-scale unpaired 3D preference dataset, featuring diverse 3D
meshes annotated by a large language model and refined by human evaluators. We
then develop RewardCS, the first reward model trained directly on unpaired
3D-MeshPref data using a novel Cauchy-Schwarz divergence objective, enabling
effective learning of human-aligned 3D geometric preferences without requiring
paired comparisons. Building on this, we propose DreamCS, a unified framework
that integrates RewardCS into text-to-3D pipelines -- enhancing both implicit
and explicit 3D generation with human preference feedback. Extensive
experiments show DreamCS outperforms prior methods, producing 3D assets that
are both geometrically faithful and human-preferred. Code and models will be
released publicly.

</details>


### [151] [MMME: A Spontaneous Multi-Modal Micro-Expression Dataset Enabling Visual-Physiological Fusion](https://arxiv.org/abs/2506.09834)
*Chuang Maa,Yu Peia,Jianhang Zhanga,Shaokai Zhaoa,Bowen Jib,Liang Xiea,Ye Yana,Erwei Yin*

Main category: cs.CV

TL;DR: 论文提出了一种新的微表情数据集MMME，首次同步采集面部动作信号、中枢神经系统信号和外周生理信号，验证了多模态融合对微表情分析的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有微表情研究局限于单一视觉模态，忽视了其他生理模态传递的情感信息，导致识别和检测性能远低于实际应用需求。

Method: 研究引入了MMME数据集，包含634个微表情、2841个宏表情和2890个同步多模态生理信号试验，通过实验验证数据集的可靠性。

Result: 实验表明，将微表情与生理信号结合显著提升了识别和检测性能。

Conclusion: MMME是目前模态多样性最全面的微表情数据集，为探索微表情神经机制和多模态融合研究提供了关键数据支持。

Abstract: Micro-expressions (MEs) are subtle, fleeting nonverbal cues that reveal an
individual's genuine emotional state. Their analysis has attracted considerable
interest due to its promising applications in fields such as healthcare,
criminal investigation, and human-computer interaction. However, existing ME
research is limited to single visual modality, overlooking the rich emotional
information conveyed by other physiological modalities, resulting in ME
recognition and spotting performance far below practical application needs.
Therefore, exploring the cross-modal association mechanism between ME visual
features and physiological signals (PS), and developing a multimodal fusion
framework, represents a pivotal step toward advancing ME analysis. This study
introduces a novel ME dataset, MMME, which, for the first time, enables
synchronized collection of facial action signals (MEs), central nervous system
signals (EEG), and peripheral PS (PPG, RSP, SKT, EDA, and ECG). By overcoming
the constraints of existing ME corpora, MMME comprises 634 MEs, 2,841
macro-expressions (MaEs), and 2,890 trials of synchronized multimodal PS,
establishing a robust foundation for investigating ME neural mechanisms and
conducting multimodal fusion-based analyses. Extensive experiments validate the
dataset's reliability and provide benchmarks for ME analysis, demonstrating
that integrating MEs with PS significantly enhances recognition and spotting
performance. To the best of our knowledge, MMME is the most comprehensive ME
dataset to date in terms of modality diversity. It provides critical data
support for exploring the neural mechanisms of MEs and uncovering the
visual-physiological synergistic effects, driving a paradigm shift in ME
research from single-modality visual analysis to multimodal fusion. The dataset
will be publicly available upon acceptance of this paper.

</details>


### [152] [DynaSplat: Dynamic-Static Gaussian Splatting with Hierarchical Motion Decomposition for Scene Reconstruction](https://arxiv.org/abs/2506.09836)
*Junli Deng,Ping Shi,Qipei Li,Jinyang Guo*

Main category: cs.CV

TL;DR: DynaSplat通过动态-静态分离和分层运动建模扩展高斯泼溅技术，实现动态场景的高精度重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以应对复杂动态场景的挑战，DynaSplat旨在解决这一问题。

Method: 结合变形偏移统计和2D运动流一致性分类静态与动态元素，采用分层运动建模捕捉全局与局部运动，并基于物理的透明度估计提升视觉一致性。

Result: 在多个数据集上，DynaSplat在精度和真实感上优于现有方法，且更高效。

Conclusion: DynaSplat为动态场景重建提供了一种更直观、紧凑且高效的解决方案。

Abstract: Reconstructing intricate, ever-changing environments remains a central
ambition in computer vision, yet existing solutions often crumble before the
complexity of real-world dynamics. We present DynaSplat, an approach that
extends Gaussian Splatting to dynamic scenes by integrating dynamic-static
separation and hierarchical motion modeling. First, we classify scene elements
as static or dynamic through a novel fusion of deformation offset statistics
and 2D motion flow consistency, refining our spatial representation to focus
precisely where motion matters. We then introduce a hierarchical motion
modeling strategy that captures both coarse global transformations and
fine-grained local movements, enabling accurate handling of intricate,
non-rigid motions. Finally, we integrate physically-based opacity estimation to
ensure visually coherent reconstructions, even under challenging occlusions and
perspective shifts. Extensive experiments on challenging datasets reveal that
DynaSplat not only surpasses state-of-the-art alternatives in accuracy and
realism but also provides a more intuitive, compact, and efficient route to
dynamic scene reconstruction.

</details>


### [153] [Learning to Align: Addressing Character Frequency Distribution Shifts in Handwritten Text Recognition](https://arxiv.org/abs/2506.09846)
*Panagiotis Kaliosis,John Pavlopoulos*

Main category: cs.CV

TL;DR: 提出了一种基于Wasserstein距离的损失函数，通过匹配预测文本与目标字符频率分布，提升手写文本识别的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 手写文本识别因字符集随时间、地域变化而具有挑战性，传统模型在特定子集上表现不佳。

Method: 设计了一种新损失函数，利用Wasserstein距离对齐字符频率分布，并在解码阶段作为评分函数优化现有模型。

Result: 实验证明该方法在多数据集和架构中显著提升泛化能力和性能。

Conclusion: 通过字符分布对齐，有效解决了手写文本识别中的上下文和时移问题，代码已开源。

Abstract: Handwritten text recognition aims to convert visual input into
machine-readable text, and it remains challenging due to the evolving and
context-dependent nature of handwriting. Character sets change over time, and
character frequency distributions shift across historical periods or regions,
often causing models trained on broad, heterogeneous corpora to underperform on
specific subsets. To tackle this, we propose a novel loss function that
incorporates the Wasserstein distance between the character frequency
distribution of the predicted text and a target distribution empirically
derived from training data. By penalizing divergence from expected
distributions, our approach enhances both accuracy and robustness under
temporal and contextual intra-dataset shifts. Furthermore, we demonstrate that
character distribution alignment can also improve existing models at inference
time without requiring retraining by integrating it as a scoring function in a
guided decoding scheme. Experimental results across multiple datasets and
architectures confirm the effectiveness of our method in boosting
generalization and performance. We open source our code at
https://github.com/pkaliosis/fada.

</details>


### [154] [IntPhys 2: Benchmarking Intuitive Physics Understanding In Complex Synthetic Environments](https://arxiv.org/abs/2506.09849)
*Florian Bordes,Quentin Garrido,Justine T Kao,Adina Williams,Michael Rabbat,Emmanuel Dupoux*

Main category: cs.CV

TL;DR: IntPhys 2是一个视频基准测试，用于评估深度学习模型对直观物理的理解能力，基于四个核心原则：持久性、不变性、时空连续性和固体性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补当前模型与人类直观物理理解之间的差距，受早期儿童物理认知发展的启发。

Method: 采用违反期望框架，在多样化虚拟环境中测试模型区分可能和不可能事件的能力。

Result: 现有模型在复杂场景中表现接近随机水平（50%），远低于人类近乎完美的准确性。

Conclusion: 当前模型在直观物理理解上存在显著不足，需改进架构和训练方法。

Abstract: We present IntPhys 2, a video benchmark designed to evaluate the intuitive
physics understanding of deep learning models. Building on the original IntPhys
benchmark, IntPhys 2 focuses on four core principles related to macroscopic
objects: Permanence, Immutability, Spatio-Temporal Continuity, and Solidity.
These conditions are inspired by research into intuitive physical understanding
emerging during early childhood. IntPhys 2 offers a comprehensive suite of
tests, based on the violation of expectation framework, that challenge models
to differentiate between possible and impossible events within controlled and
diverse virtual environments. Alongside the benchmark, we provide performance
evaluations of several state-of-the-art models. Our findings indicate that
while these models demonstrate basic visual understanding, they face
significant challenges in grasping intuitive physics across the four principles
in complex scenes, with most models performing at chance levels (50%), in stark
contrast to human performance, which achieves near-perfect accuracy. This
underscores the gap between current models and human-like intuitive physics
understanding, highlighting the need for advancements in model architectures
and training methodologies.

</details>


### [155] [Leveraging Depth and Language for Open-Vocabulary Domain-Generalized Semantic Segmentation](https://arxiv.org/abs/2506.09881)
*Siyu Chen,Ting Han,Chengzheng Fu,Changshe Zhang,Chaolei Wang,Jinhe Su,Guorong Cai,Meiliu Wu*

Main category: cs.CV

TL;DR: Vireo是一个单阶段框架，首次统一了开放词汇语义分割（OVSS）和领域泛化语义分割（DGSS），通过结合视觉基础模型（VFMs）和深度VFMs提取域不变特征，并提出了三个关键组件以提升性能。


<details>
  <summary>Details</summary>
Motivation: 开放词汇和领域泛化在语义分割中的互补性促使了OV-DGSS的研究，旨在为现实场景（如自动驾驶）提供对未见类别和领域的鲁棒性。

Method: Vireo基于冻结的VFMs，引入深度VFMs提取结构特征，并提出GeoText Prompts、CMPE和DOV-VEH三个组件以优化视觉与文本模态的融合。

Result: Vireo在领域泛化和开放词汇识别中均取得显著性能提升，超越了现有方法。

Conclusion: Vireo为动态多样环境中的鲁棒视觉理解提供了统一且可扩展的解决方案。

Abstract: Open-Vocabulary semantic segmentation (OVSS) and domain generalization in
semantic segmentation (DGSS) highlight a subtle complementarity that motivates
Open-Vocabulary Domain-Generalized Semantic Segmentation (OV-DGSS). OV-DGSS
aims to generate pixel-level masks for unseen categories while maintaining
robustness across unseen domains, a critical capability for real-world
scenarios such as autonomous driving in adverse conditions. We introduce Vireo,
a novel single-stage framework for OV-DGSS that unifies the strengths of OVSS
and DGSS for the first time. Vireo builds upon the frozen Visual Foundation
Models (VFMs) and incorporates scene geometry via Depth VFMs to extract
domain-invariant structural features. To bridge the gap between visual and
textual modalities under domain shift, we propose three key components: (1)
GeoText Prompts, which align geometric features with language cues and
progressively refine VFM encoder representations; (2) Coarse Mask Prior
Embedding (CMPE) for enhancing gradient flow for faster convergence and
stronger textual influence; and (3) the Domain-Open-Vocabulary Vector Embedding
Head (DOV-VEH), which fuses refined structural and semantic features for robust
prediction. Comprehensive evaluation on these components demonstrates the
effectiveness of our designs. Our proposed Vireo achieves the state-of-the-art
performance and surpasses existing methods by a large margin in both domain
generalization and open-vocabulary recognition, offering a unified and scalable
solution for robust visual understanding in diverse and dynamic environments.
Code is available at https://github.com/anonymouse-9c53tp182bvz/Vireo.

</details>


### [156] [3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation](https://arxiv.org/abs/2506.09883)
*Seonho Lee,Jiho Choi,Inha Kang,Jiwook Kim,Junsung Park,Hyunjung Shim*

Main category: cs.CV

TL;DR: 提出了一种轻量级、无需标注的微调框架Geometric Distillation，通过注入几何线索提升预训练视觉语言模型（VLM）的3D空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在3D空间结构理解上存在局限，需要一种高效方法提升其几何感知能力。

Method: 通过从现成的3D基础模型中提取稀疏对应、相对深度关系和密集成本体积，注入预训练VLM中，不改变其架构。

Result: 在3D视觉语言推理和感知任务中表现优于现有方法，计算成本更低。

Conclusion: 提供了一种可扩展且高效的方法，将2D训练的VLM与3D理解结合，适用于空间多模态任务。

Abstract: Vision-Language Models (VLMs) have shown remarkable performance on diverse
visual and linguistic tasks, yet they remain fundamentally limited in their
understanding of 3D spatial structures. We propose Geometric Distillation, a
lightweight, annotation-free fine-tuning framework that injects human-inspired
geometric cues into pretrained VLMs without modifying their architecture. By
distilling (1) sparse correspondences, (2) relative depth relations, and (3)
dense cost volumes from off-the-shelf 3D foundation models (e.g., MASt3R,
VGGT), our method shapes representations to be geometry-aware while remaining
compatible with natural image-text inputs. Through extensive evaluations on 3D
vision-language reasoning and 3D perception benchmarks, our method consistently
outperforms prior approaches, achieving improved 3D spatial reasoning with
significantly lower computational cost. Our work demonstrates a scalable and
efficient path to bridge 2D-trained VLMs with 3D understanding, opening up
wider use in spatially grounded multimodal tasks.

</details>


### [157] [The Less You Depend, The More You Learn: Synthesizing Novel Views from Sparse, Unposed Images without Any 3D Knowledge](https://arxiv.org/abs/2506.09885)
*Haoru Wang,Kai Ye,Yangyan Li,Wenzheng Chen,Baoquan Chen*

Main category: cs.CV

TL;DR: 论文提出了一种减少对3D知识依赖的新颖视图合成方法，通过数据驱动的方式直接从稀疏2D图像中学习3D信息，无需3D归纳偏置或姿态标注。


<details>
  <summary>Details</summary>
Motivation: 解决通用新颖视图合成任务中依赖3D知识和已知相机姿态的问题，探索减少这些依赖的可行性及其在大规模数据时代的重要性。

Method: 提出了一种最小化3D归纳偏置和姿态依赖的框架，直接从稀疏2D图像中学习隐式3D感知，无需训练时的3D知识或姿态标注。

Result: 实验表明，该方法能够生成逼真且3D一致的新颖视图，性能与依赖姿态输入的方法相当。

Conclusion: 减少对3D知识的依赖在大规模数据时代是可行且有效的，数据驱动的范式具有潜力。

Abstract: We consider the problem of generalizable novel view synthesis (NVS), which
aims to generate photorealistic novel views from sparse or even unposed 2D
images without per-scene optimization. This task remains fundamentally
challenging, as it requires inferring 3D structure from incomplete and
ambiguous 2D observations. Early approaches typically rely on strong 3D
knowledge, including architectural 3D inductive biases (e.g., embedding
explicit 3D representations, such as NeRF or 3DGS, into network design) and
ground-truth camera poses for both input and target views. While recent efforts
have sought to reduce the 3D inductive bias or the dependence on known camera
poses of input views, critical questions regarding the role of 3D knowledge and
the necessity of circumventing its use remain under-explored. In this work, we
conduct a systematic analysis on the 3D knowledge and uncover a critical trend:
the performance of methods that requires less 3D knowledge accelerates more as
data scales, eventually achieving performance on par with their 3D
knowledge-driven counterparts, which highlights the increasing importance of
reducing dependence on 3D knowledge in the era of large-scale data. Motivated
by and following this trend, we propose a novel NVS framework that minimizes 3D
inductive bias and pose dependence for both input and target views. By
eliminating this 3D knowledge, our method fully leverages data scaling and
learns implicit 3D awareness directly from sparse 2D images, without any 3D
inductive bias or pose annotation during training. Extensive experiments
demonstrate that our model generates photorealistic and 3D-consistent novel
views, achieving even comparable performance with methods that rely on posed
inputs, thereby validating the feasibility and effectiveness of our
data-centric paradigm. Project page:
https://pku-vcl-geometry.github.io/Less3Depend/ .

</details>


### [158] [EquiCaps: Predictor-Free Pose-Aware Pre-Trained Capsule Networks](https://arxiv.org/abs/2506.09895)
*Athinoulla Konstantinou,Georgios Leontidis,Mamatha Thota,Aiden Durrant*

Main category: cs.CV

TL;DR: 论文提出EquiCaps，一种基于胶囊网络的姿态感知自监督方法，无需专用预测器即可实现等变性，并在姿态估计任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用胶囊网络固有的姿态感知能力，避免依赖专用预测器来实现等变性，从而提升姿态估计任务的性能。

Method: 引入EquiCaps，利用胶囊网络的固有特性实现等变性，并通过多几何变换任务和3DIEBench-T数据集验证其性能。

Result: EquiCaps在旋转预测任务中表现优于现有方法，R²达0.78，且在复杂几何变换下仍保持稳健的等变性。

Conclusion: EquiCaps展示了胶囊网络在无预测器架构中的潜力，为姿态感知任务提供了新的解决方案。

Abstract: Learning self-supervised representations that are invariant and equivariant
to transformations is crucial for advancing beyond traditional visual
classification tasks. However, many methods rely on predictor architectures to
encode equivariance, despite evidence that architectural choices, such as
capsule networks, inherently excel at learning interpretable pose-aware
representations. To explore this, we introduce EquiCaps (Equivariant Capsule
Network), a capsule-based approach to pose-aware self-supervision that
eliminates the need for a specialised predictor for enforcing equivariance.
Instead, we leverage the intrinsic pose-awareness capabilities of capsules to
improve performance in pose estimation tasks. To further challenge our
assumptions, we increase task complexity via multi-geometric transformations to
enable a more thorough evaluation of invariance and equivariance by introducing
3DIEBench-T, an extension of a 3D object-rendering benchmark dataset. Empirical
results demonstrate that EquiCaps outperforms prior state-of-the-art
equivariant methods on rotation prediction, achieving a supervised-level $R^2$
of 0.78 on the 3DIEBench rotation prediction benchmark and improving upon SIE
and CapsIE by 0.05 and 0.04 $R^2$, respectively. Moreover, in contrast to
non-capsule-based equivariant approaches, EquiCaps maintains robust equivariant
performance under combined geometric transformations, underscoring its
generalisation capabilities and the promise of predictor-free capsule
architectures.

</details>


### [159] [CEM-FBGTinyDet: Context-Enhanced Foreground Balance with Gradient Tuning for tiny Objects](https://arxiv.org/abs/2506.09897)
*Tao Liu,Zhenchao Cui*

Main category: cs.CV

TL;DR: 论文提出E-FPN-BS架构，通过多尺度特征增强和自适应优化解决小目标检测中高层特征未被训练的问题。


<details>
  <summary>Details</summary>
Motivation: 标准标签分配协议下，高层特征（P5-P6）常因零正锚点而被排除在损失计算外，导致语义表示未训练，形成高层特征无梯度和低层特征缺乏语义上下文的问题。

Method: 提出E-FPN-BS架构，包含上下文增强模块（CEM）和前景-背景分离模块（FBSM），并引入动态梯度平衡损失（DCLoss）。

Result: 在多个基准数据集上的实验表明，该方法具有出色的性能和泛化能力。

Conclusion: E-FPN-BS有效解决了小目标检测中高层特征的梯度缺失问题，提升了检测性能。

Abstract: Tiny object detection (TOD) reveals a fundamental flaw in feature pyramid
networks: high-level features (P5-P6) frequently receive zero positive anchors
under standard label assignment protocols, leaving their semantic
representations untrained due to exclusion from loss computation. This creates
dual deficiencies: (1) Stranded high-level features become semantic dead-ends
without gradient updates, while (2) low-level features lack essential semantic
context for robust classification. We propose E-FPN-BS that systematically
converts wasted high-level semantics into low-level feature enhancements. To
address these issues, we propose E-FPN-BS, a novel architecture integrating
multi-scale feature enhancement and adaptive optimization. First, our Context
Enhancement Module(CEM) employs dual-branch processing to align and compress
high-level features for effective global-local fusion. Second, the
Foreground-Background Separation Module (FBSM) generates spatial gating masks
that dynamically amplify discriminative regions. To address gradient imbalance
across object scales, we further propose a Dynamic Gradient-Balanced Loss
(DCLoss) that automatically modulates loss contributions via scale-aware
gradient equilibrium. Extensive experiments across multiple benchmark datasets
demonstrate the outstanding performance and generalization ability of our
approach.

</details>


### [160] [Only-Style: Stylistic Consistency in Image Generation without Content Leakage](https://arxiv.org/abs/2506.09916)
*Tilemachos Aravanis,Panagiotis Filntisis,Petros Maragos,George Retsinas*

Main category: cs.CV

TL;DR: 论文提出Only-Style方法，通过自适应调整参数来减少风格一致生成中的内容泄漏问题，并提出了新的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法在风格一致生成中难以有效分离语义内容和风格元素，导致内容泄漏问题。

Method: Only-Style通过定位内容泄漏并自适应调整风格对齐参数，平衡风格一致性和泄漏消除。

Result: 实验表明，该方法显著优于现有技术，实现了无内容泄漏的稳健风格一致性。

Conclusion: Only-Style在风格一致生成中有效解决了内容泄漏问题，并提供了可扩展的评估框架。

Abstract: Generating images in a consistent reference visual style remains a
challenging computer vision task. State-of-the-art methods aiming for
style-consistent generation struggle to effectively separate semantic content
from stylistic elements, leading to content leakage from the image provided as
a reference to the targets. To address this challenge, we propose Only-Style: a
method designed to mitigate content leakage in a semantically coherent manner
while preserving stylistic consistency. Only-Style works by localizing content
leakage during inference, allowing the adaptive tuning of a parameter that
controls the style alignment process, specifically within the image patches
containing the subject in the reference image. This adaptive process best
balances stylistic consistency with leakage elimination. Moreover, the
localization of content leakage can function as a standalone component, given a
reference-target image pair, allowing the adaptive tuning of any
method-specific parameter that provides control over the impact of the
stylistic reference. In addition, we propose a novel evaluation framework to
quantify the success of style-consistent generations in avoiding undesired
content leakage. Our approach demonstrates a significant improvement over
state-of-the-art methods through extensive evaluation across diverse instances,
consistently achieving robust stylistic consistency without undesired content
leakage.

</details>


### [161] [MetricHMR: Metric Human Mesh Recovery from Monocular Images](https://arxiv.org/abs/2506.09919)
*He Zhang,Chentao Song,Hongwen Zhang,Tao Yu*

Main category: cs.CV

TL;DR: MetricHMR是一种从单目图像中恢复具有准确全局平移的度量尺度人体网格的方法，解决了现有HMR方法的尺度和深度模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有HMR方法存在严重的尺度和深度模糊问题，无法生成几何合理的身体形状和全局平移。

Method: 通过系统分析现有HMR方法的相机模型，强调标准透视投影模型的关键作用，并提出一种基于射线图的新方法，联合编码边界框信息、相机参数和几何线索。

Result: 实验表明，该方法在度量姿态、形状和全局平移估计方面达到最先进性能。

Conclusion: MetricHMR在室内和野外场景中均表现出色，无需额外度量正则化模块。

Abstract: We introduce MetricHMR (Metric Human Mesh Recovery), an approach for metric
human mesh recovery with accurate global translation from monocular images. In
contrast to existing HMR methods that suffer from severe scale and depth
ambiguity, MetricHMR is able to produce geometrically reasonable body shape and
global translation in the reconstruction results. To this end, we first
systematically analyze previous HMR methods on camera models to emphasize the
critical role of the standard perspective projection model in enabling
metric-scale HMR. We then validate the acceptable ambiguity range of metric HMR
under the standard perspective projection model. Finally, we contribute a novel
approach that introduces a ray map based on the standard perspective projection
to jointly encode bounding-box information, camera parameters, and geometric
cues for End2End metric HMR without any additional metric-regularization
modules. Extensive experiments demonstrate that our method achieves
state-of-the-art performance, even compared with sequential HMR methods, in
metric pose, shape, and global translation estimation across both indoor and
in-the-wild scenarios.

</details>


### [162] [Structural-Spectral Graph Convolution with Evidential Edge Learning for Hyperspectral Image Clustering](https://arxiv.org/abs/2506.09920)
*Jianhan Qi,Yuheng Jia,Hui Liu,Junhui Hou*

Main category: cs.CV

TL;DR: 论文提出了一种针对高光谱图像（HSI）聚类的改进方法，结合结构-光谱图卷积算子（SSGCO）和证据引导的自适应边学习（EGAEL）模块，提升了聚类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络（GNNs）的方法无法充分利用HSI的光谱信息，且超像素拓扑图的不准确性可能导致语义混淆，因此需要改进。

Method: 提出SSGCO提取空间和光谱特征，并设计EGAEL模块自适应优化边权重，结合对比学习框架实现聚类。

Result: 在四个HSI数据集上，聚类准确率分别提升了2.61%、6.06%、4.96%和3.15%。

Conclusion: 该方法显著提升了HSI聚类的性能，代码已开源。

Abstract: Hyperspectral image (HSI) clustering assigns similar pixels to the same class
without any annotations, which is an important yet challenging task. For
large-scale HSIs, most methods rely on superpixel segmentation and perform
superpixel-level clustering based on graph neural networks (GNNs). However,
existing GNNs cannot fully exploit the spectral information of the input HSI,
and the inaccurate superpixel topological graph may lead to the confusion of
different class semantics during information aggregation. To address these
challenges, we first propose a structural-spectral graph convolutional operator
(SSGCO) tailored for graph-structured HSI superpixels to improve their
representation quality through the co-extraction of spatial and spectral
features. Second, we propose an evidence-guided adaptive edge learning (EGAEL)
module that adaptively predicts and refines edge weights in the superpixel
topological graph. We integrate the proposed method into a contrastive learning
framework to achieve clustering, where representation learning and clustering
are simultaneously conducted. Experiments demonstrate that the proposed method
improves clustering accuracy by 2.61%, 6.06%, 4.96% and 3.15% over the best
compared methods on four HSI datasets. Our code is available at
https://github.com/jhqi/SSGCO-EGAEL.

</details>


### [163] [HadaNorm: Diffusion Transformer Quantization through Mean-Centered Transformations](https://arxiv.org/abs/2506.09932)
*Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel*

Main category: cs.CV

TL;DR: HadaNorm是一种新颖的线性变换方法，通过归一化激活特征通道并应用Hadamard变换，有效减少异常值，实现更激进的激活量化，提升扩散模型的量化效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成领域表现优异，但其高内存和计算需求限制了在资源受限设备上的部署。现有的后训练量化方法在处理异常值和实现高压缩时存在困难。

Method: 提出HadaNorm方法，通过归一化激活特征通道并应用Hadamard变换，减少异常值影响，实现更高效的量化。

Result: HadaNorm在多种Transformer模块中一致减少量化误差，相比现有方法实现了更好的效率-性能平衡。

Conclusion: HadaNorm为扩散模型的量化提供了一种高效解决方案，显著提升了在资源受限设备上的部署潜力。

Abstract: Diffusion models represent the cutting edge in image generation, but their
high memory and computational demands hinder deployment on resource-constrained
devices. Post-Training Quantization (PTQ) offers a promising solution by
reducing the bitwidth of matrix operations. However, standard PTQ methods
struggle with outliers, and achieving higher compression often requires
transforming model weights and activations before quantization. In this work,
we propose HadaNorm, a novel linear transformation that extends existing
approaches and effectively mitigates outliers by normalizing activations
feature channels before applying Hadamard transformations, enabling more
aggressive activation quantization. We demonstrate that HadaNorm consistently
reduces quantization error across the various components of transformer blocks,
achieving superior efficiency-performance trade-offs when compared to
state-of-the-art methods.

</details>


### [164] [LEO-VL: Towards 3D Vision-Language Generalists via Data Scaling with Efficient Representation](https://arxiv.org/abs/2506.09935)
*Jiangyong Huang,Xiaojian Ma,Xiongkun Linghu,Yue Fan,Junchao He,Wenxin Tan,Qing Li,Song-Chun Zhu,Yixin Chen,Baoxiong Jia,Siyuan Huang*

Main category: cs.CV

TL;DR: 论文提出LEO-VL模型，采用高效场景表示CFG，结合2D感知与3D结构，显著减少计算开销，并通过大规模数据训练实现3D-VL通用模型。


<details>
  <summary>Details</summary>
Motivation: 解决3D-VL通用模型在数据扩展性和场景表示效率上的瓶颈，提升其能力和鲁棒性。

Method: 提出CFG高效场景表示，结合2D与3D信息；构建700k高质量3D-VL数据集；引入SceneDPO后训练目标增强鲁棒性。

Result: 在SQA3D、MSQA和Beacon3D等基准测试中达到SOTA性能。

Conclusion: LEO-VL和SceneDPO为3D-VL通用模型的可扩展性和鲁棒性提供了有效解决方案。

Abstract: Developing 3D-VL generalists capable of understanding 3D scenes and following
natural language instructions to perform a wide range of tasks has been a
long-standing goal in the 3D-VL community. Despite recent progress, 3D-VL
models still lag behind their 2D counterparts in capability and robustness,
falling short of the generalist standard. A key obstacle to developing 3D-VL
generalists lies in data scalability, hindered by the lack of an efficient
scene representation. We propose LEO-VL, a 3D-VL model built upon condensed
feature grid (CFG), an efficient scene representation that bridges 2D
perception and 3D spatial structure while significantly reducing token
overhead. This efficiency unlocks large-scale training towards 3D-VL
generalist, for which we curate over 700k high-quality 3D-VL data spanning four
domains of real-world indoor scenes and five tasks such as captioning and
dialogue. LEO-VL achieves state-of-the-art performance on a variety of 3D QA
benchmarks, including SQA3D, MSQA, and Beacon3D. Ablation studies confirm the
efficiency of our representation, the importance of task and scene diversity,
and the validity of our data curation principle. Furthermore, we introduce
SceneDPO, a novel post-training objective that enhances the robustness of 3D-VL
models. We hope our findings contribute to the advancement of scalable and
robust 3D-VL generalists.

</details>


### [165] [CausalVQA: A Physically Grounded Causal Reasoning Benchmark for Video Models](https://arxiv.org/abs/2506.09943)
*Aaron Foss,Chloe Evans,Sasha Mitts,Koustuv Sinha,Ammar Rizvi,Justine T. Kao*

Main category: cs.CV

TL;DR: CausalVQA是一个用于视频问答（VQA）的基准数据集，专注于模型对物理世界中因果关系的理解。


<details>
  <summary>Details</summary>
Motivation: 填补现有VQA数据集的不足，提供基于真实场景的挑战性问题，测试模型对因果关系和物理推理的能力。

Method: 设计了五种问题类型（反事实、假设、预期、规划和描述性），并引入质量控制机制，防止模型利用语言线索。

Result: 当前前沿多模态模型在基准测试中表现远低于人类，尤其在预期和假设问题上。

Conclusion: CausalVQA突显了当前系统在时空推理、物理原理理解和预测能力上的不足。

Abstract: We introduce CausalVQA, a benchmark dataset for video question answering
(VQA) composed of question-answer pairs that probe models' understanding of
causality in the physical world. Existing VQA benchmarks either tend to focus
on surface perceptual understanding of real-world videos, or on narrow physical
reasoning questions created using simulation environments. CausalVQA fills an
important gap by presenting challenging questions that are grounded in
real-world scenarios, while focusing on models' ability to predict the likely
outcomes of different actions and events through five question types:
counterfactual, hypothetical, anticipation, planning and descriptive. We
designed quality control mechanisms that prevent models from exploiting trivial
shortcuts, requiring models to base their answers on deep visual understanding
instead of linguistic cues. We find that current frontier multimodal models
fall substantially below human performance on the benchmark, especially on
anticipation and hypothetical questions. This highlights a challenge for
current systems to leverage spatial-temporal reasoning, understanding of
physical principles, and comprehension of possible alternatives to make
accurate predictions in real-world settings.

</details>


### [166] [Outside Knowledge Conversational Video (OKCV) Dataset -- Dialoguing over Videos](https://arxiv.org/abs/2506.09953)
*Benjamin Reichman,Constantin Patsch,Jack Truxal,Atishay Jain,Larry Heck*

Main category: cs.CV

TL;DR: 论文提出了一种基于视频的视觉问答任务扩展，要求模型结合外部知识和视觉信息进行对话，并发布了包含2017个视频和5986个对话的数据集。


<details>
  <summary>Details</summary>
Motivation: 探索视觉问答任务在视频对话场景中的扩展，解决模型需同时处理视觉信息和外部知识的挑战。

Method: 构建了一个包含2017个视频和5986个对话的数据集，模型需识别视频片段并利用外部知识回答问题。

Result: 提供了多个基线模型，并展示了任务相关的未来挑战。

Conclusion: 该任务为视觉对话研究提供了新方向，数据集公开以促进进一步研究。

Abstract: In outside knowledge visual question answering (OK-VQA), the model must
identify relevant visual information within an image and incorporate external
knowledge to accurately respond to a question. Extending this task to a
visually grounded dialogue setting based on videos, a conversational model must
both recognize pertinent visual details over time and answer questions where
the required information is not necessarily present in the visual information.
Moreover, the context of the overall conversation must be considered for the
subsequent dialogue. To explore this task, we introduce a dataset comprised of
$2,017$ videos with $5,986$ human-annotated dialogues consisting of $40,954$
interleaved dialogue turns. While the dialogue context is visually grounded in
specific video segments, the questions further require external knowledge that
is not visually present. Thus, the model not only has to identify relevant
video parts but also leverage external knowledge to converse within the
dialogue. We further provide several baselines evaluated on our dataset and
show future challenges associated with this task. The dataset is made publicly
available here: https://github.com/c-patsch/OKCV.

</details>


### [167] [UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting](https://arxiv.org/abs/2506.09952)
*Ziyi Wang,Yanran Zhang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: UniPre3D是一种统一预训练方法，适用于任何尺度的点云数据和任何架构的3D模型，通过预测高斯基元和使用可微分高斯渲染实现像素级监督。


<details>
  <summary>Details</summary>
Motivation: 解决点云数据尺度多样性带来的挑战，填补现有预训练方法在对象和场景级点云上效果不统一的空白。

Method: 采用高斯基元预测作为预训练任务，结合可微分高斯渲染和2D特征融合，优化几何结构学习。

Result: 在各种对象和场景级任务中验证了方法的普适性，支持多种点云模型作为骨干。

Conclusion: UniPre3D首次实现了点云数据的统一预训练，为3D视觉任务提供了通用解决方案。

Abstract: The scale diversity of point cloud data presents significant challenges in
developing unified representation learning techniques for 3D vision. Currently,
there are few unified 3D models, and no existing pre-training method is equally
effective for both object- and scene-level point clouds. In this paper, we
introduce UniPre3D, the first unified pre-training method that can be
seamlessly applied to point clouds of any scale and 3D models of any
architecture. Our approach predicts Gaussian primitives as the pre-training
task and employs differentiable Gaussian splatting to render images, enabling
precise pixel-level supervision and end-to-end optimization. To further
regulate the complexity of the pre-training task and direct the model's focus
toward geometric structures, we integrate 2D features from pre-trained image
models to incorporate well-established texture knowledge. We validate the
universal effectiveness of our proposed method through extensive experiments
across a variety of object- and scene-level tasks, using diverse point cloud
models as backbones. Code is available at https://github.com/wangzy22/UniPre3D.

</details>


### [168] [Vision Generalist Model: A Survey](https://arxiv.org/abs/2506.09954)
*Ziyi Wang,Yongming Rao,Shuofeng Sun,Xinrun Liu,Yi Wei,Xumin Yu,Zuyan Liu,Yanbo Wang,Hongmin Liu,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文综述了视觉通用模型的特点和能力，包括背景、框架设计、性能提升技术、相关领域联系以及应用场景和未来方向。


<details>
  <summary>Details</summary>
Motivation: 通用模型在自然语言处理中的成功激发了将其应用于计算机视觉任务的兴趣，但视觉任务的输入输出多样性带来了挑战。

Method: 回顾背景、分析现有框架设计、介绍性能提升技术、探讨相关领域联系。

Result: 提供了视觉通用模型的全面概述，并指出了实际应用场景和挑战。

Conclusion: 总结了视觉通用模型的现状，提出了未来研究方向。

Abstract: Recently, we have witnessed the great success of the generalist model in
natural language processing. The generalist model is a general framework
trained with massive data and is able to process various downstream tasks
simultaneously. Encouraged by their impressive performance, an increasing
number of researchers are venturing into the realm of applying these models to
computer vision tasks. However, the inputs and outputs of vision tasks are more
diverse, and it is difficult to summarize them as a unified representation. In
this paper, we provide a comprehensive overview of the vision generalist
models, delving into their characteristics and capabilities within the field.
First, we review the background, including the datasets, tasks, and benchmarks.
Then, we dig into the design of frameworks that have been proposed in existing
research, while also introducing the techniques employed to enhance their
performance. To better help the researchers comprehend the area, we take a
brief excursion into related domains, shedding light on their interconnections
and potential synergies. To conclude, we provide some real-world application
scenarios, undertake a thorough examination of the persistent challenges, and
offer insights into possible directions for future research endeavors.

</details>


### [169] [Kvasir-VQA-x1: A Multimodal Dataset for Medical Reasoning and Robust MedVQA in Gastrointestinal Endoscopy](https://arxiv.org/abs/2506.09958)
*Sushant Gautam,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: Kvasir-VQA-x1是一个新的大规模胃肠道内窥镜数据集，扩展了原始数据集，包含159,549个新问题-答案对，旨在测试更深的临床推理。


<details>
  <summary>Details</summary>
Motivation: 现有MedVQA数据集缺乏临床复杂性和视觉多样性，限制了临床决策支持系统的发展。

Method: 使用大语言模型生成分层复杂性的问题，并引入视觉增强以模拟常见成像伪影。

Result: 数据集支持标准VQA性能和模型鲁棒性评估，为临床场景提供更具挑战性的基准。

Conclusion: Kvasir-VQA-x1旨在加速开发更可靠的多模态AI系统，并遵循FAIR数据原则，开放给研究社区。

Abstract: Medical Visual Question Answering (MedVQA) is a promising field for
developing clinical decision support systems, yet progress is often limited by
the available datasets, which can lack clinical complexity and visual
diversity. To address these gaps, we introduce Kvasir-VQA-x1, a new,
large-scale dataset for gastrointestinal (GI) endoscopy. Our work significantly
expands upon the original Kvasir-VQA by incorporating 159,549 new
question-answer pairs that are designed to test deeper clinical reasoning. We
developed a systematic method using large language models to generate these
questions, which are stratified by complexity to better assess a model's
inference capabilities. To ensure our dataset prepares models for real-world
clinical scenarios, we have also introduced a variety of visual augmentations
that mimic common imaging artifacts. The dataset is structured to support two
main evaluation tracks: one for standard VQA performance and another to test
model robustness against these visual perturbations. By providing a more
challenging and clinically relevant benchmark, Kvasir-VQA-x1 aims to accelerate
the development of more reliable and effective multimodal AI systems for use in
clinical settings. The dataset is fully accessible and adheres to FAIR data
principles, making it a valuable resource for the wider research community.
Code and data: https://github.com/Simula/Kvasir-VQA-x1 and
https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1

</details>


### [170] [Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing](https://arxiv.org/abs/2506.09965)
*Junfei Wu,Jian Guan,Kaituo Feng,Qiang Liu,Shu Wu,Liang Wang,Wei Wu,Tieniu Tan*

Main category: cs.CV

TL;DR: 论文提出了一种新的多模态推理范式，通过视觉空间中的基本绘图操作增强大型视觉语言模型的空间推理能力，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态推理中过于依赖文本，无法有效处理需要精确几何理解和连续空间跟踪的任务，因此需要一种新的视觉化推理方法。

Method: 提出了一种通过基本绘图操作（如标注边界框和绘制辅助线）在视觉空间中进行推理的范式，并开发了一个三阶段训练框架（冷启动训练、反射拒绝采样和强化学习）。

Result: 实验表明，模型VILASR在多种空间推理任务中平均性能提升了18.4%。

Conclusion: 通过视觉化推理方法，模型能够更有效地表达和分析空间关系，突破了传统文本中心方法的局限性。

Abstract: As textual reasoning with large language models (LLMs) has advanced
significantly, there has been growing interest in enhancing the multimodal
reasoning capabilities of large vision-language models (LVLMs). However,
existing methods primarily approach multimodal reasoning in a straightforward,
text-centric manner, where both reasoning and answer derivation are conducted
purely through text, with the only difference being the presence of multimodal
input. As a result, these methods often encounter fundamental limitations in
spatial reasoning tasks that demand precise geometric understanding and
continuous spatial tracking-capabilities that humans achieve through mental
visualization and manipulation. To address the limitations, we propose drawing
to reason in space, a novel paradigm that enables LVLMs to reason through
elementary drawing operations in the visual space. By equipping models with
basic drawing operations, including annotating bounding boxes and drawing
auxiliary lines, we empower them to express and analyze spatial relationships
through direct visual manipulation, meanwhile avoiding the performance ceiling
imposed by specialized perception tools in previous tool-integrated reasoning
approaches. To cultivate this capability, we develop a three-stage training
framework: cold-start training with synthetic data to establish basic drawing
abilities, reflective rejection sampling to enhance self-reflection behaviors,
and reinforcement learning to directly optimize for target rewards. Extensive
experiments demonstrate that our model, named VILASR, consistently outperforms
existing methods across diverse spatial reasoning benchmarks, involving maze
navigation, static spatial reasoning, video-based reasoning, and
multi-view-based reasoning tasks, with an average improvement of 18.4%.

</details>


### [171] [Vectorized Region Based Brush Strokes for Artistic Rendering](https://arxiv.org/abs/2506.09969)
*Jeripothula Prudviraj,Vikram Jamwal*

Main category: cs.CV

TL;DR: 提出一种图像到绘画的方法，通过语义引导、笔画参数计算和顺序渲染，解决现有笔画合成方法在艺术原则和意图对齐上的不足。


<details>
  <summary>Details</summary>
Motivation: 弥补静态艺术作品与其创作过程之间的情感和教育差距，同时解决现有笔画合成方法在艺术原则和意图对齐上的不足。

Method: 结合语义引导、笔画参数计算和顺序渲染，分区域优化笔画合成。

Result: 在多种输入图像（如人脸、绘画和摄影图像）上验证了方法的高保真度和优秀笔画质量。

Conclusion: 该方法能够更好地对齐艺术原则和意图，同时提升笔画合成的质量和保真度。

Abstract: Creating a stroke-by-stroke evolution process of a visual artwork tries to
bridge the emotional and educational gap between the finished static artwork
and its creation process. Recent stroke-based painting systems focus on
capturing stroke details by predicting and iteratively refining stroke
parameters to maximize the similarity between the input image and the rendered
output. However, these methods often struggle to produce stroke compositions
that align with artistic principles and intent. To address this, we explore an
image-to-painting method that (i) facilitates semantic guidance for brush
strokes in targeted regions, (ii) computes the brush stroke parameters, and
(iii) establishes a sequence among segments and strokes to sequentially render
the final painting. Experimental results on various input image types, such as
face images, paintings, and photographic images, show that our method aligns
with a region-based painting strategy while rendering a painting with high
fidelity and superior stroke quality.

</details>


### [172] [Efficient Part-level 3D Object Generation via Dual Volume Packing](https://arxiv.org/abs/2506.09980)
*Jiaxiang Tang,Ruijie Lu,Zhaoshuo Li,Zekun Hao,Xuan Li,Fangyin Wei,Shuran Song,Gang Zeng,Ming-Yu Liu,Tsung-Yi Lin*

Main category: cs.CV

TL;DR: 提出了一种新的端到端框架，用于生成具有任意数量语义部分的3D对象，解决了现有方法无法编辑单个部分的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D对象生成方法通常生成一个融合的单一网格，限制了部分编辑能力。不同对象可能有不同数量的部分，这是一个关键挑战。

Method: 采用双体积打包策略，将所有部分组织到两个互补的体积中，生成完整且语义有意义的部分。

Result: 实验表明，该方法在质量、多样性和泛化能力上优于之前的基于图像的部分级生成方法。

Conclusion: 提出的框架能够生成高质量、可编辑的3D对象，解决了部分级生成的挑战。

Abstract: Recent progress in 3D object generation has greatly improved both the quality
and efficiency. However, most existing methods generate a single mesh with all
parts fused together, which limits the ability to edit or manipulate individual
parts. A key challenge is that different objects may have a varying number of
parts. To address this, we propose a new end-to-end framework for part-level 3D
object generation. Given a single input image, our method generates
high-quality 3D objects with an arbitrary number of complete and semantically
meaningful parts. We introduce a dual volume packing strategy that organizes
all parts into two complementary volumes, allowing for the creation of complete
and interleaved parts that assemble into the final object. Experiments show
that our model achieves better quality, diversity, and generalization than
previous image-based part-level generation methods.

</details>


### [173] [Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search](https://arxiv.org/abs/2505.14156)
*Songhao Wu,Quan Tu,Hong Liu,Jia Xu,Zhongyi Liu,Guannan Zhang,Ran Wang,Xiuying Chen,Rui Yan*

Main category: cs.CV

TL;DR: 论文提出了一种名为Symbolic Graph Ranker (SGR)的方法，结合文本和图结构信息，利用大型语言模型(LLMs)提升会话搜索的效果。


<details>
  <summary>Details</summary>
Motivation: 当前会话搜索方法侧重于序列建模，忽略了交互中的图结构信息；而关注结构信息的方法又忽视了词级语义建模。

Method: SGR通过符号语法规则将会话图转换为文本，并设计自监督任务（如链接预测、节点内容生成等）增强LLMs对图结构的理解。

Result: 在AOL和Tiangong-ST数据集上的实验证实了SGR的优越性。

Conclusion: SGR为传统搜索策略与现代LLMs之间架起了桥梁，提供了一种新颖有效的方法。

Abstract: Session search involves a series of interactive queries and actions to
fulfill user's complex information need. Current strategies typically
prioritize sequential modeling for deep semantic understanding, overlooking the
graph structure in interactions. While some approaches focus on capturing
structural information, they use a generalized representation for documents,
neglecting the word-level semantic modeling. In this paper, we propose Symbolic
Graph Ranker (SGR), which aims to take advantage of both text-based and
graph-based approaches by leveraging the power of recent Large Language Models
(LLMs). Concretely, we first introduce a set of symbolic grammar rules to
convert session graph into text. This allows integrating session history,
interaction process, and task instruction seamlessly as inputs for the LLM.
Moreover, given the natural discrepancy between LLMs pre-trained on textual
corpora, and the symbolic language we produce using our graph-to-text grammar,
our objective is to enhance LLMs' ability to capture graph structures within a
textual format. To achieve this, we introduce a set of self-supervised symbolic
learning tasks including link prediction, node content generation, and
generative contrastive learning, to enable LLMs to capture the topological
information from coarse-grained to fine-grained. Experiment results and
comprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm
the superiority of our approach. Our paradigm also offers a novel and effective
methodology that bridges the gap between traditional search strategies and
modern LLMs.

</details>


### [174] [AnimateAnyMesh: A Feed-Forward 4D Foundation Model for Text-Driven Universal Mesh Animation](https://arxiv.org/abs/2506.09982)
*Zijie Wu,Chaohui Yu,Fan Wang,Xiang Bai*

Main category: cs.CV

TL;DR: AnimateAnyMesh是首个基于文本驱动的高效3D网格动画生成框架，通过DyMeshVAE架构和Rectified Flow训练策略，显著提升了4D内容生成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 当前4D内容生成面临建模时空分布的复杂性和训练数据稀缺的挑战，AnimateAnyMesh旨在解决这些问题。

Method: 采用DyMeshVAE架构分离时空特征并保留局部拓扑结构，结合Rectified Flow训练策略实现文本条件生成。

Result: 实验表明，该方法能在几秒内生成语义准确且时间连贯的网格动画，质量和效率均优于现有方法。

Conclusion: AnimateAnyMesh显著推动了4D内容生成的实用性和可访问性，相关数据和模型将开源。

Abstract: Recent advances in 4D content generation have attracted increasing attention,
yet creating high-quality animated 3D models remains challenging due to the
complexity of modeling spatio-temporal distributions and the scarcity of 4D
training data. In this paper, we present AnimateAnyMesh, the first feed-forward
framework that enables efficient text-driven animation of arbitrary 3D meshes.
Our approach leverages a novel DyMeshVAE architecture that effectively
compresses and reconstructs dynamic mesh sequences by disentangling spatial and
temporal features while preserving local topological structures. To enable
high-quality text-conditional generation, we employ a Rectified Flow-based
training strategy in the compressed latent space. Additionally, we contribute
the DyMesh Dataset, containing over 4M diverse dynamic mesh sequences with text
annotations. Experimental results demonstrate that our method generates
semantically accurate and temporally coherent mesh animations in a few seconds,
significantly outperforming existing approaches in both quality and efficiency.
Our work marks a substantial step forward in making 4D content creation more
accessible and practical. All the data, code, and models will be open-released.

</details>


### [175] [A Shortcut-aware Video-QA Benchmark for Physical Understanding via Minimal Video Pairs](https://arxiv.org/abs/2506.09987)
*Benno Krojer,Mojtaba Komeili,Candace Ross,Quentin Garrido,Koustuv Sinha,Nicolas Ballas,Mahmoud Assran*

Main category: cs.CV

TL;DR: MVP 基准测试通过最小变化对设计，减少视频语言模型依赖表面线索的捷径行为，更准确评估其物理世界理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型评估基准易因表面视觉或文本线索导致分数虚高，需更精准的评估方法。

Method: 引入 MVP 基准，包含 55K 高质量多选题视频 QA 样本，每样本配以最小变化对（视觉相似但答案相反的视频和问题）。

Result: 人类表现 92.9%，最佳开源模型 40.2%，随机表现 25%。

Conclusion: MVP 基准有效减少捷径行为，更真实反映模型物理理解能力。

Abstract: Existing benchmarks for assessing the spatio-temporal understanding and
reasoning abilities of video language models are susceptible to score inflation
due to the presence of shortcut solutions based on superficial visual or
textual cues. This paper mitigates the challenges in accurately assessing model
performance by introducing the Minimal Video Pairs (MVP) benchmark, a simple
shortcut-aware video QA benchmark for assessing the physical understanding of
video language models. The benchmark is comprised of 55K high-quality
multiple-choice video QA examples focusing on physical world understanding.
Examples are curated from nine video data sources, spanning first-person
egocentric and exocentric videos, robotic interaction data, and cognitive
science intuitive physics benchmarks. To mitigate shortcut solutions that rely
on superficial visual or textual cues and biases, each sample in MVP has a
minimal-change pair -- a visually similar video accompanied by an identical
question but an opposing answer. To answer a question correctly, a model must
provide correct answers for both examples in the minimal-change pair; as such,
models that solely rely on visual or textual biases would achieve below random
performance. Human performance on MVP is 92.9\%, while the best open-source
state-of-the-art video-language model achieves 40.2\% compared to random
performance at 25\%.

</details>


### [176] [EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits](https://arxiv.org/abs/2506.09988)
*Ron Yosef,Moran Yanuka,Yonatan Bitton,Dani Lischinski*

Main category: cs.CV

TL;DR: EditInspector是一个用于评估文本引导图像编辑的新基准，基于人工标注，用于验证编辑质量。研究发现现有模型在全面评估编辑时表现不佳，并提出了两种新方法以改进。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，文本引导图像编辑日益普及，但缺乏一个全面的框架来验证编辑质量和评估其效果。

Method: 引入EditInspector基准，利用人工标注和模板验证编辑，评估现有模型在多个维度上的表现，并提出两种新方法。

Result: 现有模型在全面评估编辑时表现不佳，常出现幻觉描述。新方法在伪影检测和差异描述生成上优于现有技术。

Conclusion: EditInspector为文本引导图像编辑提供了有效的评估工具，新方法在关键任务上表现更优，为未来研究提供了方向。

Abstract: Text-guided image editing, fueled by recent advancements in generative AI, is
becoming increasingly widespread. This trend highlights the need for a
comprehensive framework to verify text-guided edits and assess their quality.
To address this need, we introduce EditInspector, a novel benchmark for
evaluation of text-guided image edits, based on human annotations collected
using an extensive template for edit verification. We leverage EditInspector to
evaluate the performance of state-of-the-art (SoTA) vision and language models
in assessing edits across various dimensions, including accuracy, artifact
detection, visual quality, seamless integration with the image scene, adherence
to common sense, and the ability to describe edit-induced changes. Our findings
indicate that current models struggle to evaluate edits comprehensively and
frequently hallucinate when describing the changes. To address these
challenges, we propose two novel methods that outperform SoTA models in both
artifact detection and difference caption generation.

</details>


### [177] [Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes](https://arxiv.org/abs/2506.09989)
*Yiming Dou,Wonseok Oh,Yuqing Luo,Antonio Loquercio,Andrew Owens*

Main category: cs.CV

TL;DR: 研究如何通过预测人手与3D场景物理交互的声音，实现3D场景重建的交互性。


<details>
  <summary>Details</summary>
Motivation: 探索3D场景交互中的声音预测问题，以增强场景重建的沉浸感。

Method: 录制人手操作物体的视频，利用动作-声音对训练校正流模型，将3D手部轨迹映射到对应音频。

Result: 生成的音频能准确传达材料属性和动作，人类观察者难以区分其与真实声音。

Conclusion: 该方法成功实现了3D场景交互中的声音预测，提升了交互体验。

Abstract: We study the problem of making 3D scene reconstructions interactive by asking
the following question: can we predict the sounds of human hands physically
interacting with a scene? First, we record a video of a human manipulating
objects within a 3D scene using their hands. We then use these action-sound
pairs to train a rectified flow model to map 3D hand trajectories to their
corresponding audio. At test time, a user can query the model for other
actions, parameterized as sequences of hand poses, to estimate their
corresponding sounds. In our experiments, we find that our generated sounds
accurately convey material properties and actions, and that they are often
indistinguishable to human observers from real sounds. Project page:
https://www.yimingdou.com/hearing_hands/

</details>


### [178] [Text-Aware Image Restoration with Diffusion Models](https://arxiv.org/abs/2506.09993)
*Jaewon Min,Jin Hyeon Kim,Paul Hyunbin Cho,Jaeeun Lee,Jihye Park,Minkyu Park,Sangpil Kim,Hyunhee Park,Seungryong Kim*

Main category: cs.CV

TL;DR: 论文提出了一种新的图像修复任务TAIR，专注于同时恢复视觉内容和文本保真度，并提出了TeReDiff框架，结合扩散模型和文本识别模块，显著提升了文本识别准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的图像修复方法在自然图像修复中表现良好，但在文本区域重建时容易产生错误的文本幻觉现象，因此需要一种能同时恢复视觉内容和文本保真度的方法。

Method: 提出了TAIR任务和SA-Text基准数据集，并设计了TeReDiff框架，通过结合扩散模型和文本识别模块，利用联合训练提取丰富的文本表征作为去噪提示。

Result: 实验表明，TeReDiff在文本识别准确性上显著优于现有方法。

Conclusion: TAIR任务和TeReDiff框架为解决文本图像修复中的幻觉问题提供了有效方案，并在实验中验证了其优越性。

Abstract: Image restoration aims to recover degraded images. However, existing
diffusion-based restoration methods, despite great success in natural image
restoration, often struggle to faithfully reconstruct textual regions in
degraded images. Those methods frequently generate plausible but incorrect
text-like patterns, a phenomenon we refer to as text-image hallucination. In
this paper, we introduce Text-Aware Image Restoration (TAIR), a novel
restoration task that requires the simultaneous recovery of visual contents and
textual fidelity. To tackle this task, we present SA-Text, a large-scale
benchmark of 100K high-quality scene images densely annotated with diverse and
complex text instances. Furthermore, we propose a multi-task diffusion
framework, called TeReDiff, that integrates internal features from diffusion
models into a text-spotting module, enabling both components to benefit from
joint training. This allows for the extraction of rich text representations,
which are utilized as prompts in subsequent denoising steps. Extensive
experiments demonstrate that our approach consistently outperforms
state-of-the-art restoration methods, achieving significant gains in text
recognition accuracy. See our project page: https://cvlab-kaist.github.io/TAIR/

</details>


### [179] [PlayerOne: Egocentric World Simulator](https://arxiv.org/abs/2506.09995)
*Yuanpeng Tu,Hao Luo,Xi Chen,Xiang Bai,Fan Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: PlayerOne是首个以自我为中心的逼真世界模拟器，能够动态生成与用户真实动作严格对齐的沉浸式视频。


<details>
  <summary>Details</summary>
Motivation: 为自我中心视角的动态环境探索提供一种无限制且逼真的模拟工具。

Method: 采用从粗到细的训练流程，包括大规模文本-视频对的预训练和同步动作-视频数据的微调，并设计了部分解耦的运动注入方案和联合重建框架。

Result: 实验表明，PlayerOne在精确控制多样化人类动作和世界一致性建模方面表现出色。

Conclusion: PlayerOne开创了自我中心真实世界模拟的新领域，为世界建模及其多样化应用开辟了新方向。

Abstract: We introduce PlayerOne, the first egocentric realistic world simulator,
facilitating immersive and unrestricted exploration within vividly dynamic
environments. Given an egocentric scene image from the user, PlayerOne can
accurately construct the corresponding world and generate egocentric videos
that are strictly aligned with the real scene human motion of the user captured
by an exocentric camera. PlayerOne is trained in a coarse-to-fine pipeline that
first performs pretraining on large-scale egocentric text-video pairs for
coarse-level egocentric understanding, followed by finetuning on synchronous
motion-video data extracted from egocentric-exocentric video datasets with our
automatic construction pipeline. Besides, considering the varying importance of
different components, we design a part-disentangled motion injection scheme,
enabling precise control of part-level movements. In addition, we devise a
joint reconstruction framework that progressively models both the 4D scene and
video frames, ensuring scene consistency in the long-form video generation.
Experimental results demonstrate its great generalization ability in precise
control of varying human movements and worldconsistent modeling of diverse
scenarios. It marks the first endeavor into egocentric real-world simulation
and can pave the way for the community to delve into fresh frontiers of world
modeling and its diverse applications.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [180] [Designing conflict-based communicative tasks in Teaching Chinese as a Foreign Language with ChatGPT](https://arxiv.org/abs/2506.09089)
*Xia Li*

Main category: cs.HC

TL;DR: 论文探讨了在大学汉语口语教学中，教师如何利用ChatGPT辅助设计基于冲突的交际任务，以提升学生的口语互动能力，并分析了教师与ChatGPT的互动特点及其影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索ChatGPT在汉语口语教学任务设计中的应用潜力及其对教学过程的实际影响。

Method: 教师在设计基于冲突的交际任务时，借助ChatGPT辅助完成课程设计，并记录互动过程。

Result: 研究发现ChatGPT能有效辅助任务设计，同时揭示了教师与AI互动的关键特点。

Conclusion: 结论指出ChatGPT在汉语口语教学中具有实用价值，但需进一步研究其长期影响。

Abstract: In developing the teaching program for a course in Oral Expression in
Teaching Chinese as a Foreign Language at the university level, the teacher
designs communicative tasks based on conflicts to encourage learners to engage
in interactive dynamics and develop their oral interaction skills. During the
design of these tasks, the teacher uses ChatGPT to assist in finalizing the
program. This article aims to present the key characteristics of the
interactions between the teacher and ChatGPT during this program development
process, as well as to examine the use of ChatGPT and its impacts in this
specific context.

</details>


### [181] [Real-Time Confidence Detection through Facial Expressions and Hand Gestures](https://arxiv.org/abs/2506.09153)
*Tanjil Hasan Sakib,Samia Jahan Mojumder,Rajan Das Gupta,Md Imrul Hasan Showmick,Md. Yeasin Rahat,Md. Jakir Hossen*

Main category: cs.HC

TL;DR: 该研究提出了一种基于Media Pipe Face Mesh框架的实时人脸朝向识别方法，通过提取面部几何数据计算欧拉角，准确率达到90%，适用于虚拟环境中的用户互动监测。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟互动的需求增长，实时监测参与者的注意力与互动变得尤为重要，需要一种高精度且响应迅速的技术。

Method: 利用Media Pipe Face Mesh框架识别面部关键点，提取几何数据计算欧拉角，实时跟踪头部朝向。

Result: 系统在4英尺距离内识别头部朝向的准确率达90%，显著提升了虚拟互动的监测能力。

Conclusion: 该方法为虚拟用户体验的改进提供了基础，未来可进一步整合实时面部追踪技术，提升互动性。

Abstract: Real-time face orientation recognition is a cutting-edge technology meant to
track and analyze facial movements in virtual environments such as online
interviews, remote meetings, and virtual classrooms. As the demand for virtual
interactions grows, it becomes increasingly important to measure participant
engagement, attention, and overall interaction. This research presents a novel
solution that leverages the Media Pipe Face Mesh framework to identify facial
landmarks and extract geometric data for calculating Euler angles, which
determine head orientation in real time. The system tracks 3D facial landmarks
and uses this data to compute head movements with a focus on accuracy and
responsiveness. By studying Euler angles, the system can identify a user's head
orientation with an accuracy of 90\%, even at a distance of up to four feet.
This capability offers significant enhancements for monitoring user
interaction, allowing for more immersive and interactive virtual ex-periences.
The proposed method shows its reliability in evaluating participant
attentiveness during online assessments and meetings. Its application goes
beyond engagement analysis, potentially providing a means for improving the
quality of virtual communication, fostering better understanding between
participants, and ensuring a higher level of interaction in digital spaces.
This study offers a basis for future developments in enhancing virtual user
experiences by integrating real-time facial tracking technologies, paving the
way for more adaptive and interactive web-based platform.

</details>


### [182] [Show Me Your Best Side: Characteristics of User-Preferred Perspectives for 3D Graph Drawings](https://arxiv.org/abs/2506.09212)
*Lucas Joos,Gavin J. Mooney,Maximilian T. Fischer,Daniel A. Keim,Falk Schreiber,Helen C. Purchase,Karsten Klein*

Main category: cs.HC

TL;DR: 论文研究了3D图可视化中用户偏好的视角选择，通过实验和数据分析确定了影响偏好的关键指标。


<details>
  <summary>Details</summary>
Motivation: 3D图布局的视角依赖性使得视角选择对揭示结构和关系模式至关重要，但目前缺乏关于用户偏好视角的实证研究。

Method: 在虚拟现实环境中对23名参与者进行控制研究，收集他们对36种不同图的偏好视角，并结合定性反馈分析。

Result: 研究发现Stress、Crossings、Gabriel Ratio、Edge-Node Overlap和Isometric Viewpoint Deviation是影响视角偏好的关键指标。

Conclusion: 研究不仅提供了用户偏好视角的实证数据，还公开了数据集和评估指标，支持未来3D图绘制研究。

Abstract: The visual analysis of graphs in 3D has become increasingly popular,
accelerated by the rise of immersive technology, such as augmented and virtual
reality. Unlike 2D drawings, 3D graph layouts are highly viewpoint-dependent,
making perspective selection critical for revealing structural and relational
patterns. Despite its importance, there is limited empirical evidence guiding
what constitutes an effective or preferred viewpoint from the user's
perspective. In this paper, we present a systematic investigation into
user-preferred viewpoints in 3D graph visualisations. We conducted a controlled
study with 23 participants in a virtual reality environment, where users
selected their most and least preferred viewpoints for 36 different graphs
varying in size and layout. From this data, enriched by qualitative feedback,
we distil common strategies underlying viewpoint choice. We further analyse the
alignment of user preferences with classical 2D aesthetic criteria (e.g.,
Crossings), 3D-specific measures (e.g., Node-Node Occlusion), and introduce a
novel measure capturing the perceivability of a graph's principal axes
(Isometric Viewpoint Deviation). Our data-driven analysis indicates that
Stress, Crossings, Gabriel Ratio, Edge-Node Overlap, and Isometric Viewpoint
Deviation are key indicators of viewpoint preference. Beyond our findings, we
contribute a publicly available dataset consisting of the graphs and computed
aesthetic measures, supporting further research and the development of
viewpoint evaluation measures for 3D graph drawing.

</details>


### [183] ["How do you even know that stuff?": Barriers to expertise sharing among spreadsheet users](https://arxiv.org/abs/2506.09216)
*Qing,Xia,Advait Sarkar,Duncan Brumby,Anna Cox*

Main category: cs.HC

TL;DR: 研究发现，电子表格专家因社会规范、自我评价冲突及对协作的担忧而难以分享知识，揭示了功能丰富软件中长期学习的挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨电子表格专家为何难以分享知识，研究社会规范和技术设计如何影响协作学习行为。

Method: 对31名专业电子表格用户进行半结构化访谈，分析分享行为的障碍。

Result: 发现个性化策略适应困难、自我评价冲突、对协作的担忧等因素阻碍知识分享。

Conclusion: 技术设计与社会动态的复杂互动影响协作学习，需优化设计以解决这一矛盾。

Abstract: Spreadsheet collaboration provides valuable opportunities for learning and
expertise sharing between colleagues. Sharing expertise is essential for the
retention of important technical skillsets within organisations, but previous
studies suggest that spreadsheet experts often fail to disseminate their
knowledge to others. We suggest that social norms and beliefs surrounding the
value of spreadsheet use significantly influence user engagement in sharing
behaviours. To explore this, we conducted 31 semi-structured interviews with
professional spreadsheet users from two separate samples. We found that
spreadsheet providers face challenges in adapting highly personalised
strategies to often subjective standards and evaluating the appropriate social
timing of sharing. In addition, conflicted self-evaluations of one's
spreadsheet expertise, dismissive normative beliefs about the value of this
knowledge, and concerns about the potential disruptions associated with
collaboration can further deter sharing. We suggest these observations reflect
the challenges of long-term learning in feature-rich software designed
primarily with initial learnability in mind. We therefore provide implications
for design to navigate this tension. Overall, our findings demonstrate how the
complex interaction between technology design and social dynamics can shape
collaborative learning behaviours in the context of feature-rich software.

</details>


### [184] [Beyond the Hype: Mapping Uncertainty and Gratification in AI Assistant Use](https://arxiv.org/abs/2506.09220)
*Karen Joy,Tawfiq Ammari,Alyssa Sheehan*

Main category: cs.HC

TL;DR: 论文探讨了新兴AI个人助手的承诺与实际表现的差距，分析了用户不确定性及其对满意度的影响，并提出了设计和政策建议。


<details>
  <summary>Details</summary>
Motivation: 研究AI个人助手在现实中的表现与宣传的差距，以及用户在使用过程中遇到的功能、交互和社交不确定性。

Method: 通过访谈早期使用者，结合“使用与满足”和“不确定性减少理论”分析用户体验。

Result: 发现用户不确定性导致满意度下降，提出透明度、任务特定设计和用户控制的重要性。

Conclusion: 建议设计解释性工具和监管基准，以提升AI助手的可用性和可信度。

Abstract: This paper examines the gap between the promises and real-world performance
of emerging AI personal assistants. Drawing on interviews with early adopters
of devices like Rabbit R1 and Humane AI Pin, as well as services like Ohai and
Docus, we map user experiences through the lens of Uses and Gratifications and
Uncertainty Reduction Theory. We identify three core types of user uncertainty,
functional, interactional, and social, and explore how each disrupts different
user gratifications. We show that while marketing hype fuels initial adoption,
unmet expectations often result in frustration or abandonment. Our findings
highlight the importance of transparency, task-specific design, and user
control over contextual memory and personalization. We provide design and
policy recommendations, including user-facing explainability tools and calls
for regulatory benchmarks such as CI Bench, to guide ethical and interpretable
AI integration. Our study offers actionable insights for creating more usable,
trustworthy, and socially aligned AI assistants.

</details>


### [185] [Augmented Reality User Interfaces for First Responders: A Scoping Literature Review](https://arxiv.org/abs/2506.09236)
*Erin Argo,Tanim Ahmed,Sarah Gable,Callie Hampton,Jeronimo Grandi,Regis Kopper*

Main category: cs.HC

TL;DR: 论文通过系统性综述方法分析了AR用户界面在公共安全领域的应用，总结了研究趋势、挑战和文献缺口。


<details>
  <summary>Details</summary>
Motivation: 过去十年中，AR用户界面在公共安全领域的应用研究显著增加，但缺乏系统性综述。

Method: 采用系统性综述方法，筛选了90篇相关文献，并开发了分类法。

Result: 提出了AR用户界面在公共安全领域的分类法，总结了设计考虑和挑战。

Conclusion: 该综述为未来研究提供了基础，并指出了进一步发展的方向。

Abstract: During the past decade, there has been a significant increase in research
focused on integrating AR User Interfaces into public safety applications,
particularly for first responders in the domains of Emergency Medical Services,
Firefighting, and Law Enforcement. This paper presents the results of a scoping
review involving the application of AR user interfaces in the public safety
domain and applies an established systematic review methodology to provide a
comprehensive analysis of the current research landscape, identifying key
trends, challenges, and gaps in the literature. This review includes
peer-reviewed publications indexed by the major scientific databases up to
April 2025. A basic keyword search retrieved 1,751 papers, of which 90 were
deemed relevant for this review. An in-depth analysis of the literature allowed
the development of a faceted taxonomy that categorizes AR user interfaces for
public safety. This classification lays a solid foundation for future research,
while also highlighting key design considerations, challenges, and gaps in the
literature. This review serves as a valuable resource for researchers and
developers, offering insights that can drive further advances in the field.

</details>


### [186] [AI Tutors vs. Tenacious Myths: Evidence from Personalised Dialogue Interventions in Education](https://arxiv.org/abs/2506.09292)
*Brooklyn J. Corbett,Jason M. Tangen*

Main category: cs.HC

TL;DR: 个性化AI对话能更有效地纠正心理学误解，但效果随时间减弱。


<details>
  <summary>Details</summary>
Motivation: 心理学和教育中的误解难以通过传统方法纠正，研究探索个性化AI对话的效果。

Method: 375名参与者接受三种干预：个性化AI对话、通用教科书反驳或中性AI对话（对照）。

Result: 个性化AI对话在短期内显著减少误解，效果优于教科书和中性对话，但随时间减弱。

Conclusion: AI对话能加速初始纠正，但需结构化教育和强化以维持效果。

Abstract: Misconceptions in psychology and education persist despite clear
contradictory evidence, resisting traditional correction methods. This study
investigated whether personalised AI dialogue could effectively correct these
stubborn beliefs. In a preregistered experiment (N = 375), participants holding
strong psychology misconceptions engaged in one of three interventions: (1)
personalised AI dialogue targeting their specific misconception, (2) generic
textbook-style refutation, or (3) neutral AI dialogue (control). Results showed
that personalised AI dialogue produced significantly larger immediate belief
reductions compared to both textbook reading and neutral dialogue. This
advantage persisted at 10-day follow-up but diminished by 2 months, where AI
dialogue and textbook conditions converged while both remained superior to
control. Both AI conditions generated significantly higher engagement and
confidence than textbook reading, demonstrating the motivational benefits of
conversational interaction. These findings demonstrate that AI dialogue can
accelerate initial belief correction through personalised, interactive
engagement that disrupts the cognitive processes maintaining misconceptions.
However, the convergence of effects over time suggests brief interventions
require reinforcement for lasting change. Future applications should integrate
AI tutoring into structured educational programs with spaced reinforcement to
sustain the initial advantages of personalised dialogue.

</details>


### [187] ["Is This Really a Human Peer Supporter?": Misalignments Between Peer Supporters and Experts in LLM-Supported Interactions](https://arxiv.org/abs/2506.09354)
*Kellie Yu Hui Sim,Roy Ka-Wei Lee,Kenny Tsu Wei Choo*

Main category: cs.HC

TL;DR: AI驱动的系统通过LLM模拟客户并提供实时建议，增强同伴支持的质量，但需注意专家与同伴支持者之间的反应差异。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题日益严重，AI驱动的解决方案可扩展心理社会支持，但同伴支持的质量和一致性存在问题。

Method: 开发并评估一个AI支持系统，包括LLM模拟客户、实时建议和情绪可视化，通过混合方法研究验证效果。

Result: 同伴支持者和专家认可系统潜力，但专家指出同伴支持者存在关键问题（如忽视痛苦信号），显示培训不足。

Conclusion: 需标准化心理基础培训，LLM系统可辅助发展，但需专家指导和谨慎设计，以负责任地整合AI于心理健康领域。

Abstract: Mental health is a growing global concern, prompting interest in AI-driven
solutions to expand access to psychosocial support. Peer support, grounded in
lived experience, offers a valuable complement to professional care. However,
variability in training, effectiveness, and definitions raises concerns about
quality, consistency, and safety. Large Language Models (LLMs) present new
opportunities to enhance peer support interactions, particularly in real-time,
text-based interactions. We present and evaluate an AI-supported system with an
LLM-simulated distressed client, context-sensitive LLM-generated suggestions,
and real-time emotion visualisations. 2 mixed-methods studies with 12 peer
supporters and 5 mental health professionals (i.e., experts) examined the
system's effectiveness and implications for practice. Both groups recognised
its potential to enhance training and improve interaction quality. However, we
found a key tension emerged: while peer supporters engaged meaningfully,
experts consistently flagged critical issues in peer supporter responses, such
as missed distress cues and premature advice-giving. This misalignment
highlights potential limitations in current peer support training, especially
in emotionally charged contexts where safety and fidelity to best practices are
essential. Our findings underscore the need for standardised, psychologically
grounded training, especially as peer support scales globally. They also
demonstrate how LLM-supported systems can scaffold this development--if
designed with care and guided by expert oversight. This work contributes to
emerging conversations on responsible AI integration in mental health and the
evolving role of LLMs in augmenting peer-delivered care.

</details>


### [188] ["I Said Things I Needed to Hear Myself": Peer Support as an Emotional, Organisational, and Sociotechnical Practice in Singapore](https://arxiv.org/abs/2506.09362)
*Kellie Yu Hui Sim,Kenny Tsu Wei Choo*

Main category: cs.HC

TL;DR: 本文研究了新加坡20名同伴支持者的访谈数据，探讨了他们在不同环境中提供支持的方式、动机及情感劳动，并提出了文化响应的数字工具设计方向。


<details>
  <summary>Details</summary>
Motivation: 同伴支持在心理健康护理中至关重要，但数字平台的设计和影响在亚洲背景下研究不足。

Method: 通过主题分析20名新加坡同伴支持者的访谈数据，探讨其支持实践。

Result: 揭示了同伴支持者的动机、情感劳动及社会文化因素，提出了文化响应的数字工具设计方向。

Conclusion: 研究为心理健康领域可信赖且情境敏感的AI设计提供了实践和理论贡献。

Abstract: Peer support plays a vital role in expanding access to mental health care by
providing empathetic, community-based support outside formal clinical systems.
As digital platforms increasingly mediate such support, the design and impact
of these technologies remain under-examined, particularly in Asian contexts.
This paper presents findings from an interview study with 20 peer supporters in
Singapore, who operate across diverse online, offline, and hybrid environments.
Through a thematic analysis, we unpack how participants start, conduct, and
sustain peer support, highlighting their motivations, emotional labour, and the
sociocultural dimensions shaping their practices. Building on this grounded
understanding, we surface design directions for culturally responsive digital
tools that scaffold rather than supplant relational care. Drawing insights from
qualitative accounts, we offer a situated perspective on how AI might
responsibly augment peer support. This research contributes to human-centred
computing by articulating the lived realities of peer supporters and proposing
design implications for trustworthy and context-sensitive AI in mental health.

</details>


### [189] [Patterns of Patterns III](https://arxiv.org/abs/2506.09696)
*Joseph Corneli,Charles J. Danoff,Raymond S. Puzio,Sridevi Ayloo,Serge Belich,Mary Tedeschi*

Main category: cs.HC

TL;DR: 本文重新审视PLACARD模式，通过工作坊和虚拟聊天机器人案例比较，探讨其在协作反思和设计模式生成中的应用，并提出未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 研究PLACARD模式在协作反思和设计模式生成中的潜力，并探索AI代理在此领域的应用。

Method: 通过系列工作坊和虚拟聊天机器人案例比较，分析PLACARD模式的效果。

Result: 总结了人类和多代理设置中的局限性和经验教训。

Conclusion: 提出了结合AI代理、设计模式和机构治理的未来发展策略。

Abstract: Building on earlier installments, this paper re-examines the PLACARD pattern.
We report on a series of workshops where PLACARD was used to scaffold
collaborative reflection, speculative inquiry, and stimulate design pattern
generation. These accounts are enriched by a comparison case: virtual workshops
carried out with simple AI-based chatbots. We discuss limitations and lessons
learned from both the human and multi-agent settings. We conclude by outlining
a future development strategy at the intersection of AI agents, design
patterns, and institutional governance.

</details>


### [190] [Investigating the Perception of Translational Shape-Changing Haptic Interfaces](https://arxiv.org/abs/2506.09801)
*Qihan Yang,Xin Zhou,Adam J. Spiers*

Main category: cs.HC

TL;DR: 该论文通过心理物理学用户研究，评估了形状变化触觉界面（SCHIs）的动态形状感知，探讨了抓握类型和位移大小/方向的影响，并提出了优化触觉反馈的建议。


<details>
  <summary>Details</summary>
Motivation: 形状变化触觉界面（SCHIs）是一个新兴领域，但关于动态形状感知的研究较少，且抓握类型和位移特性对感知的影响尚未正式评估。

Method: 采用1自由度平移形状变化界面，进行心理物理学实验，参与者以三种不同抓握方式完成恒定刺激法研究，测试了不同位移大小和方向的感知。

Result: 实验表明，平移SCHIs应最大化位移幅度而非接触手指数量；非线性的设备位置映射在应用中更有效。

Conclusion: 该研究为SCHIs的感知评估提供了初步框架，并展示了研究结果在实际应用中的有效性，鼓励进一步探索其他SCHI形态的感知特性。

Abstract: Shape-changing haptic interfaces (SCHIs) are a promising and emerging field.
However, compared to more established stimulus modalities, such as vibration,
there is sparse literature on the perception of dynamic shapes. Furthermore,
the influence of properties such as grasp types and displacement
magnitude/direction has not been formally evaluated. This work attempts to
initiate a formal perceptual evaluation of SCHIs via a psychophysical user
study involving a 1-DOF translational shape-changing interface that can move
its body with 1.25-micrometer resolution. Participants completed a Method of
Constant Stimulus study while holding the device with three different grasps.
Stimuli direction occurred both toward and away from the thumb, while the
standard stimuli varied between small (0.48 mm) and large (6 mm). Our results
indicate that translational SCHIs should maximize the translation magnitude
rather than the number of fingers in contact. We also demonstrated how to apply
our findings to real-world applications via a simple 'paddle game', where we
compared conventional linear mapping with non-linear mapping derived from our
perceptual experiment outcomes between the device position and its represented
value. Results indicate that the non-linear mapping was more effective, with
improved error distribution. We hope this work inspires further formal
perceptual investigation into other SCHI morphologies.

</details>


### [191] [SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance](https://arxiv.org/abs/2506.09968)
*Wentao Ge,Yuqing Sun,Ziyan Wang,Haoyue Zheng,Weiyang He,Piaohong Wang,Qianyu Zhu,Benyou Wang*

Main category: cs.HC

TL;DR: 论文介绍了一种名为SRLAgent的系统，通过游戏化和LLM支持帮助大学生提升自我调节学习（SRL）能力。


<details>
  <summary>Details</summary>
Motivation: 大学生在学术独立性和需求增加时，缺乏SRL技能会导致学习习惯混乱、动力不足和时间管理不善。

Method: 基于Zimmerman的三阶段SRL框架，SRLAgent结合游戏化和LLM实时反馈，支持目标设定、策略执行和自我反思。

Result: 实验显示，SRLAgent组在SRL技能上有显著提升（p < .001, Cohen’s d = 0.234），且比对照组更受学生欢迎。

Conclusion: 研究表明，将SRL支持和AI实时反馈嵌入游戏化环境对提升学习深度和元认知技能有重要价值。

Abstract: Self-regulated learning (SRL) is crucial for college students navigating
increased academic demands and independence. Insufficient SRL skills can lead
to disorganized study habits, low motivation, and poor time management,
undermining learners ability to thrive in challenging environments. Through a
formative study involving 59 college students, we identified key challenges
students face in developing SRL skills, including difficulties with
goal-setting, time management, and reflective learning. To address these
challenges, we introduce SRLAgent, an LLM-assisted system that fosters SRL
skills through gamification and adaptive support from large language models
(LLMs). Grounded in Zimmermans three-phase SRL framework, SRLAgent enables
students to engage in goal-setting, strategy execution, and self-reflection
within an interactive game-based environment. The system offers real-time
feedback and scaffolding powered by LLMs to support students independent study
efforts. We evaluated SRLAgent using a between-subjects design, comparing it to
a baseline system (SRL without Agent features) and a traditional multimedia
learning condition. Results showed significant improvements in SRL skills
within the SRLAgent group (p < .001, Cohens d = 0.234) and higher engagement
compared to the baselines. This work highlights the value of embedding SRL
scaffolding and real-time AI support within gamified environments, offering
design implications for educational technologies that aim to promote deeper
learning and metacognitive skill development.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [192] [Llama-Affinity: A Predictive Antibody Antigen Binding Model Integrating Antibody Sequences with Llama3 Backbone Architecture](https://arxiv.org/abs/2506.09052)
*Delower Hossain,Ehsan Saghapour,Kevin Song,Jake Y. Chen*

Main category: cs.LG

TL;DR: 论文提出了一种基于Llama 3的抗体-抗原结合亲和力预测模型（LlamaAffinity），在多个评估指标上优于现有方法，并显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统抗体亲和力测量方法耗时且昂贵，AI技术的发展为抗体设计和亲和力预测提供了新途径。

Method: 利用开源Llama 3框架和OAS数据库的抗体序列数据，开发了LlamaAffinity模型。

Result: 模型在准确性（0.9640）、F1分数（0.9643）、精确度（0.9702）、召回率（0.9586）和AUC-ROC（0.9936）上表现优异，训练时间显著缩短（0.46小时）。

Conclusion: LlamaAffinity模型在抗体-抗原亲和力预测中表现出色，为AI驱动的抗体设计提供了高效工具。

Abstract: Antibody-facilitated immune responses are central to the body's defense
against pathogens, viruses, and other foreign invaders. The ability of
antibodies to specifically bind and neutralize antigens is vital for
maintaining immunity. Over the past few decades, bioengineering advancements
have significantly accelerated therapeutic antibody development. These
antibody-derived drugs have shown remarkable efficacy, particularly in treating
cancer, SARS-CoV-2, autoimmune disorders, and infectious diseases.
Traditionally, experimental methods for affinity measurement have been
time-consuming and expensive. With the advent of artificial intelligence, in
silico medicine has been revolutionized; recent developments in machine
learning, particularly the use of large language models (LLMs) for representing
antibodies, have opened up new avenues for AI-based design and improved
affinity prediction. Herein, we present an advanced antibody-antigen binding
affinity prediction model (LlamaAffinity), leveraging an open-source Llama 3
backbone and antibody sequence data sourced from the Observed Antibody Space
(OAS) database. The proposed approach shows significant improvement over
existing state-of-the-art (SOTA) methods (AntiFormer, AntiBERTa, AntiBERTy)
across multiple evaluation metrics. Specifically, the model achieved an
accuracy of 0.9640, an F1-score of 0.9643, a precision of 0.9702, a recall of
0.9586, and an AUC-ROC of 0.9936. Moreover, this strategy unveiled higher
computational efficiency, with a five-fold average cumulative training time of
only 0.46 hours, significantly lower than in previous studies.

</details>


### [193] [FinHEAR: Human Expertise and Adaptive Risk-Aware Temporal Reasoning for Financial Decision-Making](https://arxiv.org/abs/2506.09080)
*Jiaxiang Chen,Mingxi Zou,Zhuo Wang,Qifan Wang,Dongning Sun,Chi Zhang,Zenglin Xu*

Main category: cs.LG

TL;DR: FinHEAR是一个多智能体框架，结合人类专业知识和自适应风险感知推理，提升语言模型在金融决策中的表现。


<details>
  <summary>Details</summary>
Motivation: 语言模型在金融决策中缺乏对人类行为模式（如信息不对称下的专家依赖、损失厌恶和时间调整）的捕捉能力。

Method: FinHEAR通过多智能体协作，分析历史趋势、解读当前事件并检索专家知识，结合行为经济学设计专家引导检索、信心调整头寸和结果优化。

Result: 在金融数据集上，FinHEAR在趋势预测和交易任务中表现优于基线模型，准确率和风险调整收益更高。

Conclusion: FinHEAR通过结合人类专业知识和自适应风险推理，显著提升了语言模型在金融决策中的表现。

Abstract: Financial decision-making presents unique challenges for language models,
demanding temporal reasoning, adaptive risk assessment, and responsiveness to
dynamic events. While large language models (LLMs) show strong general
reasoning capabilities, they often fail to capture behavioral patterns central
to human financial decisions-such as expert reliance under information
asymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. We
propose FinHEAR, a multi-agent framework for Human Expertise and Adaptive
Risk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents to
analyze historical trends, interpret current events, and retrieve
expert-informed precedents within an event-centric pipeline. Grounded in
behavioral economics, it incorporates expert-guided retrieval,
confidence-adjusted position sizing, and outcome-based refinement to enhance
interpretability and robustness. Empirical results on curated financial
datasets show that FinHEAR consistently outperforms strong baselines across
trend prediction and trading tasks, achieving higher accuracy and better
risk-adjusted returns.

</details>


### [194] [Enhanced Whole Page Optimization via Mixed-Grained Reward Mechanism-Adapted Language Models](https://arxiv.org/abs/2506.09084)
*Xinyuan Wang,Liang Wu,Yanjie Fu*

Main category: cs.LG

TL;DR: 论文提出PageLLM，通过用户反馈和双粒度奖励机制优化LLMs在整页优化（WPO）中的应用，显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型（LLMs）在WPO任务中面临标注数据成本高和模型不稳定的挑战，需寻找替代监督信号。

Method: 提出PageLLM，利用用户反馈作为监督，结合页面级和项目级双粒度奖励机制进行模型微调。

Result: 在公开和工业数据集上验证，PageLLM优于基线模型，并在在线A/B测试中实现0.44%的GMV增长。

Conclusion: PageLLM通过用户反馈和双粒度奖励机制，有效解决了LLMs在WPO任务中的微调难题，具有实际应用价值。

Abstract: Optimizing the presentation of search and recommendation results is crucial
to enhancing user experience and engagement. Whole Page Optimization (WPO)
plays a pivotal role in this process, as it directly influences how information
is surfaced to users. While Pre-trained Large Language Models (LLMs) have
demonstrated remarkable capabilities in generating coherent and contextually
relevant content, fine-tuning these models for complex tasks like WPO presents
challenges. Specifically, the need for extensive human-annotated data to
mitigate issues such as hallucinations and model instability can be
prohibitively expensive, especially in large-scale systems that interact with
millions of items daily. In this work, we address the challenge of fine-tuning
LLMs for WPO by using user feedback as the supervision. Unlike manually labeled
datasets, user feedback is inherently noisy and less precise. To overcome this,
we propose a reward-based fine-tuning approach, PageLLM, which employs a
mixed-grained reward mechanism that combines page-level and item-level rewards.
The page-level reward evaluates the overall quality and coherence, while the
item-level reward focuses on the accuracy and relevance of key recommendations.
This dual-reward structure ensures that both the holistic presentation and the
critical individual components are optimized. We validate PageLLM on both
public and industrial datasets. PageLLM outperforms baselines and achieves a
0.44\% GMV increase in an online A/B test with over 10 million users,
demonstrating its real-world impact.

</details>


### [195] [LLM-ML Teaming: Integrated Symbolic Decoding and Gradient Search for Valid and Stable Generative Feature Transformation](https://arxiv.org/abs/2506.09085)
*Xinyuan Wang,Haoyue Bai,Nanxu Gong,Wangyang Ying,Sixun Dong,Xiquan Cui,Yanjie Fu*

Main category: cs.LG

TL;DR: 提出了一种结合LLM和ML的团队框架，通过四个步骤实现稳定且有效的特征转换，实验表明其在下游任务中表现优异且错误率降低。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在特征转换中存在稳定性和有效性挑战，现有方法无法同时解决这两个问题。

Method: 结合LLM的符号生成和ML的梯度优化，分为四个步骤：高质量样本生成、特征转换序列嵌入与搜索、学生LLM知识蒸馏、LLM-ML解码器团队协作。

Result: 实验显示团队策略在下游任务中性能提升5%，错误率降低近半，且具有高效性和鲁棒性。

Conclusion: 团队框架成功解决了生成式AI在特征转换中的挑战，并展示了LLM对原始数据的理解能力。

Abstract: Feature transformation enhances data representation by deriving new features
from the original data. Generative AI offers potential for this task, but faces
challenges in stable generation (consistent outputs) and valid generation
(error-free sequences). Existing methods--traditional MLs' low validity and
LLMs' instability--fail to resolve both. We find that LLMs ensure valid syntax,
while ML's gradient-steered search stabilizes performance. To bridge this gap,
we propose a teaming framework combining LLMs' symbolic generation with ML's
gradient optimization. This framework includes four steps: (1) golden examples
generation, aiming to prepare high-quality samples with the ground knowledge of
the teacher LLM; (2) feature transformation sequence embedding and search,
intending to uncover potentially superior embeddings within the latent space;
(3) student LLM feature transformation, aiming to distill knowledge from the
teacher LLM; (4) LLM-ML decoder teaming, dedicating to combine ML and the
student LLM probabilities for valid and stable generation. The experiments on
various datasets show that the teaming policy can achieve 5\% improvement in
downstream performance while reducing nearly half of the error cases. The
results also demonstrate the efficiency and robustness of the teaming policy.
Additionally, we also have exciting findings on LLMs' capacity to understand
the original data.

</details>


### [196] [Spiking Neural Models for Decision-Making Tasks with Learning](https://arxiv.org/abs/2506.09087)
*Sophie Jaffard,Giulia Mezzadri,Patricia Reynaud-Bouret,Etienne Tanré*

Main category: cs.LG

TL;DR: 该论文提出了一种基于尖峰神经网络的生物可解释决策模型，结合了学习机制，填补了认知模型与生物模型之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有决策模型（如漂移扩散模型和泊松计数器模型）缺乏学习机制，且仅适用于已知类别任务，无法完全解释生物神经活动。

Method: 提出了一种基于多变量霍克斯过程的尖峰神经网络模型，并通过实验验证其与漂移扩散模型的耦合关系。

Result: 证明了漂移扩散模型可通过尖峰泊松神经元近似，且特定噪声相关的漂移扩散模型可从霍克斯网络中推导。

Conclusion: 该研究为将生物神经机制整合到认知模型中提供了重要进展，深化了对神经活动与行为关系的理解。

Abstract: In cognition, response times and choices in decision-making tasks are
commonly modeled using Drift Diffusion Models (DDMs), which describe the
accumulation of evidence for a decision as a stochastic process, specifically a
Brownian motion, with the drift rate reflecting the strength of the evidence.
In the same vein, the Poisson counter model describes the accumulation of
evidence as discrete events whose counts over time are modeled as Poisson
processes, and has a spiking neurons interpretation as these processes are used
to model neuronal activities. However, these models lack a learning mechanism
and are limited to tasks where participants have prior knowledge of the
categories. To bridge the gap between cognitive and biological models, we
propose a biologically plausible Spiking Neural Network (SNN) model for
decision-making that incorporates a learning mechanism and whose neurons
activities are modeled by a multivariate Hawkes process. First, we show a
coupling result between the DDM and the Poisson counter model, establishing
that these two models provide similar categorizations and reaction times and
that the DDM can be approximated by spiking Poisson neurons. To go further, we
show that a particular DDM with correlated noise can be derived from a Hawkes
network of spiking neurons governed by a local learning rule. In addition, we
designed an online categorization task to evaluate the model predictions. This
work provides a significant step toward integrating biologically relevant
neural mechanisms into cognitive models, fostering a deeper understanding of
the relationship between neural activity and behavior.

</details>


### [197] [Integrating Asynchronous AdaBoost into Federated Learning: Five Real World Applications](https://arxiv.org/abs/2506.09090)
*Arthur Oghlukyan,Nuria Gomez Blas*

Main category: cs.LG

TL;DR: 本文提出了一种增强的异步AdaBoost框架，用于联邦学习，通过自适应通信调度和延迟权重补偿减少同步频率和通信开销，同时在五个领域验证了其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决联邦学习中同步频率高和通信开销大的问题，同时提升模型精度和效率。

Method: 采用自适应通信调度和延迟权重补偿技术，减少同步频率和通信开销。

Result: 训练时间减少20-35%，通信开销降低30-40%，收敛所需轮次显著减少。

Conclusion: 增强的AdaBoost框架在多种联邦学习场景中表现出高效性和鲁棒性，具有广泛适用性。

Abstract: This paper presents a comprehensive analysis of an enhanced asynchronous
AdaBoost framework for federated learning (FL), focusing on its application
across five distinct domains: computer vision on edge devices, blockchain-based
model transparency, on-device mobile personalization, IoT anomaly detection,
and federated healthcare diagnostics. The proposed algorithm incorporates
adaptive communication scheduling and delayed weight compensation to reduce
synchronization frequency and communication overhead while preserving or
improving model accuracy. We examine how these innovations improve
communication efficiency, scalability, convergence, and robustness in each
domain. Comparative metrics including training time, communication overhead,
convergence iterations, and classification accuracy are evaluated using data
and estimates derived from Oghlukyan's enhanced AdaBoost framework. Empirical
results show, for example, training time reductions on the order of 20-35% and
communication overhead reductions of 30-40% compared to baseline AdaBoost, with
convergence achieved in significantly fewer boosting rounds. Tables and charts
summarize these improvements by domain. Mathematical formulations of the
adaptive scheduling rule and error-driven synchronization thresholds are
provided. Overall, the enhanced AdaBoost exhibits markedly improved efficiency
and robustness across diverse FL scenarios, suggesting broad applicability of
the approach.

</details>


### [198] [Variational Inference Optimized Using the Curved Geometry of Coupled Free Energy](https://arxiv.org/abs/2506.09091)
*Kenric Nelson,Igor Oliveira,Amenah Al-Najafi,Fode Zhang,Hon Keung Tony Ng*

Main category: cs.LG

TL;DR: 提出了一种基于耦合自由能的变分推断优化框架，扩展了变分推断技术以处理耦合指数族的曲率几何。


<details>
  <summary>Details</summary>
Motivation: 传统变分推断在处理重尾分布（如广义帕累托和学生t分布）时存在局限性，需要更鲁棒的方法。

Method: 利用耦合自由能（等同于倒概率的耦合证据下界）改进模型精度和鲁棒性，并应用于耦合变分自编码器（CVAE）的设计。

Result: 在CelebA图像重建任务中，CVAE比VAE在5个训练周期后性能提升3%。

Conclusion: 该方法通过耦合概率采样重尾潜在分布，减少了异常值，提高了模型训练效果。

Abstract: We introduce an optimization framework for variational inference based on the
coupled free energy, extending variational inference techniques to account for
the curved geometry of the coupled exponential family. This family includes
important heavy-tailed distributions such as the generalized Pareto and the
Student's t. By leveraging the coupled free energy, which is equal to the
coupled evidence lower bound (ELBO) of the inverted probabilities, we improve
the accuracy and robustness of the learned model. The coupled generalization of
Fisher Information metric and the affine connection. The method is applied to
the design of a coupled variational autoencoder (CVAE). By using the coupling
for both the distributions and cost functions, the reconstruction metric is
derived to still be the mean-square average loss with modified constants. The
novelty comes from sampling the heavy-tailed latent distribution with its
associated coupled probability, which has faster decaying tails. The result is
the ability to train a model with high penalties in the tails, while assuring
that the training samples have a reduced number of outliers. The Wasserstein-2
or Fr\'echet Inception Distance of the reconstructed CelebA images shows the
CVAE has a 3\% improvement over the VAE after 5 epochs of training.

</details>


### [199] [CUDA-LLM: LLMs Can Write Efficient CUDA Kernels](https://arxiv.org/abs/2506.09092)
*Wentao Chen,Jiace Zhu,Qi Fan,Yehan Ma,An Zou*

Main category: cs.LG

TL;DR: 论文提出了一种名为FSR的框架，结合LLMs自动生成和优化高性能CUDA程序，显著提升GPU内核的执行效率。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在通用代码生成上表现优异，但在生成硬件特定、架构感知和高性能的GPU代码方面仍面临挑战。

Method: 提出FSR框架，联合优化编译、功能正确性和运行时性能，通过实际GPU执行延迟验证。

Result: FSR增强的LLMs生成的内核在正确率上表现稳定，执行速度最高可达人工编写代码的179倍。

Conclusion: 结合LLMs和性能强化技术，有望自动化生成硬件特定、架构敏感的高性能GPU代码。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in
general-purpose code generation. However, generating the code which is deeply
hardware-specific, architecture-aware, and performance-critical, especially for
massively parallel GPUs, remains a complex challenge. In this work, we explore
the use of LLMs for the automated generation and optimization of CUDA programs,
with the goal of producing high-performance GPU kernels that fully exploit the
underlying hardware. To address this challenge, we propose a novel framework
called \textbf{Feature Search and Reinforcement (FSR)}. FSR jointly optimizes
compilation and functional correctness, as well as the runtime performance,
which are validated through extensive and diverse test cases, and measured by
actual kernel execution latency on the target GPU, respectively. This approach
enables LLMs not only to generate syntactically and semantically correct CUDA
code but also to iteratively refine it for efficiency, tailored to the
characteristics of the GPU architecture. We evaluate FSR on representative CUDA
kernels, covering AI workloads and computational intensive algorithms. Our
results show that LLMs augmented with FSR consistently guarantee correctness
rates. Meanwhile, the automatically generated kernels can outperform general
human-written code by a factor of up to 179$\times$ in execution speeds. These
findings highlight the potential of combining LLMs with performance
reinforcement to automate GPU programming for hardware-specific,
architecture-sensitive, and performance-critical applications.

</details>


### [200] [Merging Smarter, Generalizing Better: Enhancing Model Merging on OOD Data](https://arxiv.org/abs/2506.09093)
*Bingjie Zhang,Hongkang Li,Changlong Shi,Guowei Rong,He Zhao,Dongsheng Wang,Dandan Guo,Meng Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为LwPTV的方法，通过构建显著性分数来修剪任务向量中的冗余参数，从而提升多任务学习在域外数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多任务学习模型合并方法主要关注域内数据集性能，而忽略了域外数据集的有效性。

Method: 提出LwPTV方法，通过显著性分数测量任务向量中参数的冗余性，进行分层修剪，保留预训练模型参数。

Result: 实验表明，该方法显著提升了域外任务性能，同时保持了域内任务的能力。

Conclusion: LwPTV方法灵活且高效，可与现有模型合并方法结合，提升多任务学习的泛化能力。

Abstract: Multi-task learning (MTL) concurrently trains a model on diverse task
datasets to exploit common features, thereby improving overall performance
across the tasks. Recent studies have dedicated efforts to merging multiple
independent model parameters into a unified model for MTL, thus circumventing
the need for training data and expanding the scope of applicable scenarios of
MTL. However, current approaches to model merging predominantly concentrate on
enhancing performance within in-domain (ID) datasets, often overlooking their
efficacy on out-of-domain (OOD) datasets. In this work, we proposed LwPTV
(Layer-wise Pruning Task Vector) by building a saliency score, measuring the
redundancy of parameters in task vectors. Designed in this way ours can achieve
mask vector for each task and thus perform layer-wise pruning on the task
vectors, only keeping the pre-trained model parameters at the corresponding
layer in merged model. Owing to its flexibility, our method can be seamlessly
integrated with most of existing model merging methods to improve their
performance on OOD tasks. Extensive experiments demonstrate that the
application of our method results in substantial enhancements in OOD
performance while preserving the ability on ID tasks.

</details>


### [201] [Intra-Trajectory Consistency for Reward Modeling](https://arxiv.org/abs/2506.09096)
*Chaoyang Zhou,Shunyu Liu,Zengmao Wang,Di Wang,Rong-Cheng Tu,Bo Du,Dacheng Tao*

Main category: cs.LG

TL;DR: 论文提出了一种利用生成概率增强奖励模型的方法，通过响应轨迹中的过程一致性提升奖励学习的细粒度信号。


<details>
  <summary>Details</summary>
Motivation: 当前奖励模型依赖粗粒度的响应级评分，难以识别与评分真正相关的响应轨迹部分，导致泛化能力差。

Method: 利用生成概率建立响应轨迹中过程间的奖励一致性，提出基于贝叶斯框架的轨迹内一致性正则化方法。

Result: 改进的奖励模型在RewardBench上表现更优，并提升了DPO对齐策略和BON推理验证效果。

Conclusion: 通过细粒度的奖励一致性正则化，显著提升了奖励模型的性能和泛化能力。

Abstract: Reward models are critical for improving large language models (LLMs),
particularly in reinforcement learning from human feedback (RLHF) or
inference-time verification. Current reward modeling typically relies on scores
of overall responses to learn the outcome rewards for the responses. However,
since the response-level scores are coarse-grained supervision signals, the
reward model struggles to identify the specific components within a response
trajectory that truly correlate with the scores, leading to poor generalization
on unseen responses. In this paper, we propose to leverage generation
probabilities to establish reward consistency between processes in the response
trajectory, which allows the response-level supervisory signal to propagate
across processes, thereby providing additional fine-grained signals for reward
learning. Building on analysis under the Bayesian framework, we develop an
intra-trajectory consistency regularization to enforce that adjacent processes
with higher next-token generation probability maintain more consistent rewards.
We apply the proposed regularization to the advanced outcome reward model,
improving its performance on RewardBench. Besides, we show that the reward
model trained with the proposed regularization induces better DPO-aligned
policies and achieves better best-of-N (BON) inference-time verification
results. Our code is provided in https://github.com/chaoyang101/ICRM.

</details>


### [202] [Too Big to Think: Capacity, Memorization, and Generalization in Pre-Trained Transformers](https://arxiv.org/abs/2506.09099)
*Joshua Barron,Devin White*

Main category: cs.LG

TL;DR: 研究探讨了大语言模型中记忆与泛化的关系，发现模型容量与学习模式之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 探索记忆与泛化在大型语言模型中的关系，揭示模型容量对学习行为的影响。

Method: 通过预训练容量受限的Transformer模型，设计字符级任务分别测试泛化和记忆能力。

Result: 小模型泛化能力强但记忆能力弱，大模型反之；中间容量模型偏向记忆；联合训练时所有模型均无法泛化。

Conclusion: 预训练可能固有地偏向某种学习模式，研究为小语言模型的设计提供了启示。

Abstract: The relationship between memorization and generalization in large language
models (LLMs) remains an open area of research, with growing evidence that the
two are deeply intertwined. In this work, we investigate this relationship by
pre-training a series of capacity-limited Transformer models from scratch on
two synthetic character-level tasks designed to separately probe generalization
(via arithmetic extrapolation) and memorization (via factual recall). We
observe a consistent trade-off: small models extrapolate to unseen arithmetic
cases but fail to memorize facts, while larger models memorize but fail to
extrapolate. An intermediate-capacity model exhibits a similar shift toward
memorization. When trained on both tasks jointly, no model (regardless of size)
succeeds at extrapolation. These findings suggest that pre-training may
intrinsically favor one learning mode over the other. By isolating these
dynamics in a controlled setting, our study offers insight into how model
capacity shapes learning behavior and offers broader implications for the
design and deployment of small language models.

</details>


### [203] [An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks](https://arxiv.org/abs/2410.16222)
*Valentyn Boreiko,Alexander Panfilov,Vaclav Voracek,Matthias Hein,Jonas Geiping*

Main category: cs.LG

TL;DR: 本文提出了一种统一的威胁模型，用于系统比较针对安全调整的大型语言模型（LLM）的越狱攻击方法。通过构建一个基于1T令牌的N-gram语言模型，该方法实现了与LLM无关、非参数化且可解释的评估。研究发现，离散优化攻击显著优于基于LLM的攻击，且攻击成功率低于此前报告。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击方法在流畅性和计算成本上差异显著，缺乏统一的评估标准，因此需要一种可解释且客观的威胁模型来比较这些方法。

Method: 构建一个基于1T令牌的N-gram语言模型，用于评估攻击方法的分布可能性。适配多种流行攻击方法，并在统一威胁模型下进行基准测试。

Result: 攻击成功率低于此前报告，离散优化攻击表现优于基于LLM的攻击。有效攻击利用了罕见或不常见的二元组。

Conclusion: 提出的威胁模型为越狱攻击提供了可解释且客观的比较框架，揭示了攻击方法的实际效果和局限性。

Abstract: A plethora of jailbreaking attacks have been proposed to obtain harmful
responses from safety-tuned LLMs. These methods largely succeed in coercing the
target output in their original settings, but their attacks vary substantially
in fluency and computational effort. In this work, we propose a unified threat
model for the principled comparison of these methods. Our threat model checks
if a given jailbreak is likely to occur in the distribution of text. For this,
we build an N-gram language model on 1T tokens, which, unlike model-based
perplexity, allows for an LLM-agnostic, nonparametric, and inherently
interpretable evaluation. We adapt popular attacks to this threat model, and,
for the first time, benchmark these attacks on equal footing with it. After an
extensive comparison, we find attack success rates against safety-tuned modern
models to be lower than previously presented and that attacks based on discrete
optimization significantly outperform recent LLM-based attacks. Being
inherently interpretable, our threat model allows for a comprehensive analysis
and comparison of jailbreak attacks. We find that effective attacks exploit and
abuse infrequent bigrams, either selecting the ones absent from real-world text
or rare ones, e.g., specific to Reddit or code datasets.

</details>


### [204] [Feature Shift Localization Network](https://arxiv.org/abs/2506.09101)
*Míriam Barrabés,Daniel Mas Montserrat,Kapal Dev,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: FSL-Net是一种神经网络，用于快速准确地定位高维数据集中的特征偏移，无需重新训练即可处理新数据集。


<details>
  <summary>Details</summary>
Motivation: 特征偏移在医疗、金融等多领域数据中普遍存在，现有方法难以准确且高效地定位偏移特征。

Method: 提出FSL-Net，通过训练学习数据集的统计特性，定位未见数据集中的特征偏移。

Result: FSL-Net能高效处理大规模高维数据，且无需重新训练即可适应新数据集。

Conclusion: FSL-Net为解决特征偏移定位问题提供了一种快速、准确的解决方案。

Abstract: Feature shifts between data sources are present in many applications
involving healthcare, biomedical, socioeconomic, financial, survey, and
multi-sensor data, among others, where unharmonized heterogeneous data sources,
noisy data measurements, or inconsistent processing and standardization
pipelines can lead to erroneous features. Localizing shifted features is
important to address the underlying cause of the shift and correct or filter
the data to avoid degrading downstream analysis. While many techniques can
detect distribution shifts, localizing the features originating them is still
challenging, with current solutions being either inaccurate or not scalable to
large and high-dimensional datasets. In this work, we introduce the Feature
Shift Localization Network (FSL-Net), a neural network that can localize
feature shifts in large and high-dimensional datasets in a fast and accurate
manner. The network, trained with a large number of datasets, learns to extract
the statistical properties of the datasets and can localize feature shifts from
previously unseen datasets and shifts without the need for re-training. The
code and ready-to-use trained model are available at
https://github.com/AI-sandbox/FSL-Net.

</details>


### [205] [Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs](https://arxiv.org/abs/2506.09104)
*Jung Hyun Lee,Seungjae Shin,Vinnam Kim,Jaeseong You,An Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为UPQ的渐进量化框架，用于将指令调优的大语言模型（LLM）从FP16逐步量化到INT2，首次实现了无需专有数据的INT2量化。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型在资源受限设备上的部署挑战日益突出，极低位量化（如2位）成为研究热点。然而，现有方法仅限于预训练模型，未扩展到指令调优模型。

Method: UPQ框架结合了块级后训练量化（PTQ）和基于蒸馏的量化感知训练（Distill-QAT），通过FP16→INT4→INT2的渐进量化过程减少误差，并使用广义Jensen-Shannon散度（JSD）优化一致性。

Result: UPQ首次实现了开源指令调优LLM的INT2量化，并在MMLU和IFEval基准测试中取得最优性能。

Conclusion: UPQ为指令调优LLM的极低位量化提供了有效解决方案，填补了研究空白，并在实际应用中表现出色。

Abstract: As the rapid scaling of large language models (LLMs) poses significant
challenges for deployment on resource-constrained devices, there is growing
interest in extremely low-bit quantization, such as 2-bit. Although prior works
have shown that 2-bit large models are pareto-optimal over their 4-bit smaller
counterparts in both accuracy and latency, these advancements have been limited
to pre-trained LLMs and have not yet been extended to instruction-tuned models.
To bridge this gap, we propose Unified Progressive Quantization (UPQ)$-$a novel
progressive quantization framework (FP16$\rightarrow$INT4$\rightarrow$INT2)
that unifies block-wise post-training quantization (PTQ) with
distillation-based quantization-aware training (Distill-QAT) for INT2
instruction-tuned LLM quantization. UPQ first quantizes FP16 instruction-tuned
models to INT4 using block-wise PTQ to significantly reduce the quantization
error introduced by subsequent INT2 quantization. Next, UPQ applies Distill-QAT
to enable INT2 instruction-tuned LLMs to generate responses consistent with
their original FP16 counterparts by minimizing the generalized Jensen-Shannon
divergence (JSD) between the two. To the best of our knowledge, we are the
first to demonstrate that UPQ can quantize open-source instruction-tuned LLMs
to INT2 without relying on proprietary post-training data, while achieving
state-of-the-art performances on MMLU and IFEval$-$two of the most
representative benchmarks for evaluating instruction-tuned LLMs.

</details>


### [206] [MetaTT: A Global Tensor-Train Adapter for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2506.09105)
*Javier Lopez-Piqueres,Pranav Deshpande,Archan Ray,Mattia J. Villani,Marco Pistoia,Niraj Kumar*

Main category: cs.LG

TL;DR: MetaTT是一个统一的Tensor Train适配器框架，用于预训练Transformer的全局低秩微调。相比LoRA，MetaTT通过共享TT分解所有子模块，显著减少参数，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LoRA独立微调权重矩阵导致参数冗余的问题，提供更高效的全局低秩微调方法。

Method: 使用Tensor Train（TT）分解所有Transformer子模块（如query、key、value等），并通过索引结构轴（如层和矩阵类型）实现参数共享。

Result: 在标准语言建模基准测试中，MetaTT显著减少参数，同时保持与LoRA相似的准确性，甚至优于其他基于张量的方法。

Conclusion: MetaTT提供了一种高效、灵活的微调方法，适用于多任务共享适配器，且无需重新设计核心张量。

Abstract: We present MetaTT, a unified Tensor Train (TT) adapter framework for global
low-rank fine-tuning of pre-trained transformers. Unlike LoRA, which fine-tunes
each weight matrix independently, MetaTT uses a single shared TT to factorize
all transformer sub-modules -- query, key, value, projection, and feed-forward
layers -- by indexing the structural axes like layer and matrix type, and
optionally heads and tasks. For a given rank, while LoRA adds parameters
proportional to the product across modes, MetaTT only adds parameters
proportional to the sum across modes leading to a significantly compressed
final adapter. Our benchmarks compare MetaTT with LoRA along with recent
state-of-the-art matrix and tensor decomposition based fine-tuning schemes. We
observe that when tested on standard language modeling benchmarks, MetaTT leads
to the most reduction in the parameters while maintaining similar accuracy to
LoRA and even outperforming other tensor-based methods. Unlike CP or other
rank-factorizations, the TT ansatz benefits from mature optimization routines
-- e.g., DMRG-style rank adaptive minimization in addition to Adam, which we
find simplifies training. Because new modes can be appended cheaply, MetaTT
naturally extends to shared adapters across many tasks without redesigning the
core tensor.

</details>


### [207] [SensorLM: Learning the Language of Wearable Sensors](https://arxiv.org/abs/2506.09108)
*Yuwei Zhang,Kumar Ayush,Siyuan Qiao,A. Ali Heydari,Girish Narayanswamy,Maxwell A. Xu,Ahmed A. Metwally,Shawn Xu,Jake Garrison,Xuhai Xu,Tim Althoff,Yun Liu,Pushmeet Kohli,Jiening Zhan,Mark Malhotra,Shwetak Patel,Cecilia Mascolo,Xin Liu,Daniel McDuff,Yuzhe Yang*

Main category: cs.LG

TL;DR: SensorLM是一种传感器-语言基础模型，通过自然语言理解可穿戴传感器数据，解决了传感器数据与语言对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏配对的、注释丰富的传感器-文本数据，传感器数据的对齐和解释仍然困难。

Method: 采用分层标题生成流程，从传感器数据中提取统计、结构和语义信息，并扩展多模态预训练架构。

Result: 构建了最大的传感器-语言数据集（59.7百万小时数据），在零样本识别、少样本学习和跨模态检索中表现优异。

Conclusion: SensorLM在传感器数据理解和任务泛化方面展现出强大能力。

Abstract: We present SensorLM, a family of sensor-language foundation models that
enable wearable sensor data understanding with natural language. Despite its
pervasive nature, aligning and interpreting sensor data with language remains
challenging due to the lack of paired, richly annotated sensor-text
descriptions in uncurated, real-world wearable data. We introduce a
hierarchical caption generation pipeline designed to capture statistical,
structural, and semantic information from sensor data. This approach enabled
the curation of the largest sensor-language dataset to date, comprising over
59.7 million hours of data from more than 103,000 people. Furthermore, SensorLM
extends prominent multimodal pretraining architectures (e.g., CLIP, CoCa) and
recovers them as specific variants within a generic architecture. Extensive
experiments on real-world tasks in human activity analysis and healthcare
verify the superior performance of SensorLM over state-of-the-art in zero-shot
recognition, few-shot learning, and cross-modal retrieval. SensorLM also
demonstrates intriguing capabilities including scaling behaviors, label
efficiency, sensor captioning, and zero-shot generalization to unseen tasks.

</details>


### [208] [CodeBrain: Bridging Decoupled Tokenizer and Multi-Scale Architecture for EEG Foundation Model](https://arxiv.org/abs/2506.09110)
*Jingying Ma,Feng Wu,Qika Lin,Yucheng Xing,Chenyu Liu,Ziyu Jia,Mengling Feng*

Main category: cs.LG

TL;DR: CodeBrain是一种高效的脑电图基础模型，通过两阶段训练解决传统模型在泛化性和多尺度依赖捕捉上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统脑电图模型因通道配置、序列长度和任务目标的差异而泛化性差，现有基础模型在异质表示能力和多尺度依赖捕捉上效率不足。

Method: 1. 提出TFDual-Tokenizer，独立标记时间和频率成分以扩展表示空间；2. 设计EEGSSM模型，结合全局卷积和滑动窗口注意力机制捕捉多尺度依赖。

Result: 在10个公开脑电图数据集上验证了CodeBrain的泛化能力。

Conclusion: CodeBrain为未来神经科学研究提供了生物启发且可解释的建模基础，代码和预训练权重将公开。

Abstract: Electroencephalography (EEG) provides real-time insights into brain activity
and is widely used in neuroscience. However, variations in channel
configurations, sequence lengths, and task objectives limit the transferability
of traditional task-specific models. Although recent EEG foundation models
(EFMs) aim to learn generalizable representations, they struggle with limited
heterogeneous representation capacity and inefficiency in capturing multi-scale
brain dependencies. To address these challenges, we propose CodeBrain, an
efficient EFM structurally aligned with brain organization, trained in two
stages. (1) We introduce a TFDual-Tokenizer that independently tokenizes
heterogeneous temporal and frequency components, enabling a quadratic expansion
of the discrete representation space. This also offers a degree of
interpretability through cross-domain token analysis. (2) We propose the
EEGSSM, which combines a structured global convolution architecture and a
sliding window attention mechanism to jointly model sparse long-range and local
dependencies. Unlike fully connected Transformer models, EEGSSM better reflects
the brain's small-world topology and efficiently captures EEG's inherent
multi-scale structure. EEGSSM is trained with a masked self-supervised learning
objective to predict token indices obtained in TFDual-Tokenizer. Comprehensive
experiments on 10 public EEG datasets demonstrate the generalizability of
CodeBrain with linear probing. By offering biologically informed and
interpretable EEG modeling, CodeBrain lays the foundation for future
neuroscience research. Both code and pretraining weights will be released in
the future version.

</details>


### [209] [TRACE: Grounding Time Series in Context for Multimodal Embedding and Retrieval](https://arxiv.org/abs/2506.09114)
*Jialin Chen,Ziyu Zhao,Gaukhar Nurbek,Aosong Feng,Ali Maatouk,Leandros Tassiulas,Yifeng Gao,Rex Ying*

Main category: cs.LG

TL;DR: TRACE是一种多模态检索器，通过将时间序列嵌入与对齐的文本上下文结合，实现细粒度通道级对齐和语义检索，提升下游任务的预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 动态数据（如天气、医疗和能源领域）的普遍性需要有效的时间序列数据解释和检索方法。现有方法缺乏语义基础，难以对齐异构模态，且处理多通道信号能力有限。

Method: 提出TRACE，一种通用多模态检索器，通过硬负样本挖掘实现细粒度通道级对齐，支持文本到时间序列和时间序列到文本的跨模态检索。

Result: TRACE在下游预测和分类任务中达到最先进性能，同时作为通用检索器增强时间序列模型。

Conclusion: TRACE不仅是一个强大的独立编码器，还能通过检索语义相关对提升下游模型的上下文信息，具有广泛的应用潜力。

Abstract: The ubiquity of dynamic data in domains such as weather, healthcare, and
energy underscores a growing need for effective interpretation and retrieval of
time-series data. These data are inherently tied to domain-specific contexts,
such as clinical notes or weather narratives, making cross-modal retrieval
essential not only for downstream tasks but also for developing robust
time-series foundation models by retrieval-augmented generation (RAG). Despite
the increasing demand, time-series retrieval remains largely underexplored.
Existing methods often lack semantic grounding, struggle to align heterogeneous
modalities, and have limited capacity for handling multi-channel signals. To
address this gap, we propose TRACE, a generic multimodal retriever that grounds
time-series embeddings in aligned textual context. TRACE enables fine-grained
channel-level alignment and employs hard negative mining to facilitate
semantically meaningful retrieval. It supports flexible cross-modal retrieval
modes, including Text-to-Timeseries and Timeseries-to-Text, effectively linking
linguistic descriptions with complex temporal patterns. By retrieving
semantically relevant pairs, TRACE enriches downstream models with informative
context, leading to improved predictive accuracy and interpretability. Beyond a
static retrieval engine, TRACE also serves as a powerful standalone encoder,
with lightweight task-specific tuning that refines context-aware
representations while maintaining strong cross-modal alignment. These
representations achieve state-of-the-art performance on downstream forecasting
and classification tasks. Extensive experiments across multiple domains
highlight its dual utility, as both an effective encoder for downstream
applications and a general-purpose retriever to enhance time-series models.

</details>


### [210] [Scalable Spatiotemporal Inference with Biased Scan Attention Transformer Neural Processes](https://arxiv.org/abs/2506.09163)
*Daniel Jenson,Jhonathan Navott,Piotr Grynfelder,Mengyan Zhang,Makkunda Sharma,Elizaveta Semenova,Seth Flaxman*

Main category: cs.LG

TL;DR: BSA-TNP是一种新型神经过程架构，通过引入KRBlocks和BSA，在保持高精度的同时显著提升模型的可扩展性，适用于多分辨率学习和时空建模。


<details>
  <summary>Details</summary>
Motivation: 现代神经过程模型在复杂应用中面临精度与可扩展性的权衡问题，尤其是在处理平移不变过程时。

Method: 提出BSA-TNP架构，结合KRBlocks、群不变注意力偏置和高效的BSA机制。

Result: BSA-TNP在精度上优于或匹配最佳模型，训练时间大幅缩短，支持多分辨率学习和时空建模，并能在单GPU上高效处理大规模数据。

Conclusion: BSA-TNP证明了在平移不变过程中无需牺牲精度即可实现可扩展性，为复杂应用提供了高效解决方案。

Abstract: Neural Processes (NPs) are a rapidly evolving class of models designed to
directly model the posterior predictive distribution of stochastic processes.
While early architectures were developed primarily as a scalable alternative to
Gaussian Processes (GPs), modern NPs tackle far more complex and data hungry
applications spanning geology, epidemiology, climate, and robotics. These
applications have placed increasing pressure on the scalability of these
models, with many architectures compromising accuracy for scalability. In this
paper, we demonstrate that this tradeoff is often unnecessary, particularly
when modeling fully or partially translation invariant processes. We propose a
versatile new architecture, the Biased Scan Attention Transformer Neural
Process (BSA-TNP), which introduces Kernel Regression Blocks (KRBlocks),
group-invariant attention biases, and memory-efficient Biased Scan Attention
(BSA). BSA-TNP is able to: (1) match or exceed the accuracy of the best models
while often training in a fraction of the time, (2) exhibit translation
invariance, enabling learning at multiple resolutions simultaneously, (3)
transparently model processes that evolve in both space and time, (4) support
high dimensional fixed effects, and (5) scale gracefully -- running inference
with over 1M test points with 100K context points in under a minute on a single
24GB GPU.

</details>


### [211] [Improving LLM Agent Planning with In-Context Learning via Atomic Fact Augmentation and Lookahead Search](https://arxiv.org/abs/2506.09171)
*Samuel Holt,Max Ruiz Luyten,Thomas Pouplin,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 论文提出了一种新型LLM代理框架，通过上下文学习增强规划能力，利用原子事实增强和递归前瞻搜索，无需微调即可优化决策。


<details>
  <summary>Details</summary>
Motivation: 现有方法在适应新信息或高效利用历史经验进行多步推理时存在不足，需要改进。

Method: 引入原子事实增强和递归前瞻搜索，动态提取任务关键信息并模拟潜在轨迹以优化决策。

Result: 代理在交互任务中表现出更好的性能和适应性，如TextFrozenLake和ALFWorld任务。

Conclusion: 该框架通过经验积累优化行为，无需权重更新，展示了LLM在复杂环境中的潜力。

Abstract: Large Language Models (LLMs) are increasingly capable but often require
significant guidance or extensive interaction history to perform effectively in
complex, interactive environments. Existing methods may struggle with adapting
to new information or efficiently utilizing past experiences for multi-step
reasoning without fine-tuning. We introduce a novel LLM agent framework that
enhances planning capabilities through in-context learning, facilitated by
atomic fact augmentation and a recursive lookahead search. Our agent learns to
extract task-critical ``atomic facts'' from its interaction trajectories. These
facts dynamically augment the prompts provided to LLM-based components
responsible for action proposal, latent world model simulation, and state-value
estimation. Planning is performed via a depth-limited lookahead search, where
the LLM simulates potential trajectories and evaluates their outcomes, guided
by the accumulated facts and interaction history. This approach allows the
agent to improve its understanding and decision-making online, leveraging its
experience to refine its behavior without weight updates. We provide a
theoretical motivation linking performance to the quality of fact-based
abstraction and LLM simulation accuracy. Empirically, our agent demonstrates
improved performance and adaptability on challenging interactive tasks,
achieving more optimal behavior as it accumulates experience, showcased in
tasks such as TextFrozenLake and ALFWorld.

</details>


### [212] [MultiNet: An Open-Source Software Toolkit \& Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models](https://arxiv.org/abs/2506.09172)
*Pranav Guruprasad,Yangyue Wang,Harshvardhan Sikka*

Main category: cs.LG

TL;DR: MultiNet是一个开源的多模态动作模型基准测试和软件生态系统，用于评估和适应视觉、语言和动作领域的模型。


<details>
  <summary>Details</summary>
Motivation: 开发通用智能代理系统需要结合视觉理解、语言理解和动作生成，但目前缺乏统一的评估标准。

Method: 提出MultiNet，包括标准化评估协议、开源软件工具和包含1.3万亿标记的复合数据集。

Result: MultiNet已用于下游研究，揭示了视觉-语言-动作模型的泛化局限性。

Conclusion: MultiNet为多模态动作模型的研究提供了全面的评估工具和数据支持。

Abstract: Recent innovations in multimodal action models represent a promising
direction for developing general-purpose agentic systems, combining visual
understanding, language comprehension, and action generation. We introduce
MultiNet - a novel, fully open-source benchmark and surrounding software
ecosystem designed to rigorously evaluate and adapt models across vision,
language, and action domains. We establish standardized evaluation protocols
for assessing vision-language models (VLMs) and vision-language-action models
(VLAs), and provide open source software to download relevant data, models, and
evaluations. Additionally, we provide a composite dataset with over 1.3
trillion tokens of image captioning, visual question answering, commonsense
reasoning, robotic control, digital game-play, simulated
locomotion/manipulation, and many more tasks. The MultiNet benchmark,
framework, toolkit, and evaluation harness have been used in downstream
research on the limitations of VLA generalization.

</details>


### [213] [The Curious Language Model: Strategic Test-Time Information Acquisition](https://arxiv.org/abs/2506.09173)
*Michael Cooper,Rohan Wadhawan,John Michael Giorgi,Chenhao Tan,Davis Liang*

Main category: cs.LG

TL;DR: CuriosiTree是一种基于启发式的零样本信息获取策略，通过贪心树搜索平衡信息增益与成本，优化决策。


<details>
  <summary>Details</summary>
Motivation: 决策者在信息不足时需高效获取信息，但不同信息获取方式的成本差异大，需选择既有效又经济的方法。

Method: 提出CuriosiTree，利用贪心树搜索估计每项行动的预期信息增益，并基于信息增益与成本的平衡选择行动。

Result: 在临床诊断模拟中，CuriosiTree能有效整合异构信息源，优于基线策略，实现准确诊断。

Conclusion: CuriosiTree为信息获取提供了一种高效且经济的解决方案，适用于复杂决策场景。

Abstract: Decision-makers often possess insufficient information to render a confident
decision. In these cases, the decision-maker can often undertake actions to
acquire the necessary information about the problem at hand, e.g., by
consulting knowledgeable authorities or by conducting experiments. Importantly,
different levers of information acquisition come with different costs, posing
the challenge of selecting the actions that are both informative and
cost-effective. In this work, we propose CuriosiTree, a heuristic-based,
test-time policy for zero-shot information acquisition in large language models
(LLMs). CuriosiTree employs a greedy tree search to estimate the expected
information gain of each action and strategically chooses actions based on a
balance of anticipated information gain and associated cost. Empirical
validation in a clinical diagnosis simulation shows that CuriosiTree enables
cost-effective integration of heterogenous sources of information, and
outperforms baseline action selection strategies in selecting action sequences
that enable accurate diagnosis.

</details>


### [214] [Multivariate Long-term Time Series Forecasting with Fourier Neural Filter](https://arxiv.org/abs/2506.09174)
*Chenheng Xu,Dan Wu,Yixin Zhu,Ying Nian Wu*

Main category: cs.LG

TL;DR: 论文提出FNF和DBD架构，用于解决多变量长期时间序列预测中时空依赖性问题，无需辅助技术即可实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多借用自然语言处理或计算机视觉的通用架构，未能充分处理时间序列的独特性质（如周期性），缺乏专用的时空建模骨干网络。

Method: 引入FNF作为骨干网络，统一局部时域和全局频域信息处理；DBD架构提供更优的梯度流和表示能力。

Result: 在11个公共基准数据集上验证了最优性能，且无需辅助技术。

Conclusion: 设计合理的神经网络架构可捕捉时间序列的固有特性，有望推动科学和工业应用中的时间序列建模。

Abstract: Multivariate long-term time series forecasting has been suffering from the
challenge of capturing both temporal dependencies within variables and spatial
correlations across variables simultaneously. Current approaches predominantly
repurpose backbones from natural language processing or computer vision (e.g.,
Transformers), which fail to adequately address the unique properties of time
series (e.g., periodicity). The research community lacks a dedicated backbone
with temporal-specific inductive biases, instead relying on domain-agnostic
backbones supplemented with auxiliary techniques (e.g., signal decomposition).
We introduce FNF as the backbone and DBD as the architecture to provide
excellent learning capabilities and optimal learning pathways for
spatio-temporal modeling, respectively. Our theoretical analysis proves that
FNF unifies local time-domain and global frequency-domain information
processing within a single backbone that extends naturally to spatial modeling,
while information bottleneck theory demonstrates that DBD provides superior
gradient flow and representation capacity compared to existing unified or
sequential architectures. Our empirical evaluation across 11 public benchmark
datasets spanning five domains (energy, meteorology, transportation,
environment, and nature) confirms state-of-the-art performance with consistent
hyperparameter settings. Notably, our approach achieves these results without
any auxiliary techniques, suggesting that properly designed neural
architectures can capture the inherent properties of time series, potentially
transforming time series modeling in scientific and industrial applications.

</details>


### [215] [Multi-Task Reward Learning from Human Ratings](https://arxiv.org/abs/2506.09183)
*Mingkang Wu,Devin White,Evelyn Rose,Vernon Lawhern,Nicholas R Waytowich,Yongcan Cao*

Main category: cs.LG

TL;DR: 提出一种新的强化学习方法，通过联合考虑多任务来模拟人类决策，优于现有基于评分的RL方法。


<details>
  <summary>Details</summary>
Motivation: 当前RLHF方法将人类决策简化为孤立任务（如分类或回归），但人类决策是多策略的，因此需要更贴近人类决策的方法。

Method: 利用无奖励环境中的人类评分推断奖励函数，引入可学习权重平衡分类和回归模型的贡献，捕捉人类决策的不确定性。

Result: 实验表明，该方法优于现有基于评分的RL方法，有时甚至超越传统RL方法。

Conclusion: 该方法通过模拟人类多策略决策，显著提升了RLHF的性能。

Abstract: Reinforcement learning from human feeback (RLHF) has become a key factor in
aligning model behavior with users' goals. However, while humans integrate
multiple strategies when making decisions, current RLHF approaches often
simplify this process by modeling human reasoning through isolated tasks such
as classification or regression. In this paper, we propose a novel
reinforcement learning (RL) method that mimics human decision-making by jointly
considering multiple tasks. Specifically, we leverage human ratings in
reward-free environments to infer a reward function, introducing learnable
weights that balance the contributions of both classification and regression
models. This design captures the inherent uncertainty in human decision-making
and allows the model to adaptively emphasize different strategies. We conduct
several experiments using synthetic human ratings to validate the effectiveness
of the proposed approach. Results show that our method consistently outperforms
existing rating-based RL methods, and in some cases, even surpasses traditional
RL approaches.

</details>


### [216] [LaDCast: A Latent Diffusion Model for Medium-Range Ensemble Weather Forecasting](https://arxiv.org/abs/2506.09193)
*Yilin Zhuang,Karthik Duraisamy*

Main category: cs.LG

TL;DR: LaDCast是一个全球潜在扩散框架，用于中程集合预报，通过潜在空间生成小时级集合预报，性能接近欧洲中期天气预报中心（IFS-ENS），且在极端事件跟踪上表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统数值天气预报（NWP）和机器学习方法在高精度和高效不确定性量化方面存在挑战，需要一种更高效的解决方案。

Method: 使用自动编码器压缩高维ERA5再分析数据，结合基于Transformer的扩散模型生成潜在更新，并引入GeoRoPE、双流注意力机制和正弦时间嵌入。

Result: LaDCast在确定性和概率性技能上接近IFS-ENS，且在极端事件（如气旋）跟踪上表现更优，同时大幅降低计算和存储需求。

Conclusion: LaDCast展示了在潜在空间进行实时公里级分辨率预报的可行性，为未来天气预报提供了高效路径。

Abstract: Accurate probabilistic weather forecasting demands both high accuracy and
efficient uncertainty quantification, challenges that overburden both ensemble
numerical weather prediction (NWP) and recent machine-learning methods. We
introduce LaDCast, the first global latent-diffusion framework for medium-range
ensemble forecasting, which generates hourly ensemble forecasts entirely in a
learned latent space. An autoencoder compresses high-dimensional ERA5
reanalysis fields into a compact representation, and a transformer-based
diffusion model produces sequential latent updates with arbitrary hour
initialization. The model incorporates Geometric Rotary Position Embedding
(GeoRoPE) to account for the Earth's spherical geometry, a dual-stream
attention mechanism for efficient conditioning, and sinusoidal temporal
embeddings to capture seasonal patterns. LaDCast achieves deterministic and
probabilistic skill close to that of the European Centre for Medium-Range
Forecast IFS-ENS, without any explicit perturbations. Notably, LaDCast
demonstrates superior performance in tracking rare extreme events such as
cyclones, capturing their trajectories more accurately than established models.
By operating in latent space, LaDCast reduces storage and compute by orders of
magnitude, demonstrating a practical path toward forecasting at kilometer-scale
resolution in real time. We open-source our code and models and provide the
training and evaluation pipelines at: https://github.com/tonyzyl/ladcast.

</details>


### [217] [FLoRIST: Singular Value Thresholding for Efficient and Accurate Federated Fine-Tuning of Large Language Models](https://arxiv.org/abs/2506.09199)
*Hariharan Ramesh,Jyotikrishna Dass*

Main category: cs.LG

TL;DR: FLoRIST框架通过高效分解本地适配器，解决了联邦学习中LoRA方法的通信效率和计算成本问题，同时保持模型准确性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦LoRA方法在通信效率、模型准确性和计算成本之间存在平衡问题，尤其是在异构客户端环境中。

Method: FLoRIST采用奇异值分解本地适配器，在紧凑中间空间中表示信息，并通过可调阈值选择最优全局低秩适配器。

Result: FLoRIST在多种数据集和LLMs上表现出优越的通信效率和竞争性性能。

Conclusion: FLoRIST在异构和同构环境中均实现了通信效率和性能的最佳平衡。

Abstract: Integrating Low-Rank Adaptation (LoRA) into federated learning offers a
promising solution for parameter-efficient fine-tuning of Large Language Models
(LLMs) without sharing local data. However, several methods designed for
federated LoRA present significant challenges in balancing communication
efficiency, model accuracy, and computational cost, particularly among
heterogeneous clients. These methods either rely on simplistic averaging of
local adapters, which introduces aggregation noise, require transmitting large
stacked local adapters, leading to poor communication efficiency, or
necessitate reconstructing memory-dense global weight-update matrix and
performing computationally expensive decomposition to design client-specific
low-rank adapters. In this work, we propose FLoRIST, a federated fine-tuning
framework that achieves mathematically accurate aggregation without incurring
high communication or computational overhead. Instead of constructing the full
global weight-update matrix at the server, FLoRIST employs an efficient
decomposition pipeline by performing singular value decomposition on stacked
local adapters separately. This approach operates within a compact intermediate
space to represent the accumulated information from local LoRAs. We introduce
tunable singular value thresholding for server-side optimal rank selection to
construct a pair of global low-rank adapters shared by all clients. Extensive
empirical evaluations across multiple datasets and LLMs demonstrate that
FLoRIST consistently strikes the best balance between superior communication
efficiency and competitive performance in both homogeneous and heterogeneous
setups.

</details>


### [218] [FedRAG: A Framework for Fine-Tuning Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2506.09200)
*Val Andrei Fajardo,David B. Emerson,Amandeep Singh,Veronica Chatrath,Marcelo Lotif,Ravi Theja,Alex Cheung,Izuki Matsubi*

Main category: cs.LG

TL;DR: FedRAG是一个框架，用于在集中式和联邦式架构中微调RAG系统，填补了现有工具的空白。


<details>
  <summary>Details</summary>
Motivation: 解决仅依赖大型语言模型参数化记忆的缺点，并通过微调检索器和生成器模型提升RAG系统性能。

Method: 引入FedRAG框架，支持最先进的微调方法，提供简单接口和从集中式到联邦式任务的转换。

Result: FedRAG填补了现代RAG生态系统的关键工具空白。

Conclusion: FedRAG为RAG系统的微调提供了高效且灵活的解决方案。

Abstract: Retrieval-augmented generation (RAG) systems have been shown to be effective
in addressing many of the drawbacks of relying solely on the parametric memory
of large language models. Recent work has demonstrated that RAG systems can be
improved via fine-tuning of their retriever and generator models. In this work,
we introduce FedRAG, a framework for fine-tuning RAG systems across centralized
and federated architectures. FedRAG supports state-of-the-art fine-tuning
methods, offering a simple and intuitive interface and a seamless conversion
from centralized to federated training tasks. FedRAG is also deeply integrated
with the modern RAG ecosystem, filling a critical gap in available tools.

</details>


### [219] [Policy-Based Trajectory Clustering in Offline Reinforcement Learning](https://arxiv.org/abs/2506.09202)
*Hao Hu,Xinqi Wang,Simon Shaolei Du*

Main category: cs.LG

TL;DR: 提出了一种基于离线强化学习数据集的轨迹聚类新任务，通过KL散度和策略诱导分布的关系设计目标，并提出了PG-Kmeans和CAAE两种方法。


<details>
  <summary>Details</summary>
Motivation: 解决离线强化学习中轨迹聚类的需求，通过聚类中心表示生成轨迹的策略。

Method: 提出PG-Kmeans（迭代训练行为克隆策略并分配轨迹）和CAAE（通过引导潜在表示实现聚类）。

Result: 在D4RL数据集和GridWorld环境中验证了方法的有效性，成功将轨迹划分为有意义的聚类。

Conclusion: PG-Kmeans和CAAE为基于策略的轨迹聚类提供了有前景的框架，适用于离线强化学习等广泛领域。

Abstract: We introduce a novel task of clustering trajectories from offline
reinforcement learning (RL) datasets, where each cluster center represents the
policy that generated its trajectories. By leveraging the connection between
the KL-divergence of offline trajectory distributions and a mixture of
policy-induced distributions, we formulate a natural clustering objective. To
solve this, we propose Policy-Guided K-means (PG-Kmeans) and Centroid-Attracted
Autoencoder (CAAE). PG-Kmeans iteratively trains behavior cloning (BC) policies
and assigns trajectories based on policy generation probabilities, while CAAE
resembles the VQ-VAE framework by guiding the latent representations of
trajectories toward the vicinity of specific codebook entries to achieve
clustering. Theoretically, we prove the finite-step convergence of PG-Kmeans
and identify a key challenge in offline trajectory clustering: the inherent
ambiguity of optimal solutions due to policy-induced conflicts, which can
result in multiple equally valid but structurally distinct clusterings.
Experimentally, we validate our methods on the widely used D4RL dataset and
custom GridWorld environments. Our results show that both PG-Kmeans and CAAE
effectively partition trajectories into meaningful clusters. They offer a
promising framework for policy-based trajectory clustering, with broad
applications in offline RL and beyond.

</details>


### [220] [mLaSDI: Multi-stage latent space dynamics identification](https://arxiv.org/abs/2506.09207)
*William Anderson,Kevin Chung,Youngsoo Choi*

Main category: cs.LG

TL;DR: 论文提出了一种改进的降阶模型方法mLaSDI，通过多阶段训练自编码器来提升对复杂或高频数据的重建和预测能力。


<details>
  <summary>Details</summary>
Motivation: 传统LaSDI方法在复杂或高频数据下难以同时满足数据重建和潜空间动力学要求，因此需要改进。

Method: mLaSDI通过分阶段训练多个自编码器，每个阶段修正前一阶段的误差，从而提升性能。

Result: mLaSDI使用小型自编码器时，预测和重建误差更低，同时训练时间更短。

Conclusion: mLaSDI在提升降阶模型性能方面具有潜力，特别是在复杂或高频数据场景下。

Abstract: Determining accurate numerical solutions of partial differential equations
(PDEs) is an important task in many scientific disciplines. However, solvers
can be computationally expensive, leading to the development of reduced-order
models (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was
proposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the
training data using an autoencoder and learns a system of user-chosen ordinary
differential equations (ODEs), which govern the latent space dynamics. This
allows for rapid predictions by interpolating and evolving the low-dimensional
ODEs in the latent space. While LaSDI has produced effective ROMs for numerous
problems, the autoencoder can have difficulty accurately reconstructing
training data while also satisfying the imposed dynamics in the latent space,
particularly in complex or high-frequency regimes. To address this, we propose
multi-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, several
autoencoders are trained sequentially in stages, where each autoencoder learns
to correct the error of the previous stages. We find that applying mLaSDI with
small autoencoders results in lower prediction and reconstruction errors, while
also reducing training time compared to LaSDI.

</details>


### [221] [Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs](https://arxiv.org/abs/2506.09215)
*Greyson Brothers*

Main category: cs.LG

TL;DR: 论文研究了用于汇总Transformer嵌入模型输出的池化方法设计，提出了一种基于注意力的自适应池化方法，优于传统方法（如AvgPool、MaxPool、ClsToken），在信号噪声比波动时表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于强化学习和视觉应用中，输入向量中部分为有用信号、部分为噪声的问题，传统池化方法在信号噪声比波动时性能下降。

Method: 提出了一种基于注意力的自适应池化方法，通过向量量化最小化信号损失，理论上证明了其在任何信号噪声比下能逼近信号最优向量量化器。

Result: 在合成数据集和标准基准测试（如关系推理、多智能体强化学习、视觉任务）中验证了方法的有效性，自适应池化Transformer表现出更强的鲁棒性。

Conclusion: 结论表明，自适应池化方法在信号噪声比波动时优于传统池化方法，具有更广泛的适用性和鲁棒性。

Abstract: We investigate the design of pooling methods used to summarize the outputs of
transformer embedding models, primarily motivated by reinforcement learning and
vision applications. This work considers problems where a subset of the input
vectors contains requisite information for a downstream task (signal) while the
rest are distractors (noise). By framing pooling as vector quantization with
the goal of minimizing signal loss, we demonstrate that the standard methods
used to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are
vulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs
fluctuates. We then show that an attention-based adaptive pooling method can
approximate the signal-optimal vector quantizer within derived error bounds for
any SNR. Our theoretical results are first validated by supervised experiments
on a synthetic dataset designed to isolate the SNR problem, then generalized to
standard relational reasoning, multi-agent reinforcement learning, and vision
benchmarks with noisy observations, where transformers with adaptive pooling
display superior robustness across tasks.

</details>


### [222] [SoK: Machine Unlearning for Large Language Models](https://arxiv.org/abs/2506.09227)
*Jie Ren,Yue Xing,Yingqian Cui,Charu C. Aggarwal,Hui Liu*

Main category: cs.LG

TL;DR: 本文提出了一种基于意图的新分类法，用于分析大语言模型（LLM）的遗忘技术，探讨了真实遗忘的必要性与可行性，评估了现有方法的局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究LLM遗忘技术的根本意图，区分真实遗忘与行为抑制，以填补现有分类法的不足。

Method: 提出基于意图的新分类法，分析现有遗忘技术的功能行为，评估现有评测策略的局限性。

Result: 发现许多遗忘方法可能仅实现行为抑制而非真实遗忘，指出当前评测方法的不足，并提出改进方向。

Conclusion: 为生成式AI中的遗忘技术提供了全面框架，支持未来研究和数据隐私政策制定。

Abstract: Large language model (LLM) unlearning has become a critical topic in machine
learning, aiming to eliminate the influence of specific training data or
knowledge without retraining the model from scratch. A variety of techniques
have been proposed, including Gradient Ascent, model editing, and re-steering
hidden representations. While existing surveys often organize these methods by
their technical characteristics, such classifications tend to overlook a more
fundamental dimension: the underlying intention of unlearning--whether it seeks
to truly remove internal knowledge or merely suppress its behavioral effects.
In this SoK paper, we propose a new taxonomy based on this intention-oriented
perspective. Building on this taxonomy, we make three key contributions. First,
we revisit recent findings suggesting that many removal methods may
functionally behave like suppression, and explore whether true removal is
necessary or achievable. Second, we survey existing evaluation strategies,
identify limitations in current metrics and benchmarks, and suggest directions
for developing more reliable and intention-aligned evaluations. Third, we
highlight practical challenges--such as scalability and support for sequential
unlearning--that currently hinder the broader deployment of unlearning methods.
In summary, this work offers a comprehensive framework for understanding and
advancing unlearning in generative AI, aiming to support future research and
guide policy decisions around data removal and privacy.

</details>


### [223] [Agent-based Condition Monitoring Assistance with Multimodal Industrial Database Retrieval Augmented Generation](https://arxiv.org/abs/2506.09247)
*Karl Löwenmark,Daniel Strömbergsson,Chang Liu,Marcus Liwicki,Fredrik Sandin*

Main category: cs.LG

TL;DR: 论文提出MindRAG框架，结合多模态检索增强生成（RAG）和新型向量存储结构，用于优化工业条件监测（CM）工作流，减少误报并提升决策支持。


<details>
  <summary>Details</summary>
Motivation: 当前CM系统在故障严重性估计和维护决策上依赖人工，存在高误报率和不确定性，导致效率低下。

Method: 提出MindRAG框架，整合多模态RAG技术和定制化向量存储，利用现有标注和维护工单作为监督学习标签。

Result: 初步实验表明，MindRAG能有效支持决策，提高CM系统的可解释性和效率。

Conclusion: MindRAG为工业CM提供了一种高效、可解释的解决方案，有望减少人工依赖并提升系统性能。

Abstract: Condition monitoring (CM) plays a crucial role in ensuring reliability and
efficiency in the process industry. Although computerised maintenance systems
effectively detect and classify faults, tasks like fault severity estimation,
and maintenance decisions still largely depend on human expert analysis. The
analysis and decision making automatically performed by current systems
typically exhibit considerable uncertainty and high false alarm rates, leading
to increased workload and reduced efficiency.
  This work integrates large language model (LLM)-based reasoning agents with
CM workflows to address analyst and industry needs, namely reducing false
alarms, enhancing fault severity estimation, improving decision support, and
offering explainable interfaces. We propose MindRAG, a modular framework
combining multimodal retrieval-augmented generation (RAG) with novel vector
store structures designed specifically for CM data. The framework leverages
existing annotations and maintenance work orders as surrogates for labels in a
supervised learning protocol, addressing the common challenge of training
predictive models on unlabelled and noisy real-world datasets.
  The primary contributions include: (1) an approach for structuring industry
CM data into a semi-structured multimodal vector store compatible with
LLM-driven workflows; (2) developing multimodal RAG techniques tailored for CM
data; (3) developing practical reasoning agents capable of addressing
real-world CM queries; and (4) presenting an experimental framework for
integrating and evaluating such agents in realistic industrial scenarios.
Preliminary results, evaluated with the help of an experienced analyst,
indicate that MindRAG provide meaningful decision support for more efficient
management of alarms, thereby improving the interpretability of CM systems.

</details>


### [224] [CFMI: Flow Matching for Missing Data Imputation](https://arxiv.org/abs/2506.09258)
*Vaidotas Simkus,Michael U. Gutmann*

Main category: cs.LG

TL;DR: CFMI是一种新的通用缺失数据填补方法，结合连续归一化流和共享条件建模，性能优于传统和现代技术。


<details>
  <summary>Details</summary>
Motivation: 解决传统多重填补方法的计算难题，提供更高效且通用的填补方案。

Method: 结合连续归一化流、流匹配和共享条件建模。

Result: 在24个数据集上表现优于9种传统和现代方法，时间序列填补中计算效率更高。

Conclusion: CFMI是一种高效、通用的填补方法，适用于多种数据类型和维度。

Abstract: We introduce conditional flow matching for imputation (CFMI), a new
general-purpose method to impute missing data. The method combines continuous
normalising flows, flow-matching, and shared conditional modelling to deal with
intractabilities of traditional multiple imputation. Our comparison with nine
classical and state-of-the-art imputation methods on 24 small to
moderate-dimensional tabular data sets shows that CFMI matches or outperforms
both traditional and modern techniques across a wide range of metrics. Applying
the method to zero-shot imputation of time-series data, we find that it matches
the accuracy of a related diffusion-based method while outperforming it in
terms of computational efficiency. Overall, CFMI performs at least as well as
traditional methods on lower-dimensional data while remaining scalable to
high-dimensional settings, matching or exceeding the performance of other deep
learning-based approaches, making it a go-to imputation method for a wide range
of data types and dimensionalities.

</details>


### [225] [Uncertainty Prioritized Experience Replay](https://arxiv.org/abs/2506.09270)
*Rodrigo Carrasco-Davis,Sebastian Lee,Claudia Clopath,Will Dabney*

Main category: cs.LG

TL;DR: 论文提出了一种基于认知不确定性估计的经验回放优先级方法，以减少噪声对价值估计的干扰，并在实验中验证了其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于时序差分误差的经验回放优先级方法容易受到噪声干扰，导致效率下降。

Method: 使用认知不确定性估计来指导经验回放缓冲区的优先级排序，以减少噪声的影响。

Result: 在表格模型和Atari游戏中验证了方法的有效性，优于传统的分位数回归深度Q学习方法。

Conclusion: 认知不确定性优先级回放为强化学习代理提供了一种更高效的样本利用方式。

Abstract: Prioritized experience replay, which improves sample efficiency by selecting
relevant transitions to update parameter estimates, is a crucial component of
contemporary value-based deep reinforcement learning models. Typically,
transitions are prioritized based on their temporal difference error. However,
this approach is prone to favoring noisy transitions, even when the value
estimation closely approximates the target mean. This phenomenon resembles the
noisy TV problem postulated in the exploration literature, in which
exploration-guided agents get stuck by mistaking noise for novelty. To mitigate
the disruptive effects of noise in value estimation, we propose using epistemic
uncertainty estimation to guide the prioritization of transitions from the
replay buffer. Epistemic uncertainty quantifies the uncertainty that can be
reduced by learning, hence reducing transitions sampled from the buffer
generated by unpredictable random processes. We first illustrate the benefits
of epistemic uncertainty prioritized replay in two tabular toy models: a simple
multi-arm bandit task, and a noisy gridworld. Subsequently, we evaluate our
prioritization scheme on the Atari suite, outperforming quantile regression
deep Q-learning benchmarks; thus forging a path for the use of uncertainty
prioritized replay in reinforcement learning agents.

</details>


### [226] [G-Sim: Generative Simulations with Large Language Models and Gradient-Free Calibration](https://arxiv.org/abs/2506.09272)
*Samuel Holt,Max Ruiz Luyten,Antonin Berthon,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: G-Sim是一种混合框架，结合LLM驱动的结构设计和经验校准，用于构建可靠的模拟器。


<details>
  <summary>Details</summary>
Motivation: 现有模拟器方法难以泛化或准确性不足，G-Sim旨在解决这些问题。

Method: G-Sim通过LLM迭代设计模拟器结构，并使用灵活校准技术估计参数。

Result: G-Sim能够处理非可微和随机模拟器，生成因果可靠的模拟器。

Conclusion: G-Sim通过结合领域先验和实证证据，支持复杂决策中的系统级干预。

Abstract: Constructing robust simulators is essential for asking "what if?" questions
and guiding policy in critical domains like healthcare and logistics. However,
existing methods often struggle, either failing to generalize beyond historical
data or, when using Large Language Models (LLMs), suffering from inaccuracies
and poor empirical alignment. We introduce G-Sim, a hybrid framework that
automates simulator construction by synergizing LLM-driven structural design
with rigorous empirical calibration. G-Sim employs an LLM in an iterative loop
to propose and refine a simulator's core components and causal relationships,
guided by domain knowledge. This structure is then grounded in reality by
estimating its parameters using flexible calibration techniques. Specifically,
G-Sim can leverage methods that are both likelihood-free and gradient-free with
respect to the simulator, such as gradient-free optimization for direct
parameter estimation or simulation-based inference for obtaining a posterior
distribution over parameters. This allows it to handle non-differentiable and
stochastic simulators. By integrating domain priors with empirical evidence,
G-Sim produces reliable, causally-informed simulators, mitigating
data-inefficiency and enabling robust system-level interventions for complex
decision-making.

</details>


### [227] [Learning The Minimum Action Distance](https://arxiv.org/abs/2506.09276)
*Lorenzo Steccanella,Joshua B. Evans,Özgür Şimşek,Anders Jonsson*

Main category: cs.LG

TL;DR: 提出一种仅从状态轨迹学习MDP状态表示的框架，无需奖励信号或动作信息，通过最小动作距离（MAD）捕获环境结构。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖奖励或动作信息，限制了应用范围。本文旨在通过自监督学习MAD，提供一种通用的状态表示方法。

Method: 提出学习MAD作为状态间距离度量，构建嵌入空间使嵌入距离对应MAD，支持对称与非对称近似。

Result: 在多种环境中验证了方法的有效性，MAD表示质量显著优于现有方法。

Conclusion: 该方法为无监督状态表示提供了高效且通用的解决方案，适用于多种任务。

Abstract: This paper presents a state representation framework for Markov decision
processes (MDPs) that can be learned solely from state trajectories, requiring
neither reward signals nor the actions executed by the agent. We propose
learning the minimum action distance (MAD), defined as the minimum number of
actions required to transition between states, as a fundamental metric that
captures the underlying structure of an environment. MAD naturally enables
critical downstream tasks such as goal-conditioned reinforcement learning and
reward shaping by providing a dense, geometrically meaningful measure of
progress. Our self-supervised learning approach constructs an embedding space
where the distances between embedded state pairs correspond to their MAD,
accommodating both symmetric and asymmetric approximations. We evaluate the
framework on a comprehensive suite of environments with known MAD values,
encompassing both deterministic and stochastic dynamics, as well as discrete
and continuous state spaces, and environments with noisy observations.
Empirical results demonstrate that the proposed approach not only efficiently
learns accurate MAD representations across these diverse settings but also
significantly outperforms existing state representation methods in terms of
representation quality.

</details>


### [228] [A Topic Modeling Analysis of Stigma Dimensions, Social, and Related Behavioral Circumstances in Clinical Notes Among Patients with HIV](https://arxiv.org/abs/2506.09279)
*Ziyi Chen,Yiyang Liu,Mattia Prosperi,Krishna Vaddiparti,Robert L Cook,Jiang Bian,Yi Guo,Yonghui Wu*

Main category: cs.LG

TL;DR: 该研究利用自然语言处理技术分析电子健康记录，揭示了HIV感染者面临的多种污名化问题和社会行为情况。


<details>
  <summary>Details</summary>
Motivation: 传统问卷方法在评估HIV相关污名化问题时存在局限性，研究旨在通过电子健康记录提供更高效、可扩展的评估方法。

Method: 使用潜在狄利克雷分配（LDA）主题建模方法，结合专家筛选的关键词和雪球策略，分析9,140名HIV感染者的临床记录。

Result: 识别出多种与HIV污名化相关的主题，如心理健康问题、社会支持、医疗资源限制等，并在不同年龄和性别亚组中发现差异。

Conclusion: 通过电子健康记录分析，可高效评估HIV相关污名化问题，为改善患者结局提供新途径。

Abstract: Objective: To characterize stigma dimensions, social, and related behavioral
circumstances in people living with HIV (PLWHs) seeking care, using natural
language processing methods applied to a large collection of electronic health
record (EHR) clinical notes from a large integrated health system in the
southeast United States. Methods: We identified 9,140 cohort of PLWHs from the
UF Health IDR and performed topic modeling analysis using Latent Dirichlet
Allocation (LDA) to uncover stigma dimensions, social, and related behavioral
circumstances. Domain experts created a seed list of HIV-related stigma
keywords, then applied a snowball strategy to iteratively review notes for
additional terms until saturation was reached. To identify more target topics,
we tested three keyword-based filtering strategies. Domain experts manually
reviewed the detected topics using the prevalent terms and key discussion
topics. Word frequency analysis was used to highlight the prevalent terms
associated with each topic. In addition, we conducted topic variation analysis
among subgroups to examine differences across age and sex-specific
demographics. Results and Conclusion: Topic modeling on sentences containing at
least one keyword uncovered a wide range of topic themes associated with
HIV-related stigma, social, and related behaviors circumstances, including
"Mental Health Concern and Stigma", "Social Support and Engagement", "Limited
Healthcare Access and Severe Illness", "Treatment Refusal and Isolation" and so
on. Topic variation analysis across age subgroups revealed differences.
Extracting and understanding the HIV-related stigma dimensions, social, and
related behavioral circumstances from EHR clinical notes enables scalable,
time-efficient assessment, overcoming the limitations of traditional
questionnaires and improving patient outcomes.

</details>


### [229] [Causal Graph Recovery in Neuroimaging through Answer Set Programming](https://arxiv.org/abs/2506.09286)
*Mohammadsajad Abavisani,Kseniya Solovyeva,David Danks,Vince Calhoun,Sergey Plis*

Main category: cs.LG

TL;DR: 论文提出了一种利用约束优化方法（ASP）从时间序列数据中学习因果图结构的方法，解决了因采样频率不匹配导致的信息丢失问题，显著提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据中因果图的学习因采样频率与因果时间尺度不匹配而面临挑战，导致信息丢失和多种可能的因果图。研究旨在解决这一问题。

Method: 采用答案集编程（ASP）作为约束优化方法，结合图论修剪可能的解集，提高了效率和准确性。

Result: 在模拟数据和实际脑结构连接数据上验证了方法的优越性，F1分数平均提升12%，且在精度和召回率上达到最优。

Conclusion: 该方法对不同程度的子采样具有鲁棒性，显著优于传统方法，可作为现有方法的补充提升性能。

Abstract: Learning graphical causal structures from time series data presents
significant challenges, especially when the measurement frequency does not
match the causal timescale of the system. This often leads to a set of equally
possible underlying causal graphs due to information loss from sub-sampling
(i.e., not observing all possible states of the system throughout time). Our
research addresses this challenge by incorporating the effects of sub-sampling
in the derivation of causal graphs, resulting in more accurate and intuitive
outcomes. We use a constraint optimization approach, specifically answer set
programming (ASP), to find the optimal set of answers. ASP not only identifies
the most probable underlying graph, but also provides an equivalence class of
possible graphs for expert selection. In addition, using ASP allows us to
leverage graph theory to further prune the set of possible solutions, yielding
a smaller, more accurate answer set significantly faster than traditional
approaches. We validate our approach on both simulated data and empirical
structural brain connectivity, and demonstrate its superiority over established
methods in these experiments. We further show how our method can be used as a
meta-approach on top of established methods to obtain, on average, 12%
improvement in F1 score. In addition, we achieved state of the art results in
terms of precision and recall of reconstructing causal graph from sub-sampled
time series data. Finally, our method shows robustness to varying degrees of
sub-sampling on realistic simulations, whereas other methods perform worse for
higher rates of sub-sampling.

</details>


### [230] [Efficient Preference-Based Reinforcement Learning: Randomized Exploration Meets Experimental Design](https://arxiv.org/abs/2506.09508)
*Andreas Schlaginhaufen,Reda Ouhamma,Maryam Kamgarpour*

Main category: cs.LG

TL;DR: 论文研究了基于人类反馈的强化学习，提出了一种基于随机探索的元算法，解决了乐观方法的计算难题，并通过批量轨迹对和实验设计优化查询效率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在马尔可夫决策过程中，如何通过轨迹级偏好比较高效学习奖励函数，同时保证理论性能。

Method: 提出了一种基于随机探索的元算法，并引入批量轨迹对和最优实验设计来优化查询效率。

Result: 在温和的强化学习假设下，算法实现了遗憾和最终迭代保证，实验表明其与基于奖励的强化学习性能相当且查询次数少。

Conclusion: 该方法在理论和实践中均表现出色，为基于人类反馈的强化学习提供了高效且可扩展的解决方案。

Abstract: We study reinforcement learning from human feedback in general Markov
decision processes, where agents learn from trajectory-level preference
comparisons. A central challenge in this setting is to design algorithms that
select informative preference queries to identify the underlying reward while
ensuring theoretical guarantees. We propose a meta-algorithm based on
randomized exploration, which avoids the computational challenges associated
with optimistic approaches and remains tractable. We establish both regret and
last-iterate guarantees under mild reinforcement learning oracle assumptions.
To improve query complexity, we introduce and analyze an improved algorithm
that collects batches of trajectory pairs and applies optimal experimental
design to select informative comparison queries. The batch structure also
enables parallelization of preference queries, which is relevant in practical
deployment as feedback can be gathered concurrently. Empirical evaluation
confirms that the proposed method is competitive with reward-based
reinforcement learning while requiring a small number of preference queries.

</details>


### [231] [On-the-Fly Adaptive Distillation of Transformer to Dual-State Linear Attention](https://arxiv.org/abs/2506.09316)
*Yeonju Ro,Zhenyu Zhang,Souvik Kundu,Zhangyang Wang,Aditya Akella*

Main category: cs.LG

TL;DR: 论文提出了一种双状态线性注意力（DSLA）和自适应蒸馏框架（Serve），以平衡长输入下的计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在长输入下计算和内存成本高的问题，同时避免线性注意力对近期令牌过度关注导致的准确性下降。

Method: 提出DSLA，通过维护两个隐藏状态（历史上下文和近期令牌）来缓解线性注意力的短程偏差；引入Serve框架，动态替换Transformer层为DSLA层。

Result: Serve在推理速度上比Llama2-7B快2.3倍，比Zamba-7B快3.0倍，同时保持下游任务性能。

Conclusion: DSLA和Serve有效平衡了效率和准确性，解决了线性注意力中历史令牌代表性不足的问题。

Abstract: Large language models (LLMs) excel at capturing global token dependencies via
self-attention but face prohibitive compute and memory costs on lengthy inputs.
While sub-quadratic methods (e.g., linear attention) can reduce these costs,
they often degrade accuracy due to overemphasizing recent tokens. In this work,
we first propose \textit{dual-state linear attention} (\textbf{\dsla}), a novel
design that maintains two specialized hidden states-one for preserving
historical context and one for tracking recency-thereby mitigating the
short-range bias typical of linear-attention architectures. To further balance
efficiency and accuracy under dynamic workload conditions, we introduce
\textbf{\serve}, an online \textit{adaptive distillation} framework that
progressively replaces Transformer layers with DSLA layers at inference time,
guided by a sensitivity-based layer ordering. \serve\ uses a chained
fine-tuning strategy to ensure that each newly converted DSLA layer remains
consistent with previously replaced layers, preserving the overall quality.
Extensive evaluations on commonsense reasoning, long-context QA, and text
summarization demonstrate that \serve\ yields \textbf{2.3x} faster inference
than Llama2-7B and \textbf{3.0x} faster than the hybrid Zamba-7B, while
retaining comparable performance across downstream tasks. Our ablation studies
show that DSLA's dual states capture both global and local dependencies,
addressing the historical-token underrepresentation seen in prior linear
attentions. Codes are available at https://github.com/utnslab/DSLA-Serve.

</details>


### [232] [Natural Language Guided Ligand-Binding Protein Design](https://arxiv.org/abs/2506.09332)
*Zhenqiao Song,Ramith Hettiarachchi,Chuan Li,Jianwen Xie,Lei Li*

Main category: cs.LG

TL;DR: InstructPro是一种基于自然语言指令设计蛋白质的AI模型，能够根据功能描述和配体公式生成功能一致的蛋白质序列，性能优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 设计能够结合特定配体的蛋白质在生物学和化学应用中至关重要，但现有AI模型依赖稀缺的蛋白质-配体复合物数据。人类整理的文本描述数据更为丰富，因此提出利用自然语言指令指导蛋白质设计。

Method: 提出InstructPro模型家族，包括1B和3B参数版本，基于自然语言指令和配体SMILES公式生成蛋白质序列。开发了大规模数据集InstructProBench（9,592,829条数据）支持训练和评估。

Result: InstructPro-1B和InstructPro-3B均显著优于基线模型（ProGen2、ESM3、Pinal），其中InstructPro-1B的对接成功率达81.52%，平均RMSD为4.026Å；InstructPro-3B进一步将RMSD降至2.527Å。

Conclusion: InstructPro展示了通过自然语言指令设计功能蛋白质的能力，为蛋白质生成任务提供了高效解决方案。

Abstract: Can AI protein models follow human language instructions and design proteins
with desired functions (e.g. binding to a ligand)? Designing proteins that bind
to a given ligand is crucial in a wide range of applications in biology and
chemistry. Most prior AI models are trained on protein-ligand complex data,
which is scarce due to the high cost and time requirements of laboratory
experiments. In contrast, there is a substantial body of human-curated text
descriptions about protein-ligand interactions and ligand formula. In this
paper, we propose InstructPro, a family of protein generative models that
follow natural language instructions to design ligand-binding proteins. Given a
textual description of the desired function and a ligand formula in SMILES,
InstructPro generates protein sequences that are functionally consistent with
the specified instructions. We develop the model architecture, training
strategy, and a large-scale dataset, InstructProBench, to support both training
and evaluation. InstructProBench consists of 9,592,829 triples of (function
description, ligand formula, protein sequence). We train two model variants:
InstructPro-1B (with 1 billion parameters) and InstructPro-3B~(with 3 billion
parameters). Both variants consistently outperform strong baselines, including
ProGen2, ESM3, and Pinal. Notably, InstructPro-1B achieves the highest docking
success rate (81.52% at moderate confidence) and the lowest average root mean
square deviation (RMSD) compared to ground truth structures (4.026{\AA}).
InstructPro-3B further descreases the average RMSD to 2.527{\AA}, demonstrating
InstructPro's ability to generate ligand-binding proteins that align with the
functional specifications.

</details>


### [233] [ErrorEraser: Unlearning Data Bias for Improved Continual Learning](https://arxiv.org/abs/2506.09347)
*Xuemei Cao,Hanlin Gu,Xin Yang,Bingjun Wei,Haoyang Liang,Xiangkun Wang,Tianrui Li*

Main category: cs.LG

TL;DR: 论文提出ErrorEraser，一种解决持续学习中数据偏差问题的通用插件，通过识别和擦除错误记忆提升新旧任务性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习方法通常忽略真实数据中的偏差，导致模型学习虚假相关性，影响知识保留和迁移。

Method: ErrorEraser包含错误识别和错误擦除模块，前者通过特征空间概率密度分布识别偏差样本，后者通过调整决策空间擦除错误知识。

Result: 实验表明ErrorEraser显著减轻数据偏差的负面影响，在三种持续学习方法中实现更高准确率和更低遗忘率。

Conclusion: ErrorEraser通过主动遗忘错误知识，提升了持续学习的性能，为数据偏差问题提供了有效解决方案。

Abstract: Continual Learning (CL) primarily aims to retain knowledge to prevent
catastrophic forgetting and transfer knowledge to facilitate learning new
tasks. Unlike traditional methods, we propose a novel perspective: CL not only
needs to prevent forgetting, but also requires intentional forgetting.This
arises from existing CL methods ignoring biases in real-world data, leading the
model to learn spurious correlations that transfer and amplify across tasks.
From feature extraction and prediction results, we find that data biases
simultaneously reduce CL's ability to retain and transfer knowledge. To address
this, we propose ErrorEraser, a universal plugin that removes erroneous
memories caused by biases in CL, enhancing performance in both new and old
tasks. ErrorEraser consists of two modules: Error Identification and Error
Erasure. The former learns the probability density distribution of task data in
the feature space without prior knowledge, enabling accurate identification of
potentially biased samples. The latter ensures only erroneous knowledge is
erased by shifting the decision space of representative outlier samples.
Additionally, an incremental feature distribution learning strategy is designed
to reduce the resource overhead during error identification in downstream
tasks. Extensive experimental results show that ErrorEraser significantly
mitigates the negative impact of data biases, achieving higher accuracy and
lower forgetting rates across three types of CL methods. The code is available
at https://github.com/diadai/ErrorEraser.

</details>


### [234] [Adversarial Surrogate Risk Bounds for Binary Classification](https://arxiv.org/abs/2506.09348)
*Natalie S. Frank*

Main category: cs.LG

TL;DR: 本文研究了对抗训练中替代风险与分类风险的关系，量化了分类风险的收敛速率，并提出了标准学习环境下的分布相关替代风险界。


<details>
  <summary>Details</summary>
Motivation: 对抗训练是提升分类器鲁棒性的重要方法，但现有研究未能量化替代风险最小化序列对分类风险收敛速率的影响。

Method: 通过理论分析，推导了替代风险界，量化了分类风险的收敛速率，并扩展至标准学习环境。

Result: 提出了对抗训练中替代风险与分类风险收敛速率的量化关系，并提供了标准学习环境下的分布相关风险界。

Conclusion: 本文填补了对抗训练中替代风险与分类风险收敛速率关系的理论空白，为未来研究提供了新视角。

Abstract: A central concern in classification is the vulnerability of machine learning
models to adversarial attacks. Adversarial training is one of the most popular
techniques for training robust classifiers, which involves minimizing an
adversarial surrogate risk. Recent work characterized when a minimizing
sequence of an adversarial surrogate risk is also a minimizing sequence of the
adversarial classification risk for binary classification -- a property known
as adversarial consistency. However, these results do not address the rate at
which the adversarial classification risk converges to its optimal value for
such a sequence of functions that minimize the adversarial surrogate. This
paper provides surrogate risk bounds that quantify that convergence rate.
Additionally, we derive distribution-dependent surrogate risk bounds in the
standard (non-adversarial) learning setting, that may be of independent
interest.

</details>


### [235] [Anomaly Detection and Generation with Diffusion Models: A Survey](https://arxiv.org/abs/2506.09368)
*Yang Liu,Jing Liu,Chengfang Li,Rui Xi,Wenchao Li,Liang Cao,Jin Wang,Laurence T. Yang,Junsong Yuan,Wei Zhou*

Main category: cs.LG

TL;DR: 本文综述了基于扩散模型的异常检测与生成（ADGDM），探讨了其理论基础、实际应用及两者间的协同关系，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 异常检测在多个领域至关重要，但传统方法难以应对复杂数据分布。扩散模型因其强大的数据学习能力，为异常检测提供了新思路。

Method: 通过教程式分析，综述了扩散模型在异常检测与生成中的应用，包括评分机制、条件策略和架构设计。

Result: 揭示了异常检测与生成之间的协同关系，扩散模型能同时提升检测与生成能力。

Conclusion: 扩散模型为异常检测提供了创新解决方案，未来需关注高效架构、条件策略及与基础模型的结合。

Abstract: Anomaly detection (AD) plays a pivotal role across diverse domains, including
cybersecurity, finance, healthcare, and industrial manufacturing, by
identifying unexpected patterns that deviate from established norms in
real-world data. Recent advancements in deep learning, specifically diffusion
models (DMs), have sparked significant interest due to their ability to learn
complex data distributions and generate high-fidelity samples, offering a
robust framework for unsupervised AD. In this survey, we comprehensively review
anomaly detection and generation with diffusion models (ADGDM), presenting a
tutorial-style analysis of the theoretical foundations and practical
implementations and spanning images, videos, time series, tabular, and
multimodal data. Crucially, unlike existing surveys that often treat anomaly
detection and generation as separate problems, we highlight their inherent
synergistic relationship. We reveal how DMs enable a reinforcing cycle where
generation techniques directly address the fundamental challenge of anomaly
data scarcity, while detection methods provide critical feedback to improve
generation fidelity and relevance, advancing both capabilities beyond their
individual potential. A detailed taxonomy categorizes ADGDM methods based on
anomaly scoring mechanisms, conditioning strategies, and architectural designs,
analyzing their strengths and limitations. We final discuss key challenges
including scalability and computational efficiency, and outline promising
future directions such as efficient architectures, conditioning strategies, and
integration with foundation models (e.g., visual-language models and large
language models). By synthesizing recent advances and outlining open research
questions, this survey aims to guide researchers and practitioners in
leveraging DMs for innovative AD solutions across diverse applications.

</details>


### [236] [LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization](https://arxiv.org/abs/2506.09373)
*Jiaqi Tang,Yu Xia,Yi-Feng Wu,Yuwei Hu,Yuhui Chen,Qing-Guo Chen,Xiaogang Xu,Xiangyu Wu,Hao Lu,Yanqing Ma,Shiyin Lu,Qifeng Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为LPO的新方法，通过利用位置数据和信息熵优化GUI交互偏好，显著提升了交互精度。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理在空间定位上主要依赖监督微调方法，但这些方法在感知位置数据时存在局限性，限制了其实际应用。

Method: LPO利用信息熵预测交互位置，并引入基于物理距离的动态位置奖励函数，结合GRPO支持广泛探索GUI环境。

Result: 实验表明LPO在离线和在线评估中均达到SOTA性能。

Conclusion: LPO通过优化位置偏好，显著提升了GUI交互的精确性，具有实际应用潜力。

Abstract: The advent of autonomous agents is transforming interactions with Graphical
User Interfaces (GUIs) by employing natural language as a powerful
intermediary. Despite the predominance of Supervised Fine-Tuning (SFT) methods
in current GUI agents for achieving spatial localization, these methods face
substantial challenges due to their limited capacity to accurately perceive
positional data. Existing strategies, such as reinforcement learning, often
fail to assess positional accuracy effectively, thereby restricting their
utility. In response, we introduce Location Preference Optimization (LPO), a
novel approach that leverages locational data to optimize interaction
preferences. LPO uses information entropy to predict interaction positions by
focusing on zones rich in information. Besides, it further introduces a dynamic
location reward function based on physical distance, reflecting the varying
importance of interaction positions. Supported by Group Relative Preference
Optimization (GRPO), LPO facilitates an extensive exploration of GUI
environments and significantly enhances interaction precision. Comprehensive
experiments demonstrate LPO's superior performance, achieving SOTA results
across both offline benchmarks and real-world online evaluations. Our code will
be made publicly available soon, at https://github.com/AIDC-AI/LPO.

</details>


### [237] [Revisiting Diffusion Models: From Generative Pre-training to One-Step Generation](https://arxiv.org/abs/2506.09376)
*Bowen Zheng,Tianming Yang*

Main category: cs.LG

TL;DR: 扩散蒸馏技术用于降低扩散模型的采样成本，但存在训练时间长和学生模型性能下降的问题。研究发现，GAN目标可以解决这些问题，并提出扩散训练可作为生成预训练，通过轻量级GAN微调实现高效一步生成。


<details>
  <summary>Details</summary>
Motivation: 扩散蒸馏技术虽然广泛使用，但存在训练时间长和学生模型性能下降的问题，需要探索更高效的解决方案。

Method: 通过分析扩散蒸馏的局限性，提出使用独立的GAN目标替代蒸馏损失，并结合预训练模型进行轻量级微调。

Result: 实验表明，该方法仅需0.2M图像即可实现强性能，5M图像时接近SOTA结果。

Conclusion: 扩散训练可作为生成预训练，通过GAN微调实现高效一步生成，为扩散模型的应用提供了新视角。

Abstract: Diffusion distillation is a widely used technique to reduce the sampling cost
of diffusion models, yet it often requires extensive training, and the student
performance tends to be degraded. Recent studies show that incorporating a GAN
objective may alleviate these issues, yet the underlying mechanism remains
unclear. In this work, we first identify a key limitation of distillation:
mismatched step sizes and parameter numbers between the teacher and the student
model lead them to converge to different local minima, rendering direct
imitation suboptimal. We further demonstrate that a standalone GAN objective,
without relying a distillation loss, overcomes this limitation and is
sufficient to convert diffusion models into efficient one-step generators.
Based on this finding, we propose that diffusion training may be viewed as a
form of generative pre-training, equipping models with capabilities that can be
unlocked through lightweight GAN fine-tuning. Supporting this view, we create a
one-step generation model by fine-tuning a pre-trained model with 85% of
parameters frozen, achieving strong performance with only 0.2M images and
near-SOTA results with 5M images. We further present a frequency-domain
analysis that may explain the one-step generative capability gained in
diffusion training. Overall, our work provides a new perspective for diffusion
training, highlighting its role as a powerful generative pre-training process,
which can be the basis for building efficient one-step generation models.

</details>


### [238] [Efficient Prediction of SO(3)-Equivariant Hamiltonian Matrices via SO(2) Local Frames](https://arxiv.org/abs/2506.09398)
*Haiyang Yu,Yuchao Lin,Xuan Zhang,Xiaofeng Qian,Shuiwang Ji*

Main category: cs.LG

TL;DR: 论文提出了一种名为QHNetV2的高效网络，用于预测哈密顿矩阵以加速电子结构计算，通过引入SO(2)局部框架和高效操作，避免了昂贵的SO(3)张量积。


<details>
  <summary>Details</summary>
Motivation: 哈密顿矩阵预测在物理、化学和材料科学中具有重要意义，但传统方法计算成本高。论文旨在通过SO(2)局部框架实现高效且对称性感知的电子结构学习。

Method: 提出QHNetV2网络，利用SO(2)局部框架进行特征更新和信息传递，避免SO(3)张量积，同时引入连续SO(2)张量积操作。

Result: 在QH9和MD17数据集上的实验表明，模型在多种分子结构和轨迹中表现优异，具有强泛化能力。

Conclusion: SO(2)局部框架操作为电子结构学习提供了可扩展且对称性感知的新方向，代码将开源。

Abstract: We consider the task of predicting Hamiltonian matrices to accelerate
electronic structure calculations, which plays an important role in physics,
chemistry, and materials science. Motivated by the inherent relationship
between the off-diagonal blocks of the Hamiltonian matrix and the SO(2) local
frame, we propose a novel and efficient network, called QHNetV2, that achieves
global SO(3) equivariance without the costly SO(3) Clebsch-Gordan tensor
products. This is achieved by introducing a set of new efficient and powerful
SO(2)-equivariant operations and performing all off-diagonal feature updates
and message passing within SO(2) local frames, thereby eliminating the need of
SO(3) tensor products. Moreover, a continuous SO(2) tensor product is performed
within the SO(2) local frame at each node to fuse node features, mimicking the
symmetric contraction operation. Extensive experiments on the large QH9 and
MD17 datasets demonstrate that our model achieves superior performance across a
wide range of molecular structures and trajectories, highlighting its strong
generalization capability. The proposed SO(2) operations on SO(2) local frames
offer a promising direction for scalable and symmetry-aware learning of
electronic structures. Our code will be released as part of the AIRS library
https://github.com/divelab/AIRS.

</details>


### [239] [Synergizing Reinforcement Learning and Genetic Algorithms for Neural Combinatorial Optimization](https://arxiv.org/abs/2506.09404)
*Shengda Gu,Kai Li,Junliang Xing,Yifan Zhang,Jian Cheng*

Main category: cs.LG

TL;DR: 提出了一种结合深度强化学习（DRL）和遗传算法（GA）优势的进化增强机制（EAM），通过生成和优化解决方案提升探索能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 组合优化问题因离散结构和庞大解空间而具有挑战性，现有DRL方法探索能力有限且易陷入局部最优，而GA虽具全局搜索能力但效率低。

Method: EAM框架通过DRL生成解，利用GA的交叉和变异操作优化解，并将优化后的解重新注入策略训练循环。

Result: 在TSP、CVRP等基准问题上，EAM显著提升了解的质量和训练效率。

Conclusion: EAM是一种通用且即插即用的框架，能有效结合DRL和GA的优势，提升组合优化问题的求解性能。

Abstract: Combinatorial optimization problems are notoriously challenging due to their
discrete structure and exponentially large solution space. Recent advances in
deep reinforcement learning (DRL) have enabled the learning heuristics directly
from data. However, DRL methods often suffer from limited exploration and
susceptibility to local optima. On the other hand, evolutionary algorithms such
as Genetic Algorithms (GAs) exhibit strong global exploration capabilities but
are typically sample inefficient and computationally intensive. In this work,
we propose the Evolutionary Augmentation Mechanism (EAM), a general and
plug-and-play framework that synergizes the learning efficiency of DRL with the
global search power of GAs. EAM operates by generating solutions from a learned
policy and refining them through domain-specific genetic operations such as
crossover and mutation. These evolved solutions are then selectively reinjected
into the policy training loop, thereby enhancing exploration and accelerating
convergence. We further provide a theoretical analysis that establishes an
upper bound on the KL divergence between the evolved solution distribution and
the policy distribution, ensuring stable and effective policy updates. EAM is
model-agnostic and can be seamlessly integrated with state-of-the-art DRL
solvers such as the Attention Model, POMO, and SymNCO. Extensive results on
benchmark problems (e.g., TSP, CVRP, PCTSP, and OP) demonstrate that EAM
significantly improves both solution quality and training efficiency over
competitive baselines.

</details>


### [240] [Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training](https://arxiv.org/abs/2506.09433)
*Shurui Gui,Shuiwang Ji*

Main category: cs.LG

TL;DR: 论文提出了一种因果感知的后训练方法（CAPT），通过分解有偏预测为两个无偏步骤，减少LLMs的预训练偏差，提升泛化能力。实验表明，CAPT在小样本下优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在语言建模中表现优异，但在分布外（OOD）样本上常因预训练中的虚假相关性而失败。研究旨在通过CAPT减少这种偏差。

Method: CAPT将有偏预测分解为事件估计和事件干预两个无偏步骤，避免额外微调偏差，提升模型泛化能力。

Result: 在CLadder和PrOntoQA数据集上，3B规模的LLMs使用CAPT仅需100个样本即可在ID和OOD任务上优于传统方法和更大模型。

Conclusion: CAPT有效且样本高效，能显著减少LLMs的预训练偏差并提升泛化性能。

Abstract: While large language models (LLMs) have demonstrated remarkable capabilities
in language modeling, recent studies reveal that they often fail on
out-of-distribution (OOD) samples due to spurious correlations acquired during
pre-training. Here, we aim to mitigate such spurious correlations through
causality-aware post-training (CAPT). By decomposing a biased prediction into
two unbiased steps, known as \textit{event estimation} and \textit{event
intervention}, we reduce LLMs' pre-training biases without incurring additional
fine-tuning biases, thus enhancing the model's generalization ability.
Experiments on the formal causal inference benchmark CLadder and the logical
reasoning dataset PrOntoQA show that 3B-scale language models fine-tuned with
CAPT can outperform both traditional SFT and larger LLMs on in-distribution
(ID) and OOD tasks using only 100 ID fine-tuning samples, demonstrating the
effectiveness and sample efficiency of CAPT.

</details>


### [241] [Generalization Error Analysis for Attack-Free and Byzantine-Resilient Decentralized Learning with Data Heterogeneity](https://arxiv.org/abs/2506.09438)
*Haoxiang Ye,Tao Sun,Qing Ling*

Main category: cs.LG

TL;DR: 本文研究了去中心化学习中的泛化误差，分析了数据异质性、模型初始化和随机梯度噪声等因素的影响，并揭示了拜占庭攻击对泛化误差的负面影响。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习的优化误差已被广泛研究，但其泛化误差尚未深入探讨，而泛化误差对模型在现实应用中的性能至关重要。

Method: 提出了针对攻击自由和拜占鲁容错的去中心化学习的细粒度泛化误差分析，考虑了数据异质性和温和假设。

Result: 研究发现数据异质性、模型初始化和随机梯度噪声对泛化误差有显著影响，拜占庭攻击的负面影响与数据异质性相关。

Conclusion: 通过数值实验验证了理论发现，为去中心化学习的泛化误差提供了新的见解。

Abstract: Decentralized learning, which facilitates joint model training across
geographically scattered agents, has gained significant attention in the field
of signal and information processing in recent years. While the optimization
errors of decentralized learning algorithms have been extensively studied,
their generalization errors remain relatively under-explored. As the
generalization errors reflect the scalability of trained models on unseen data
and are crucial in determining the performance of trained models in real-world
applications, understanding the generalization errors of decentralized learning
is of paramount importance. In this paper, we present fine-grained
generalization error analysis for both attack-free and Byzantine-resilient
decentralized learning with heterogeneous data as well as under mild
assumptions, in contrast to prior studies that consider homogeneous data and/or
rely on a stringent bounded stochastic gradient assumption. Our results shed
light on the impact of data heterogeneity, model initialization and stochastic
gradient noise -- factors that have not been closely investigated before -- on
the generalization error of decentralized learning. We also reveal that
Byzantine attacks performed by malicious agents largely affect the
generalization error, and their negative impact is inherently linked to the
data heterogeneity while remaining independent on the sample size. Numerical
experiments on both convex and non-convex tasks are conducted to validate our
theoretical findings.

</details>


### [242] [Safe Screening Rules for Group SLOPE](https://arxiv.org/abs/2506.09451)
*Runxue Bao,Quanchao Lu,Yanfu Zhang*

Main category: cs.LG

TL;DR: 提出了一种针对Group SLOPE模型的安全筛选规则，通过识别无效组提升计算效率和内存使用。


<details>
  <summary>Details</summary>
Motivation: 高维稀疏学习中存在组结构时，Group SLOPE的块不可分性导致现有方法无效或低效，计算和内存成本高。

Method: 引入安全筛选规则，识别无效组并排除，适用于批量和随机算法。

Result: 实验证明方法能有效检测无效组，显著提升效率且不损失精度。

Conclusion: 提出的筛选规则安全高效，可无缝集成现有优化算法。

Abstract: Variable selection is a challenging problem in high-dimensional sparse
learning, especially when group structures exist. Group SLOPE performs well for
the adaptive selection of groups of predictors. However, the block
non-separable group effects in Group SLOPE make existing methods either invalid
or inefficient. Consequently, Group SLOPE tends to incur significant
computational costs and memory usage in practical high-dimensional scenarios.
To overcome this issue, we introduce a safe screening rule tailored for the
Group SLOPE model, which efficiently identifies inactive groups with zero
coefficients by addressing the block non-separable group effects. By excluding
these inactive groups during training, we achieve considerable gains in
computational efficiency and memory usage. Importantly, the proposed screening
rule can be seamlessly integrated into existing solvers for both batch and
stochastic algorithms. Theoretically, we establish that our screening rule can
be safely employed with existing optimization algorithms, ensuring the same
results as the original approaches. Experimental results confirm that our
method effectively detects inactive feature groups and significantly boosts
computational efficiency without compromising accuracy.

</details>


### [243] [Learning Obfuscations Of LLM Embedding Sequences: Stained Glass Transform](https://arxiv.org/abs/2506.09452)
*Jay Roberts,Kyle Mylonakis,Sidhartha Roy,Kaan Kale*

Main category: cs.LG

TL;DR: 论文提出了一种名为Stained Glass Transform的方法，通过随机变换LLM的词嵌入来保护输入数据的隐私，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI计算基础设施的高成本和LLM服务的挑战导致企业对共享或多租户部署的依赖，但数据隐私问题限制了敏感数据的使用。

Method: 提出Stained Glass Transform，一种学习到的、随机的、序列依赖的词嵌入变换，理论上通过高斯混合模型的互信息提供隐私保护。

Result: 通过互信息计算后验隐私估计，并通过隐私指标和标准LLM性能基准验证了方法的隐私性和实用性。

Conclusion: Stained Glass Transform在保护输入隐私的同时，有效维持了LLM的实用性。

Abstract: The high cost of ownership of AI compute infrastructure and challenges of
robust serving of large language models (LLMs) has led to a surge in managed
Model-as-a-service deployments. Even when enterprises choose on-premises
deployments, the compute infrastructure is typically shared across many teams
in order to maximize the return on investment. In both scenarios the deployed
models operate only on plaintext data, and so enterprise data owners must allow
their data to appear in plaintext on a shared or multi-tenant compute
infrastructure. This results in data owners with private or sensitive data
being hesitant or restricted in what data they use with these types of
deployments. In this work we introduce the Stained Glass Transform, a learned,
stochastic, and sequence dependent transformation of the word embeddings of an
LLM which information theoretically provides privacy to the input of the LLM
while preserving the utility of model. We theoretically connect a particular
class of Stained Glass Transforms to the theory of mutual information of
Gaussian Mixture Models. We then calculate a-postiori privacy estimates, based
on mutual information, and verify the privacy and utility of instances of
transformed embeddings through token level metrics of privacy and standard LLM
performance benchmarks.

</details>


### [244] [NDCG-Consistent Softmax Approximation with Accelerated Convergence](https://arxiv.org/abs/2506.09454)
*Yuanhao Pu,Defu Lian,Xiaolong Chen,Xu Huang,Jin Chen,Enhong Chen*

Main category: cs.LG

TL;DR: 论文提出了两种新的损失函数（RG²和RG×），通过泰勒展开Softmax损失函数，解决了大规模对象空间中的计算和扩展性问题，并结合ALS优化方法，在保持排名性能的同时显著加速收敛。


<details>
  <summary>Details</summary>
Motivation: Softmax损失在大规模对象空间中存在计算开销和扩展性限制，需要更高效的替代方案。

Method: 通过泰勒展开Softmax损失函数，提出RG²和RG×损失函数，并结合ALS优化方法。

Result: 实验表明，新方法在排名性能上与Softmax损失相当或更优，同时显著加速收敛。

Conclusion: 该框架为相似性学习提供了理论见解和高效工具，适用于需要平衡排名质量和计算效率的任务。

Abstract: Ranking tasks constitute fundamental components of extreme similarity
learning frameworks, where extremely large corpora of objects are modeled
through relative similarity relationships adhering to predefined ordinal
structures. Among various ranking surrogates, Softmax (SM) Loss has been widely
adopted due to its natural capability to handle listwise ranking via global
negative comparisons, along with its flexibility across diverse application
scenarios. However, despite its effectiveness, SM Loss often suffers from
significant computational overhead and scalability limitations when applied to
large-scale object spaces. To address this challenge, we propose novel loss
formulations that align directly with ranking metrics: the
Ranking-Generalizable \textbf{squared} (RG$^2$) Loss and the
Ranking-Generalizable interactive (RG$^\times$) Loss, both derived through
Taylor expansions of the SM Loss. Notably, RG$^2$ reveals the intrinsic
mechanisms underlying weighted squared losses (WSL) in ranking methods and
uncovers fundamental connections between sampling-based and non-sampling-based
loss paradigms. Furthermore, we integrate the proposed RG losses with the
highly efficient Alternating Least Squares (ALS) optimization method, providing
both generalization guarantees and convergence rate analyses. Empirical
evaluations on real-world datasets demonstrate that our approach achieves
comparable or superior ranking performance relative to SM Loss, while
significantly accelerating convergence. This framework offers the similarity
learning community both theoretical insights and practically efficient tools,
with methodologies applicable to a broad range of tasks where balancing ranking
quality and computational efficiency is essential.

</details>


### [245] [On a few pitfalls in KL divergence gradient estimation for RL](https://arxiv.org/abs/2506.09477)
*Yunhao Tang,Rémi Munos*

Main category: cs.LG

TL;DR: 论文指出了在LLM强化学习中KL散度梯度估计的几个常见错误，并展示了正确实现方法。


<details>
  <summary>Details</summary>
Motivation: 发现开源项目和论文中KL散度梯度估计的错误实现，影响了RL训练的效果。

Method: 分析错误实现，通过表格和LLM实验展示问题，并提出正确实现方法。

Result: 错误实现无法得到正确的KL梯度，而正确方法解决了这一问题。

Conclusion: 正确实现KL梯度估计对RL训练至关重要。

Abstract: We point out a few pitfalls in implementing gradient estimation for KL
divergence in RL training for LLM, as seen in a number of open source projects
and papers. The first major pitfall is to differentiate through the KL estimate
as loss functions to minimize KL divergence. We show that such implementations
are generally incorrect and do not produce the desired KL gradient. Secondly,
we show that some implementations do not account for the sequential nature of
the estimation problem and produce a partial gradient at best. We demonstrate
the impact of such issues with illustrative tabular and LLM experiments, and
show the correct way to implement the KL gradient.

</details>


### [246] [EnerBridge-DPO: Energy-Guided Protein Inverse Folding with Markov Bridges and Direct Preference Optimization](https://arxiv.org/abs/2506.09496)
*Dingyi Rong,Haotian Lu,Wenzhuo Zheng,Fan Zhang,Shuangjia Zheng,Ning Liu*

Main category: cs.LG

TL;DR: EnerBridge-DPO是一种新型蛋白质逆折叠框架，通过结合Markov Bridges和Direct Preference Optimization（DPO），直接生成低能量、高稳定性的蛋白质序列。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法主要关注序列恢复率，而忽略了生成序列的能量稳定性，EnerBridge-DPO旨在解决这一问题。

Method: 整合Markov Bridges与DPO，引入能量约束损失，利用先验序列优化模型，直接预测序列能量值。

Result: EnerBridge-DPO设计的蛋白质序列能量更低，同时保持与先进模型相当的序列恢复率，并能准确预测ΔΔG值。

Conclusion: EnerBridge-DPO在蛋白质逆折叠中实现了能量稳定性和序列恢复率的平衡，为蛋白质设计提供了新思路。

Abstract: Designing protein sequences with optimal energetic stability is a key
challenge in protein inverse folding, as current deep learning methods are
primarily trained by maximizing sequence recovery rates, often neglecting the
energy of the generated sequences. This work aims to overcome this limitation
by developing a model that directly generates low-energy, stable protein
sequences. We propose EnerBridge-DPO, a novel inverse folding framework focused
on generating low-energy, high-stability protein sequences. Our core innovation
lies in: First, integrating Markov Bridges with Direct Preference Optimization
(DPO), where energy-based preferences are used to fine-tune the Markov Bridge
model. The Markov Bridge initiates optimization from an information-rich prior
sequence, providing DPO with a pool of structurally plausible sequence
candidates. Second, an explicit energy constraint loss is introduced, which
enhances the energy-driven nature of DPO based on prior sequences, enabling the
model to effectively learn energy representations from a wealth of prior
knowledge and directly predict sequence energy values, thereby capturing
quantitative features of the energy landscape. Our evaluations demonstrate that
EnerBridge-DPO can design protein complex sequences with lower energy while
maintaining sequence recovery rates comparable to state-of-the-art models, and
accurately predicts $\Delta \Delta G$ values between various sequences.

</details>


### [247] [A Unified Theory of Compositionality, Modularity, and Interpretability in Markov Decision Processes](https://arxiv.org/abs/2506.09499)
*Thomas J. Ringstrom,Paul R. Schrater*

Main category: cs.LG

TL;DR: OKBEs提出了一种新的无奖励MDP方法，通过状态-时间选项核（STOK）直接优化预测映射，支持可组合、模块化和可解释的长时规划。


<details>
  <summary>Details</summary>
Motivation: 传统基于价值函数的方法在组合性、模块化和可解释性方面存在不足，OKBEs旨在解决这些问题，支持可验证的长时规划和内在动机。

Method: 通过构造和优化STOK，利用Chapman-Kolmogorov方程组合预测，分解高维STOK为可重构形式，并记录语义事件概率。

Result: OKBEs实现了高效的高维规划，支持快速元策略合成、跨任务规划表示重用，并通过内在动机验证目标。

Conclusion: OKBEs为高维动态世界模型提供了可组合、模块化和可解释的规划方法，优于传统奖励最大化方法。

Abstract: We introduce Option Kernel Bellman Equations (OKBEs) for a new reward-free
Markov Decision Process. Rather than a value function, OKBEs directly construct
and optimize a predictive map called a state-time option kernel (STOK) to
maximize the probability of completing a goal while avoiding constraint
violations. STOKs are compositional, modular, and interpretable
initiation-to-termination transition kernels for policies in the Options
Framework of Reinforcement Learning. This means: 1) STOKs can be composed using
Chapman-Kolmogorov equations to make spatiotemporal predictions for multiple
policies over long horizons, 2) high-dimensional STOKs can be represented and
computed efficiently in a factorized and reconfigurable form, and 3) STOKs
record the probabilities of semantically interpretable goal-success and
constraint-violation events, needed for formal verification. Given a
high-dimensional state-transition model for an intractable planning problem, we
can decompose it with local STOKs and goal-conditioned policies that are
aggregated into a factorized goal kernel, making it possible to forward-plan at
the level of goals in high-dimensions to solve the problem. These properties
lead to highly flexible agents that can rapidly synthesize meta-policies, reuse
planning representations across many tasks, and justify goals using
empowerment, an intrinsic motivation function. We argue that
reward-maximization is in conflict with the properties of compositionality,
modularity, and interpretability. Alternatively, OKBEs facilitate these
properties to support verifiable long-horizon planning and intrinsic motivation
that scales to dynamic high-dimensional world-models.

</details>


### [248] [Neural Functions for Learning Periodic Signal](https://arxiv.org/abs/2506.09526)
*Woojin Cho,Minju Jo,Kookjin Lee,Noseong Park*

Main category: cs.LG

TL;DR: 论文提出了一种新型网络架构，用于提取周期性信号模式，提升模型的泛化能力和外推性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于坐标的多层感知机（MLP）在学习连续神经表示时存在过拟合和外推性能差的问题，尤其是在处理周期性信号时。

Method: 提出了一种新型网络架构，能够从测量数据中提取周期性模式，并利用这些信息表示信号。

Result: 通过实验验证了方法的有效性，包括学习微分方程的周期解、时间序列插补和预测。

Conclusion: 该方法显著提升了周期性信号的学习和外推性能。

Abstract: As function approximators, deep neural networks have served as an effective
tool to represent various signal types. Recent approaches utilize multi-layer
perceptrons (MLPs) to learn a nonlinear mapping from a coordinate to its
corresponding signal, facilitating the learning of continuous neural
representations from discrete data points. Despite notable successes in
learning diverse signal types, coordinate-based MLPs often face issues of
overfitting and limited generalizability beyond the training region, resulting
in subpar extrapolation performance. This study addresses scenarios where the
underlying true signals exhibit periodic properties, either spatially or
temporally. We propose a novel network architecture, which extracts periodic
patterns from measurements and leverages this information to represent the
signal, thereby enhancing generalization and improving extrapolation
performance. We demonstrate the efficacy of the proposed method through
comprehensive experiments, including the learning of the periodic solutions for
differential equations, and time series imputation (interpolation) and
forecasting (extrapolation) on real-world datasets.

</details>


### [249] [Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models](https://arxiv.org/abs/2506.09532)
*Shuai Wang,Zhenhua Liu,Jiaheng Wei,Xuanwu Yin,Dong Li,Emad Barsoum*

Main category: cs.LG

TL;DR: Athena-PRM是一种多模态过程奖励模型，用于评估复杂推理问题中每一步的奖励分数。通过利用弱和强完成者之间的一致性生成高质量标签，仅需5000样本即可高效实现高性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动标注方法（如蒙特卡洛估计）噪声大且计算成本高，亟需高效生成高质量过程标注数据的方法。

Method: 提出利用弱和强完成者的预测一致性作为可靠过程标签的准则，并采用ORM初始化和负数据上采样策略优化PRM性能。

Result: Athena-PRM在多个场景和基准测试中表现优异，如在WeMath和MathVista上分别提升10.2和7.1分，并在VisualProcessBench中超越之前SoTA 3.9 F1分。

Conclusion: Athena-PRM高效且性能优越，适用于多种推理评估场景，并能显著提升模型性能。

Abstract: We present Athena-PRM, a multimodal process reward model (PRM) designed to
evaluate the reward score for each step in solving complex reasoning problems.
Developing high-performance PRMs typically demands significant time and
financial investment, primarily due to the necessity for step-level annotations
of reasoning steps. Conventional automated labeling methods, such as Monte
Carlo estimation, often produce noisy labels and incur substantial
computational costs. To efficiently generate high-quality process-labeled data,
we propose leveraging prediction consistency between weak and strong completers
as a criterion for identifying reliable process labels. Remarkably, Athena-PRM
demonstrates outstanding effectiveness across various scenarios and benchmarks
with just 5,000 samples. Furthermore, we also develop two effective strategies
to improve the performance of PRMs: ORM initialization and up-sampling for
negative data. We validate our approach in three specific scenarios:
verification for test time scaling, direct evaluation of reasoning step
correctness, and reward ranked fine-tuning. Our Athena-PRM consistently
achieves superior performance across multiple benchmarks and scenarios.
Notably, when using Qwen2.5-VL-7B as the policy model, Athena-PRM enhances
performance by 10.2 points on WeMath and 7.1 points on MathVista for test time
scaling. Furthermore, Athena-PRM sets the state-of-the-art (SoTA) results in
VisualProcessBench and outperforms the previous SoTA by 3.9 F1-score,
showcasing its robust capability to accurately assess the correctness of the
reasoning step. Additionally, utilizing Athena-PRM as the reward model, we
develop Athena-7B with reward ranked fine-tuning and outperforms baseline with
a significant margin on five benchmarks.

</details>


### [250] [STOAT: Spatial-Temporal Probabilistic Causal Inference Network](https://arxiv.org/abs/2506.09544)
*Yang Yang,Du Yin,Hao Xue,Flora Salim*

Main category: cs.LG

TL;DR: STOAT是一种新型空间-时间概率因果推断网络，用于空间-时间因果时间序列的概率预测，通过结合空间关系矩阵和深度概率模型，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立建模空间和时间动态，忽略了因果驱动的概率预测，限制了预测能力。

Method: STOAT扩展了因果推断方法，引入空间关系矩阵编码区域间依赖关系，并通过深度概率模型估计分布参数。

Result: 在COVID-19数据上的实验表明，STOAT在关键指标上优于现有概率预测模型，尤其在空间依赖性强的区域表现突出。

Conclusion: STOAT为复杂空间-时间任务（如疫情管理）提供了一个通用框架，结合了因果推断和地理空间概率预测。

Abstract: Spatial-temporal causal time series (STC-TS) involve region-specific temporal
observations driven by causally relevant covariates and interconnected across
geographic or network-based spaces. Existing methods often model spatial and
temporal dynamics independently and overlook causality-driven probabilistic
forecasting, limiting their predictive power. To address this, we propose STOAT
(Spatial-Temporal Probabilistic Causal Inference Network), a novel framework
for probabilistic forecasting in STC-TS. The proposed method extends a causal
inference approach by incorporating a spatial relation matrix that encodes
interregional dependencies (e.g. proximity or connectivity), enabling spatially
informed causal effect estimation. The resulting latent series are processed by
deep probabilistic models to estimate the parameters of the distributions,
enabling calibrated uncertainty modeling. We further explore multiple output
distributions (e.g., Gaussian, Student's-$t$, Laplace) to capture
region-specific variability. Experiments on COVID-19 data across six countries
demonstrate that STOAT outperforms state-of-the-art probabilistic forecasting
models (DeepAR, DeepVAR, Deep State Space Model, etc.) in key metrics,
particularly in regions with strong spatial dependencies. By bridging causal
inference and geospatial probabilistic forecasting, STOAT offers a
generalizable framework for complex spatial-temporal tasks, such as epidemic
management.

</details>


### [251] [MOORL: A Framework for Integrating Offline-Online Reinforcement Learning](https://arxiv.org/abs/2506.09574)
*Gaurav Chaudhary,Wassim Uddin Mondal,Laxmidhar Behera*

Main category: cs.LG

TL;DR: MOORL是一种结合离线与在线强化学习的混合框架，通过元策略无缝适应不同轨迹，解决了样本效率和探索问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习中样本效率和探索的挑战，尤其是离线RL中的分布外动作问题。

Method: 提出MOORL框架，利用元策略结合离线与在线数据，提升探索效率并稳定Q函数。

Result: 在28个任务上验证了MOORL的有效性，性能优于现有离线与混合RL方法。

Conclusion: MOORL以低计算开销实现高效学习，适用于实际场景。

Abstract: Sample efficiency and exploration remain critical challenges in Deep
Reinforcement Learning (DRL), particularly in complex domains. Offline RL,
which enables agents to learn optimal policies from static, pre-collected
datasets, has emerged as a promising alternative. However, offline RL is
constrained by issues such as out-of-distribution (OOD) actions that limit
policy performance and generalization. To overcome these limitations, we
propose Meta Offline-Online Reinforcement Learning (MOORL), a hybrid framework
that unifies offline and online RL for efficient and scalable learning. While
previous hybrid methods rely on extensive design components and added
computational complexity to utilize offline data effectively, MOORL introduces
a meta-policy that seamlessly adapts across offline and online trajectories.
This enables the agent to leverage offline data for robust initialization while
utilizing online interactions to drive efficient exploration. Our theoretical
analysis demonstrates that the hybrid approach enhances exploration by
effectively combining the complementary strengths of offline and online data.
Furthermore, we demonstrate that MOORL learns a stable Q-function without added
complexity. Extensive experiments on 28 tasks from the D4RL and V-D4RL
benchmarks validate its effectiveness, showing consistent improvements over
state-of-the-art offline and hybrid RL baselines. With minimal computational
overhead, MOORL achieves strong performance, underscoring its potential for
practical applications in real-world scenarios.

</details>


### [252] [Beyond Overconfidence: Foundation Models Redefine Calibration in Deep Neural Networks](https://arxiv.org/abs/2506.09593)
*Achim Hekler,Lukas Kuhn,Florian Buettner*

Main category: cs.LG

TL;DR: 本文研究了基础模型（如ConvNeXt、EVA和BEiT）的校准行为，发现其在分布内预测中倾向于不自信，导致校准误差较高，但在分布偏移下校准表现更好。后处理校准技术在分布内有效，但在严重偏移下可能失效。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型的校准行为，填补现有研究空白，挑战传统校准范式。

Method: 通过实证分析基础模型的校准行为，评估其在分布内和分布偏移下的表现，并测试后处理校准技术的效果。

Result: 基础模型在分布内预测中不自信，校准误差高；在分布偏移下校准表现更好。后处理校准在分布内有效，但在严重偏移下可能失效。

Conclusion: 基础模型的校准行为复杂，受架构和训练创新影响，挑战了持续改进的传统观点。

Abstract: Reliable uncertainty calibration is essential for safely deploying deep
neural networks in high-stakes applications. Deep neural networks are known to
exhibit systematic overconfidence, especially under distribution shifts.
Although foundation models such as ConvNeXt, EVA and BEiT have demonstrated
significant improvements in predictive performance, their calibration
properties remain underexplored. This paper presents a comprehensive
investigation into the calibration behavior of foundation models, revealing
insights that challenge established paradigms. Our empirical analysis shows
that these models tend to be underconfident in in-distribution predictions,
resulting in higher calibration errors, while demonstrating improved
calibration under distribution shifts. Furthermore, we demonstrate that
foundation models are highly responsive to post-hoc calibration techniques in
the in-distribution setting, enabling practitioners to effectively mitigate
underconfidence bias. However, these methods become progressively less reliable
under severe distribution shifts and can occasionally produce counterproductive
results. Our findings highlight the complex, non-monotonic effects of
architectural and training innovations on calibration, challenging established
narratives of continuous improvement.

</details>


### [253] [Accelerating Large-Scale Regularized High-Order Tensor Recovery](https://arxiv.org/abs/2506.09594)
*Wenjin Qin,Hailin Wang,Jingyao Hou,Jianjun Wang*

Main category: cs.LG

TL;DR: 论文提出了一种针对大规模高阶张量数据的快速随机化低秩张量逼近算法，并结合非凸建模框架，显著提升了计算效率和恢复精度。


<details>
  <summary>Details</summary>
Motivation: 现有张量恢复方法未能考虑张量尺度变化对结构特性的影响，且计算成本高昂。

Method: 结合Krylov子空间迭代、块Lanczos双对角化过程和随机投影策略，设计了两种快速随机化算法，并开发了非凸建模框架。

Result: 实验证明所提方法在大规模张量数据上具有高效性和优越性。

Conclusion: 该方法为大规模张量恢复提供了实用且高效的解决方案。

Abstract: Currently, existing tensor recovery methods fail to recognize the impact of
tensor scale variations on their structural characteristics. Furthermore,
existing studies face prohibitive computational costs when dealing with
large-scale high-order tensor data. To alleviate these issue, assisted by the
Krylov subspace iteration, block Lanczos bidiagonalization process, and random
projection strategies, this article first devises two fast and accurate
randomized algorithms for low-rank tensor approximation (LRTA) problem.
Theoretical bounds on the accuracy of the approximation error estimate are
established. Next, we develop a novel generalized nonconvex modeling framework
tailored to large-scale tensor recovery, in which a new regularization paradigm
is exploited to achieve insightful prior representation for large-scale
tensors. On the basis of the above, we further investigate new unified
nonconvex models and efficient optimization algorithms, respectively, for
several typical high-order tensor recovery tasks in unquantized and quantized
situations. To render the proposed algorithms practical and efficient for
large-scale tensor data, the proposed randomized LRTA schemes are integrated
into their central and time-intensive computations. Finally, we conduct
extensive experiments on various large-scale tensors, whose results demonstrate
the practicability, effectiveness and superiority of the proposed method in
comparison with some state-of-the-art approaches.

</details>


### [254] [SparseSSM: Efficient Selective Structured State Space Models Can Be Pruned in One-Shot](https://arxiv.org/abs/2506.09613)
*Kaiwen Tuo,Huan Wang*

Main category: cs.LG

TL;DR: SparseSSM是一种无需训练的剪枝框架，专为状态空间模型设计，通过二阶显著性评分和组件敏感性分析，实现了50%的权重剪枝且零精度损失。


<details>
  <summary>Details</summary>
Motivation: 现有的一剪枝方法不适用于状态空间模型的独特结构，导致部署效率低下。

Method: 提出SparseSSM框架，结合二阶显著性评分和组件敏感性分析，支持半结构化和结构化稀疏化。

Result: 剪枝50%的SSM权重且无需微调，保持零精度损失，成为Mamba模型剪枝的SOTA方法。

Conclusion: SparseSSM为状态空间模型提供了一种高效、无需训练的剪枝方案，显著提升了部署效率。

Abstract: State-space language models such as Mamba match Transformer quality while
permitting linear complexity inference, yet still comprise billions of
parameters that hinder deployment. Existing one-shot pruning methods are
tailored to attention blocks and fail to account for the time-shared and
discretized state-transition matrix at the heart of the selective state-space
module (SSM). In this paper, we introduce SparseSSM, the first training-free
pruning framework that extends the classic optimal brain surgeon (OBS)
framework to state space architectures. Our layer-wise algorithm (i) derives an
approximate second-order saliency score that aggregates Hessian-trace
information across time steps, (ii) incorporates a component sensitivity
analysis to guide feed-forward network (FFN) pruning, which also sheds light on
where redundancy resides in mamba architecture, (iii) can be easily extended to
semi-structured and structured sparsity. Empirically, we prune 50% of SSM
weights without fine-tuning and observe no zero-shot accuracy loss, achieving
the current state-of-the-art pruning algorithm for Mamba-based LLMs.

</details>


### [255] [GLGENN: A Novel Parameter-Light Equivariant Neural Networks Architecture Based on Clifford Geometric Algebras](https://arxiv.org/abs/2506.09625)
*Ekaterina Filimoshina,Dmitry Shirokov*

Main category: cs.LG

TL;DR: 提出了一种基于几何代数的等变神经网络架构GLGENN，适用于多种伪正交变换，参数轻量化且性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决现有等变神经网络在处理伪正交变换时的局限性，同时减少参数和过拟合风险。

Method: 利用几何代数的结构和操作设计权重共享参数化技术，构建GLGENN架构。

Result: GLGENN在多个基准任务中表现优于或匹配竞争对手，且参数更少。

Conclusion: GLGENN是一种高效且参数轻量化的等变神经网络架构，适用于广泛的几何变换任务。

Abstract: We propose, implement, and compare with competitors a new architecture of
equivariant neural networks based on geometric (Clifford) algebras: Generalized
Lipschitz Group Equivariant Neural Networks (GLGENN). These networks are
equivariant to all pseudo-orthogonal transformations, including rotations and
reflections, of a vector space with any non-degenerate or degenerate symmetric
bilinear form. We propose a weight-sharing parametrization technique that takes
into account the fundamental structures and operations of geometric algebras.
Due to this technique, GLGENN architecture is parameter-light and has less
tendency to overfitting than baseline equivariant models. GLGENN outperforms or
matches competitors on several benchmarking equivariant tasks, including
estimation of an equivariant function and a convex hull experiment, while using
significantly fewer optimizable parameters.

</details>


### [256] [In-Context Bias Propagation in LLM-Based Tabular Data Generation](https://arxiv.org/abs/2506.09630)
*Pol G. Recasens,Alberto Gutierrez,Jordi Torres,Josep. Ll Berral,Anisa Halimi,Kieran Fraser*

Main category: cs.LG

TL;DR: LLMs用于生成合成表格数据时，上下文示例中的统计偏差会导致全局数据失真，甚至可能被恶意利用，影响下游分类器的公平性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在数据稀缺场景下生成合成表格数据时，上下文示例中的统计偏差如何影响数据分布，并探讨恶意注入偏差的风险。

Method: 系统研究上下文示例中的统计偏差如何传播到合成数据分布，并引入恶意注入偏差的对抗场景。

Result: 即使轻微的上下文偏差也会导致全局统计失真，恶意注入偏差会损害下游分类器对特定受保护子组的公平性。

Conclusion: LLM基于上下文提示的数据生成管道在敏感领域存在新的漏洞，需警惕偏差传播和恶意利用。

Abstract: Large Language Models (LLMs) are increasingly used for synthetic tabular data
generation through in-context learning (ICL), offering a practical solution for
data augmentation in data scarce scenarios. While prior work has shown the
potential of LLMs to improve downstream task performance through augmenting
underrepresented groups, these benefits often assume access to a subset of
unbiased in-context examples, representative of the real dataset. In real-world
settings, however, data is frequently noisy and demographically skewed. In this
paper, we systematically study how statistical biases within in-context
examples propagate to the distribution of synthetic tabular data, showing that
even mild in-context biases lead to global statistical distortions. We further
introduce an adversarial scenario where a malicious contributor can inject bias
into the synthetic dataset via a subset of in-context examples, ultimately
compromising the fairness of downstream classifiers for a targeted and
protected subgroup. Our findings demonstrate a new vulnerability associated
with LLM-based data generation pipelines that rely on in-context prompts with
in sensitive domains.

</details>


### [257] [FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models](https://arxiv.org/abs/2506.09638)
*Weiying Zheng,Ziyue Lin,Pengxin Guo,Yuyin Zhou,Feifei Wang,Liangqiong Qu*

Main category: cs.LG

TL;DR: 该论文提出了首个系统化的联邦学习视觉语言模型（VLM）微调基准FedVLMBench，涵盖多种架构、策略和数据集，揭示了关键优化配置和数据异质性影响。


<details>
  <summary>Details</summary>
Motivation: 现有VLM微调方法依赖集中式训练，难以满足隐私敏感领域（如医疗）的需求，且缺乏联邦学习环境下的全面评估基准。

Method: 通过整合两种主流VLM架构、四种微调策略、五种FL算法和六种多模态数据集，构建FedVLMBench，并进行广泛实验。

Result: 发现2层MLP连接器与并发调优是FL中基于编码器VLM的最佳配置，且FL方法在视觉任务中对数据异质性更敏感。

Conclusion: FedVLMBench为隐私保护的多模态基础模型联邦训练提供了标准化平台和实证指导。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable capabilities in
cross-modal understanding and generation by integrating visual and textual
information. While instruction tuning and parameter-efficient fine-tuning
methods have substantially improved the generalization of VLMs, most existing
approaches rely on centralized training, posing challenges for deployment in
domains with strict privacy requirements like healthcare. Recent efforts have
introduced Federated Learning (FL) into VLM fine-tuning to address these
privacy concerns, yet comprehensive benchmarks for evaluating federated
fine-tuning strategies, model architectures, and task generalization remain
lacking. In this work, we present \textbf{FedVLMBench}, the first systematic
benchmark for federated fine-tuning of VLMs. FedVLMBench integrates two
mainstream VLM architectures (encoder-based and encoder-free), four fine-tuning
strategies, five FL algorithms, six multimodal datasets spanning four
cross-domain single-task scenarios and two cross-domain multitask settings,
covering four distinct downstream task categories. Through extensive
experiments, we uncover key insights into the interplay between VLM
architectures, fine-tuning strategies, data heterogeneity, and multi-task
federated optimization. Notably, we find that a 2-layer multilayer perceptron
(MLP) connector with concurrent connector and LLM tuning emerges as the optimal
configuration for encoder-based VLMs in FL. Furthermore, current FL methods
exhibit significantly higher sensitivity to data heterogeneity in
vision-centric tasks than text-centric ones, across both encoder-free and
encoder-based VLM architectures. Our benchmark provides essential tools,
datasets, and empirical guidance for the research community, offering a
standardized platform to advance privacy-preserving, federated training of
multimodal foundation models.

</details>


### [258] [SyncFed: Time-Aware Federated Learning through Explicit Timestamping and Synchronization](https://arxiv.org/abs/2506.09660)
*Baran Can Gül,Stefanos Tziampazis,Nasser Jazdi,Michael Weyrich*

Main category: cs.LG

TL;DR: SyncFed是一个时间感知的联邦学习框架，通过显式同步和时间戳量化滞后，提升模型准确性和信息新鲜度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在大规模分布式环境中面临网络延迟、时钟不同步和客户端更新不一致等问题，影响模型可靠性和收敛性。

Method: 采用显式同步和时间戳（基于NTP协议）量化滞后，服务器根据时间戳对客户端更新进行加权聚合。

Result: 实验表明，SyncFed在分布式测试环境中能稳定全局模型的时间上下文，提高准确性和信息新鲜度。

Conclusion: SyncFed通过时间感知机制有效解决了联邦学习中的滞后问题，优于传统基于轮次的基线方法。

Abstract: As Federated Learning (FL) expands to larger and more distributed
environments, consistency in training is challenged by network-induced delays,
clock unsynchronicity, and variability in client updates. This combination of
factors may contribute to misaligned contributions that undermine model
reliability and convergence. Existing methods like staleness-aware aggregation
and model versioning address lagging updates heuristically, yet lack mechanisms
to quantify staleness, especially in latency-sensitive and cross-regional
deployments. In light of these considerations, we introduce \emph{SyncFed}, a
time-aware FL framework that employs explicit synchronization and timestamping
to establish a common temporal reference across the system. Staleness is
quantified numerically based on exchanged timestamps under the Network Time
Protocol (NTP), enabling the server to reason about the relative freshness of
client updates and apply temporally informed weighting during aggregation. Our
empirical evaluation on a geographically distributed testbed shows that, under
\emph{SyncFed}, the global model evolves within a stable temporal context,
resulting in improved accuracy and information freshness compared to
round-based baselines devoid of temporal semantics.

</details>


### [259] [Wavelet Scattering Transform and Fourier Representation for Offline Detection of Malicious Clients in Federated Learning](https://arxiv.org/abs/2506.09674)
*Alessandro Licciardi,Davide Leo,Davide Carbone*

Main category: cs.LG

TL;DR: WAFFLE提出了一种基于小波散射变换和傅里叶变换的联邦学习异常客户端检测算法，无需访问原始数据即可在训练前标记恶意客户端。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中异常客户端（如数据分布不具代表性或传感器故障）会显著降低模型性能，如何在保护隐私的前提下检测这些客户端是关键挑战。

Method: 利用小波散射变换（WST）或傅里叶变换生成低维任务无关嵌入，通过轻量级检测器在公共数据集上进行训练，实现高效标记。

Result: 实验表明，WAFFLE在检测准确性和下游分类性能上优于现有联邦学习异常检测算法。

Conclusion: WAFFLE作为一种预训练替代方案，为联邦学习中的异常检测提供了高效且隐私保护的解决方案。

Abstract: Federated Learning (FL) enables the training of machine learning models
across decentralized clients while preserving data privacy. However, the
presence of anomalous or corrupted clients - such as those with faulty sensors
or non representative data distributions - can significantly degrade model
performance. Detecting such clients without accessing raw data remains a key
challenge. We propose WAFFLE (Wavelet and Fourier representations for Federated
Learning) a detection algorithm that labels malicious clients {\it before
training}, using locally computed compressed representations derived from
either the Wavelet Scattering Transform (WST) or the Fourier Transform. Both
approaches provide low-dimensional, task-agnostic embeddings suitable for
unsupervised client separation. A lightweight detector, trained on a
distillated public dataset, performs the labeling with minimal communication
and computational overhead. While both transforms enable effective detection,
WST offers theoretical advantages, such as non-invertibility and stability to
local deformations, that make it particularly well-suited to federated
scenarios. Experiments on benchmark datasets show that our method improves
detection accuracy and downstream classification performance compared to
existing FL anomaly detection algorithms, validating its effectiveness as a
pre-training alternative to online detection strategies.

</details>


### [260] [Wasserstein Hypergraph Neural Network](https://arxiv.org/abs/2506.09682)
*Iulia Duta,Pietro Liò*

Main category: cs.LG

TL;DR: 论文提出了一种基于Wasserstein距离的超图神经网络模型，通过分布聚合信息，显著提升了节点分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的超图神经网络多采用两阶段聚合方法，但通常简化聚合操作，未能充分捕捉高阶关系。本文旨在通过分布建模和Wasserstein距离改进信息聚合。

Method: 提出Wasserstein超图神经网络，将节点和超边邻域视为分布，利用Sliced Wasserstein Pooling进行信息聚合，保留分布的几何特性。

Result: 实验表明，该方法在多个真实数据集上显著提升了节点分类任务的性能。

Conclusion: Wasserstein聚合方法在超图神经网络中具有优势，能够更好地建模高阶关系并提升任务表现。

Abstract: The ability to model relational information using machine learning has driven
advancements across various domains, from medicine to social science. While
graph representation learning has become mainstream over the past decade,
representing higher-order relationships through hypergraphs is rapidly gaining
momentum. In the last few years, numerous hypergraph neural networks have
emerged, most of them falling under a two-stage, set-based framework. The
messages are sent from nodes to edges and then from edges to nodes. However,
most of the advancement still takes inspiration from the graph counterpart,
often simplifying the aggregations to basic pooling operations. In this paper
we are introducing Wasserstein Hypergraph Neural Network, a model that treats
the nodes and hyperedge neighbourhood as distributions and aggregate the
information using Sliced Wasserstein Pooling. Unlike conventional aggregators
such as mean or sum, which only capture first-order statistics, our approach
has the ability to preserve geometric properties like the shape and spread of
distributions. This enables the learned embeddings to reflect how easily one
hyperedge distribution can be transformed into another, following principles of
optimal transport. Experimental results demonstrate that applying Wasserstein
pooling in a hypergraph setting significantly benefits node classification
tasks, achieving top performance on several real-world datasets.

</details>


### [261] [TRIDENT: Temporally Restricted Inference via DFA-Enhanced Neural Traversal](https://arxiv.org/abs/2506.09701)
*Vincenzo Collura,Karim Tit,Laura Bussi,Eleonora Giunchiglia,Maxime Cordy*

Main category: cs.LG

TL;DR: TRIDENT是一种模型无关的推理时算法，确保LLM输出满足线性时序逻辑（LTLf）约束，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有LLM无法保证输出满足时序约束，如LTLf。

Method: 将LTLf公式编译为DFA，指导约束束搜索，动态屏蔽违规路径并重新排序。

Result: TRIDENT保证输出满足约束，并在图像流分类和文本生成任务中提升质量。

Conclusion: TRIDENT高效且优于现有方法，完美满足约束并保持高质量。

Abstract: Large Language Models (LLMs) and other neural architectures have achieved
impressive results across a variety of generative and classification tasks.
However, they remain fundamentally ill-equipped to ensure that their outputs
satisfy temporal constraints, such as those expressible in Linear Temporal
Logic over finite traces (LTLf). In this paper, we introduce TRIDENT: a general
and model-agnostic inference-time algorithm that guarantees compliance with
such constraints without requiring any retraining. TRIDENT compiles LTLf
formulas into a Deterministic Finite Automaton (DFA), which is used to guide a
constrained variant of beam search. At each decoding step, transitions that
would lead to constraint violations are masked, while remaining paths are
dynamically re-ranked based on both the model's probabilities and the DFA's
acceptance structure. We formally prove that the resulting sequences are
guaranteed to satisfy the given LTLf constraints, and we empirically
demonstrate that TRIDENT also improves output quality. We validate our approach
on two distinct tasks: temporally constrained image-stream classification and
controlled text generation. In both settings, TRIDENT achieves perfect
constraint satisfaction, while comparison with the state of the art shows
improved efficiency and high standard quality metrics.

</details>


### [262] [Auto-Compressing Networks](https://arxiv.org/abs/2506.09714)
*Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos*

Main category: cs.LG

TL;DR: Auto-Compressing Networks (ACNs) 通过长前馈连接替代短残差连接，实现自动压缩信息，提升表示质量，减少计算冗余。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络增加深度时可能引入计算冗余，而表示质量未相应提升。ACNs旨在通过架构设计实现信息自动压缩。

Method: ACNs采用从每层到输出的长前馈连接，通过梯度下降动态压缩信息，增强早期层表示质量。

Result: ACNs在噪声鲁棒性、低数据性能、迁移学习和灾难性遗忘方面表现优异，参数更少且压缩率高达30-80%。

Conclusion: ACNs是一种高效架构，能自动适应任务复杂度，学习鲁棒表示，并与传统剪枝技术结合实现更好的稀疏性-性能权衡。

Abstract: Deep neural networks with short residual connections have demonstrated
remarkable success across domains, but increasing depth often introduces
computational redundancy without corresponding improvements in representation
quality. In this work, we introduce Auto-Compressing Networks (ACNs), an
architectural variant where additive long feedforward connections from each
layer to the output replace traditional short residual connections. ACNs
showcase a unique property we coin as "auto-compression", the ability of a
network to organically compress information during training with gradient
descent, through architectural design alone. Through auto-compression,
information is dynamically "pushed" into early layers during training,
enhancing their representational quality and revealing potential redundancy in
deeper ones. We theoretically show that this property emerges from layer-wise
training patterns present in ACNs, where layers are dynamically utilized during
training based on task requirements. We also find that ACNs exhibit enhanced
noise robustness compared to residual networks, superior performance in
low-data settings, improved transfer learning capabilities, and mitigate
catastrophic forgetting suggesting that they learn representations that
generalize better despite using fewer parameters. Our results demonstrate up to
18% reduction in catastrophic forgetting and 30-80% architectural compression
while maintaining accuracy across vision transformers, MLP-mixers, and BERT
architectures. Furthermore, we demonstrate that coupling ACNs with traditional
pruning techniques, enables significantly better sparsity-performance
trade-offs compared to conventional architectures. These findings establish
ACNs as a practical approach to developing efficient neural architectures that
automatically adapt their computational footprint to task complexity, while
learning robust representations.

</details>


### [263] [AtmosMJ: Revisiting Gating Mechanism for AI Weather Forecasting Beyond the Year Scale](https://arxiv.org/abs/2506.09733)
*Minjong Cheon*

Main category: cs.LG

TL;DR: AtmosMJ挑战了传统观点，证明标准经纬度网格也能实现长期稳定天气预报，通过GRF机制和高效设计，在低训练成本下达到竞争性效果。


<details>
  <summary>Details</summary>
Motivation: 探讨是否能在标准经纬度网格上实现长期稳定的天气预报，而非依赖非标准数据表示。

Method: 引入AtmosMJ，一种直接在ERA5数据上运行的深度卷积网络，采用GRF机制防止误差累积。

Result: AtmosMJ能稳定预测约500天，10天预报精度与先进模型相当，训练成本极低。

Conclusion: 高效架构设计而非非标准数据表示是实现长期稳定天气预报的关键。

Abstract: The advent of Large Weather Models (LWMs) has marked a turning point in
data-driven forecasting, with many models now outperforming traditional
numerical systems in the medium range. However, achieving stable, long-range
autoregressive forecasts beyond a few weeks remains a significant challenge.
Prevailing state-of-the-art models that achieve year-long stability, such as
SFNO and DLWP-HPX, have relied on transforming input data onto non-standard
spatial domains like spherical harmonics or HEALPix meshes. This has led to the
prevailing assumption that such representations are necessary to enforce
physical consistency and long-term stability. This paper challenges that
assumption by investigating whether comparable long-range performance can be
achieved on the standard latitude-longitude grid. We introduce AtmosMJ, a deep
convolutional network that operates directly on ERA5 data without any spherical
remapping. The model's stability is enabled by a novel Gated Residual Fusion
(GRF) mechanism, which adaptively moderates feature updates to prevent error
accumulation over long recursive simulations. Our results demonstrate that
AtmosMJ produces stable and physically plausible forecasts for about 500 days.
In quantitative evaluations, it achieves competitive 10-day forecast accuracy
against models like Pangu-Weather and GraphCast, all while requiring a
remarkably low training budget of 5.7 days on a V100 GPU. Our findings suggest
that efficient architectural design, rather than non-standard data
representation, can be the key to unlocking stable and computationally
efficient long-range weather prediction.

</details>


### [264] [Towards Multi-modal Graph Large Language Model](https://arxiv.org/abs/2506.09738)
*Xin Wang,Zeyang Zhang,Linxin Xiao,Haibo Chen,Chendi Ge,Wenwu Zhu*

Main category: cs.LG

TL;DR: 该论文探讨了多模态图大语言模型（MG-LLM）的潜力，旨在统一和泛化多模态图数据与任务，提出了五个关键特性，并总结了相关挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法泛化到不同多模态图数据与任务，因此需要探索MG-LLM的潜力以实现统一和泛化。

Method: 提出了一个统一的多模态图数据、任务和模型框架，并定义了MG-LLM的五个关键特性。

Result: 论文总结了现有相关数据集，并提出了实现MG-LLM的关键挑战和未来方向。

Conclusion: MG-LLM有望推动多模态图数据与任务的泛化研究。

Abstract: Multi-modal graphs, which integrate diverse multi-modal features and
relations, are ubiquitous in real-world applications. However, existing
multi-modal graph learning methods are typically trained from scratch for
specific graph data and tasks, failing to generalize across various multi-modal
graph data and tasks. To bridge this gap, we explore the potential of
Multi-modal Graph Large Language Models (MG-LLM) to unify and generalize across
diverse multi-modal graph data and tasks. We propose a unified framework of
multi-modal graph data, task, and model, discovering the inherent
multi-granularity and multi-scale characteristics in multi-modal graphs.
Specifically, we present five key desired characteristics for MG-LLM: 1)
unified space for multi-modal structures and attributes, 2) capability of
handling diverse multi-modal graph tasks, 3) multi-modal graph in-context
learning, 4) multi-modal graph interaction with natural language, and 5)
multi-modal graph reasoning. We then elaborate on the key challenges, review
related works, and highlight promising future research directions towards
realizing these ambitious characteristics. Finally, we summarize existing
multi-modal graph datasets pertinent for model training. We believe this paper
can contribute to the ongoing advancement of the research towards MG-LLM for
generalization across multi-modal graph data and tasks.

</details>


### [265] [Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring](https://arxiv.org/abs/2506.09742)
*Gusseppe Bravo-Rocca,Peini Liu,Jordi Guitart,Rodrigo M Carrillo-Larco,Ajay Dholakia,David Ellison*

Main category: cs.LG

TL;DR: 提出了一种基于特征工程和LLM的认知架构，用于提升ML模型监控输出的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统ML监控方法输出冗长且难以理解，影响决策效果。

Method: 通过Refactor、Break Down和Compile三个步骤模拟特征工程，优化LLM的监控输出。

Result: 实验表明，该方法显著提高了准确性，优于多种基线模型。

Conclusion: 结合特征工程和选择性LLM利用，构建了高效且可解释的决策支持系统。

Abstract: Monitoring Machine Learning (ML) models in production environments is
crucial, yet traditional approaches often yield verbose, low-interpretability
outputs that hinder effective decision-making. We propose a cognitive
architecture for ML monitoring that applies feature engineering principles to
agents based on Large Language Models (LLMs), significantly enhancing the
interpretability of monitoring outputs. Central to our approach is a Decision
Procedure module that simulates feature engineering through three key steps:
Refactor, Break Down, and Compile. The Refactor step improves data
representation to better capture feature semantics, allowing the LLM to focus
on salient aspects of the monitoring data while reducing noise and irrelevant
information. Break Down decomposes complex information for detailed analysis,
and Compile integrates sub-insights into clear, interpretable outputs. This
process leads to a more deterministic planning approach, reducing dependence on
LLM-generated planning, which can sometimes be inconsistent and overly general.
The combination of feature engineering-driven planning and selective LLM
utilization results in a robust decision support system, capable of providing
highly interpretable and actionable insights. Experiments using multiple LLMs
demonstrate the efficacy of our approach, achieving significantly higher
accuracy compared to various baselines across several domains.

</details>


### [266] [Load-Aware Training Scheduling for Model Circulation-based Decentralized Federated Learning](https://arxiv.org/abs/2506.09769)
*Haruki Kainuma,Takayuki Nishio*

Main category: cs.LG

TL;DR: Load-aware Tram-FL通过引入训练调度机制，优化去中心化联邦学习中的计算和通信负载，显著减少训练时间并加速收敛。


<details>
  <summary>Details</summary>
Motivation: 解决去中心化联邦学习中因计算和通信负载不均导致的总训练时间过长问题。

Method: 将全局优化问题分解为节点级子问题，引入方差约束以平衡非独立同分布数据利用，并通过目标函数最小化训练延迟。

Result: 在MNIST和CIFAR-10数据集上的仿真表明，Load-aware Tram-FL显著优于基线方法。

Conclusion: Load-aware Tram-FL有效优化了训练调度，提升了去中心化联邦学习的效率。

Abstract: This paper proposes Load-aware Tram-FL, an extension of Tram-FL that
introduces a training scheduling mechanism to minimize total training time in
decentralized federated learning by accounting for both computational and
communication loads. The scheduling problem is formulated as a global
optimization task, which-though intractable in its original form-is made
solvable by decomposing it into node-wise subproblems. To promote balanced data
utilization under non-IID distributions, a variance constraint is introduced,
while the overall training latency, including both computation and
communication costs, is minimized through the objective function. Simulation
results on MNIST and CIFAR-10 demonstrate that Load-aware Tram-FL significantly
reduces training time and accelerates convergence compared to baseline methods.

</details>


### [267] [On the Similarities of Embeddings in Contrastive Learning](https://arxiv.org/abs/2506.09781)
*Chungpa Lee,Sehee Lim,Kibok Lee,Jy-yong Sohn*

Main category: cs.LG

TL;DR: 本文提出了一个统一的对比学习框架，分析了正负对嵌入的余弦相似性，并解决了小批量训练中的相似性方差问题。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习目标缺乏系统性解释，需要统一框架来理解其原理。

Method: 基于余弦相似性分析正负对嵌入，提出辅助损失项以减少负对相似性方差。

Result: 实验表明，提出的损失项在小批量训练中能稳定提升对比学习性能。

Conclusion: 通过统一框架和辅助损失项，本文改进了对比学习在小批量训练中的表现。

Abstract: Contrastive learning (CL) operates on a simple yet effective principle:
embeddings of positive pairs are pulled together, while those of negative pairs
are pushed apart. Although various forms of contrastive loss have been proposed
and analyzed from different perspectives, prior works lack a comprehensive
framework that systematically explains a broad class of these objectives. In
this paper, we present a unified framework for understanding CL, which is based
on analyzing the cosine similarity between embeddings of positive and negative
pairs. In full-batch settings, we show that perfect alignment of positive pairs
is unattainable when similarities of negative pairs fall below a certain
threshold, and that this misalignment can be alleviated by incorporating
within-view negative pairs. In mini-batch settings, we demonstrate that smaller
batch sizes incur stronger separation among negative pairs within batches,
which leads to higher variance in similarities of negative pairs. To address
this limitation of mini-batch CL, we introduce an auxiliary loss term that
reduces the variance of similarities of negative pairs in CL. Empirical results
demonstrate that incorporating the proposed loss consistently improves the
performance of CL methods in small-batch training.

</details>


### [268] [A theoretical framework for self-supervised contrastive learning for continuous dependent data](https://arxiv.org/abs/2506.09785)
*Alexander Marusov,Alexander Yuhay,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 论文提出了一种针对连续依赖数据的自监督学习框架，通过硬和软相似性度量改进对比学习，在时空数据任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统对比自监督学习方法假设样本间语义独立，不适用于依赖数据（如时空数据），因此需要新框架。

Method: 提出依赖感知的对比学习框架，包括硬和软相似性度量，并推导出适应依赖性的相似性矩阵和损失函数。

Result: 在UEA和UCR基准测试中分别提升4.17%和2.08%的准确率，干旱分类任务中ROC-AUC提高7%。

Conclusion: 依赖感知的对比学习方法能有效捕捉时空依赖关系，显著提升性能。

Abstract: Self-supervised learning (SSL) has emerged as a powerful approach to learning
representations, particularly in the field of computer vision. However, its
application to dependent data, such as temporal and spatio-temporal domains,
remains underexplored. Besides, traditional contrastive SSL methods often
assume \emph{semantic independence between samples}, which does not hold for
dependent data exhibiting complex correlations. We propose a novel theoretical
framework for contrastive SSL tailored to \emph{continuous dependent data},
which allows the nearest samples to be semantically close to each other. In
particular, we propose two possible \textit{ground truth similarity measures}
between objects -- \emph{hard} and \emph{soft} closeness. Under it, we derive
an analytical form for the \textit{estimated similarity matrix} that
accommodates both types of closeness between samples, thereby introducing
dependency-aware loss functions. We validate our approach, \emph{Dependent
TS2Vec}, on temporal and spatio-temporal downstream problems. Given the
dependency patterns presented in the data, our approach surpasses modern ones
for dependent data, highlighting the effectiveness of our theoretically
grounded loss functions for SSL in capturing spatio-temporal dependencies.
Specifically, we outperform TS2Vec on the standard UEA and UCR benchmarks, with
accuracy improvements of $4.17$\% and $2.08$\%, respectively. Furthermore, on
the drought classification task, which involves complex spatio-temporal
patterns, our method achieves a $7$\% higher ROC-AUC score.

</details>


### [269] [Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols](https://arxiv.org/abs/2506.09803)
*Longzhu He,Chaozhuo Li,Peng Tang,Litian Zhang,Sen Su*

Main category: cs.LG

TL;DR: 该论文提出了针对本地隐私图学习协议的首个数据投毒攻击，并探讨了防御策略。


<details>
  <summary>Details</summary>
Motivation: 现实图中的敏感信息引发隐私问题，本地隐私图学习协议虽提供隐私保护，但可能面临数据投毒攻击的威胁。

Method: 攻击者通过注入虚假用户并操纵其与真实用户建立链接，发送精心设计的数据以破坏图学习的效用。

Result: 攻击在理论和实验上均证明有效，现有防御策略效果有限。

Conclusion: 需开发更强大的防御机制以确保隐私保护图学习框架的鲁棒性和安全性。

Abstract: Graph neural networks (GNNs) have achieved significant success in graph
representation learning and have been applied to various domains. However, many
real-world graphs contain sensitive personal information, such as user profiles
in social networks, raising serious privacy concerns when graph learning is
performed using GNNs. To address this issue, locally private graph learning
protocols have gained considerable attention. These protocols leverage the
privacy advantages of local differential privacy (LDP) and the effectiveness of
GNN's message-passing in calibrating noisy data, offering strict privacy
guarantees for users' local data while maintaining high utility (e.g., node
classification accuracy) for graph learning. Despite these advantages, such
protocols may be vulnerable to data poisoning attacks, a threat that has not
been considered in previous research. Identifying and addressing these threats
is crucial for ensuring the robustness and security of privacy-preserving graph
learning frameworks. This work introduces the first data poisoning attack
targeting locally private graph learning protocols. The attacker injects fake
users into the protocol, manipulates these fake users to establish links with
genuine users, and sends carefully crafted data to the server, ultimately
compromising the utility of private graph learning. The effectiveness of the
attack is demonstrated both theoretically and empirically. In addition, several
defense strategies have also been explored, but their limited effectiveness
highlights the need for more robust defenses.

</details>


### [270] [Generalizing Supervised Contrastive learning: A Projection Perspective](https://arxiv.org/abs/2506.09810)
*Minoh Jeong,Alfred Hero*

Main category: cs.LG

TL;DR: 论文提出了ProjNCE，一种统一监督和自监督对比学习目标的损失函数，并证明其是互信息的有效下界，同时在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索监督对比学习（SupCon）与互信息（MI）的关系，填补现有研究的空白。

Method: 引入ProjNCE损失函数，结合投影函数和负对调整项，统一监督和自监督目标，并验证其作为MI下界的有效性。

Result: ProjNCE在多个数据集和设置中表现优于SupCon和标准交叉熵训练。

Conclusion: ProjNCE从互信息解释和投影设计两个角度改进了SupCon，为对比学习提供了更灵活和有效的工具。

Abstract: Self-supervised contrastive learning (SSCL) has emerged as a powerful
paradigm for representation learning and has been studied from multiple
perspectives, including mutual information and geometric viewpoints. However,
supervised contrastive (SupCon) approaches have received comparatively little
attention in this context: for instance, while InfoNCE used in SSCL is known to
form a lower bound on mutual information (MI), the relationship between SupCon
and MI remains unexplored. To address this gap, we introduce ProjNCE, a
generalization of the InfoNCE loss that unifies supervised and self-supervised
contrastive objectives by incorporating projection functions and an adjustment
term for negative pairs. We prove that ProjNCE constitutes a valid MI bound and
affords greater flexibility in selecting projection strategies for class
embeddings. Building on this flexibility, we further explore the centroid-based
class embeddings in SupCon by exploring a variety of projection methods.
Extensive experiments on multiple datasets and settings demonstrate that
ProjNCE consistently outperforms both SupCon and standard cross-entropy
training. Our work thus refines SupCon along two complementary
perspective--mutual information interpretation and projection design--and
offers broadly applicable improvements whenever SupCon serves as the
foundational contrastive objective.

</details>


### [271] [Metritocracy: Representative Metrics for Lite Benchmarks](https://arxiv.org/abs/2506.09813)
*Ariel Procaccia,Benjamin Schiffer,Serena Wang,Shirley Zhang*

Main category: cs.LG

TL;DR: 论文提出两种形式化的度量子集选择方法，基于社会选择理论，确保子集的代表性和比例性，并通过案例研究验证。


<details>
  <summary>Details</summary>
Motivation: 解决LLM评估中度量子集选择缺乏明确‘代表性’定义的问题。

Method: 引入位置代表性和位置比例性两种形式化概念，并研究其理论界限和实际应用。

Result: 证明了在最坏情况下所需最小度量数量的上下界，并通过案例研究验证了方法的实用性。

Conclusion: 形式化的代表性和比例性方法为度量子集选择提供了理论支持，并在实际应用中表现出色。

Abstract: A common problem in LLM evaluation is how to choose a subset of metrics from
a full suite of possible metrics. Subset selection is usually done for
efficiency or interpretability reasons, and the goal is often to select a
``representative'' subset of metrics. However, ``representative'' is rarely
clearly defined. In this work, we use ideas from social choice theory to
formalize two notions of representation for the selection of a subset of
evaluation metrics. We first introduce positional representation, which
guarantees every alternative is sufficiently represented at every position
cutoff. We then introduce positional proportionality, which guarantees no
alternative is proportionally over- or under-represented by more than a small
error at any position. We prove upper and lower bounds on the smallest number
of metrics needed to guarantee either of these properties in the worst case. We
also study a generalized form of each property that allows for additional input
on groups of metrics that must be represented. Finally, we tie theory to
practice through real-world case studies on both LLM evaluation and hospital
quality evaluation.

</details>


### [272] [Identifiability Challenges in Sparse Linear Ordinary Differential Equations](https://arxiv.org/abs/2506.09816)
*Cecilia Casolo,Sören Becker,Niki Kilbertus*

Main category: cs.LG

TL;DR: 论文探讨稀疏线性常微分方程（ODE）的可识别性，指出在稀疏情况下系统可能无法识别，并提供了相关概率的下界。


<details>
  <summary>Details</summary>
Motivation: 稀疏线性ODE在实际应用中广泛存在，但其可识别性尚未充分研究，填补这一空白是研究的主要动机。

Method: 通过理论分析和实证研究，论文研究了稀疏线性ODE的可识别性，并评估了现有估计方法的局限性。

Result: 研究发现稀疏系统在相关稀疏性条件下具有不可识别的概率，且现有方法无法解决这一问题。

Conclusion: 研究呼吁重新思考数据驱动的动态系统建模的预期，并提供了量化评估学习线性ODE可信度的方法。

Abstract: Dynamical systems modeling is a core pillar of scientific inquiry across
natural and life sciences. Increasingly, dynamical system models are learned
from data, rendering identifiability a paramount concept. For systems that are
not identifiable from data, no guarantees can be given about their behavior
under new conditions and inputs, or about possible control mechanisms to steer
the system. It is known in the community that "linear ordinary differential
equations (ODE) are almost surely identifiable from a single trajectory."
However, this only holds for dense matrices. The sparse regime remains
underexplored, despite its practical relevance with sparsity arising naturally
in many biological, social, and physical systems. In this work, we address this
gap by characterizing the identifiability of sparse linear ODEs. Contrary to
the dense case, we show that sparse systems are unidentifiable with a positive
probability in practically relevant sparsity regimes and provide lower bounds
for this probability. We further study empirically how this theoretical
unidentifiability manifests in state-of-the-art methods to estimate linear ODEs
from data. Our results corroborate that sparse systems are also practically
unidentifiable. Theoretical limitations are not resolved through inductive
biases or optimization dynamics. Our findings call for rethinking what can be
expected from data-driven dynamical system modeling and allows for quantitative
assessments of how much to trust a learned linear ODE.

</details>


### [273] [Weighted Loss Methods for Robust Federated Learning under Data Heterogeneity](https://arxiv.org/abs/2506.09824)
*Johan Erbani,Sonia Ben Mokhtar,Pierre-Edouard Portier,Elod Egyed-Zsigmond,Diana Nurbakova*

Main category: cs.LG

TL;DR: 论文提出了一种名为WoLA的加权损失方法，用于在联邦学习中解决数据异构性下拜占庭攻击的问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）中，拜占庭参与者可能通过提交有毒梯度破坏模型收敛性，而现有方法在数据异构性下难以区分诚实与拜占庭梯度。

Method: 引入Worker Label Alignment Loss（WoLA），通过加权损失对齐诚实工作者的梯度，便于识别拜占庭梯度。

Result: WoLA在异构数据设置下显著优于现有方法，并通过理论和实验验证了其有效性。

Conclusion: WoLA为解决联邦学习中拜占庭攻击问题提供了一种有效方法，尤其在数据异构性下表现突出。

Abstract: Federated learning (FL) is a machine learning paradigm that enables multiple
data holders to collaboratively train a machine learning model without sharing
their training data with external parties. In this paradigm, workers locally
update a model and share with a central server their updated gradients (or
model parameters). While FL seems appealing from a privacy perspective, it
opens a number of threats from a security perspective as (Byzantine)
participants can contribute poisonous gradients (or model parameters) harming
model convergence. Byzantine-resilient FL addresses this issue by ensuring that
the training proceeds as if Byzantine participants were absent. Towards this
purpose, common strategies ignore outlier gradients during model aggregation,
assuming that Byzantine gradients deviate more from honest gradients than
honest gradients do from each other. However, in heterogeneous settings, honest
gradients may differ significantly, making it difficult to distinguish honest
outliers from Byzantine ones. In this paper, we introduce the Worker Label
Alignement Loss (WoLA), a weighted loss that aligns honest worker gradients
despite data heterogeneity, which facilitates the identification of Byzantines'
gradients. This approach significantly outperforms state-of-the-art methods in
heterogeneous settings. In this paper, we provide both theoretical insights and
empirical evidence of its effectiveness.

</details>


### [274] [Guided Graph Compression for Quantum Graph Neural Networks](https://arxiv.org/abs/2506.09862)
*Mikel Casals,Vasilis Belis,Elias F. Combarro,Eduard Alarcón,Sofia Vallecorsa,Michele Grossi*

Main category: cs.LG

TL;DR: 论文提出了一种名为GGC的框架，通过图自动编码器压缩图的节点和特征维度，以提升下游分类任务性能，并在高能物理的Jet Tagging任务中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决GNN在大规模图上内存需求高和GPU稀疏矩阵操作效率低的问题，同时探索量子计算在GNN中的潜力。

Method: 提出GGC框架，利用图自动编码器压缩图结构和节点特征，并指导压缩以优化下游分类任务。

Result: GGC在Jet Tagging任务中表现优于单独使用自动编码器和传统GNN分类器。

Conclusion: GGC不仅提升了分类性能，还为在现实数据集上测试新型QGNN提供了可能。

Abstract: Graph Neural Networks (GNNs) are effective for processing graph-structured
data but face challenges with large graphs due to high memory requirements and
inefficient sparse matrix operations on GPUs. Quantum Computing (QC) offers a
promising avenue to address these issues and inspires new algorithmic
approaches. In particular, Quantum Graph Neural Networks (QGNNs) have been
explored in recent literature. However, current quantum hardware limits the
dimension of the data that can be effectively encoded. Existing approaches
either simplify datasets manually or use artificial graph datasets. This work
introduces the Guided Graph Compression (GGC) framework, which uses a graph
autoencoder to reduce both the number of nodes and the dimensionality of node
features. The compression is guided to enhance the performance of a downstream
classification task, which can be applied either with a quantum or a classical
classifier. The framework is evaluated on the Jet Tagging task, a
classification problem of fundamental importance in high energy physics that
involves distinguishing particle jets initiated by quarks from those by gluons.
The GGC is compared against using the autoencoder as a standalone preprocessing
step and against a baseline classical GNN classifier. Our numerical results
demonstrate that GGC outperforms both alternatives, while also facilitating the
testing of novel QGNN ansatzes on realistic datasets.

</details>


### [275] [Machine Learning-Based Classification of Oils Using Dielectric Properties and Microwave Resonant Sensing](https://arxiv.org/abs/2506.09867)
*Amit Baran Dey,Wasim Arif,Rakhesh Singh Kshetrimayum*

Main category: cs.LG

TL;DR: 提出了一种基于机器学习的微波谐振传感器方法，用于根据介电特性分类油样，随机森林分类器达到99.41%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 油样的分子组成决定了其介电特性，通过微波谐振传感器捕捉这些特性，实现高效、非破坏性的油类分类。

Method: 利用微波谐振传感器测量油样的谐振频率和振幅变化，提取特征后输入多种机器学习分类器进行训练和评估。

Result: 随机森林分类器表现最佳，分类准确率达99.41%，验证了方法的有效性。

Conclusion: 该方法具有高效、紧凑和高性能的特点，适用于工业环境中的实时油类识别。

Abstract: This paper proposes a machine learning-based methodology for the
classification of various oil samples based on their dielectric properties,
utilizing a microwave resonant sensor. The dielectric behaviour of oils,
governed by their molecular composition, induces distinct shifts in the
sensor's resonant frequency and amplitude response. These variations are
systematically captured and processed to extract salient features, which serve
as inputs for multiple machine learning classifiers. The microwave resonant
sensor operates in a non-destructive, low-power manner, making it particularly
well-suited for real-time industrial applications. A comprehensive dataset is
developed by varying the permittivity of oil samples and acquiring the
corresponding sensor responses. Several classifiers are trained and evaluated
using the extracted resonant features to assess their capability in
distinguishing between oil types. Experimental results demonstrate that the
proposed approach achieves a high classification accuracy of 99.41% with the
random forest classifier, highlighting its strong potential for automated oil
identification. The system's compact form factor, efficiency, and high
performance underscore its viability for fast and reliable oil characterization
in industrial environments.

</details>


### [276] [Private Aggregation for Byzantine-Resilient Heterogeneous Federated Learning](https://arxiv.org/abs/2506.09870)
*Maximilian Egger,Rawad Bitar*

Main category: cs.LG

TL;DR: 提出一种多阶段方法，结合可验证秘密共享、安全聚合和定制对称私有信息检索方案，解决联邦学习中数据异构下的隐私保护和拜占庭容错问题。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据异构情况下隐私保护和拜占庭容错的挑战，现有方法在此场景下失效。

Method: 多阶段方法，结合可验证秘密共享、安全聚合和定制对称私有信息检索方案。

Result: 在多种攻击下表现优于现有技术，并通过零阶估计方法降低通信开销。

Conclusion: 该方法在数据异构下实现了信息论隐私保证和拜占庭容错，同时降低了通信成本。

Abstract: Ensuring resilience to Byzantine clients while maintaining the privacy of the
clients' data is a fundamental challenge in federated learning (FL). When the
clients' data is homogeneous, suitable countermeasures were studied from an
information-theoretic perspective utilizing secure aggregation techniques while
ensuring robust aggregation of the clients' gradients. However, the
countermeasures used fail when the clients' data is heterogeneous. Suitable
pre-processing techniques, such as nearest neighbor mixing, were recently shown
to enhance the performance of those countermeasures in the heterogeneous
setting. Nevertheless, those pre-processing techniques cannot be applied with
the introduced privacy-preserving mechanisms.
  We propose a multi-stage method encompassing a careful co-design of
verifiable secret sharing, secure aggregation, and a tailored symmetric private
information retrieval scheme to achieve information-theoretic privacy
guarantees and Byzantine resilience under data heterogeneity. We evaluate the
effectiveness of our scheme on a variety of attacks and show how it outperforms
the previously known techniques. Since the communication overhead of secure
aggregation is non-negligible, we investigate the interplay with zero-order
estimation methods that reduce the communication cost in state-of-the-art FL
tasks and thereby make private aggregation scalable.

</details>


### [277] [Learning single-index models via harmonic decomposition](https://arxiv.org/abs/2506.09887)
*Nirmit Joshi,Hugo Koubbi,Theodor Misiakiewicz,Nathan Srebro*

Main category: cs.LG

TL;DR: 论文研究了单指标模型的学习问题，提出用球谐函数而非埃尔米特多项式作为自然基，以捕捉问题的旋转对称性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明高斯输入下恢复单指标模型的统计和计算复杂度由链接函数的埃尔米特展开决定，但球谐函数更符合问题的旋转对称性。

Method: 基于球谐函数的视角，提出了两种估计器：基于张量展开和在线SGD，分别优化样本复杂度和运行时。

Result: 理论不仅在高斯输入下恢复现有结果，还揭示了新现象。

Conclusion: 球谐函数为单指标模型学习提供了更自然的框架，但可能无法同时优化样本复杂度和运行时。

Abstract: We study the problem of learning single-index models, where the label $y \in
\mathbb{R}$ depends on the input $\boldsymbol{x} \in \mathbb{R}^d$ only through
an unknown one-dimensional projection $\langle
\boldsymbol{w}_*,\boldsymbol{x}\rangle$. Prior work has shown that under
Gaussian inputs, the statistical and computational complexity of recovering
$\boldsymbol{w}_*$ is governed by the Hermite expansion of the link function.
In this paper, we propose a new perspective: we argue that "spherical
harmonics" -- rather than "Hermite polynomials" -- provide the natural basis
for this problem, as they capture its intrinsic "rotational symmetry". Building
on this insight, we characterize the complexity of learning single-index models
under arbitrary spherically symmetric input distributions. We introduce two
families of estimators -- based on tensor unfolding and online SGD -- that
respectively achieve either optimal sample complexity or optimal runtime, and
argue that estimators achieving both may not exist in general. When specialized
to Gaussian inputs, our theory not only recovers and clarifies existing results
but also reveals new phenomena that had previously been overlooked.

</details>


### [278] [Causal Climate Emulation with Bayesian Filtering](https://arxiv.org/abs/2506.09891)
*Sebastian Hickman,Ilija Trajkovic,Julia Kaltenborn,Francis Pelletier,Alex Archibald,Yaniv Gurwicz,Peer Nowack,David Rolnick,Julien Boussard*

Main category: cs.LG

TL;DR: 提出了一种基于因果表示学习的可解释气候模型模拟器，用于高效模拟气候动态。


<details>
  <summary>Details</summary>
Motivation: 传统气候模型计算成本高，机器学习虽能快速模拟数据，但缺乏物理因果关系的整合。

Method: 开发了一种基于因果表示学习的模拟器，结合贝叶斯滤波器实现稳定的长期自回归模拟。

Result: 模拟器能准确学习气候动态，并在合成数据集和实际气候模型数据中验证了其各组件的有效性。

Conclusion: 该方法为高效且物理可解释的气候模拟提供了新途径。

Abstract: Traditional models of climate change use complex systems of coupled equations
to simulate physical processes across the Earth system. These simulations are
highly computationally expensive, limiting our predictions of climate change
and analyses of its causes and effects. Machine learning has the potential to
quickly emulate data from climate models, but current approaches are not able
to incorporate physics-informed causal relationships. Here, we develop an
interpretable climate model emulator based on causal representation learning.
We derive a physics-informed approach including a Bayesian filter for stable
long-term autoregressive emulation. We demonstrate that our emulator learns
accurate climate dynamics, and we show the importance of each one of its
components on a realistic synthetic dataset and data from two widely deployed
climate models.

</details>


### [279] [A look at adversarial attacks on radio waveforms from discrete latent space](https://arxiv.org/abs/2506.09896)
*Attanasia Garuso,Silvija Kokalj-Filipovic,Yagna Kaasaragadda*

Main category: cs.LG

TL;DR: 该论文研究了VQVAE在对抗攻击下的防御能力，发现其能显著降低攻击效果，并分析了离散潜在空间的特性。


<details>
  <summary>Details</summary>
Motivation: 研究VQVAE在高信噪比射频数据对抗攻击中的抑制能力，探索其在数字调制波形分类中的防御潜力。

Method: 设计保留相位的对抗攻击，比较其与非保留相位攻击的效果，测试VQVAE重建后的分类准确性，并分析潜在空间分布。

Result: VQVAE显著降低了对抗攻击的有效性，且离散潜在空间特性可能有助于攻击检测。

Conclusion: VQVAE在对抗攻击防御中表现出色，其潜在空间特性为攻击检测提供了新思路。

Abstract: Having designed a VQVAE that maps digital radio waveforms into discrete
latent space, and yields a perfectly classifiable reconstruction of the
original data, we here analyze the attack suppressing properties of VQVAE when
an adversarial attack is performed on high-SNR radio-frequency (RF)
data-points. To target amplitude modulations from a subset of digitally
modulated waveform classes, we first create adversarial attacks that preserve
the phase between the in-phase and quadrature component whose values are
adversarially changed. We compare them with adversarial attacks of the same
intensity where phase is not preserved. We test the classification accuracy of
such adversarial examples on a classifier trained to deliver 100% accuracy on
the original data. To assess the ability of VQVAE to suppress the strength of
the attack, we evaluate the classifier accuracy on the reconstructions by VQVAE
of the adversarial datapoints and show that VQVAE substantially decreases the
effectiveness of the attack. We also compare the I/Q plane diagram of the
attacked data, their reconstructions and the original data. Finally, using
multiple methods and metrics, we compare the probability distribution of the
VQVAE latent space with and without attack. Varying the attack strength, we
observe interesting properties of the discrete space, which may help detect the
attacks.

</details>


### [280] ["What are my options?": Explaining RL Agents with Diverse Near-Optimal Alternatives (Extended)](https://arxiv.org/abs/2506.09901)
*Noel Brindise,Vijeth Hebbar,Riya Shah,Cedric Langbort*

Main category: cs.LG

TL;DR: DNA是一种新的可解释强化学习方法，通过生成多样化的近优轨迹选项，帮助人类用户理解代理的决策。


<details>
  <summary>Details</summary>
Motivation: 旨在通过提供多样化的轨迹选项，增强强化学习代理的可解释性，同时为探索和自适应规划提供新可能性。

Method: 利用奖励塑造和局部改进的Q学习问题，求解具有保证ε最优性的多样化策略。

Result: 成功生成具有显著差异的策略选项，并在仿真中验证了其有效性。

Conclusion: DNA不仅提升了可解释性，还为强化学习的探索和规划开辟了新方向。

Abstract: In this work, we provide an extended discussion of a new approach to
explainable Reinforcement Learning called Diverse Near-Optimal Alternatives
(DNA), first proposed at L4DC 2025. DNA seeks a set of reasonable "options" for
trajectory-planning agents, optimizing policies to produce qualitatively
diverse trajectories in Euclidean space. In the spirit of explainability, these
distinct policies are used to "explain" an agent's options in terms of
available trajectory shapes from which a human user may choose. In particular,
DNA applies to value function-based policies on Markov decision processes where
agents are limited to continuous trajectories. Here, we describe DNA, which
uses reward shaping in local, modified Q-learning problems to solve for
distinct policies with guaranteed epsilon-optimality. We show that it
successfully returns qualitatively different policies that constitute
meaningfully different "options" in simulation, including a brief comparison to
related approaches in the stochastic optimization field of Quality Diversity.
Beyond the explanatory motivation, this work opens new possibilities for
exploration and adaptive planning in RL.

</details>


### [281] [Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling](https://arxiv.org/abs/2506.09998)
*Tim Z. Xiao,Johannes Zenn,Zhen Liu,Weiyang Liu,Robert Bamler,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 论文研究了大型语言模型（LLM）在生成概率分布样本时的偏差问题，并提出了一种基于自然语言的拒绝采样方法（VRS）来减少偏差。


<details>
  <summary>Details</summary>
Motivation: LLM在描述概率分布时表现良好，但在生成样本时存在偏差，限制了其在需要可靠随机性的任务中的应用。

Method: 提出Verbalized Rejection Sampling（VRS），通过自然语言提示LLM对样本进行接受或拒绝，减少采样偏差。

Result: VRS显著减少了采样偏差，理论分析表明其在直接采样基础上有所改进。

Conclusion: 研究表明，经典概率工具可以通过自然语言嵌入LLM工作流，提高可靠性，无需修改模型内部或复杂提示设计。

Abstract: Large language models (LLMs) can often accurately describe probability
distributions using natural language, yet they still struggle to generate
faithful samples from them. This mismatch limits their use in tasks requiring
reliable stochasticity, such as Monte Carlo methods, agent-based simulations,
and randomized decision-making. We investigate this gap between knowledge and
sampling in the context of Bernoulli distributions. We introduce Verbalized
Rejection Sampling (VRS), a natural-language adaptation of classical rejection
sampling that prompts the LLM to reason about and accept or reject proposed
samples. Despite relying on the same Bernoulli mechanism internally, VRS
substantially reduces sampling bias across models. We provide theoretical
analysis showing that, under mild assumptions, VRS improves over direct
sampling, with gains attributable to both the algorithm and prompt design. More
broadly, our results show how classical probabilistic tools can be verbalized
and embedded into LLM workflows to improve reliability, without requiring
access to model internals or heavy prompt engineering.

</details>


### [282] [Apollo: A Posteriori Label-Only Membership Inference Attack Towards Machine Unlearning](https://arxiv.org/abs/2506.09923)
*Liou Tang,James Joshi,Ashish Kundu*

Main category: cs.LG

TL;DR: 论文提出了一种新的隐私攻击方法Apollo，针对机器遗忘（MU）场景，仅需访问遗忘模型的标签输出即可推断数据样本是否被遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有针对MU的隐私推断攻击依赖较弱的威胁模型，假设攻击者可访问原始和遗忘模型，限制了其实际可行性。本文旨在提出一种更严格的威胁模型下的攻击方法。

Method: 提出A Posteriori Label-Only Membership Inference Attack（Apollo），仅需标签输出即可推断样本是否被遗忘。

Result: Apollo在仅需较少模型访问权限的情况下，仍能高精度推断遗忘样本的成员状态。

Conclusion: Apollo攻击方法在严格威胁模型下高效，突显了MU场景中的隐私风险。

Abstract: Machine Unlearning (MU) aims to update Machine Learning (ML) models following
requests to remove training samples and their influences on a trained model
efficiently without retraining the original ML model from scratch. While MU
itself has been employed to provide privacy protection and regulatory
compliance, it can also increase the attack surface of the model. Existing
privacy inference attacks towards MU that aim to infer properties of the
unlearned set rely on the weaker threat model that assumes the attacker has
access to both the unlearned model and the original model, limiting their
feasibility toward real-life scenarios. We propose a novel privacy attack, A
Posteriori Label-Only Membership Inference Attack towards MU, Apollo, that
infers whether a data sample has been unlearned, following a strict threat
model where an adversary has access to the label-output of the unlearned model
only. We demonstrate that our proposed attack, while requiring less access to
the target model compared to previous attacks, can achieve relatively high
precision on the membership status of the unlearned samples.

</details>


### [283] [Bayesian Probabilistic Matrix Factorization](https://arxiv.org/abs/2506.09928)
*Ruixuan Xu,Xiangxiang Weng*

Main category: cs.LG

TL;DR: 论文比较了MCMC和VI在PMF中的性能，发现VI收敛更快，MCMC后验估计更准确。


<details>
  <summary>Details</summary>
Motivation: 传统PMF无法高效计算高维积分导致的后验分布，需解决这一问题。

Method: 采用MCMC和VI两种贝叶斯推断方法近似后验分布。

Result: 在MovieLens数据集上，VI收敛更快，MCMC后验估计更准。

Conclusion: VI适合快速收敛场景，MCMC适合需要高精度后验估计的任务。

Abstract: Matrix factorization is a widely used technique in recommendation systems.
Probabilistic Matrix Factorization (PMF) [1] extends traditional matrix
factorization by incorporating probability distributions over latent factors,
allowing for uncertainty quantification. However, computing the posterior
distribution is intractable due to the high-dimensional integral. To address
this, we employ two Bayesian inference methods: Markov Chain Monte Carlo (MCMC)
[2] and Variational Inference (VI) [3] to approximate the posterior. We
evaluate their performance on MovieLens dataset and compare their convergence
speed, predictive accuracy, and computational efficiency. Experimental results
demonstrate that VI offers faster convergence, while MCMC provides more
accurate posterior estimates.

</details>


### [284] [The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability](https://arxiv.org/abs/2506.09940)
*Jiachen Hu,Rui Ai,Han Zhong,Xiaoyu Chen,Liwei Wang,Zhaoran Wang,Zhuoran Yang*

Main category: cs.LG

TL;DR: 论文提出了一种样本高效算法，用于在信息不对称和知识迁移挑战下学习系统动态，并证明其能以O(1/ε²)的样本复杂度学习ε-最优策略。


<details>
  <summary>Details</summary>
Motivation: 信息不对称和知识迁移是多智能体系统中的核心挑战，尤其是在经济学和社会科学中。论文旨在解决这些挑战，探索如何在非独立同分布动作下学习混杂变量并实现知识迁移。

Method: 提出了一种样本高效的算法，基于在线战略交互模型，通过强化学习框架识别系统动态并处理知识迁移问题。

Result: 算法能够准确识别系统动态，并在信息不对称和知识迁移的背景下，以O(1/ε²)的样本复杂度学习ε-最优策略。

Conclusion: 论文证明了在信息不对称和知识迁移的复杂环境中，通过非独立同分布动作学习混杂变量并实现高效知识迁移的可行性。

Abstract: Information asymmetry is a pervasive feature of multi-agent systems,
especially evident in economics and social sciences. In these settings, agents
tailor their actions based on private information to maximize their rewards.
These strategic behaviors often introduce complexities due to confounding
variables. Simultaneously, knowledge transportability poses another significant
challenge, arising from the difficulties of conducting experiments in target
environments. It requires transferring knowledge from environments where
empirical data is more readily available. Against these backdrops, this paper
explores a fundamental question in online learning: Can we employ non-i.i.d.
actions to learn about confounders even when requiring knowledge transfer? We
present a sample-efficient algorithm designed to accurately identify system
dynamics under information asymmetry and to navigate the challenges of
knowledge transfer effectively in reinforcement learning, framed within an
online strategic interaction model. Our method provably achieves learning of an
$\epsilon$-optimal policy with a tight sample complexity of $O(1/\epsilon^2)$.

</details>


### [285] [Canonical Latent Representations in Conditional Diffusion Models](https://arxiv.org/abs/2506.09955)
*Yitao Xu,Tong Zhang,Ehsan Pajouheshgar,Sabine Süsstrunk*

Main category: cs.LG

TL;DR: 论文提出了一种名为CLAReps的潜在表示方法，用于从条件扩散模型（CDMs）中提取类别核心特征，同时去除无关背景信息。基于CLAReps，开发了名为CaDistill的特征蒸馏范式，显著提升了模型的对抗鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: CDMs在生成任务中表现出色，但其建模能力导致类别特征与无关背景信息纠缠，难以提取鲁棒且可解释的表示。

Method: 提出CLAReps方法，提取CDMs中保留核心类别信息的潜在表示，并基于此开发CaDistill特征蒸馏范式。

Result: 实验表明，CaDistill仅需10%的训练数据即可实现强大的对抗鲁棒性和泛化能力。

Conclusion: CDMs不仅能作为图像生成器，还可作为紧凑、可解释的教师模型，推动鲁棒表示学习。

Abstract: Conditional diffusion models (CDMs) have shown impressive performance across
a range of generative tasks. Their ability to model the full data distribution
has opened new avenues for analysis-by-synthesis in downstream discriminative
learning. However, this same modeling capacity causes CDMs to entangle the
class-defining features with irrelevant context, posing challenges to
extracting robust and interpretable representations. To this end, we identify
Canonical LAtent Representations (CLAReps), latent codes whose internal CDM
features preserve essential categorical information while discarding
non-discriminative signals. When decoded, CLAReps produce representative
samples for each class, offering an interpretable and compact summary of the
core class semantics with minimal irrelevant details. Exploiting CLAReps, we
develop a novel diffusion-based feature-distillation paradigm, CaDistill. While
the student has full access to the training set, the CDM as teacher transfers
core class knowledge only via CLAReps, which amounts to merely 10 % of the
training data in size. After training, the student achieves strong adversarial
robustness and generalization ability, focusing more on the class signals
instead of spurious background cues. Our findings suggest that CDMs can serve
not just as image generators but also as compact, interpretable teachers that
can drive robust representation learning.

</details>


### [286] [Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation](https://arxiv.org/abs/2506.09991)
*Xinyu Yang,Yuwei An,Hongyi Liu,Tianqi Chen,Beidi Chen*

Main category: cs.LG

TL;DR: Multiverse是一种新型生成模型，通过MapReduce范式实现并行生成，性能媲美主流AR-LLMs，并提供开源生态系统。


<details>
  <summary>Details</summary>
Motivation: 受AR-LLMs中隐式并行性的启发，开发一种原生支持并行生成的模型，以提高效率和性能。

Method: 采用MapReduce范式，分为Map（任务分解）、Process（并行执行）和Reduce（结果合成）三阶段；设计Multiverse Attention和Multiverse Engine支持并行推理。

Result: Multiverse-32B在3小时微调后，性能与同规模AR-LLMs相当（AIME24/25得分54%/46%），并在相同上下文长度下平均优于AR-LLMs 1.87%。

Conclusion: Multiverse展示了并行生成模型的潜力，提供高效、可扩展的解决方案，并开源了完整生态系统。

Abstract: Autoregressive Large Language Models (AR-LLMs) frequently exhibit implicit
parallelism in sequential generation. Inspired by this, we introduce
Multiverse, a new generative model that enables natively parallel generation.
Multiverse internalizes a MapReduce paradigm, generating automatically through
three stages: (i) a Map stage for adaptive task decomposition, (ii) a Process
stage for parallel subtask execution, and (iii) a Reduce stage for lossless
result synthesis. Next, we build a real-world Multiverse reasoning model with
co-design of data, algorithm, and system, enabling rapid and seamless transfer
from frontier AR-LLMs. Starting from sequential reasoning chains, we create
Multiverse 1K by converting them into structured training data using an
automated LLM-assisted pipeline, avoiding costly human annotations.
Algorithmically, we design Multiverse Attention to separate parallel reasoning
steps while keeping compatibility with causal attention for efficient training.
Systematically, we implement Multiverse Engine to enable parallel inference. It
features a dedicated scheduler that dynamically switches between sequential and
parallel generation, triggered directly by the model. After a 3-hour
fine-tuning with 1K examples, our Multiverse-32B stands as the only
open-sourced non-AR model achieving performance on par with leading AR-LLMs of
the same scale, evidenced by AIME24 & 25 scores of 54% and 46%, respectively.
Moreover, our budget control experiments show that Multiverse-32B exhibits
superior scaling, outperforming AR-LLMs by 1.87% on average using the same
context length. Such scaling further leads to practical efficiency gain,
achieving up to 2x speedup across varying batch sizes. We have open-sourced the
entire Multiverse ecosystem, including data, model weights, engine, supporting
tools, as well as complete data curation prompts and detailed training and
evaluation recipes.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [287] [Intelligent System of Emergent Knowledge: A Coordination Fabric for Billions of Minds](https://arxiv.org/abs/2506.09335)
*Moshi Wei,Sparks Li*

Main category: cs.MA

TL;DR: ISEK是一个去中心化网络，结合人类与人工智能代理，通过Web3基础设施实现自我组织的认知生态系统。


<details>
  <summary>Details</summary>
Motivation: 旨在打破中心化平台的限制，促进大规模去中心化认知系统的有机发展。

Method: 采用六阶段工作流程（发布、发现、招募、执行、结算、反馈）和分布式共识机制，结合多维声誉系统和$ISEK代币激励。

Result: 实现了抗审查的协作网络，支持自主代理的集体智能进化。

Conclusion: ISEK通过区块链、AI和激励机制的结合，推动了去中心化认知系统的范式转变。

Abstract: The Intelligent System of Emergent Knowledge (ISEK) establishes a
decentralized network where human and artificial intelligence agents
collaborate as peers, forming a self-organizing cognitive ecosystem. Built on
Web3 infrastructure, ISEK combines three fundamental principles: (1) a
decentralized multi-agent architecture resistant to censorship, (2) symbiotic
AI-human collaboration with equal participation rights, and (3) resilient
self-adaptation through distributed consensus mechanisms.
  The system implements an innovative coordination protocol featuring a
six-phase workflow (Publish, Discover, Recruit, Execute, Settle, Feedback) for
dynamic task allocation, supported by robust fault tolerance and a
multidimensional reputation system. Economic incentives are governed by the
native $ISEK token, facilitating micropayments, governance participation, and
reputation tracking, while agent sovereignty is maintained through NFT-based
identity management.
  This synthesis of blockchain technology, artificial intelligence, and
incentive engineering creates an infrastructure that actively facilitates
emergent intelligence. ISEK represents a paradigm shift from conventional
platforms, enabling the organic development of large-scale, decentralized
cognitive systems where autonomous agents collectively evolve beyond
centralized constraints.

</details>


### [288] [When Is Diversity Rewarded in Cooperative Multi-Agent Learning?](https://arxiv.org/abs/2506.09434)
*Michael Amir,Matteo Bettini,Amanda Prorok*

Main category: cs.MA

TL;DR: 论文研究了多智能体任务分配问题中，异质性团队何时优于同质性团队，通过奖励设计理论分析，并提出了Heterogeneous Environment Design (HED)算法验证理论。


<details>
  <summary>Details</summary>
Motivation: 团队在机器人、自然和社会中的成功常依赖于多样化的分工，但缺乏对异质性团队优势的合理解释。

Method: 通过广义聚合算子分析奖励设计，提出HED算法优化多智能体强化学习环境参数。

Result: 理论预测的奖励机制在实验中验证了异质性的优势，HED算法有效。

Conclusion: 研究揭示了行为多样性何时带来可衡量的优势，为奖励设计提供了理论支持。

Abstract: The success of teams in robotics, nature, and society often depends on the
division of labor among diverse specialists; however, a principled explanation
for when such diversity surpasses a homogeneous team is still missing. Focusing
on multi-agent task allocation problems, our goal is to study this question
from the perspective of reward design: what kinds of objectives are best suited
for heterogeneous teams? We first consider an instantaneous, non-spatial
setting where the global reward is built by two generalized aggregation
operators: an inner operator that maps the $N$ agents' effort allocations on
individual tasks to a task score, and an outer operator that merges the $M$
task scores into the global team reward. We prove that the curvature of these
operators determines whether heterogeneity can increase reward, and that for
broad reward families this collapses to a simple convexity test. Next, we ask
what incentivizes heterogeneity to emerge when embodied, time-extended agents
must learn an effort allocation policy. To study heterogeneity in such
settings, we use multi-agent reinforcement learning (MARL) as our computational
paradigm, and introduce Heterogeneous Environment Design (HED), a
gradient-based algorithm that optimizes the parameter space of underspecified
MARL environments to find scenarios where heterogeneity is advantageous.
Experiments in matrix games and an embodied Multi-Goal-Capture environment show
that, despite the difference in settings, HED rediscovers the reward regimes
predicted by our theory to maximize the advantage of heterogeneity, both
validating HED and connecting our theoretical insights to reward design in
MARL. Together, these results help us understand when behavioral diversity
delivers a measurable benefit.

</details>


### [289] [Effective Red-Teaming of Policy-Adherent Agents](https://arxiv.org/abs/2506.09600)
*Itay Nakash,George Kour,Koren Lazar,Matan Vetzler,Guy Uziel,Ateret Anaby-Tavor*

Main category: cs.MA

TL;DR: 论文提出了一种针对任务导向LLM代理的威胁模型，并开发了CRAFT多代理红队系统，用于测试代理在客户服务场景中的政策遵循能力。同时，提出了tau-break基准和防御策略，但现有防御措施仍不足。


<details>
  <summary>Details</summary>
Motivation: 在严格政策领域中，确保LLM代理始终遵循规则并拒绝违规请求，同时保持自然交互，是一个重要挑战。

Method: 提出了CRAFT多代理红队系统，使用政策感知策略测试代理的鲁棒性，并引入tau-break基准评估代理对抗操纵行为的能力。

Result: CRAFT在客户服务场景中优于传统越狱方法，但现有防御策略仍不足以完全保护代理。

Conclusion: 需要更强有力的研究驱动保护措施，以应对对抗性攻击。

Abstract: Task-oriented LLM-based agents are increasingly used in domains with strict
policies, such as refund eligibility or cancellation rules. The challenge lies
in ensuring that the agent consistently adheres to these rules and policies,
appropriately refusing any request that would violate them, while still
maintaining a helpful and natural interaction. This calls for the development
of tailored design and evaluation methodologies to ensure agent resilience
against malicious user behavior. We propose a novel threat model that focuses
on adversarial users aiming to exploit policy-adherent agents for personal
benefit. To address this, we present CRAFT, a multi-agent red-teaming system
that leverages policy-aware persuasive strategies to undermine a
policy-adherent agent in a customer-service scenario, outperforming
conventional jailbreak methods such as DAN prompts, emotional manipulation, and
coercive. Building upon the existing tau-bench benchmark, we introduce
tau-break, a complementary benchmark designed to rigorously assess the agent's
robustness against manipulative user behavior. Finally, we evaluate several
straightforward yet effective defense strategies. While these measures provide
some protection, they fall short, highlighting the need for stronger,
research-driven safeguards to protect policy-adherent agents from adversarial
attacks

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [290] [Dynamic Sub-region Search in Homogeneous Collections Using CLIP](https://arxiv.org/abs/2506.09506)
*Bastian Jäckl,Vojtěch Kloda,Daniel A. Keim,Jakub Lokoč*

Main category: cs.MM

TL;DR: 论文探讨了在特定领域图像集合中，通过补充位置信息改进文本查询的召回率，提出动态图像分区方法，并评估其性能与局限性。


<details>
  <summary>Details</summary>
Motivation: 用户在高度同质的特定领域图像集合中难以提供描述性文本查询，导致召回率低，研究旨在通过位置信息提升查询效果。

Method: 提出动态图像分区方法，允许用户指定感兴趣区域，并将位置约束整合到语义搜索模型中，与静态分区方法对比。

Result: 动态搜索模型的检索性能可达静态分区的两倍，但对查询位置扰动高度敏感。

Conclusion: 动态分区方法在提升召回率方面具有潜力，但需解决位置敏感性问题。

Abstract: Querying with text-image-based search engines in highly homogeneous
domain-specific image collections is challenging for users, as they often
struggle to provide descriptive text queries. For example, in an underwater
domain, users can usually characterize entities only with abstract labels, such
as corals and fish, which leads to low recall rates. Our work investigates
whether recall can be improved by supplementing text queries with position
information. Specifically, we explore dynamic image partitioning approaches
that divide candidates into semantically meaningful regions of interest.
Instead of querying entire images, users can specify regions they recognize.
This enables the use of position constraints while preserving the semantic
capabilities of multimodal models. We introduce and evaluate strategies for
integrating position constraints into semantic search models and compare them
against static partitioning approaches. Our evaluation highlights both the
potential and the limitations of sub-region-based search methods using dynamic
partitioning. Dynamic search models achieve up to double the retrieval
performance compared to static partitioning approaches but are highly sensitive
to perturbations in the specified query positions.

</details>


### [291] [Learning Quality from Complexity and Structure: A Feature-Fused XGBoost Model for Video Quality Assessment](https://arxiv.org/abs/2506.09795)
*Amritha Premkumar,Prajit T Rajendran,Vignesh V Menon*

Main category: cs.MM

TL;DR: 提出了一种基于低复杂度特征和结构信息的视频质量评估方法，无需深度学习即可实现高效预测。


<details>
  <summary>Details</summary>
Motivation: 解决视频质量评估中高效且轻量化的需求，适用于实时流媒体场景。

Method: 结合VCA提取时空特征和SSIM计算结构特征，通过XGBoost回归模型预测质量分数。

Result: 在挑战数据集上表现优异，计算开销低且泛化能力强。

Conclusion: 该方法适用于实时视频质量监控和自适应编码，具有实际应用价值。

Abstract: This paper presents a novel approach for reduced-reference video quality
assessment (VQA), developed as part of the recent VQA Grand Challenge. Our
method leverages low-level complexity and structural information from reference
and test videos to predict perceptual quality scores. Specifically, we extract
spatio-temporal features using Video Complexity Analyzer (VCA) and compute SSIM
values from the test video to capture both texture and structural
characteristics. These features are aggregated through temporal pooling, and
residual features are calculated by comparing the original and distorted
feature sets. The combined features are used to train an XGBoost regression
model that estimates the overall video quality. The pipeline is fully
automated, interpretable, and highly scalable, requiring no deep neural
networks or GPU inference. Experimental results on the challenge dataset
demonstrate that our proposed method achieves competitive correlation with
subjective quality scores while maintaining a low computational footprint. The
model's lightweight design and strong generalization performance suit real-time
streaming quality monitoring and adaptive encoding scenarios.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [292] [WD-DETR: Wavelet Denoising-Enhanced Real-Time Object Detection Transformer for Robot Perception with Event Cameras](https://arxiv.org/abs/2506.09098)
*Yangjie Cui,Boyang Gao,Yiwei Zhang,Xin Dong,Jinwu Xiang,Daochun Li,Zhan Tu*

Main category: cs.RO

TL;DR: 论文提出了一种基于小波去噪的检测变换器（WD-DETR）网络，用于事件相机的目标检测，解决了密集事件表示中的噪声问题，并在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 密集事件表示中的累积噪声影响了检测性能，现有方法对此关注不足。

Method: 提出WD-DETR网络，包括密集事件表示、小波去噪方法、基于变换器的目标预测网络，以及动态重组卷积块（DRCB）以减少推理时间。

Result: 在DSEC、Gen1和1Mpx数据集上表现优于现有方法，并在NVIDIA Jetson Orin NX上实现约35 FPS的高帧率。

Conclusion: WD-DETR有效解决了噪声问题，适用于实时机器人感知。

Abstract: Previous studies on event camera sensing have demonstrated certain detection
performance using dense event representations. However, the accumulated noise
in such dense representations has received insufficient attention, which
degrades the representation quality and increases the likelihood of missed
detections. To address this challenge, we propose the Wavelet
Denoising-enhanced DEtection TRansformer, i.e., WD-DETR network, for event
cameras. In particular, a dense event representation is presented first, which
enables real-time reconstruction of events as tensors. Then, a wavelet
transform method is designed to filter noise in the event representations. Such
a method is integrated into the backbone for feature extraction. The extracted
features are subsequently fed into a transformer-based network for object
prediction. To further reduce inference time, we incorporate the Dynamic
Reorganization Convolution Block (DRCB) as a fusion module within the hybrid
encoder. The proposed method has been evaluated on three event-based object
detection datasets, i.e., DSEC, Gen1, and 1Mpx. The results demonstrate that
WD-DETR outperforms tested state-of-the-art methods. Additionally, we implement
our approach on a common onboard computer for robots, the NVIDIA Jetson Orin
NX, achieving a high frame rate of approximately 35 FPS using TensorRT FP16,
which is exceptionally well-suited for real-time perception of onboard robotic
systems.

</details>


### [293] [Hearing the Slide: Acoustic-Guided Constraint Learning for Fast Non-Prehensile Transport](https://arxiv.org/abs/2506.09169)
*Yuemin Mao,Bardienus P. Duisterhof,Moonyoung Lee,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: 论文提出了一种基于声学传感学习摩擦模型的新方法，用于优化非抓取式物体运输中的摩擦约束，显著减少了物体位移。


<details>
  <summary>Details</summary>
Motivation: 现有基于库仑摩擦模型的方法在快速运动中因机械振动而不精确，导致物体滑动或掉落，需要更精确的摩擦约束。

Method: 通过声学传感学习动态摩擦系数模型，并结合优化运动规划器调整摩擦约束。

Result: 实验表明，学习模型比基线库仑模型减少物体位移达86.0%。

Conclusion: 声学传感能有效学习真实摩擦约束，提升运输效率与安全性。

Abstract: Object transport tasks are fundamental in robotic automation, emphasizing the
importance of efficient and secure methods for moving objects. Non-prehensile
transport can significantly improve transport efficiency, as it enables
handling multiple objects simultaneously and accommodating objects unsuitable
for parallel-jaw or suction grasps. Existing approaches incorporate constraints
based on the Coulomb friction model, which is imprecise during fast motions
where inherent mechanical vibrations occur. Imprecise constraints can cause
transported objects to slide or even fall off the tray. To address this
limitation, we propose a novel method to learn a friction model using acoustic
sensing that maps a tray's motion profile to a dynamically conditioned friction
coefficient. This learned model enables an optimization-based motion planner to
adjust the friction constraint at each control step according to the planned
motion at that step. In experiments, we generate time-optimized trajectories
for a UR5e robot to transport various objects with constraints using both the
standard Coulomb friction model and the learned friction model. Results suggest
that the learned friction model reduces object displacement by up to 86.0%
compared to the baseline, highlighting the effectiveness of acoustic sensing in
learning real-world friction constraints.

</details>


### [294] [Towards Full-Scenario Safety Evaluation of Automated Vehicles: A Volume-Based Method](https://arxiv.org/abs/2506.09182)
*Hang Zhou,Chengyuan Ma,Shiyu Shen,Xiaopeng Li*

Main category: cs.RO

TL;DR: 本文提出了一种新的全场景自动驾驶车辆安全评估框架，通过统一模型标准化驾驶场景表示，并采用基于体积的评估方法解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶安全评估方法主要针对简单操作，无法有效评估复杂环境中的高级自动化功能，且依赖高质量自然驾驶数据，计算复杂度高。

Method: 引入统一模型标准化场景表示，提出基于体积的评估方法，量化风险场景比例，并在特定条件下证明安全场景集的凸性。

Result: 实验验证了基于体积的方法的有效性，使用了现有文献中的AV行为模型和实际测试数据校准的六种生产AV模型。

Conclusion: 提出的框架显著降低了评估维度，避免了概率方法的局限性，为全场景AV安全评估提供了可行方案。

Abstract: With the rapid development of automated vehicles (AVs) in recent years,
commercially available AVs are increasingly demonstrating high-level automation
capabilities. However, most existing AV safety evaluation methods are primarily
designed for simple maneuvers such as car-following and lane-changing. While
suitable for basic tests, these methods are insufficient for assessing
high-level automation functions deployed in more complex environments. First,
these methods typically use crash rate as the evaluation metric, whose accuracy
heavily depends on the quality and completeness of naturalistic driving
environment data used to estimate scenario probabilities. Such data is often
difficult and expensive to collect. Second, when applied to diverse scenarios,
these methods suffer from the curse of dimensionality, making large-scale
evaluation computationally intractable. To address these challenges, this paper
proposes a novel framework for full-scenario AV safety evaluation. A unified
model is first introduced to standardize the representation of diverse driving
scenarios. This modeling approach constrains the dimension of most scenarios to
a regular highway setting with three lanes and six surrounding background
vehicles, significantly reducing dimensionality. To further avoid the
limitations of probability-based method, we propose a volume-based evaluation
method that quantifies the proportion of risky scenarios within the entire
scenario space. For car-following scenarios, we prove that the set of safe
scenarios is convex under specific settings, enabling exact volume computation.
Experimental results validate the effectiveness of the proposed volume-based
method using both AV behavior models from existing literature and six
production AV models calibrated from field-test trajectory data in the Ultra-AV
dataset. Code and data will be made publicly available upon acceptance of this
paper.

</details>


### [295] [Perception Characteristics Distance: Measuring Stability and Robustness of Perception System in Dynamic Conditions under a Certain Decision Rule](https://arxiv.org/abs/2506.09217)
*Boyu Jiang,Liang Shi,Zhengzhi Lin,Loren Stowe,Feng Guo*

Main category: cs.RO

TL;DR: 本文提出了一种新的评估指标PCD，用于量化自动驾驶感知系统在不同距离下可靠检测物体的能力，并引入了SensorRainFall数据集以支持研究。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标无法捕捉感知系统输出中的不确定性，尤其是在不同环境条件下（如天气）的性能波动。

Method: 提出Perception Characteristics Distance (PCD)指标，结合SensorRainFall数据集（包含精确距离标注的雨天和晴天场景数据），通过统计分析方法检测置信度方差的变化点。

Result: PCD能够有效捕捉不同天气条件下感知系统的可靠性差异，而传统静态指标无法做到这一点。

Conclusion: PCD为感知性能提供了分布感知的度量标准，支持更安全、更稳健的自动驾驶系统运行，SensorRainFall数据集为评估提供了有价值的基准。

Abstract: The performance of perception systems in autonomous driving systems (ADS) is
strongly influenced by object distance, scene dynamics, and environmental
conditions such as weather. AI-based perception outputs are inherently
stochastic, with variability driven by these external factors, while
traditional evaluation metrics remain static and event-independent, failing to
capture fluctuations in confidence over time. In this work, we introduce the
Perception Characteristics Distance (PCD) -- a novel evaluation metric that
quantifies the farthest distance at which an object can be reliably detected,
incorporating uncertainty in model outputs. To support this, we present the
SensorRainFall dataset, collected on the Virginia Smart Road using a
sensor-equipped vehicle (cameras, radar, LiDAR) under controlled daylight-clear
and daylight-rain scenarios, with precise ground-truth distances to the target
objects. Statistical analysis reveals the presence of change points in the
variance of detection confidence score with distance. By averaging the PCD
values across a range of detection quality thresholds and probabilistic
thresholds, we compute the mean PCD (mPCD), which captures the overall
perception characteristics of a system with respect to detection distance.
Applying state-of-the-art perception models shows that mPCD captures meaningful
reliability differences under varying weather conditions -- differences that
static metrics overlook. PCD provides a principled, distribution-aware measure
of perception performance, supporting safer and more robust ADS operation,
while the SensorRainFall dataset offers a valuable benchmark for evaluation.
The SensorRainFall dataset is publicly available at
https://www.kaggle.com/datasets/datadrivenwheels/sensorrainfall, and the
evaluation code is open-sourced at
https://github.com/datadrivenwheels/PCD_Python.

</details>


### [296] [UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation](https://arxiv.org/abs/2506.09284)
*Yihe Tang,Wenlong Huang,Yingke Wang,Chengshu Li,Roy Yuan,Ruohan Zhang,Jiajun Wu,Li Fei-Fei*

Main category: cs.RO

TL;DR: UAD是一种无监督方法，通过利用基础模型从视觉和语言模型中提取知识，无需人工标注即可生成任务条件化的物体功能模型。


<details>
  <summary>Details</summary>
Motivation: 理解细粒度物体功能对机器人在开放任务指令下操作物体至关重要，但现有方法依赖人工标注或预定义任务集。

Method: UAD结合大型视觉模型和视觉语言模型，自动标注大规模数据集，并训练轻量级任务条件化解码器。

Result: UAD在仿真环境中训练后，能泛化到真实场景和人类活动中，模仿学习策略在少量演示后表现出色。

Conclusion: UAD通过无监督方法显著提升了物体功能预测的泛化能力，为机器人操作提供了新思路。

Abstract: Understanding fine-grained object affordances is imperative for robots to
manipulate objects in unstructured environments given open-ended task
instructions. However, existing methods of visual affordance predictions often
rely on manually annotated data or conditions only on a predefined set of
tasks. We introduce UAD (Unsupervised Affordance Distillation), a method for
distilling affordance knowledge from foundation models into a task-conditioned
affordance model without any manual annotations. By leveraging the
complementary strengths of large vision models and vision-language models, UAD
automatically annotates a large-scale dataset with detailed $<$instruction,
visual affordance$>$ pairs. Training only a lightweight task-conditioned
decoder atop frozen features, UAD exhibits notable generalization to
in-the-wild robotic scenes and to various human activities, despite only being
trained on rendered objects in simulation. Using affordance provided by UAD as
the observation space, we show an imitation learning policy that demonstrates
promising generalization to unseen object instances, object categories, and
even variations in task instructions after training on as few as 10
demonstrations. Project website: https://unsup-affordance.github.io/

</details>


### [297] [SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation via Skill Blending](https://arxiv.org/abs/2506.09366)
*Yuxuan Kuang,Haoran Geng,Amine Elhafsi,Tan-Dzung Do,Pieter Abbeel,Jitendra Malik,Marco Pavone,Yue Wang*

Main category: cs.RO

TL;DR: SkillBlender是一个分层强化学习框架，通过预训练任务无关的原始技能并动态混合，实现多样化的人形机器人运动与操作任务，减少任务特定调优。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要针对每个任务进行繁琐调优，限制了其通用性和可扩展性。

Method: 预训练目标条件的任务无关原始技能，动态混合这些技能完成复杂任务。

Result: 在模拟实验中显著优于基线方法，行为更准确可行。

Conclusion: SkillBlender提供了一种通用且高效的方法，适用于多样化日常任务。

Abstract: Humanoid robots hold significant potential in accomplishing daily tasks
across diverse environments thanks to their flexibility and human-like
morphology. Recent works have made significant progress in humanoid whole-body
control and loco-manipulation leveraging optimal control or reinforcement
learning. However, these methods require tedious task-specific tuning for each
task to achieve satisfactory behaviors, limiting their versatility and
scalability to diverse tasks in daily scenarios. To that end, we introduce
SkillBlender, a novel hierarchical reinforcement learning framework for
versatile humanoid loco-manipulation. SkillBlender first pretrains
goal-conditioned task-agnostic primitive skills, and then dynamically blends
these skills to accomplish complex loco-manipulation tasks with minimal
task-specific reward engineering. We also introduce SkillBench, a parallel,
cross-embodiment, and diverse simulated benchmark containing three embodiments,
four primitive skills, and eight challenging loco-manipulation tasks,
accompanied by a set of scientific evaluation metrics balancing accuracy and
feasibility. Extensive simulated experiments show that our method significantly
outperforms all baselines, while naturally regularizing behaviors to avoid
reward hacking, resulting in more accurate and feasible movements for diverse
loco-manipulation tasks in our daily scenarios. Our code and benchmark will be
open-sourced to the community to facilitate future research. Project page:
https://usc-gvl.github.io/SkillBlender-web/.

</details>


### [298] [Bipedal Balance Control with Whole-body Musculoskeletal Standing and Falling Simulations](https://arxiv.org/abs/2506.09383)
*Chengtian Ma,Yunyue Wei,Chenhui Zuo,Chen Zhang,Yanan Sui*

Main category: cs.RO

TL;DR: 该研究提出了一种层次化控制流程，通过全身肌肉骨骼系统模拟人类平衡，揭示了稳定站立时的时空动态、肌肉损伤对平衡的影响，并验证了髋关节外骨骼辅助在扰动下改善平衡的效果。


<details>
  <summary>Details</summary>
Motivation: 动态平衡研究较多，但静态平衡和跌倒的定量理解有限，需要更深入的研究。

Method: 采用层次化控制流程和全身肌肉骨骼系统模拟人类平衡，分析稳定站立、肌肉损伤及外骨骼辅助的效果。

Result: 揭示了平衡的时空动态，验证了外骨骼辅助能改善平衡并减少肌肉努力，生成了与临床数据一致的跌倒接触模式。

Conclusion: 该研究为理解人类平衡提供了肌肉层面的见解，有助于开发针对平衡障碍的干预措施，并推动人形机器人系统的发展。

Abstract: Balance control is important for human and bipedal robotic systems. While
dynamic balance during locomotion has received considerable attention,
quantitative understanding of static balance and falling remains limited. This
work presents a hierarchical control pipeline for simulating human balance via
a comprehensive whole-body musculoskeletal system. We identified spatiotemporal
dynamics of balancing during stable standing, revealed the impact of muscle
injury on balancing behavior, and generated fall contact patterns that aligned
with clinical data. Furthermore, our simulated hip exoskeleton assistance
demonstrated improvement in balance maintenance and reduced muscle effort under
perturbation. This work offers unique muscle-level insights into human balance
dynamics that are challenging to capture experimentally. It could provide a
foundation for developing targeted interventions for individuals with balance
impairments and support the advancement of humanoid robotic systems.

</details>


### [299] [Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation](https://arxiv.org/abs/2506.09384)
*Chendong Xin,Mingrui Yu,Yongpeng Jiang,Zhefeng Zhang,Xiang Li*

Main category: cs.RO

TL;DR: 该论文研究了从人手到机器人手的运动学重定向问题，提出了一种综合目标函数，并通过实验评估了各因素的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于人手与机器人手之间存在机械差异，完全复现人手运动是不可能的。现有研究缺乏对各重定向目标的实验比较，导致其重要性和有效性不明确。

Method: 提出了一种综合重定向目标函数，整合了近期方法中的关键因素，并通过实验消融研究评估了各因素的重要性。

Result: 实验结果为重定向算法的设计提供了有价值的见解，以提高真实世界灵巧操作的准确性和有效性。

Conclusion: 该研究为设计更准确和有效的重定向算法提供了实验依据，推动了灵巧操作领域的发展。

Abstract: Kinematic retargeting from human hands to robot hands is essential for
transferring dexterity from humans to robots in manipulation teleoperation and
imitation learning. However, due to mechanical differences between human and
robot hands, completely reproducing human motions on robot hands is impossible.
Existing works on retargeting incorporate various optimization objectives,
focusing on different aspects of hand configuration. However, the lack of
experimental comparative studies leaves the significance and effectiveness of
these objectives unclear. This work aims to analyze these retargeting
objectives for dexterous manipulation through extensive real-world comparative
experiments. Specifically, we propose a comprehensive retargeting objective
formulation that integrates intuitively crucial factors appearing in recent
approaches. The significance of each factor is evaluated through experimental
ablation studies on the full objective in kinematic posture retargeting and
real-world teleoperated manipulation tasks. Experimental results and
conclusions provide valuable insights for designing more accurate and effective
retargeting algorithms for real-world dexterous manipulation.

</details>


### [300] [Scoop-and-Toss: Dynamic Object Collection for Quadrupedal Systems](https://arxiv.org/abs/2506.09406)
*Minji Kang,Chanwoo Baek,Yoonsang Lee*

Main category: cs.RO

TL;DR: 提出了一种框架，使四足机器人能够利用腿的敏捷性收集物体，无需额外执行器。


<details>
  <summary>Details</summary>
Motivation: 探索四足机器人如何利用腿部进行动态物体操纵，而不仅仅是静态任务。

Method: 采用分层策略结构，包括两个专家策略（舀取和抛掷、接近物体位置）和一个动态切换的元策略。

Result: 展示了四足机器人腿部在动态物体操纵中的有效性。

Conclusion: 该方法扩展了四足机器人腿部的功能，使其不仅限于运动。

Abstract: Quadruped robots have made significant advances in locomotion, extending
their capabilities from controlled environments to real-world applications.
Beyond movement, recent work has explored loco-manipulation using the legs to
perform tasks such as pressing buttons or opening doors. While these efforts
demonstrate the feasibility of leg-based manipulation, most have focused on
relatively static tasks. In this work, we propose a framework that enables
quadruped robots to collect objects without additional actuators by leveraging
the agility of their legs. By attaching a simple scoop-like add-on to one leg,
the robot can scoop objects and toss them into a collection tray mounted on its
back. Our method employs a hierarchical policy structure comprising two expert
policies-one for scooping and tossing, and one for approaching object
positions-and a meta-policy that dynamically switches between them. The expert
policies are trained separately, followed by meta-policy training for
coordinated multi-object collection. This approach demonstrates how quadruped
legs can be effectively utilized for dynamic object manipulation, expanding
their role beyond locomotion.

</details>


### [301] [Time-Unified Diffusion Policy with Action Discrimination for Robotic Manipulation](https://arxiv.org/abs/2506.09422)
*Ye Niu,Sanping Zhou,Yizhe Li,Ye Den,Le Wang*

Main category: cs.RO

TL;DR: 论文提出了一种时间统一的扩散策略（TUDP），通过结合动作识别能力优化了机器人动作生成的效率和准确性，显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的策略在机器人操作中需要大量时间迭代去噪，且时间变化的去噪过程增加了模型训练难度，导致动作准确性不足。

Method: TUDP构建了时间统一的速度场，并通过动作判别分支提供额外信息，简化了策略学习并加速动作生成。

Result: 在RLBench上，TUDP在多视图和单视图设置下分别达到82.6%和83.8%的最高成功率，且在较少去噪迭代时表现更优。

Conclusion: TUDP通过时间统一的去噪过程和动作判别训练，显著提升了机器人动作生成的效率和准确性，适用于广泛的实际任务。

Abstract: In many complex scenarios, robotic manipulation relies on generative models
to estimate the distribution of multiple successful actions. As the diffusion
model has better training robustness than other generative models, it performs
well in imitation learning through successful robot demonstrations. However,
the diffusion-based policy methods typically require significant time to
iteratively denoise robot actions, which hinders real-time responses in robotic
manipulation. Moreover, existing diffusion policies model a time-varying action
denoising process, whose temporal complexity increases the difficulty of model
training and leads to suboptimal action accuracy. To generate robot actions
efficiently and accurately, we present the Time-Unified Diffusion Policy
(TUDP), which utilizes action recognition capabilities to build a time-unified
denoising process. On the one hand, we build a time-unified velocity field in
action space with additional action discrimination information. By unifying all
timesteps of action denoising, our velocity field reduces the difficulty of
policy learning and speeds up action generation. On the other hand, we propose
an action-wise training method, which introduces an action discrimination
branch to supply additional action discrimination information. Through
action-wise training, the TUDP implicitly learns the ability to discern
successful actions to better denoising accuracy. Our method achieves
state-of-the-art performance on RLBench with the highest success rate of 82.6%
on a multi-view setup and 83.8% on a single-view setup. In particular, when
using fewer denoising iterations, TUDP achieves a more significant improvement
in success rate. Additionally, TUDP can produce accurate actions for a wide
range of real-world tasks.

</details>


### [302] [Design of an innovative robotic surgical instrument for circular stapling](https://arxiv.org/abs/2506.09444)
*Paul Tucan,Nadim Al Hajjar,Calin Vaida,Alexandru Pusca,Tiberiu Antal,Corina Radu,Daniel Jucan,Adrian Pisla,Damien Chablat,Doina Pisla*

Main category: cs.RO

TL;DR: 本文介绍了一种新型机器人圆形吻合器，旨在提高食管癌手术的精确度和减少术后风险。


<details>
  <summary>Details</summary>
Motivation: 食管癌手术传统方法存在精度不足、恢复时间长及并发症多的问题，需要改进。

Method: 设计了一种集成认知机器人的吻合器，通过三个执行器实现运动，并利用运动学分析确保同步。

Result: 吻合器可实现75度弯曲，提高组织对齐和手术精确度。

Conclusion: 新型机器人吻合器有望改善食管癌手术效果，减少并发症。

Abstract: Esophageal cancer remains a highly aggressive malignancy with low survival
rates, requiring advanced surgical interventions like esophagectomy.
Traditional manual techniques, including circular staplers, face challenges
such as limited precision, prolonged recovery times, and complications like
leaks and tissue misalignment. This paper presents a novel robotic circular
stapler designed to enhance the dexterity in confined spaces, improve tissue
alignment, and reduce post-operative risks. Integrated with a cognitive robot
that serves as a surgeon's assistant, the surgical stapler uses three actuators
to perform anvil motion, cutter/stapler motion and allows a 75-degree bending
of the cartridge (distal tip). Kinematic analysis is used to compute the
stapler tip's position, ensuring synchronization with a robotic system.

</details>


### [303] [Adv-BMT: Bidirectional Motion Transformer for Safety-Critical Traffic Scenario Generation](https://arxiv.org/abs/2506.09485)
*Yuxin Liu,Zhenghao Peng,Xuanhao Cui,Bolei Zhou*

Main category: cs.RO

TL;DR: Adv-BMT框架通过双向运动变换器生成多样且真实的对抗性交互，解决了自动驾驶测试中长尾安全关键场景数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中长尾安全关键场景稀缺，限制了自动驾驶系统性能验证的场景测试。

Method: Adv-BMT框架采用双向运动变换器（BMT）逆向预测交通运动，通过两阶段流程（对抗初始化和逆向运动预测）生成碰撞交互。

Result: 实验表明，Adv-BMT生成的碰撞场景质量高，使用增强数据集训练可将碰撞率降低20%。

Conclusion: Adv-BMT无需碰撞数据预训练，能生成真实多样的碰撞交互，显著提升自动驾驶系统测试效果。

Abstract: Scenario-based testing is essential for validating the performance of
autonomous driving (AD) systems. However, such testing is limited by the
scarcity of long-tailed, safety-critical scenarios in existing datasets
collected in the real world. To tackle the data issue, we propose the Adv-BMT
framework, which augments real-world scenarios with diverse and realistic
adversarial interactions. The core component of Adv-BMT is a bidirectional
motion transformer (BMT) model to perform inverse traffic motion predictions,
which takes agent information in the last time step of the scenario as input,
and reconstruct the traffic in the inverse of chronological order until the
initial time step. The Adv-BMT framework is a two-staged pipeline: it first
conducts adversarial initializations and then inverse motion predictions.
Different from previous work, we do not need any collision data for
pretraining, and are able to generate realistic and diverse collision
interactions. Our experimental results validate the quality of generated
collision scenarios by Adv-BMT: training in our augmented dataset would reduce
episode collision rates by 20\% compared to previous work.

</details>


### [304] [DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects](https://arxiv.org/abs/2506.09491)
*Guanghu Xie,Zhiduo Jiang,Yonglong Zhang,Yang Liu,Zongwu Xie,Baoshi Cao,Hong Liu*

Main category: cs.RO

TL;DR: DCIRNet是一种新型多模态深度补全网络，通过融合RGB图像和深度图提升透明和反射物体的深度估计质量。


<details>
  <summary>Details</summary>
Motivation: 透明和反射物体的独特视觉特性（如镜面反射和光传输）导致深度传感器估计不完整或不准确，影响下游视觉任务。

Method: 提出DCIRNet，结合RGB图像和深度图，采用多模态特征融合模块和多阶段监督与深度细化策略。

Result: 在公开数据集上表现优异，抓取成功率提升44%，验证了方法的有效性和泛化能力。

Conclusion: DCIRNet有效解决了透明和反射物体的深度估计问题，显著提升了相关任务的性能。

Abstract: Transparent and reflective objects in everyday environments pose significant
challenges for depth sensors due to their unique visual properties, such as
specular reflections and light transmission. These characteristics often lead
to incomplete or inaccurate depth estimation, which severely impacts downstream
geometry-based vision tasks, including object recognition, scene
reconstruction, and robotic manipulation. To address the issue of missing depth
information in transparent and reflective objects, we propose DCIRNet, a novel
multimodal depth completion network that effectively integrates RGB images and
depth maps to enhance depth estimation quality. Our approach incorporates an
innovative multimodal feature fusion module designed to extract complementary
information between RGB images and incomplete depth maps. Furthermore, we
introduce a multi-stage supervision and depth refinement strategy that
progressively improves depth completion and effectively mitigates the issue of
blurred object boundaries. We integrate our depth completion model into
dexterous grasping frameworks and achieve a $44\%$ improvement in the grasp
success rate for transparent and reflective objects. We conduct extensive
experiments on public datasets, where DCIRNet demonstrates superior
performance. The experimental results validate the effectiveness of our
approach and confirm its strong generalization capability across various
transparent and reflective objects.

</details>


### [305] [Advances on Affordable Hardware Platforms for Human Demonstration Acquisition in Agricultural Applications](https://arxiv.org/abs/2506.09494)
*Alberto San-Miguel-Tello,Gennaro Scarati,Alejandro Hernández,Mario Cavero-Vidal,Aakash Maroti,Néstor García*

Main category: cs.RO

TL;DR: UMI改进为低成本手持夹爪，用于农业场景中的机器人学习示范，通过任务事件提取样本和结合惯性测量与视觉定位，提升轨迹生成可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决农业场景中复杂任务的学习示范问题，减少空闲时间和用户认知负担。

Method: 1. 从连续示范中提取任务事件样本；2. 结合惯性测量和视觉定位（EKF）生成可靠轨迹。

Result: 在水果采摘任务中表现优于默认流程。

Conclusion: UMI改进方法有效提升了农业场景中机器人学习示范的效率和可靠性。

Abstract: This paper presents advances on the Universal Manipulation Interface (UMI), a
low-cost hand-held gripper for robot Learning from Demonstration (LfD), for
complex in-the-wild scenarios found in agricultural settings. The focus is on
improving the acquisition of suitable samples with minimal additional setup.
Firstly, idle times and user's cognitive load are reduced through the
extraction of individual samples from a continuous demonstration considering
task events. Secondly, reliability on the generation of task sample's
trajectories is increased through the combination on-board inertial
measurements and external visual marker localization usage using Extended
Kalman Filtering (EKF). Results are presented for a fruit harvesting task,
outperforming the default pipeline.

</details>


### [306] [Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information](https://arxiv.org/abs/2506.09548)
*Taku Okawara,Kenji Koide,Aoki Takanose,Shuji Oishi,Masashi Yokozuka,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种紧耦合的LiDAR-IMU-腿部里程计方法，通过在线学习腿部运动学模型提升对无特征环境和可变形地形的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决在无特征环境和可变形地形下里程计估计的挑战性问题。

Method: 开发了基于神经网络的腿部运动学模型，结合触觉信息，并在统一因子图上联合优化模型训练和里程计估计。

Result: 在沙地和校园等复杂环境中验证了方法的优越性，优于现有技术。

Conclusion: 该方法通过在线学习和自适应能力，显著提升了里程计的鲁棒性和准确性。

Abstract: In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is
robust to challenging conditions such as featureless environments and
deformable terrains. We developed an online learning-based leg kinematics model
named the neural leg kinematics model, which incorporates tactile information
(foot reaction force) to implicitly express the nonlinear dynamics between
robot feet and the ground. Online training of this model enhances its
adaptability to weight load changes of a robot (e.g., assuming delivery or
transportation tasks) and terrain conditions. According to the \textit{neural
adaptive leg odometry factor} and online uncertainty estimation of the leg
kinematics model-based motion predictions, we jointly solve online training of
this kinematics model and odometry estimation on a unified factor graph to
retain the consistency of both. The proposed method was verified through real
experiments using a quadruped robot in two challenging situations: 1) a sandy
beach, representing an extremely featureless area with a deformable terrain,
and 2) a campus, including multiple featureless areas and terrain types of
asphalt, gravel (deformable terrain), and grass. Experimental results showed
that our odometry estimation incorporating the \textit{neural leg kinematics
model} outperforms state-of-the-art works. Our project page is available for
further details: https://takuokawara.github.io/RAL2025_project_page/

</details>


### [307] [Enhancing Human-Robot Collaboration: A Sim2Real Domain Adaptation Algorithm for Point Cloud Segmentation in Industrial Environments](https://arxiv.org/abs/2506.09552)
*Fatemeh Mohammadi Amin,Darwin G. Caldwell,Hans Wernher van de Venn*

Main category: cs.RO

TL;DR: 论文提出了一种名为FUSION的双流网络架构，结合DGCNN和CNN，用于3D点云数据的Sim2Real域适应，显著提升了语义分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人协作（HRC）中，安全性和操作效率至关重要，而语义分割是实现环境精确理解的关键。由于真实工业标注数据的稀缺，论文提出了一种Sim2Real域适应方法。

Method: 提出了一种双流网络架构（FUSION），结合动态图卷积神经网络（DGCNN）和卷积神经网络（CNN），并加入残差层，用于工业环境的Sim2Real域适应。

Result: 在真实HRC设置和模拟工业点云数据上评估，模型实现了97.76%的分割准确率，性能优于现有方法。

Conclusion: FUSION架构显著提升了语义分割的准确性和鲁棒性，为HRC中的安全性和效率提供了有效解决方案。

Abstract: The robust interpretation of 3D environments is crucial for human-robot
collaboration (HRC) applications, where safety and operational efficiency are
paramount. Semantic segmentation plays a key role in this context by enabling a
precise and detailed understanding of the environment. Considering the intense
data hunger for real-world industrial annotated data essential for effective
semantic segmentation, this paper introduces a pioneering approach in the
Sim2Real domain adaptation for semantic segmentation of 3D point cloud data,
specifically tailored for HRC. Our focus is on developing a network that
robustly transitions from simulated environments to real-world applications,
thereby enhancing its practical utility and impact on a safe HRC.
  In this work, we propose a dual-stream network architecture (FUSION)
combining Dynamic Graph Convolutional Neural Networks (DGCNN) and Convolutional
Neural Networks (CNN) augmented with residual layers as a Sim2Real domain
adaptation algorithm for an industrial environment. The proposed model was
evaluated on real-world HRC setups and simulation industrial point clouds, it
showed increased state-of-the-art performance, achieving a segmentation
accuracy of 97.76%, and superior robustness compared to existing methods.

</details>


### [308] [Integrating Quantized LLMs into Robotics Systems as Edge AI to Leverage their Natural Language Processing Capabilities](https://arxiv.org/abs/2506.09581)
*Miguel Á. González-Santamarta,Francisco J. Rodríguez-Lera,David Sobrín-Hidalgo,Ángel Manuel Guerrero-Higueras,Vicente MatellÁn-Olivera*

Main category: cs.RO

TL;DR: llama_ros是一个工具，用于将量化的大型语言模型（LLMs）集成到ROS 2机器人系统中，提升自然语言处理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在机器人领域的应用潜力巨大，但面临计算效率和内存限制的挑战。

Method: 利用llama.cpp高效运行时引擎，部署量化LLMs于资源受限的机器人环境。

Result: llama_ros成功实现高效运行量化LLMs，提升机器人决策和交互能力。

Conclusion: llama_ros为机器人系统提供了强大的自然语言处理工具，未来可结合其他技术进一步扩展功能。

Abstract: Large Language Models (LLMs) have experienced great advancements in the last
year resulting in an increase of these models in several fields to face natural
language tasks. The integration of these models in robotics can also help to
improve several aspects such as human-robot interaction, navigation, planning
and decision-making. Therefore, this paper introduces llama\_ros, a tool
designed to integrate quantized Large Language Models (LLMs) into robotic
systems using ROS 2. Leveraging llama.cpp, a highly optimized runtime engine,
llama\_ros enables the efficient execution of quantized LLMs as edge artificial
intelligence (AI) in robotics systems with resource-constrained environments,
addressing the challenges of computational efficiency and memory limitations.
By deploying quantized LLMs, llama\_ros empowers robots to leverage the natural
language understanding and generation for enhanced decision-making and
interaction which can be paired with prompt engineering, knowledge graphs,
ontologies or other tools to improve the capabilities of autonomous robots.
Additionally, this paper provides insights into some use cases of using
llama\_ros for planning and explainability in robotics.

</details>


### [309] [VAULT: A Mobile Mapping System for ROS 2-based Autonomous Robots](https://arxiv.org/abs/2506.09583)
*Miguel Á. González-Santamarta,Francisco J. Rodríguez-Lera,Vicente Matellán-Olivera*

Main category: cs.RO

TL;DR: 论文介绍了VAULT原型，一种基于ROS 2的移动测绘系统，结合多种传感器实现室内外鲁棒定位。


<details>
  <summary>Details</summary>
Motivation: 解决农业和林业等户外环境中自主机器人实时定位和一致测绘的挑战。

Method: 结合GNSS、VIO、IMU数据和EKF生成3D里程计，并利用VSLAM提高定位精度。

Result: 开发出能够生成全面3D点云地图的原型系统。

Conclusion: VAULT原型为户外自主移动机器人提供了高精度的定位和测绘解决方案。

Abstract: Localization plays a crucial role in the navigation capabilities of
autonomous robots, and while indoor environments can rely on wheel odometry and
2D LiDAR-based mapping, outdoor settings such as agriculture and forestry,
present unique challenges that necessitate real-time localization and
consistent mapping. Addressing this need, this paper introduces the VAULT
prototype, a ROS 2-based mobile mapping system (MMS) that combines various
sensors to enable robust outdoor and indoor localization. The proposed solution
harnesses the power of Global Navigation Satellite System (GNSS) data,
visual-inertial odometry (VIO), inertial measurement unit (IMU) data, and the
Extended Kalman Filter (EKF) to generate reliable 3D odometry. To further
enhance the localization accuracy, Visual SLAM (VSLAM) is employed, resulting
in the creation of a comprehensive 3D point cloud map. By leveraging these
sensor technologies and advanced algorithms, the prototype offers a
comprehensive solution for outdoor localization in autonomous mobile robots,
enabling them to navigate and map their surroundings with confidence and
precision.

</details>


### [310] [Attention-Based Map Encoding for Learning Generalized Legged Locomotion](https://arxiv.org/abs/2506.09588)
*Junzhe He,Chong Zhang,Fabian Jenelten,Ruben Grandia,Moritz BÄcher,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种基于注意力机制的地图编码方法，结合强化学习训练端到端控制器，实现四足和人形机器人在复杂地形上的动态运动。


<details>
  <summary>Details</summary>
Motivation: 传统模型控制器在复杂地形上表现优秀但难以应对不确定性，而学习型控制器虽鲁棒性高但在稀疏地形上精度不足。混合方法计算量大且受限。

Method: 学习基于机器人本体感知的注意力地图编码，作为端到端控制器的一部分，通过强化学习训练。

Result: 网络学会在动态导航时聚焦可踩踏区域，实现鲁棒性和精确性。控制器在真实世界的多种挑战性场景中表现优异。

Conclusion: 该方法不仅提升了机器人在复杂地形上的运动能力，还提供了对神经网络地形感知的解释方式。

Abstract: Dynamic locomotion of legged robots is a critical yet challenging topic in
expanding the operational range of mobile robots. It requires precise planning
when possible footholds are sparse, robustness against uncertainties and
disturbances, and generalizability across diverse terrains. While traditional
model-based controllers excel at planning on complex terrains, they struggle
with real-world uncertainties. Learning-based controllers offer robustness to
such uncertainties but often lack precision on terrains with sparse steppable
areas. Hybrid methods achieve enhanced robustness on sparse terrains by
combining both methods but are computationally demanding and constrained by the
inherent limitations of model-based planners. To achieve generalized legged
locomotion on diverse terrains while preserving the robustness of
learning-based controllers, this paper proposes to learn an attention-based map
encoding conditioned on robot proprioception, which is trained as part of the
end-to-end controller using reinforcement learning. We show that the network
learns to focus on steppable areas for future footholds when the robot
dynamically navigates diverse and challenging terrains. We synthesize behaviors
that exhibit robustness against uncertainties while enabling precise and agile
traversal of sparse terrains. Additionally, our method offers a way to
interpret the topographical perception of a neural network. We have trained two
controllers for a 12-DoF quadrupedal robot and a 23-DoF humanoid robot
respectively and tested the resulting controllers in the real world under
various challenging indoor and outdoor scenarios, including ones unseen during
training.

</details>


### [311] [Analytic Task Scheduler: Recursive Least Squares Based Method for Continual Learning in Embodied Foundation Models](https://arxiv.org/abs/2506.09623)
*Lipei Xie,Yingxin Li,Huiping Zhuang*

Main category: cs.RO

TL;DR: 论文提出了一种名为ATS的新框架，用于解决具身基础模型中的持续学习问题，避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 具身基础模型在多模态输入下表现出色，但在持续学习新技能时容易遗忘旧技能，即灾难性遗忘问题。

Method: ATS框架包括任务特定模型库和基于递归最小二乘法的分析调度器，动态选择模型并避免参数干扰。

Result: 在真实机器人平台（RM65B）上验证，ATS表现出优异的抗遗忘能力和任务适应性。

Conclusion: ATS是一种高效、可扩展且可部署的解决方案，适用于复杂动态环境中的持续学习。

Abstract: Embodied foundation models are crucial for Artificial Intelligence (AI)
interacting with the physical world by integrating multi-modal inputs, such as
proprioception, vision and language, to understand human intentions and
generate actions to control robots. While these models demonstrate strong
generalization and few-shot learning capabilities, they face significant
challenges in continually acquiring new skills without forgetting previously
learned skills, a problem known as catastrophic forgetting. To address this
issue, we propose the Analytic Task Scheduler (ATS), a novel framework for
continual learning in embodied foundation models. ATS consists of a
task-specific model library, where each model is fine-tuned independently on a
single task, and an analytic scheduler trained using recursive least squares
(RLS) to learn the mapping between language instructions and task-specific
models. This architecture enables accurate task recognition and dynamic model
selection while fundamentally avoiding parameter interference across tasks. The
scheduler updates its parameters incrementally using only statistics
(autocorrelation and cross-correlation matrices), enabling forgetting-resistant
learning without the need to revisit historical data. We validate ATS on a
real-world robot platform (RM65B), demonstrating superior resistance to
forgetting and strong adaptability to task variations. The results highlight
ATS as an effective, scalable, and deployable solution for continual learning
in embodied foundation models operating in complex, dynamic environments. Our
code will be available at
https://github.com/MIAA-Embodied-AI/AnalyticTaskScheduler

</details>


### [312] [R-CARLA: High-Fidelity Sensor Simulations with Interchangeable Dynamics for Autonomous Racing](https://arxiv.org/abs/2506.09629)
*Maurice Brunner,Edoardo Ghignone,Nicolas Baumann,Michele Magno*

Main category: cs.RO

TL;DR: R-CARLA是CARLA模拟器的增强版，支持从感知到控制的全栈测试，通过整合车辆动力学、传感器模拟和数字孪生技术，显著缩小了仿真与现实的差距。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车作为算法测试平台，需要平衡车辆动力学和传感器精度，但现有工具难以兼顾。R-CARLA旨在解决这一矛盾。

Method: R-CARLA通过无缝整合高精度车辆动力学、传感器模拟、NPC对手模拟及数字孪生技术，提供全栈测试环境。

Result: 实验表明，R-CARLA将车辆动力学和传感器模拟的仿真与现实差距分别减少了42%和82%。

Conclusion: R-CARLA为自动驾驶赛车研究提供了更真实的测试环境，显著提升了仿真效果。

Abstract: Autonomous racing has emerged as a crucial testbed for autonomous driving
algorithms, necessitating a simulation environment for both vehicle dynamics
and sensor behavior. Striking the right balance between vehicle dynamics and
sensor accuracy is crucial for pushing vehicles to their performance limits.
However, autonomous racing developers often face a trade-off between accurate
vehicle dynamics and high-fidelity sensor simulations. This paper introduces
R-CARLA, an enhancement of the CARLA simulator that supports holistic
full-stack testing, from perception to control, using a single system. By
seamlessly integrating accurate vehicle dynamics with sensor simulations,
opponents simulation as NPCs, and a pipeline for creating digital twins from
real-world robotic data, R-CARLA empowers researchers to push the boundaries of
autonomous racing development. Furthermore, it is developed using CARLA's rich
suite of sensor simulations. Our results indicate that incorporating the
proposed digital-twin framework into R-CARLA enables more realistic full-stack
testing, demonstrating a significant reduction in the Sim-to-Real gap of car
dynamics simulation by 42% and by 82% in the case of sensor simulation across
various testing scenarios.

</details>


### [313] [Human-robot collaborative transport personalization via Dynamic Movement Primitives and velocity scaling](https://arxiv.org/abs/2506.09697)
*Paolo Franceschi,Andrea Bussolan,Vincenzo Pomponi,Oliver Avram,Stefano Baraldo,Anna Valente*

Main category: cs.RO

TL;DR: 论文提出了一种基于动态运动基元（DMPs）和实时速度调整的个性化轨迹生成方法，用于人机协作任务，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 工业对人机协作的需求增长，需要智能策略规划机器人动作，同时考虑任务约束和人类特定因素（如身高和运动偏好）。

Method: 使用动态运动基元（DMPs）生成个性化轨迹，并结合实时速度调整以适应人类反馈。

Result: 实验表明，DMP生成的轨迹在适应性和用户体验上优于BiTRRT方法，主观和客观评估均支持这一结论。

Conclusion: DMP方法能显著提升人机交互效果和用户体验，适用于工业协作任务。

Abstract: Nowadays, industries are showing a growing interest in human-robot
collaboration, particularly for shared tasks. This requires intelligent
strategies to plan a robot's motions, considering both task constraints and
human-specific factors such as height and movement preferences. This work
introduces a novel approach to generate personalized trajectories using Dynamic
Movement Primitives (DMPs), enhanced with real-time velocity scaling based on
human feedback. The method was rigorously tested in industrial-grade
experiments, focusing on the collaborative transport of an engine cowl lip
section. Comparative analysis between DMP-generated trajectories and a
state-of-the-art motion planner (BiTRRT) highlights their adaptability combined
with velocity scaling. Subjective user feedback further demonstrates a clear
preference for DMP- based interactions. Objective evaluations, including
physiological measurements from brain and skin activity, reinforce these
findings, showcasing the advantages of DMPs in enhancing human-robot
interaction and improving user experience.

</details>


### [314] [Learning to Optimize Package Picking for Large-Scale, Real-World Robot Induction](https://arxiv.org/abs/2506.09765)
*Shuai Li,Azarakhsh Keipour,Sicong Zhao,Srinath Rajagopalan,Charles Swan,Kostas E. Bekris*

Main category: cs.RO

TL;DR: 提出了一种基于机器学习的框架，通过预测调整和优化吸盘选择，显著降低了仓库自动化中的拾取失败率。


<details>
  <summary>Details</summary>
Motivation: 仓库自动化需要提高拾取成功率和操作效率，现有方法主要依赖启发式采样，缺乏数据驱动的优化。

Method: 开发了一个ML框架，用于预测拾取调整和优化吸盘选择，并在模拟环境中集成测试。

Result: 在200万次拾取测试中，拾取失败率降低了20%，优于启发式基线方法。

Conclusion: 该框架在大型仓库自动化中表现出高效性，为数据驱动的拾取优化提供了新思路。

Abstract: Warehouse automation plays a pivotal role in enhancing operational
efficiency, minimizing costs, and improving resilience to workforce
variability. While prior research has demonstrated the potential of machine
learning (ML) models to increase picking success rates in large-scale robotic
fleets by prioritizing high-probability picks and packages, these efforts
primarily focused on predicting success probabilities for picks sampled using
heuristic methods. Limited attention has been given, however, to leveraging
data-driven approaches to directly optimize sampled picks for better
performance at scale. In this study, we propose an ML-based framework that
predicts transform adjustments as well as improving the selection of suction
cups for multi-suction end effectors for sampled picks to enhance their success
probabilities. The framework was integrated and evaluated in test workcells
that resemble the operations of Amazon Robotics' Robot Induction (Robin) fleet,
which is used for package manipulation. Evaluated on over 2 million picks, the
proposed method achieves a 20\% reduction in pick failure rates compared to a
heuristic-based pick sampling baseline, demonstrating its effectiveness in
large-scale warehouse automation scenarios.

</details>


### [315] [Reinforced Refinement with Self-Aware Expansion for End-to-End Autonomous Driving](https://arxiv.org/abs/2506.09800)
*Haochen Liu,Tianyu Li,Haohan Yang,Li Chen,Caojun Wang,Ke Guo,Haochen Tian,Hongchen Li,Hongyang Li,Chen Lv*

Main category: cs.RO

TL;DR: 论文提出了一种名为R2SE的学习框架，通过结合模仿学习和强化学习，优化端到端自动驾驶系统的泛化能力和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于模仿学习（IL）的模型在泛化到复杂场景时表现不佳，且缺乏部署后的纠正反馈；而强化学习（RL）虽能解决复杂场景，但容易过拟合且样本效率低。

Method: R2SE框架包含三个关键组件：1）通用预训练与动态识别失败案例；2）基于RL的残差修正优化；3）自适应策略扩展。

Result: 实验表明，R2SE在闭环仿真和真实数据中显著提升了泛化性、安全性和长期策略鲁棒性。

Conclusion: R2SE通过强化细化与自适应扩展，为可扩展的自动驾驶系统提供了有效解决方案。

Abstract: End-to-end autonomous driving has emerged as a promising paradigm for
directly mapping sensor inputs to planning maneuvers using learning-based
modular integrations. However, existing imitation learning (IL)-based models
suffer from generalization to hard cases, and a lack of corrective feedback
loop under post-deployment. While reinforcement learning (RL) offers a
potential solution to tackle hard cases with optimality, it is often hindered
by overfitting to specific driving cases, resulting in catastrophic forgetting
of generalizable knowledge and sample inefficiency. To overcome these
challenges, we propose Reinforced Refinement with Self-aware Expansion (R2SE),
a novel learning pipeline that constantly refines hard domain while keeping
generalizable driving policy for model-agnostic end-to-end driving systems.
Through reinforcement fine-tuning and policy expansion that facilitates
continuous improvement, R2SE features three key components: 1) Generalist
Pretraining with hard-case allocation trains a generalist imitation learning
(IL) driving system while dynamically identifying failure-prone cases for
targeted refinement; 2) Residual Reinforced Specialist Fine-tuning optimizes
residual corrections using reinforcement learning (RL) to improve performance
in hard case domain while preserving global driving knowledge; 3) Self-aware
Adapter Expansion dynamically integrates specialist policies back into the
generalist model, enhancing continuous performance improvement. Experimental
results in closed-loop simulation and real-world datasets demonstrate
improvements in generalization, safety, and long-horizon policy robustness over
state-of-the-art E2E systems, highlighting the effectiveness of reinforce
refinement for scalable autonomous driving.

</details>


### [316] [Hierarchical Learning-Enhanced MPC for Safe Crowd Navigation with Heterogeneous Constraints](https://arxiv.org/abs/2506.09859)
*Huajian Liu,Yixuan Feng,Wei Dong,Kunpeng Fan,Chao Wang,Yongzhuo Gao*

Main category: cs.RO

TL;DR: 提出了一种新颖的分层框架，用于动态环境中机器人导航，结合图神经网络和强化学习，通过增量动作掩蔽机制和特权学习策略实现端到端训练，显著提升计算效率和训练可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中机器人导航的复杂性和非凸优化问题，减少对高保真模拟环境的依赖。

Method: 使用图神经网络和强化学习估计成本，结合时空路径搜索模块生成参考轨迹，引入增量动作掩蔽机制和特权学习策略。

Result: 在仿真和实际实验中表现出色，达到SOTA性能，计算效率和训练可扩展性显著提升。

Conclusion: 该方法有效解决了动态环境中的局部规划问题，具有实际应用潜力。

Abstract: In this paper, we propose a novel hierarchical framework for robot navigation
in dynamic environments with heterogeneous constraints. Our approach leverages
a graph neural network trained via reinforcement learning (RL) to efficiently
estimate the robot's cost-to-go, formulated as local goal recommendations. A
spatio-temporal path-searching module, which accounts for kinematic
constraints, is then employed to generate a reference trajectory to facilitate
solving the non-convex optimization problem used for explicit constraint
enforcement. More importantly, we introduce an incremental action-masking
mechanism and a privileged learning strategy, enabling end-to-end training of
the proposed planner. Both simulation and real-world experiments demonstrate
that the proposed method effectively addresses local planning in complex
dynamic environments, achieving state-of-the-art (SOTA) performance. Compared
with existing learning-optimization hybrid methods, our approach eliminates the
dependency on high-fidelity simulation environments, offering significant
advantages in computational efficiency and training scalability. The code will
be released as open-source upon acceptance of the paper.

</details>


### [317] [Aucamp: An Underwater Camera-Based Multi-Robot Platform with Low-Cost, Distributed, and Robust Localization](https://arxiv.org/abs/2506.09876)
*Jisheng Xu,Ding Lin,Pangkit Fong,Chongrong Fang,Xiaoming Duan,Jianping He*

Main category: cs.RO

TL;DR: 本文介绍了一种名为Aucamp的水下多机器人平台，具有低成本单目摄像头感知、分布式协议和鲁棒方向控制的特点，用于定位。


<details>
  <summary>Details</summary>
Motivation: 为水下传感器网络提供广泛海洋探索支持。

Method: 利用清晰度特征测量距离，提出单目成像模型，设计分布式更新协议实现全局定位，并提出鲁棒方向控制框架。

Result: 平台能快速从非稳定状态恢复，定位系统稳定且覆盖范围广。

Conclusion: 新平台为水下传感器网络的海洋探索提供了有效支持。

Abstract: This paper introduces an underwater multi-robot platform, named Aucamp,
characterized by cost-effective monocular-camera-based sensing, distributed
protocol and robust orientation control for localization. We utilize the
clarity feature to measure the distance, present the monocular imaging model,
and estimate the position of the target object. We achieve global positioning
in our platform by designing a distributed update protocol. The distributed
algorithm enables the perception process to simultaneously cover a broader
range, and greatly improves the accuracy and robustness of the positioning.
Moreover, the explicit dynamics model of the robot in our platform is obtained,
based on which, we propose a robust orientation control framework. The control
system ensures that the platform maintains a balanced posture for each robot,
thereby ensuring the stability of the localization system. The platform can
swiftly recover from an forced unstable state to a stable horizontal posture.
Additionally, we conduct extensive experiments and application scenarios to
evaluate the performance of our platform. The proposed new platform may provide
support for extensive marine exploration by underwater sensor networks.

</details>


### [318] [From Theory to Practice: Advancing Multi-Robot Path Planning Algorithms and Applications](https://arxiv.org/abs/2506.09914)
*Teng Guo*

Main category: cs.RO

TL;DR: 本文提出可扩展的多机器人路径规划（MRPP）方法，包括理论保证和实用启发式算法，解决了密集和实际场景中的路径规划问题。


<details>
  <summary>Details</summary>
Motivation: MRPP问题在复杂性和工业应用中的重要性推动了研究，需要高效且可扩展的解决方案。

Method: 1. 针对2D网格上的密集MRPP，提出Rubik Table方法，实现接近最优的时间效率。2. 为实际场景设计最优布局和基于拼图的系统。3. 扩展MRPP至Reeds-Shepp机器人，引入运动基元和平滑技术。

Result: Rubik Table方法在理论上设定了新标准，实际测试验证了其在城市驾驶和机器人运输中的有效性。

Conclusion: 本文的方法为MRPP提供了理论和实践上的突破，适用于多种实际应用场景。

Abstract: The labeled MRPP (Multi-Robot Path Planning) problem involves routing robots
from start to goal configurations efficiently while avoiding collisions.
Despite progress in solution quality and runtime, its complexity and industrial
relevance continue to drive research.
  This dissertation introduces scalable MRPP methods with provable guarantees
and practical heuristics. First, we study dense MRPP on 2D grids, relevant to
warehouse and parcel systems. We propose the Rubik Table method, achieving $(1
+ \delta)$-optimal makespan (with $\delta \in (0, 0.5]$) for up to $\frac{m_1
m_2}{2}$ robots, solving large instances efficiently and setting a new
theoretical benchmark.
  Next, we address real-world MRPP. We design optimal layouts for structured
environments (e.g., warehouses, parking systems) and propose a puzzle-based
system for dense, deadlock-free autonomous vehicle parking. We also extend MRPP
to Reeds-Shepp robots, introducing motion primitives and smoothing techniques
to ensure feasible, efficient paths under nonholonomic constraints. Simulations
and real-world tests validate the approach in urban driving and robotic
transport scenarios.

</details>


### [319] [From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models](https://arxiv.org/abs/2506.09930)
*Irving Fang,Juexiao Zhang,Shengbang Tong,Chen Feng*

Main category: cs.RO

TL;DR: 论文提出了一种统一的仿真任务套件，用于评估视觉-语言-动作（VLA）模型的泛化能力，发现VLM预训练虽能提升感知和规划能力，但在动作执行上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型的评估不足，缺乏语言指令的基准测试，且现有基准任务有限，无法全面考察VLM预训练对机器人策略泛化能力的贡献。

Method: 引入包含50个仿真任务的统一测试套件，涵盖语言指令、视觉和物体操作，系统评估多种VLA架构的泛化能力。

Result: VLM骨干网络赋予VLA模型强大的感知和高层规划能力（"良好意图"），但在动作执行上表现不稳定，且微调可能削弱VLM的泛化推理能力。

Conclusion: 发布任务套件和评估代码作为标准化基准，推动研究弥合感知与动作之间的差距。

Abstract: One promise that Vision-Language-Action (VLA) models hold over traditional
imitation learning for robotics is to leverage the broad generalization
capabilities of large Vision-Language Models (VLMs) to produce versatile,
"generalist" robot policies. However, current evaluations of VLAs remain
insufficient. Traditional imitation learning benchmarks are unsuitable due to
the lack of language instructions. Emerging benchmarks for VLAs that
incorporate language often come with limited evaluation tasks and do not intend
to investigate how much VLM pretraining truly contributes to the generalization
capabilities of the downstream robotic policy. Meanwhile, much research relies
on real-world robot setups designed in isolation by different institutions,
which creates a barrier for reproducibility and accessibility. To address this
gap, we introduce a unified probing suite of 50 simulation-based tasks across
10 subcategories spanning language instruction, vision, and objects. We
systematically evaluate several state-of-the-art VLA architectures on this
suite to understand their generalization capability. Our results show that
while VLM backbones endow VLAs with robust perceptual understanding and high
level planning, which we refer to as good intentions, this does not reliably
translate into precise motor execution: when faced with out-of-distribution
observations, policies often exhibit coherent intentions, but falter in action
execution. Moreover, finetuning on action data can erode the original VLM's
generalist reasoning abilities. We release our task suite and evaluation code
to serve as a standardized benchmark for future VLAs and to drive research on
closing the perception-to-action gap. More information, including the source
code, can be found at https://ai4ce.github.io/INT-ACT/

</details>


### [320] [Fluoroscopic Shape and Pose Tracking of Catheters with Custom Radiopaque Markers](https://arxiv.org/abs/2506.09934)
*Jared Lawson,Rohan Chitale,Nabil Simaan*

Main category: cs.RO

TL;DR: 论文提出了一种通过定制不透射线标记物实现微导管形状和姿态同步估计的方法，以减轻医生在脑部血管导航中的感知负担。


<details>
  <summary>Details</summary>
Motivation: 目前脑部血管导航中，医生需要从双平面透视图像中重建和预测导管运动，负担较重。现有导管跟踪方法局限于平面分割或笨重的传感设备，无法用于神经介入中的微导管。

Method: 在导管上布置定制的不透射线标记物，设计标记物排列以减少对标记物跟踪不确定性的敏感性。

Result: 该方法在直径小于2mm的微导管上部署，形状跟踪误差小于1mm，导管旋转误差低于40度。

Conclusion: 该方法可实现双平面成像下导管的自主导航。

Abstract: Safe navigation of steerable and robotic catheters in the cerebral
vasculature requires awareness of the catheters shape and pose. Currently, a
significant perception burden is placed on interventionalists to mentally
reconstruct and predict catheter motions from biplane fluoroscopy images.
Efforts to track these catheters are limited to planar segmentation or bulky
sensing instrumentation, which are incompatible with microcatheters used in
neurointervention. In this work, a catheter is equipped with custom radiopaque
markers arranged to enable simultaneous shape and pose estimation under biplane
fluoroscopy. A design measure is proposed to guide the arrangement of these
markers to minimize sensitivity to marker tracking uncertainty. This approach
was deployed for microcatheters smaller than 2mm OD navigating phantom
vasculature with shape tracking errors less than 1mm and catheter roll errors
below 40 degrees. This work can enable steerable catheters to autonomously
navigate under biplane imaging.

</details>


### [321] [SAFE: Multitask Failure Detection for Vision-Language-Action Models](https://arxiv.org/abs/2506.09937)
*Qiao Gu,Yuanliang Ju,Shengxiang Sun,Igor Gilitschenski,Haruki Nishimura,Masha Itkina,Florian Shkurti*

Main category: cs.RO

TL;DR: 本文提出了一种名为SAFE的多任务失败检测器，用于通用机器人策略（如VLA模型），能够在新任务和环境中泛化检测失败。


<details>
  <summary>Details</summary>
Motivation: 现有失败检测器仅针对特定任务训练和测试，而VLA模型需要泛化能力以应对未见任务和环境。

Method: 分析VLA特征空间，利用其内部特征训练SAFE，预测任务失败的单一标量。

Result: SAFE在模拟和真实环境中测试，表现优于基线，实现最佳准确性和检测时间平衡。

Conclusion: SAFE为通用机器人策略提供了高效的失败检测方案，适用于多种策略架构。

Abstract: While vision-language-action models (VLAs) have shown promising robotic
behaviors across a diverse set of manipulation tasks, they achieve limited
success rates when deployed on novel tasks out-of-the-box. To allow these
policies to safely interact with their environments, we need a failure detector
that gives a timely alert such that the robot can stop, backtrack, or ask for
help. However, existing failure detectors are trained and tested only on one or
a few specific tasks, while VLAs require the detector to generalize and detect
failures also in unseen tasks and novel environments. In this paper, we
introduce the multitask failure detection problem and propose SAFE, a failure
detector for generalist robot policies such as VLAs. We analyze the VLA feature
space and find that VLAs have sufficient high-level knowledge about task
success and failure, which is generic across different tasks. Based on this
insight, we design SAFE to learn from VLA internal features and predict a
single scalar indicating the likelihood of task failure. SAFE is trained on
both successful and failed rollouts, and is evaluated on unseen tasks. SAFE is
compatible with different policy architectures. We test it on OpenVLA, $\pi_0$,
and $\pi_0$-FAST in both simulated and real-world environments extensively. We
compare SAFE with diverse baselines and show that SAFE achieves
state-of-the-art failure detection performance and the best trade-off between
accuracy and detection time using conformal prediction. More qualitative
results can be found at https://vla-safe.github.io/.

</details>


### [322] [Locomotion on Constrained Footholds via Layered Architectures and Model Predictive Control](https://arxiv.org/abs/2506.09979)
*Zachary Olkin,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出一种分层架构，结合无梯度和梯度方法，解决足式机器人实时控制中的非线性、混合和高维问题。


<details>
  <summary>Details</summary>
Motivation: 足式机器人的非线性、混合和高维特性导致实时稳定和最优控制困难。

Method: 分层架构：采样法确定离散变量，平滑MPC处理连续变量。

Result: 在四足和双足机器人上验证，优于启发式方法，计算更快。

Conclusion: 分层方法在最优性和实时性上表现优异。

Abstract: Computing stabilizing and optimal control actions for legged locomotion in
real time is difficult due to the nonlinear, hybrid, and high dimensional
nature of these robots. The hybrid nature of the system introduces a
combination of discrete and continuous variables which causes issues for
numerical optimal control. To address these challenges, we propose a layered
architecture that separates the choice of discrete variables and a smooth Model
Predictive Controller (MPC). The layered formulation allows for online
flexibility and optimality without sacrificing real-time performance through a
combination of gradient-free and gradient-based methods. The architecture
leverages a sampling-based method for determining discrete variables, and a
classical smooth MPC formulation using these fixed discrete variables. We
demonstrate the results on a quadrupedal robot stepping over gaps and onto
terrain with varying heights. In simulation, we demonstrate the controller on a
humanoid robot for gap traversal. The layered approach is shown to be more
optimal and reliable than common heuristic-based approaches and faster to
compute than pure sampling methods.

</details>


### [323] [Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation](https://arxiv.org/abs/2506.09990)
*Wenbo Zhang,Tianrun Hu,Yanyuan Qiao,Hanbo Zhang,Yuchu Qin,Yang Li,Jiajun Liu,Tao Kong,Lingqiao Liu,Xiao Ma*

Main category: cs.RO

TL;DR: Chain-of-Action (CoA) 是一种基于轨迹自回归建模的新型视觉运动策略范式，通过反向推理生成完整轨迹，实现全局到局部的动作约束。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅正向预测下一步动作，而 CoA 通过反向推理和任务目标驱动的动作级 Chain-of-Thought 过程，提升动作生成的全局一致性。

Method: CoA 采用自回归结构，首先生成任务目标的关键帧动作，随后自回归生成后续动作。设计了连续动作表示、动态停止、反向时间集成和多令牌预测等技术。

Result: CoA 在 60 个 RLBench 任务和 8 个真实世界操作任务中达到最先进性能。

Conclusion: CoA 在保持视觉运动策略灵活性的同时，实现了强大的空间泛化能力。

Abstract: We present Chain-of-Action (CoA), a novel visuo-motor policy paradigm built
upon Trajectory Autoregressive Modeling. Unlike conventional approaches that
predict next step action(s) forward, CoA generates an entire trajectory by
explicit backward reasoning with task-specific goals through an action-level
Chain-of-Thought (CoT) process. This process is unified within a single
autoregressive structure: (1) the first token corresponds to a stable keyframe
action that encodes the task-specific goals; and (2) subsequent action tokens
are generated autoregressively, conditioned on the initial keyframe and
previously predicted actions. This backward action reasoning enforces a
global-to-local structure, allowing each local action to be tightly constrained
by the final goal. To further realize the action reasoning structure, CoA
incorporates four complementary designs: continuous action token
representation; dynamic stopping for variable-length trajectory generation;
reverse temporal ensemble; and multi-token prediction to balance action chunk
modeling with global structure. As a result, CoA gives strong spatial
generalization capabilities while preserving the flexibility and simplicity of
a visuo-motor policy. Empirically, we observe CoA achieves the state-of-the-art
performance across 60 RLBench tasks and 8 real-world manipulation tasks.

</details>


### [324] [eFlesh: Highly customizable Magnetic Touch Sensing using Cut-Cell Microstructures](https://arxiv.org/abs/2506.09994)
*Venkatesh Pattabiraman,Zizhou Huang,Daniele Panozzo,Denis Zorin,Lerrel Pinto,Raunaq Bhirangi*

Main category: cs.RO

TL;DR: 论文介绍了一种低成本、易定制化的磁性触觉传感器eFlesh，填补了机器人操作中缺乏通用触觉传感器的空白。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在非结构化环境中感知物理交互的力，但现有触觉传感器缺乏通用性和可定制性，导致解决方案碎片化。

Method: eFlesh传感器由3D打印、现成磁铁、CAD模型和磁力计电路板组成，通过模块化设计实现几何和机械响应的调整。

Result: 实验显示，eFlesh在接触定位和力预测方面表现优异，并提高了机器人操作的准确性和成功率。

Conclusion: eFlesh为机器人操作提供了一种低成本、易定制的触觉传感器解决方案，并开源了设计工具和代码。

Abstract: If human experience is any guide, operating effectively in unstructured
environments -- like homes and offices -- requires robots to sense the forces
during physical interaction. Yet, the lack of a versatile, accessible, and
easily customizable tactile sensor has led to fragmented, sensor-specific
solutions in robotic manipulation -- and in many cases, to force-unaware,
sensorless approaches. With eFlesh, we bridge this gap by introducing a
magnetic tactile sensor that is low-cost, easy to fabricate, and highly
customizable. Building an eFlesh sensor requires only four components: a
hobbyist 3D printer, off-the-shelf magnets (<$5), a CAD model of the desired
shape, and a magnetometer circuit board. The sensor is constructed from tiled,
parameterized microstructures, which allow for tuning the sensor's geometry and
its mechanical response. We provide an open-source design tool that converts
convex OBJ/STL files into 3D-printable STLs for fabrication. This modular
design framework enables users to create application-specific sensors, and to
adjust sensitivity depending on the task. Our sensor characterization
experiments demonstrate the capabilities of eFlesh: contact localization RMSE
of 0.5 mm, and force prediction RMSE of 0.27 N for normal force and 0.12 N for
shear force. We also present a learned slip detection model that generalizes to
unseen objects with 95% accuracy, and visuotactile control policies that
improve manipulation performance by 40% over vision-only baselines -- achieving
91% average success rate for four precise tasks that require sub-mm accuracy
for successful completion. All design files, code and the CAD-to-eFlesh STL
conversion tool are open-sourced and available on https://e-flesh.com.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [325] [Incorporating Linguistic Constraints from External Knowledge Source for Audio-Visual Target Speech Extraction](https://arxiv.org/abs/2506.09792)
*Wenxuan Wu,Shuai Wang,Xixin Wu,Helen Meng,Haizhou Li*

Main category: cs.SD

TL;DR: 论文提出利用预训练的语音-语言模型（PSLMs）和语言模型（PLMs）的辅助知识，为音频-视觉目标说话人提取（AV-TSE）模型提供额外的监督信号，从而提升语音质量和可懂度。


<details>
  <summary>Details</summary>
Motivation: 人类在语音感知中会利用语言知识（如语法和语义），因此研究探索了PSLMs和PLMs作为AV-TSE的辅助知识来源的潜力。

Method: 将PSLMs或PLMs的语言约束作为额外监督信号引入AV-TSE模型，无需在推理阶段增加计算成本。

Result: 该方法在语音质量和可懂度上表现一致提升，并在多语言和视觉线索受损场景中展现出鲁棒性能增益。

Conclusion: 研究表明，利用预训练语言模型的辅助知识可以有效提升AV-TSE模型的性能，且无需额外推理成本。

Abstract: Audio-visual target speaker extraction (AV-TSE) models primarily rely on
target visual cues to isolate the target speaker's voice from others. We know
that humans leverage linguistic knowledge, such as syntax and semantics, to
support speech perception. Inspired by this, we explore the potential of
pre-trained speech-language models (PSLMs) and pre-trained language models
(PLMs) as auxiliary knowledge sources for AV-TSE. In this study, we propose
incorporating the linguistic constraints from PSLMs or PLMs for the AV-TSE
model as additional supervision signals. Without introducing any extra
computational cost during inference, the proposed approach consistently
improves speech quality and intelligibility. Furthermore, we evaluate our
method in multi-language settings and visual cue-impaired scenarios and show
robust performance gains.

</details>


### [326] [Fractional Fourier Sound Synthesis](https://arxiv.org/abs/2506.09189)
*Esteban Gutiérrez,Rodrigo Cádiz,Carlos Sing Long,Frederic Font,Xavier Serra*

Main category: cs.SD

TL;DR: 论文探讨了分数阶傅里叶变换（FrFT）在声音合成中的创新应用，展示了其在音频处理中重新定义时频分析的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用FrFT的分数阶参数，实现时域和频域之间的连续插值，为信号处理提供前所未有的灵活性，并探索其在声音合成中的独特能力。

Method: 方法包括深入分析FrFT的数学原理、历史演变，以及通过实验展示其在新颖声音设计技术（如alpha合成和alpha滤波）中的应用。

Result: 结果表明，FrFT能够通过时频旋转特性产生创新的声音效果，为声音设计师和研究人员提供了新的工具。

Conclusion: 结论认为FrFT是一种变革性工具，能够推动听觉创意的边界。

Abstract: This paper explores the innovative application of the Fractional Fourier
Transform (FrFT) in sound synthesis, highlighting its potential to redefine
time-frequency analysis in audio processing. As an extension of the classical
Fourier Transform, the FrFT introduces fractional order parameters, enabling a
continuous interpolation between time and frequency domains and unlocking
unprecedented flexibility in signal manipulation. Crucially, the FrFT also
opens the possibility of directly synthesizing sounds in the alpha-domain,
providing a unique framework for creating timbral and dynamic characteristics
unattainable through conventional methods. This work delves into the
mathematical principles of the FrFT, its historical evolution, and its
capabilities for synthesizing complex audio textures. Through experimental
analyses, we showcase novel sound design techniques, such as alpha-synthesis
and alpha-filtering, which leverage the FrFT's time-frequency rotation
properties to produce innovative sonic results. The findings affirm the FrFT's
value as a transformative tool for composers, sound designers, and researchers
seeking to push the boundaries of auditory creativity.

</details>


### [327] [SimClass: A Classroom Speech Dataset Generated via Game Engine Simulation For Automatic Speech Recognition Research](https://arxiv.org/abs/2506.09206)
*Ahmed Adel Attia,Jing Liu,Carl Espy-Wilson*

Main category: cs.SD

TL;DR: 论文提出了一种利用游戏引擎合成课堂噪声的方法，并发布了SimClass数据集，包含合成噪声和模拟课堂语音数据，实验证明其接近真实课堂语音。


<details>
  <summary>Details</summary>
Motivation: 大规模课堂语音数据的稀缺限制了教育领域AI语音模型的发展，现有公共数据集有限且缺乏专用噪声语料库。

Method: 使用游戏引擎合成课堂噪声，结合公开儿童语音语料库和YouTube讲座视频生成模拟课堂语音数据。

Result: 实验表明SimClass数据集在干净和嘈杂条件下均能近似真实课堂语音。

Conclusion: SimClass为开发鲁棒的语音识别和增强模型提供了有价值的资源。

Abstract: The scarcity of large-scale classroom speech data has hindered the
development of AI-driven speech models for education. Public classroom datasets
remain limited, and the lack of a dedicated classroom noise corpus prevents the
use of standard data augmentation techniques.
  In this paper, we introduce a scalable methodology for synthesizing classroom
noise using game engines, a framework that extends to other domains. Using this
methodology, we present SimClass, a dataset that includes both a synthesized
classroom noise corpus and a simulated classroom speech dataset. The speech
data is generated by pairing a public children's speech corpus with YouTube
lecture videos to approximate real classroom interactions in clean conditions.
Our experiments on clean and noisy speech demonstrate that SimClass closely
approximates real classroom speech, making it a valuable resource for
developing robust speech recognition and enhancement models.

</details>


### [328] [OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary](https://arxiv.org/abs/2506.09448)
*Yui Sudo,Yusuke Fujita,Atsushi Kojima,Tomoya Mizumoto,Lianbo Liu*

Main category: cs.SD

TL;DR: 该论文提出了一种将上下文偏置（CB）方法与预训练的语音基础模型（OWSM v3.1）结合的方法，显著提高了罕见词的识别准确率，同时保持了模型的整体性能。


<details>
  <summary>Details</summary>
Motivation: 尽管语音基础模型（SFMs）在大规模数据集上表现优异，但对罕见和未见词的识别仍存在困难。现有的上下文偏置方法因缺乏预训练知识而性能较低。

Method: 通过冻结OWSM v3.1的预训练参数，将现有的CB方法与之结合，利用SFMs的嵌入知识实现有效的上下文偏置。

Result: 实验结果显示，该方法在LibriSpeech 100测试集上，偏置词错误率（B-WER）降低了11.6点，整体WER提升了0.9点，实时因子减少了7.5%。

Conclusion: 该方法成功结合了CB与预训练SFMs的优势，显著提升了罕见词识别性能，同时保持了模型的整体效率。

Abstract: Speech foundation models (SFMs), such as Open Whisper-Style Speech Models
(OWSM), are trained on massive datasets to achieve accurate automatic speech
recognition. However, even SFMs struggle to accurately recognize rare and
unseen words. While contextual biasing (CB) is a promising approach to improve
recognition of such words, most CB methods are trained from scratch, resulting
in lower performance than SFMs due to the lack of pre-trained knowledge. This
paper integrates an existing CB method with OWSM v3.1 while freezing its
pre-trained parameters. By leveraging the knowledge embedded in SFMs, the
proposed method enables effective CB while preserving the advantages of SFMs,
even with a small dataset. Experimental results show that the proposed method
improves the biasing word error rate (B-WER) by 11.6 points, resulting in a 0.9
point improvement in the overall WER while reducing the real-time factor by
7.5% compared to the non-biasing baseline on the LibriSpeech 100 test-clean
set.

</details>


### [329] [BemaGANv2: A Tutorial and Comparative Survey of GAN-based Vocoders for Long-Term Audio Generation](https://arxiv.org/abs/2506.09487)
*Taesoo Park,Mungwi Jeong,Mingyu Park,Narae Kim,Junyoung Kim,Mujung Kim,Jisang Yoo,Hoyun Lee,Sanghoon Kim,Soonchul Kwon*

Main category: cs.SD

TL;DR: BemaGANv2是一种基于GAN的高保真音频生成模型，通过引入AMP模块和MED架构改进生成器和判别器，结合MRD提升长时依赖建模能力。


<details>
  <summary>Details</summary>
Motivation: 改进原始BemaGAN架构，提升音频生成的高保真度和长时依赖性。

Method: 生成器采用AMP模块（含Snake激活函数），判别器结合MED和MRD，评估多种配置。

Result: 通过客观指标（FAD、SSIM等）和主观评估（MOS、SMOS）验证模型性能。

Conclusion: BemaGANv2在音频生成中表现优异，提供详细教程和开源代码以促进复现。

Abstract: This paper presents a tutorial-style survey and implementation guide of
BemaGANv2, an advanced GAN-based vocoder designed for high-fidelity and
long-term audio generation. Built upon the original BemaGAN architecture,
BemaGANv2 incorporates major architectural innovations by replacing traditional
ResBlocks in the generator with the Anti-aliased Multi-Periodicity composition
(AMP) module, which internally applies the Snake activation function to better
model periodic structures. In the discriminator framework, we integrate the
Multi-Envelope Discriminator (MED), a novel architecture we originally
proposed, to extract rich temporal envelope features crucial for periodicity
detection. Coupled with the Multi-Resolution Discriminator (MRD), this
combination enables more accurate modeling of long-range dependencies in audio.
We systematically evaluate various discriminator configurations, including MSD
+ MED, MSD + MRD, and MPD + MED + MRD, using objective metrics (FAD, SSIM,
PLCC, MCD) and subjective evaluations (MOS, SMOS). This paper also provides a
comprehensive tutorial on the model architecture, training methodology, and
implementation to promote reproducibility. The code and pre-trained models are
available at: https://github.com/dinhoitt/BemaGANv2.

</details>


### [330] [Training-Free Voice Conversion with Factorized Optimal Transport](https://arxiv.org/abs/2506.09709)
*Alexander Lobashev,Assel Yermekova,Maria Larchenko*

Main category: cs.SD

TL;DR: Factorized MKL-VC是一种无需训练的改进方法，用于kNN-VC流程，仅需5秒参考音频即可实现高质量跨语言语音转换。


<details>
  <summary>Details</summary>
Motivation: 解决kNN-VC在短参考音频下内容保留和鲁棒性不足的问题。

Method: 用因子化的最优传输映射替换kNN回归，基于WavLM嵌入子空间和Monge-Kantorovich线性解。

Result: 在LibriSpeech和FLEURS数据集上表现优于kNN-VC，尤其在跨语言语音转换领域接近FACodec性能。

Conclusion: MKL-VC在短参考音频下显著提升了语音转换的质量和鲁棒性。

Abstract: This paper introduces Factorized MKL-VC, a training-free modification for
kNN-VC pipeline. In contrast with original pipeline, our algorithm performs
high quality any-to-any cross-lingual voice conversion with only 5 second of
reference audio. MKL-VC replaces kNN regression with a factorized optimal
transport map in WavLM embedding subspaces, derived from Monge-Kantorovich
Linear solution. Factorization addresses non-uniform variance across
dimensions, ensuring effective feature transformation. Experiments on
LibriSpeech and FLEURS datasets show MKL-VC significantly improves content
preservation and robustness with short reference audio, outperforming kNN-VC.
MKL-VC achieves performance comparable to FACodec, especially in cross-lingual
voice conversion domain.

</details>


### [331] [UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching](https://arxiv.org/abs/2506.09874)
*Neta Glazer,Aviv Navon,Yael Segal,Aviv Shamsian,Hilit Segev,Asaf Buchnick,Menachem Pirchi,Gil Hetz,Joseph Keshet*

Main category: cs.SD

TL;DR: UmbraTTS是一种基于流匹配的TTS模型，可同时生成语音和环境音频，解决了复杂背景环境中语音合成的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前TTS技术虽能生成高度自然的语音，但在复杂背景环境中的语音合成仍具挑战性。

Method: 提出UmbraTTS模型，结合流匹配技术，通过自监督框架从无标注录音中提取语音、背景音频和文本。

Result: UmbraTTS显著优于现有基线，生成自然、高质量且环境感知的音频。

Conclusion: UmbraTTS为复杂环境中的语音合成提供了有效解决方案，具有广泛的应用潜力。

Abstract: Recent advances in Text-to-Speech (TTS) have enabled highly natural speech
synthesis, yet integrating speech with complex background environments remains
challenging. We introduce UmbraTTS, a flow-matching based TTS model that
jointly generates both speech and environmental audio, conditioned on text and
acoustic context. Our model allows fine-grained control over background volume
and produces diverse, coherent, and context-aware audio scenes. A key challenge
is the lack of data with speech and background audio aligned in natural
context. To overcome the lack of paired training data, we propose a
self-supervised framework that extracts speech, background audio, and
transcripts from unannotated recordings. Extensive evaluations demonstrate that
UmbraTTS significantly outperformed existing baselines, producing natural,
high-quality, environmentally aware audios.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [332] [Graph Attention-based Decentralized Actor-Critic for Dual-Objective Control of Multi-UAV Swarms](https://arxiv.org/abs/2506.09195)
*Haoran Peng,Ying-Jun Angela Zhang*

Main category: eess.SP

TL;DR: 本文提出了一种基于图注意力的分散式行动者-评论者（GADC）方法，用于优化多无人机系统的服务覆盖范围和电池寿命。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多无人机系统中服务覆盖范围最大化与电池寿命延长之间的双重目标优化问题。

Method: 采用图注意力网络处理无人机的局部观测，并开发行动者-双重评论者网络以管理双重策略，同时利用KL散度因子平衡目标间的权衡。

Result: 在理论和实验评估中，GADC表现出优于现有方法的性能，尤其在现实环境中表现突出。

Conclusion: GADC在多无人机系统中实现了服务覆盖和电池寿命的双重优化，具有较高的可扩展性和效率。

Abstract: This research focuses on optimizing multi-UAV systems with dual objectives:
maximizing service coverage as the primary goal while extending battery
lifetime as the secondary objective. We propose a Graph Attention-based
Decentralized Actor-Critic (GADC) to optimize the dual objectives. The proposed
approach leverages a graph attention network to process UAVs' limited local
observation and reduce the dimension of the environment states. Subsequently,
an actor-double-critic network is developed to manage dual policies for joint
objective optimization. The proposed GADC uses a Kullback-Leibler (KL)
divergence factor to balance the tradeoff between coverage performance and
battery lifetime in the multi-UAV system. We assess the scalability and
efficiency of GADC through comprehensive benchmarking against state-of-the-art
methods, considering both theory and experimental aspects. Extensive testing in
both ideal settings and NVIDIA Sionna's realistic ray tracing environment
demonstrates GADC's superior performance.

</details>


### [333] [Estimating Visceral Adiposity from Wrist-Worn Accelerometry](https://arxiv.org/abs/2506.09167)
*James R. Williamson,Andrew Alini,Brian A. Telfer,Adam W. Potter,Karl E. Friedl*

Main category: eess.SP

TL;DR: 研究通过两种方法（特征工程和深度学习）从加速度计数据中估计内脏脂肪组织（VAT），发现其与代谢健康风险密切相关。


<details>
  <summary>Details</summary>
Motivation: 内脏脂肪组织（VAT）是代谢健康和日常身体活动（PA）的关键标志物，过量VAT与2型糖尿病和胰岛素抵抗高度相关。研究旨在探索PA与VAT的关系。

Method: 使用NHANES数据（2011-2014），通过特征工程（基于步态和睡眠动作）和深度学习（24小时连续加速度计数据）两种方法估计VAT。

Result: 结合两种方法的最优估计VAT与真实值的相关性达到r=0.86，表明PA与VAT及代谢健康风险密切相关。

Conclusion: 研究证实PA与VAT存在强关联，进一步支持PA对代谢健康的积极影响。

Abstract: Visceral adipose tissue (VAT) is a key marker of both metabolic health and
habitual physical activity (PA). Excess VAT is highly correlated with type 2
diabetes and insulin resistance. The mechanistic basis for this pathophysiology
relates to overloading the liver with fatty acids. VAT is also a highly labile
fat depot, with increased turnover stimulated by catecholamines during
exercise. VAT can be measured with sophisticated imaging technologies, but can
also be inferred directly from PA. We tested this relationship using National
Health and Nutrition Examination Survey (NHANES) data from 2011-2014, for
individuals aged 20-60 years with 7 days of accelerometry data (n=2,456 men;
2,427 women) [1]. Two approaches were used for estimating VAT from activity.
The first used engineered features based on movements during gait and sleep,
and then ridge regression to map summary statistics of these features into a
VAT estimate. The second approach used deep neural networks trained on 24 hours
of continuous accelerometry. A foundation model first mapped each 10s frame
into a high-dimensional feature vector. A transformer model then mapped each
day's feature vector time series into a VAT estimate, which were averaged over
multiple days. For both approaches, the most accurate estimates were obtained
with the addition of covariate information about subject demographics and body
measurements. The best performance was obtained by combining the two
approaches, resulting in VAT estimates with correlations of r=0.86. These
findings demonstrate a strong relationship between PA and VAT and, by
extension, between PA and metabolic health risks.

</details>


### [334] [Integration of Contrastive Predictive Coding and Spiking Neural Networks](https://arxiv.org/abs/2506.09194)
*Emirhan Bilgiç,Neslihan Serap Şengör,Namık Berk Yalabık,Yavuz Selim İşler,Aykut Görkem Gelen,Rahmi Elibol*

Main category: eess.SP

TL;DR: 研究探讨了对比预测编码（CPC）与脉冲神经网络（SNN）的结合，旨在开发更具生物合理性的预测编码模型。


<details>
  <summary>Details</summary>
Motivation: 结合CPC和SNN，以模拟生物神经系统的计算过程，提升预测编码模型的生物合理性。

Method: 在MNIST数据集上测试提出的模型，处理输入和输出为脉冲信号。

Result: 模型在区分正序和非序样本时表现出高分类率，证明CPC与SNN的有效结合。

Conclusion: 研究表明，SNN不仅可用于分类任务，还能作为编码机制，CPC与SNN的结合具有潜力。

Abstract: This study examines the integration of Contrastive Predictive Coding (CPC)
with Spiking Neural Networks (SNN). While CPC learns the predictive structure
of data to generate meaningful representations, SNN mimics the computational
processes of biological neural systems over time. In this study, the goal is to
develop a predictive coding model with greater biological plausibility by
processing inputs and outputs in a spike-based system. The proposed model was
tested on the MNIST dataset and achieved a high classification rate in
distinguishing positive sequential samples from non-sequential negative
samples. The study demonstrates that CPC can be effectively combined with SNN,
showing that an SNN trained for classification tasks can also function as an
encoding mechanism. Project codes and detailed results can be accessed on our
GitHub page: https://github.com/vnd-ogrenme/ongorusel-kodlama/tree/main/CPC_SNN

</details>


### [335] [AI-Driven SEEG Channel Ranking for Epileptogenic Zone Localization](https://arxiv.org/abs/2506.09255)
*Saeed Hashemi,Genchang Peng,Mehrdad Nourani,Omar Nofal,Jay Harvey*

Main category: eess.SP

TL;DR: 提出了一种基于机器学习的SEEG通道排序方法，结合临床选择和计算发现，用于高效识别癫痫发作相关通道。


<details>
  <summary>Details</summary>
Motivation: 传统SEEG信号人工检查效率低，需自动化方法辅助识别关键通道。

Method: 使用XGBoost分类模型提取发作期特征，结合SHAP评分排序通道，并扩展搜索空间。

Result: 在五例患者数据中验证，表现出高准确性、一致性和可解释性。

Conclusion: 该方法能有效辅助临床决策，扩展可疑癫痫区域的识别范围。

Abstract: Stereo-electroencephalography (SEEG) is an invasive technique to implant
depth electrodes and collect data for pre-surgery evaluation. Visual inspection
of signals recorded from hundreds of channels is time consuming and
inefficient. We propose a machine learning approach to rank the impactful
channels by incorporating clinician's selection and computational finding. A
classification model using XGBoost is trained to learn the discriminative
features of each channel during ictal periods. Then, the SHapley Additive
exPlanations (SHAP) scoring is utilized to rank SEEG channels based on their
contribution to seizures. A channel extension strategy is also incorporated to
expand the search space and identify suspicious epileptogenic zones beyond
those selected by clinicians. For validation, SEEG data for five patients were
analyzed showing promising results in terms of accuracy, consistency, and
explainability.

</details>


### [336] [Cross-Channel Unlabeled Sensing over a Union of Signal Subspaces](https://arxiv.org/abs/2506.09773)
*Taulant Koka,Manolis C. Tsakiris,Benjamín Béjar Haro,Michael Muma*

Main category: eess.SP

TL;DR: 论文扩展了跨通道无标记感知框架，支持更复杂的信号结构（如子空间联合），改进了样本需求量的界限，并在全脑钙成像中验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 解决多通道信号因样本与通道错位（如自由移动生物的全脑钙成像）而难以重建的问题。

Method: 将跨通道无标记感知框架扩展到子空间联合信号，推导更紧的样本需求量界限。

Result: 在样本与通道关联不精确的实际场景中（如全脑钙成像），实现了准确的信号重建。

Conclusion: 该框架能有效处理复杂信号结构，适用于样本与通道错位的实际应用。

Abstract: Cross-channel unlabeled sensing addresses the problem of recovering a
multi-channel signal from measurements that were shuffled across channels. This
work expands the cross-channel unlabeled sensing framework to signals that lie
in a union of subspaces. The extension allows for handling more complex signal
structures and broadens the framework to tasks like compressed sensing. These
mismatches between samples and channels often arise in applications such as
whole-brain calcium imaging of freely moving organisms or multi-target
tracking. We improve over previous models by deriving tighter bounds on the
required number of samples for unique reconstruction, while supporting more
general signal types. The approach is validated through an application in
whole-brain calcium imaging, where organism movements disrupt sample-to-neuron
mappings. This demonstrates the utility of our framework in real-world settings
with imprecise sample-channel associations, achieving accurate signal
reconstruction.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [337] [Empirical and computer-aided robustness analysis of long-step and accelerated methods in smooth convex optimization](https://arxiv.org/abs/2506.09730)
*Pierre Vernimmen,François Glineur*

Main category: math.OC

TL;DR: 论文评估了不同一阶优化方法在梯度计算相对不精确时的鲁棒性，提出了缩短因子改进理论保证，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究梯度计算相对不精确（如梯度压缩）对优化方法的影响，以解决大规模GPU计算中的问题。

Method: 分析了三种方法：恒定步长梯度下降、长步方法和加速方法，提出缩短因子改进理论鲁棒性，并在实验中测试其表现。

Result: 加速方法比预期更鲁棒，缩短因子显著帮助长步方法，所有改进方法在不精确条件下表现良好。

Conclusion: 缩短因子能有效提升优化方法在梯度不精确时的鲁棒性，具有实际应用潜力。

Abstract: This work assesses both empirically and theoretically, using the performance
estimation methodology, how robust different first-order optimization methods
are when subject to relative inexactness in their gradient computations.
Relative inexactness occurs, for example, when compressing the gradient using
fewer bits of information, which happens when dealing with large-scale problems
on GPUs. Three major families of methods are analyzed: constant step gradient
descent, long-step methods, and accelerated methods. The latter two are first
shown to be theoretically not robust to inexactness. Then, a semi-heuristic
shortening factor is introduced to improve their theoretical guarantees. All
methods are subsequently tested on a concrete inexact problem, with two
different types of relative inexactness, and it is observed that both
accelerated methods are much more robust than expected, and that the shortening
factor significantly helps the long-step methods. In the end, all shortened
methods appear to be promising, even in this inexact setting.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [338] [Adaptive event-triggered robust tracking control of soft robots](https://arxiv.org/abs/2506.09523)
*Renjie Ma,Ziyao Qu,Zhijian Hu,Dong Zhao,Marios M. Polycarpou*

Main category: eess.SY

TL;DR: 本文研究了软体机器人在不确定条件下的跟踪控制问题，提出了一种基于事件触发的控制策略，并通过案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其高适应性和灵活性在复杂环境中具有广泛应用潜力，但其控制面临未建模动态和外部干扰等不确定性挑战。

Method: 通过建立新型切换函数和补偿跟踪误差动态，结合反步法和自适应逻辑，设计了一种事件触发控制策略。

Result: 在不同切换函数场景下，证明了统一的有限时间稳定性，并通过软体机器人案例验证了算法的有效性。

Conclusion: 提出的控制算法能有效应对软体机器人的不确定性，为其在复杂环境中的应用提供了理论支持。

Abstract: Soft robots manufactured with flexible materials can be highly compliant and
adaptive to their surroundings, which facilitates their application in areas
such as dexterous manipulation and environmental exploration. This paper aims
at investigating the tracking control problem for soft robots under uncertainty
such as unmodeled dynamics and external disturbance. First, we establish a
novel switching function and design the compensated tracking error dynamics by
virtue of the command filter. Then, based on the backstepping methodology, the
virtual controllers and the adaptive logic estimating the supremum of
uncertainty impacts are developed for synthesizing an event-triggered control
strategy. In addition, the uniformed finite-time stability certification is
derived for different scenarios of the switching function. Finally, we perform
a case study of a soft robot to illustrate the effectiveness of the proposed
control algorithm.

</details>


### [339] [A Survey on the Role of Artificial Intelligence and Machine Learning in 6G-V2X Applications](https://arxiv.org/abs/2506.09512)
*Donglin Wang,Anjie Qiu,Qiuheng Zhou,Hans D. Schotten*

Main category: eess.SY

TL;DR: 本文综述了AI和ML在6G-V2X通信中的最新进展，重点介绍了深度学习、强化学习、生成学习和联邦学习等技术，并探讨了技术挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，AI和ML在优化V2X通信方面展现出巨大潜力，但缺乏系统性总结，本文旨在填补这一空白。

Method: 通过全面回顾近两年的研究，分析AI和ML在6G-V2X中的应用，如资源分配、波束成形、交通管理和安全管理。

Result: AI（尤其是生成学习）显著提升了6G-V2X系统的性能、适应性和智能性。

Conclusion: 本文为研究人员和决策者提供了AI驱动的6G-V2X发展的宝贵见解，并指出了未来的研究方向。

Abstract: The rapid advancement of Vehicle-to-Everything (V2X) communication is
transforming Intelligent Transportation Systems (ITS), with 6G networks
expected to provide ultra-reliable, low-latency, and high-capacity connectivity
for Connected and Autonomous Vehicles (CAVs). Artificial Intelligence (AI) and
Machine Learning (ML) have emerged as key enablers in optimizing V2X
communication by enhancing network management, predictive analytics, security,
and cooperative driving due to their outstanding performance across various
domains, such as natural language processing and computer vision. This survey
comprehensively reviews recent advances in AI and ML models applied to 6G-V2X
communication. It focuses on state-of-the-art techniques, including Deep
Learning (DL), Reinforcement Learning (RL), Generative Learning (GL), and
Federated Learning (FL), with particular emphasis on developments from the past
two years. Notably, AI, especially GL, has shown remarkable progress and
emerging potential in enhancing the performance, adaptability, and intelligence
of 6G-V2X systems. Despite these advances, a systematic summary of recent
research efforts in this area remains lacking, which this survey aims to
address. We analyze their roles in 6G-V2X applications, such as intelligent
resource allocation, beamforming, intelligent traffic management, and security
management. Furthermore, we explore the technical challenges, including
computational complexity, data privacy, and real-time decision-making
constraints, while identifying future research directions for AI-driven 6G-V2X
development. This study aims to provide valuable insights for researchers,
engineers, and policymakers working towards realizing intelligent, AI-powered
V2X ecosystems in 6G communication.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [340] [Abstraction-Based Proof Production in Formal Verification of Neural Networks](https://arxiv.org/abs/2506.09455)
*Yizhak Yisrael Elboher,Omri Isac,Guy Katz,Tobias Ladner,Haoze Wu*

Main category: cs.LO

TL;DR: 提出了一种新的框架，用于支持基于抽象的DNN验证的证明生成，填补了可扩展性与可证明保证之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前基于抽象的DNN验证工具缺乏证明生成能力，导致可扩展性与可靠性之间的脱节。

Method: 将验证任务模块化为两部分：证明抽象网络的正确性，以及证明抽象相对于原始DNN的可靠性。

Result: 初步实现了在形式证明框架内支持常见抽象技术的目标。

Conclusion: 该框架为可扩展且可信赖的DNN验证提供了新的可能性。

Abstract: Modern verification tools for deep neural networks (DNNs) increasingly rely
on abstraction to scale to realistic architectures. In parallel, proof
production is becoming a critical requirement for increasing the reliability of
DNN verification results. However, current proofproducing verifiers do not
support abstraction-based reasoning, creating a gap between scalability and
provable guarantees. We address this gap by introducing a novel framework for
proof-producing abstraction-based DNN verification. Our approach modularly
separates the verification task into two components: (i) proving the
correctness of an abstract network, and (ii) proving the soundness of the
abstraction with respect to the original DNN. The former can be handled by
existing proof-producing verifiers, whereas we propose the first method for
generating formal proofs for the latter. This preliminary work aims to enable
scalable and trustworthy verification by supporting common abstraction
techniques within a formal proof framework.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [341] [Exploring Image Transforms derived from Eye Gaze Variables for Progressive Autism Diagnosis](https://arxiv.org/abs/2506.09065)
*Abigail Copiaco,Christian Ritz,Yassine Himeur,Valsamma Eapen,Ammar Albanna,Wathiq Mansoor*

Main category: eess.IV

TL;DR: 本文提出了一种基于AI的辅助技术，通过眼动变量和图像变换简化ASD诊断和管理，提高效率并保护隐私。


<details>
  <summary>Details</summary>
Motivation: ASD患病率上升，现有诊断方法耗时且成本高，亟需更高效便捷的解决方案。

Method: 结合迁移学习和眼动变量生成的图像变换技术进行ASD诊断。

Result: 实现了家庭定期诊断，减轻了患者和护理者的压力，同时保护隐私。

Conclusion: 该方法提供了及时、便捷的诊断，改善了ASD患者的生活质量。

Abstract: The prevalence of Autism Spectrum Disorder (ASD) has surged rapidly over the
past decade, posing significant challenges in communication, behavior, and
focus for affected individuals. Current diagnostic techniques, though
effective, are time-intensive, leading to high social and economic costs. This
work introduces an AI-powered assistive technology designed to streamline ASD
diagnosis and management, enhancing convenience for individuals with ASD and
efficiency for caregivers and therapists. The system integrates transfer
learning with image transforms derived from eye gaze variables to diagnose ASD.
This facilitates and opens opportunities for in-home periodical diagnosis,
reducing stress for individuals and caregivers, while also preserving user
privacy through the use of image transforms. The accessibility of the proposed
method also offers opportunities for improved communication between guardians
and therapists, ensuring regular updates on progress and evolving support
needs. Overall, the approach proposed in this work ensures timely, accessible
diagnosis while protecting the subjects' privacy, improving outcomes for
individuals with ASD.

</details>


### [342] [Foundation Models in Medical Imaging -- A Review and Outlook](https://arxiv.org/abs/2506.09095)
*Vivien van Veldhuizen,Vanessa Botha,Chunyao Lu,Melis Erdal Cesur,Kevin Groot Lipman,Edwin D. de Jong,Hugo Horlings,Clárisa Sanchez,Cees Snoek,Ritse Mann,Eric Marcus,Jonas Teuwen*

Main category: eess.IV

TL;DR: 本文综述了基础模型（FMs）在医学图像分析中的应用，包括其开发、核心组件及在不同医学领域的应用，并探讨了未来研究的挑战。


<details>
  <summary>Details</summary>
Motivation: FMs通过从大量未标记数据中学习，减少了对人工标注的依赖，为医学图像分析提供了新的方法。

Method: 综述了150多项研究，分析了FMs的模型架构、自监督学习方法及下游任务适配策略。

Result: FMs在病理学、放射学和眼科等领域展现出潜力，但设计选择因应用而异。

Conclusion: FMs为医学图像分析提供了新方向，但仍需解决关键挑战以推动未来发展。

Abstract: Foundation models (FMs) are changing the way medical images are analyzed by
learning from large collections of unlabeled data. Instead of relying on
manually annotated examples, FMs are pre-trained to learn general-purpose
visual features that can later be adapted to specific clinical tasks with
little additional supervision. In this review, we examine how FMs are being
developed and applied in pathology, radiology, and ophthalmology, drawing on
evidence from over 150 studies. We explain the core components of FM pipelines,
including model architectures, self-supervised learning methods, and strategies
for downstream adaptation. We also review how FMs are being used in each
imaging domain and compare design choices across applications. Finally, we
discuss key challenges and open questions to guide future research.

</details>


### [343] [Low-Rank Augmented Implicit Neural Representation for Unsupervised High-Dimensional Quantitative MRI Reconstruction](https://arxiv.org/abs/2506.09100)
*Haonan Zhang,Guoyan Lao,Yuyao Zhang,Hongjiang Wei*

Main category: eess.IV

TL;DR: LoREIN是一种新型无监督双先验集成框架，用于加速3D多参数定量MRI重建，结合低秩和连续性先验以提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 当前重建方法仅依赖单一先验或物理模型，导致高度欠采样、高维测量下的定量MRI重建效果不佳。

Method: LoREIN结合低秩表示（LRR）和隐式神经表示（INR），利用低秩先验和连续性先验增强重建保真度。

Result: 该方法能高保真重建加权图像，并通过多对比加权图像提升定量参数图的重建精度。

Conclusion: LoREIN为零样本学习范式提供了广泛潜力，推动了医学影像领域的发展。

Abstract: Quantitative magnetic resonance imaging (qMRI) provides tissue-specific
parameters vital for clinical diagnosis. Although simultaneous multi-parametric
qMRI (MP-qMRI) technologies enhance imaging efficiency, robustly reconstructing
qMRI from highly undersampled, high-dimensional measurements remains a
significant challenge. This difficulty arises primarily because current
reconstruction methods that rely solely on a single prior or physics-informed
model to solve the highly ill-posed inverse problem, which often leads to
suboptimal results. To overcome this limitation, we propose LoREIN, a novel
unsupervised and dual-prior-integrated framework for accelerated 3D MP-qMRI
reconstruction. Technically, LoREIN incorporates both low-rank prior and
continuity prior via low-rank representation (LRR) and implicit neural
representation (INR), respectively, to enhance reconstruction fidelity. The
powerful continuous representation of INR enables the estimation of optimal
spatial bases within the low-rank subspace, facilitating high-fidelity
reconstruction of weighted images. Simultaneously, the predicted multi-contrast
weighted images provide essential structural and quantitative guidance, further
enhancing the reconstruction accuracy of quantitative parameter maps.
Furthermore, our work introduces a zero-shot learning paradigm with broad
potential in complex spatiotemporal and high-dimensional image reconstruction
tasks, further advancing the field of medical imaging.

</details>


### [344] [An Explainable Deep Learning Framework for Brain Stroke and Tumor Progression via MRI Interpretation](https://arxiv.org/abs/2506.09161)
*Rajan Das Gupta,Md Imrul Hasan Showmick,Mushfiqur Rahman Abir,Shanjida Akter,Md. Yeasin Rahat,Md. Jakir Hossen*

Main category: eess.IV

TL;DR: 论文提出了一种基于深度学习的系统，利用MobileNet V2和ResNet-50模型，通过MRI图像早期准确检测脑肿瘤和中风及其阶段。


<details>
  <summary>Details</summary>
Motivation: 早期准确检测脑部异常（如肿瘤和中风）对及时干预和改善患者预后至关重要。

Method: 采用卷积神经网络（MobileNet V2和ResNet-50），通过迁移学习优化，将MRI扫描分为五类诊断类别。数据集经过精心整理和增强，应用dropout层和数据增强防止过拟合。

Result: 模型表现优异，训练准确率达93%，验证准确率达88%。ResNet-50略优，但MobileNet V2因其轻量级架构适合资源有限环境。

Conclusion: 研究为早期脑部异常检测提供了实用的AI解决方案，具有临床部署潜力，未来可通过更大数据集和多模态输入进一步优化。

Abstract: Early and accurate detection of brain abnormalities, such as tumors and
strokes, is essential for timely intervention and improved patient outcomes. In
this study, we present a deep learning-based system capable of identifying both
brain tumors and strokes from MRI images, along with their respective stages.
We have executed two groundbreaking strategies involving convolutional neural
networks, MobileNet V2 and ResNet-50-optimized through transfer learning to
classify MRI scans into five diagnostic categories. Our dataset, aggregated and
augmented from various publicly available MRI sources, was carefully curated to
ensure class balance and image diversity. To enhance model generalization and
prevent overfitting, we applied dropout layers and extensive data augmentation.
The models achieved strong performance, with training accuracy reaching 93\%
and validation accuracy up to 88\%. While ResNet-50 demonstrated slightly
better results, Mobile Net V2 remains a promising option for real-time
diagnosis in low resource settings due to its lightweight architecture. This
research offers a practical AI-driven solution for early brain abnormality
detection, with potential for clinical deployment and future enhancement
through larger datasets and multi modal inputs.

</details>


### [345] [The RSNA Lumbar Degenerative Imaging Spine Classification (LumbarDISC) Dataset](https://arxiv.org/abs/2506.09162)
*Tyler J. Richards,Adam E. Flanders,Errol Colak,Luciano M. Prevedello,Robyn L. Ball,Felipe Kitamura,John Mongan,Maryam Vazirabad,Hui-Ming Lin,Anne Kendell,Thanat Kanthawang,Salita Angkurawaranon,Emre Altinmakas,Hakan Dogan,Paulo Eduardo de Aguiar Kuriki,Arjuna Somasundaram,Christopher Ruston,Deniz Bulja,Naida Spahovic,Jennifer Sommer,Sirui Jiang,Eduardo Moreno Judice de Mattos Farina,Eduardo Caminha Nunes,Michael Brassil,Megan McNamara,Johanna Ortiz,Jacob Peoples,Vinson L. Uytana,Anthony Kam,Venkata N. S. Dola,Daniel Murphy,David Vu,Dataset Contributor Group,Dataset Annotator Group,Competition Data Notebook Group,Jason F. Talbott*

Main category: eess.IV

TL;DR: RSNA LumbarDISC数据集是最大的公开成人腰椎MRI数据集，用于研究退行性变化，包含2,697名患者的8,593个影像系列，来自全球8个机构。


<details>
  <summary>Details</summary>
Motivation: 促进机器学习和腰椎影像研究，以改善患者护理和临床效率。

Method: 数据集由专家放射科医生标注，用于深度学习模型竞赛，评估腰椎退行性变化。

Result: 数据集免费提供，支持非商业用途，通过Kaggle和RSNA MIRA平台获取。

Conclusion: LumbarDISC数据集为腰椎退行性变化的机器学习研究提供了重要资源。

Abstract: The Radiological Society of North America (RSNA) Lumbar Degenerative Imaging
Spine Classification (LumbarDISC) dataset is the largest publicly available
dataset of adult MRI lumbar spine examinations annotated for degenerative
changes. The dataset includes 2,697 patients with a total of 8,593 image series
from 8 institutions across 6 countries and 5 continents. The dataset is
available for free for non-commercial use via Kaggle and RSNA Medical Imaging
Resource of AI (MIRA). The dataset was created for the RSNA 2024 Lumbar Spine
Degenerative Classification competition where competitors developed deep
learning models to grade degenerative changes in the lumbar spine. The degree
of spinal canal, subarticular recess, and neural foraminal stenosis was graded
at each intervertebral disc level in the lumbar spine. The images were
annotated by expert volunteer neuroradiologists and musculoskeletal
radiologists from the RSNA, American Society of Neuroradiology, and the
American Society of Spine Radiology. This dataset aims to facilitate research
and development in machine learning and lumbar spine imaging to lead to
improved patient care and clinical efficiency.

</details>


### [346] [A Cytology Dataset for Early Detection of Oral Squamous Cell Carcinoma](https://arxiv.org/abs/2506.09661)
*Garima Jain,Sanghamitra Pati,Mona Duggal,Amit Sethi,Abhijeet Patil,Gururaj Malekar,Nilesh Kowe,Jitender Kumar,Jatin Kashyap,Divyajeet Rout,Deepali,Hitesh,Nishi Halduniya,Sharat Kumar,Heena Tabassum,Rupinder Singh Dhaliwal,Sucheta Devi Khuraijam,Sushma Khuraijam,Sharmila Laishram,Simmi Kharb,Sunita Singh,K. Swaminadtan,Ranjana Solanki,Deepika Hemranjani,Shashank Nath Singh,Uma Handa,Manveen Kaur,Surinder Singhal,Shivani Kalhan,Rakesh Kumar Gupta,Ravi. S,D. Pavithra,Sunil Kumar Mahto,Arvind Kumar,Deepali Tirkey,Saurav Banerjee,L. Sreelakshmi*

Main category: eess.IV

TL;DR: 论文介绍了一个大型多中心口腔细胞学数据集，旨在通过人工智能改进口腔鳞状细胞癌（OSCC）的早期诊断。


<details>
  <summary>Details</summary>
Motivation: 传统组织病理学诊断在资源匮乏地区难以普及，而口腔细胞学刷检虽成本低且微创，但存在观察者间变异和专家不足的问题。AI可以解决这些问题，但需要大量标注数据支持。

Method: 研究团队收集了来自印度十个三级医疗中心的PAP和MGG染色口腔细胞学切片，由专家标注用于细胞异常分类和检测。

Result: 该数据集填补了公开口腔细胞学数据的空白，支持开发高泛化能力的AI模型。

Conclusion: 该资源有望提升自动化检测水平，减少诊断错误，改善资源匮乏地区的OSCC早期诊断，降低死亡率。

Abstract: Oral squamous cell carcinoma OSCC is a major global health burden,
particularly in several regions across Asia, Africa, and South America, where
it accounts for a significant proportion of cancer cases. Early detection
dramatically improves outcomes, with stage I cancers achieving up to 90 percent
survival. However, traditional diagnosis based on histopathology has limited
accessibility in low-resource settings because it is invasive,
resource-intensive, and reliant on expert pathologists. On the other hand, oral
cytology of brush biopsy offers a minimally invasive and lower cost
alternative, provided that the remaining challenges, inter observer variability
and unavailability of expert pathologists can be addressed using artificial
intelligence. Development and validation of robust AI solutions requires access
to large, labeled, and multi-source datasets to train high capacity models that
generalize across domain shifts. We introduce the first large and multicenter
oral cytology dataset, comprising annotated slides stained with
Papanicolaou(PAP) and May-Grunwald-Giemsa(MGG) protocols, collected from ten
tertiary medical centers in India. The dataset is labeled and annotated by
expert pathologists for cellular anomaly classification and detection, is
designed to advance AI driven diagnostic methods. By filling the gap in
publicly available oral cytology datasets, this resource aims to enhance
automated detection, reduce diagnostic errors, and improve early OSCC diagnosis
in resource-constrained settings, ultimately contributing to reduced mortality
and better patient outcomes worldwide.

</details>


### [347] [Sampling Theory for Super-Resolution with Implicit Neural Representations](https://arxiv.org/abs/2506.09949)
*Mahrokh Najaf,Gregory Ongie*

Main category: eess.IV

TL;DR: 研究了隐式神经表示（INRs）在解决线性逆问题中的样本复杂度，提出了从低通傅里叶样本中恢复连续域图像的采样要求。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）在计算机视觉和计算成像中表现出强大潜力，但其在逆问题中的样本复杂度尚不明确。

Method: 使用单隐藏层INR（ReLU激活和傅里叶特征层）结合广义权重衰减正则化，将非凸优化问题与无限维空间中的凸惩罚联系起来。

Result: 确定了INR可实现图像精确恢复的足够傅里叶样本数量，并通过实验验证了低宽度INR的恢复概率。

Conclusion: INRs在连续域图像的超分辨率恢复中表现出良好性能，为逆问题提供了理论基础。

Abstract: Implicit neural representations (INRs) have emerged as a powerful tool for
solving inverse problems in computer vision and computational imaging. INRs
represent images as continuous domain functions realized by a neural network
taking spatial coordinates as inputs. However, unlike traditional pixel
representations, little is known about the sample complexity of estimating
images using INRs in the context of linear inverse problems. Towards this end,
we study the sampling requirements for recovery of a continuous domain image
from its low-pass Fourier samples by fitting a single hidden-layer INR with
ReLU activation and a Fourier features layer using a generalized form of weight
decay regularization. Our key insight is to relate minimizers of this
non-convex parameter space optimization problem to minimizers of a convex
penalty defined over an infinite-dimensional space of measures. We identify a
sufficient number of Fourier samples for which an image realized by an INR is
exactly recoverable by solving the INR training problem. To validate our
theory, we empirically assess the probability of achieving exact recovery of
images realized by low-width single hidden-layer INRs, and illustrate the
performance of INRs on super-resolution recovery of continuous domain phantom
images.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [348] [A Topological Improvement of the Overall Performance of Sparse Evolutionary Training: Motif-Based Structural Optimization of Sparse MLPs Project](https://arxiv.org/abs/2506.09204)
*Xiaotian Chen,Hongyun Liu,Seyed Sahand Mohammadi Ziabari*

Main category: cs.NE

TL;DR: 研究探讨了通过结构优化（motif-based optimization）改进稀疏进化训练（SET-MLP）的性能，目标是提升效率超40%且性能下降低于4%。


<details>
  <summary>Details</summary>
Motivation: 随着DNN模型复杂度增加，降低计算成本和内存开销的需求日益迫切，稀疏性成为主流方法。

Method: 采用稀疏多层感知机（MLPs）和稀疏进化训练（SET），结合结构优化方法（motif-based optimization）。

Result: 研究表明SET-MLP通过结构优化可显著提升效率，潜在效率增益超40%，性能下降低于4%。

Conclusion: 结构优化可有效提升稀疏进化训练的性能，为降低DNN计算成本提供了可行方案。

Abstract: Deep Neural Networks (DNNs) have been proven to be exceptionally effective
and have been applied across diverse domains within deep learning. However, as
DNN models increase in complexity, the demand for reduced computational costs
and memory overheads has become increasingly urgent. Sparsity has emerged as a
leading approach in this area. The robustness of sparse Multi-layer Perceptrons
(MLPs) for supervised feature selection, along with the application of Sparse
Evolutionary Training (SET), illustrates the feasibility of reducing
computational costs without compromising accuracy. Moreover, it is believed
that the SET algorithm can still be improved through a structural optimization
method called motif-based optimization, with potential efficiency gains
exceeding 40% and a performance decline of under 4%. This research investigates
whether the structural optimization of Sparse Evolutionary Training applied to
Multi-layer Perceptrons (SET-MLP) can enhance performance and to what extent
this improvement can be achieved.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [349] [Know What You Don't Know: Uncertainty Calibration of Process Reward Models](https://arxiv.org/abs/2506.09338)
*Young-Jin Park,Kristjan Greenewald,Kaveh Alim,Hao Wang,Navid Azizan*

Main category: stat.ML

TL;DR: 论文提出了一种校准过程奖励模型（PRMs）的方法，通过分位数回归调整PRM输出以更准确预测成功概率，并基于此提出了动态调整推理预算的实例自适应缩放（IAS）框架。


<details>
  <summary>Details</summary>
Motivation: 现有PRMs校准不佳，常高估成功概率，影响推理效率。

Method: 采用分位数回归校准PRM输出，结合置信区间设计IAS框架，动态调整推理预算。

Result: 实验显示校准方法显著降低误差，IAS框架在保持准确性的同时减少计算成本。

Conclusion: 校准PRMs对自适应缩放至关重要，IAS框架能高效节省计算资源。

Abstract: Process reward models (PRMs) play a central role in guiding inference-time
scaling algorithms for large language models (LLMs). However, we observe that
even state-of-the-art PRMs can be poorly calibrated and often overestimate
success probabilities. To address this, we present a calibration approach,
performed via quantile regression, that adjusts PRM outputs to better align
with true success probabilities. Leveraging these calibrated success estimates
and their associated confidence bounds, we introduce an \emph{instance-adaptive
scaling} (IAS) framework that dynamically adjusts the inference budget based on
the estimated likelihood that a partial reasoning trajectory will yield a
correct final answer. Unlike conventional methods that allocate a fixed number
of reasoning trajectories per query, this approach successfully adapts to each
instance and reasoning step when using our calibrated PRMs. Experiments on
mathematical reasoning benchmarks show that (i) our PRM calibration method
successfully achieves small calibration error, outperforming the baseline
methods, (ii) calibration is crucial for enabling effective adaptive scaling,
and (iii) the proposed IAS strategy reduces inference costs while maintaining
final answer accuracy, utilizing less compute on more confident problems as
desired.

</details>


### [350] [Attention-Bayesian Hybrid Approach to Modular Multiple Particle Tracking](https://arxiv.org/abs/2506.09441)
*Piyush Mishra,Philippe Roudot*

Main category: stat.ML

TL;DR: 论文提出了一种结合自注意力机制和贝叶斯滤波的混合跟踪框架，用于解决多粒子在噪声和杂乱场景中的跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 由于轨迹假设的组合爆炸问题，传统方法在多粒子和多帧场景中难以高效跟踪。Transformer架构虽能提升鲁棒性，但在局部稀疏场景中表现不如贝叶斯滤波。

Method: 通过结合自注意力机制学习粒子行为的表示，并利用贝叶斯滤波的可靠性和可解释性，提出了一种混合框架。使用Transformer编码器推断帧间检测的软关联，修剪假设集。

Result: 该方法在多粒子跟踪中表现出更高的准确性和对虚假检测的鲁棒性。

Conclusion: 混合框架为高杂乱场景中的多粒子跟踪提供了一种有效解决方案。

Abstract: Tracking multiple particles in noisy and cluttered scenes remains challenging
due to a combinatorial explosion of trajectory hypotheses, which scales
super-exponentially with the number of particles and frames. The transformer
architecture has shown a significant improvement in robustness against this
high combinatorial load. However, its performance still falls short of the
conventional Bayesian filtering approaches in scenarios presenting a reduced
set of trajectory hypothesis. This suggests that while transformers excel at
narrowing down possible associations, they may not be able to reach the
optimality of the Bayesian approach in locally sparse scenario. Hence, we
introduce a hybrid tracking framework that combines the ability of
self-attention to learn the underlying representation of particle behavior with
the reliability and interpretability of Bayesian filtering. We perform
trajectory-to-detection association by solving a label prediction problem,
using a transformer encoder to infer soft associations between detections
across frames. This prunes the hypothesis set, enabling efficient
multiple-particle tracking in Bayesian filtering framework. Our approach
demonstrates improved tracking accuracy and robustness against spurious
detections, offering a solution for high clutter multiple particle tracking
scenarios.

</details>


### [351] [LLM-Powered CPI Prediction Inference with Online Text Time Series](https://arxiv.org/abs/2506.09516)
*Yingying Fan,Jinchi Lv,Ao Sun,Yurou Wang*

Main category: stat.ML

TL;DR: 该论文提出了一种基于大语言模型（LLM）的方法LLM-CPI，利用高频在线文本数据改进CPI预测，结合传统CPI数据和文本嵌入，展示了其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统CPI预测依赖低频调查数据，而大语言模型的出现为利用高频在线文本数据提供了新机会，这一领域尚未充分探索。

Method: 通过收集高频在线文本数据，使用LLM（如ChatGPT和BERT）生成通胀标签，提取文本嵌入，并构建结合CPI数据和文本嵌入的联合时间序列模型。

Result: 方法在仿真和实际数据中表现出良好的有限样本性能，并提供了预测区间的构建形式。

Conclusion: LLM-CPI展示了利用在线文本数据改进CPI预测的潜力，为经济学研究提供了新工具。

Abstract: Forecasting the Consumer Price Index (CPI) is an important yet challenging
task in economics, where most existing approaches rely on low-frequency,
survey-based data. With the recent advances of large language models (LLMs),
there is growing potential to leverage high-frequency online text data for
improved CPI prediction, an area still largely unexplored. This paper proposes
LLM-CPI, an LLM-based approach for CPI prediction inference incorporating
online text time series. We collect a large set of high-frequency online texts
from a popularly used Chinese social network site and employ LLMs such as
ChatGPT and the trained BERT models to construct continuous inflation labels
for posts that are related to inflation. Online text embeddings are extracted
via LDA and BERT. We develop a joint time series framework that combines
monthly CPI data with LLM-generated daily CPI surrogates. The monthly model
employs an ARX structure combining observed CPI data with text embeddings and
macroeconomic variables, while the daily model uses a VARX structure built on
LLM-generated CPI surrogates and text embeddings. We establish the asymptotic
properties of the method and provide two forms of constructed prediction
intervals. The finite-sample performance and practical advantages of LLM-CPI
are demonstrated through both simulation and real data examples.

</details>


### [352] [Evasion Attacks Against Bayesian Predictive Models](https://arxiv.org/abs/2506.09640)
*Pablo G. Arce,Roi Naveiro,David Ríos Insua*

Main category: stat.ML

TL;DR: 本文提出了一种针对贝叶斯预测模型设计最优规避攻击的通用方法，研究了两种对抗目标，并提出了基于梯度的新型攻击方法。


<details>
  <summary>Details</summary>
Motivation: 当前对抗机器学习研究主要集中在经典预测模型上，而贝叶斯预测模型的易受攻击性尚未充分探索。

Method: 提出了一种通用方法，设计针对贝叶斯预测模型的最优规避攻击，包括两种对抗目标和基于梯度的攻击方法。

Result: 研究了攻击方法在不同计算场景下的实现和特性。

Conclusion: 本文填补了贝叶斯预测模型对抗攻击研究的空白，为相关领域提供了新的攻击方法和分析框架。

Abstract: There is an increasing interest in analyzing the behavior of machine learning
systems against adversarial attacks. However, most of the research in
adversarial machine learning has focused on studying weaknesses against evasion
or poisoning attacks to predictive models in classical setups, with the
susceptibility of Bayesian predictive models to attacks remaining
underexplored. This paper introduces a general methodology for designing
optimal evasion attacks against such models. We investigate two adversarial
objectives: perturbing specific point predictions and altering the entire
posterior predictive distribution. For both scenarios, we propose novel
gradient-based attacks and study their implementation and properties in various
computational setups.

</details>


### [353] [Scaling Laws for Uncertainty in Deep Learning](https://arxiv.org/abs/2506.09648)
*Mattia Rosso,Simone Rossi,Giulio Franzese,Markus Heinonen,Maurizio Filippone*

Main category: stat.ML

TL;DR: 论文探讨了深度学习中的预测不确定性是否遵循与数据集和模型规模相关的缩放定律，并通过实验验证了这种规律的存在。


<details>
  <summary>Details</summary>
Motivation: 受深度学习缩放定律的启发，研究预测不确定性是否也存在类似的规律，以解决对贝叶斯方法的质疑。

Method: 通过视觉和语言任务的实验，使用近似贝叶斯推理和集成方法，研究预测不确定性的缩放行为。

Result: 实验证实了预测不确定性在数据集和模型规模上的缩放定律，表明数据量通常不足以使认知不确定性可忽略。

Conclusion: 研究不仅展示了缩放定律的优雅性，还为贝叶斯方法在深度学习中的实用性提供了有力支持。

Abstract: Deep learning has recently revealed the existence of scaling laws,
demonstrating that model performance follows predictable trends based on
dataset and model sizes. Inspired by these findings and fascinating phenomena
emerging in the over-parameterized regime, we examine a parallel direction: do
similar scaling laws govern predictive uncertainties in deep learning? In
identifiable parametric models, such scaling laws can be derived in a
straightforward manner by treating model parameters in a Bayesian way. In this
case, for example, we obtain $O(1/N)$ contraction rates for epistemic
uncertainty with respect to the number of data $N$. However, in
over-parameterized models, these guarantees do not hold, leading to largely
unexplored behaviors. In this work, we empirically show the existence of
scaling laws associated with various measures of predictive uncertainty with
respect to dataset and model sizes. Through experiments on vision and language
tasks, we observe such scaling laws for in- and out-of-distribution predictive
uncertainty estimated through popular approximate Bayesian inference and
ensemble methods. Besides the elegance of scaling laws and the practical
utility of extrapolating uncertainties to larger data or models, this work
provides strong evidence to dispel recurring skepticism against Bayesian
approaches: "In many applications of deep learning we have so much data
available: what do we need Bayes for?". Our findings show that "so much data"
is typically not enough to make epistemic uncertainty negligible.

</details>


### [354] [Assessing the Quality of Denoising Diffusion Models in Wasserstein Distance: Noisy Score and Optimal Bounds](https://arxiv.org/abs/2506.09681)
*Vahan Arsenyan,Elen Vardanyan,Arnak Dalalyan*

Main category: stat.ML

TL;DR: DDPMs对噪声评分估计具有鲁棒性，并在Wasserstein-2距离中实现了更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 研究DDPMs在噪声评分估计下的鲁棒性及其收敛性能。

Method: 通过扩散过程映射布朗运动，利用估计的评分函数驱动。

Result: DDPMs对恒定方差噪声具有鲁棒性，且收敛速度优于已知结果。

Conclusion: DDPMs的收敛速率与高斯情况一致，表明其最优性。

Abstract: Generative modeling aims to produce new random examples from an unknown
target distribution, given access to a finite collection of examples. Among the
leading approaches, denoising diffusion probabilistic models (DDPMs) construct
such examples by mapping a Brownian motion via a diffusion process driven by an
estimated score function. In this work, we first provide empirical evidence
that DDPMs are robust to constant-variance noise in the score evaluations. We
then establish finite-sample guarantees in Wasserstein-2 distance that exhibit
two key features: (i) they characterize and quantify the robustness of DDPMs to
noisy score estimates, and (ii) they achieve faster convergence rates than
previously known results. Furthermore, we observe that the obtained rates match
those known in the Gaussian case, implying their optimality.

</details>


### [355] [A Deep Generative Model for the Simulation of Discrete Karst Networks](https://arxiv.org/abs/2506.09832)
*Dany Lauzon,Julien Straubhaar,Philippe Renard*

Main category: stat.ML

TL;DR: 论文提出了一种基于图生成模型的新方法，用于模拟复杂的离散岩溶网络，结合图循环神经网络和去噪扩散概率模型，生成具有真实性的岩溶网络图。


<details>
  <summary>Details</summary>
Motivation: 岩溶网络的复杂性及其与水文地质条件的紧密联系，使得模拟其离散网络具有挑战性。

Method: 使用图循环神经网络（GraphRNN）学习岩溶网络的拓扑分布，再通过图去噪扩散概率模型（G-DDPM）学习节点特征，生成具有统计特性的网络图。

Result: 通过真实岩溶网络数据验证，生成子图与实际子图在几何和拓扑指标上表现一致。

Conclusion: 该方法能够随机模拟不同类型岩溶网络，为研究物理过程（如流动和传输）提供了有效工具。

Abstract: The simulation of discrete karst networks presents a significant challenge
due to the complexity of the physicochemical processes occurring within various
geological and hydrogeological contexts over extended periods. This complex
interplay leads to a wide variety of karst network patterns, each intricately
linked to specific hydrogeological conditions. We explore a novel approach that
represents karst networks as graphs and applies graph generative models (deep
learning techniques) to capture the intricate nature of karst environments. In
this representation, nodes retain spatial information and properties, while
edges signify connections between nodes. Our generative process consists of two
main steps. First, we utilize graph recurrent neural networks (GraphRNN) to
learn the topological distribution of karst networks. GraphRNN decomposes the
graph simulation into a sequential generation of nodes and edges, informed by
previously generated structures. Second, we employ denoising diffusion
probabilistic models on graphs (G-DDPM) to learn node features (spatial
coordinates and other properties). G-DDPMs enable the generation of nodes
features on the graphs produced by the GraphRNN that adhere to the learned
statistical properties by sampling from the derived probability distribution,
ensuring that the generated graphs are realistic and capture the essential
features of the original data. We test our approach using real-world karst
networks and compare generated subgraphs with actual subgraphs from the
database, by using geometry and topology metrics. Our methodology allows
stochastic simulation of discrete karst networks across various types of
formations, a useful tool for studying the behavior of physical processes such
as flow and transport.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [356] [Surrogate models to optimize plasma assisted atomic layer deposition in high aspect ratio features](https://arxiv.org/abs/2506.09313)
*Angel Yanguas-Gil,Jeffrey W. Elam*

Main category: cond-mat.mtrl-sci

TL;DR: 利用机器学习训练替代模型，优化高纵横比特征中等离子体增强原子层沉积（PEALD）工艺，仅需两次实验即可预测饱和时间，准确率达99%。


<details>
  <summary>Details</summary>
Motivation: 在PEALD等等离子体工艺中，表面复合可能主导等离子体与表面的反应，导致纳米结构内实现完全一致性的时间过长。

Method: 基于PEALD模拟的合成数据集，训练人工神经网络预测饱和时间，并通过部分涂层条件下的截面厚度数据验证。

Result: 仅需两次欠饱和实验即可预测饱和时间，误差在10%以内；替代模型判断表面复合主导的准确率达99%。

Conclusion: 机器学习为加速PEALD工艺优化提供了新途径，并可扩展至原子层刻蚀和更复杂结构。

Abstract: In this work we explore surrogate models to optimize plasma enhanced atomic
layer deposition (PEALD) in high aspect ratio features. In plasma-based
processes such as PEALD and atomic layer etching, surface recombination can
dominate the reactivity of plasma species with the surface, which can lead to
unfeasibly long exposure times to achieve full conformality inside
nanostructures like high aspect ratio vias. Using a synthetic dataset based on
simulations of PEALD, we train artificial neural networks to predict saturation
times based on cross section thickness data obtained for partially coated
conditions. The results obtained show that just two experiments in
undersaturated conditions contain enough information to predict saturation
times within 10% of the ground truth. A surrogate model trained to determine
whether surface recombination dominates the plasma-surface interactions in a
PEALD process achieves 99% accuracy. This demonstrates that machine learning
can provide a new pathway to accelerate the optimization of PEALD processes in
areas such as microelectronics. Our approach can be easily extended to atomic
layer etching and more complex structures.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [357] [STREAMINGGS: Voxel-Based Streaming 3D Gaussian Splatting with Memory Optimization and Architectural Support](https://arxiv.org/abs/2506.09070)
*Chenqi Zhang,Yu Feng,Jieru Zhao,Guangda Liu,Wenchao Ding,Chentao Wu,Minyi Guo*

Main category: cs.GR

TL;DR: STREAMINGGS是一种算法-架构协同设计的3D高斯溅射方法，通过内存中心渲染显著提升移动设备上的实时性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射（3DGS）在资源受限的移动设备上无法满足实时性要求（90 FPS），现有加速器忽视了内存效率。

Method: 提出STREAMINGGS，采用完全流式设计和内存中心渲染，减少DRAM流量。

Result: 设计实现了45.7倍的速度提升和62.9倍的能耗节省。

Conclusion: STREAMINGGS显著优化了3DGS在移动设备上的性能和能效。

Abstract: 3D Gaussian Splatting (3DGS) has gained popularity for its efficiency and
sparse Gaussian-based representation. However, 3DGS struggles to meet the
real-time requirement of 90 frames per second (FPS) on resource-constrained
mobile devices, achieving only 2 to 9 FPS.Existing accelerators focus on
compute efficiency but overlook memory efficiency, leading to redundant DRAM
traffic. We introduce STREAMINGGS, a fully streaming 3DGS
algorithm-architecture co-design that achieves fine-grained pipelining and
reduces DRAM traffic by transforming from a tile-centric rendering to a
memory-centric rendering. Results show that our design achieves up to 45.7
$\times$ speedup and 62.9 $\times$ energy savings over mobile Ampere GPUs.

</details>


### [358] [SILK: Smooth InterpoLation frameworK for motion in-betweening A Simplified Computational Approach](https://arxiv.org/abs/2506.09075)
*Elly Akhoundi,Hung Yu Ling,Anup Anand Deshmukh,Judith Butepage*

Main category: cs.GR

TL;DR: 本文提出了一种基于Transformer的简单框架，用于运动插值任务，强调数据建模选择的重要性，并挑战了模型复杂性决定动画质量的假设。


<details>
  <summary>Details</summary>
Motivation: 运动插值是动画师的重要工具，但现有机器学习方法依赖复杂模型。本文旨在探索一种更简单、数据驱动的方法。

Method: 使用单一Transformer编码器框架，重点优化数据建模选择，包括数据量、姿态表示和速度输入特征。

Result: 实验表明，增加数据量、优化姿态表示和引入速度特征可显著提升运动插值质量。

Conclusion: 模型复杂性并非动画质量的决定因素，数据建模选择更为关键，为运动插值提供了更高效的方法。

Abstract: Motion in-betweening is a crucial tool for animators, enabling intricate
control over pose-level details in each keyframe. Recent machine learning
solutions for motion in-betweening rely on complex models, incorporating
skeleton-aware architectures or requiring multiple modules and training steps.
In this work, we introduce a simple yet effective Transformer-based framework,
employing a single Transformer encoder to synthesize realistic motions for
motion in-betweening tasks. We find that data modeling choices play a
significant role in improving in-betweening performance. Among others, we show
that increasing data volume can yield equivalent or improved motion
transitions, that the choice of pose representation is vital for achieving
high-quality results, and that incorporating velocity input features enhances
animation performance. These findings challenge the assumption that model
complexity is the primary determinant of animation quality and provide insights
into a more data-centric approach to motion interpolation. Additional videos
and supplementary material are available at https://silk-paper.github.io.

</details>


### [359] [VideoMat: Extracting PBR Materials from Video Diffusion Models](https://arxiv.org/abs/2506.09665)
*Jacob Munkberg,Zian Wang,Ruofan Liang,Tianchang Shen,Jon Hasselgren*

Main category: cs.GR

TL;DR: 利用视频扩散模型、视频固有分解和基于物理的可微分渲染，通过文本提示或单张图像为3D模型生成高质量材质。


<details>
  <summary>Details</summary>
Motivation: 为3D模型生成高质量材质通常需要大量手动工作，本文旨在通过自动化方法简化这一过程。

Method: 1. 使用微调的视频扩散模型生成多视角一致材质；2. 提取固有属性（基础色、粗糙度、金属度）；3. 结合可微分路径追踪提取PBR材质。

Result: 生成的材质与常见内容创作工具兼容，质量高且一致。

Conclusion: 该方法为3D模型材质生成提供了一种高效、自动化的解决方案。

Abstract: We leverage finetuned video diffusion models, intrinsic decomposition of
videos, and physically-based differentiable rendering to generate high quality
materials for 3D models given a text prompt or a single image. We condition a
video diffusion model to respect the input geometry and lighting condition.
This model produces multiple views of a given 3D model with coherent material
properties. Secondly, we use a recent model to extract intrinsics (base color,
roughness, metallic) from the generated video. Finally, we use the intrinsics
alongside the generated video in a differentiable path tracer to robustly
extract PBR materials directly compatible with common content creation tools.

</details>


### [360] [DGS-LRM: Real-Time Deformable 3D Gaussian Reconstruction From Monocular Videos](https://arxiv.org/abs/2506.09997)
*Chieh Hubert Lin,Zhaoyang Lv,Songyin Wu,Zhen Xu,Thu Nguyen-Phuoc,Hung-Yu Tseng,Julian Straub,Numair Khan,Lei Xiao,Ming-Hsuan Yang,Yuheng Ren,Richard Newcombe,Zhao Dong,Zhengqin Li*

Main category: cs.GR

TL;DR: DGS-LRM是一种基于前馈的方法，通过单目视频预测可变形3D高斯斑点，实现动态场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有前馈模型多限于静态场景，无法重建动态物体运动，而动态场景重建面临训练数据稀缺和3D表示等挑战。

Method: 提出大规模合成数据集、可变形3D高斯表示和大型Transformer网络，实现实时动态重建。

Result: DGS-LRM在动态重建质量上媲美优化方法，优于现有预测方法，且3D变形准确，适用于长程跟踪任务。

Conclusion: DGS-LRM为动态场景重建提供了高效且高质量的解决方案，性能与先进单目视频3D跟踪方法相当。

Abstract: We introduce the Deformable Gaussian Splats Large Reconstruction Model
(DGS-LRM), the first feed-forward method predicting deformable 3D Gaussian
splats from a monocular posed video of any dynamic scene. Feed-forward scene
reconstruction has gained significant attention for its ability to rapidly
create digital replicas of real-world environments. However, most existing
models are limited to static scenes and fail to reconstruct the motion of
moving objects. Developing a feed-forward model for dynamic scene
reconstruction poses significant challenges, including the scarcity of training
data and the need for appropriate 3D representations and training paradigms. To
address these challenges, we introduce several key technical contributions: an
enhanced large-scale synthetic dataset with ground-truth multi-view videos and
dense 3D scene flow supervision; a per-pixel deformable 3D Gaussian
representation that is easy to learn, supports high-quality dynamic view
synthesis, and enables long-range 3D tracking; and a large transformer network
that achieves real-time, generalizable dynamic scene reconstruction. Extensive
qualitative and quantitative experiments demonstrate that DGS-LRM achieves
dynamic scene reconstruction quality comparable to optimization-based methods,
while significantly outperforming the state-of-the-art predictive dynamic
reconstruction method on real-world examples. Its predicted physically grounded
3D deformation is accurate and can readily adapt for long-range 3D tracking
tasks, achieving performance on par with state-of-the-art monocular video 3D
tracking methods.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [361] [Reconstructing Heterogeneous Biomolecules via Hierarchical Gaussian Mixtures and Part Discovery](https://arxiv.org/abs/2506.09063)
*Shayan Shekarforoush,David B. Lindell,Marcus A. Brubaker,David J. Fleet*

Main category: q-bio.QM

TL;DR: CryoSPIRE是一种新的冷冻电镜3D重建框架，通过分层高斯混合模型处理分子构象和组成变化，显著提升了复杂数据集的结构解析能力。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜在解析分子结构时面临非刚性构象变化和组成变化的挑战，需要新的计算方法来准确建模。

Method: 提出了一种基于分层高斯混合模型的3D重建框架，结合部分分割技术，处理构象和组成变化。

Result: CryoSPIRE在复杂实验数据集上揭示了生物学意义的结构，并在CryoBench基准测试中达到最新水平。

Conclusion: CryoSPIRE为冷冻电镜中的异质性建模提供了创新解决方案，显著提升了结构解析能力。

Abstract: Cryo-EM is a transformational paradigm in molecular biology where
computational methods are used to infer 3D molecular structure at atomic
resolution from extremely noisy 2D electron microscope images. At the forefront
of research is how to model the structure when the imaged particles exhibit
non-rigid conformational flexibility and compositional variation where parts
are sometimes missing. We introduce a novel 3D reconstruction framework with a
hierarchical Gaussian mixture model, inspired in part by Gaussian Splatting for
4D scene reconstruction. In particular, the structure of the model is grounded
in an initial process that infers a part-based segmentation of the particle,
providing essential inductive bias in order to handle both conformational and
compositional variability. The framework, called CryoSPIRE, is shown to reveal
biologically meaningful structures on complex experimental datasets, and
establishes a new state-of-the-art on CryoBench, a benchmark for cryo-EM
heterogeneity methods.

</details>


### [362] [Detecting malignant dynamics on very few blood sample using signature coefficients](https://arxiv.org/abs/2506.09097)
*Rémi Vaucher,Stéphane Chrétien*

Main category: q-bio.QM

TL;DR: 该论文提出了一种结合连续时间马尔可夫模型和签名理论的方法，用于基于血液样本中ctDNA水平的动态分析来检测侵袭性癌症。


<details>
  <summary>Details</summary>
Motivation: ctDNA在癌症监测中具有潜力，但数据稀疏性是一个挑战。签名理论为处理不规则采样信号提供了新思路。

Method: 结合连续时间马尔可夫模型和签名理论，构建高效的检测流程。

Result: 数值实验验证了方法的有效性，能够克服数据稀疏性问题。

Conclusion: 该方法为侵袭性癌症的早期检测提供了新工具，具有实际应用潜力。

Abstract: Recent discoveries have suggested that the promising avenue of using
circulating tumor DNA (ctDNA) levels in blood samples provides reasonable
accuracy for cancer monitoring, with extremely low burden on the patient's
side. It is known that the presence of ctDNA can result from various mechanisms
leading to DNA release from cells, such as apoptosis, necrosis or active
secretion. One key idea in recent cancer monitoring studies is that monitoring
the dynamics of ctDNA levels might be sufficient for early multi-cancer
detection. This interesting idea has been turned into commercial products, e.g.
in the company named GRAIL.
  In the present work, we propose to explore the use of Signature theory for
detecting aggressive cancer tumors based on the analysis of blood samples. Our
approach combines tools from continuous time Markov modelling for the dynamics
of ctDNA levels in the blood, with Signature theory for building efficient
testing procedures. Signature theory is a topic of growing interest in the
Machine Learning community (see Chevyrev2016 and Fermanian2021), which is now
recognised as a powerful feature extraction tool for irregularly sampled
signals. The method proposed in the present paper is shown to correctly address
the challenging problem of overcoming the inherent data scarsity due to the
extremely small number of blood samples per patient. The relevance of our
approach is illustrated with extensive numerical experiments that confirm the
efficiency of the proposed pipeline.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [363] [How attention simplifies mental representations for planning](https://arxiv.org/abs/2506.09520)
*Jason da Silva Castanheira,Nicholas Shea,Stephen M. Fleming*

Main category: q-bio.NC

TL;DR: 人类规划高效且灵活，通过简化心理表征平衡任务复杂性与实用性。研究发现空间注意力控制任务表征的主观意识，影响规划能力。


<details>
  <summary>Details</summary>
Motivation: 探索人类规划中感知与注意力的交互机制，以理解任务表征的形成及其对行为的影响。

Method: 利用虚拟迷宫导航实验，研究空间注意力如何影响任务表征的可用性。

Result: 空间接近性和自然注意力轮廓影响迷宫表征的简化与实用性，个体差异显著。

Conclusion: 将视觉空间注意力效应融入计算模型，为理解感知与决策的交互提供了新视角。

Abstract: Human planning is efficient -- it frugally deploys limited cognitive
resources to accomplish difficult tasks -- and flexible -- adapting to novel
problems and environments. Computational approaches suggest that people
construct simplified mental representations of their environment, balancing the
complexity of a task representation with its utility. These models imply a
nested optimisation in which planning shapes perception, and perception shapes
planning -- but the perceptual and attentional mechanisms governing how this
interaction unfolds remain unknown. Here, we harness virtual maze navigation to
characterise how spatial attention controls which aspects of a task
representation enter subjective awareness and are available for planning. We
find that spatial proximity governs which aspects of a maze are available for
planning, and that when task-relevant information follows natural (lateralised)
contours of attention, people can more easily construct simplified and useful
maze representations. This influence of attention varies considerably across
individuals, explaining differences in people's task representations and
behaviour. Inspired by the 'spotlight of attention' analogy, we incorporate the
effects of visuospatial attention into existing computational accounts of
value-guided construal. Together, our work bridges computational perspectives
on perception and decision-making to better understand how individuals
represent their environments in aid of planning.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [364] [ThinkQE: Query Expansion via an Evolving Thinking Process](https://arxiv.org/abs/2506.09260)
*Yibin Lei,Tao Shen,Andrew Yates*

Main category: cs.IR

TL;DR: ThinkQE通过思考式扩展和语料库交互策略，提升了查询扩展的多样性和探索性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法生成的查询扩展过于狭窄，未能充分捕捉查询的多面性和多样性。

Method: 提出ThinkQE框架，结合思考式扩展过程和语料库交互策略，迭代优化扩展。

Result: 在多个基准测试（DL19、DL20、BRIGHT）中表现优于现有方法。

Conclusion: ThinkQE无需额外训练即可提升查询扩展的多样性和检索性能。

Abstract: Effective query expansion for web search benefits from promoting both
exploration and result diversity to capture multiple interpretations and facets
of a query. While recent LLM-based methods have improved retrieval performance
and demonstrate strong domain generalization without additional training, they
often generate narrowly focused expansions that overlook these desiderata. We
propose ThinkQE, a test-time query expansion framework addressing this
limitation through two key components: a thinking-based expansion process that
encourages deeper and comprehensive semantic exploration, and a
corpus-interaction strategy that iteratively refines expansions using retrieval
feedback from the corpus. Experiments on diverse web search benchmarks (DL19,
DL20, and BRIGHT) show ThinkQE consistently outperforms prior approaches,
including training-intensive dense retrievers and rerankers.

</details>


### [365] [Revisiting Graph Projections for Effective Complementary Product Recommendation](https://arxiv.org/abs/2506.09209)
*Leandro Anghinoni,Pablo Zivic,Jorge Adrian Sanchez*

Main category: cs.IR

TL;DR: 提出了一种基于用户-物品二分图投影的有向加权图结构的互补产品推荐方法，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 互补产品推荐对提升用户体验和零售销售至关重要，但由于用户-物品交互数据的噪声和稀疏性，推荐任务具有挑战性。

Method: 通过用户-物品二分图投影构建有向加权图，从中推断互补关系。

Result: 与现有方法相比，平均提升43%（序列推荐）和38%（图推荐）。

Conclusion: 该方法简单有效，显著提升了互补产品推荐的性能。

Abstract: Complementary product recommendation is a powerful strategy to improve
customer experience and retail sales. However, recommending the right product
is not a simple task because of the noisy and sparse nature of user-item
interactions. In this work, we propose a simple yet effective method to predict
a list of complementary products given a query item, based on the structure of
a directed weighted graph projected from the user-item bipartite graph. We
revisit bipartite graph projections for recommender systems and propose a novel
approach for inferring complementarity relationships from historical user-item
interactions. We compare our model with recent methods from the literature and
show, despite the simplicity of our approach, an average improvement of +43%
and +38% over sequential and graph-based recommenders, respectively, over
different benchmarks.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [366] [EdgeProfiler: A Fast Profiling Framework for Lightweight LLMs on Edge Using Analytical Model](https://arxiv.org/abs/2506.09061)
*Alyssa Pinnock,Shakya Jayakody,Kawsher A Roxy,Md Rubel Ahmed*

Main category: cs.DC

TL;DR: EdgeProfiler是一个快速分析框架，用于评估边缘系统上的轻量级大语言模型（LLM），通过量化技术和内存约束优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在边缘设备上部署时的高计算、内存和功耗问题。

Method: 使用4位量化技术分析紧凑LLM，通过分析模型估计延迟、FLOPs和能耗。

Result: 4位量化减少内存60-70%，精度损失2-5%，推理速度提升2-3倍，能耗降低35-50%。

Conclusion: EdgeProfiler为轻量级LLM在边缘环境中的高效部署提供了重要工具，平衡了精度、能效和计算可行性。

Abstract: This paper introduces EdgeProfiler, a fast profiling framework designed for
evaluating lightweight Large Language Models (LLMs) on edge systems. While LLMs
offer remarkable capabilities in natural language understanding and generation,
their high computational, memory, and power requirements often confine them to
cloud environments. EdgeProfiler addresses these challenges by providing a
systematic methodology for assessing LLM performance in resource-constrained
edge settings. The framework profiles compact LLMs, including TinyLLaMA,
Gemma3.1B, Llama3.2-1B, and DeepSeek-r1-1.5B, using aggressive quantization
techniques and strict memory constraints. Analytical modeling is used to
estimate latency, FLOPs, and energy consumption. The profiling reveals that
4-bit quantization reduces model memory usage by approximately 60-70%, while
maintaining accuracy within 2-5% of full-precision baselines. Inference speeds
are observed to improve by 2-3x compared to FP16 baselines across various edge
devices. Power modeling estimates a 35-50% reduction in energy consumption for
INT4 configurations, enabling practical deployment on hardware such as
Raspberry Pi 4/5 and Jetson Orin Nano Super. Our findings emphasize the
importance of efficient profiling tailored to lightweight LLMs in edge
environments, balancing accuracy, energy efficiency, and computational
feasibility.

</details>


### [367] [SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving](https://arxiv.org/abs/2506.09397)
*Xiangchen Li,Dimitrios Spatharakis,Saeid Ghafouri,Jiakun Fan,Dimitrios Nikolopoulos*

Main category: cs.DC

TL;DR: 论文提出SLED方法，利用推测解码技术优化边缘设备上的大型语言模型推理，通过异构设备协同计算降低延迟和能耗，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 尽管设备能力提升，边缘设备上高效推理大型语言模型仍受限于内存和功耗。现有方法（如量化、剪枝或远程推理）需牺牲精度或增加成本。

Method: 提出SLED方法，轻量级边缘设备本地生成候选令牌，边缘服务器批量验证，减少服务器内存占用并支持设备异构性。

Result: 实验表明，SLED显著降低延迟、提高能效，并支持更多并发推理会话，且不牺牲模型精度。

Conclusion: SLED为边缘计算中的高效LLM推理提供了可行方案，兼顾性能和资源限制。

Abstract: Regardless the advancements in device capabilities, efficient inferencing
advanced large language models (LLMs) at the edge remains challenging due to
limited device memory and power constraints. Existing strategies, such as
aggressive quantization, pruning, or remote inference, trade accuracy for
efficiency or lead to substantial cost burdens. This position paper introduces
a new approach that leverages speculative decoding, previously viewed primarily
as a decoding acceleration technique for autoregressive generation of LLMs, as
a promising approach specifically adapted for edge computing by orchestrating
computation across heterogeneous devices. We propose SLED, a method that allows
lightweight edge devices to draft multiple candidate tokens locally using
diverse draft models, while a single, shared edge server efficiently batches
and verifies the tokens utilizing a more precise target model. This approach
supports device heterogeneity and reduces server-side memory footprint by
avoiding the need to deploy multiple target models. Our initial experiments
with Jetson Orin Nano, Raspberry Pi 5, and an RTX 6000 edge server indicate
substantial benefits: significantly reduced latency, improved energy
efficiency, and increased concurrent inference sessions, all without
sacrificing model accuracy.

</details>


### [368] [TTrace: Lightweight Error Checking and Diagnosis for Distributed Training](https://arxiv.org/abs/2506.09280)
*Haitian Jiang,Shaowei Zhu,Zhen Zhang,Zhenyu Song,Xinwei Fu,Zhen Jia,Yida Wang,Jinyang Li*

Main category: cs.DC

TL;DR: TTrace是一个用于检测和定位分布式训练中无声错误的系统，通过对比单设备参考实现和分布式训练中的中间张量，有效区分错误和浮点舍入误差。


<details>
  <summary>Details</summary>
Motivation: 分布式训练中的无声错误难以检测和定位，传统调试方法效率低下。

Method: TTrace收集分布式训练的中间张量，与单设备参考实现对比，并提出数学分析设置阈值。

Result: 实验证明TTrace在Megatron-LM框架中检测到11个现有错误和3个新错误，代码改动少于10行。

Conclusion: TTrace在多种训练场景（包括低精度训练）中均有效。

Abstract: Distributed training is essential for scaling the training of large neural
network models, such as large language models (LLMs), across thousands of GPUs.
However, the complexity of distributed training programs makes them
particularly prone to silent bugs, which do not produce explicit error signal
but lead to incorrect training outcome. Effectively detecting and localizing
such silent bugs in distributed training is challenging. Common debugging
practice using metrics like training loss or gradient norm curves can be
inefficient and ineffective. Additionally, obtaining intermediate tensor values
and determining whether they are correct during silent bug localization is
difficult, particularly in the context of low-precision training.
  To address those challenges, we design and implement TTrace, the first system
capable of detecting and localizing silent bugs in distributed training. TTrace
collects intermediate tensors from distributing training in a fine-grained
manner and compares them against those from a trusted single-device reference
implementation. To properly compare the floating-point values in the tensors,
we propose novel mathematical analysis that provides a guideline for setting
thresholds, enabling TTrace to distinguish bug-induced errors from
floating-point round-off errors. Experimental results demonstrate that TTrace
effectively detects 11 existing bugs and 3 new bugs in the widely used
Megatron-LM framework, while requiring fewer than 10 lines of code change.
TTrace is effective in various training recipes, including low-precision
recipes involving BF16 and FP8.

</details>


### [369] [ScalableHD: Scalable and High-Throughput Hyperdimensional Computing Inference on Multi-Core CPUs](https://arxiv.org/abs/2506.09282)
*Dhruv Parikh,Viktor Prasanna*

Main category: cs.DC

TL;DR: ScalableHD是一种针对多核CPU的高通量超维计算（HDC）推理方法，通过两阶段流水线执行模型和并行化技术，实现了比现有方法高达10倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 传统HDC方法在推理时主要依赖专用硬件（如FPGA和GPU），而多核CPU上的高效推理研究较少。ScalableHD旨在填补这一空白。

Method: 采用两阶段流水线执行模型，并行处理基类和类别超向量，结合内存分块和NUMA感知的核心绑定，优化缓存局部性和计算并行性。

Result: 在多种任务（如人类活动识别和图像分类）中，ScalableHD的吞吐量比TorchHD等基线方法提升高达10倍，同时保持任务准确性。

Conclusion: ScalableHD在多核CPU上实现了高效且可扩展的HDC推理，为通用计算平台上的HDC应用提供了实用解决方案。

Abstract: Hyperdimensional Computing (HDC) is a brain-inspired computing paradigm that
represents and manipulates information using high-dimensional vectors, called
hypervectors (HV). Traditional HDC methods, while robust to noise and
inherently parallel, rely on single-pass, non-parametric training and often
suffer from low accuracy. To address this, recent approaches adopt iterative
training of base and class HVs, typically accelerated on GPUs. Inference,
however, remains lightweight and well-suited for real-time execution. Yet,
efficient HDC inference has been studied almost exclusively on specialized
hardware such as FPGAs and GPUs, with limited attention to general-purpose
multi-core CPUs. To address this gap, we propose ScalableHD for scalable and
high-throughput HDC inference on multi-core CPUs. ScalableHD employs a
two-stage pipelined execution model, where each stage is parallelized across
cores and processes chunks of base and class HVs. Intermediate results are
streamed between stages using a producer-consumer mechanism, enabling
on-the-fly consumption and improving cache locality. To maximize performance,
ScalableHD integrates memory tiling and NUMA-aware worker-to-core binding.
Further, it features two execution variants tailored for small and large batch
sizes, each designed to exploit compute parallelism based on workload
characteristics while mitigating the memory-bound compute pattern that limits
HDC inference performance on modern multi-core CPUs. ScalableHD achieves up to
10x speedup in throughput (samples per second) over state-of-the-art baselines
such as TorchHD, across a diverse set of tasks ranging from human activity
recognition to image classification, while preserving task accuracy.
Furthermore, ScalableHD exhibits robust scalability: increasing the number of
cores yields near-proportional throughput improvements.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [370] [Large Language Models for Design Structure Matrix Optimization](https://arxiv.org/abs/2506.09749)
*Shuo Jiang,Min Xie,Jianxi Luo*

Main category: cs.CE

TL;DR: 论文提出了一种基于大语言模型（LLM）的框架，用于优化设计结构矩阵（DSM）中的元素排序问题，结合网络拓扑和领域知识，显著提升了优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在处理复杂工程系统的依赖关系时，难以捕捉上下文细微差别，导致效果不佳。LLM因其高级推理和上下文理解能力，有望解决此类组合优化问题。

Method: 提出了一种新颖的LLM框架，整合网络拓扑和领域知识，通过迭代优化DSM元素排序。

Result: 实验表明，该方法在收敛速度和解决方案质量上均优于随机和确定性基线，且领域知识的引入显著提升了性能。

Conclusion: LLM通过结合语义和数学推理，为解决复杂工程组合优化问题提供了新范式。

Abstract: In complex engineering systems, the interdependencies among components or
development activities are often modeled and analyzed using Design Structure
Matrix (DSM). Reorganizing elements within a DSM to minimize feedback loops and
enhance modularity or process efficiency constitutes a challenging
combinatorial optimization (CO) problem in engineering design and operations.
As problem sizes increase and dependency networks become more intricate,
traditional optimization methods that solely use mathematical heuristics often
fail to capture the contextual nuances and struggle to deliver effective
solutions. In this study, we explore the potential of Large Language Models
(LLMs) for helping solve such CO problems by leveraging their capabilities for
advanced reasoning and contextual understanding. We propose a novel LLM-based
framework that integrates network topology with contextual domain knowledge for
iterative optimization of DSM element sequencing - a common CO problem.
Experiments on various DSM cases show that our method consistently achieves
faster convergence and superior solution quality compared to both stochastic
and deterministic baselines. Notably, we find that incorporating contextual
domain knowledge significantly enhances optimization performance regardless of
the chosen LLM backbone. These findings highlight the potential of LLMs to
solve complex engineering CO problems by combining semantic and mathematical
reasoning. This approach paves the way towards a new paradigm in LLM-based
engineering design optimization.

</details>


### [371] [Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era](https://arxiv.org/abs/2506.09755)
*Shuo Jiang,Min Xie,Frank Youhua Chen,Jian Ma,Jianxi Luo*

Main category: cs.CE

TL;DR: 本文介绍了智能设计4.0（ID 4.0），这是一个由多智能体AI系统驱动的新兴范式，旨在实现工程设计的端到端自动化。


<details>
  <summary>Details</summary>
Motivation: 研究智能设计（ID）的演变及其在工程创新中的潜力，特别是在基础模型（如LLMs）的推动下，探索如何进一步提升设计效率和质量。

Method: 回顾智能设计的四个历史阶段，并提出ID 4.0的概念框架，强调多智能体协作的潜力。

Result: ID 4.0有望通过自主多智能体系统实现工程设计的全面自动化，并适应更复杂的设计场景。

Conclusion: ID 4.0为智能设计提供了更高的适应性、自主性和有效性，为未来复杂设计挑战奠定了基础。

Abstract: Research and practice in Intelligent Design (ID) have significantly enhanced
engineering innovation, efficiency, quality, and productivity over recent
decades, fundamentally reshaping how engineering designers think, behave, and
interact with design processes. The recent emergence of Foundation Models
(FMs), particularly Large Language Models (LLMs), has demonstrated general
knowledge-based reasoning capabilities, and open new paths and avenues for
further transformation in engineering design. In this context, this paper
introduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by
agentic AI systems. We review the historical evolution of ID across four
distinct stages: rule-based expert systems, task-specific machine learning
models, large-scale foundation AI models, and the recent emerging paradigm of
multi-agent collaboration. We propose a conceptual framework for ID 4.0 and
discuss its potential to support end-to-end automation of engineering design
processes through coordinated, autonomous multi-agent-based systems.
Furthermore, we discuss future perspectives to enhance and fully realize ID
4.0's potential, including more complex design scenarios, more practical design
implementations, novel agent coordination mechanisms, and autonomous design
goal-setting with better human value alignment. In sum, these insights lay a
foundation for advancing Intelligent Design toward greater adaptivity,
autonomy, and effectiveness in addressing increasingly complex design
challenges.

</details>


### [372] [Superstudent intelligence in thermodynamics](https://arxiv.org/abs/2506.09822)
*Rebecca Loubet,Pascal Zittlau,Marco Hoffmann,Luisa Vollmer,Sophie Fellenz,Heike Leitte,Fabian Jirasek,Johannes Lenhard,Hans Hasse*

Main category: cs.CE

TL;DR: OpenAI的o3模型在热力学考试中表现优于所有学生，展示了AI在复杂任务中的卓越能力。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在传统上被认为是人类智力证明的复杂任务中的表现，及其对工程教育和实践的影响。

Method: 将热力学考试同时提供给学生和OpenAI的o3模型，并对两者的答案进行相同标准的评估。

Result: o3在零样本模式下正确解决了所有问题，得分超过所有学生，达到历史最佳水平。

Conclusion: AI在复杂任务中的优异表现标志着技术发展的转折点，对工程师的工作和教育提出了新的挑战和机遇。

Abstract: In this short note, we report and analyze a striking event: OpenAI's large
language model o3 has outwitted all students in a university exam on
thermodynamics. The thermodynamics exam is a difficult hurdle for most
students, where they must show that they have mastered the fundamentals of this
important topic. Consequently, the failure rates are very high, A-grades are
rare - and they are considered proof of the students' exceptional intellectual
abilities. This is because pattern learning does not help in the exam. The
problems can only be solved by knowledgeably and creatively combining
principles of thermodynamics. We have given our latest thermodynamics exam not
only to the students but also to OpenAI's most powerful reasoning model, o3,
and have assessed the answers of o3 exactly the same way as those of the
students. In zero-shot mode, the model o3 solved all problems correctly, better
than all students who took the exam; its overall score was in the range of the
best scores we have seen in more than 10,000 similar exams since 1985. This is
a turning point: machines now excel in complex tasks, usually taken as proof of
human intellectual capabilities. We discuss the consequences this has for the
work of engineers and the education of future engineers.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [373] [Automatic Treatment Planning using Reinforcement Learning for High-dose-rate Prostate Brachytherapy](https://arxiv.org/abs/2506.09805)
*Tonghe Wang,Yining Feng,Xiaofeng Yang*

Main category: physics.med-ph

TL;DR: 研究探讨了使用强化学习（RL）在高剂量率（HDR）前列腺近距离放射治疗中自动生成针位和停留时间的可行性，结果显示RL计划在减少针数和改善部分剂量指标上优于传统临床方法。


<details>
  <summary>Details</summary>
Motivation: 目前HDR前列腺近距离放射治疗中的针位放置仅依赖医生经验，RL方法旨在减少手术时间并确保计划质量的一致性。

Method: 训练RL代理逐步调整针位和停留时间以最大化奖励函数，使用11例患者数据（1例训练，10例测试）进行验证。

Result: RL计划在减少前列腺热点（V150）和尿道剂量（D20%）上显著优于临床计划，且平均少用2根针。

Conclusion: RL方法首次证明可自主生成临床实用的HDR前列腺近距离放射治疗计划，具有标准化规划、减少临床变异性和改善患者预后的潜力。

Abstract: Purpose: In high-dose-rate (HDR) prostate brachytherapy procedures, the
pattern of needle placement solely relies on physician experience. We
investigated the feasibility of using reinforcement learning (RL) to provide
needle positions and dwell times based on patient anatomy during pre-planning
stage. This approach would reduce procedure time and ensure consistent plan
quality. Materials and Methods: We train a RL agent to adjust the position of
one selected needle and all the dwell times on it to maximize a pre-defined
reward function after observing the environment. After adjusting, the RL agent
then moves on to the next needle, until all needles are adjusted. Multiple
rounds are played by the agent until the maximum number of rounds is reached.
Plan data from 11 prostate HDR boost patients (1 for training, and 10 for
testing) treated in our clinic were included in this study. The dosimetric
metrics and the number of used needles of RL plan were compared to those of the
clinical results (ground truth). Results: On average, RL plans and clinical
plans have very similar prostate coverage (Prostate V100) and Rectum D2cc (no
statistical significance), while RL plans have less prostate hotspot (Prostate
V150) and Urethra D20% plans with statistical significance. Moreover, RL plans
use 2 less needles than clinical plan on average. Conclusion: We present the
first study demonstrating the feasibility of using reinforcement learning to
autonomously generate clinically practical HDR prostate brachytherapy plans.
This RL-based method achieved equal or improved plan quality compared to
conventional clinical approaches while requiring fewer needles. With minimal
data requirements and strong generalizability, this approach has substantial
potential to standardize brachytherapy planning, reduce clinical variability,
and enhance patient outcomes.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [374] [Advancing Exchange Rate Forecasting: Leveraging Machine Learning and AI for Enhanced Accuracy in Global Financial Markets](https://arxiv.org/abs/2506.09851)
*Md. Yeasin Rahat,Rajan Das Gupta,Nur Raisa Rahman,Sudipto Roy Pritom,Samiur Rahman Shakir,Md Imrul Hasan Showmick,Md. Jakir Hossen*

Main category: q-fin.ST

TL;DR: 该研究利用LSTM神经网络预测美元/孟加拉塔卡汇率，准确率达99.449%，显著优于传统ARIMA方法。虽然GBC模型显示40.82%的盈利交易率，但整体净亏损20,653.25美元。


<details>
  <summary>Details</summary>
Motivation: 外汇汇率预测对全球金融市场至关重要，本研究旨在通过机器学习提供更准确的预测工具。

Method: 使用LSTM神经网络和GBC模型，基于2018-2023年历史数据进行分析和预测。

Result: LSTM模型表现优异（RMSE 0.9858），GBC模型虽部分盈利但整体亏损。汇率呈下降趋势。

Conclusion: 深度学习在外汇预测中潜力巨大，未来可结合情感分析和实时经济指标提升模型适应性。

Abstract: The prediction of foreign exchange rates, such as the US Dollar (USD) to
Bangladeshi Taka (BDT), plays a pivotal role in global financial markets,
influencing trade, investments, and economic stability. This study leverages
historical USD/BDT exchange rate data from 2018 to 2023, sourced from Yahoo
Finance, to develop advanced machine learning models for accurate forecasting.
A Long Short-Term Memory (LSTM) neural network is employed, achieving an
exceptional accuracy of 99.449%, a Root Mean Square Error (RMSE) of 0.9858, and
a test loss of 0.8523, significantly outperforming traditional methods like
ARIMA (RMSE 1.342). Additionally, a Gradient Boosting Classifier (GBC) is
applied for directional prediction, with backtesting on a $10,000 initial
capital revealing a 40.82% profitable trade rate, though resulting in a net
loss of $20,653.25 over 49 trades. The study analyzes historical trends,
showing a decline in BDT/USD rates from 0.012 to 0.009, and incorporates
normalized daily returns to capture volatility. These findings highlight the
potential of deep learning in forex forecasting, offering traders and
policymakers robust tools to mitigate risks. Future work could integrate
sentiment analysis and real-time economic indicators to further enhance model
adaptability in volatile markets.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [375] [Alice and the Caterpillar: A more descriptive null model for assessing data mining results](https://arxiv.org/abs/2506.09764)
*Giulia Preti,Gianmarco De Francisci Morales,Matteo Riondato*

Main category: cs.SI

TL;DR: 提出了新的零模型用于评估二元交易和序列数据集，通过统计假设检验，比现有模型保留更多数据特性。


<details>
  <summary>Details</summary>
Motivation: 现有零模型未能充分保留数据集特性，需要更精确的模型以提升统计检验的可靠性。

Method: 提出基于二分联合度矩阵的零模型，并开发Alice算法套件，利用马尔可夫链蒙特卡洛方法高效采样。

Result: 实验表明Alice算法混合速度快、扩展性好，且新零模型能发现与以往不同的显著结果。

Conclusion: 新零模型和Alice算法为数据集分析提供了更精确的工具，适用于更广泛的统计检验场景。

Abstract: We introduce novel null models for assessing the results obtained from
observed binary transactional and sequence datasets, using statistical
hypothesis testing. Our null models maintain more properties of the observed
dataset than existing ones. Specifically, they preserve the Bipartite Joint
Degree Matrix of the bipartite (multi-)graph corresponding to the dataset,
which ensures that the number of caterpillars, i.e., paths of length three, is
preserved, in addition to other properties considered by other models. We
describe Alice, a suite of Markov chain Monte Carlo algorithms for sampling
datasets from our null models, based on a carefully defined set of states and
efficient operations to move between them. The results of our experimental
evaluation show that Alice mixes fast and scales well, and that our null model
finds different significant results than ones previously considered in the
literature.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [376] [Adversarial Text Generation with Dynamic Contextual Perturbation](https://arxiv.org/abs/2506.09148)
*Hetvi Waghela,Jaydip Sen,Sneha Rakshit,Subhasis Dasgupta*

Main category: cs.CR

TL;DR: 提出了一种名为DCP的动态上下文扰动方法，通过在句子、段落和文档层面生成上下文感知的扰动，提升对抗攻击的隐蔽性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法多关注词级或局部文本修改，忽略了上下文，导致扰动易被检测或语义不一致。

Method: 利用预训练语言模型，通过对抗目标函数动态生成并优化上下文感知的扰动，平衡误导模型和保持文本自然性。

Result: 实验表明，DCP能有效挑战现有NLP模型的鲁棒性，生成更自然的对抗样本。

Conclusion: DCP强调了上下文在对抗攻击中的重要性，为构建更鲁棒的NLP系统提供了基础。

Abstract: Adversarial attacks on Natural Language Processing (NLP) models expose
vulnerabilities by introducing subtle perturbations to input text, often
leading to misclassification while maintaining human readability. Existing
methods typically focus on word-level or local text segment alterations,
overlooking the broader context, which results in detectable or semantically
inconsistent perturbations. We propose a novel adversarial text attack scheme
named Dynamic Contextual Perturbation (DCP). DCP dynamically generates
context-aware perturbations across sentences, paragraphs, and documents,
ensuring semantic fidelity and fluency. Leveraging the capabilities of
pre-trained language models, DCP iteratively refines perturbations through an
adversarial objective function that balances the dual objectives of inducing
model misclassification and preserving the naturalness of the text. This
comprehensive approach allows DCP to produce more sophisticated and effective
adversarial examples that better mimic natural language patterns. Our
experimental results, conducted on various NLP models and datasets, demonstrate
the efficacy of DCP in challenging the robustness of state-of-the-art NLP
systems. By integrating dynamic contextual analysis, DCP significantly enhances
the subtlety and impact of adversarial attacks. This study highlights the
critical role of context in adversarial attacks and lays the groundwork for
creating more robust NLP systems capable of withstanding sophisticated
adversarial strategies.

</details>


### [377] [Empirical Quantification of Spurious Correlations in Malware Detection](https://arxiv.org/abs/2506.09662)
*Bianca Perasso,Ludovico Lozza,Andrea Ponte,Luca Demetrio,Luca Oneto,Fabio Roli*

Main category: cs.CR

TL;DR: 论文探讨了端到端深度学习在恶意软件检测中依赖虚假相关性的问题，尤其是编译器留下的空白空间对模型决策的影响，并通过小规模平衡数据集的分析比较了两种模型的适用性。


<details>
  <summary>Details</summary>
Motivation: 揭示深度学习模型在恶意软件检测中如何依赖虚假相关性，尤其是编译器留下的空白空间，以量化其对决策的影响。

Method: 在小规模平衡数据集上对两种端到端深度学习模型进行对比分析，量化其对虚假相关性的依赖程度。

Result: 研究发现模型主要依赖编译器留下的空白空间，而非编译代码本身，这降低了模型的实际有效性。

Conclusion: 通过分析比较，论文为选择更适合实际生产的模型提供了依据，同时揭示了深度学习在恶意软件检测中的局限性。

Abstract: End-to-end deep learning exhibits unmatched performance for detecting
malware, but such an achievement is reached by exploiting spurious correlations
-- features with high relevance at inference time, but known to be useless
through domain knowledge. While previous work highlighted that deep networks
mainly focus on metadata, none investigated the phenomenon further, without
quantifying their impact on the decision. In this work, we deepen our
understanding of how spurious correlation affects deep learning for malware
detection by highlighting how much models rely on empty spaces left by the
compiler, which diminishes the relevance of the compiled code. Through our
seminal analysis on a small-scale balanced dataset, we introduce a ranking of
two end-to-end models to better understand which is more suitable to be put in
production.

</details>


### [378] [DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt](https://arxiv.org/abs/2506.09353)
*Yitong Zhang,Jia Li,Liyi Cai,Ge Li*

Main category: cs.CR

TL;DR: 论文提出了一种名为DAVSP的方法，通过视觉安全提示和深度对齐技术，有效抵御恶意查询，同时保持良性输入的实用性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多种应用中表现优异，但对恶意查询的视觉模态攻击仍存在脆弱性，现有对齐方法难以兼顾安全性与实用性。

Method: 1. 引入视觉安全提示，在输入图像周围添加可训练填充区域；2. 提出深度对齐方法，通过模型激活空间的监督训练视觉安全提示。

Result: 在五个基准测试和两种代表性LVLMs上的实验表明，DAVSP能有效抵御恶意查询并保持良性输入实用性，且具备跨模型生成能力。

Conclusion: DAVSP通过视觉安全提示和深度对齐的联合作用，显著提升了模型的安全性和实用性，代码已开源。

Abstract: Large Vision-Language Models (LVLMs) have achieved impressive progress across
various applications but remain vulnerable to malicious queries that exploit
the visual modality. Existing alignment approaches typically fail to resist
malicious queries while preserving utility on benign ones effectively. To
address these challenges, we propose Deep Aligned Visual Safety Prompt (DAVSP),
which is built upon two key innovations. First, we introduce the Visual Safety
Prompt, which appends a trainable padding region around the input image. It
preserves visual features and expands the optimization space. Second, we
propose Deep Alignment, a novel approach to train the visual safety prompt
through supervision in the model's activation space. It enhances the inherent
ability of LVLMs to perceive malicious queries, achieving deeper alignment than
prior works. Extensive experiments across five benchmarks on two representative
LVLMs demonstrate that DAVSP effectively resists malicious queries while
preserving benign input utility. Furthermore, DAVSP exhibits great cross-model
generation ability. Ablation studies further reveal that both the Visual Safety
Prompt and Deep Alignment are essential components, jointly contributing to its
overall effectiveness. The code is publicly available at
https://github.com/zhangyitonggg/DAVSP.

</details>


### [379] [What is the Cost of Differential Privacy for Deep Learning-Based Trajectory Generation?](https://arxiv.org/abs/2506.09312)
*Erik Buchholz,Natasha Fernandes,David D. Nguyen,Alsharif Abuadbba,Surya Nepal,Salil S. Kanhere*

Main category: cs.CR

TL;DR: 论文研究了在生成合成轨迹时如何平衡隐私保护（差分隐私）与数据效用，提出了新的DP机制并评估了不同模型的效果。


<details>
  <summary>Details</summary>
Motivation: 位置轨迹数据包含敏感信息，现有生成模型缺乏正式隐私保护，需研究如何在保证隐私的同时维持数据效用。

Method: 1. 评估DP-SGD对生成模型效用的影响；2. 提出一种新的DP机制用于条件生成；3. 比较Diffusion、VAE和GAN模型的效用-隐私权衡。

Result: DP-SGD显著影响性能，但大数据集下仍保留部分效用；新DP机制提升训练稳定性；Diffusion模型无隐私保证时表现最佳，但GAN在DP-SGD下最优。

Conclusion: DP轨迹生成仍具挑战性，正式隐私保护仅适用于大数据集和受限场景。

Abstract: While location trajectories offer valuable insights, they also reveal
sensitive personal information. Differential Privacy (DP) offers formal
protection, but achieving a favourable utility-privacy trade-off remains
challenging. Recent works explore deep learning-based generative models to
produce synthetic trajectories. However, current models lack formal privacy
guarantees and rely on conditional information derived from real data during
generation. This work investigates the utility cost of enforcing DP in such
models, addressing three research questions across two datasets and eleven
utility metrics. (1) We evaluate how DP-SGD, the standard DP training method
for deep learning, affects the utility of state-of-the-art generative models.
(2) Since DP-SGD is limited to unconditional models, we propose a novel DP
mechanism for conditional generation that provides formal guarantees and assess
its impact on utility. (3) We analyse how model types - Diffusion, VAE, and GAN
- affect the utility-privacy trade-off. Our results show that DP-SGD
significantly impacts performance, although some utility remains if the
datasets is sufficiently large. The proposed DP mechanism improves training
stability, particularly when combined with DP-SGD, for unstable models such as
GANs and on smaller datasets. Diffusion models yield the best utility without
guarantees, but with DP-SGD, GANs perform best, indicating that the best
non-private model is not necessarily optimal when targeting formal guarantees.
In conclusion, DP trajectory generation remains a challenging task, and formal
guarantees are currently only feasible with large datasets and in constrained
use cases.

</details>


### [380] [TooBadRL: Trigger Optimization to Boost Effectiveness of Backdoor Attacks on Deep Reinforcement Learning](https://arxiv.org/abs/2506.09562)
*Songze Li,Mingxuan Zhang,Oubo Ma,Kang Wei,Shouling Ji*

Main category: cs.CR

TL;DR: TooBadRL是一个系统优化DRL后门攻击触发器的框架，通过时间、空间和幅度三个维度提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击依赖简单启发式触发器配置，忽视了触发器优化的潜力。

Method: 提出性能感知的自适应冻结机制、基于合作游戏的维度选择和梯度优化的幅度调整。

Result: 在三种主流DRL算法和九项基准任务中显著提高攻击成功率，同时保持正常任务性能。

Conclusion: 触发器优化在DRL后门攻击中具有重要但被低估的作用。

Abstract: Deep reinforcement learning (DRL) has achieved remarkable success in a wide
range of sequential decision-making domains, including robotics, healthcare,
smart grids, and finance. Recent research demonstrates that attackers can
efficiently exploit system vulnerabilities during the training phase to execute
backdoor attacks, producing malicious actions when specific trigger patterns
are present in the state observations. However, most existing backdoor attacks
rely primarily on simplistic and heuristic trigger configurations, overlooking
the potential efficacy of trigger optimization. To address this gap, we
introduce TooBadRL (Trigger Optimization to Boost Effectiveness of Backdoor
Attacks on DRL), the first framework to systematically optimize DRL backdoor
triggers along three critical axes, i.e., temporal, spatial, and magnitude.
Specifically, we first introduce a performance-aware adaptive freezing
mechanism for injection timing. Then, we formulate dimension selection as a
cooperative game, utilizing Shapley value analysis to identify the most
influential state variable for the injection dimension. Furthermore, we propose
a gradient-based adversarial procedure to optimize the injection magnitude
under environment constraints. Evaluations on three mainstream DRL algorithms
and nine benchmark tasks show that TooBadRL significantly improves attack
success rates, while ensuring minimal degradation of normal task performance.
These results highlight the previously underappreciated importance of
principled trigger optimization in DRL backdoor attacks. The source code of
TooBadRL can be found at https://github.com/S3IC-Lab/TooBadRL.

</details>


### [381] [LLMail-Inject: A Dataset from a Realistic Adaptive Prompt Injection Challenge](https://arxiv.org/abs/2506.09956)
*Sahar Abdelnabi,Aideen Fay,Ahmed Salem,Egor Zverev,Kai-Chieh Liao,Chi-Huang Liu,Chun-Chih Kuo,Jannis Weigend,Danyael Manlangit,Alex Apostolov,Haris Umair,João Donato,Masayuki Kawakita,Athar Mahboob,Tran Huu Bach,Tsun-Han Chiang,Myeongjin Cho,Hajin Choi,Byeonghyeon Kim,Hyeonjin Lee,Benjamin Pannell,Conor McCauley,Mark Russinovich,Andrew Paverd,Giovanni Cherubin*

Main category: cs.CR

TL;DR: 论文通过LLMail-Inject挑战系统评估间接提示注入攻击，揭示了LLM在区分指令与数据时的局限性，并提供了数据集和分析以推动未来防御研究。


<details>
  <summary>Details</summary>
Motivation: 现有防御方案对适应性攻击者的系统性评估不足，而成功的攻击可能导致严重的安全和隐私问题，许多实际应用仍易受攻击。

Method: 通过LLMail-Inject公共挑战，模拟真实场景，参与者尝试在电子邮件中注入恶意指令以触发未经授权的工具调用。

Result: 挑战收集了208,095次攻击提交，涵盖多种防御策略、LLM架构和检索配置，提供了丰富的数据集和分析。

Conclusion: 研究为未来解决提示注入问题提供了基础，推动了实用结构化解决方案的研究。

Abstract: Indirect Prompt Injection attacks exploit the inherent limitation of Large
Language Models (LLMs) to distinguish between instructions and data in their
inputs. Despite numerous defense proposals, the systematic evaluation against
adaptive adversaries remains limited, even when successful attacks can have
wide security and privacy implications, and many real-world LLM-based
applications remain vulnerable. We present the results of LLMail-Inject, a
public challenge simulating a realistic scenario in which participants
adaptively attempted to inject malicious instructions into emails in order to
trigger unauthorized tool calls in an LLM-based email assistant. The challenge
spanned multiple defense strategies, LLM architectures, and retrieval
configurations, resulting in a dataset of 208,095 unique attack submissions
from 839 participants. We release the challenge code, the full dataset of
submissions, and our analysis demonstrating how this data can provide new
insights into the instruction-data separation problem. We hope this will serve
as a foundation for future research towards practical structural solutions to
prompt injection.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [382] [A theoretical basis for model collapse in recursive training](https://arxiv.org/abs/2506.09401)
*Vivek Shripad Borkar*

Main category: math.PR

TL;DR: 递归训练生成模型可能导致概率分布“崩溃”，但研究表明，是否引入外部样本会影响两种不同的渐进行为。


<details>
  <summary>Details</summary>
Motivation: 探讨递归训练生成模型时概率分布崩溃的现象，并研究外部样本对行为的影响。

Method: 分析递归训练生成模型的动态过程，比较有无外部样本输入时的渐进行为。

Result: 发现引入外部样本会导致两种不同的渐进行为，避免完全崩溃。

Conclusion: 外部样本的引入可以改变生成模型的渐进行为，防止分布崩溃。

Abstract: It is known that recursive training from generative models can lead to the so
called `collapse' of the simulated probability distribution. This note shows
that one in fact gets two different asymptotic behaviours depending on whether
an external source, howsoever minor, is also contributing samples.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [383] [A Study on Speech Assessment with Visual Cues](https://arxiv.org/abs/2506.09549)
*Shafique Ahmed,Ryandhimas E. Zezario,Nasir Saleem,Amir Hussain,Hsin-Min Wang,Yu Tsao*

Main category: eess.AS

TL;DR: 提出了一种多模态框架，结合音频和视觉特征预测PESQ和STOI分数，优于仅音频基线。


<details>
  <summary>Details</summary>
Motivation: 在缺乏干净参考信号时，非侵入式评估语音质量和清晰度至关重要。

Method: 采用双分支架构，分别提取音频频谱特征和视觉嵌入，通过CNN-BLSTM与注意力机制融合，多任务学习预测PESQ和STOI。

Result: 在LRS3-TED数据集上，模型在PESQ和STOI上分别提升9.61%和11.47%。

Conclusion: 视觉线索的引入显著提升了非侵入式语音评估的准确性。

Abstract: Non-intrusive assessment of speech quality and intelligibility is essential
when clean reference signals are unavailable. In this work, we propose a
multimodal framework that integrates audio features and visual cues to predict
PESQ and STOI scores. It employs a dual-branch architecture, where spectral
features are extracted using STFT, and visual embeddings are obtained via a
visual encoder. These features are then fused and processed by a CNN-BLSTM with
attention, followed by multi-task learning to simultaneously predict PESQ and
STOI. Evaluations on the LRS3-TED dataset, augmented with noise from the DEMAND
corpus, show that our model outperforms the audio-only baseline. Under seen
noise conditions, it improves LCC by 9.61% (0.8397->0.9205) for PESQ and 11.47%
(0.7403->0.8253) for STOI. These results highlight the effectiveness of
incorporating visual cues in enhancing the accuracy of non-intrusive speech
assessment.

</details>


### [384] [Regularizing Learnable Feature Extraction for Automatic Speech Recognition](https://arxiv.org/abs/2506.09804)
*Peter Vieting,Maximilian Kannen,Benedikt Hilmes,Ralf Schlüter,Hermann Ney*

Main category: eess.AS

TL;DR: 论文研究了可学习特征提取前端在ASR系统中的正则化方法，通过音频扰动和STFT域掩码改进性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定特征提取方法在ASR中表现优于可学习前端，主要原因是后者易过拟合。

Method: 研究了音频扰动方法，并提出了STFT域掩码作为改进SpecAugment的简单有效方法。

Result: 结合两种正则化方法，可学习特征与传统特征性能差距显著缩小。

Conclusion: 正则化方法有效提升了可学习特征前端的性能，使其接近传统方法。

Abstract: Neural front-ends are an appealing alternative to traditional, fixed feature
extraction pipelines for automatic speech recognition (ASR) systems since they
can be directly trained to fit the acoustic model. However, their performance
often falls short compared to classical methods, which we show is largely due
to their increased susceptibility to overfitting. This work therefore
investigates regularization methods for training ASR models with learnable
feature extraction front-ends. First, we examine audio perturbation methods and
show that larger relative improvements can be obtained for learnable features.
Additionally, we identify two limitations in the standard use of SpecAugment
for these front-ends and propose masking in the short time Fourier transform
(STFT)-domain as a simple but effective modification to address these
challenges. Finally, integrating both regularization approaches effectively
closes the performance gap between traditional and learnable features.

</details>


### [385] [Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements](https://arxiv.org/abs/2506.09707)
*Suhas BN,Andrew M. Sherrill,Jyoti Alaparthi,Dominik Mattioli,Rosa I. Arriaga,Chris W. Wiese,Saeed Abdullah*

Main category: eess.AS

TL;DR: 提出了一种基于音频和转录文本的自动定位方法，用于评估Prolonged Exposure (PE)治疗中的关键元素，减少人工审核负担。


<details>
  <summary>Details</summary>
Motivation: PE疗法对PTSD有效，但评估治疗师依从性需人工审核录音，效率低下。

Method: 利用预训练音频-语言模型Qwen2-Audio，通过LoRA微调处理30秒音频-转录窗口，生成核心阶段的标签。

Result: 在313个真实PE会话中，最佳配置（LoRA rank 8，30秒窗口）的平均绝对误差为5.3秒。

Conclusion: 该方法为PE治疗依从性跟踪提供了可扩展框架，支持临床培训和质量保证。

Abstract: Prolonged Exposure (PE) therapy is an effective treatment for post-traumatic
stress disorder (PTSD), but evaluating therapist fidelity remains
labor-intensive due to the need for manual review of session recordings. We
present a method for the automatic temporal localization of key PE fidelity
elements -- identifying their start and stop times -- directly from session
audio and transcripts. Our approach fine-tunes a large pre-trained
audio-language model, Qwen2-Audio, using Low-Rank Adaptation (LoRA) to process
focused 30-second windows of audio-transcript input. Fidelity labels for three
core protocol phases -- therapist orientation (P1), imaginal exposure (P2), and
post-imaginal processing (P3) -- are generated via LLM-based prompting and
verified by trained raters. The model is trained to predict normalized boundary
offsets using soft supervision guided by task-specific prompts. On a dataset of
313 real PE sessions, our best configuration (LoRA rank 8, 30s windows)
achieves a mean absolute error (MAE) of 5.3 seconds across tasks. We further
analyze the effects of window size and LoRA rank, highlighting the importance
of context granularity and model adaptation. This work introduces a scalable
framework for fidelity tracking in PE therapy, with potential to support
clinician training, supervision, and quality assurance.

</details>


### [386] [You Are What You Say: Exploiting Linguistic Content for VoicePrivacy Attacks](https://arxiv.org/abs/2506.09521)
*Ünal Ege Gaznepoglu,Anna Leschanowsky,Ahmad Aloradi,Prachi Singh,Daniel Tenbrinck,Emanuël A. P. Habets,Nils Peters*

Main category: eess.AS

TL;DR: 研究评估了说话人匿名化系统的隐私保护效果，通过BERT模型作为自动说话人验证系统，发现数据集中的语言内容相似性会影响评估结果。


<details>
  <summary>Details</summary>
Motivation: 评估说话人匿名化系统的隐私保护效果，并探讨数据集中的语言内容相似性对评估的影响。

Method: 使用BERT模型作为自动说话人验证系统，分析VoicePrivacy Attacker Challenge数据集中的语言内容。

Result: 平均等错误率为35%，部分说话人低至2%，系统决策与语义相似关键词相关。

Conclusion: 建议重新设计VoicePrivacy数据集以确保公平评估，并质疑全局等错误率在隐私评估中的可靠性。

Abstract: Speaker anonymization systems hide the identity of speakers while preserving
other information such as linguistic content and emotions. To evaluate their
privacy benefits, attacks in the form of automatic speaker verification (ASV)
systems are employed. In this study, we assess the impact of intra-speaker
linguistic content similarity in the attacker training and evaluation datasets,
by adapting BERT, a language model, as an ASV system. On the VoicePrivacy
Attacker Challenge datasets, our method achieves a mean equal error rate (EER)
of 35%, with certain speakers attaining EERs as low as 2%, based solely on the
textual content of their utterances. Our explainability study reveals that the
system decisions are linked to semantically similar keywords within utterances,
stemming from how LibriSpeech is curated. Our study suggests reworking the
VoicePrivacy datasets to ensure a fair and unbiased evaluation and challenge
the reliance on global EER for privacy evaluations.

</details>


<div id='physics.ed-ph'></div>

# physics.ed-ph [[Back]](#toc)

### [387] [Particle Builder -- Learn about the Standard Model while playing against an AI](https://arxiv.org/abs/2506.09054)
*Mohammad Attar,Andrew Carse,Yeming Chen,Thomas Green,Jeong-Yeon Ha,Yanbai Jin,Amy McWilliams,Theirry Panggabean,Zhengyu Peng,Lujin Sun,Jing Ru,Jiacheng She,Jialin Wang,Zilun Wei,Jiayuan Zhu,Lachlan McGinness*

Main category: physics.ed-ph

TL;DR: Particle Builder Online是一款基于网页的教育游戏，旨在帮助高中物理学生熟悉粒子物理标准模型。


<details>
  <summary>Details</summary>
Motivation: 设计这款游戏的目的是通过游戏化学习提高学生对粒子物理的理解，并适应国际文凭和澳大利亚课程。

Method: 学生可以与AI或同学对战，完成课程后进行了前后测试和调查。

Result: 学生对粒子物理概念的理解显著提升，且认为游戏比传统课堂更有趣和有效。

Conclusion: 游戏化学习在高中物理教育中具有潜力，能够提升学习效果和兴趣。

Abstract: Particle Builder Online is a web-based education game designed for high
school physics students. Students can play against an AI opponent or peers to
familiarise themselves with the Standard Model of Particle Physics. The game is
aimed at a high school level and tailored to the International Baccalaureate
and the Australian Curriculum. Students from four schools in Canberra took
pre/post-tests and a survey while completing a lesson where they played
Particle Builder. Students' understanding of particle physics concepts improved
significantly. Students found the game more enjoyable and effective than
regular classroom lessons.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [388] [Devanagari Digit Recognition using Quantum Machine Learning](https://arxiv.org/abs/2506.09069)
*Sahaj Raj Malla*

Main category: quant-ph

TL;DR: 本文提出了一种混合量子-经典架构，用于Devanagari手写数字识别，结合CNN和量子电路，实现了99.80%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: Devanagari手写数字识别对多语言文档数字化、教育工具和文化遗产保护至关重要，但其复杂结构和有限标注数据对传统模型构成挑战。

Method: 采用卷积神经网络（CNN）进行空间特征提取，结合10量子比特变分量子电路（VQC）进行量子增强分类。

Result: 在Devanagari手写字符数据集（DHCD）上，模型测试准确率达99.80%，测试损失为0.2893，平均每类F1分数为0.9980。

Conclusion: 该模型在参数更少的情况下优于经典CNN，展示了量子机器学习在低资源语言场景中的潜力。

Abstract: Handwritten digit recognition in regional scripts, such as Devanagari, is
crucial for multilingual document digitization, educational tools, and the
preservation of cultural heritage. The script's complex structure and limited
annotated datasets pose significant challenges to conventional models. This
paper introduces the first hybrid quantum-classical architecture for Devanagari
handwritten digit recognition, combining a convolutional neural network (CNN)
for spatial feature extraction with a 10-qubit variational quantum circuit
(VQC) for quantum-enhanced classification. Trained and evaluated on the
Devanagari Handwritten Character Dataset (DHCD), the proposed model achieves a
state-of-the-art test accuracy for quantum implementation of 99.80% and a test
loss of 0.2893, with an average per-class F1-score of 0.9980. Compared to
equivalent classical CNNs, our model demonstrates superior accuracy with
significantly fewer parameters and enhanced robustness. By leveraging quantum
principles such as superposition and entanglement, this work establishes a
novel benchmark for regional script recognition, highlighting the promise of
quantum machine learning (QML) in real-world, low-resource language settings.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [389] [A Multi-Armed Bandit Framework for Online Optimisation in Green Integrated Terrestrial and Non-Terrestrial Networks](https://arxiv.org/abs/2506.09268)
*Henri Alam,Antonio de Domenico,Tareq Si Salem,Florian Kaltenberger*

Main category: cs.NI

TL;DR: 论文提出了一种基于多臂老虎机（MAB）的在线优化框架，用于集成地面与非地面网络（TN-NTN），旨在平衡网络容量与能源效率。


<details>
  <summary>Details</summary>
Motivation: 随着地面网络部署密度的增加，探索非地面网络（NTN）在减轻地面网络负载和实现可持续网络方面的潜力。

Method: 采用多臂老虎机（MAB）和Bandit-feedback Constrained Online Mirror Descent（BCOMD）算法，实时优化带宽分配、用户设备关联和宏基站关闭等参数。

Result: 系统级模拟显示，该框架在高峰时段显著减少未满足需求的用户设备比例，并在低流量时段实现19%的吞吐量提升和5%的节能。

Conclusion: 提出的框架在集成TN-NTN架构中表现出色，优于3GPP标准设置，为可持续网络提供了有效解决方案。

Abstract: Integrated terrestrial and non-terrestrial network (TN-NTN) architectures
offer a promising solution for expanding coverage and improving capacity for
the network. While non-terrestrial networks (NTNs) are primarily exploited for
these specific reasons, their role in alleviating terrestrial network (TN) load
and enabling energy-efficient operation has received comparatively less
attention. In light of growing concerns associated with the densification of
terrestrial deployments, this work aims to explore the potential of NTNs in
supporting a more sustainable network. In this paper, we propose a novel online
optimisation framework for integrated TN-NTN architectures, built on a
multi-armed bandit (MAB) formulation and leveraging the Bandit-feedback
Constrained Online Mirror Descent (BCOMD) algorithm. Our approach adaptively
optimises key system parameters--including bandwidth allocation, user equipment
(UE) association, and macro base station (MBS) shutdown--to balance network
capacity and energy efficiency in real time. Extensive system-level simulations
over a 24-hour period show that our framework significantly reduces the
proportion of unsatisfied UEs during peak hours and achieves up to 19%
throughput gains and 5% energy savings in low-traffic periods, outperforming
standard network settings following 3GPP recommendations.

</details>


### [390] [Real-Time Network Traffic Forecasting with Missing Data: A Generative Model Approach](https://arxiv.org/abs/2506.09647)
*Lei Deng,Wenhan Xu,Jingwei Li,Danny H. K. Tsang*

Main category: cs.NI

TL;DR: 提出了一种基于生成模型的实时网络流量预测方法，解决了数据缺失问题，通过张量补全和预训练生成模型实现高效预测。


<details>
  <summary>Details</summary>
Motivation: 现有网络流量预测方法假设数据完整，但实际数据常因人为或自然因素缺失，需解决这一问题。

Method: 将流量预测建模为张量补全问题，利用预训练生成模型捕获数据的低秩结构，优化潜在表示实现实时预测。

Result: 在真实数据集上验证，预测误差（MAE）低于0.002，响应时间在100毫秒内。

Conclusion: 该方法在数据缺失情况下仍能实现高精度实时预测，具有理论和实践价值。

Abstract: Real-time network traffic forecasting is crucial for network management and
early resource allocation. Existing network traffic forecasting approaches
operate under the assumption that the network traffic data is fully observed.
However, in practical scenarios, the collected data are often incomplete due to
various human and natural factors. In this paper, we propose a generative model
approach for real-time network traffic forecasting with missing data. Firstly,
we model the network traffic forecasting task as a tensor completion problem.
Secondly, we incorporate a pre-trained generative model to achieve the low-rank
structure commonly associated with tensor completion. The generative model
effectively captures the intrinsic low-rank structure of network traffic data
during pre-training and enables the mapping from a compact latent
representation to the tensor space. Thirdly, rather than directly optimizing
the high-dimensional tensor, we optimize its latent representation, which
simplifies the optimization process and enables real-time forecasting. We also
establish a theoretical recovery guarantee that quantifies the error bound of
the proposed approach. Experiments on real-world datasets demonstrate that our
approach achieves accurate network traffic forecasting within 100 ms, with a
mean absolute error (MAE) below 0.002, as validated on the Abilene dataset.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [391] [Stakeholder Participation for Responsible AI Development: Disconnects Between Guidance and Current Practice](https://arxiv.org/abs/2506.09873)
*Emma Kallina,Thomas Bohné,Jat Singh*

Main category: cs.SE

TL;DR: 研究探讨了现有利益相关者参与（SHI）实践对负责任AI（rAI）的贡献及其潜在脱节，提出了改进措施。


<details>
  <summary>Details</summary>
Motivation: 明确现有SHI实践是否能支持rAI目标，并为未来干预提供依据。

Method: 分析56份rAI指南，进行在线调查（n=130）和半结构化访谈（n=10）。

Result: SHI实践主要受商业目标驱动，与rAI目标脱节。

Conclusion: 需针对性干预以推动SHI实践向rAI对齐。

Abstract: Responsible AI (rAI) guidance increasingly promotes stakeholder involvement
(SHI) during AI development. At the same time, SHI is already common in
commercial software development, but with potentially different foci. This
study clarifies the extent to which established SHI practices are able to
contribute to rAI efforts as well as potential disconnects -- essential
insights to inform and tailor future interventions that further shift industry
practice towards rAI efforts. First, we analysed 56 rAI guidance documents to
identify why SHI is recommended (i.e. its expected benefits for rAI) and
uncovered goals such as redistributing power, improving socio-technical
understandings, anticipating risks, and enhancing public oversight. To
understand why and how SHI is currently practised in commercial settings, we
then conducted an online survey (n=130) and semi-structured interviews (n=10)
with AI practitioners. Our findings reveal that SHI in practice is primarily
driven by commercial priorities (e.g. customer value, compliance) and several
factors currently discourage more rAI-aligned SHI practices. This suggests that
established SHI practices are largely not contributing to rAI efforts. To
address this disconnect, we propose interventions and research opportunities to
advance rAI development in practice.

</details>


### [392] [UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench](https://arxiv.org/abs/2506.09289)
*Boxi Yu,Yuxuan Zhu,Pinjia He,Daniel Kang*

Main category: cs.SE

TL;DR: 论文提出UTGenerator和UTBoost框架，用于自动生成测试用例并增强SWE-Bench基准，解决了手动测试用例不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有SWE-Bench基准中的手动测试用例不足以检测代码生成代理生成的补丁是否真正解决问题，导致错误补丁被误判为通过。

Method: 引入UTGenerator（基于LLM的测试用例生成器）和UTBoost框架，自动分析代码库和依赖关系生成测试用例。

Result: 在评估中，发现了36个测试用例不足的任务实例和345个错误补丁，影响了SWE-Bench的排行榜排名。

Conclusion: UTGenerator和UTBoost能有效提升测试用例质量，显著改善代码生成代理的评估准确性。

Abstract: The advent of Large Language Models (LLMs) has spurred the development of
coding agents for real-world code generation. As a widely used benchmark for
evaluating the code generation capabilities of these agents, SWE-Bench uses
real-world problems based on GitHub issues and their corresponding pull
requests. However, the manually written test cases included in these pull
requests are often insufficient, allowing generated patches to pass the tests
without resolving the underlying issue. To address this challenge, we introduce
UTGenerator, an LLM-driven test case generator that automatically analyzes
codebases and dependencies to generate test cases for real-world Python
projects. Building on UTGenerator, we propose UTBoost, a comprehensive
framework for test case augmentation. In our evaluation, we identified 36 task
instances with insufficient test cases and uncovered 345 erroneous patches
incorrectly labeled as passed in the original SWE Bench. These corrections,
impacting 40.9% of SWE-Bench Lite and 24.4% of SWE-Bench Verified leaderboard
entries, yield 18 and 11 ranking changes, respectively.

</details>


### [393] [Reasoning as a Resource: Optimizing Fast and Slow Thinking in Code Generation Models](https://arxiv.org/abs/2506.09396)
*Zongjie Li,Shuai Wang*

Main category: cs.SE

TL;DR: 提出将推理深度作为可控资源，优化代码生成模型的设计，以平衡快速直接答案与详细推理之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统代码生成模型未明确管理推理深度，导致在准确性、延迟和成本之间的权衡不足。

Method: 通过自适应控制推理深度，从数据创建到部署全生命周期优化推理预算。

Result: 该方法能提升监督信号、推动多维基准测试，并支持成本和安全意识的部署策略。

Conclusion: 将快速与慢速推理视为互补模式，可实现代码代理在必要时深入思考，在可能时快速行动。

Abstract: This position paper proposes a fundamental shift in designing code generation
models: treating reasoning depth as a controllable resource. Rather than being
an incidental byproduct of prompting, we argue that the trade-off between
rapid, direct answers ("fast thinking") and elaborate, chain-of-thought
deliberation ("slow thinking") must be explicitly managed. We contend that
optimizing reasoning budgets across the entire model lifecycle - from synthetic
data creation and benchmarking to real-world deploymen - can unlock superior
trade-offs among accuracy, latency, and cost. This paper outlines how adaptive
control over reasoning can enrich supervision signals, motivate new
multi-dimensional benchmarks, and inform cost-aware, security-conscious
deployment policies. By viewing fast and slow thinking as complementary modes
to be scheduled, we envision coding agents that think deep when necessary and
act fast when possible.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [394] [A Probabilistic Framework for Imputing Genetic Distances in Spatiotemporal Pathogen Models](https://arxiv.org/abs/2506.09076)
*Haley Stone,Jing Du,Hao Xue,Matthew Scotch,David Heslop,Andreas Züfle,Chandini Raina MacIntyre,Flora Salim*

Main category: q-bio.GN

TL;DR: 提出一种概率框架，通过时间感知的进化距离模型，推断未测序病例与已知序列之间的遗传距离，支持基因组数据的不确定性增强。


<details>
  <summary>Details</summary>
Motivation: 病原体基因组数据在空间模型中有重要价值，但测序覆盖不完整限制了其应用。

Method: 利用时间感知的进化距离模型，估计未测序病例与已知序列之间的遗传距离，无需序列比对或已知传播链。

Result: 应用于美国野生鸟类高致病性禽流感A/H5病例，支持基因组数据的不确定性增强和进化信息的整合。

Conclusion: 该方法为基因组数据的不完整提供了可行的解决方案，增强了时空建模中进化信息的利用。

Abstract: Pathogen genome data offers valuable structure for spatial models, but its
utility is limited by incomplete sequencing coverage. We propose a
probabilistic framework for inferring genetic distances between unsequenced
cases and known sequences within defined transmission chains, using time-aware
evolutionary distance modeling. The method estimates pairwise divergence from
collection dates and observed genetic distances, enabling biologically
plausible imputation grounded in observed divergence patterns, without
requiring sequence alignment or known transmission chains. Applied to highly
pathogenic avian influenza A/H5 cases in wild birds in the United States, this
approach supports scalable, uncertainty-aware augmentation of genomic datasets
and enhances the integration of evolutionary information into spatiotemporal
modeling workflows.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [395] [Delegations as Adaptive Representation Patterns: Rethinking Influence in Liquid Democracy](https://arxiv.org/abs/2506.09789)
*Davide Grossi,Andreas Nitsche*

Main category: cs.CY

TL;DR: 本文提出了一种新的方法来评估流动民主中投票节点的影响力，考虑了现实世界中委托和投票的独立性，并展示了传递性如何有效调节决策权力。


<details>
  <summary>Details</summary>
Motivation: 研究流动民主中传递性对权力积累的影响，探索其作为适应性民主代表过程的潜力。

Method: 通过LiquidFeedback软件支持的流动民主实现，提出了一种新的委托模型，分析传递性对影响力的调节作用。

Result: 传递性可以显著降低代理人的预期影响力，遵循指数下降轨迹，同时保持一人一票原则。

Conclusion: 流动民主的适应性特征值得深入研究，本文为这一领域的研究奠定了基础，并提出了未来的研究方向。

Abstract: Liquid democracy is a mechanism for the division of labor in decision-making
through the transitive delegation of influence. In essence, all individuals
possess the autonomy to determine the issues with which they will engage
directly, while for other matters, they may appoint a representative of their
choosing. So far, the literature has studied the delegation structures emerging
in liquid democracy as static. As a result, transitivity defined as the
capacity to transfer acquired authority to another entity, has been identified
as a concern as it would be conducive to unrestrained accumulation of power.
  Focusing on the implementation of liquid democracy supported by the
LiquidFeedback software, we propose a novel approach to assessing the influence
of voting nodes in a transitive delegation graph, taking into account the
process nature of real-world liquid democracy in which delegation and voting
are distinct and increasingly independent activities. By introducing a novel
model of delegations in liquid democracy, we show how transitivity may in fact
contribute to an effective regulation of deliberation influence and
decision-making power. While maintaining the one-person, one-vote paradigm for
all votes cast, the anticipated influence of an agent, to the extent it is
stemming from transitivity, experiences a precipitous decline following an
exponential trajectory.
  In general, it is our objective to move the first steps towards a rigorous
analysis of liquid democracy as an adaptive democratic representation process.
The adaptivity aspect of liquid democracy has not yet been explored within the
existing academic literature despite it being, we believe, one of its most
important features. We therefore also outline a research agenda focusing on
this aspect of liquid democracy.

</details>


### [396] [Understanding and Improving Data Repurposing](https://arxiv.org/abs/2506.09073)
*J. Parsons,R. Lukyanenko,B. Greenwood,C. Cooper*

Main category: cs.CY

TL;DR: 本文探讨了数据再利用的重要性及其与原始数据使用和重复使用的区别，提出了一个数据再利用框架，并通过医疗和公民科学领域的例子加以说明。


<details>
  <summary>Details</summary>
Motivation: 在数据广泛再利用的时代，研究数据再利用作为数据管理的前沿问题具有重要意义。

Method: 提出了一个数据再利用框架，包含适应现有数据到新任务的概念和活动。

Result: 通过医疗和公民科学领域的例子展示了框架的应用。

Conclusion: 建议未来研究进一步理解数据再利用，并优化其实践方法。

Abstract: We live in an age of unprecedented opportunities to use existing data for
tasks not anticipated when those data were collected, resulting in widespread
data repurposing. This commentary defines and maps the scope of data
repurposing to highlight its importance for organizations and society and the
need to study data repurposing as a frontier of data management. We explain how
repurposing differs from original data use and data reuse and then develop a
framework for data repurposing consisting of concepts and activities for
adapting existing data to new tasks. The framework and its implications are
illustrated using two examples of repurposing, one in healthcare and one in
citizen science. We conclude by suggesting opportunities for research to better
understand data repurposing and enable more effective data repurposing
practices.

</details>


### [397] [Understanding Human-AI Trust in Education](https://arxiv.org/abs/2506.09160)
*Griffin Pitts,Sanaz Motamedi*

Main category: cs.CY

TL;DR: 研究探讨学生对AI聊天机器人的信任类型（人际信任与技术信任）如何影响其使用意愿和学习效果，发现两种信任类型对学生的感知和行为有不同影响，提出需要新的人机信任理论框架。


<details>
  <summary>Details</summary>
Motivation: AI聊天机器人在教育中的应用日益广泛，但其拟人化特性导致学生对它的信任类型模糊，现有信任模型（人际信任与技术信任）可能不适用，需明确其影响。

Method: 采用偏最小二乘结构方程模型（PLS-SEM），分析学生对AI聊天机器人的信任类型（人际信任与技术信任）如何影响其感知享受、信任意图、使用意图和感知有用性。

Result: 人际信任更强烈预测信任意图，而技术信任更有效预测使用意图和感知有用性；两种信任对感知享受的影响相似。

Conclusion: 学生与AI聊天机器人形成了一种独特的信任类型（人机信任），不同于传统的人际或技术信任模型，需开发新理论框架以支持AI在教育中的有效应用。

Abstract: As AI chatbots become increasingly integrated in education, students are
turning to these systems for guidance, feedback, and information. However, the
anthropomorphic characteristics of these chatbots create ambiguity regarding
whether students develop trust toward them as they would a human peer or
instructor, based in interpersonal trust, or as they would any other piece of
technology, based in technology trust. This ambiguity presents theoretical
challenges, as interpersonal trust models may inappropriately ascribe human
intentionality and morality to AI, while technology trust models were developed
for non-social technologies, leaving their applicability to anthropomorphic
systems unclear. To address this gap, we investigate how human-like and
system-like trusting beliefs comparatively influence students' perceived
enjoyment, trusting intention, behavioral intention to use, and perceived
usefulness of an AI chatbot - factors associated with students' engagement and
learning outcomes. Through partial least squares structural equation modeling,
we found that human-like and system-like trust significantly influenced student
perceptions, with varied effects. Human-like trust more strongly predicted
trusting intention, while system-like trust better predicted behavioral
intention and perceived usefulness. Both had similar effects on perceived
enjoyment. Given the partial explanatory power of each type of trust, we
propose that students develop a distinct form of trust with AI chatbots
(human-AI trust) that differs from human-human and human-technology models of
trust. Our findings highlight the need for new theoretical frameworks specific
to human-AI trust and offer practical insights for fostering appropriately
calibrated trust, which is critical for the effective adoption and pedagogical
impact of AI in education.

</details>


### [398] [Revolutionizing Clinical Trials: A Manifesto for AI-Driven Transformation](https://arxiv.org/abs/2506.09102)
*Mihaela van der Schaar,Richard Peck,Eoin McKinney,Jim Weatherall,Stuart Bailey,Justine Rochon,Chris Anagnostopoulos,Pierre Marquet,Anthony Wood,Nicky Best,Harry Amad,Julianna Piskorz,Krzysztof Kacprzyk,Rafik Salama,Christina Gunther,Francesca Frau,Antoine Pugeat,Ramon Hernandez*

Main category: cs.CY

TL;DR: 本文提出了一种通过因果推断和数字孪生技术革新临床试验的路线图，旨在实现更快、更安全、更个性化的患者结果。


<details>
  <summary>Details</summary>
Motivation: 通过整合人工智能技术，优化临床试验流程，提升效率和个性化治疗。

Method: 采用因果推断和数字孪生技术，结合现有监管框架，提出可行的实施方案。

Result: 预期实现临床试验的革新，重新定义其黄金标准。

Conclusion: 通过AI技术的整合，临床试验将迎来革命性变革。

Abstract: This manifesto represents a collaborative vision forged by leaders in
pharmaceuticals, consulting firms, clinical research, and AI. It outlines a
roadmap for two AI technologies - causal inference and digital twins - to
transform clinical trials, delivering faster, safer, and more personalized
outcomes for patients. By focusing on actionable integration within existing
regulatory frameworks, we propose a way forward to revolutionize clinical
research and redefine the gold standard for clinical trials using AI.

</details>


### [399] [FAIRTOPIA: Envisioning Multi-Agent Guardianship for Disrupting Unfair AI Pipelines](https://arxiv.org/abs/2506.09107)
*Athena Vakali,Ilias Dimitriadis*

Main category: cs.CY

TL;DR: 论文提出FAIRTOPIA框架，通过多角色智能体在AI流程中嵌入公平性保障，实现人类中心化的公平性监督。


<details>
  <summary>Details</summary>
Motivation: AI技术快速发展导致有害事件和不公平问题，亟需在AI流程中嵌入人类原则和公平性保障。

Method: 引入基于智能体的公平性设计方法，提出三层架构的FAIRTOPIA框架，覆盖AI流程各阶段。

Result: FAIRTOPIA框架通过多智能体工作流实现公平性监督，支持自适应和现实场景的公平性需求。

Conclusion: 智能体可作为公平性守护者，推动基于人类中心化原则的公平性研究和实践。

Abstract: AI models have become active decision makers, often acting without human
supervision. The rapid advancement of AI technology has already caused harmful
incidents that have hurt individuals and societies and AI unfairness in heavily
criticized. It is urgent to disrupt AI pipelines which largely neglect human
principles and focus on computational biases exploration at the data (pre),
model(in), and deployment (post) processing stages. We claim that by exploiting
the advances of agents technology, we will introduce cautious, prompt, and
ongoing fairness watch schemes, under realistic, systematic, and human-centric
fairness expectations. We envision agents as fairness guardians, since agents
learn from their environment, adapt to new information, and solve complex
problems by interacting with external tools and other systems. To set the
proper fairness guardrails in the overall AI pipeline, we introduce a
fairness-by-design approach which embeds multi-role agents in an end-to-end
(human to AI) synergetic scheme. Our position is that we may design adaptive
and realistic AI fairness frameworks, and we introduce a generalized algorithm
which can be customized to the requirements and goals of each AI decision
making scenario. Our proposed, so called FAIRTOPIA framework, is structured
over a three-layered architecture, which encapsulates the AI pipeline inside an
agentic guardian and a knowledge-based, self-refining layered scheme. Based on
our proposition, we enact fairness watch in all of the AI pipeline stages,
under robust multi-agent workflows, which will inspire new fairness research
hypothesis, heuristics, and methods grounded in human-centric, systematic,
interdisciplinary, socio-technical principles.

</details>
