<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.RO](#cs.RO) [Total: 7]
- [cs.SD](#cs.SD) [Total: 5]
- [eess.SY](#eess.SY) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 该研究应用符号回归（SR）和答案集编程（ASP）的混合框架，从数值模拟数据中推导出三维不可压缩流动的解析方程，展示了SR在简化复杂流动行为和知识表示方法提升模型可靠性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 在流体力学中，理解流动物理机制与准确预测同样重要。SR作为一种可解释的数学建模工具，无需先验假设模型结构，适合揭示复杂物理系统的数学关系。

Method: 使用PySR库从数值模拟数据中推导符号方程，并结合ASP框架确保方程不仅统计准确，还符合物理原理。

Result: 推导的方程不仅近似模拟了抛物线速度分布和压力降，还与文献中的解析解完全一致。

Conclusion: SR能简化复杂流动行为为可解释方程，知识表示方法可提升数据驱动模型的可靠性和与领域原理的一致性。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [2] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: I2I-STRADA是一种基于结构化推理的代理架构，旨在通过模块化子任务模拟分析推理的认知步骤，提升数据分析的规划一致性和洞察对齐。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统在数据分析中忽视了结构化推理过程，导致通用LLMs的推理步骤缺乏任务特定的固定流程。

Method: 提出I2I-STRADA架构，通过模块化子任务模拟分析推理的认知步骤，包括目标解释、上下文知识、抽象计划构建和动态执行。

Result: 在DABstep和DABench基准测试中，I2I-STRADA在规划一致性和洞察对齐方面优于现有系统。

Conclusion: 结构化认知工作流对数据分析代理设计至关重要，I2I-STRADA为此提供了有效解决方案。

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [3] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: SmartAPS是一个基于大型语言模型的对话系统，旨在为供应链规划师提供更易访问的高级规划系统（APS），通过自然语言交互实现查询、反事实推理和场景分析。


<details>
  <summary>Details</summary>
Motivation: 传统APS系统因定制和维护成本高昂，许多用户无法负担。SmartAPS旨在通过LLM技术降低使用门槛，满足供应链规划师的需求。

Method: SmartAPS基于工具增强的大型语言模型，提供自然语言聊天界面，支持查询、反事实推理、推荐和场景分析。

Result: 系统通过直观的交互方式帮助用户管理运营，降低了APS的使用门槛。

Conclusion: SmartAPS展示了LLM在提升传统工具可访问性和用户体验方面的潜力。

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [4] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 本文提出了一种定性时间线规划的片段，其计划存在性问题可直接映射到确定性有限自动机的非空性问题，从而能够直接合成策略。


<details>
  <summary>Details</summary>
Motivation: 定性时间线规划的计划存在性问题已被证明是PSPACE完全的，但非确定性自动机无法直接用于合成策略，需要昂贵的确定性化步骤。

Method: 识别了一个定性时间线规划的片段，并将其计划存在性问题映射到确定性有限自动机的非空性问题。

Result: 确定了可以映射到确定性片段的Allen关系的最大子集。

Conclusion: 该研究为直接合成规划策略提供了有效方法，并扩展了确定性片段的应用范围。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [5] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: 论文提出E.A.R.T.H.框架，通过错误生成、放大、精炼选择、转换和反馈利用，将AI生成的错误转化为创意资产，显著提升创造力。


<details>
  <summary>Details</summary>
Motivation: 探索AI如何超越模仿实现真正的创造力，提出“创意潜力隐藏在失败中”的观点。

Method: 采用五阶段生成管道（E.A.R.T.H.），结合结构化提示、语义评分和人类反馈，使用多种模型（如LLaMA-2-7B-Chat、SBERT等）和复合奖励函数（新颖性、惊喜性、相关性）。

Result: 创造力评分提升70.4%，口号更短、更新颖，跨模态测试显示强对齐，人类评价中60%输出得分≥4.0。

Conclusion: 错误中心和反馈驱动的生成方法显著增强创造力，为自进化、人类对齐的创意AI提供可行路径。

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [6] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 研究发现，AI系统（如GPT 4.1和Claude 3.5）在处理合成数据集时，若数据配有散点图，其描述会更精确和准确。


<details>
  <summary>Details</summary>
Motivation: 探讨图表是否对AI系统分析数据有帮助。

Method: 使用两种商业视觉语言模型（GPT 4.1和Claude 3.5），在三种代表性分析任务中测试数据配图的效果，并与空白图表和错误数据图表进行对比。

Result: AI系统在数据配有散点图时表现更优，尤其是在复杂数据集上。

Conclusion: 初步证据表明，AI系统与人类一样，可以从可视化中受益。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [7] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO是一种新型的多智能体强化学习框架，通过结合集中式指导和分散式执行，优化了CTDE范式，提供了理论保证和实际性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有CTDE方法未能充分利用集中式训练或缺乏理论保证，MAGPO旨在解决这些问题。

Method: MAGPO采用自回归联合策略进行可扩展的协调探索，并明确与分散策略对齐以确保可部署性。

Result: 在43个任务和6个环境中，MAGPO表现优于现有CTDE基线，甚至媲美完全集中式方法。

Conclusion: MAGPO为分散式多智能体学习提供了理论和实践上的有效解决方案。

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [8] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: ASI-Arch是首个用于AI研究的超级智能系统，通过自主进行神经架构发现，突破了人类认知限制，实现了从自动化优化到自动化创新的范式转变。


<details>
  <summary>Details</summary>
Motivation: AI研究受限于人类认知能力，发展速度线性增长，而AI能力呈指数提升，形成瓶颈。ASI-Arch旨在突破这一限制。

Method: ASI-Arch通过自主假设、实现、训练和验证新架构，进行端到端研究，超越了传统神经架构搜索（NAS）。

Result: 系统进行了1,773次实验，发现了106种创新的线性注意力架构，性能超越人类设计，并建立了科学发现的缩放定律。

Conclusion: ASI-Arch展示了AI自主研究的潜力，为自加速AI系统提供了蓝图。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [9] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: 该论文提出了一种Agentic AI框架，自动化临床数据从输入到推理的整个流程，通过模块化代理解决医疗机器学习中的高成本和碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 医疗领域机器学习解决方案的构建和部署成本高且劳动密集，主要由于预处理流程碎片化、模型兼容性问题以及严格的数据隐私限制。

Method: 采用模块化、任务特定的代理系统，处理结构化和非结构化数据，自动完成特征选择、模型选择和预处理推荐。

Result: 在老年医学、姑息治疗和结肠镜成像等公开数据集上验证了框架的有效性，减少了专家干预需求。

Conclusion: 该框架为临床环境中AI的规模化、低成本应用提供了可行路径。

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [10] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 该研究利用自然语言处理（NLP）和主动学习技术，开发了一种分类器，用于从急诊科分诊记录中快速检测潜在的疫苗安全问题，以弥补临床试验中安全数据收集窗口有限的不足。


<details>
  <summary>Details</summary>
Motivation: 由于临床试验中安全数据收集时间有限，且疫苗广泛接种后需要及时监测安全问题，因此需要开发一种高效的方法来识别潜在的疫苗安全问题。

Method: 结合自然语言处理（NLP）、主动学习和数据增强技术，开发分类器，利用急诊科分诊记录进行疫苗安全信号监测。

Result: 该方法能够更准确、高效地检测疫苗安全问题，减少误报，并优化标注数据的质量。

Conclusion: 通过NLP和主动学习的结合，可以显著提升疫苗安全监测的效率和准确性，为公共卫生提供有力支持。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [11] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 论文研究了使用均值聚合函数的图神经网络（GNNs）的表达能力，发现其在非均匀和均匀设置下分别与特定模态逻辑等价，且表达能力介于最大值和求和聚合之间。


<details>
  <summary>Details</summary>
Motivation: 探索均值聚合GNNs的表达能力，以理解其在不同逻辑框架下的表现。

Method: 通过非均匀和均匀设置下的理论分析，比较均值GNNs与其他聚合函数的表达能力。

Result: 均值GNNs在非均匀设置下与比率模态逻辑等价，均匀设置下与无交替模态逻辑等价，表达能力介于最大值和求和聚合之间。

Conclusion: 均值GNNs的表达能力受设置和假设影响，严格低于求和和最大值聚合GNNs，但放宽假设可提升其能力。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [12] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: Shop-R1是一个强化学习框架，通过分阶段生成理由和预测动作，提升LLM在在线购物环境中模拟人类行为的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖LLM生成的理由进行训练，但其性能受限于模型的推理能力，因此需要一种新方法来增强推理能力。

Method: Shop-R1将任务分解为理由生成和动作预测两阶段，分别使用自监督和分层奖励结构进行优化。

Result: 实验结果显示，该方法相比基线提升了65%的性能。

Conclusion: Shop-R1通过分阶段和分层奖励设计，有效提升了LLM在模拟人类行为中的推理能力。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [13] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: DG-PRM提出了一种动态且可泛化的过程奖励建模方法，通过奖励树和多维奖励标准，显著提升了LLM在复杂任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型（PRMs）依赖启发式方法，跨领域泛化能力不足，且现有研究忽视了文本中的指导意义。

Method: DG-PRM采用奖励树存储细粒度奖励标准，动态选择奖励信号，并首次使用帕累托优势估计处理多维奖励信号。

Result: 实验表明DG-PRM在主流基准测试中表现优异，显著提升模型性能，并展现出良好的分布外泛化能力。

Conclusion: DG-PRM为复杂任务中的过程奖励建模提供了高效且泛化的解决方案。

Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [14] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

TL;DR: VeriMinder是一个交互式系统，用于检测和缓解自然语言数据库接口中的认知偏差，通过语义映射、分析框架和优化的LLM生成提示，显著提升分析质量。


<details>
  <summary>Details</summary>
Motivation: 帮助缺乏统计背景的用户在自然语言数据库接口中避免认知偏差，提升分析问题的质量。

Method: 1. 上下文语义映射框架；2. 基于Hard-to-Vary原则的分析框架；3. 优化的LLM生成提示系统。

Result: 用户测试显示82.5%的参与者认可其提升分析质量的效果，且在具体性、全面性和准确性上优于其他方法至少20%。

Conclusion: VeriMinder有效解决了“错误问题”漏洞，其开源代码和提示库有助于进一步研究和社区采用。

Abstract: Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [15] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 提出了一种高效端到端的自动口语评估方法，通过单一Whisper-small编码器处理多部分口语测试，减少推理时间并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多部分第二语言测试的自动口语评估问题，提高效率并减少对转录和单独模型的需求。

Method: 使用单一Whisper-small编码器处理所有口语响应，通过轻量级聚合器整合信息并预测最终分数。

Result: 系统RMSE为0.384，优于基于文本的基线（0.44），且仅需168M参数。数据采样策略使模型仅需44.8%的语料库即可达到0.383 RMSE。

Conclusion: 该方法高效且数据利用率高，适用于大规模计算机辅助语言学习系统。

Abstract: We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [16] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

TL;DR: 研究了六种AI检测工具对DeepSeek生成文本的识别能力，发现对抗攻击（如改写和人化）显著降低了检测准确性，而Few-shot和CoT提示方法表现优异。


<details>
  <summary>Details</summary>
Motivation: 探讨DeepSeek这一新兴LLM的文本是否容易被现有AI检测工具识别，填补文献空白。

Method: 使用六种检测工具测试DeepSeek生成文本的识别能力，并应用对抗攻击（改写、人化）和Few-shot/CoT提示方法。

Result: QuillBot和Copyleaks表现最佳，但人化攻击显著降低准确性；Few-shot和CoT提示方法准确率高达96%-100%。

Conclusion: 对抗攻击削弱检测工具性能，Few-shot和CoT提示是有效的替代检测方法。

Abstract: Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [17] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究探讨了更大、更强大的语言模型是否能在上下文中根据证据更一致地更新其“信念”以符合贝叶斯定理。通过提出贝叶斯一致性系数（BCC）并生成数据集进行测量，发现更大、更先进的预训练语言模型确实更符合贝叶斯定理。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型是否能在上下文中根据证据更一致地更新其“信念”，以符合贝叶斯定理。

Method: 提出贝叶斯一致性系数（BCC）并生成数据集，测量多个预训练语言模型的BCC，比较模型参数、训练数据量和基准测试分数。

Result: 更大、更先进的预训练语言模型在贝叶斯一致性上表现更好。

Conclusion: 研究结果对理解和管理大型语言模型具有重要意义。

Abstract: Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [18] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: TELEVAL是一个动态基准测试，专为评估中文交互场景中口语语言模型（SLMs）作为对话代理的有效性而设计，关注显式语义、副语言和隐式语义以及系统能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多关注SLMs能否完成复杂任务，而忽略了用户在实际对话中的自然交互方式。

Method: TELEVAL定义了三个评估维度，采用对话形式，分别评估文本和音频输出，特别关注模型从用户语音中提取隐式线索并适当回应的能力。

Result: 实验表明，现有SLMs在自然对话任务中仍有较大改进空间。

Conclusion: TELEVAL可作为以用户为中心的评估框架，促进对话导向SLMs的发展。

Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [19] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

TL;DR: 本文综述了提格里尼亚语（Tigrinya）在自然语言处理（NLP）领域的研究现状，分析了40多项研究，揭示了从规则系统到神经架构的演变，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 提格里尼亚语在NLP研究中代表性不足，本文旨在填补这一空白，为研究者提供参考和路线图。

Method: 系统回顾了2011至2025年间40多项研究，涵盖10种下游任务，分析资源、模型和应用。

Result: 研究发现从规则系统到神经架构的演变，资源创建是关键进展点，但语言形态复杂性和资源稀缺仍是挑战。

Conclusion: 本文为提格里尼亚语NLP研究提供了全面参考，并提出了形态感知建模、跨语言迁移等未来方向。

Abstract: Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [20] [WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection](https://arxiv.org/abs/2507.18173)
*Haodong Zhu,Wenhao Dong,Linlin Yang,Hong Li,Yuguang Yang,Yangyang Ren,Qingcheng Zhu,Zichao Feng,Changbai Li,Shaohui Lin,Runqi Wang,Xiaoyan Luo,Baochang Zhang*

Main category: cs.CV

TL;DR: WaveMamba是一种跨模态融合方法，通过离散小波变换（DWT）分解RGB和红外（IR）图像的互补频率特征，并结合改进的检测头减少信息损失，显著提升目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 利用RGB和红外图像的互补特性提升目标检测性能。

Method: 提出WaveMamba Fusion Block（WMFB），结合低/高频子带的融合策略，包括基于Mamba框架的低频特征融合和高频特征增强。

Result: 在四个基准测试中平均mAP提升4.5%，超越现有方法。

Conclusion: WaveMamba通过高效融合RGB和IR图像的频率特征，显著提升了目标检测性能。

Abstract: Leveraging the complementary characteristics of visible (RGB) and infrared
(IR) imagery offers significant potential for improving object detection. In
this paper, we propose WaveMamba, a cross-modality fusion method that
efficiently integrates the unique and complementary frequency features of RGB
and IR decomposed by Discrete Wavelet Transform (DWT). An improved detection
head incorporating the Inverse Discrete Wavelet Transform (IDWT) is also
proposed to reduce information loss and produce the final detection results.
The core of our approach is the introduction of WaveMamba Fusion Block (WMFB),
which facilitates comprehensive fusion across low-/high-frequency sub-bands.
Within WMFB, the Low-frequency Mamba Fusion Block (LMFB), built upon the Mamba
framework, first performs initial low-frequency feature fusion with channel
swapping, followed by deep fusion with an advanced gated attention mechanism
for enhanced integration. High-frequency features are enhanced using a strategy
that applies an ``absolute maximum" fusion approach. These advancements lead to
significant performance gains, with our method surpassing state-of-the-art
approaches and achieving average mAP improvements of 4.5% on four benchmarks.

</details>


### [21] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
*Yi Xin,Juncheng Yan,Qi Qin,Zhen Li,Dongyang Liu,Shicheng Li,Victor Shea-Jay Huang,Yupeng Zhou,Renrui Zhang,Le Zhuo,Tiancheng Han,Xiaoqing Sun,Siqi Luo,Mengmeng Wang,Bin Fu,Yuewen Cao,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Yu Qiao,Peng Gao*

Main category: cs.CV

TL;DR: Lumina-mGPT 2.0是一个独立的自回归模型，通过从头训练实现高质量图像生成，性能媲美扩散模型，并支持多任务处理。


<details>
  <summary>Details</summary>
Motivation: 重新审视并振兴自回归范式，以实现高质量图像生成和多任务处理，同时避免依赖预训练组件或混合架构。

Method: 采用从头训练的自回归模型，结合统一的标记化方案和高效解码策略（如推理时间缩放和推测性Jacobi采样）。

Result: 在文本到图像基准测试中表现优异，甚至超越扩散模型，并在多任务基准Graph200K上表现突出。

Conclusion: Lumina-mGPT 2.0是一个强大且灵活的多模态生成基础模型，具有广泛的应用潜力。

Abstract: We present Lumina-mGPT 2.0, a stand-alone, decoder-only autoregressive model
that revisits and revitalizes the autoregressive paradigm for high-quality
image generation and beyond. Unlike existing approaches that rely on pretrained
components or hybrid architectures, Lumina-mGPT 2.0 is trained entirely from
scratch, enabling unrestricted architectural design and licensing freedom. It
achieves generation quality on par with state-of-the-art diffusion models such
as DALL-E 3 and SANA, while preserving the inherent flexibility and
compositionality of autoregressive modeling. Our unified tokenization scheme
allows the model to seamlessly handle a wide spectrum of tasks-including
subject-driven generation, image editing, controllable synthesis, and dense
prediction-within a single generative framework. To further boost usability, we
incorporate efficient decoding strategies like inference-time scaling and
speculative Jacobi sampling to improve quality and speed, respectively.
Extensive evaluations on standard text-to-image benchmarks (e.g., GenEval, DPG)
demonstrate that Lumina-mGPT 2.0 not only matches but in some cases surpasses
diffusion-based models. Moreover, we confirm its multi-task capabilities on the
Graph200K benchmark, with the native Lumina-mGPT 2.0 performing exceptionally
well. These results position Lumina-mGPT 2.0 as a strong, flexible foundation
model for unified multimodal generation. We have released our training details,
code, and models at https://github.com/Alpha-VLLM/Lumina-mGPT-2.0.

</details>


### [22] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
*Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam*

Main category: cs.CV

TL;DR: SV3.3B是一个轻量级的3.3B参数视频理解模型，用于自动化体育视频分析，通过创新的时间运动差异采样和自监督学习，实现了高效的设备端部署，并在性能上超越了GPT-4o等大型模型。


<details>
  <summary>Details</summary>
Motivation: 传统体育视频分析模型计算量大且缺乏对运动细节的精细理解，无法捕捉关键的运动阶段（如准备、执行和后续动作）。

Method: 采用DWT-VGG16-LDA关键帧提取机制和V-DWT-JEPA2编码器，结合自监督学习和LLM解码器，生成详细的运动动作描述。

Result: 在NSVA篮球数据集上，SV3.3B在文本生成和体育特定评估指标上表现优异，性能提升29.2%，信息密度和动作复杂性显著提高。

Conclusion: SV3.3B为体育视频分析提供了高效且性能优越的解决方案，适用于设备端部署。

Abstract: This paper addresses the challenge of automated sports video analysis, which
has traditionally been limited by computationally intensive models requiring
server-side processing and lacking fine-grained understanding of athletic
movements. Current approaches struggle to capture the nuanced biomechanical
transitions essential for meaningful sports analysis, often missing critical
phases like preparation, execution, and follow-through that occur within
seconds. To address these limitations, we introduce SV3.3B, a lightweight 3.3B
parameter video understanding model that combines novel temporal motion
difference sampling with self-supervised learning for efficient on-device
deployment. Our approach employs a DWT-VGG16-LDA based keyframe extraction
mechanism that intelligently identifies the 16 most representative frames from
sports sequences, followed by a V-DWT-JEPA2 encoder pretrained through
mask-denoising objectives and an LLM decoder fine-tuned for sports action
description generation. Evaluated on a subset of the NSVA basketball dataset,
SV3.3B achieves superior performance across both traditional text generation
metrics and sports-specific evaluation criteria, outperforming larger
closed-source models including GPT-4o variants while maintaining significantly
lower computational requirements. Our model demonstrates exceptional capability
in generating technically detailed and analytically rich sports descriptions,
achieving 29.2% improvement over GPT-4o in ground truth validation metrics,
with substantial improvements in information density, action complexity, and
measurement precision metrics essential for comprehensive athletic analysis.
Model Available at https://huggingface.co/sportsvision/SV3.3B.

</details>


### [23] [3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation](https://arxiv.org/abs/2507.18625)
*Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu*

Main category: cs.CV

TL;DR: Scenethesis是一种新型的3D软件合成方法，通过领域特定语言ScenethesisLang实现用户需求与生成软件之间的可追溯性，显著提升了3D软件生成的精确性和约束处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有3D软件生成方法无法精细控制单个元素且难以处理复杂空间和语义约束，因此需要一种新方法来解决这些问题。

Method: 提出Scenethesis，基于ScenethesisLang（一种领域特定语言），将3D软件合成分解为多个阶段，支持独立验证、针对性修改和系统约束满足。

Result: Scenethesis能准确捕捉80%以上用户需求，满足90%以上的硬约束，同时处理100多个约束，并在视觉评估中比现有方法提升42.8%。

Conclusion: Scenethesis通过其语言和分阶段方法，显著提升了3D软件生成的灵活性和精确性，为未来研究提供了新方向。

Abstract: Graphical user interface (UI) software has undergone a fundamental
transformation from traditional two-dimensional (2D) desktop/web/mobile
interfaces to spatial three-dimensional (3D) environments. While existing work
has made remarkable success in automated 2D software generation, such as
HTML/CSS and mobile app interface code synthesis, the generation of 3D software
still remains under-explored. Current methods for 3D software generation
usually generate the 3D environments as a whole and cannot modify or control
specific elements in the software. Furthermore, these methods struggle to
handle the complex spatial and semantic constraints inherent in the real world.
To address the challenges, we present Scenethesis, a novel
requirement-sensitive 3D software synthesis approach that maintains formal
traceability between user specifications and generated 3D software. Scenethesis
is built upon ScenethesisLang, a domain-specific language that serves as a
granular constraint-aware intermediate representation (IR) to bridge natural
language requirements and executable 3D software. It serves both as a
comprehensive scene description language enabling fine-grained modification of
3D software elements and as a formal constraint-expressive specification
language capable of expressing complex spatial constraints. By decomposing 3D
software synthesis into stages operating on ScenethesisLang, Scenethesis
enables independent verification, targeted modification, and systematic
constraint satisfaction. Our evaluation demonstrates that Scenethesis
accurately captures over 80% of user requirements and satisfies more than 90%
of hard constraints while handling over 100 constraints simultaneously.
Furthermore, Scenethesis achieves a 42.8% improvement in BLIP-2 visual
evaluation scores compared to the state-of-the-art method.

</details>


### [24] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
*Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang*

Main category: cs.CV

TL;DR: Detail++是一个无需训练的框架，通过渐进式细节注入策略（PDI）解决复杂提示下多主体生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在复杂提示（多主体及属性）下表现不佳，受人类绘画过程启发，提出分阶段生成方法。

Method: 将复杂提示分解为子提示，分阶段生成；利用自注意力控制布局，交叉注意力绑定属性，引入质心对齐损失减少噪声。

Result: 在T2I-CompBench和新风格组合基准上显著优于现有方法，尤其在多对象和复杂风格场景。

Conclusion: Detail++通过分阶段生成和属性绑定优化，显著提升了复杂提示下的图像生成质量。

Abstract: Recent advances in text-to-image (T2I) generation have led to impressive
visual results. However, these models still face significant challenges when
handling complex prompt, particularly those involving multiple subjects with
distinct attributes. Inspired by the human drawing process, which first
outlines the composition and then incrementally adds details, we propose
Detail++, a training-free framework that introduces a novel Progressive Detail
Injection (PDI) strategy to address this limitation. Specifically, we decompose
a complex prompt into a sequence of simplified sub-prompts, guiding the
generation process in stages. This staged generation leverages the inherent
layout-controlling capacity of self-attention to first ensure global
composition, followed by precise refinement. To achieve accurate binding
between attributes and corresponding subjects, we exploit cross-attention
mechanisms and further introduce a Centroid Alignment Loss at test time to
reduce binding noise and enhance attribute consistency. Extensive experiments
on T2I-CompBench and a newly constructed style composition benchmark
demonstrate that Detail++ significantly outperforms existing methods,
particularly in scenarios involving multiple objects and complex stylistic
conditions.

</details>


### [25] [SIDA: Synthetic Image Driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2507.18632)
*Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: 提出了一种基于合成图像的零样本域适应方法SIDA，通过生成目标域风格的合成图像，结合Domain Mix和Patch Style Transfer模块，高效建模真实世界变化。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本描述的方法难以捕捉复杂真实世界变化且耗时，因此探索利用图像数据提供更细粒度的风格线索。

Method: 通过生成源域风格的详细图像并应用图像翻译生成目标域风格的合成图像，利用其风格特征作为目标域代理，结合Domain Mix和Patch Style Transfer模块。

Result: 在多种零样本适应场景中表现优异，尤其在挑战性领域，同时显著减少适应时间。

Conclusion: SIDA通过合成图像和高效模块设计，实现了高效且高性能的零样本域适应。

Abstract: Zero-shot domain adaptation is a method for adapting a model to a target
domain without utilizing target domain image data. To enable adaptation without
target images, existing studies utilize CLIP's embedding space and text
description to simulate target-like style features. Despite the previous
achievements in zero-shot domain adaptation, we observe that these text-driven
methods struggle to capture complex real-world variations and significantly
increase adaptation time due to their alignment process. Instead of relying on
text descriptions, we explore solutions leveraging image data, which provides
diverse and more fine-grained style cues. In this work, we propose SIDA, a
novel and efficient zero-shot domain adaptation method leveraging synthetic
images. To generate synthetic images, we first create detailed, source-like
images and apply image translation to reflect the style of the target domain.
We then utilize the style features of these synthetic images as a proxy for the
target domain. Based on these features, we introduce Domain Mix and Patch Style
Transfer modules, which enable effective modeling of real-world variations. In
particular, Domain Mix blends multiple styles to expand the intra-domain
representations, and Patch Style Transfer assigns different styles to
individual patches. We demonstrate the effectiveness of our method by showing
state-of-the-art performance in diverse zero-shot adaptation scenarios,
particularly in challenging domains. Moreover, our approach achieves high
efficiency by significantly reducing the overall adaptation time.

</details>


### [26] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
*Muayad Abujabal,Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: FishDet-M是一个统一的水下鱼类检测基准，整合了13个公开数据集，评估了28种目标检测模型，并提出了基于CLIP的模型选择框架。


<details>
  <summary>Details</summary>
Motivation: 解决水下鱼类检测中数据集碎片化、成像条件异质性和评估协议不一致的问题。

Method: 整合13个数据集，使用COCO风格标注，评估28种模型，引入CLIP-based模型选择框架。

Result: 不同模型在FishDet-M上表现各异，CLIP-based框架实现了高效零-shot模型选择。

Conclusion: FishDet-M为水下计算机视觉提供了标准化评估平台，支持未来研究。

Abstract: Accurate fish detection in underwater imagery is essential for ecological
monitoring, aquaculture automation, and robotic perception. However, practical
deployment remains limited by fragmented datasets, heterogeneous imaging
conditions, and inconsistent evaluation protocols. To address these gaps, we
present \textit{FishDet-M}, the largest unified benchmark for fish detection,
comprising 13 publicly available datasets spanning diverse aquatic environments
including marine, brackish, occluded, and aquarium scenes. All data are
harmonized using COCO-style annotations with both bounding boxes and
segmentation masks, enabling consistent and scalable cross-domain evaluation.
We systematically benchmark 28 contemporary object detection models, covering
the YOLOv8 to YOLOv12 series, R-CNN based detectors, and DETR based models.
Evaluations are conducted using standard metrics including mAP, mAP@50, and
mAP@75, along with scale-specific analyses (AP$_S$, AP$_M$, AP$_L$) and
inference profiling in terms of latency and parameter count. The results
highlight the varying detection performance across models trained on FishDet-M,
as well as the trade-off between accuracy and efficiency across models of
different architectures. To support adaptive deployment, we introduce a
CLIP-based model selection framework that leverages vision-language alignment
to dynamically identify the most semantically appropriate detector for each
input image. This zero-shot selection strategy achieves high performance
without requiring ensemble computation, offering a scalable solution for
real-time applications. FishDet-M establishes a standardized and reproducible
platform for evaluating object detection in complex aquatic scenes. All
datasets, pretrained models, and evaluation tools are publicly available to
facilitate future research in underwater computer vision and intelligent marine
systems.

</details>


### [27] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel*

Main category: cs.CV

TL;DR: 利用生成式AI评估皮肤癌分类器的公平性，发现合成数据在公平性评估中具有潜力，但需注意训练数据与合成数据的匹配问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习在皮肤癌筛查中的应用潜力巨大，但存在潜在偏见风险，因此评估和改进公平性至关重要。

Method: 使用先进的生成式AI模型（LightningDiT）评估公开可用的黑色素瘤分类器的公平性。

Result: 合成数据在公平性评估中表现良好，但若评估模型与合成数据训练数据不匹配，公平性验证会变得困难。

Conclusion: 合成数据为医学影像生成式AI系统的公平性评估和改进提供了新途径。

Abstract: Recent advancements in Deep Learning and its application on the edge hold
great potential for the revolution of routine screenings for skin cancers like
Melanoma. Along with the anticipated benefits of this technology, potential
dangers arise from unforseen and inherent biases. Thus, assessing and improving
the fairness of such systems is of utmost importance. A key challenge in
fairness assessment is to ensure that the evaluation dataset is sufficiently
representative of different Personal Identifiable Information (PII) (sex, age,
and race) and other minority groups. Against the backdrop of this challenge,
this study leverages the state-of-the-art Generative AI (GenAI) LightningDiT
model to assess the fairness of publicly available melanoma classifiers. The
results suggest that fairness assessment using highly realistic synthetic data
is a promising direction. Yet, our findings indicate that verifying fairness
becomes difficult when the melanoma-detection model used for evaluation is
trained on data that differ from the dataset underpinning the synthetic images.
Nonetheless, we propose that our approach offers a valuable new avenue for
employing synthetic data to gauge and enhance fairness in medical-imaging GenAI
systems.

</details>


### [28] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
*Hanzhou Liu,Binghan Li,Chengkai Liu,Mi Lu*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的图像修复方法DiNAT-IR，通过结合局部和全局注意力机制，解决了传统方法在高分辨率图像上的计算效率和局部细节恢复问题。


<details>
  <summary>Details</summary>
Motivation: Transformer的自注意力机制在图像修复任务中表现出色，但高计算成本限制了其在高分辨率图像上的应用。现有方法如Restormer通过通道自注意力优化效率，但可能忽略局部细节。

Method: 提出Dilated Neighborhood Attention (DiNA)，结合滑动窗口注意力和混合膨胀因子，平衡全局和局部信息。进一步引入通道感知模块，增强全局上下文理解。

Result: DiNAT-IR在多个基准测试中取得竞争性结果，为低层次计算机视觉问题提供了高质量解决方案。

Conclusion: DiNAT-IR通过创新的注意力机制设计，有效解决了图像修复中的效率和精度问题，具有广泛应用潜力。

Abstract: Transformers, with their self-attention mechanisms for modeling long-range
dependencies, have become a dominant paradigm in image restoration tasks.
However, the high computational cost of self-attention limits scalability to
high-resolution images, making efficiency-quality trade-offs a key research
focus. To address this, Restormer employs channel-wise self-attention, which
computes attention across channels instead of spatial dimensions. While
effective, this approach may overlook localized artifacts that are crucial for
high-quality image restoration. To bridge this gap, we explore Dilated
Neighborhood Attention (DiNA) as a promising alternative, inspired by its
success in high-level vision tasks. DiNA balances global context and local
precision by integrating sliding-window attention with mixed dilation factors,
effectively expanding the receptive field without excessive overhead. However,
our preliminary experiments indicate that directly applying this global-local
design to the classic deblurring task hinders accurate visual restoration,
primarily due to the constrained global context understanding within local
attention. To address this, we introduce a channel-aware module that
complements local attention, effectively integrating global context without
sacrificing pixel-level precision. The proposed DiNAT-IR, a Transformer-based
architecture specifically designed for image restoration, achieves competitive
results across multiple benchmarks, offering a high-quality solution for
diverse low-level computer vision problems.

</details>


### [29] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
*Md. Al-Masrur Khan,Durgakant Pushp,Lantao Liu*

Main category: cs.CV

TL;DR: 论文提出了一种自适应特征细化（AFR）模块，用于无监督域自适应语义分割（UDA-SS），通过结合高低分辨率特征和高频组件，提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有UDA-SS方法难以平衡局部细节与全局上下文信息，导致复杂区域的分割错误。

Method: 引入AFR模块，利用低分辨率语义先验细化高分辨率特征，并集成高频组件和不确定性驱动的注意力机制。

Result: 在GTA V→Cityscapes和Synthia→Cityscapes上分别提升了1.05%和1.04%的mIoU。

Conclusion: AFR模块轻量且高效，显著提升了UDA-SS的分割性能。

Abstract: In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is
trained on labeled source domain data (e.g., synthetic images) and adapted to
an unlabeled target domain (e.g., real-world images) without access to target
annotations. Existing UDA-SS methods often struggle to balance fine-grained
local details with global contextual information, leading to segmentation
errors in complex regions. To address this, we introduce the Adaptive Feature
Refinement (AFR) module, which enhances segmentation accuracy by refining
highresolution features using semantic priors from low-resolution logits. AFR
also integrates high-frequency components, which capture fine-grained
structures and provide crucial boundary information, improving object
delineation. Additionally, AFR adaptively balances local and global information
through uncertaintydriven attention, reducing misclassifications. Its
lightweight design allows seamless integration into HRDA-based UDA methods,
leading to state-of-the-art segmentation performance. Our approach improves
existing UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on
Synthia-->Cityscapes. The implementation of our framework is available at:
https://github.com/Masrur02/AFRDA

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [30] [Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction](https://arxiv.org/abs/2507.17768)
*Yujia Tong,Jingling Yuan,Chuang Hu*

Main category: cs.LG

TL;DR: QuaRC是一个基于边缘设备的量化感知训练框架，通过核心集选择和层校正策略减少量化误差，显著提升低比特量化模型的性能。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上低比特量化模型的需求增加，但传统量化感知训练依赖完整数据集，计算成本高且隐私受限。核心集选择技术可缓解问题，但现有方法在小规模数据集上难以消除量化误差。

Method: QuaRC引入“相对熵评分”选择核心集，并采用“级联层校正”策略对齐量化模型与全精度模型的中间层输出。

Result: 在ImageNet-1K数据集上，QuaRC使用1%数据子集量化ResNet-18至2比特时，Top-1准确率比现有技术提升5.72%。

Conclusion: QuaRC通过核心集选择和层校正有效减少量化误差，显著提升边缘设备上低比特量化模型的性能。

Abstract: With the development of mobile and edge computing, the demand for low-bit
quantized models on edge devices is increasing to achieve efficient deployment.
To enhance the performance, it is often necessary to retrain the quantized
models using edge data. However, due to privacy concerns, certain sensitive
data can only be processed on edge devices. Therefore, employing
Quantization-Aware Training (QAT) on edge devices has become an effective
solution. Nevertheless, traditional QAT relies on the complete dataset for
training, which incurs a huge computational cost. Coreset selection techniques
can mitigate this issue by training on the most representative subsets.
However, existing methods struggle to eliminate quantization errors in the
model when using small-scale datasets (e.g., only 10% of the data), leading to
significant performance degradation. To address these issues, we propose QuaRC,
a QAT framework with coresets on edge devices, which consists of two main
phases: In the coreset selection phase, QuaRC introduces the ``Relative Entropy
Score" to identify the subsets that most effectively capture the model's
quantization errors. During the training phase, QuaRC employs the Cascaded
Layer Correction strategy to align the intermediate layer outputs of the
quantized model with those of the full-precision model, thereby effectively
reducing the quantization errors in the intermediate layers. Experimental
results demonstrate the effectiveness of our approach. For instance, when
quantizing ResNet-18 to 2-bit using a 1% data subset, QuaRC achieves a 5.72%
improvement in Top-1 accuracy on the ImageNet-1K dataset compared to
state-of-the-art techniques.

</details>


### [31] [Knowledge Abstraction for Knowledge-based Semantic Communication: A Generative Causality Invariant Approach](https://arxiv.org/abs/2507.17784)
*Minh-Duong Nguyen,Quoc-Viet Pham,Nguyen H. Tran,Hoang-Khoi Do,Duy T. Ngo,Won-Joo Hwang*

Main category: cs.LG

TL;DR: 提出了一种低复杂度、通用的AI模型，通过因果不变学习提取数据的因果和非因果表示，用于语义通信中信道解码器的数据重建。


<details>
  <summary>Details</summary>
Motivation: 解决语义通信中数据重建的挑战，特别是在用户数据多样化和知识随时间演变的情况下，确保解码器的鲁棒性和一致性。

Method: 使用生成对抗网络（GAN）和因果不变学习，提取因果和非因果表示；设计稀疏更新协议以减少通信开销。

Result: 因果不变知识确保了跨设备的一致性，分类任务表现优异，数据重建的PSNR优于现有方法。

Conclusion: 该方法在语义通信中表现出高效性和鲁棒性，尤其在跨域数据重建和知识一致性方面具有优势。

Abstract: In this study, we design a low-complexity and generalized AI model that can
capture common knowledge to improve data reconstruction of the channel decoder
for semantic communication. Specifically, we propose a generative adversarial
network that leverages causality-invariant learning to extract causal and
non-causal representations from the data. Causal representations are invariant
and encompass crucial information to identify the data's label. They can
encapsulate semantic knowledge and facilitate effective data reconstruction at
the receiver. Moreover, the causal mechanism ensures that learned
representations remain consistent across different domains, making the system
reliable even with users collecting data from diverse domains. As
user-collected data evolves over time causing knowledge divergence among users,
we design sparse update protocols to improve the invariant properties of the
knowledge while minimizing communication overheads. Three key observations were
drawn from our empirical evaluations. Firstly, causality-invariant knowledge
ensures consistency across different devices despite the diverse training data.
Secondly, invariant knowledge has promising performance in classification
tasks, which is pivotal for goal-oriented semantic communications. Thirdly, our
knowledge-based data reconstruction highlights the robustness of our decoder,
which surpasses other state-of-the-art data reconstruction and semantic
compression methods in terms of Peak Signal-to-Noise Ratio (PSNR).

</details>


### [32] [Self-similarity Analysis in Deep Neural Networks](https://arxiv.org/abs/2507.17785)
*Jingyi Ding,Chengwen Qi,Hongfei Wang,Jianshe Wu,Licheng Jiao,Yuwei Guo,Jian Gao*

Main category: cs.LG

TL;DR: 本文提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，研究不同隐藏层构建的特征网络的自相似性，并分析调整自相似度如何提升深度神经网络的分类性能。


<details>
  <summary>Details</summary>
Motivation: 当前研究发现某些深度神经网络在特征表示或参数分布上表现出强烈的层次自相似性，但缺乏对隐藏空间几何自相似性如何影响模型权重优化的定量分析，以及对内部神经元动态行为的清晰理解。

Method: 提出基于隐藏层神经元输出特征的复杂网络建模方法，研究不同隐藏层特征网络的自相似性，并调整自相似度以优化模型性能。

Result: 在MLP、卷积网络和注意力架构上验证发现，不同模型架构的特征网络自相似度各异；训练过程中嵌入自相似性约束可提升自相似深度神经网络（MLP和注意力架构）性能高达6个百分点。

Conclusion: 调整特征网络的自相似度能显著提升深度神经网络的分类性能，尤其在MLP和注意力架构中效果明显。

Abstract: Current research has found that some deep neural networks exhibit strong
hierarchical self-similarity in feature representation or parameter
distribution. However, aside from preliminary studies on how the power-law
distribution of weights across different training stages affects model
performance,there has been no quantitative analysis on how the self-similarity
of hidden space geometry influences model weight optimization, nor is there a
clear understanding of the dynamic behavior of internal neurons. Therefore,
this paper proposes a complex network modeling method based on the output
features of hidden-layer neurons to investigate the self-similarity of feature
networks constructed at different hidden layers, and analyzes how adjusting the
degree of self-similarity in feature networks can enhance the classification
performance of deep neural networks. Validated on three types of networks MLP
architectures, convolutional networks, and attention architectures this study
reveals that the degree of self-similarity exhibited by feature networks varies
across different model architectures. Furthermore, embedding constraints on the
self-similarity of feature networks during the training process can improve the
performance of self-similar deep neural networks (MLP architectures and
attention architectures) by up to 6 percentage points.

</details>


### [33] [Reinforcement Learning for Accelerated Aerodynamic Shape Optimisation](https://arxiv.org/abs/2507.17786)
*Florian Sobieczky,Alfredo Lopez,Erika Dudkin,Christopher Lackner,Matthias Hochsteger,Bernhard Scheichl,Helmut Sobieczky*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习（RL）的自适应优化算法，用于降维的气动形状优化。通过代理模型和MCMC方法，结合参数冻结策略，以减少计算成本并解释优化结果。


<details>
  <summary>Details</summary>
Motivation: 目标是减少计算成本，并通过优化结果解释极值点对实现目标流场的作用。

Method: 采用基于代理模型的actor-critic策略评估MCMC方法，结合参数冻结策略，通过局部优化参数变化加速全局优化。

Result: 在简单流体动力学问题上，该方法能够实现特征重要性评分，并加速全局优化。

Conclusion: 该方法在降维优化中有效，能够解释优化结果并减少计算成本。

Abstract: We introduce a reinforcement learning (RL) based adaptive optimization
algorithm for aerodynamic shape optimization focused on dimensionality
reduction. The form in which RL is applied here is that of a surrogate-based,
actor-critic policy evaluation MCMC approach allowing for temporal 'freezing'
of some of the parameters to be optimized. The goals are to minimize
computational effort, and to use the observed optimization results for
interpretation of the discovered extrema in terms of their role in achieving
the desired flow-field.
  By a sequence of local optimized parameter changes around intermediate CFD
simulations acting as ground truth, it is possible to speed up the global
optimization if (a) the local neighbourhoods of the parameters in which the
changed parameters must reside are sufficiently large to compete with the
grid-sized steps and its large number of simulations, and (b) the estimates of
the rewards and costs on these neighbourhoods necessary for a good step-wise
parameter adaption are sufficiently accurate. We give an example of a simple
fluid-dynamical problem on which the method allows interpretation in the sense
of a feature importance scoring.

</details>


### [34] [Hyperbolic Deep Learning for Foundation Models: A Survey](https://arxiv.org/abs/2507.17787)
*Neil He,Hiren Madhu,Ngoc Bui,Menglin Yang,Rex Ying*

Main category: cs.LG

TL;DR: 论文探讨了基础模型的局限性，并提出双曲空间作为改进几何表示的方法。


<details>
  <summary>Details</summary>
Motivation: 基础模型在欧几里得几何下的表现存在局限性，如表示能力不足、适应性差和扩展性有限，因此探索非欧几里得几何（如双曲空间）是否能更好地匹配真实数据的结构。

Method: 利用双曲空间的数学特性（如指数体积增长）来改进基础模型，包括语言模型、视觉语言模型和多模态模型。

Result: 双曲空间能更高效地嵌入层次结构和幂律分布，提升模型的推理能力、零样本泛化和跨模态对齐，同时保持参数效率。

Conclusion: 双曲空间为基础模型提供了新的研究方向，但仍需解决关键挑战以推动领域发展。

Abstract: Foundation models pre-trained on massive datasets, including large language
models (LLMs), vision-language models (VLMs), and large multimodal models, have
demonstrated remarkable success in diverse downstream tasks. However, recent
studies have shown fundamental limitations of these models: (1) limited
representational capacity, (2) lower adaptability, and (3) diminishing
scalability. These shortcomings raise a critical question: is Euclidean
geometry truly the optimal inductive bias for all foundation models, or could
incorporating alternative geometric spaces enable models to better align with
the intrinsic structure of real-world data and improve reasoning processes?
Hyperbolic spaces, a class of non-Euclidean manifolds characterized by
exponential volume growth with respect to distance, offer a mathematically
grounded solution. These spaces enable low-distortion embeddings of
hierarchical structures (e.g., trees, taxonomies) and power-law distributions
with substantially fewer dimensions compared to Euclidean counterparts. Recent
advances have leveraged these properties to enhance foundation models,
including improving LLMs' complex reasoning ability, VLMs' zero-shot
generalization, and cross-modal semantic alignment, while maintaining parameter
efficiency. This paper provides a comprehensive review of hyperbolic neural
networks and their recent development for foundation models. We further outline
key challenges and research directions to advance the field.

</details>


### [35] [Remembering the Markov Property in Cooperative MARL](https://arxiv.org/abs/2507.18333)
*Kale-ab Abebe Tessera,Leonard Hinckeldey,Riccardo Zamboni,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: 论文指出当前多智能体强化学习（MARL）方法依赖简单惯例而非有效信号恢复，并提出新环境设计原则。


<details>
  <summary>Details</summary>
Motivation: 探讨当前MARL方法在Dec-POMDP框架下的局限性，揭示其成功依赖简单惯例而非真实推理能力。

Method: 通过案例研究分析现有MARL算法的表现，提出新环境设计原则。

Result: 发现现有方法学习的是脆弱的惯例，而非基于观察和记忆的推理，任务设计是关键。

Conclusion: 呼吁设计新环境，强调观察和记忆推理，以测试智能体的真实能力。

Abstract: Cooperative multi-agent reinforcement learning (MARL) is typically formalised
as a Decentralised Partially Observable Markov Decision Process (Dec-POMDP),
where agents must reason about the environment and other agents' behaviour. In
practice, current model-free MARL algorithms use simple recurrent function
approximators to address the challenge of reasoning about others using partial
information. In this position paper, we argue that the empirical success of
these methods is not due to effective Markov signal recovery, but rather to
learning simple conventions that bypass environment observations and memory.
Through a targeted case study, we show that co-adapting agents can learn
brittle conventions, which then fail when partnered with non-adaptive agents.
Crucially, the same models can learn grounded policies when the task design
necessitates it, revealing that the issue is not a fundamental limitation of
the learning models but a failure of the benchmark design. Our analysis also
suggests that modern MARL environments may not adequately test the core
assumptions of Dec-POMDPs. We therefore advocate for new cooperative
environments built upon two core principles: (1) behaviours grounded in
observations and (2) memory-based reasoning about other agents, ensuring
success requires genuine skill rather than fragile, co-adapted agreements.

</details>


### [36] [Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking](https://arxiv.org/abs/2507.17788)
*Ali Vardasbi,Gustavo Penha,Claudia Hauff,Hugues Bouchard*

Main category: cs.LG

TL;DR: 论文研究了LLMs在排序和评估任务中的位置偏差和重复不一致性，提出了一种动态早停方法以减少计算成本。


<details>
  <summary>Details</summary>
Motivation: LLMs在排序和评估任务中存在位置偏差和重复不一致性，静态重复策略计算成本高，需针对每个实例动态调整。

Method: 提出动态早停方法，自适应确定每个实例所需的重复次数，并引入基于置信度的改进。

Result: 动态策略平均减少81%的LLM调用，基于置信度的改进进一步减少至87%，同时保持准确性。

Conclusion: 动态早停方法有效减少计算成本，适用于不同规模和任务的LLMs。

Abstract: When using LLMs to rank items based on given criteria, or evaluate answers,
the order of candidate items can influence the model's final decision. This
sensitivity to item positioning in a LLM's prompt is known as position bias.
Prior research shows that this bias exists even in large models, though its
severity varies across models and tasks. In addition to position bias, LLMs
also exhibit varying degrees of low repetition consistency, where repeating the
LLM call with the same candidate ordering can lead to different rankings. To
address both inconsistencies, a common approach is to prompt the model multiple
times with different candidate orderings and aggregate the results via majority
voting. However, this repetition strategy, significantly increases
computational costs. Extending prior findings, we observe that both the
direction -- favoring either the earlier or later candidate in the prompt --
and magnitude of position bias across instances vary substantially, even within
a single dataset. This observation highlights the need for a per-instance
mitigation strategy. To this end, we introduce a dynamic early-stopping method
that adaptively determines the number of repetitions required for each
instance. Evaluating our approach across three LLMs of varying sizes and on two
tasks, namely re-ranking and alignment, we demonstrate that transitioning to a
dynamic repetition strategy reduces the number of LLM calls by an average of
81%, while preserving the accuracy. Furthermore, we propose a confidence-based
adaptation to our early-stopping method, reducing LLM calls by an average of
87% compared to static repetition, with only a slight accuracy trade-off
relative to our original early-stopping method.

</details>


### [37] [Moving Out: Physically-grounded Human-AI Collaboration](https://arxiv.org/abs/2507.18623)
*Xuhui Kang,Sung-Wook Lee,Haolin Liu,Yuyan Wang,Yen-Ling Kuo*

Main category: cs.LG

TL;DR: 论文提出了一个名为Moving Out的新基准，用于评估人-AI协作中物理约束下的适应性，并提出了BASS方法以提升AI在复杂物理环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决具身智能体（如机器人）在物理约束下与人类协作时面临的连续状态-动作空间和动态约束的复杂性。

Method: 提出了BASS方法（行为增强、模拟和选择），通过增强行为多样性和动作结果理解来应对物理环境中的挑战。

Result: 实验表明，BASS在AI-AI和人-AI协作中优于现有最先进模型。

Conclusion: Moving Out基准和BASS方法为物理约束下的人-AI协作提供了有效的评估和解决方案。

Abstract: The ability to adapt to physical actions and constraints in an environment is
crucial for embodied agents (e.g., robots) to effectively collaborate with
humans. Such physically grounded human-AI collaboration must account for the
increased complexity of the continuous state-action space and constrained
dynamics caused by physical constraints. In this paper, we introduce
\textit{Moving Out}, a new human-AI collaboration benchmark that resembles a
wide range of collaboration modes affected by physical attributes and
constraints, such as moving heavy items together and maintaining consistent
actions to move a big item around a corner. Using Moving Out, we designed two
tasks and collected human-human interaction data to evaluate models' abilities
to adapt to diverse human behaviors and unseen physical attributes. To address
the challenges in physical environments, we propose a novel method, BASS
(Behavior Augmentation, Simulation, and Selection), to enhance the diversity of
agents and their understanding of the outcome of actions. Our experiments show
that BASS outperforms state-of-the-art models in AI-AI and human-AI
collaboration. The project page is available at
\href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\_ai/}.

</details>


### [38] [Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data](https://arxiv.org/abs/2507.17791)
*Eduardo Aguilar-Bejarano,Daniel Lea,Karthikeyan Sivakumar,Jimiama M. Mase,Reza Omidvar,Ruizhe Li,Troy Kettle,James Mitchell-White,Morgan R Alexander,David A Winkler,Grazziela Figueredo*

Main category: cs.LG

TL;DR: Helix是一个基于Python的开源软件框架，旨在为表格数据提供可重现和可解释的机器学习工作流程，支持透明化的数据分析过程。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习工作流中实验数据和分析过程的可重现性、可解释性和透明性问题，同时为非数据科学背景的研究者提供易用工具。

Method: Helix提供标准化模块，涵盖数据预处理、可视化、模型训练、评估、解释、结果检查和预测等功能，并集成用户友好界面和新型解释方法。

Result: Helix通过MIT许可证发布，支持社区开发，并遵循FAIR原则，促进透明化和可重现的机器学习研究。

Conclusion: Helix是一个强大的工具，能够提升机器学习工作流的透明度和可解释性，尤其适合非专业用户和需要可重现研究的场景。

Abstract: Helix is an open-source, extensible, Python-based software framework to
facilitate reproducible and interpretable machine learning workflows for
tabular data. It addresses the growing need for transparent experimental data
analytics provenance, ensuring that the entire analytical process -- including
decisions around data transformation and methodological choices -- is
documented, accessible, reproducible, and comprehensible to relevant
stakeholders. The platform comprises modules for standardised data
preprocessing, visualisation, machine learning model training, evaluation,
interpretation, results inspection, and model prediction for unseen data. To
further empower researchers without formal training in data science to derive
meaningful and actionable insights, Helix features a user-friendly interface
that enables the design of computational experiments, inspection of outcomes,
including a novel interpretation approach to machine learning decisions using
linguistic terms all within an integrated environment. Released under the MIT
licence, Helix is accessible via GitHub and PyPI, supporting community-driven
development and promoting adherence to the FAIR principles.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [39] [Technical Implementation of Tippy: Multi-Agent Architecture and System Design for Drug Discovery Laboratory Automation](https://arxiv.org/abs/2507.17852)
*Yao Fehlis,Charles Crain,Aidan Jensen,Michael Watson,James Juhasz,Paul Mandel,Betty Liu,Shawn Mahon,Daren Wilson,Nick Lynch-Jonely,Ben Leedom,David Fuller*

Main category: cs.MA

TL;DR: 本文详细介绍了Tippy的多智能体系统在药物发现实验室自动化中的实现，采用分布式微服务架构和标准化协议，展示了AI智能体如何高效协调复杂工作流程。


<details>
  <summary>Details</summary>
Motivation: 基于先前关于药物研究中代理AI的工作，本文旨在通过技术分析展示多智能体系统在实验室自动化中的实际应用和优势。

Method: 采用分布式微服务架构，包含五个专业智能体，通过OpenAI Agents SDK协调，使用Model Context Protocol（MCP）访问实验室工具，并集成Git配置管理、Kubernetes部署、CI/CD管道等技术。

Result: 系统成功实现了复杂实验室工作流的协调，具备安全性、可扩展性、可靠性和与现有基础设施的集成能力。

Conclusion: 研究表明，专业化的AI智能体能够通过标准化协议有效协调复杂的实验室工作流程，同时满足安全性和可扩展性需求。

Abstract: Building on the conceptual framework presented in our previous work on
agentic AI for pharmaceutical research, this paper provides a comprehensive
technical analysis of Tippy's multi-agent system implementation for drug
discovery laboratory automation. We present a distributed microservices
architecture featuring five specialized agents (Supervisor, Molecule, Lab,
Analysis, and Report) that coordinate through OpenAI Agents SDK orchestration
and access laboratory tools via the Model Context Protocol (MCP). The system
architecture encompasses agent-specific tool integration, asynchronous
communication patterns, and comprehensive configuration management through
Git-based tracking. Our production deployment strategy utilizes Kubernetes
container orchestration with Helm charts, Docker containerization, and CI/CD
pipelines for automated testing and deployment. The implementation integrates
vector databases for RAG functionality and employs an Envoy reverse proxy for
secure external access. This work demonstrates how specialized AI agents can
effectively coordinate complex laboratory workflows while maintaining security,
scalability, reliability, and integration with existing laboratory
infrastructure through standardized protocols.

</details>


### [40] [Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation](https://arxiv.org/abs/2507.18224)
*Shiyuan Li,Yixin Liu,Qingsong Wen,Chengqi Zhang,Shirui Pan*

Main category: cs.MA

TL;DR: 论文提出了一种基于条件自回归图生成的多智能体系统（MAS）设计方法ARG-Designer，通过动态生成协作图来优化任务适应性。


<details>
  <summary>Details</summary>
Motivation: 现有MAS设计方法受限于预定义的代理和交互结构，缺乏灵活性，无法满足任务特定需求。

Method: 将MAS设计重新定义为条件自回归图生成任务，提出ARG-Designer模型，动态生成代理数量、角色和通信链路。

Result: 在六个基准测试中，ARG-Designer实现了最优性能，并显著提高了效率和可扩展性。

Conclusion: ARG-Designer为MAS设计提供了灵活且可扩展的解决方案，显著提升了任务适应性。

Abstract: Multi-agent systems (MAS) based on large language models (LLMs) have emerged
as a powerful solution for dealing with complex problems across diverse
domains. The effectiveness of MAS is critically dependent on its collaboration
topology, which has become a focal point for automated design research.
However, existing approaches are fundamentally constrained by their reliance on
a template graph modification paradigm with a predefined set of agents and
hard-coded interaction structures, significantly limiting their adaptability to
task-specific requirements. To address these limitations, we reframe MAS design
as a conditional autoregressive graph generation task, where both the system
composition and structure are designed jointly. We propose ARG-Designer, a
novel autoregressive model that operationalizes this paradigm by constructing
the collaboration graph from scratch. Conditioned on a natural language task
query, ARG-Designer sequentially and dynamically determines the required number
of agents, selects their appropriate roles from an extensible pool, and
establishes the optimal communication links between them. This generative
approach creates a customized topology in a flexible and extensible manner,
precisely tailored to the unique demands of different tasks. Extensive
experiments across six diverse benchmarks demonstrate that ARG-Designer not
only achieves state-of-the-art performance but also enjoys significantly
greater token efficiency and enhanced extensibility. The source code of
ARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.

</details>


### [41] [Designing Value-Aligned Traffic Agents through Conflict Sensitivity](https://arxiv.org/abs/2507.18284)
*Astrid Rakow,Joe Collenette,Maike Schwammberger,Marija Slavkovik,Gleifer Vs Alves*

Main category: cs.MA

TL;DR: 本文提出了一种基于认知博弈论的形式化模型，用于开发符合多方利益（法律、社会、道德）的自主交通代理（ATAs），重点解决价值冲突问题。


<details>
  <summary>Details</summary>
Motivation: 确保自主交通代理的行为不仅安全，还能在多维度（法律、社会、道德）上与利益相关者的价值观保持一致。

Method: 采用认知博弈论中的冲突模型，分析价值冲突，并将其应用于设计流程中的价值提取、能力规范、解释和系统优化。

Result: 提出了价值对齐操作设计域（VODDs）的概念，用于在开发阶段预结构和优化价值敏感行为。

Conclusion: 通过提前分析和结构化价值冲突，将道德困境的解决从运行时转移到开发阶段，从而更有效地实现价值对齐。

Abstract: Autonomous traffic agents (ATAs) are expected to act in ways tat are not only
safe, but also aligned with stakeholder values across legal, social, and moral
dimensions. In this paper, we adopt an established formal model of conflict
from epistemic game theory to support the development of such agents. We focus
on value conflicts-situations in which agents face competing goals rooted in
value-laden situations and show how conflict analysis can inform key phases of
the design process. This includes value elicitation, capability specification,
explanation, and adaptive system refinement. We elaborate and apply the concept
of Value-Aligned Operational Design Domains (VODDs) to structure autonomy in
accordance with contextual value priorities. Our approach shifts the emphasis
from solving moral dilemmas at runtime to anticipating and structuring
value-sensitive behaviour during development.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [42] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
*Alison Bartsch,Arvind Car,Amir Barati Farimani*

Main category: cs.RO

TL;DR: 研究提出了一种名为PinchBot的机器人系统，通过基于捏合的动作实现简单陶艺制作，结合扩散策略模型和预训练的3D点云嵌入技术。


<details>
  <summary>Details</summary>
Motivation: 探索高度多模态和长时程的可变形物体操控挑战，尤其是陶艺制作中的精确动作需求。

Method: 采用目标条件扩散策略模型，结合预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影。

Result: PinchBot能够成功制作多种简单陶艺目标。

Conclusion: 该系统为复杂可变形物体操控提供了有效解决方案。

Abstract: Pottery creation is a complicated art form that requires dexterous, precise
and delicate actions to slowly morph a block of clay to a meaningful, and often
useful 3D goal shape. In this work, we aim to create a robotic system that can
create simple pottery goals with only pinch-based actions. This pinch pottery
task allows us to explore the challenges of a highly multi-modal and
long-horizon deformable manipulation task. To this end, we present PinchBot, a
goal-conditioned diffusion policy model that when combined with pre-trained 3D
point cloud embeddings, task progress prediction and collision-constrained
action projection, is able to successfully create a variety of simple pottery
goals. For experimental videos and access to the demonstration dataset, please
visit our project website:
https://sites.google.com/andrew.cmu.edu/pinchbot/home.

</details>


### [43] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
*Dennis Benders,Laura Ferranti,Johannes Köhler*

Main category: cs.RO

TL;DR: 该技术报告介绍了如何通过非线性模型预测控制（NMPC）实现移动机器人在障碍物环境中的安全导航，强调理论与实际应用的结合。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在复杂环境中安全导航是一个关键但复杂的任务，需要确保机器人遵守状态和输入约束，同时避免与障碍物碰撞。

Method: 报告提供了一种逐步实现NMPC的方法，重点关注安全性和性能保证，从理论概念到数学证明和实际实现。

Result: 报告为研究人员和工程师提供了一种实用的NMPC实现路径，旨在填补理论NMPC与实际机器人应用之间的鸿沟。

Conclusion: 该报告旨在为NMPC在机器人导航中的应用提供实用指南，并欢迎反馈以更新内容。

Abstract: Designing a Model Predictive Control (MPC) scheme that enables a mobile robot
to safely navigate through an obstacle-filled environment is a complicated yet
essential task in robotics. In this technical report, safety refers to ensuring
that the robot respects state and input constraints while avoiding collisions
with obstacles despite the presence of disturbances and measurement noise. This
report offers a step-by-step approach to implementing Nonlinear Model
Predictive Control (NMPC) schemes addressing these safety requirements.
Numerous books and survey papers provide comprehensive overviews of linear MPC
(LMPC) \cite{bemporad2007robust,kouvaritakis2016model}, NMPC
\cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook},
and their applications in various domains, including robotics
\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}.
This report does not aim to replicate those exhaustive reviews. Instead, it
focuses specifically on NMPC as a foundation for safe mobile robot navigation.
The goal is to provide a practical and accessible path from theoretical
concepts to mathematical proofs and implementation, emphasizing safety and
performance guarantees. It is intended for researchers, robotics engineers, and
practitioners seeking to bridge the gap between theoretical NMPC formulations
and real-world robotic applications.
  This report is not necessarily meant to remain fixed over time. If someone
finds an error in the presented theory, please reach out via the given email
addresses. We are happy to update the document if necessary.

</details>


### [44] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
*Mingfeng Yuan,Letian Wang,Steven L. Waslander*

Main category: cs.RO

TL;DR: 论文提出了一种利用多模态大语言模型（MLLMs）结合视觉语言感知模型的方法，使机器人能够解析复杂语言指令并生成轨迹点，完成开放世界中的导航任务。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练大语言模型（LLMs）在常识推理方面表现出色，但在开放世界中实现语言描述到实际机器人动作的转换仍具挑战性。

Method: 利用MLLMs的跨模态理解和代码生成能力，结合视觉语言感知模型生成2D鸟瞰价值图，整合语义知识与空间信息。

Result: 在户外导航任务中验证了零样本视觉语言导航框架的可行性，并在室内外场景中展示了系统的鲁棒性和实用性。

Conclusion: 该方法能够处理多样化的自然语言导航指令，并在实际机器人平台上验证了其有效性。

Abstract: Pre-trained large language models (LLMs) have demonstrated strong
common-sense reasoning abilities, making them promising for robotic navigation
and planning tasks. However, despite recent progress, bridging the gap between
language descriptions and actual robot actions in the open-world, beyond merely
invoking limited predefined motion primitives, remains an open challenge. In
this work, we aim to enable robots to interpret and decompose complex language
instructions, ultimately synthesizing a sequence of trajectory points to
complete diverse navigation tasks given open-set instructions and open-set
objects. We observe that multi-modal large language models (MLLMs) exhibit
strong cross-modal understanding when processing free-form language
instructions, demonstrating robust scene comprehension. More importantly,
leveraging their code-generation capability, MLLMs can interact with
vision-language perception models to generate compositional 2D bird-eye-view
value maps, effectively integrating semantic knowledge from MLLMs with spatial
information from maps to reinforce the robot's spatial understanding. To
further validate our approach, we effectively leverage large-scale autonomous
vehicle datasets (AVDs) to validate our proposed zero-shot vision-language
navigation framework in outdoor navigation tasks, demonstrating its capability
to execute a diverse range of free-form natural language navigation
instructions while maintaining robustness against object detection errors and
linguistic ambiguities. Furthermore, we validate our system on a Husky robot in
both indoor and outdoor scenes, demonstrating its real-world robustness and
applicability. Supplementary videos are available at
https://trailab.github.io/OpenNav-website/

</details>


### [45] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
*Behzad Zamani,Jochen Trumpf,Chris Manzie*

Main category: cs.RO

TL;DR: 提出了一种模块化非线性最小二乘滤波方法，用于独立子系统组成的系统，通过协方差交集算法避免信息重复计算，并在机器人-地标定位问题中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 解决由独立子系统组成的系统中状态和误差协方差估计的独立更新问题，特别是在相对测量同时依赖多个子系统状态时。

Method: 采用模块化非线性最小二乘滤波方法，结合协方差交集（CI）算法，避免信息重复计算，并在机器人-地标定位问题中具体应用。

Result: 通过随机模拟研究，验证了模块化方法相对于联合状态滤波器的性能权衡，并展示了在减少通信和带宽需求时的性能退化情况。

Conclusion: 模块化方法在独立子系统系统中有效，协方差交集算法的集成避免了信息重复计算，适用于机器人-地标定位等问题。

Abstract: In this paper we propose a modular nonlinear least squares filtering approach
for systems composed of independent subsystems. The state and error covariance
estimate of each subsystem is updated independently, even when a relative
measurement simultaneously depends on the states of multiple subsystems. We
integrate the Covariance Intersection (CI) algorithm as part of our solution in
order to prevent double counting of information when subsystems share estimates
with each other. An alternative derivation of the CI algorithm based on least
squares estimation makes this integration possible. We particularise the
proposed approach to the robot-landmark localization problem. In this problem,
noisy measurements of the bearing angle to a stationary landmark position
measured relative to the SE(2) pose of a moving robot couple the estimation
problems for the robot pose and the landmark position. In a randomized
simulation study, we benchmark the proposed modular method against a monolithic
joint state filter to elucidate their respective trade-offs. In this study we
also include variants of the proposed method that achieve a graceful
degradation of performance with reduced communication and bandwidth
requirements.

</details>


### [46] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
*Min-Gyu Kim,Dongyun Kang,Hajun Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种结合模型驱动和学习驱动框架的新方法，通过残差模块提升鲁棒运动控制性能。


<details>
  <summary>Details</summary>
Motivation: 解决模型不匹配导致的性能下降问题，提升在高不确定性环境中的控制表现和学习效率。

Method: 将残差模块与启发式设计的模型驱动框架（如步态规划和动态模型）结合，并选择适合的学习方法。

Result: 在真实四足机器人上验证了框架的可行性，机器人成功保持平衡并跟踪指令速度。

Conclusion: 该方法不仅提升了控制性能，还增强了名义控制器对参数调整的鲁棒性。

Abstract: This paper presents a novel approach that combines the advantages of both
model-based and learning-based frameworks to achieve robust locomotion. The
residual modules are integrated with each corresponding part of the model-based
framework, a footstep planner and dynamic model designed using heuristics, to
complement performance degradation caused by a model mismatch. By utilizing a
modular structure and selecting the appropriate learning-based method for each
residual module, our framework demonstrates improved control performance in
environments with high uncertainty, while also achieving higher learning
efficiency compared to baseline methods. Moreover, we observed that our
proposed methodology not only enhances control performance but also provides
additional benefits, such as making nominal controllers more robust to
parameter tuning. To investigate the feasibility of our framework, we
demonstrated residual modules combined with model predictive control in a real
quadrupedal robot. Despite uncertainties beyond the simulation, the robot
successfully maintains balance and tracks the commanded velocity.

</details>


### [47] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 该论文提出了一种基于无人机（UAV）的子系统，用于搜救任务，结合了人员检测、人脸识别和个体跟踪功能，通过ROS2框架和多种CNN模型实现。


<details>
  <summary>Details</summary>
Motivation: 解决搜救任务中快速定位和跟踪特定个体的需求，提高救援效率和准确性。

Method: 集成UAV与ROS2框架，使用YOLOv11和YOLOv11-pose CNN模型进行跟踪，dlib库进行人脸识别，并通过系统识别和PD控制器实现自主导航。

Result: 初步实验在14个已知个体上验证了系统的实时可行性。

Conclusion: 系统具备实际应用潜力，下一步将在大规模实验无人机上部署，并结合GPS导航优化救援规划。

Abstract: In this paper, we present a subsystem, using Unmanned Aerial Vehicles (UAV),
for search and rescue missions, focusing on people detection, face recognition
and tracking of identified individuals. The proposed solution integrates a UAV
with ROS2 framework, that utilizes multiple convolutional neural networks (CNN)
for search missions. System identification and PD controller deployment are
performed for autonomous UAV navigation. The ROS2 environment utilizes the
YOLOv11 and YOLOv11-pose CNNs for tracking purposes, and the dlib library CNN
for face recognition. The system detects a specific individual, performs face
recognition and starts tracking. If the individual is not yet known, the UAV
operator can manually locate the person, save their facial image and
immediately initiate the tracking process. The tracking process relies on
specific keypoints identified on the human body using the YOLOv11-pose CNN
model. These keypoints are used to track a specific individual and maintain a
safe distance. To enhance accurate tracking, system identification is
performed, based on measurement data from the UAVs IMU. The identified system
parameters are used to design PD controllers that utilize YOLOv11-pose to
estimate the distance between the UAVs camera and the identified individual.
The initial experiments, conducted on 14 known individuals, demonstrated that
the proposed subsystem can be successfully used in real time. The next step
involves implementing the system on a large experimental UAV for field use and
integrating autonomous navigation with GPS-guided control for rescue operations
planning.

</details>


### [48] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
*Arup Kumar Sahoo,Itzik Klein*

Main category: cs.RO

TL;DR: MoRPI-PINN是一种基于物理信息的神经网络框架，用于提高移动机器人在无卫星或摄像头情况下的惯性导航精度。


<details>
  <summary>Details</summary>
Motivation: 解决在卫星导航或摄像头不可用时，仅依赖惯性传感器导致的导航漂移问题。

Method: 通过蛇形运动增加惯性信号的信噪比，并利用物理信息神经网络框架（MoRPI-PINN）嵌入物理定律和约束进行训练。

Result: 实验显示，MoRPI-PINN的导航精度比其他方法提高了85%以上。

Conclusion: MoRPI-PINN是一种轻量级且适用于边缘设备的解决方案，可广泛应用于移动机器人导航。

Abstract: A fundamental requirement for full autonomy in mobile robots is accurate
navigation even in situations where satellite navigation or cameras are
unavailable. In such practical situations, relying only on inertial sensors
will result in navigation solution drift due to the sensors' inherent noise and
error terms. One of the emerging solutions to mitigate drift is to maneuver the
robot in a snake-like slithering motion to increase the inertial
signal-to-noise ratio, allowing the regression of the mobile robot position. In
this work, we propose MoRPI-PINN as a physics-informed neural network framework
for accurate inertial-based mobile robot navigation. By embedding physical laws
and constraints into the training process, MoRPI-PINN is capable of providing
an accurate and robust navigation solution. Using real-world experiments, we
show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN
is a lightweight approach that can be implemented even on edge devices and used
in any typical mobile robot application.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [49] [Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability](https://arxiv.org/abs/2507.17851)
*Xiaoxu Zhu,Junhua Li*

Main category: cs.SD

TL;DR: 该论文提出了一种基于可解释性的语音预训练模型中的音色解耦方法，通过量化音色残留和改进音色过滤，实现了音色与内容的有效分离。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以直接量化音色残留，且去除音色信息时易导致内容损失，因此需要一种更直接且有效的方法。

Method: 提出InterpTRQE-SptME基准和InterpTF-SptME方法，利用SHAP技术量化音色残留并过滤音色信息。

Result: 实验表明，SHAP Noise方法可将音色残留从18.05%降至接近0%，同时保持内容完整性。

Conclusion: 该方法显著优化了音色解耦，提升了内容相关任务的性能，并防止音色隐私泄露。

Abstract: Speech pretrained models contain task-specific information across different
layers, but decoupling content and timbre information remains challenging as
removing speaker-specific information often causes content loss. Current
research lacks direct metrics to quantify timbre residual in model encodings,
relying on indirect evaluation through downstream tasks. This paper addresses
these challenges through interpretability-based speaker disentanglement in
speech pretraining models. We quantitatively evaluate timbre residual in model
embeddings and improve speaker disentanglement using interpretive
representations. Our contributions include: (1) InterpTRQE-SptME Benchmark - a
timbre residual recognition framework using interpretability. The benchmark
concatenates content embeddings with timbre embeddings for speaker
classification, then applies Gradient SHAP Explainer to quantify timbre
residual. We evaluate seven speech pretraining model variations. (2)
InterpTF-SptME method - an interpretability-based timbre filtering approach
using SHAP Noise and SHAP Cropping techniques. This model-agnostic method
transforms intermediate encodings to remove timbre while preserving content.
Experiments on VCTK dataset with HuBERT LARGE demonstrate successful content
preservation and significant speaker disentanglement optimization. Results show
the SHAP Noise method can reduce timbre residual from 18.05% to near 0% while
maintaining content integrity, contributing to enhanced performance in
content-related speech processing tasks and preventing timbre privacy leakage.

</details>


### [50] [Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation](https://arxiv.org/abs/2507.17937)
*Jaechul Roh,Zachary Novack,Yuefeng Peng,Niloofar Mireshghallah,Taylor Berg-Kirkpatrick,Amir Houmansadr*

Main category: cs.SD

TL;DR: 论文研究了歌词到歌曲生成模型（LS2）对训练数据记忆的脆弱性，提出了一种名为APT的攻击方法，通过同音替换改变歌词语义但保留声学结构，揭示了模型对训练内容的记忆现象，并发现这种现象在文本到视频模型中同样存在。


<details>
  <summary>Details</summary>
Motivation: 探索歌词到歌曲生成模型对训练数据记忆的脆弱性，揭示其潜在的安全和版权问题。

Method: 提出Adversarial PhoneTic Prompting (APT)攻击方法，通过同音替换改变歌词语义但保留声学结构，测试模型对训练内容的记忆能力。

Result: 发现模型（如SUNO和YuE）会生成与训练内容高度相似的输出，且在文本到视频模型中也能触发视觉记忆现象。

Conclusion: 揭示了转录条件多模态生成中的关键漏洞，提出对现代生成系统的版权、安全和内容来源的紧迫问题。

Abstract: Lyrics-to-Song (LS2) generation models promise end-to-end music synthesis
from text, yet their vulnerability to training data memorization remains
underexplored. We introduce Adversarial PhoneTic Prompting (APT), a novel
attack where lyrics are semantically altered while preserving their acoustic
structure through homophonic substitutions (e.g., Eminem's famous "mom's
spaghetti" $\rightarrow$ "Bob's confetti"). Despite these distortions, we
uncover a powerful form of sub-lexical memorization: models like SUNO and YuE
regenerate outputs strikingly similar to known training content, achieving high
similarity across audio-domain metrics, including CLAP, AudioJudge, and
CoverID. This vulnerability persists across multiple languages and genres. More
surprisingly, we discover that phoneme-altered lyrics alone can trigger visual
memorization in text-to-video models. When prompted with phonetically modified
lyrics from Lose Yourself, Veo 3 reconstructs visual elements from the original
music video -- including character appearance and scene composition -- despite
no visual cues in the prompt. We term this phenomenon phonetic-to-visual
regurgitation. Together, these findings expose a critical vulnerability in
transcript-conditioned multimodal generation: phonetic prompting alone can
unlock memorized audiovisual content, raising urgent questions about copyright,
safety, and content provenance in modern generative systems. Example
generations are available on our demo page (jrohsc.github.io/music_attack/).

</details>


### [51] [Resnet-conformer network with shared weights and attention mechanism for sound event localization, detection, and distance estimation](https://arxiv.org/abs/2507.17941)
*Quoc Thinh Vo,David Han*

Main category: cs.SD

TL;DR: 本文介绍了DCASE 2024任务3A的解决方案，专注于声音事件定位与检测（SELD），采用音频输入和EINV2网络架构，取得了显著结果。


<details>
  <summary>Details</summary>
Motivation: SELD在机器认知任务（如环境推断和导航）中具有重要价值，DCASE 2024挑战赛新增了距离估计任务，需要更全面的评估方法。

Method: 使用log-mel频谱图和强度向量，结合多种数据增强技术，提出基于EINV2的网络架构。

Result: 在测试集上取得了F-score 40.2%，角度误差17.7度，相对距离误差0.32的改进结果。

Conclusion: 该方法在音频输入的任务中表现优异，为SELD任务提供了有效的解决方案。

Abstract: This technical report outlines our approach to Task 3A of the Detection and
Classification of Acoustic Scenes and Events (DCASE) 2024, focusing on Sound
Event Localization and Detection (SELD). SELD provides valuable insights by
estimating sound event localization and detection, aiding in various machine
cognition tasks such as environmental inference, navigation, and other sound
localization-related applications. This year's challenge evaluates models using
either audio-only (Track A) or audiovisual (Track B) inputs on annotated
recordings of real sound scenes. A notable change this year is the introduction
of distance estimation, with evaluation metrics adjusted accordingly for a
comprehensive assessment. Our submission is for Task A of the Challenge, which
focuses on the audio-only track. Our approach utilizes log-mel spectrograms,
intensity vectors, and employs multiple data augmentations. We proposed an
EINV2-based [1] network architecture, achieving improved results: an F-score of
40.2%, Angular Error (DOA) of 17.7 degrees, and Relative Distance Error (RDE)
of 0.32 on the test set of the Development Dataset [2 ,3].

</details>


### [52] [The TEA-ASLP System for Multilingual Conversational Speech Recognition and Speech Diarization in MLC-SLM 2025 Challenge](https://arxiv.org/abs/2507.18051)
*Hongfei Xue,Kaixun Huang,Zhikai Zhou,Shen Huang,Shidong Shang*

Main category: cs.SD

TL;DR: TEA-ASLP系统在MLC-SLM 2025挑战赛中，通过改进Ideal-LLM模型和优化说话人日志ASR模型，分别在多语言对话ASR和语音日志ASR任务中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决多语言对话ASR和语音日志ASR任务中的性能问题，提升自动语音识别的准确性和效率。

Method: 在Task I中，结合已知语言识别和多语言MOE LoRA结构，使用CTC预测标记作为提示；在Task II中，替换基线模型为更适合的英语版本。

Result: Task I的WER降低30.8%，最终WER为9.60%；Task II的时间约束最小排列WER为17.49%，分别在挑战赛中排名第一和第二。

Conclusion: 提出的方法在多语言和语音日志ASR任务中表现出色，显著提升了性能。

Abstract: This paper presents the TEA-ASLP's system submitted to the MLC-SLM 2025
Challenge, addressing multilingual conversational automatic speech recognition
(ASR) in Task I and speech diarization ASR in Task II. For Task I, we enhance
Ideal-LLM model by integrating known language identification and a multilingual
MOE LoRA structure, along with using CTC-predicted tokens as prompts to improve
autoregressive generation. The model is trained on approximately 180k hours of
multilingual ASR data. In Task II, we replace the baseline English-Chinese
speaker diarization model with a more suitable English-only version. Our
approach achieves a 30.8% reduction in word error rate (WER) compared to the
baseline speech language model, resulting in a final WER of 9.60% in Task I and
a time-constrained minimum-permutation WER of 17.49% in Task II, earning first
and second place in the respective challenge tasks.

</details>


### [53] [DIFFA: Large Language Diffusion Models Can Listen and Understand](https://arxiv.org/abs/2507.18452)
*Jiaming Zhou,Hongjie Chen,Shiwan Zhao,Jian Kang,Jie Li,Enzhi Wang,Yujie Guo,Haoqin Sun,Hui Wang,Aobo Kong,Yong Qin,Xuelong Li*

Main category: cs.SD

TL;DR: DIFFA是首个基于扩散的大规模音频语言模型，用于口语理解，通过双适配器架构和两阶段训练，在有限数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型在音频模态的应用，解决现有自回归模型的局限性。

Method: 结合冻结扩散模型与双适配器架构，分两阶段训练：语义对齐和指令学习。

Result: 在MMSU、MMAU和VoiceBench等基准测试中表现优于开源自回归基线。

Conclusion: 扩散模型为高效、可扩展的音频理解提供了新方向。

Abstract: Recent advances in Large language models (LLMs) have shown remarkable
capabilities across textual and multimodal domains. In parallel,
diffusion-based language models have emerged as a promising alternative to the
autoregressive paradigm, offering improved controllability, bidirectional
context modeling, and robust generation. However, their application to the
audio modality remains underexplored. In this work, we introduce
\textbf{DIFFA}, the first diffusion-based Large Audio-Language Model designed
to perform spoken language understanding. DIFFA integrates a frozen diffusion
language model with a lightweight dual-adapter architecture that bridges speech
understanding and natural language reasoning. We employ a two-stage training
pipeline: first, aligning semantic representations via an ASR objective; then,
learning instruction-following abilities through synthetic audio-caption pairs
automatically generated by prompting LLMs. Despite being trained on only 960
hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates
competitive performance on major benchmarks, including MMSU, MMAU, and
VoiceBench, outperforming several autoregressive open-source baselines. Our
results reveal the potential of diffusion-based language models for efficient
and scalable audio understanding, opening a new direction for speech-driven AI.
Our code will be available at https://github.com/NKU-HLT/DIFFA.git.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [54] [Rapid Modeling Architecture for Lightweight Simulator to Accelerate and Improve Decision Making for Industrial Systems](https://arxiv.org/abs/2507.17990)
*Takumi Kato,Zhi Li Hu*

Main category: eess.SY

TL;DR: 提出了一种轻量级工业模拟器的快速建模架构（RMA），显著减少建模时间，提升决策效率。


<details>
  <summary>Details</summary>
Motivation: 工业系统设计早期阶段信息有限，传统模拟器建模时间长，无法满足快速决策需求。

Method: 提出RMA架构，开发基于RMA的模拟器原型，并应用于实际工厂布局设计问题。

Result: 与传统模拟器相比，建模时间减少78.3%。

Conclusion: RMA有效减轻建模负担，加速决策过程。

Abstract: Designing industrial systems, such as building, improving, and automating
distribution centers and manufacturing plants, involves critical
decision-making with limited information in the early phases. The lack of
information leads to less accurate designs of the systems, which are often
difficult to resolve later. It is effective to use simulators to model the
designed system and find out the issues early. However, the modeling time
required by conventional simulators is too long to allow for rapid model
creation to meet decision-making demands. In this paper, we propose a Rapid
Modeling Architecture (RMA) for a lightweight industrial simulator that
mitigates the modeling burden while maintaining the essential details in order
to accelerate and improve decision-making. We have prototyped a simulator based
on the RMA and applied it to the actual factory layout design problem. We also
compared the modeling time of our simulator to that of an existing simulator,
and as a result, our simulator achieved a 78.3% reduction in modeling time
compared to conventional simulators.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [55] [A Concept-based approach to Voice Disorder Detection](https://arxiv.org/abs/2507.17799)
*Davide Ghia,Gabriele Ciravegna,Alkis Koudounas,Marco Fantini,Erika Crosetti,Giovanni Succo,Tania Cerquitelli*

Main category: eess.AS

TL;DR: 论文探讨了基于可解释AI（XAI）的方法，如概念瓶颈模型（CBM）和概念嵌入模型（CEM），用于诊断语音障碍，旨在提高模型透明度和可解释性，同时保持与传统深度学习方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 语音障碍影响广泛，自动化、非侵入性诊断技术可显著改善患者生活质量。当前深度神经网络（DNNs）虽有效，但其决策过程不透明，限制了临床信任。

Method: 研究采用可解释AI（XAI）方法，特别是概念瓶颈模型（CBM）和概念嵌入模型（CEM），以提供更透明的决策框架。

Result: 结果表明，概念基础模型（如CBM和CEM）在性能上可与传统深度学习方法媲美，同时提供更高的可解释性。

Conclusion: 概念基础模型为语音障碍诊断提供了透明且高效的解决方案，有望提升临床应用的信任度。

Abstract: Voice disorders affect a significant portion of the population, and the
ability to diagnose them using automated, non-invasive techniques would
represent a substantial advancement in healthcare, improving the quality of
life of patients. Recent studies have demonstrated that artificial intelligence
models, particularly Deep Neural Networks (DNNs), can effectively address this
task. However, due to their complexity, the decision-making process of such
models often remain opaque, limiting their trustworthiness in clinical
contexts. This paper investigates an alternative approach based on Explainable
AI (XAI), a field that aims to improve the interpretability of DNNs by
providing different forms of explanations. Specifically, this works focuses on
concept-based models such as Concept Bottleneck Model (CBM) and Concept
Embedding Model (CEM) and how they can achieve performance comparable to
traditional deep learning methods, while offering a more transparent and
interpretable decision framework.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [56] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
*Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage*

Main category: cs.GR

TL;DR: 论文提出了一种轻量化的实时面部动画模型，通过混合知识蒸馏和伪标签技术解决数据不足问题，实现了3.4 MB的小型模型和81 ms的低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前语音驱动的3D面部动画模型依赖大型预训练语音编码器，导致模型过大且仅适用于离线推理，难以在游戏开发中实现实时应用。

Method: 采用混合知识蒸馏和伪标签技术，利用大型音频数据集和教师模型训练小型学生模型，仅包含卷积和全连接层，无需注意力机制或循环更新。

Result: 实验表明，模型内存占用降至3.4 MB，未来音频上下文需求降至81 ms，同时保持高质量动画效果。

Conclusion: 该方法为设备端实时推理提供了可行方案，推动了模型驱动的数字角色发展。

Abstract: The training of high-quality, robust machine learning models for
speech-driven 3D facial animation requires a large, diverse dataset of
high-quality audio-animation pairs. To overcome the lack of such a dataset,
recent work has introduced large pre-trained speech encoders that are robust to
variations in the input audio and, therefore, enable the facial animation model
to generalize across speakers, audio quality, and languages. However, the
resulting facial animation models are prohibitively large and lend themselves
only to offline inference on a dedicated machine. In this work, we explore
on-device, real-time facial animation models in the context of game
development. We overcome the lack of large datasets by using hybrid knowledge
distillation with pseudo-labeling. Given a large audio dataset, we employ a
high-performing teacher model to train very small student models. In contrast
to the pre-trained speech encoders, our student models only consist of
convolutional and fully-connected layers, removing the need for attention
context or recurrent updates. In our experiments, we demonstrate that we can
reduce the memory footprint to up to 3.4 MB and required future audio context
to up to 81 ms while maintaining high-quality animations. This paves the way
for on-device inference, an important step towards realistic, model-driven
digital characters.

</details>
