<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.CV](#cs.CV) [Total: 86]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.SD](#cs.SD) [Total: 9]
- [math.OC](#math.OC) [Total: 2]
- [hep-ex](#hep-ex) [Total: 1]
- [physics.data-an](#physics.data-an) [Total: 1]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.SC](#cs.SC) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.CR](#cs.CR) [Total: 6]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.IR](#cs.IR) [Total: 3]
- [stat.ML](#stat.ML) [Total: 4]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [eess.SP](#eess.SP) [Total: 2]
- [cs.SE](#cs.SE) [Total: 4]
- [eess.IV](#eess.IV) [Total: 8]
- [quant-ph](#quant-ph) [Total: 3]
- [cs.AR](#cs.AR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [astro-ph.GA](#astro-ph.GA) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 6]
- [cs.DL](#cs.DL) [Total: 1]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.CY](#cs.CY) [Total: 5]
- [q-bio.GN](#q-bio.GN) [Total: 2]
- [cs.GR](#cs.GR) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 探讨AI能否帮助人类与自然从支配关系转向相互依存，并通过案例研究展示AI在生态设计中的创新应用。


<details>
  <summary>Details</summary>
Motivation: 研究人类与自然关系的转变，探索AI在生态设计中的潜在作用，以促进可持续发展。

Method: 通过案例研究分析AI在数据、图像识别和生态修复中的应用，并结合原型设计（AI辅助水体修复）提出新方法。

Result: AI不仅扩展了创意方法，还重构了生态设计的理论与实践，展示了其在科学、艺术和环境管理中的潜力。

Conclusion: AI为可持续技术生态系统提供了研究路径，未来可进一步探索其在生态设计中的应用。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [2] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: MLLMs作为验证器在复杂任务中存在一致性偏差问题，提出Self-Grounded Verification（SGV）方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 扩展验证器在无明确成功标准领域的应用，解决MLLMs作为验证器时的局限性。

Method: 提出SGV方法，通过无条件与条件生成结合MLLMs的知识与推理能力。

Result: SGV使MLLM验证器准确率提升20%，任务完成率提升48%。

Conclusion: SGV有效解决了MLLMs的一致性偏差问题，显著提升了其在复杂任务中的验证能力。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [3] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种模块化设计的LLM代理框架，包含感知、记忆和推理组件，适用于多种游戏环境，无需领域特定工程。实验表明该框架显著提升性能，并揭示了不同模块的贡献模式。


<details>
  <summary>Details</summary>
Motivation: 通过模块化设计提升LLM代理在多样化游戏环境中的通用性和性能，避免领域特定工程。

Method: 设计包含感知、记忆和推理的模块化框架，并在经典和现代游戏套件中进行测试。

Result: 框架显著提升游戏性能，感知在视觉噪声环境中关键，记忆在长时谜题中主导。

Conclusion: 模块化设计有效推进通用代理的发展，游戏环境的多样性和熟悉性为验证提供了理想平台。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [4] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: ClarifAI结合案例推理和本体驱动方法，提升AI透明度和可解释性，适用于高风险决策场景。


<details>
  <summary>Details</summary>
Motivation: 满足AI应用中各利益相关方对解释性的复杂需求，提升AI系统的透明度和可信度。

Method: 结合案例推理（CBR）和本体驱动方法，设计理论框架和架构蓝图。

Result: ClarifAI能显著增强AI系统的可解释性，适用于多领域和高风险环境。

Conclusion: ClarifAI为AI系统的可解释性提供了新途径，有望在关键决策中广泛应用。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [5] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 论文提出DP-Bench基准和DPLM模型，通过DualReflect数据生成方法解决动态规划问题中LLM应用的挑战。


<details>
  <summary>Details</summary>
Motivation: 动态规划（DP）建模通常需要专家知识，LLMs可自动化此过程，但面临数据稀缺和随机性挑战。

Method: 引入DP-Bench基准和7B参数的DPLM模型，采用DualReflect合成数据生成方法结合前向和后向生成。

Result: DPLM性能媲美OpenAI o1和DeepSeek-R1，在难题上表现更优。

Conclusion: 后向生成在低数据下可靠，前向生成在规模下多样，两者结合效果最佳。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [6] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 综述探讨了基于群体智能（SI）的语义相似性文档搜索的最新进展，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 群体智能因其高效性被广泛应用于优化问题，本文旨在总结其在语义相似性文档搜索中的应用与发展。

Method: 通过综述文献，分析群体智能算法在文档搜索中的最新应用。

Result: 总结了群体智能在语义相似性文档搜索中的有效性及当前进展。

Conclusion: 群体智能在文档搜索领域具有潜力，未来研究可进一步优化算法并拓展应用场景。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [7] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 提出了一种利用GPU并行计算优化深度优先搜索（DFS）的方法，扩展了经典搜索算法如IDA*和BTS，并在实验中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: GPU技术的快速发展为经典搜索算法的优化提供了新机会，但目前很少有算法在搜索过程中充分利用GPU。

Method: 提出了一种成本限制的深度优先搜索（CB-DFS）方法，结合CPU和GPU的并行计算能力，扩展了IDA*和BTS算法。

Result: 在3x3魔方和4x4滑块拼图（STP）上验证了GPU批量计算在DFS中的高效性，并分析了超参数和硬件资源对性能的影响。

Conclusion: 该方法成功地将GPU并行计算引入DFS，保持了最优性保证，并在实验中表现出显著性能提升。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [8] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime是一个新型多智能体框架，通过动态反应式规划和执行解决传统静态框架的局限性，显著提升多智能体系统的适应性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统的规划和执行框架存在刚性执行、静态能力和低效通信等问题，限制了其在动态环境中的适应性和鲁棒性。

Method: Aime采用动态规划器、动态角色工厂和集中式进度管理模块，实现实时策略调整、按需角色生成和全局状态一致性。

Result: 在通用推理、软件工程和实时网络导航等任务中，Aime表现优于领域内最先进的专用智能体。

Conclusion: Aime为多智能体协作提供了更具弹性和高效性的基础框架。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [9] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 论文研究了基于光学流的强化学习无人机导航策略，发现其注意力模式与蜜蜂类似，专注于光学流的不连续区域和大流量区域。


<details>
  <summary>Details</summary>
Motivation: 生物系统（如蜜蜂）在有限感官和计算能力下仍能飞行和避障，启发研究如何利用光学流实现无人机导航。

Method: 训练强化学习代理仅使用光学流作为感官输入，在隧道中导航并避障，分析其注意力模式。

Result: 代理主要关注光学流的不连续区域和大流量区域，行为类似昆虫飞行，且策略在不同代理间一致。

Conclusion: 该策略可能适用于开发简单明确的无人机控制法则。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [10] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种拓扑增强的多智能体强化学习方法（TPE-MARL），用于优化混合交通中联网自动驾驶车辆（CAVs）的协作决策，通过压缩高维状态信息和减少搜索空间，有效平衡探索与利用。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习（MARL）中因联合状态-动作空间指数增长而加剧的探索-利用权衡问题，特别是在混合交通场景中。

Method: 构建动态交通流的游戏拓扑张量以压缩高维信息，并以QMIX为骨干算法，结合访问计数和智能体互信息，建立拓扑增强的MARL框架。

Result: 在不同交通密度和CAV渗透率下，TPE-MARL在交通效率、安全性、决策平滑性和任务完成度上表现优越，且决策合理性接近或超过人类驾驶员。

Conclusion: TPE-MARL成功平衡了探索与利用，适用于混合和完全自动驾驶场景，为MARL在复杂交通环境中的应用提供了有效解决方案。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [11] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出了一种新的在线近似POMDP求解器，通过深度采样未来历史并逐步更新策略，性能损失由采样误差的平均值而非最大值决定。


<details>
  <summary>Details</summary>
Motivation: 解决在线规划中采样稀疏性问题，提升动态环境下的决策性能。

Method: 提出Partially Observable Reference Policy Programming，结合深度采样和逐步策略更新。

Result: 理论证明性能损失受采样误差平均值限制，实验验证在动态环境中优于现有基准。

Conclusion: 该求解器在复杂动态环境中表现优异，具有理论和实际应用价值。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [12] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo框架利用LLMs自动设计高效且可解释的建筑能耗预测启发式方法，结合物理原理，实现高性能和透明性。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法精度不足，而高级模型缺乏透明性和泛化能力，忽视物理原理。

Method: BuildEvo通过进化过程引导LLMs构建和优化启发式方法，结合建筑特性和运营数据的物理洞察。

Result: 在基准测试中表现优异，泛化能力提升，预测逻辑透明。

Conclusion: BuildEvo推动了自动化设计稳健、基于物理的启发式方法，为复杂能源系统提供可信模型。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [13] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 论文提出了一种针对中国象棋（Xiangqi）的LLM训练框架，通过多阶段训练提升模型在空间战略推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在复杂棋盘游戏中的空间战略推理能力，填补现有研究的不足。

Method: 采用多阶段训练：1) 合法移动预测微调；2) 战略标注增强决策；3) 强化学习优化推理稳定性。

Result: Xiangqi-R1模型在合法移动和分析准确性上分别提升18%和22%，显著优于通用LLMs。

Conclusion: 研究为在空间复杂领域开发通用战略智能提供了可行路径。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance](https://arxiv.org/abs/2507.11582)
*Kazuyoshi Otsuka*

Main category: cs.CL

TL;DR: 研究将大语言模型（LLMs）作为“主观文学评论家”，探讨其在文学评估中的审美偏好和评价模式。通过分析十篇日本科幻短篇小说的翻译文本，发现LLMs在评价一致性和词汇使用上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在文学评估中的表现，揭示其是否具有类似人类批评家的个体评价特征。

Method: 将十篇日本科幻小说翻译成英文，由六种先进LLMs进行七次独立评估，使用主成分分析和聚类技术分析数据。

Result: 发现评价一致性差异显著（α值1.00至0.35），并识别出五种评价模式。不同模型的评价词汇也具独特性。

Conclusion: LLMs可能具有类似人类批评家的个体评价特征，而非中性基准工具。

Abstract: This study positions large language models (LLMs) as "subjective literary
critics" to explore aesthetic preferences and evaluation patterns in literary
assessment. Ten Japanese science fiction short stories were translated into
English and evaluated by six state-of-the-art LLMs across seven independent
sessions. Principal component analysis and clustering techniques revealed
significant variations in evaluation consistency ({\alpha} ranging from 1.00 to
0.35) and five distinct evaluation patterns. Additionally, evaluation variance
across stories differed by up to 4.5-fold, with TF-IDF analysis confirming
distinctive evaluation vocabularies for each model. Our seven-session
within-day protocol using an original Science Fiction corpus strategically
minimizes external biases, allowing us to observe implicit value systems shaped
by RLHF and their influence on literary judgment. These findings suggest that
LLMs may possess individual evaluation characteristics similar to human
critical schools, rather than functioning as neutral benchmarkers.

</details>


### [15] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: PolyChartQA是一个多语言图表问答基准，覆盖10种语言的22,606张图表和26,151个问答对，旨在解决现有图表理解基准的英语中心问题。


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准主要针对英语，限制了其全球适用性。PolyChartQA旨在填补这一空白，推动多语言图表理解的发展。

Method: 采用解耦管道，分离图表数据和渲染代码，通过翻译数据和重用代码生成多语言图表，并利用先进的LLM翻译和严格质量控制确保一致性。

Result: 实验显示，英语与其他语言（尤其是非拉丁文字的低资源语言）之间存在显著性能差距。

Conclusion: PolyChartQA为推进全球包容性视觉语言模型奠定了基础。

Abstract: Charts are a universally adopted medium for interpreting and communicating
data. However, existing chart understanding benchmarks are predominantly
English-centric, limiting their accessibility and applicability to global
audiences. In this paper, we present PolyChartQA, the first large-scale
multilingual chart question answering benchmark covering 22,606 charts and
26,151 question-answering pairs across 10 diverse languages. PolyChartQA is
built using a decoupled pipeline that separates chart data from rendering code,
allowing multilingual charts to be flexibly generated by simply translating the
data and reusing the code. We leverage state-of-the-art LLM-based translation
and enforce rigorous quality control in the pipeline to ensure the linguistic
and semantic consistency of the generated multilingual charts. PolyChartQA
facilitates systematic evaluation of multilingual chart understanding.
Experiments on both open- and closed-source large vision-language models reveal
a significant performance gap between English and other languages, especially
low-resource ones with non-Latin scripts. This benchmark lays a foundation for
advancing globally inclusive vision-language models.

</details>


### [16] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 论文介绍了MapIQ，一个包含14,706个问答对的基准数据集，涵盖三种地图类型和六个主题，用于评估多模态大语言模型（MLLMs）在地图视觉问答（Map-VQA）中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有Map-VQA研究主要局限于等值区域图（choropleth maps），覆盖的主题和任务有限，需要更全面的评估基准。

Method: 构建MapIQ数据集，包含三种地图类型和六个主题的问答对，评估多种MLLMs在六种视觉分析任务中的表现，并与人类基线对比。

Result: 实验揭示了MLLMs的鲁棒性和敏感性，以及其对内部地理知识的依赖，为提升Map-VQA性能提供了潜在方向。

Conclusion: MapIQ填补了Map-VQA研究的空白，为未来改进MLLMs在地图理解方面的能力提供了基础。

Abstract: Recent advancements in multimodal large language models (MLLMs) have driven
researchers to explore how well these models read data visualizations, e.g.,
bar charts, scatter plots. More recently, attention has shifted to visual
question answering with maps (Map-VQA). However, Map-VQA research has primarily
focused on choropleth maps, which cover only a limited range of thematic
categories and visual analytical tasks. To address these gaps, we introduce
MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three
map types: choropleth maps, cartograms, and proportional symbol maps spanning
topics from six distinct themes (e.g., housing, crime). We evaluate multiple
MLLMs using six visual analytical tasks, comparing their performance against
one another and a human baseline. An additional experiment examining the impact
of map design changes (e.g., altered color schemes, modified legend designs,
and removal of map elements) provides insights into the robustness and
sensitivity of MLLMs, their reliance on internal geographic knowledge, and
potential avenues for improving Map-VQA performance.

</details>


### [17] [Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation](https://arxiv.org/abs/2507.11634)
*Farideh Majidi,Ziaeddin Beheshtifard*

Main category: cs.CL

TL;DR: 研究探讨了在波斯语中使用少样本学习和增量学习方法进行跨语言情感分析，通过多语言预训练模型实现了高准确率。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在数据有限的波斯语中利用高资源语言先验知识进行情感分析的模型。

Method: 使用XLM-RoBERTa、mDeBERTa和DistilBERT三种预训练模型，通过少样本和增量学习方法在波斯语数据上进行微调。

Result: mDeBERTa和XLM-RoBERTa在波斯语情感分析中达到96%的准确率。

Conclusion: 结合少样本学习、增量学习和多语言预训练模型是有效的。

Abstract: This research examines cross-lingual sentiment analysis using few-shot
learning and incremental learning methods in Persian. The main objective is to
develop a model capable of performing sentiment analysis in Persian using
limited data, while getting prior knowledge from high-resource languages. To
achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and
DistilBERT) were employed, which were fine-tuned using few-shot and incremental
learning approaches on small samples of Persian data from diverse sources,
including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled
the models to learn from a broad range of contexts. Experimental results show
that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%
accuracy on Persian sentiment analysis. These findings highlight the
effectiveness of combining few-shot learning and incremental learning with
multilingual pre-trained models.

</details>


### [18] [Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](https://arxiv.org/abs/2507.11979)
*Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro*

Main category: cs.CL

TL;DR: 研究探讨了价值相似性对LLM代理间关系建立的影响，发现价值相似性高的代理间信任和亲密感更强。


<details>
  <summary>Details</summary>
Motivation: 探索价值相似性在人工社会中是否与人类社会中一样对关系建立有影响。

Method: 通过两个实验：初步实验评估LLM中价值的可控性；主实验生成具有特定价值的代理对并分析其对话后的信任和亲密感。

Result: 价值相似性高的代理对表现出更强的信任和亲密感。

Conclusion: LLM代理模拟可作为社会科学理论的有效测试平台，并有助于理解价值对关系建立的影响机制。

Abstract: Large language models (LLMs) have emerged as powerful tools for simulating
complex social phenomena using human-like agents with specific traits. In human
societies, value similarity is important for building trust and close
relationships; however, it remains unexplored whether this principle holds true
in artificial societies comprising LLM agents. Therefore, this study
investigates the influence of value similarity on relationship-building among
LLM agents through two experiments. First, in a preliminary experiment, we
evaluated the controllability of values in LLMs to identify the most effective
model and prompt design for controlling the values. Subsequently, in the main
experiment, we generated pairs of LLM agents imbued with specific values and
analyzed their mutual evaluations of trust and interpersonal closeness
following a dialogue. The experiments were conducted in English and Japanese to
investigate language dependence. The results confirmed that pairs of agents
with higher value similarity exhibited greater mutual trust and interpersonal
closeness. Our findings demonstrate that the LLM agent simulation serves as a
valid testbed for social science theories, contributes to elucidating the
mechanisms by which values influence relationship building, and provides a
foundation for inspiring new theories and insights into the social sciences.

</details>


### [19] [Partitioner Guided Modal Learning Framework](https://arxiv.org/abs/2507.11661)
*Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi*

Main category: cs.CL

TL;DR: PgM框架通过模态分割器分离单模态和配对模态特征，结合专用学习组件和解码器，实现多模态任务的灵活优化。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中，单模态和配对模态特征的学习需求不同，现有方法未能充分区分和优化这两类特征。

Method: 提出PgM框架，包含模态分割器、单模态学习器、配对模态学习器和解码器，支持特征分离和灵活调整。

Result: 实验证明PgM在四种多模态任务中有效，且具有迁移性；可视化展示了特征的分布和贡献。

Conclusion: PgM通过区分和优化单模态与配对模态特征，提升了多模态学习的性能和灵活性。

Abstract: Multimodal learning benefits from multiple modal information, and each
learned modal representations can be divided into uni-modal that can be learned
from uni-modal training and paired-modal features that can be learned from
cross-modal interaction. Building on this perspective, we propose a
partitioner-guided modal learning framework, PgM, which consists of the modal
partitioner, uni-modal learner, paired-modal learner, and uni-paired modal
decoder. Modal partitioner segments the learned modal representation into
uni-modal and paired-modal features. Modal learner incorporates two dedicated
components for uni-modal and paired-modal learning. Uni-paired modal decoder
reconstructs modal representation based on uni-modal and paired-modal features.
PgM offers three key benefits: 1) thorough learning of uni-modal and
paired-modal features, 2) flexible distribution adjustment for uni-modal and
paired-modal representations to suit diverse downstream tasks, and 3) different
learning rates across modalities and partitions. Extensive experiments
demonstrate the effectiveness of PgM across four multimodal tasks and further
highlight its transferability to existing models. Additionally, we visualize
the distribution of uni-modal and paired-modal features across modalities and
tasks, offering insights into their respective contributions.

</details>


### [20] [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](https://arxiv.org/abs/2507.11694)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas*

Main category: cs.CL

TL;DR: ExpliCIT-QA是一个多模态表格问答系统，通过模块化设计提供可解释的答案，包括表格理解、语言推理、代码生成、执行和自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 解决端到端表格问答系统中可解释性不足的问题，适用于金融和医疗等敏感领域。

Method: 采用模块化设计，包括多模态表格理解、语言推理、自动代码生成、代码执行和自然语言解释。

Result: 在TableVQA-Bench基准测试中表现优于现有基线，提高了可解释性和透明度。

Conclusion: ExpliCIT-QA填补了表格问答系统的可解释性空白，适用于需要审计结果的领域。

Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for
tabular question answering into a multimodal pipeline capable of handling
complex table images and providing explainable answers. ExpliCIT-QA follows a
modular design, consisting of: (1) Multimodal Table Understanding, which uses a
Chain-of-Thought approach to extract and transform content from table images;
(2) Language-based Reasoning, where a step-by-step explanation in natural
language is generated to solve the problem; (3) Automatic Code Generation,
where Python/Pandas scripts are created based on the reasoning steps, with
feedback for handling errors; (4) Code Execution to compute the final answer;
and (5) Natural Language Explanation that describes how the answer was
computed. The system is built for transparency and auditability: all
intermediate outputs, parsed tables, reasoning steps, generated code, and final
answers are available for inspection. This strategy works towards closing the
explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on
the TableVQA-Bench benchmark, comparing it with existing baselines. We
demonstrated improvements in interpretability and transparency, which open the
door for applications in sensitive domains like finance and healthcare where
auditing results are critical.

</details>


### [21] [CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks](https://arxiv.org/abs/2507.11742)
*Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher*

Main category: cs.CL

TL;DR: 论文提出了一种名为CRABS的方法，通过结合浅层语法分析和LLM，解决Python笔记本理解中的幻觉和长上下文问题，生成信息流图和执行依赖图。


<details>
  <summary>Details</summary>
Motivation: 由于数据科学和机器学习Python笔记本的依赖问题，重新执行笔记本不切实际，而现有LLM在理解复杂笔记本时存在幻觉和长上下文挑战。

Method: 采用CRABS策略，结合浅层语法分析（AST）和LLM的零样本学习，捕获笔记本的正确解释并解决剩余歧义。

Result: 在50个Kaggle笔记本上，LLM解决了98%的歧义，CRABS在信息流和执行依赖识别上分别达到98%和99%的F1分数。

Conclusion: CRABS方法有效解决了笔记本理解问题，结合语法分析和LLM显著提升了准确性和实用性。

Abstract: Recognizing the information flows and operations comprising data science and
machine learning Python notebooks is critical for evaluating, reusing, and
adapting notebooks for new tasks. Investigating a notebook via re-execution
often is impractical due to the challenges of resolving data and software
dependencies. While Large Language Models (LLMs) pre-trained on large codebases
have demonstrated effectiveness in understanding code without running it, we
observe that they fail to understand some realistic notebooks due to
hallucinations and long-context challenges. To address these issues, we propose
a notebook understanding task yielding an information flow graph and
corresponding cell execution dependency graph for a notebook, and demonstrate
the effectiveness of a pincer strategy that uses limited syntactic analysis to
assist full comprehension of the notebook using an LLM. Our Capture and Resolve
Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and
analysis of the abstract syntax tree (AST) to capture the correct
interpretation of a notebook between lower and upper estimates of the
inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via
cell-by-cell zero-shot learning, thereby identifying the true data inputs and
outputs of each cell. We evaluate and demonstrate the effectiveness of our
approach using an annotated dataset of 50 representative, highly up-voted
Kaggle notebooks that together represent 3454 actual cell inputs and outputs.
The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the
syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves
average F1 scores of 98% identifying cell-to-cell information flows and 99%
identifying transitive cell execution dependencies.

</details>


### [22] [AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles](https://arxiv.org/abs/2507.11764)
*Matteo Fasulo,Luca Babboni,Luca Tedeschini*

Main category: cs.CL

TL;DR: AI Wizards团队在CLEF 2025 CheckThat! Lab Task 1中，通过结合情感分数与句子表示，提升了基于Transformer的分类器性能，尤其在多语言和零样本设置下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决新闻文章中主观性检测的挑战，尤其是在多语言和零样本场景下的泛化能力。

Method: 使用mDeBERTaV3-base、ModernBERT-base和Llama3.2-1B模型，结合情感分数增强句子表示，并通过决策阈值校准解决类别不平衡问题。

Result: 情感特征显著提升了性能，尤其在主观F1分数上，团队在希腊语任务中排名第一（Macro F1 = 0.51）。

Conclusion: 情感特征与Transformer模型的结合在多语言主观性检测任务中具有显著优势。

Abstract: This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab
Task 1: Subjectivity Detection in News Articles, classifying sentences as
subjective/objective in monolingual, multilingual, and zero-shot settings.
Training/development datasets were provided for Arabic, German, English,
Italian, and Bulgarian; final evaluation included additional unseen languages
(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our
primary strategy enhanced transformer-based classifiers by integrating
sentiment scores, derived from an auxiliary model, with sentence
representations, aiming to improve upon standard fine-tuning. We explored this
sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base
(English), and Llama3.2-1B. To address class imbalance, prevalent across
languages, we employed decision threshold calibration optimized on the
development set. Our experiments show sentiment feature integration
significantly boosts performance, especially subjective F1 score. This
framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).

</details>


### [23] [Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models](https://arxiv.org/abs/2507.11809)
*Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss*

Main category: cs.CL

TL;DR: 本文通过可重复性研究探讨了大型语言模型（LLMs）如何处理事实与反事实信息的竞争，重点关注注意力头的作用。研究发现，注意力头通过通用的复制抑制而非选择性反事实抑制来促进事实输出，且其行为具有领域依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证和调和近期三项关于LLMs中事实与反事实信息竞争的研究结果，探讨注意力头的作用机制及其领域特异性。

Method: 采用机制解释工具，分析注意力头强度与事实输出比例的关系，评估关于注意力头抑制机制的竞争假设，并研究注意力模式的领域特异性。

Result: 研究发现，促进事实输出的注意力头通过通用复制抑制实现，而非选择性反事实抑制；同时，注意力头行为具有领域依赖性，较大模型表现出更专业和类别敏感的模式。

Conclusion: 结论表明，注意力头的作用机制和领域依赖性对理解LLMs如何处理信息竞争具有重要意义，为未来研究提供了新方向。

Abstract: This paper presents a reproducibility study examining how Large Language
Models (LLMs) manage competing factual and counterfactual information, focusing
on the role of attention heads in this process. We attempt to reproduce and
reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and
Pavlick and McDougall et al. that investigate the competition between
model-learned facts and contradictory context information through Mechanistic
Interpretability tools. Our study specifically examines the relationship
between attention head strength and factual output ratios, evaluates competing
hypotheses about attention heads' suppression mechanisms, and investigates the
domain specificity of these attention patterns. Our findings suggest that
attention heads promoting factual output do so via general copy suppression
rather than selective counterfactual suppression, as strengthening them can
also inhibit correct facts. Additionally, we show that attention head behavior
is domain-dependent, with larger models exhibiting more specialized and
category-sensitive patterns.

</details>


### [24] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
*Yash Ingle,Pruthwik Mishra*

Main category: cs.CL

TL;DR: 该论文发布了一个包含英语和22种印度官方语言的23万句子数据集，并开发了基于机器学习和深度学习的基线模型，用于语言识别任务。


<details>
  <summary>Details</summary>
Motivation: 语言识别是NLP中的关键预处理步骤，但在嘈杂、简短和代码混合的环境中，尤其是印度语言之间具有相似性时，任务更具挑战性。

Method: 论文创建了一个新数据集，并利用机器学习和深度学习的最新方法开发了基线模型。

Result: 基线模型在语言识别任务中表现与现有最先进模型相当。

Conclusion: 该数据集和模型为印度语言识别研究提供了有力支持。

Abstract: The language identification task is a crucial fundamental step in NLP. Often
it serves as a pre-processing step for widely used NLP applications such as
multilingual machine translation, information retrieval, question and
answering, and text summarization. The core challenge of language
identification lies in distinguishing languages in noisy, short, and code-mixed
environments. This becomes even harder in case of diverse Indian languages that
exhibit lexical and phonetic similarities, but have distinct differences. Many
Indian languages share the same script making the task even more challenging.
In this paper, we release a dataset of 230K sentences consisting of English and
all 22 official Indian languages labeled with their language identifiers where
data in most languages are newly created. We also develop and release robust
baseline models using state-of-the-art approaches in machine learning and deep
learning that can aid the research in this field. Our baseline models are
comparable to the state-of-the-art models for the language identification task.

</details>


### [25] [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
*Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 提出了一种新框架，通过多令牌预测加速自回归语言模型的推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型的顺序生成特性限制了推理速度和并行性，尤其是在生成后期方向明确时。

Method: 结合掩码输入、门控LoRA、轻量采样器、辅助训练损失和推测生成策略，实现多令牌预测。

Result: 代码和数学生成速度提升近5倍，通用聊天和知识任务提升约2.5倍，且质量无损失。

Conclusion: 新框架显著提升了自回归模型的推理效率，适用于多种任务且不影响生成质量。

Abstract: Autoregressive language models are constrained by their inherently sequential
nature, generating one token at a time. This paradigm limits inference speed
and parallelism, especially during later stages of generation when the
direction and semantics of text are relatively certain. In this work, we
propose a novel framework that leverages the inherent knowledge of vanilla
autoregressive language models about future tokens, combining techniques to
realize this potential and enable simultaneous prediction of multiple
subsequent tokens. Our approach introduces several key innovations: (1) a
masked-input formulation where multiple future tokens are jointly predicted
from a common prefix; (2) a gated LoRA formulation that preserves the original
LLM's functionality, while equipping it for multi-token prediction; (3) a
lightweight, learnable sampler module that generates coherent sequences from
the predicted future tokens; (4) a set of auxiliary training losses, including
a consistency loss, to enhance the coherence and accuracy of jointly generated
tokens; and (5) a speculative generation strategy that expands tokens
quadratically in the future while maintaining high fidelity. Our method
achieves significant speedups through supervised fine-tuning on pretrained
models. For example, it generates code and math nearly 5x faster, and improves
general chat and knowledge tasks by almost 2.5x. These gains come without any
loss in quality.

</details>


### [26] [Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition](https://arxiv.org/abs/2507.11862)
*Junhong Ye,Xu Yuan,Xinying Qiu*

Main category: cs.CL

TL;DR: 论文研究了跨领域模型迁移、多领域数据融合和样本高效学习在PII识别中的效果，发现法律领域数据对传记文本迁移效果好，而医疗领域数据迁移效果差。


<details>
  <summary>Details</summary>
Motivation: 探索PII识别的跨领域模型迁移、数据融合和样本高效学习方法，以提高自动化文本匿名化的准确性。

Method: 使用医疗（I2B2）、法律（TAB）和传记（Wikipedia）领域的标注语料库，评估模型在域内性能、跨领域迁移性、数据融合和少样本学习四个维度上的表现。

Result: 法律领域数据对传记文本迁移效果好，医疗领域数据迁移效果差；数据融合的效果因领域而异；在低专业化领域，仅需10%的训练数据即可实现高质量识别。

Conclusion: 跨领域迁移和数据融合的效果具有领域依赖性，样本高效学习在低专业化领域表现优异。

Abstract: Accurate recognition of personally identifiable information (PII) is central
to automated text anonymization. This paper investigates the effectiveness of
cross-domain model transfer, multi-domain data fusion, and sample-efficient
learning for PII recognition. Using annotated corpora from healthcare (I2B2),
legal (TAB), and biography (Wikipedia), we evaluate models across four
dimensions: in-domain performance, cross-domain transferability, fusion, and
few-shot learning. Results show legal-domain data transfers well to
biographical texts, while medical domains resist incoming transfer. Fusion
benefits are domain-specific, and high-quality recognition is achievable with
only 10% of training data in low-specialization domains.

</details>


### [27] [Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception](https://arxiv.org/abs/2507.12356)
*Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan*

Main category: cs.CL

TL;DR: 研究发现性别偏见在阿尔茨海默病（AD）语音感知中存在，男性语音更易被识别为AD，尤其是在中文语音中。声学分析显示男性语音的shimmer值与AD感知显著相关。


<details>
  <summary>Details</summary>
Motivation: 探讨性别偏见在AD语音感知中的影响，以及语言是否对AD感知有显著作用。

Method: 通过16名中文听众对中文和希腊语语音的感知实验，结合声学分析（如shimmer值和语音片段）。

Result: 男性语音更频繁被识别为AD，shimmer值与AD感知显著相关，语言对AD感知无显著影响。

Conclusion: 性别偏见在AD语音感知中起关键作用，需在AD检测模型中解决性别偏见，并进一步验证不同语言背景下的模型性能。

Abstract: Gender bias has been widely observed in speech perception tasks, influenced
by the fundamental voicing differences between genders. This study reveals a
gender bias in the perception of Alzheimer's Disease (AD) speech. In a
perception experiment involving 16 Chinese listeners evaluating both Chinese
and Greek speech, we identified that male speech was more frequently identified
as AD, with this bias being particularly pronounced in Chinese speech. Acoustic
analysis showed that shimmer values in male speech were significantly
associated with AD perception, while speech portion exhibited a significant
negative correlation with AD identification. Although language did not have a
significant impact on AD perception, our findings underscore the critical role
of gender bias in AD speech perception. This work highlights the necessity of
addressing gender bias when developing AD detection models and calls for
further research to validate model performance across different linguistic
contexts.

</details>


### [28] [COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction](https://arxiv.org/abs/2507.11867)
*Xiangyu Yang,Xinying Qiu*

Main category: cs.CL

TL;DR: COLA-GEC框架通过双向知识转移提升语法错误纠正（GEC）和语法可接受性判断（COLA）任务，在多语言基准测试中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: GEC和COLA任务共享语法知识但独立发展，通过双向知识转移可以提升两者性能。

Method: 1. 使用GEC数据集增强语法可接受性模型；2. 通过动态损失函数将语法可接受性信号整合到GEC模型训练中。

Result: 在多语言基准测试中达到最优性能，但仍存在标点错误纠正等挑战。

Conclusion: COLA-GEC框架有效提升任务性能，未来需进一步改进语法建模。

Abstract: Grammatical Error Correction (GEC) and grammatical acceptability judgment
(COLA) are core tasks in natural language processing, sharing foundational
grammatical knowledge yet typically evolving independently. This paper
introduces COLA-GEC, a novel bidirectional framework that enhances both tasks
through mutual knowledge transfer. First, we augment grammatical acceptability
models using GEC datasets, significantly improving their performance across
multiple languages. Second, we integrate grammatical acceptability signals into
GEC model training via a dynamic loss function, effectively guiding corrections
toward grammatically acceptable outputs. Our approach achieves state-of-the-art
results on several multilingual benchmarks. Comprehensive error analysis
highlights remaining challenges, particularly in punctuation error correction,
providing insights for future improvements in grammatical modeling.

</details>


### [29] [DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation](https://arxiv.org/abs/2507.11875)
*Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu*

Main category: cs.CL

TL;DR: DualReward是一种新颖的强化学习框架，用于自动生成完形填空测试的干扰项，通过双奖励结构和自适应缩放机制优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要依赖监督学习或静态生成模型，无法动态调整奖励信号，限制了干扰项生成的质量和多样性。

Method: 采用双奖励结构，区分人类创建的黄金标准干扰项和模型生成的候选干扰项，并动态调整奖励信号的强度。

Result: 在CLOTH-F和MCQ数据集上表现优于现有方法，尤其在跨域数据上提升显著（3.48-3.86% P@1）。

Conclusion: DualReward框架能有效平衡从可靠人类示例中学习和探索高质量干扰项，适用于自动化测试生成。

Abstract: This paper introduces DualReward, a novel reinforcement learning framework
for automatic distractor generation in cloze tests. Unlike conventional
approaches that rely primarily on supervised learning or static generative
models, our method employs a dual reward structure with adaptive scaling that
differentiates between human-created gold standard distractors and
model-generated candidates. The framework dynamically adjusts reward signal
intensity based on model performance and confidence. We evaluate our approach
on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,
demonstrating consistent improvements over state-of-the-art baselines.
Experimental results show that our adaptive reward scaling mechanism provides
modest but consistent benefits on homogeneous datasets (CLOTH-F) and more
substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data
(MCQ), suggesting its particular effectiveness for handling varied question
types and domains. Our work offers a flexible framework that effectively
balances learning from reliable human examples while exploring novel,
high-quality distractors for automated test generation.

</details>


### [30] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
*Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi*

Main category: cs.CL

TL;DR: LLMs内部对有害性的理解与拒绝行为是两个独立的概念，研究发现有害性方向与拒绝方向不同，可用于开发更稳健的安全机制。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否真正理解有害性，而不仅仅是机械地拒绝有害指令。

Method: 通过识别有害性方向和拒绝方向，分析LLMs内部机制，并开发Latent Guard作为安全应用。

Result: 有害性概念比拒绝行为更稳健，Latent Guard在检测不安全输入和减少过度拒绝方面表现优异。

Conclusion: LLMs对有害性的内部理解比拒绝行为更稳定，为AI安全研究提供了新视角。

Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand
harmfulness beyond just refusing? Prior work has shown that LLMs' refusal
behaviors can be mediated by a one-dimensional subspace, i.e., a refusal
direction. In this work, we identify a new dimension to analyze safety
mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a
separate concept from refusal. There exists a harmfulness direction that is
distinct from the refusal direction. As causal evidence, steering along the
harmfulness direction can lead LLMs to interpret harmless instructions as
harmful, but steering along the refusal direction tends to elicit refusal
responses directly without reversing the model's judgment on harmfulness.
Furthermore, using our identified harmfulness concept, we find that certain
jailbreak methods work by reducing the refusal signals without reversing the
model's internal belief of harmfulness. We also find that adversarially
finetuning models to accept harmful instructions has minimal impact on the
model's internal belief of harmfulness. These insights lead to a practical
safety application: The model's latent harmfulness representation can serve as
an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing
over-refusals that is robust to finetuning attacks. For instance, our Latent
Guard achieves performance comparable to or better than Llama Guard 3 8B, a
dedicated finetuned safeguard model, across different jailbreak methods. Our
findings suggest that LLMs' internal understanding of harmfulness is more
robust than their refusal decision to diverse input instructions, offering a
new perspective to study AI safety

</details>


### [31] [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models](https://arxiv.org/abs/2507.11882)
*Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 论文提出了一个多语言指令跟随基准Marco-Bench-MIF，覆盖30种语言，解决了现有数据集在语言和文化适应性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有指令跟随评估数据集多为英语或简单机器翻译，限制了多语言场景的适用性。

Method: 通过结合翻译与验证的混合流程，创建本地化多语言版本的IFEval。

Result: 发现高低资源语言间存在25-35%的准确率差距，模型规模影响性能45-60%，机器翻译数据低估准确率7-22%。

Conclusion: Marco-Bench-MIF揭示了多语言指令跟随的挑战，如关键词一致性和跨语言约束遵循。

Abstract: Instruction-following capability has become a major ability to be evaluated
for Large Language Models (LLMs). However, existing datasets, such as IFEval,
are either predominantly monolingual and centered on English or simply machine
translated to other languages, limiting their applicability in multilingual
contexts. In this paper, we present an carefully-curated extension of IFEval to
a localized multilingual version named Marco-Bench-MIF, covering 30 languages
with varying levels of localization. Our benchmark addresses linguistic
constraints (e.g., modifying capitalization requirements for Chinese) and
cultural references (e.g., substituting region-specific company names in
prompts) via a hybrid pipeline combining translation with verification. Through
comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)
25-35% accuracy gap between high/low-resource languages, (2) model scales
largely impact performance by 45-60% yet persists script-specific challenges,
and (3) machine-translated data underestimates accuracy by7-22% versus
localized data. Our analysis identifies challenges in multilingual instruction
following, including keyword consistency preservation and compositional
constraint adherence across languages. Our Marco-Bench-MIF is available at
https://github.com/AIDC-AI/Marco-Bench-MIF.

</details>


### [32] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 本文综述了深度学习在几何问题求解中的应用，包括任务总结、方法回顾、评估指标分析及未来挑战与方向讨论。


<details>
  <summary>Details</summary>
Motivation: 几何问题求解是数学推理的关键领域，涉及教育、人工智能数学能力评估和多模态能力评估等重要领域。深度学习技术的发展推动了该领域的研究热潮。

Method: 通过综述深度学习在几何问题求解中的应用，包括任务分类、方法回顾、评估指标分析和未来方向讨论。

Result: 提供了深度学习在几何问题求解中的全面参考，并创建了持续更新的论文列表。

Conclusion: 本文旨在促进几何问题求解领域的进一步发展，为研究者提供实用参考。

Abstract: Geometry problem solving is a key area of mathematical reasoning, which is
widely involved in many important fields such as education, mathematical
ability assessment of artificial intelligence, and multimodal ability
assessment. In recent years, the rapid development of deep learning technology,
especially the rise of multimodal large language models, has triggered a
widespread research boom. This paper provides a survey of the applications of
deep learning in geometry problem solving, including (i) a comprehensive
summary of the relevant tasks in geometry problem solving; (ii) a thorough
review of related deep learning methods; (iii) a detailed analysis of
evaluation metrics and methods; and (iv) a critical discussion of the current
challenges and future directions that can be explored. Our goal is to provide a
comprehensive and practical reference of deep learning for geometry problem
solving to promote further developments in this field. We create a continuously
updated list of papers on GitHub: https://github.com/majianz/dl4gps.

</details>


### [33] [BlockBPE: Parallel BPE Tokenization](https://arxiv.org/abs/2507.11941)
*Amos You*

Main category: cs.CL

TL;DR: BlockBPE是一种并行GPU实现的BPE算法，优化了高吞吐量的批量推理，比现有方法快2-2.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有CPU-bound的tokenization方法在GPU批量推理中效率低下，BlockBPE旨在解决这一问题。

Method: 通过消除Regex预分词步骤，实现高度并行化的token合并，复杂度降至O(nd)。

Result: 在高批量推理任务中，BlockBPE的吞吐量比tiktoken高2倍，比HuggingFace Tokenizers高2.5倍。

Conclusion: BlockBPE为GPU批量推理提供了高效的tokenization解决方案，尽管生成质量略有损失。

Abstract: Tokenization is a critical preprocessing step in large language model
pipelines, yet widely-used implementations remain CPU-bound and suboptimal for
batch inference workflows on GPU. We present BlockBPE, a parallel GPU
implementation of byte-pair encoding (BPE) that achieves near linear-time
complexity under realistic assumptions and is optimized for high-throughput,
batch inference. Unlike existing Rust-based tokenizers such as HuggingFace
Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex
pre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates the
Regex pre-tokenization which leads to small loss in generation quality, but
enables highly parallelized token merges within thread blocks, reducing overall
complexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,
BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over
HuggingFace Tokenizers.

</details>


### [34] [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://arxiv.org/abs/2507.11942)
*Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu*

Main category: cs.CL

TL;DR: 提出了一种动态注意力感知的任务无关提示压缩方法（DAC），通过结合熵和注意力信息，动态感知压缩过程中的熵变化，实现细粒度压缩。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖信息熵压缩词汇单元，但忽略了算法层面的注意力关键令牌和压缩过程中的熵变化。

Method: 提出DAC方法，动态整合熵和注意力信息，感知压缩中的熵变化。

Result: 在多个领域（如LongBench、GSM8K、BBH）的实验表明，DAC在不同任务和LLMs上均表现优异。

Conclusion: DAC通过动态整合熵和注意力信息，显著提升了任务无关提示压缩的效果。

Abstract: Task-agnostic prompt compression leverages the redundancy in natural language
to reduce computational overhead and enhance information density within
prompts, especially in long-context scenarios. Existing methods predominantly
rely on information entropy as the metric to compress lexical units, aiming to
achieve minimal information loss. However, these approaches overlook two
critical aspects: (i) the importance of attention-critical tokens at the
algorithmic level, and (ii) shifts in information entropy during the
compression process. Motivated by these challenges, we propose a dynamic
attention-aware approach for task-agnostic prompt compression (DAC). This
approach effectively integrates entropy and attention information, dynamically
sensing entropy shifts during compression to achieve fine-grained prompt
compression. Extensive experiments across various domains, including LongBench,
GSM8K, and BBH, show that DAC consistently yields robust and substantial
improvements across a diverse range of tasks and LLMs, offering compelling
evidence of its efficacy.

</details>


### [35] [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://arxiv.org/abs/2507.11953)
*Yi Zhao,Zuchao Li,Hai Zhao*

Main category: cs.CL

TL;DR: 论文提出IAM框架，通过利用不同规模LLMs间注意力矩阵的高相似性，实现加速注意力计算和减少KV缓存使用，实验显示预填充加速15%，KV缓存减少22.1%。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在长上下文场景下资源消耗大，现有优化方法主要依赖模型内部稀疏性，未利用外部信息。

Method: 提出IAM框架，分析注意力矩阵相似性、映射层选择和一致性，实现小规模与大规模LLMs间的注意力映射。

Result: IAM加速预填充15%，减少KV缓存22.1%，且性能无明显损失，适用于不同模型系列。

Conclusion: IAM是一种通用且与现有KV缓存优化方法正交的高效LLM优化工具。

Abstract: LLMs encounter significant challenges in resource consumption nowadays,
especially with long contexts. Despite extensive efforts dedicate to enhancing
inference efficiency, these methods primarily exploit internal sparsity within
the models, without leveraging external information for optimization. We
identify the high similarity of attention matrices across different-scale LLMs,
which offers a novel perspective for optimization. We first conduct a
comprehensive analysis of how to measure similarity, how to select mapping
Layers and whether mapping is consistency. Based on these insights, we
introduce the IAM framework, which achieves dual benefits of accelerated
attention computation and reduced KV cache usage by performing attention
mapping between small and large LLMs. Our experimental results demonstrate that
IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without
appreciably sacrificing performance. Experiments on different series of models
show the generalizability of IAM. Importantly, it is also orthogonal to many
existing KV cache optimization methods, making it a versatile addition to the
current toolkit for enhancing LLM efficiency.

</details>


### [36] [The benefits of query-based KGQA systems for complex and temporal questions in LLM era](https://arxiv.org/abs/2507.11954)
*Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 论文提出了一种基于多阶段查询的知识图谱问答框架，用于提升多跳和时间问题的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多跳推理和时间问题上表现不佳，而基于查询的知识图谱问答（KGQA）提供了一种模块化替代方案。

Method: 采用多阶段查询框架，结合新的实体链接和谓词匹配方法，利用CoT推理。

Result: 在多跳和时间问答数据集上表现出色，验证了框架的鲁棒性。

Conclusion: 基于查询的多阶段KGQA框架为小型语言模型在多跳和时间问答中提供了改进潜力。

Abstract: Large language models excel in question-answering (QA) yet still struggle
with multi-hop reasoning and temporal questions. Query-based knowledge graph QA
(KGQA) offers a modular alternative by generating executable queries instead of
direct answers. We explore multi-stage query-based framework for WikiData QA,
proposing multi-stage approach that enhances performance on challenging
multi-hop and temporal benchmarks. Through generalization and rejection
studies, we evaluate robustness across multi-hop and temporal QA datasets.
Additionally, we introduce a novel entity linking and predicate matching method
using CoT reasoning. Our results demonstrate the potential of query-based
multi-stage KGQA framework for improving multi-hop and temporal QA with small
language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System

</details>


### [37] [PoTPTQ: A Two-step Power-of-Two Post-training for LLMs](https://arxiv.org/abs/2507.11959)
*Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui*

Main category: cs.CL

TL;DR: 提出了一种新型的PoT量化框架，用于LLM权重，在极低精度格式下优于现有技术，并通过高效反量化加速推理。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs部署中因计算资源需求大而面临的挑战，尤其是GPU上PoT量化效果不佳的问题。

Method: 采用两步后训练算法：初始化量化尺度并利用最小校准集优化，提出更高效的反量化方法。

Result: 在2-和3-bit格式下超越现有整数量化技术，NVIDIA V100和RTX 4090上分别实现3.67倍和1.63倍加速。

Conclusion: 新型PoT量化框架在低精度和推理速度上显著优于现有方法，为LLM部署提供了高效解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing (NLP) tasks. However, their deployment is
challenging due to the substantial computational resources required.
Power-of-two (PoT) quantization is a general tool to counteract this
difficulty. Albeit previous works on PoT quantization can be efficiently
dequantized on CPUs using fixed-point addition, it showed less effectiveness on
GPUs. The reason is entanglement of the sign bit and sequential bit
manipulations needed for dequantization. We propose a novel POT quantization
framework for LLM weights that (i) outperforms state-of-the-art accuracy in
extremely low-precision number formats, and (ii) enables faster inference
through more efficient dequantization. To maintain the accuracy of the
quantized model, we introduce a two-step post-training algorithm: (i)
initialize the quantization scales with a robust starting point, and (ii)
refine these scales using a minimal calibration set. The performance of our PoT
post-training algorithm surpasses the current state-of-the-art in integer
quantization, particularly at low precisions such as 2- and 3-bit formats. Our
PoT quantization accelerates the dequantization step required for the floating
point inference and leads to $3.67\times$ speed up on a NVIDIA V100, and
$1.63\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.

</details>


### [38] [Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation](https://arxiv.org/abs/2507.11966)
*Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 提出了一种两阶段框架，用于在低资源语言对中保留毒性的翻译，以新加坡英语为例，通过人工验证和模型优化提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 在线交流中低资源语言和方言的翻译常忽略本地俚语和文化敏感内容，标准翻译系统无法有效处理毒性和混合语言。

Method: 1. 人工验证的少样本提示工程；2. 通过直接和回译优化模型-提示对。

Result: 定量人工评估证实了框架的有效性和效率。

Conclusion: 该框架不仅提升翻译质量，还支持低资源环境下的文化敏感内容审核，强调了保留社会语言细微差别的重要性。

Abstract: As online communication increasingly incorporates under-represented languages
and colloquial dialects, standard translation systems often fail to preserve
local slang, code-mixing, and culturally embedded markers of harmful speech.
Translating toxic content between low-resource language pairs poses additional
challenges due to scarce parallel data and safety filters that sanitize
offensive expressions. In this work, we propose a reproducible, two-stage
framework for toxicity-preserving translation, demonstrated on a code-mixed
Singlish safety corpus. First, we perform human-verified few-shot prompt
engineering: we iteratively curate and rank annotator-selected Singlish-target
examples to capture nuanced slang, tone, and toxicity. Second, we optimize
model-prompt pairs by benchmarking several large language models using semantic
similarity via direct and back-translation. Quantitative human evaluation
confirms the effectiveness and efficiency of our pipeline. Beyond improving
translation quality, our framework contributes to the safety of multicultural
LLMs by supporting culturally sensitive moderation and benchmarking in
low-resource contexts. By positioning Singlish as a testbed for inclusive NLP,
we underscore the importance of preserving sociolinguistic nuance in real-world
applications such as content moderation and regional platform governance.

</details>


### [39] [Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker](https://arxiv.org/abs/2507.11972)
*Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.CL

TL;DR: 研究比较了人类和大型语言模型（LLMs）在阅读理解中的差异，通过图结构分析发现LLMs在语言理解上具有高度一致性。


<details>
  <summary>Details</summary>
Motivation: 探索人类和LLMs在语言理解上的差异，以改进人机协作学习策略。

Method: 使用LLM将阅读材料中的单词分组为节点和边，构建基于语义的图结构，并通过眼动数据验证重要节点和边的注视分布。

Result: LLMs在图拓扑结构层面表现出高度一致的语言理解能力。

Conclusion: 研究结果支持了LLMs在语言理解中的潜力，为人机协作学习提供了新视角。

Abstract: Reading comprehension is a fundamental skill in human cognitive development.
With the advancement of Large Language Models (LLMs), there is a growing need
to compare how humans and LLMs understand language across different contexts
and apply this understanding to functional tasks such as inference, emotion
interpretation, and information retrieval. Our previous work used LLMs and
human biomarkers to study the reading comprehension process. The results showed
that the biomarkers corresponding to words with high and low relevance to the
inference target, as labeled by the LLMs, exhibited distinct patterns,
particularly when validated using eye-tracking data. However, focusing solely
on individual words limited the depth of understanding, which made the
conclusions somewhat simplistic despite their potential significance. This
study used an LLM-based AI agent to group words from a reading passage into
nodes and edges, forming a graph-based text representation based on semantic
meaning and question-oriented prompts. We then compare the distribution of eye
fixations on important nodes and edges. Our findings indicate that LLMs exhibit
high consistency in language understanding at the level of graph topological
structure. These results build on our previous findings and offer insights into
effective human-AI co-learning strategies.

</details>


### [40] [Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions](https://arxiv.org/abs/2507.11981)
*Lukas Ellinger,Miriam Anschütz,Georg Groh*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLM）在不同目标群体（如儿童或语言学习者）中简化定义对同形异义词解释质量的影响，发现简化会显著降低定义的完整性，增加误解风险。通过微调模型，可以显著提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 同形异义词的多义性在简化定义中容易被忽略，可能导致信息丢失和用户误解，因此需要研究简化对定义质量的影响。

Method: 使用两个多语言评估数据集，测试多个LLM模型（如DeepSeek v3、Llama 4等），结合LLM-as-Judge和人工标注，评估简化对定义完整性的影响。通过微调Llama 3.1 8B模型优化响应质量。

Result: 简化显著降低了定义的完整性，尤其是忽略了多义性。微调后的Llama 3.1 8B模型在所有提示类型中显著提升了同形异义词的响应质量。

Conclusion: 教育NLP需要在简单性和完整性之间取得平衡，以确保为所有学习者提供可靠且上下文感知的定义。

Abstract: Large Language Models (LLMs) can provide accurate word definitions and
explanations for any context. However, the scope of the definition changes for
different target groups, like children or language learners. This is especially
relevant for homonyms, words with multiple meanings, where oversimplification
might risk information loss by omitting key senses, potentially misleading
users who trust LLM outputs. We investigate how simplification impacts homonym
definition quality across three target groups: Normal, Simple, and ELI5. Using
two novel evaluation datasets spanning multiple languages, we test DeepSeek v3,
Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge
and human annotations. Our results show that simplification drastically
degrades definition completeness by neglecting polysemy, increasing the risk of
misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization
substantially improves homonym response quality across all prompt types. These
findings highlight the need to balance simplicity and completeness in
educational NLP to ensure reliable, context-aware definitions for all learners.

</details>


### [41] [Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis](https://arxiv.org/abs/2507.12004)
*Josip Jukić*

Main category: cs.CL

TL;DR: 论文提出通过表示平滑分析和优化技术提升神经语言模型的数据与参数效率，结合主动学习和参数高效微调，显著减少标注需求和计算资源。


<details>
  <summary>Details</summary>
Motivation: 解决神经语言模型在数据与参数效率上的挑战，提升模型的鲁棒性和泛化能力。

Method: 1. 分析语言表示的平滑性并提出基于Jacobian和Hessian矩阵的正则化策略；2. 结合主动学习与参数高效微调；3. 利用上下文学习增强弱监督技术。

Result: 实验表明，这些方法在性能、稳定性和效率上显著优于传统方法，尤其在低资源环境中表现突出。

Conclusion: 提出的方法有效提升了模型的效率与鲁棒性，减少了标注和计算需求，适用于动态数据环境。

Abstract: This thesis addresses challenges related to data and parameter efficiency in
neural language models, with a focus on representation analysis and the
introduction of new optimization techniques. The first part examines the
properties and dynamics of language representations within neural models,
emphasizing their significance in enhancing robustness and generalization. It
proposes innovative approaches based on representation smoothness, including
regularization strategies that utilize Jacobian and Hessian matrices to
stabilize training and mitigate sensitivity to input perturbations. The second
part focuses on methods to significantly enhance data and parameter efficiency
by integrating active learning strategies with parameter-efficient fine-tuning,
guided by insights from representation smoothness analysis. It presents
smoothness-informed early-stopping techniques designed to eliminate the need
for labeled validation sets and proposes innovative combinations of active
learning and parameter-efficient fine-tuning to reduce labeling efforts and
computational resources. Extensive experimental evaluations across various NLP
tasks demonstrate that these combined approaches substantially outperform
traditional methods in terms of performance, stability, and efficiency. The
third part explores weak supervision techniques enhanced by in-context learning
to effectively utilize unlabeled data, further reducing dependence on extensive
labeling. It shows that using in-context learning as a mechanism for weak
supervision enables models to better generalize from limited labeled data by
leveraging unlabeled examples more effectively during training. Comprehensive
empirical evaluations confirm significant gains in model accuracy,
adaptability, and robustness, especially in low-resource settings and dynamic
data environments.

</details>


### [42] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
*Anca Dinu,Andra-Maria Florescu,Alina Resceanu*

Main category: cs.CL

TL;DR: 论文介绍了一种通用的语言创造力测试，用于评估人类和大型语言模型（LLMs）在生成新词和短语方面的能力。测试结果显示，LLMs在所有评估标准上均优于人类。


<details>
  <summary>Details</summary>
Motivation: 研究旨在比较人类和LLMs在语言创造力方面的表现，特别是在新词生成和隐喻使用上的能力。

Method: 通过设计包含派生、复合和隐喻任务的语言创造力测试，对24名人类和24个LLMs进行评估，并使用OCSAI工具自动分析答案的原创性、精细度和灵活性。

Result: LLMs在所有评估标准上优于人类，并在八项任务中的六项中表现更好。人类更倾向于扩展性创造力（E-creativity），而LLMs则偏向固定性创造力（F-creativity）。

Conclusion: 研究表明，LLMs在语言创造力方面具有显著优势，但人类和LLMs在创造力类型上存在差异。

Abstract: The following paper introduces a general linguistic creativity test for
humans and Large Language Models (LLMs). The test consists of various tasks
aimed at assessing their ability to generate new original words and phrases
based on word formation processes (derivation and compounding) and on
metaphorical language use. We administered the test to 24 humans and to an
equal number of LLMs, and we automatically evaluated their answers using OCSAI
tool for three criteria: Originality, Elaboration, and Flexibility. The results
show that LLMs not only outperformed humans in all the assessed criteria, but
did better in six out of the eight test tasks. We then computed the uniqueness
of the individual answers, which showed some minor differences between humans
and LLMs. Finally, we performed a short manual analysis of the dataset, which
revealed that humans are more inclined towards E(extending)-creativity, while
LLMs favor F(ixed)-creativity.

</details>


### [43] [Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](https://arxiv.org/abs/2507.12059)
*Anthony G Cohn,Robert E Blackwell*

Main category: cs.CL

TL;DR: 研究28个大型语言模型（LLMs）在方向推理能力上的表现，发现即使是新的大型推理模型也无法在所有问题上可靠确定正确方向。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在方向推理任务中的能力，探索其局限性。

Method: 使用基于模板生成的基准测试，测试LLMs在不同场景下确定正确方向的能力。

Result: 即使是新的大型推理模型也无法在所有问题上可靠确定正确方向。

Conclusion: LLMs在方向推理任务中存在局限性，需要进一步改进。

Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason
about cardinal directions (CDs) using a benchmark generated from a set of
templates, extensively testing an LLM's ability to determine the correct CD
given a particular scenario. The templates allow for a number of degrees of
variation such as means of locomotion of the agent involved, and whether set in
the first, second or third person. Even the newer Large Reasoning Models are
unable to reliably determine the correct CD for all questions. This paper
summarises and extends earlier work presented at COSIT-24.

</details>


### [44] [StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features](https://arxiv.org/abs/2507.12064)
*Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak*

Main category: cs.CL

TL;DR: 论文提出了一种基于模块化风格测量管道的二进制AI检测方法，使用spaCy模型进行文本预处理和特征提取，并采用轻量梯度提升机作为分类器。


<details>
  <summary>Details</summary>
Motivation: 旨在通过非神经网络的、计算成本低但可解释的方法，有效检测机器生成的文本。

Method: 使用spaCy模型进行文本预处理和特征提取，结合轻量梯度提升机作为分类器，并探索多种参数选项以优化性能。

Result: 在超过50万机器生成文本的大规模语料库上训练分类器，取得了有效的结果。

Conclusion: 该方法在保持计算效率的同时，提供了可解释性，适用于大规模AI生成文本的检测。

Abstract: This submission to the binary AI detection task is based on a modular
stylometric pipeline, where: public spaCy models are used for text
preprocessing (including tokenisation, named entity recognition, dependency
parsing, part-of-speech tagging, and morphology annotation) and extracting
several thousand features (frequencies of n-grams of the above linguistic
annotations); light-gradient boosting machines are used as the classifier. We
collect a large corpus of more than 500 000 machine-generated texts for the
classifier's training. We explore several parameter options to increase the
classifier's capacity and take advantage of that training set. Our approach
follows the non-neural, computationally inexpensive but explainable approach
found effective previously.

</details>


### [45] [BOOKCOREF: Coreference Resolution at Book Scale](https://arxiv.org/abs/2507.12075)
*Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli*

Main category: cs.CL

TL;DR: 论文提出了一个自动标注长文本共指消解的流程，并创建了首个书籍规模的共指消解基准BOOKCOREF，实验表明该资源显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有共指消解基准主要针对短文本，缺乏对长文本（如书籍）的评估能力。

Method: 提出自动标注流程，创建BOOKCOREF基准，包含平均超过20万标记的文档。

Result: 实验验证了自动流程的鲁棒性，BOOKCOREF使系统性能提升高达20 CoNLL-F1分。

Conclusion: 当前模型在书籍规模下表现不佳，需进一步研究。数据与代码已开源。

Abstract: Coreference Resolution systems are typically evaluated on benchmarks
containing small- to medium-scale documents. When it comes to evaluating long
texts, however, existing benchmarks, such as LitBank, remain limited in length
and do not adequately assess system capabilities at the book scale, i.e., when
co-referring mentions span hundreds of thousands of tokens. To fill this gap,
we first put forward a novel automatic pipeline that produces high-quality
Coreference Resolution annotations on full narrative texts. Then, we adopt this
pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with
an average document length of more than 200,000 tokens. We carry out a series
of experiments showing the robustness of our automatic procedure and
demonstrating the value of our resource, which enables current long-document
coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full
books. Moreover, we report on the new challenges introduced by this
unprecedented book-scale setting, highlighting that current models fail to
deliver the same performance they achieve on smaller documents. We release our
data and code to encourage research and development of new book-scale
Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.

</details>


### [46] [Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning](https://arxiv.org/abs/2507.12079)
*Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed*

Main category: cs.CL

TL;DR: 该论文研究了结合苏格拉底法、思维链推理、简化游戏化和形成性反馈的MEGA方法对大学生数学学习的影响，发现MEGA方法比传统逐步法更有效。


<details>
  <summary>Details</summary>
Motivation: 许多学生在数学学习中遇到困难，导致他们回避数学相关学科，而传统的教学方法可能效果不佳。

Method: 采用组内设计，随机分配问题，比较MEGA方法和传统逐步法，使用GSM8K和MATH数据集评估两种大型语言模型（GPT4o和Claude 3.5 Sonnet）。

Result: 结果显示，MEGA方法在两种数据集上均被认为更有利于学习，尤其在难度较高的MATH数据集中表现更优（47.5% vs 26.67%）。

Conclusion: MEGA方法在解释复杂数学问题时更具优势，适合提升学生的数学学习效果。

Abstract: This paper presents an intervention study on the effects of the combined
methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)
simplified gamification and (4) formative feedback on university students'
Maths learning driven by large language models (LLMs). We call our approach
Mathematics Explanations through Games by AI LLMs (MEGA). Some students
struggle with Maths and as a result avoid Math-related discipline or subjects
despite the importance of Maths across many fields, including signal
processing. Oftentimes, students' Maths difficulties stem from suboptimal
pedagogy. We compared the MEGA method to the traditional step-by-step (CoT)
method to ascertain which is better by using a within-group design after
randomly assigning questions for the participants, who are university students.
Samples (n=60) were randomly drawn from each of the two test sets of the Grade
School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)
datasets, based on the error margin of 11%, the confidence level of 90%, and a
manageable number of samples for the student evaluators. These samples were
used to evaluate two capable LLMs at length (Generative Pretrained Transformer
4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for
capability. The results showed that students agree in more instances that the
MEGA method is experienced as better for learning for both datasets. It is even
much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH
dataset, indicating that MEGA is better at explaining difficult Maths problems.

</details>


### [47] [Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis](https://arxiv.org/abs/2507.12126)
*Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta*

Main category: cs.CL

TL;DR: 本文提出了一种评估框架，用于分析基于大语言模型（LLM）的文本增强技术，重点关注语义一致性和迭代生成中的语义漂移。实验表明，GPT-3.5 Turbo在语义保真度、多样性和生成效率方面表现最佳，并在实际应用中显著提升了主题建模的效果。


<details>
  <summary>Details</summary>
Motivation: 在低资源NLP场景中，现有文本增强技术缺乏语义一致性保障，导致冗余和不稳定。本文旨在解决这一问题。

Method: 提出两个评估组件：可扩展性分析（Scalability Analysis）和迭代增强与摘要细化（IASR），用于衡量语义一致性和语义漂移。

Result: GPT-3.5 Turbo表现最优，实际应用中主题建模的粒度提升400%，完全消除了主题重叠。

Conclusion: 提出的框架有效评估了LLM增强技术，为实际NLP任务提供了结构化解决方案。

Abstract: Text data augmentation is a widely used strategy for mitigating data sparsity
in natural language processing (NLP), particularly in low-resource settings
where limited samples hinder effective semantic modeling. While augmentation
can improve input diversity and downstream interpretability, existing
techniques often lack mechanisms to ensure semantic preservation during
large-scale or iterative generation, leading to redundancy and instability.
This work introduces a principled evaluation framework for large language model
(LLM) based text augmentation, comprising two components: (1) Scalability
Analysis, which measures semantic consistency as augmentation volume increases,
and (2) Iterative Augmentation with Summarization Refinement (IASR), which
evaluates semantic drift across recursive paraphrasing cycles. Empirical
evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the
best balance of semantic fidelity, diversity, and generation efficiency.
Applied to a real-world topic modeling task using BERTopic with GPT-enhanced
few-shot labeling, the proposed approach results in a 400% increase in topic
granularity and complete elimination of topic overlaps. These findings
validated the utility of the proposed frameworks for structured evaluation of
LLM-based augmentation in practical NLP pipelines.

</details>


### [48] [Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators](https://arxiv.org/abs/2507.12143)
*Pavel Šindelář,Ondřej Bojar*

Main category: cs.CL

TL;DR: ELOQUENT的Sensemaking任务旨在评估生成模型如何从给定文本中生成有意义的内容，分为问题生成、回答和评分三个步骤。2025年的实验涉及多语言材料，参与者有限，但揭示了任务中的挑战，如问题质量评估、回答限制和评分准确性。


<details>
  <summary>Details</summary>
Motivation: 通过Sensemaking任务，评估生成语言模型在理解文本和生成有意义内容方面的能力，为模型提供高标准的测试环境。

Method: 任务分为三步：(1)教师系统生成问题，(2)学生系统回答问题，(3)评估系统评分。实验使用多语言材料，并对比自动与人工评估。

Result: 发现任务中的挑战：问题生成质量难以评估，回答限制存在问题，评分系统易误判。

Conclusion: Sensemaking任务揭示了生成模型在复杂任务中的局限性，未来需改进评估策略和模型表现。

Abstract: ELOQUENT is a set of shared tasks that aims to create easily testable
high-level criteria for evaluating generative language models. Sensemaking is
one such shared task.
  In Sensemaking, we try to assess how well generative models ``make sense out
of a given text'' in three steps inspired by exams in a classroom setting: (1)
Teacher systems should prepare a set of questions, (2) Student systems should
answer these questions, and (3) Evaluator systems should score these answers,
all adhering rather strictly to a given set of input materials.
  We report on the 2025 edition of Sensemaking, where we had 7 sources of test
materials (fact-checking analyses of statements, textbooks, transcribed
recordings of a lecture, and educational videos) spanning English, German,
Ukrainian, and Czech languages.
  This year, 4 teams participated, providing us with 2 Teacher submissions, 2
Student submissions, and 2 Evaluator submissions. We added baselines for
Teacher and Student using commercial large language model systems. We devised a
fully automatic evaluation procedure, which we compare to a minimalistic manual
evaluation.
  We were able to make some interesting observations. For the first task, the
creation of questions, better evaluation strategies will still have to be
devised because it is difficult to discern the quality of the various candidate
question sets. In the second task, question answering, the LLMs examined
overall perform acceptably, but restricting their answers to the given input
texts remains problematic. In the third task, evaluation of question answers,
our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm
erroneously rate both garbled question-answer pairs and answers to mixed-up
questions as acceptable.

</details>


### [49] [Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production](https://arxiv.org/abs/2507.12208)
*Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren*

Main category: cs.CL

TL;DR: 论文提出了一种行为翻译风格空间（BTSS），用于描述行为翻译模式，并通过分析击键和注视数据揭示隐藏的认知过程。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解翻译行为背后的高阶认知和情感状态如何影响可观察的行为模式。

Method: 方法包括分析击键和注视数据，构建多层嵌入的BTSS，并基于此开发计算翻译代理。

Result: 结果表明BTSS能有效模拟翻译过程中的情感、自动行为和认知动态。

Conclusion: 结论是BTSS为理解翻译行为提供了新框架，并为计算翻译代理的开发奠定了基础。

Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that
describes possible behavioural translation patterns. The suggested BTSS is
organized as a hierarchical structure that entails various embedded processing
layers. We posit that observable translation behaviour - i.e., eye and finger
movements - is fundamental when executing the physical act of translation but
it is caused and shaped by higher-order cognitive processes and affective
translation states. We analyse records of keystrokes and gaze data as
indicators of the hidden mental processing structure and organize the
behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the
basis for a computational translation agent to simulate the temporal dynamics
of affect, automatized behaviour and cognition during human translation
production.

</details>


### [50] [Towards few-shot isolated word reading assessment](https://arxiv.org/abs/2507.12217)
*Reuben Smit,Retief Louw,Herman Kamper*

Main category: cs.CL

TL;DR: 探索了一种在低资源环境下无需自动语音识别（ASR）的孤立词阅读评估方法，通过对比儿童语音与少量成人参考模板，使用自监督学习（SSL）模型进行编码，但发现SSL表示在处理儿童数据时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 在低资源环境中，传统的自动语音识别（ASR）方法可能不适用，因此需要探索无需ASR的评估方法，尤其是针对儿童语音的阅读评估。

Method: 采用少量样本学习方法，将儿童语音输入与成人参考模板进行比较，使用SSL模型的中间层进行编码，并研究了离散化SSL特征和模板的重心平均等设计选项。

Result: 实验表明，该方法在成人语音上表现良好，但在儿童语音上效果显著下降，即使使用儿童模板。

Conclusion: 尽管SSL表示在低资源语音任务中表现优异，但在处理儿童数据的少量样本分类系统中存在明显局限性。

Abstract: We explore an ASR-free method for isolated word reading assessment in
low-resource settings. Our few-shot approach compares input child speech to a
small set of adult-provided reference templates. Inputs and templates are
encoded using intermediate layers from large self-supervised learned (SSL)
models. Using an Afrikaans child speech benchmark, we investigate design
options such as discretising SSL features and barycentre averaging of the
templates. Idealised experiments show reasonable performance for adults, but a
substantial drop for child speech input, even with child templates. Despite the
success of employing SSL representations in low-resource speech tasks, our work
highlights the limitations of SSL representations for processing child data
when used in a few-shot classification system.

</details>


### [51] [Improving Contextual ASR via Multi-grained Fusion with Large Language Models](https://arxiv.org/abs/2507.12252)
*Shilin Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 提出了一种多粒度融合方法，结合了词级和短语级融合的优势，利用LLM提升ASR对上下文相关关键词的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有的ASR模型在识别上下文相关关键词（如专有名词或用户特定实体）时表现不佳，现有方法（词级或短语级融合）各有局限。

Method: 提出了一种多粒度融合方法，结合了词级和短语级融合，并采用后融合策略将ASR的声学信息与LLM的上下文知识结合。

Result: 在中英文数据集上实现了关键词相关指标的最优性能，同时保持了非关键词文本的高准确率。

Conclusion: 多粒度融合框架中，词级和短语级组件相互补充，显著提升了性能。

Abstract: While end-to-end Automatic Speech Recognition (ASR) models have shown
impressive performance in transcribing general speech, they often struggle to
accurately recognize contextually relevant keywords, such as proper nouns or
user-specific entities.
  Previous approaches have explored leveraging keyword dictionaries in the
textual modality to improve keyword recognition, either through token-level
fusion that guides token-by-token generation or phrase-level fusion that
enables direct copying of keyword phrases.
  However, these methods operate at different granularities and have their own
limitations.
  In this paper, we propose a novel multi-grained fusion approach that jointly
leverages the strengths of both token-level and phrase-level fusion with Large
Language Models (LLMs).
  Our approach incorporates a late-fusion strategy that elegantly combines
ASR's acoustic information with LLM's rich contextual knowledge, balancing
fine-grained token precision with holistic phrase-level understanding.
  Experiments on Chinese and English datasets demonstrate that our approach
achieves state-of-the-art performance on keyword-related metrics while
preserving high accuracy on non-keyword text.
  Ablation studies further confirm that the token-level and phrase-level
components both contribute significantly to the performance gains,
complementing each other in our joint multi-grained framework.
  The code and models will be publicly available at https://github.com/.

</details>


### [52] [Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese](https://arxiv.org/abs/2507.12260)
*Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu*

Main category: cs.CL

TL;DR: 提出了一种名为T-index的定量测量方法，用于评估翻译文本的翻译特征（translationese），并通过对比微调的语言模型计算。实验表明T-index在跨域设置中具有普适性，并与人类判断一致。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译质量评估指标（如BLEU和COMET）未能涵盖翻译特征，因此需要一种新的定量测量方法。

Method: 使用两个对比微调的语言模型（0.5B参数）计算T-index，并通过合成数据和真实翻译数据验证其普适性和有效性。

Result: T-index能够有效捕捉翻译特征，并与人类标注的翻译特征程度显著相关（Pearson's r = 0.568）。

Conclusion: T-index是一种稳健且高效的翻译特征测量方法，可作为现有机器翻译质量评估指标的补充。

Abstract: In this paper, we propose the first quantitative measure for translationese
-- the translationese-index (T-index) for graded and generalizable measurement
of translationese, computed from the likelihood ratios of two contrastively
fine-tuned language models (LMs). We use a synthesized dataset and a dataset
with translations in the wild to evaluate T-index's generalizability in
cross-domain settings and its validity against human judgments. Our results
show that T-index is both robust and efficient. T-index scored by two 0.5B LMs
fine-tuned on only 1-5k pairs of synthetic data can well capture translationese
in the wild. We find that the relative differences in T-indices between
translations can well predict pairwise translationese annotations obtained from
human annotators; and the absolute values of T-indices correlate well with
human ratings of degrees of translationese (Pearson's $r = 0.568$).
Additionally, the correlation between T-index and existing machine translation
(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting
that T-index is not covered by these metrics and can serve as a complementary
metric in MT QE.

</details>


### [53] [Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](https://arxiv.org/abs/2507.12261)
*Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer*

Main category: cs.CL

TL;DR: Infherno是一个基于LLM代理、代码执行和医学术语数据库的端到端框架，用于将自由形式的临床笔记转换为结构化FHIR资源，解决了现有方法的泛化性和结构一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如模块化规则系统或指令调优的LLM）在泛化性和结构一致性上表现不佳，需要一种更高效的解决方案。

Method: 采用LLM代理、代码执行和医学术语数据库工具，构建端到端框架Infherno，支持自定义和合成数据的前端，以及本地和专有模型。

Result: Infherno在预测FHIR资源时表现优于人类基线，并符合FHIR文档模式。

Conclusion: Infherno为临床数据集成和跨机构互操作性提供了高效解决方案。

Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard
has established itself as a desirable format for interoperability between
complex health data. Previous attempts at automating the translation from
free-form clinical notes into structured FHIR resources rely on modular,
rule-based systems or LLMs with instruction tuning and constrained decoding.
Since they frequently suffer from limited generalizability and structural
inconformity, we propose an end-to-end framework powered by LLM agents, code
execution, and healthcare terminology database tools to address these issues.
Our solution, called Infherno, is designed to adhere to the FHIR document
schema and competes well with a human baseline in predicting FHIR resources
from unstructured text. The implementation features a front end for custom and
synthetic data and both local and proprietary models, supporting clinical data
integration processes and interoperability across institutions.

</details>


### [54] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 该论文提出了一个文本异常检测的基准测试工具包，通过多种预训练语言模型的嵌入和多领域数据集，系统评估了嵌入质量对异常检测效果的影响，并开源了工具包。


<details>
  <summary>Details</summary>
Motivation: 文本异常检测在NLP中至关重要，但缺乏标准化的评估基准，限制了方法的比较和创新。

Method: 利用多种预训练语言模型的嵌入和多领域数据集，结合多种评估指标（如AUROC、AUPRC），系统评估嵌入质量对异常检测的影响。

Result: 实验表明，嵌入质量对异常检测效果至关重要，深度学习模型在LLM嵌入下并未优于传统浅层算法（如KNN、Isolation Forest）。

Conclusion: 开源基准工具包为未来研究提供了基础，揭示了嵌入质量的关键作用，并提出了高效的模型评估策略。

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [55] [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](https://arxiv.org/abs/2507.12308)
*Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan*

Main category: cs.CL

TL;DR: 该研究评估了现有代码LLMs在VHDL代码生成和摘要任务中的表现，发现其性能不足，并提出了一种名为Chain-of-Descriptions (CoDes)的新方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在通用代码任务中表现优异，但在硬件描述语言（如VHDL）中的研究和优化不足，因此需要评估和改进LLMs在此领域的适用性。

Method: 研究使用VHDL-Eval和VHDL-Xform两个数据集评估LLMs的性能，并提出CoDes方法，通过生成中间描述步骤来增强LLMs的输入提示。

Result: 实验表明，CoDes方法在多个指标上显著优于标准提示策略，提升了VHDL代码生成和摘要的质量。

Conclusion: CoDes不仅解决了LLMs在VHDL任务中的性能问题，还为未来研究提供了框架。

Abstract: Large Language Models (LLMs) have become widely used across diverse NLP tasks
and domains, demonstrating their adaptability and effectiveness. In the realm
of Electronic Design Automation (EDA), LLMs show promise for tasks like
Register-Transfer Level (RTL) code generation and summarization. However,
despite the proliferation of LLMs for general code-related tasks, there's a
dearth of research focused on evaluating and refining these models for hardware
description languages (HDLs), notably VHDL. In this study, we evaluate the
performance of existing code LLMs for VHDL code generation and summarization
using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,
an in-house dataset, aims to gauge LLMs' understanding of functionally
equivalent code. Our findings reveal consistent underperformance of these
models across different metrics, underscoring a significant gap in their
suitability for this domain. To address this challenge, we propose
Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of
LLMs for VHDL code generation and summarization tasks. CoDes involves
generating a series of intermediate descriptive steps based on: (i) the problem
statement for code generation, and (ii) the VHDL code for summarization. These
steps are then integrated with the original input prompt (problem statement or
code) and provided as input to the LLMs to generate the final output. Our
experiments demonstrate that the CoDes approach significantly surpasses the
standard prompting strategy across various metrics on both datasets. This
method not only improves the quality of VHDL code generation and summarization
but also serves as a framework for future research aimed at enhancing code LLMs
for VHDL.

</details>


### [56] [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](https://arxiv.org/abs/2507.12370)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CL

TL;DR: 论文提出了一种多智能体辩论框架，用于提升大语言模型（LLMs）在检测和解决用户请求模糊性方面的能力，实验显示该框架显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理用户请求时存在模糊性问题，需要一种方法来增强其检测和解决能力。

Method: 采用多智能体辩论框架，结合三种LLM架构（Llama3-8B、Gemma2-9B和Mistral-7B变体）和多样化模糊性数据集。

Result: 辩论框架显著提升了Llama3-8B和Mistral-7B的性能，其中Mistral-7B主导的辩论成功率高达76.7%，尤其在复杂模糊性和高效共识方面表现突出。

Conclusion: 多智能体辩论框架是增强LLM能力的有效方法，为开发更鲁棒和自适应的语言理解系统提供了重要启示。

Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in
understanding and generating human language, contributing to more natural
interactions with complex systems. However, they face challenges such as
ambiguity in user requests processed by LLMs. To address these challenges, this
paper introduces and evaluates a multi-agent debate framework designed to
enhance detection and resolution capabilities beyond single models. The
framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and
Mistral-7B variants) and a dataset with diverse ambiguities. The debate
framework markedly enhanced the performance of Llama3-8B and Mistral-7B
variants over their individual baselines, with Mistral-7B-led debates achieving
a notable 76.7% success rate and proving particularly effective for complex
ambiguities and efficient consensus. While acknowledging varying model
responses to collaborative strategies, these findings underscore the debate
framework's value as a targeted method for augmenting LLM capabilities. This
work offers important insights for developing more robust and adaptive language
understanding systems by showing how structured debates can lead to improved
clarity in interactive systems.

</details>


### [57] [Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics](https://arxiv.org/abs/2507.12372)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh*

Main category: cs.CL

TL;DR: 该论文探讨了具备网页浏览能力的大型语言模型（LLMs）能否通过用户名推断社交媒体用户的 demographics，并揭示了潜在的偏见和风险。


<details>
  <summary>Details</summary>
Motivation: 传统LLMs依赖静态数据，而新功能使其能实时获取网络信息。研究填补了LLMs直接分析社交媒体数据的空白。

Method: 使用48个X（Twitter）账户的合成数据集和1,384名国际参与者的调查数据，评估LLMs预测用户 demographics 的能力。

Result: LLMs能合理准确地预测用户 demographics，但可能引入性别和政治偏见，尤其对低活跃账户。

Conclusion: 该能力对计算社会科学有益，但也存在滥用风险，建议限制公开访问，保留研究用途的受控访问。

Abstract: Large language models (LLMs) have traditionally relied on static training
data, limiting their knowledge to fixed snapshots. Recent advancements,
however, have equipped LLMs with web browsing capabilities, enabling real time
information retrieval and multi step reasoning over live web content. While
prior studies have demonstrated LLMs ability to access and analyze websites,
their capacity to directly retrieve and analyze social media data remains
unexplored. Here, we evaluate whether web browsing LLMs can infer demographic
attributes of social media users given only their usernames. Using a synthetic
dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international
participants, we show that these models can access social media content and
predict user demographics with reasonable accuracy. Analysis of the synthetic
dataset further reveals how LLMs parse and interpret social media profiles,
which may introduce gender and political biases against accounts with minimal
activity. While this capability holds promise for computational social science
in the post API era, it also raises risks of misuse particularly in information
operations and targeted advertising underscoring the need for safeguards. We
recommend that LLM providers restrict this capability in public facing
applications, while preserving controlled access for verified research
purposes.

</details>


### [58] [Probing for Arithmetic Errors in Language Models](https://arxiv.org/abs/2507.12379)
*Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 研究探讨语言模型内部激活是否可用于检测算术错误，通过简单探针解码隐藏状态，训练轻量级错误检测器，并扩展至复杂任务，实现选择性重新提示以提高准确性。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型内部激活是否能有效检测算术错误，为轻量级模型自我修正提供可行路径。

Method: 从3位数加法开始，训练探针解码隐藏状态；构建错误检测器；扩展至结构化思维链任务；利用探针指导选择性重新提示。

Result: 探针能准确解码模型预测和正确答案；错误检测器准确率超90%；探针在复杂任务中表现一致；选择性重新提示提高任务准确性。

Conclusion: 算术错误可从内部激活中预测，简单探针为模型自我修正提供可行方案。

Abstract: We investigate whether internal activations in language models can be used to
detect arithmetic errors. Starting with a controlled setting of 3-digit
addition, we show that simple probes can accurately decode both the model's
predicted output and the correct answer from hidden states, regardless of
whether the model's output is correct. Building on this, we train lightweight
error detectors that predict model correctness with over 90% accuracy. We then
extend our analysis to structured chain-of-thought traces on addition-only
GSM8K problems and find that probes trained on simple arithmetic generalize
well to this more complex setting, revealing consistent internal
representations. Finally, we demonstrate that these probes can guide selective
re-prompting of erroneous reasoning steps, improving task accuracy with minimal
disruption to correct outputs. Our findings suggest that arithmetic errors can
be anticipated from internal activations alone, and that simple probes offer a
viable path toward lightweight model self-correction.

</details>


### [59] [Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](https://arxiv.org/abs/2507.12425)
*Chandana Cheerla*

Main category: cs.CL

TL;DR: 提出了一种改进的RAG框架，结合混合检索策略和元数据过滤，显著提升了企业数据的检索和生成效果。


<details>
  <summary>Details</summary>
Motivation: 企业依赖专有数据决策，但现有LLM和RAG框架在处理结构化数据时存在局限性。

Method: 结合密集嵌入和BM25检索，利用SpaCy NER和交叉编码器重排序，保留表格结构，优化检索效率。

Result: 实验显示Precision@5提升15%，Recall@5提升13%，定性评估得分显著提高。

Conclusion: 框架有效提升企业任务响应质量，未来将扩展至多模态数据和基于代理的检索。

Abstract: Organizations increasingly rely on proprietary enterprise data, including HR
records, structured reports, and tabular documents, for critical
decision-making. While Large Language Models (LLMs) have strong generative
capabilities, they are limited by static pretraining, short context windows,
and challenges in processing heterogeneous data formats. Conventional
Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but
often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval
strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by
metadata-aware filtering with SpaCy NER and cross-encoder reranking. The
framework applies semantic chunking to maintain textual coherence and retains
tabular data structures to preserve row-column integrity. Quantized indexing
optimizes retrieval efficiency, while human-in-the-loop feedback and
conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5
increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),
and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative
evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness
(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.
These results demonstrate the framework's effectiveness in delivering accurate,
comprehensive, and contextually relevant responses for enterprise tasks. Future
work includes extending to multimodal data and integrating agent-based
retrieval. The source code will be released at
https://github.com/CheerlaChandana/Enterprise-Chatbot

</details>


### [60] [Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models](https://arxiv.org/abs/2507.12428)
*Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CL

TL;DR: 研究发现，通过线性探针分析CoT激活可以更准确地预测最终响应的安全性，优于基于文本的方法。


<details>
  <summary>Details</summary>
Motivation: 探究是否可以利用CoT预测最终响应的不安全性，以减少对齐风险。

Method: 评估多种监测方法，包括人类、大语言模型和文本分类器，比较基于CoT文本和激活的方法。

Result: 线性探针在CoT激活上的表现显著优于文本方法，且能在推理完成前做出准确预测。

Conclusion: 轻量级探针可用于实时安全监测和早期干预，适用于不同模型和基准。

Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs)
before producing a final response, which improves performance but introduces
additional alignment risks, with harmful content often appearing in both the
CoTs and the final outputs. In this work, we investigate if we can use CoTs to
predict final response misalignment. We evaluate a range of monitoring
approaches, including humans, highly-capable large language models, and text
classifiers, using either CoT text or activations. First, we find that a simple
linear probe trained on CoT activations can significantly outperform all
text-based methods in predicting whether a final response will be safe or
unsafe. CoT texts are often unfaithful and can mislead humans and classifiers,
while model latents (i.e., CoT activations) offer a more reliable predictive
signal. Second, the probe makes accurate predictions before reasoning
completes, achieving strong performance even when applied to early CoT
segments. These findings generalize across model sizes, families, and safety
benchmarks, suggesting that lightweight probes could enable real-time safety
monitoring and early intervention during generation.

</details>


### [61] [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://arxiv.org/abs/2507.12451)
*Suman Adhya,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: 论文提出了一种名为S2WTM的新方法，通过使用球面切片Wasserstein距离来改进变分自编码器在主题建模中的性能，避免了后验崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于变分自编码器的神经主题模型（VAE-NTMs）在建模高维文本数据时，常因后验崩溃导致潜在表示失效。

Method: S2WTM采用单位超球面上的先验分布，并利用球面切片Wasserstein距离对齐后验分布与先验。

Result: 实验表明，S2WTM在生成更连贯和多样化主题的同时，提升了下游任务的性能。

Conclusion: S2WTM通过改进潜在空间的结构建模，显著提升了主题建模的效果。

Abstract: Modeling latent representations in a hyperspherical space has proven
effective for capturing directional similarities in high-dimensional text data,
benefiting topic modeling. Variational autoencoder-based neural topic models
(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical
structure. However, VAE-NTMs often suffer from posterior collapse, where the KL
divergence term in the objective function highly diminishes, leading to
ineffective latent representations. To mitigate this issue while modeling
hyperspherical structure in the latent space, we propose the Spherical Sliced
Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior
distribution supported on the unit hypersphere and leverages the Spherical
Sliced-Wasserstein distance to align the aggregated posterior distribution with
the prior. Experimental results demonstrate that S2WTM outperforms
state-of-the-art topic models, generating more coherent and diverse topics
while improving performance on downstream tasks.

</details>


### [62] [Language Models Improve When Pretraining Data Matches Target Tasks](https://arxiv.org/abs/2507.12466)
*David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan*

Main category: cs.CL

TL;DR: 论文提出了一种名为BETR的显式优化数据选择方法，通过将预训练文档与基准训练示例对齐，显著提升了模型性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索显式优化数据选择方法的效果，以解决实践中常见的隐式目标优化问题。

Method: 提出BETR方法，通过嵌入基准示例和预训练文档到共享空间，基于相似性评分选择数据，并训练轻量级分类器预测全语料库的分数。

Result: BETR在10项任务中的9项上表现优于基线，计算效率提升2.1倍，且适用于不同规模的模型。

Conclusion: 研究结果表明，显式匹配预训练数据与目标任务能精确塑造模型能力，且数据选择策略需根据模型规模调整。

Abstract: Every data selection method inherently has a target. In practice, these
targets often emerge implicitly through benchmark-driven iteration: researchers
develop selection strategies, train models, measure benchmark performance, then
refine accordingly. This raises a natural question: what happens when we make
this optimization explicit? To explore this, we propose benchmark-targeted
ranking (BETR), a simple method that selects pretraining documents based on
similarity to benchmark training examples. BETR embeds benchmark examples and a
sample of pretraining documents in a shared space, scores this sample by
similarity to benchmarks, then trains a lightweight classifier to predict these
scores for the full corpus. We compare data selection methods by training over
500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to
them. From this, we find that simply aligning pretraining data to evaluation
benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline
(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks
across all scales. BETR also generalizes well: when targeting a diverse set of
benchmarks disjoint from our evaluation suite, it still matches or outperforms
baselines. Our scaling analysis further reveals a clear trend: larger models
require less aggressive filtering. Overall, our findings show that directly
matching pretraining data to target tasks precisely shapes model capabilities
and highlight that optimal selection strategies must adapt to model scale.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [63] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种硬件友好的优化框架，用于解决可变形注意力变换器（DAT）在硬件部署中的内存访问问题，通过神经架构搜索（NAS）和新的切片策略，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: DAT在计算机视觉任务中表现优异，但其数据依赖的采样机制导致不规则内存访问模式，影响硬件部署效率。现有方法要么硬件开销高，要么牺牲模型精度。

Method: 提出基于NAS的方法和切片策略，自动划分输入特征为均匀块以避免内存冲突；设计FPGA验证系统测试性能。

Result: 在ImageNet-1K上的实验显示，框架仅导致0.2%的精度下降；FPGA实验显示DRAM访问次数减少至现有方法的18%。

Conclusion: 该框架在保持精度的同时显著优化了硬件效率，适用于边缘设备部署。

Abstract: Deformable Attention Transformers (DAT) have shown remarkable performance in
computer vision tasks by adaptively focusing on informative image regions.
However, their data-dependent sampling mechanism introduces irregular memory
access patterns, posing significant challenges for efficient hardware
deployment. Existing acceleration methods either incur high hardware overhead
or compromise model accuracy. To address these issues, this paper proposes a
hardware-friendly optimization framework for DAT. First, a neural architecture
search (NAS)-based method with a new slicing strategy is proposed to
automatically divide the input feature into uniform patches during the
inference process, avoiding memory conflicts without modifying model
architecture. The method explores the optimal slice configuration by jointly
optimizing hardware cost and inference accuracy. Secondly, an FPGA-based
verification system is designed to test the performance of this framework on
edge-side hardware. Algorithm experiments on the ImageNet-1K dataset
demonstrate that our hardware-friendly framework can maintain have only 0.2%
accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA
show the proposed method reduces DRAM access times to 18% compared with
existing DAT acceleration methods.

</details>


### [64] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为DDCN的新方法，通过动态可变形卷积网络解决交通预测中的异质性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉交通数据的时空异质性和可扩展性方面存在不足，尤其是GNN需要预定义邻接矩阵且难以处理大规模数据。

Method: DDCN采用动态可变形滤波器，分解为编码器-解码器结构，结合空间和时空注意力模块，强调重要特征。

Result: 在四个真实数据集上的实验表明，DDCN具有竞争性的性能。

Conclusion: DDCN展示了基于CNN的方法在时空交通预测中的潜力和有效性。

Abstract: Spatio-temporal traffic prediction plays a key role in intelligent
transportation systems by enabling accurate prediction in complex urban areas.
Although not only accuracy but also efficiency for scalability is important,
some previous methods struggle to capture heterogeneity such as varying traffic
patterns across regions and time periods. Moreover, Graph Neural Networks
(GNNs), which are the mainstream of traffic prediction, not only require
predefined adjacency matrix, but also limit scalability to large-scale data
containing many nodes due to their inherent complexity. To overcome these
limitations, we propose Deformable Dynamic Convolution Network (DDCN) for
accurate yet efficient traffic prediction. Traditional Convolutional Neural
Networks (CNNs) are limited in modeling non-Euclidean spatial structures and
spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically
applying deformable filters based on offset. Specifically, DDCN decomposes
transformer-style CNN to encoder-decoder structure, and applies proposed
approaches to the spatial and spatio-temporal attention blocks of the encoder
to emphasize important features. The decoder, composed of feed-forward module,
complements the output of the encoder. This novel structure make DDCN can
perform accurate yet efficient traffic prediction. In comprehensive experiments
on four real-world datasets, DDCN achieves competitive performance, emphasizing
the potential and effectiveness of CNN-based approaches for spatio-temporal
traffic prediction.

</details>


### [65] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: 提出Inversion-DPO，一种无需奖励模型的新型扩散模型对齐框架，通过DDIM反演优化直接偏好，提升训练效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型对齐方法计算开销大且可能影响模型精度，需改进。

Method: 利用DDIM反演将直接偏好优化（DPO）应用于扩散模型，避免奖励建模。

Result: 在文本到图像和组合图像生成任务中表现优异，生成高保真且组合一致的图像。

Conclusion: Inversion-DPO为扩散模型提供高效、高精度的对齐方法，适用于复杂生成任务。

Abstract: Recent advancements in diffusion models (DMs) have been propelled by
alignment methods that post-train models to better conform to human
preferences. However, these approaches typically require computation-intensive
training of a base model and a reward model, which not only incurs substantial
computational overhead but may also compromise model accuracy and training
efficiency. To address these limitations, we propose Inversion-DPO, a novel
alignment framework that circumvents reward modeling by reformulating Direct
Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts
intractable posterior sampling in Diffusion-DPO with the deterministic
inversion from winning and losing samples to noise and thus derive a new
post-training paradigm. This paradigm eliminates the need for auxiliary reward
models or inaccurate appromixation, significantly enhancing both precision and
efficiency of training. We apply Inversion-DPO to a basic task of text-to-image
generation and a challenging task of compositional image generation. Extensive
experiments show substantial performance improvements achieved by Inversion-DPO
compared to existing post-training methods and highlight the ability of the
trained generative models to generate high-fidelity compositionally coherent
images. For the post-training of compostitional image geneation, we curate a
paired dataset consisting of 11,140 images with complex structural annotations
and comprehensive scores, designed to enhance the compositional capabilities of
generative models. Inversion-DPO explores a new avenue for efficient,
high-precision alignment in diffusion models, advancing their applicability to
complex realistic generation tasks. Our code is available at
https://github.com/MIGHTYEZ/Inversion-DPO

</details>


### [66] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: InstructFLIP是一种基于视觉语言模型（VLM）的新型框架，通过文本指导增强跨域泛化能力，显著减少训练冗余并提升人脸反欺骗（FAS）的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决人脸反欺骗中攻击类型语义理解不足和跨域训练冗余的两大挑战。

Method: 结合VLM增强视觉输入感知，采用元域策略学习统一模型，并解耦指令为内容和风格两部分。

Result: 在FAS任务中超越现有最优模型，显著减少跨域训练冗余。

Conclusion: InstructFLIP通过文本指导和指令解耦，有效提升了FAS的泛化能力和效率。

Abstract: Face anti-spoofing (FAS) aims to construct a robust system that can withstand
diverse attacks. While recent efforts have concentrated mainly on cross-domain
generalization, two significant challenges persist: limited semantic
understanding of attack types and training redundancy across domains. We
address the first by integrating vision-language models (VLMs) to enhance the
perception of visual input. For the second challenge, we employ a meta-domain
strategy to learn a unified model that generalizes well across multiple
domains. Our proposed InstructFLIP is a novel instruction-tuned framework that
leverages VLMs to enhance generalization via textual guidance trained solely on
a single domain. At its core, InstructFLIP explicitly decouples instructions
into content and style components, where content-based instructions focus on
the essential semantics of spoofing, and style-based instructions consider
variations related to the environment and camera characteristics. Extensive
experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA
models in accuracy and substantially reducing training redundancy across
diverse domains in FAS. Project website is available at
https://kunkunlin1221.github.io/InstructFLIP.

</details>


### [67] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: ST-VFM是一个新颖的框架，通过重新编程视觉基础模型（VFMs）来解决时空预测任务，克服了时间建模能力不足和模态差异的挑战。


<details>
  <summary>Details</summary>
Motivation: 基础模型在自然语言处理和计算机视觉中表现出色，但在时空预测中缺乏对时空相关性的建模能力。ST-VFM旨在填补这一空白。

Method: 采用双分支架构，结合原始时空输入和辅助时空流输入，并通过前后两个重新编程阶段（预VFM和后VFM）处理数据。

Result: 在十个时空数据集上的实验表明，ST-VFM优于现有基线，展示了其有效性和鲁棒性。

Conclusion: ST-VFM是一个强大的通用框架，适用于时空预测任务。

Abstract: Foundation models have achieved remarkable success in natural language
processing and computer vision, demonstrating strong capabilities in modeling
complex patterns. While recent efforts have explored adapting large language
models (LLMs) for time-series forecasting, LLMs primarily capture
one-dimensional sequential dependencies and struggle to model the richer
spatio-temporal (ST) correlations essential for accurate ST forecasting. In
this paper, we present \textbf{ST-VFM}, a novel framework that systematically
reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal
forecasting. While VFMs offer powerful spatial priors, two key challenges arise
when applying them to ST tasks: (1) the lack of inherent temporal modeling
capacity and (2) the modality gap between visual and ST data. To address these,
ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs
with auxiliary ST flow inputs, where the flow encodes lightweight temporal
difference signals interpretable as dynamic spatial cues. To effectively
process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming
stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token
Adapter to embed temporal context and align both branches into VFM-compatible
feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral
Cross-Prompt Coordination module, enabling dynamic interaction between branches
through prompt-based conditioning, thus enriching joint representation learning
without modifying the frozen VFM backbone. Extensive experiments on ten
spatio-temporal datasets show that ST-VFM outperforms state-of-the-art
baselines, demonstrating effectiveness and robustness across VFM backbones
(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong
general framework for spatio-temporal forecasting.

</details>


### [68] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: xOp-GAN是一种新型GAN模型，通过多个专家生成器网络解决水下图像恢复问题，优于传统单生成器方法。


<details>
  <summary>Details</summary>
Motivation: 水下图像恢复因复杂的光传播、散射和深度相关衰减而具有挑战性，传统单生成器方法难以应对异构域。

Method: 提出xOp-GAN，包含多个专家生成器网络，每个生成器专注于特定质量范围的图像恢复，判别器选择最佳恢复结果。

Result: 在LSUI数据集上，xOp-GAN的PSNR达到25.16 dB，显著优于单回归器模型。

Conclusion: xOp-GAN通过多生成器和判别器协作，显著提升了水下图像恢复性能。

Abstract: The wide range of deformation artifacts that arise from complex light
propagation, scattering, and depth-dependent attenuation makes the underwater
image restoration to remain a challenging problem. Like other single deep
regressor networks, conventional GAN-based restoration methods struggle to
perform well across this heterogeneous domain, since a single generator network
is typically insufficient to capture the full range of visual degradations. In
order to overcome this limitation, we propose xOp-GAN, a novel GAN model with
several expert generator networks, each trained solely on a particular subset
with a certain image quality. Thus, each generator can learn to maximize its
restoration performance for a particular quality range. Once a xOp-GAN is
trained, each generator can restore the input image and the best restored image
can then be selected by the discriminator based on its perceptual confidence
score. As a result, xOP-GAN is the first GAN model with multiple generators
where the discriminator is being used during the inference of the regression
task. Experimental results on benchmark Large Scale Underwater Image (LSUI)
dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,
surpassing all single-regressor models by a large margin even, with reduced
complexity.

</details>


### [69] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 该论文通过元分析和大规模实验，评估了基于步态估计年龄的方法，发现多传感器融合误差最低（3.4年），并分析了步态特征与年龄的相关性。


<details>
  <summary>Details</summary>
Motivation: 步态年龄估计在医疗、安全和人机交互中有重要应用，但现有方法性能差异较大，需建立基准和实用指南。

Method: 结合元分析（59项研究）和大规模实验（OU-ISIR和VersatileGait数据集），使用CNN、惯性传感器和多传感器融合等方法，并分析步态特征与年龄的相关性。

Result: 多传感器融合误差最低（3.4年），CNN误差4.2年；步态特征与年龄相关性显著（相关系数≥0.27）；深度学习模型准确率达96%。

Conclusion: 通过综合方法，论文为实际场景中步态年龄估计提供了性能基准和实用指南，目标将误差降至3年以下。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [70] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 论文探讨了利用改进的PPGNet模型（PPGNet-Cat）对野猫进行重识别（re-ID），以提升监控效率，结果显示模型性能优异。


<details>
  <summary>Details</summary>
Motivation: 野猫对澳大利亚野生动物造成严重威胁，需高效监控以减少其影响，re-ID技术为此提供了可能。

Method: 改进PPGNet模型（原用于东北虎re-ID）为PPGNet-Cat，并探索对比学习方法如ArcFace损失。

Result: PPGNet-Cat表现优异，mAP达0.86，rank-1准确率为0.95。

Conclusion: PPGNet-Cat是一种高效的野猫re-ID模型，适用于实际监控。

Abstract: Feral cats exert a substantial and detrimental impact on Australian wildlife,
placing them among the most dangerous invasive species worldwide. Therefore,
closely monitoring these cats is essential labour in minimising their effects.
In this context, the potential application of Re-Identification (re-ID) emerges
to enhance monitoring activities for these animals, utilising images captured
by camera traps. This project explores different CV approaches to create a
re-ID model able to identify individual feral cats in the wild. The main
approach consists of modifying a part-pose guided network (PPGNet) model,
initially used in the re-ID of Amur tigers, to be applicable for feral cats.
This adaptation, resulting in PPGNet-Cat, which incorporates specific
modifications to suit the characteristics of feral cats images. Additionally,
various experiments were conducted, particularly exploring contrastive learning
approaches such as ArcFace loss. The main results indicate that PPGNet-Cat
excels in identifying feral cats, achieving high performance with a mean
Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes
establish PPGNet-Cat as a competitive model within the realm of re-ID.

</details>


### [71] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: SketchDNN提出了一种生成CAD草图的模型，通过统一的连续-离散扩散过程联合建模连续参数和离散类别标签。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图中原始参数化的异质性和原始元素的排列不变性问题。

Method: 采用Gaussian-Softmax扩散，通过高斯噪声扰动logits并通过softmax变换投影到概率单纯形上。

Result: 显著提升生成质量，FID从16.04降至7.80，NLL从84.8降至81.33。

Conclusion: 在SketchGraphs数据集上实现了CAD草图生成的最新成果。

Abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that
jointly models both continuous parameters and discrete class labels through a
unified continuous-discrete diffusion process. Our core innovation is
Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are
projected onto the probability simplex via a softmax transformation,
facilitating blended class labels for discrete variables. This formulation
addresses 2 key challenges, namely, the heterogeneity of primitive
parameterizations and the permutation invariance of primitives in CAD sketches.
Our approach significantly improves generation quality, reducing Fr\'echet
Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)
from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch
generation on the SketchGraphs dataset.

</details>


### [72] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 使用变分自编码器（VAE）替代传统CNN进行直肠癌淋巴结转移（LNM）分期，VAE-MLP模型在MRI数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于淋巴结大小、形状和纹理的放射学标准诊断准确性有限，VAE能直接编码视觉特征和有意义的数据模式，生成解耦且结构化的潜在空间。

Method: 采用VAE作为特征编码器，替代大型预训练CNN，并在168例未经新辅助治疗的患者的MRI数据集上部署模型。

Result: VAE-MLP模型在MRI数据集上达到AUC 0.86 +/- 0.05、敏感性0.79 +/- 0.06、特异性0.85 +/- 0.05的优异性能。

Conclusion: VAE-MLP模型在直肠癌LNM分期中表现优于现有方法，提供了解释性更强的潜在空间。

Abstract: Effective treatment for rectal cancer relies on accurate lymph node
metastasis (LNM) staging. However, radiological criteria based on lymph node
(LN) size, shape and texture morphology have limited diagnostic accuracy. In
this work, we investigate applying a Variational Autoencoder (VAE) as a feature
encoder model to replace the large pre-trained Convolutional Neural Network
(CNN) used in existing approaches. The motivation for using a VAE is that the
generative model aims to reconstruct the images, so it directly encodes visual
features and meaningful patterns across the data. This leads to a disentangled
and structured latent space which can be more interpretable than a CNN. Models
are deployed on an in-house MRI dataset with 168 patients who did not undergo
neo-adjuvant treatment. The post-operative pathological N stage was used as the
ground truth to evaluate model predictions. Our proposed model 'VAE-MLP'
achieved state-of-the-art performance on the MRI dataset, with cross-validated
metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85
+/- 0.05. Code is available at:
https://github.com/benkeel/Lymph_Node_Classification_MIUA.

</details>


### [73] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 论文提出了一种基于姿势的心理状态推断方法，通过运动分析识别板球运动员的进攻或防守意图，F1分数超过75%，AUC-ROC超过80%。


<details>
  <summary>Details</summary>
Motivation: 姿势推断在疲劳诊断、伤害预防和性能提升方面潜力巨大，但面临数据敏感性问题。体育场景为获取多样化情绪状态数据提供了可行方案。

Method: 利用板球比赛中的活动视频，通过姿势分析识别运动员意图，并结合现有数据统计作为弱监督验证。

Result: 方法在区分进攻和防守意图时表现优异，F1分数和AUC-ROC分别超过75%和80%。

Conclusion: 姿势分析为意图推断提供了强信号，弱监督方法可解决数据标注限制，研究成果适用于体育分析及其他行为分析领域。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [74] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: VISTA是一种新颖的全局定位框架，通过对象分割和跟踪结合几何一致性，解决了视角变化和季节变化带来的挑战，无需特定领域训练。


<details>
  <summary>Details</summary>
Motivation: 解决在无结构环境中因视角变化、季节变化等导致的定位困难问题。

Method: 结合对象分割、跟踪和子图对应搜索，利用几何一致性对齐参考帧。

Result: 在季节和斜视角数据集上，召回率提升69%，地图大小仅为基线方法的0.6%。

Conclusion: VISTA在多样环境下实现高效、轻量级的全局定位，适用于资源受限平台。

Abstract: Global localization is critical for autonomous navigation, particularly in
scenarios where an agent must localize within a map generated in a different
session or by another agent, as agents often have no prior knowledge about the
correlation between reference frames. However, this task remains challenging in
unstructured environments due to appearance changes induced by viewpoint
variation, seasonal changes, spatial aliasing, and occlusions -- known failure
modes for traditional place recognition methods. To address these challenges,
we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame
Alignment), a novel open-set, monocular global localization framework that
combines: 1) a front-end, object-based, segmentation and tracking pipeline,
followed by 2) a submap correspondence search, which exploits geometric
consistencies between environment maps to align vehicle reference frames. VISTA
enables consistent localization across diverse camera viewpoints and seasonal
changes, without requiring any domain-specific training or finetuning. We
evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a
69% improvement in recall over baseline methods. Furthermore, we maintain a
compact object-based map that is only 0.6% the size of the most
memory-conservative baseline, making our approach capable of real-time
implementation on resource-constrained platforms.

</details>


### [75] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 论文比较了多模态视觉语言模型（VLMs）与传统CNN-based OCR在户外广告文本识别中的表现，发现VLMs在场景理解上更优，但轻量级CNN在裁剪文本识别上仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 户外广告文本识别在复杂场景中仍具挑战性，传统OCR在噪声环境下表现不佳，而新兴的VLMs可能提供更好的解决方案。

Method: 系统评估了Qwen 2.5 VL 3B、InternVL3和SmolVLM2等VLMs与PaddleOCRv4在ICDAR 2015和SVT数据集上的表现，并加入合成天气噪声模拟真实场景。

Result: VLMs在整体场景推理上表现优异，但轻量级CNN在裁剪文本识别上仍具竞争力且计算成本更低。

Conclusion: VLMs在复杂场景中表现更好，但CNN在特定任务中仍具优势，适合边缘部署。论文公开了天气增强的基准测试和评估代码。

Abstract: Outdoor advertisements remain a critical medium for modern marketing, yet
accurately verifying billboard text visibility under real-world conditions is
still challenging. Traditional Optical Character Recognition (OCR) pipelines
excel at cropped text recognition but often struggle with complex outdoor
scenes, varying fonts, and weather-induced visual noise. Recently, multimodal
Vision-Language Models (VLMs) have emerged as promising alternatives, offering
end-to-end scene understanding with no explicit detection step. This work
systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,
InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline
(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with
synthetic weather distortions to simulate realistic degradation. Our results
reveal that while selected VLMs excel at holistic scene reasoning, lightweight
CNN pipelines still achieve competitive accuracy for cropped text at a fraction
of the computational cost-an important consideration for edge deployment. To
foster future research, we release our weather-augmented benchmark and
evaluation code publicly.

</details>


### [76] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种统一的条件生成求解器（UCGS），用于解决多种抽象视觉推理（AVR）任务，避免了任务特定设计和重新训练的成本。


<details>
  <summary>Details</summary>
Motivation: 设计具有人类抽象视觉推理能力的智能系统是人工智能领域的长期目标，但现有方法通常需要任务特定设计或重新训练。

Method: 将多种AVR任务重新表述为目标图像可预测性问题，并通过训练一个统一的条件生成模型来解决。

Result: 实验表明，UCGS通过多任务训练实现了跨任务的抽象推理能力，并展示了零样本推理能力。

Conclusion: UCGS为AVR任务提供了一种高效、统一的解决方案，减少了任务特定设计的成本。

Abstract: Abstract visual reasoning (AVR) enables humans to quickly discover and
generalize abstract rules to new scenarios. Designing intelligent systems with
human-like AVR abilities has been a long-standing topic in the artificial
intelligence community. Deep AVR solvers have recently achieved remarkable
success in various AVR tasks. However, they usually use task-specific designs
or parameters in different tasks. In such a paradigm, solving new tasks often
means retraining the model, and sometimes retuning the model architectures,
which increases the cost of solving AVR problems. In contrast to task-specific
approaches, this paper proposes a novel Unified Conditional Generative Solver
(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we
prove that some well-known AVR tasks can be reformulated as the problem of
estimating the predictability of target images in problem panels. Then, we
illustrate that, under the proposed framework, training one conditional
generative model can solve various AVR tasks. The experiments show that with a
single round of multi-task training, UCGS demonstrates abstract reasoning
ability across various AVR tasks. Especially, UCGS exhibits the ability of
zero-shot reasoning, enabling it to perform abstract reasoning on problems from
unseen AVR tasks in the testing phase.

</details>


### [77] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: CorrMoE提出了一种新的对应点修剪框架，通过去风格化双分支和双融合专家混合模块，提升了跨域和跨场景的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在密集对应点修剪中假设视觉域一致，忽视了多样场景结构带来的挑战。

Method: 采用去风格化双分支处理域偏移，双融合专家混合模块自适应整合多视角特征。

Result: 在基准数据集上表现出优于现有方法的准确性和泛化能力。

Conclusion: CorrMoE为跨域和跨场景的对应点修剪提供了有效解决方案。

Abstract: Establishing reliable correspondences between image pairs is a fundamental
task in computer vision, underpinning applications such as 3D reconstruction
and visual localization. Although recent methods have made progress in pruning
outliers from dense correspondence sets, they often hypothesize consistent
visual domains and overlook the challenges posed by diverse scene structures.
In this paper, we propose CorrMoE, a novel correspondence pruning framework
that enhances robustness under cross-domain and cross-scene variations. To
address domain shift, we introduce a De-stylization Dual Branch, performing
style mixing on both implicit and explicit graph features to mitigate the
adverse influence of domain-specific representations. For scene diversity, we
design a Bi-Fusion Mixture of Experts module that adaptively integrates
multi-perspective features through linear-complexity attention and dynamic
expert routing. Extensive experiments on benchmark datasets demonstrate that
CorrMoE achieves superior accuracy and generalization compared to
state-of-the-art methods. The code and pre-trained models are available at
https://github.com/peiwenxia/CorrMoE.

</details>


### [78] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: ProtoConNet通过整合背景信息增强特征空间多样性，提出原型增强与对齐方法，提升小样本开放集图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖单张图像的视觉信息，忽略了上下文信息的整合，导致性能受限。

Method: ProtoConNet包含三个模块：聚类数据选择（CDS）挖掘多样数据模式；上下文增强语义细化（CSR）整合背景信息；原型对齐（PA）缩小图像表示与类别原型的差距。

Result: 在两个数据集上的实验验证了ProtoConNet在小样本开放集分类中的优越性。

Conclusion: ProtoConNet通过上下文信息整合和原型对齐，显著提升了小样本开放集分类的性能。

Abstract: Open-set few-shot image classification aims to train models using a small
amount of labeled data, enabling them to achieve good generalization when
confronted with unknown environments. Existing methods mainly use visual
information from a single image to learn class representations to distinguish
known from unknown categories. However, these methods often overlook the
benefits of integrating rich contextual information. To address this issue,
this paper proposes a prototypical augmentation and alignment method, termed
ProtoConNet, which incorporates background information from different samples
to enhance the diversity of the feature space, breaking the spurious
associations between context and image subjects in few-shot scenarios.
Specifically, it consists of three main modules: the clustering-based data
selection (CDS) module mines diverse data patterns while preserving core
features; the contextual-enhanced semantic refinement (CSR) module builds a
context dictionary to integrate into image representations, which boosts the
model's robustness in various scenarios; and the prototypical alignment (PA)
module reduces the gap between image representations and class prototypes,
amplifying feature distances for known and unknown classes. Experimental
results from two datasets verified that ProtoConNet enhances the effectiveness
of representation learning in few-shot scenarios and identifies open-set
samples, making it superior to existing methods.

</details>


### [79] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 论文提出GRACE方法，通过动态运动建模、语义文本细化和跨模态对齐，提升动态面部表情识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用文本中的情感线索，且缺乏过滤无关面部动态的有效机制。

Method: 结合动态运动建模、语义文本细化（CATE模块）和基于熵正则化最优传输的跨模态对齐。

Result: 在三个基准数据集上显著提升识别性能，特别是在模糊或不平衡情感类别场景中，达到SOTA。

Conclusion: GRACE通过细粒度跨模态对齐和情感文本增强，有效解决了现有方法的局限性。

Abstract: Dynamic Facial Expression Recognition (DFER) aims to identify human emotions
from temporally evolving facial movements and plays a critical role in
affective computing. While recent vision-language approaches have introduced
semantic textual descriptions to guide expression recognition, existing methods
still face two key limitations: they often underutilize the subtle emotional
cues embedded in generated text, and they have yet to incorporate sufficiently
effective mechanisms for filtering out facial dynamics that are irrelevant to
emotional expression. To address these gaps, We propose GRACE, Granular
Representation Alignment for Cross-modal Emotion recognition that integrates
dynamic motion modeling, semantic text refinement, and token-level cross-modal
alignment to facilitate the precise localization of emotionally salient
spatiotemporal features. Our method constructs emotion-aware textual
descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and
highlights expression-relevant facial motion through a motion-difference
weighting mechanism. These refined semantic and visual signals are aligned at
the token level using entropy-regularized optimal transport. Experiments on
three benchmark datasets demonstrate that our method significantly improves
recognition performance, particularly in challenging settings with ambiguous or
imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in
terms of both UAR and WAR.

</details>


### [80] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: 提出了一种空间频率调制（SFM）方法，通过调制高频特征以降低频率，再通过解调恢复高频信息，有效缓解下采样中的混叠问题。


<details>
  <summary>Details</summary>
Motivation: 高频信息对语义分割精度至关重要，但下采样层容易导致高频信息混叠或失真。

Method: 采用自适应重采样（ARS）调制高频特征，设计多尺度自适应上采样（MSAU）解调并恢复高频信息。

Result: SFM有效缓解混叠并保留细节，适用于多种任务和架构。

Conclusion: SFM是一种通用且有效的方法，可提升高频信息在下采样中的保留能力。

Abstract: High spatial frequency information, including fine details like textures,
significantly contributes to the accuracy of semantic segmentation. However,
according to the Nyquist-Shannon Sampling Theorem, high-frequency components
are vulnerable to aliasing or distortion when propagating through downsampling
layers such as strided-convolution. Here, we propose a novel Spatial Frequency
Modulation (SFM) that modulates high-frequency features to a lower frequency
before downsampling and then demodulates them back during upsampling.
Specifically, we implement modulation through adaptive resampling (ARS) and
design a lightweight add-on that can densely sample the high-frequency areas to
scale up the signal, thereby lowering its frequency in accordance with the
Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling
(MSAU) to demodulate the modulated feature and recover high-frequency
information through non-uniform upsampling This module further improves
segmentation by explicitly exploiting information interaction between densely
and sparsely resampled areas at multiple scales. Both modules can seamlessly
integrate with various architectures, extending from convolutional neural
networks to transformers. Feature visualization and analysis confirm that our
method effectively alleviates aliasing while successfully retaining details
after demodulation. Finally, we validate the broad applicability and
effectiveness of SFM by extending it to image classification, adversarial
robustness, instance segmentation, and panoptic segmentation tasks. The code is
available at
\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.

</details>


### [81] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose是一个基于事件的合成人体姿态估计数据集，用于固定行人感知，填补了真实数据不足的空白。


<details>
  <summary>Details</summary>
Motivation: 解决行人监控系统中因数据不足而难以应对复杂条件的问题。

Method: 使用CARLA模拟器和动态视觉传感器生成合成数据集SEPose，包含近350K标注行人姿态关键点。

Result: 在SEPose上训练现有先进模型（如RVT和YOLOv8），并在真实事件数据上验证其泛化能力。

Conclusion: SEPose展示了从模拟到现实的泛化潜力，为事件传感器在行人监控中的应用提供了支持。

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [82] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 论文提出Dark-EvGS框架，利用事件相机和3D高斯泼溅技术，在低光条件下从任意视角重建明亮帧，解决了噪声、帧质量差和色调不一致问题。


<details>
  <summary>Details</summary>
Motivation: 低光环境下传统相机难以捕捉清晰多视角图像，事件相机和高斯泼溅技术虽有潜力，但直接结合仍面临噪声、帧质量低和色调不一致的挑战。

Method: 提出Dark-EvGS框架，采用三重监督学习、色调匹配模块，并构建首个真实数据集，实现低光条件下的高质量帧重建。

Result: 实验表明，该方法在低光条件下优于现有方法，成功重建辐射场。

Conclusion: Dark-EvGS框架有效解决了低光环境下的多视角图像重建问题，为相关任务提供了新思路和数据支持。

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [83] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: 论文提出Hyperphantasia基准，用于评估多模态大语言模型（MLLMs）的心理可视化能力，发现其与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前基准主要评估被动视觉感知，缺乏对主动构建视觉模式以支持问题解决能力的评估，而心理可视化是人类认知的核心能力。

Method: 设计了四个程序生成的谜题任务，分为三个难度级别，通过综合评估和强化学习探索模型表现。

Result: 现有MLLMs在心理可视化能力上与人类存在显著差距，部分模型能识别视觉模式但整体表现不足。

Conclusion: 心理可视化是当前MLLMs的开放挑战，需进一步研究提升其视觉模拟能力。

Abstract: Mental visualization, the ability to construct and manipulate visual
representations internally, is a core component of human cognition and plays a
vital role in tasks involving reasoning, prediction, and abstraction. Despite
the rapid progress of Multimodal Large Language Models (MLLMs), current
benchmarks primarily assess passive visual perception, offering limited insight
into the more active capability of internally constructing visual patterns to
support problem solving. Yet mental visualization is a critical cognitive skill
in humans, supporting abilities such as spatial navigation, predicting physical
trajectories, and solving complex visual problems through imaginative
simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic
benchmark designed to evaluate the mental visualization abilities of MLLMs
through four carefully constructed puzzles. Each task is procedurally generated
and presented at three difficulty levels, enabling controlled analysis of model
performance across increasing complexity. Our comprehensive evaluation of
state-of-the-art models reveals a substantial gap between the performance of
humans and MLLMs. Additionally, we explore the potential of reinforcement
learning to improve visual simulation capabilities. Our findings suggest that
while some models exhibit partial competence in recognizing visual patterns,
robust mental visualization remains an open challenge for current MLLMs.

</details>


### [84] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: RaDL框架通过关系感知解耦学习，解决了多实例图像生成中的关系差异和属性泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多实例图像生成中难以处理实例间的关系差异和属性泄漏，RaDL旨在解决这些问题。

Method: RaDL通过可学习参数增强实例特定属性，并利用关系注意力生成关系感知图像特征。

Result: 在COCO-Position等基准测试中，RaDL在位置准确性、多属性考虑和实例关系方面表现优于现有方法。

Conclusion: RaDL是解决多实例图像生成中关系和属性问题的有效方案。

Abstract: With recent advancements in text-to-image (T2I) models, effectively
generating multiple instances within a single image prompt has become a crucial
challenge. Existing methods, while successful in generating positions of
individual instances, often struggle to account for relationship discrepancy
and multiple attributes leakage. To address these limitations, this paper
proposes the relation-aware disentangled learning (RaDL) framework. RaDL
enhances instance-specific attributes through learnable parameters and
generates relation-aware image features via Relation Attention, utilizing
action verbs extracted from the global prompt. Through extensive evaluations on
benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that
RaDL outperforms existing methods, showing significant improvements in
positional accuracy, multiple attributes consideration, and the relationships
between instances. Our results present RaDL as the solution for generating
images that consider both the relationships and multiple attributes of each
instance within the multi-instance image.

</details>


### [85] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: PPAR框架通过渐进式对齐和原型重加权，结合CLIP模型，提升了语义分割的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有原型方法在语义分割泛化中的三个挑战：粗粒度对齐、原型过拟合及忽略特征适应难度差异。

Method: 提出PPAR框架，定义OTP和VTP原型，采用渐进式对齐和重加权机制优化源数据贡献。

Result: 在多个基准测试中达到最先进性能。

Conclusion: PPAR有效提升了语义分割的泛化能力，理论分析与实验结果一致。

Abstract: Generalizable semantic segmentation aims to perform well on unseen target
domains, a critical challenge due to real-world applications requiring high
generalizability. Class-wise prototypes, representing class centroids, serve as
domain-invariant cues that benefit generalization due to their stability and
semantic consistency. However, this approach faces three challenges. First,
existing methods often adopt coarse prototypical alignment strategies, which
may hinder performance. Second, naive prototypes computed by averaging source
batch features are prone to overfitting and may be negatively affected by
unrelated source data. Third, most methods treat all source samples equally,
ignoring the fact that different features have varying adaptation difficulties.
To address these limitations, we propose a novel framework for generalizable
semantic segmentation: Prototypical Progressive Alignment and Reweighting
(PPAR), leveraging the strong generalization ability of the CLIP model.
Specifically, we define two prototypes: the Original Text Prototype (OTP) and
Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for
alignment. We then introduce a progressive alignment strategy that aligns
features in an easy-to-difficult manner, reducing domain gaps gradually.
Furthermore, we propose a prototypical reweighting mechanism that estimates the
reliability of source data and adjusts its contribution, mitigating the effect
of irrelevant or harmful features (i.e., reducing negative transfer). We also
provide a theoretical analysis showing the alignment between our method and
domain generalization theory. Extensive experiments across multiple benchmarks
demonstrate that PPAR achieves state-of-the-art performance, validating its
effectiveness.

</details>


### [86] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: 提出了LG-CAV-MAE模型，通过结合文本编码器改进音频-视觉表示学习，自动生成高质量的三模态数据，显著提升检索和分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 改进音频-视觉表示学习，通过引入文本模态增强跨模态学习能力。

Method: 结合预训练文本编码器到对比音频-视觉掩码自编码器中，自动生成音频-视觉-文本三模态数据，利用CLAP过滤确保对齐。

Result: 在音频-视觉检索任务中召回率提升5.6%，分类任务准确率提升3.2%。

Conclusion: LG-CAV-MAE通过多模态学习和自动数据生成，显著提升了音频-视觉任务的性能。

Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked
Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning.
LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual
masked autoencoders, enabling the model to learn across audio, visual and text
modalities. To train LG-CAV-MAE, we introduce an automatic method to generate
audio-visual-text triplets from unlabeled videos. We first generate frame-level
captions using an image captioning model and then apply CLAP-based filtering to
ensure strong alignment between audio and captions. This approach yields
high-quality audio-visual-text triplets without requiring manual annotations.
We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an
audio-visual classification task. Our method significantly outperforms existing
approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks
and a 3.2% improvement for the classification task.

</details>


### [87] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 本文提出了一种评估多模态大语言模型（MLLMs）在短视频内容审核中的安全性的框架，包括SVMA数据集和ChimeraBreak攻击策略，揭示了模型的高攻击成功率及其偏见。


<details>
  <summary>Details</summary>
Motivation: 当前的安全评估主要针对单模态攻击，缺乏对多模态联合攻击的鲁棒性研究，特别是在短视频内容审核中。

Method: 1. 构建SVMA数据集，包含多样化的短视频和人工引导的合成对抗攻击；2. 提出ChimeraBreak三模态攻击策略，同时挑战视觉、听觉和语义推理路径。

Result: 实验显示MLLMs存在显著漏洞，攻击成功率高，并揭示了模型对良性或违规内容的分类偏见。

Conclusion: 研究为开发更鲁棒和安全的MLLMs提供了关键见解，数据集和攻击策略具有重要价值。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used for content
moderation, yet their robustness in short-form video contexts remains
underexplored. Current safety evaluations often rely on unimodal attacks,
failing to address combined attack vulnerabilities. In this paper, we introduce
a comprehensive framework for evaluating the tri-modal safety of MLLMs. First,
we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising
diverse short-form videos with human-guided synthetic adversarial attacks.
Second, we propose ChimeraBreak, a novel tri-modal attack strategy that
simultaneously challenges visual, auditory, and semantic reasoning pathways.
Extensive experiments on state-of-the-art MLLMs reveal significant
vulnerabilities with high Attack Success Rates (ASR). Our findings uncover
distinct failure modes, showing model biases toward misclassifying benign or
policy-violating content. We assess results using LLM-as-a-judge, demonstrating
attack reasoning efficacy. Our dataset and findings provide crucial insights
for developing more robust and safe MLLMs.

</details>


### [88] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: GS-Bias是一种高效且有效的测试时适应（TTA）方法，通过全局和空间偏置提升视觉语言模型的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在性能和效率之间难以平衡，要么调整文本提示的开销过大，要么手工视觉特征增强效果不稳定。

Method: GS-Bias引入全局偏置和空间偏置，直接添加到预训练模型的输出logits中，避免全反向传播，提升效率。

Result: 在15个基准数据集上实现SOTA性能，例如在跨数据集和领域泛化中分别提升2.23%和2.72%，且内存使用仅为TPT的6.5%。

Conclusion: GS-Bias在高效性和性能上均优于现有TTA方法，为视觉语言模型的测试时适应提供了新思路。

Abstract: Recent advances in test-time adaptation (TTA) for Vision-Language Models
(VLMs) have garnered increasing attention, particularly through the use of
multiple augmented views of a single image to boost zero-shot generalization.
Unfortunately, existing methods fail to strike a satisfactory balance between
performance and efficiency, either due to excessive overhead of tuning text
prompts or unstable benefits from handcrafted, training-free visual feature
enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),
an efficient and effective TTA paradigm that incorporates two learnable biases
during TTA, unfolded as the global bias and spatial bias. Particularly, the
global bias captures the global semantic features of a test image by learning
consistency across augmented views, while spatial bias learns the semantic
coherence between regions in the image's spatial visual representation. It is
worth highlighting that these two sets of biases are directly added to the
logits outputed by the pretrained VLMs, which circumvent the full
backpropagation through VLM that hinders the efficiency of existing TTA
methods. This endows GS-Bias with extremely high efficiency while achieving
state-of-the-art performance on 15 benchmark datasets. For example, it achieves
a 2.23% improvement over TPT in cross-dataset generalization and a 2.72%
improvement in domain generalization, while requiring only 6.5% of TPT's memory
usage on ImageNet.

</details>


### [89] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: EC-Diff是一种混合边缘-云协作框架，通过梯度噪声估计加速云推理，并通过优化云-边缘切换点保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有混合框架中云去噪时间过长或不足导致的语义模糊和边缘输出不一致问题。

Method: 提出K步噪声近似策略减少云推理频率，并设计两阶段贪心搜索算法优化噪声近似和边缘模型切换参数。

Result: 实验表明，EC-Diff在生成质量上优于边缘推理，推理速度比云推理快2倍。

Conclusion: EC-Diff有效平衡了生成质量和推理速度，适用于高效图像和视频合成。

Abstract: Diffusion Models have shown remarkable proficiency in image and video
synthesis. As model size and latency increase limit user experience, hybrid
edge-cloud collaborative framework was recently proposed to realize fast
inference and high-quality generation, where the cloud model initiates
high-quality semantic planning and the edge model expedites later-stage
refinement. However, excessive cloud denoising prolongs inference time, while
insufficient steps cause semantic ambiguity, leading to inconsistency in edge
model output. To address these challenges, we propose EC-Diff that accelerates
cloud inference through gradient-based noise estimation while identifying the
optimal point for cloud-edge handoff to maintain generation quality.
Specifically, we design a K-step noise approximation strategy to reduce cloud
inference frequency by using noise gradients between steps and applying cloud
inference periodically to adjust errors. Then we design a two-stage greedy
search algorithm to efficiently find the optimal parameters for noise
approximation and edge model switching. Extensive experiments demonstrate that
our method significantly enhances generation quality compared to edge
inference, while achieving up to an average $2\times$ speedup in inference
compared to cloud inference. Video samples and source code are available at
https://ec-diff.github.io/.

</details>


### [90] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为MPAE的无监督部件发现方法，通过掩码自编码器学习部件描述符，并在复杂场景中实现鲁棒的部件发现。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏细粒度标签，部件级特征研究较少，现有无监督方法在跨类别和场景中鲁棒性不足。

Method: MPAE通过掩码自编码器学习部件描述符和特征图，利用局部特征与描述符的相似性填充掩码区域，恢复部件形状。

Result: MPAE在复杂场景中鲁棒地发现与实际物体形状匹配的部件，并支持跨类别和场景的无监督部件识别。

Conclusion: MPAE为无监督部件发现提供了有效解决方案，支持遮挡处理和跨类别部件相似性探索。

Abstract: Part-level features are crucial for image understanding, but few studies
focus on them because of the lack of fine-grained labels. Although unsupervised
part discovery can eliminate the reliance on labels, most of them cannot
maintain robustness across various categories and scenarios, which restricts
their application range. To overcome this limitation, we present a more
effective paradigm for unsupervised part discovery, named Masked Part
Autoencoder (MPAE). It first learns part descriptors as well as a feature map
from the inputs and produces patch features from a masked version of the
original images. Then, the masked regions are filled with the learned part
descriptors based on the similarity between the local features and descriptors.
By restoring these masked patches using the part descriptors, they become
better aligned with their part shapes, guided by appearance features from
unmasked patches. Finally, MPAE robustly discovers meaningful parts that
closely match the actual object shapes, even in complex scenarios. Moreover,
several looser yet more effective constraints are proposed to enable MPAE to
identify the presence of parts across various scenarios and categories in an
unsupervised manner. This provides the foundation for addressing challenges
posed by occlusion and for exploring part similarity across multiple
categories. Extensive experiments demonstrate that our method robustly
discovers meaningful parts across various categories and scenarios. The code is
available at the project https://github.com/Jiahao-UTS/MPAE.

</details>


### [91] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出了一种零样本扩散管道，通过融合不同风格模型的去噪潜在空间，实现区域特定的风格混合。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在风格混合时难以控制区域风格的问题。

Method: 利用低噪声潜在空间携带更强风格信息的特点，通过空间掩码融合不同风格模型的潜在空间，并结合ControlNet进行深度图调节。

Result: 定性和定量实验表明，该方法能根据掩码实现区域特定的风格混合。

Conclusion: 该方法成功实现了精确的区域风格控制，同时保持了各风格的保真度。

Abstract: Diffusion-based text-to-image models have achieved remarkable results in
synthesizing diverse images from text prompts and can capture specific artistic
styles via style personalization. However, their entangled latent space and
lack of smooth interpolation make it difficult to apply distinct painting
techniques in a controlled, regional manner, often causing one style to
dominate. To overcome this, we propose a zero-shot diffusion pipeline that
naturally blends multiple styles by performing style composition on the
denoised latents predicted during the flow-matching denoising process of
separately trained, style-specialized models. We leverage the fact that
lower-noise latents carry stronger stylistic information and fuse them across
heterogeneous diffusion pipelines using spatial masks, enabling precise,
region-specific style control. This mechanism preserves the fidelity of each
individual style while allowing user-guided mixing. Furthermore, to ensure
structural coherence across different models, we incorporate depth-map
conditioning via ControlNet into the diffusion framework. Qualitative and
quantitative experiments demonstrate that our method successfully achieves
region-specific style mixing according to the given masks.

</details>


### [92] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: ID-EA框架通过文本嵌入与视觉身份嵌入的对齐，显著提升了文本到图像扩散模型中个性化肖像生成的身份一致性。


<details>
  <summary>Details</summary>
Motivation: 当前Textual Inversion方法在个性化生成中难以保持面部身份一致性，主要由于文本与视觉嵌入空间的语义不对齐。

Method: ID-EA包含ID-Enhancer和ID-Adapter两个组件，前者通过文本ID锚点优化视觉身份嵌入，后者调整预训练UNet模型的交叉注意力模块以保持身份。

Result: ID-EA在身份保留指标上显著优于现有方法，且计算效率高，生成速度比现有方法快约15倍。

Conclusion: ID-EA为个性化肖像生成提供了一种高效且身份一致的新方法。

Abstract: Recently, personalized portrait generation with a text-to-image diffusion
model has significantly advanced with Textual Inversion, emerging as a
promising approach for creating high-fidelity personalized images. Despite its
potential, current Textual Inversion methods struggle to maintain consistent
facial identity due to semantic misalignments between textual and visual
embedding spaces regarding identity. We introduce ID-EA, a novel framework that
guides text embeddings to align with visual identity embeddings, thereby
improving identity preservation in a personalized generation. ID-EA comprises
two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned
Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings
with a textual ID anchor, refining visual identity embeddings derived from a
face recognition model using representative text embeddings. Then, the
ID-Adapter leverages the identity-enhanced embedding to adapt the text
condition, ensuring identity preservation by adjusting the cross-attention
module in the pre-trained UNet model. This process encourages the text features
to find the most related visual clues across the foreground snippets. Extensive
quantitative and qualitative evaluations demonstrate that ID-EA substantially
outperforms state-of-the-art methods in identity preservation metrics while
achieving remarkable computational efficiency, generating personalized
portraits approximately 15 times faster than existing approaches.

</details>


### [93] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc是一种新颖的定位系统，通过利用语义信息直接从3D高斯泼溅（3DGS）表示回归相机姿态。


<details>
  <summary>Details</summary>
Motivation: 传统定位方法通常依赖初始姿态先验信息，而SGLoc旨在无需初始姿态先验即可实现全局定位。

Method: 采用多级姿态回归策略，结合语义关系匹配2D图像与3D场景表示，并通过迭代优化细化姿态估计。

Result: 在12scenes和7scenes数据集上表现优于基线方法，展示了无需初始姿态先验的全局定位能力。

Conclusion: SGLoc通过语义信息与3DGS表示的结合，实现了高效的全局定位，具有广泛的应用潜力。

Abstract: We propose SGLoc, a novel localization system that directly regresses camera
poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic
information. Our method utilizes the semantic relationship between 2D image and
3D scene representation to estimate the 6DoF pose without prior pose
information. In this system, we introduce a multi-level pose regression
strategy that progressively estimates and refines the pose of query image from
the global 3DGS map, without requiring initial pose priors. Moreover, we
introduce a semantic-based global retrieval algorithm that establishes
correspondences between 2D (image) and 3D (3DGS map). By matching the extracted
scene semantic descriptors of 2D query image and 3DGS semantic representation,
we align the image with the local region of the global 3DGS map, thereby
obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by
iteratively optimizing the difference between the query image and the rendered
image from 3DGS. Our SGLoc demonstrates superior performance over baselines on
12scenes and 7scenes datasets, showing excellent capabilities in global
localization without initial pose prior. Code will be available at
https://github.com/IRMVLab/SGLoc.

</details>


### [94] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: SAMST是一种半监督语义分割方法，利用Segment Anything Model（SAM）的零样本泛化和边界检测能力，通过迭代优化伪标签提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 公共遥感数据集因分辨率和地物类别定义不一致而通用性受限，需要利用大量未标记数据提升模型性能。

Method: SAMST结合监督模型自训练和基于SAM的伪标签优化器，后者包括阈值过滤、提示生成和标签细化模块。

Result: 在Potsdam数据集上的实验验证了SAMST的有效性，能够解决标记数据不足的问题。

Conclusion: SAMST通过结合大模型的泛化能力和小模型的训练效率，显著提升了遥感语义分割的性能。

Abstract: Public remote sensing datasets often face limitations in universality due to
resolution variability and inconsistent land cover category definitions. To
harness the vast pool of unlabeled remote sensing data, we propose SAMST, a
semi-supervised semantic segmentation method. SAMST leverages the strengths of
the Segment Anything Model (SAM) in zero-shot generalization and boundary
detection. SAMST iteratively refines pseudo-labels through two main components:
supervised model self-training using both labeled and pseudo-labeled data, and
a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three
modules: a Threshold Filter Module for preprocessing, a Prompt Generation
Module for extracting connected regions and generating prompts for SAM, and a
Label Refinement Module for final label stitching. By integrating the
generalization power of large models with the training efficiency of small
models, SAMST improves pseudo-label accuracy, thereby enhancing overall model
performance. Experiments on the Potsdam dataset validate the effectiveness and
feasibility of SAMST, demonstrating its potential to address the challenges
posed by limited labeled data in remote sensing semantic segmentation.

</details>


### [95] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 提出了一种基于规划视角的运动预测方法，通过先推理行为意图再预测轨迹，结合逆向强化学习（IRL）和分层解码器，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法直接预测轨迹，缺乏对行为意图的显式建模，影响预测准确性和可解释性。

Method: 1. 使用向量化表示编码交通场景；2. 通过查询为中心的IRL推理行为意图；3. 分层解码器生成轨迹及其概率。

Result: 在Argoverse和nuScenes数据集上表现优异，显著提升了预测置信度。

Conclusion: 通过显式建模行为意图和奖励驱动推理，实现了更准确和可解释的运动预测。

Abstract: Motion forecasting for on-road traffic agents presents both a significant
challenge and a critical necessity for ensuring safety in autonomous driving
systems. In contrast to most existing data-driven approaches that directly
predict future trajectories, we rethink this task from a planning perspective,
advocating a "First Reasoning, Then Forecasting" strategy that explicitly
incorporates behavior intentions as spatial guidance for trajectory prediction.
To achieve this, we introduce an interpretable, reward-driven intention
reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)
scheme. Our method first encodes traffic agents and scene elements into a
unified vectorized representation, then aggregates contextual features through
a query-centric paradigm. This enables the derivation of a reward distribution,
a compact yet informative representation of the target agent's behavior within
the given scene context via IRL. Guided by this reward heuristic, we perform
policy rollouts to reason about multiple plausible intentions, providing
valuable priors for subsequent trajectory generation. Finally, we develop a
hierarchical DETR-like decoder integrated with bidirectional selective state
space models to produce accurate future trajectories along with their
associated probabilities. Extensive experiments on the large-scale Argoverse
and nuScenes motion forecasting datasets demonstrate that our approach
significantly enhances trajectory prediction confidence, achieving highly
competitive performance relative to state-of-the-art methods.

</details>


### [96] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: 论文提出了AUBlendSet数据集和AUBlendNet网络，用于基于面部动作单元（AUs）的细粒度3D面部表情风格化操纵。


<details>
  <summary>Details</summary>
Motivation: 现有3D面部动画在细粒度风格化表情操纵上存在挑战，主要由于缺乏合适的数据集。

Method: 引入AUBlendSet数据集（基于32个标准AUs的500个身份数据），并提出AUBlendNet网络学习不同风格的AU-Blendshape基向量。

Result: 通过实验验证了AUBlendSet和AUBlendNet在风格化表情操纵、语音驱动动画和情感识别数据增强中的有效性。

Conclusion: AUBlendSet和AUBlendNet在3D面部动画任务中具有重要潜力，填补了相关领域的空白。

Abstract: While 3D facial animation has made impressive progress, challenges still
exist in realizing fine-grained stylized 3D facial expression manipulation due
to the lack of appropriate datasets. In this paper, we introduce the
AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for
fine-grained facial expression manipulation across identities. AUBlendSet is a
blendshape data collection based on 32 standard facial action units (AUs)
across 500 identities, along with an additional set of facial postures
annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to
learn AU-Blendshape basis vectors for different character styles. AUBlendNet
predicts, in parallel, the AU-Blendshape basis vectors of the corresponding
style for a given identity mesh, thereby achieving stylized 3D emotional facial
manipulation. We comprehensively validate the effectiveness of AUBlendSet and
AUBlendNet through tasks such as stylized facial expression manipulation,
speech-driven emotional facial animation, and emotion recognition data
augmentation. Through a series of qualitative and quantitative experiments, we
demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D
facial animation tasks. To the best of our knowledge, AUBlendSet is the first
dataset, and AUBlendNet is the first network for continuous 3D facial
expression manipulation for any identity through facial AUs. Our source code is
available at https://github.com/wslh852/AUBlendNet.git.

</details>


### [97] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: AutoVDC框架利用视觉语言模型自动检测视觉数据集中的错误标注，提升数据质量。


<details>
  <summary>Details</summary>
Motivation: 人工标注存在缺陷且成本高，需要自动化方法提高数据集质量。

Method: 使用Vision-Language Models (VLMs)自动识别错误标注，并在KITTI和nuImages数据集上验证。

Result: 方法在错误检测和数据清理实验中表现优异。

Conclusion: AutoVDC能显著提升自动驾驶大规模数据集的可靠性和准确性。

Abstract: Training of autonomous driving systems requires extensive datasets with
precise annotations to attain robust performance. Human annotations suffer from
imperfections, and multiple iterations are often needed to produce high-quality
datasets. However, manually reviewing large datasets is laborious and
expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)
framework and investigate the utilization of Vision-Language Models (VLMs) to
automatically identify erroneous annotations in vision datasets, thereby
enabling users to eliminate these errors and enhance data quality. We validate
our approach using the KITTI and nuImages datasets, which contain object
detection benchmarks for autonomous driving. To test the effectiveness of
AutoVDC, we create dataset variants with intentionally injected erroneous
annotations and observe the error detection rate of our approach. Additionally,
we compare the detection rates using different VLMs and explore the impact of
VLM fine-tuning on our pipeline. The results demonstrate our method's high
performance in error detection and data cleaning experiments, indicating its
potential to significantly improve the reliability and accuracy of large-scale
production datasets in autonomous driving.

</details>


### [98] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种基于电路理论的频率动态注意力调制（FDAM）方法，通过注意力反转和频率动态缩放技术，解决了ViTs中频率消失问题，提升了性能。


<details>
  <summary>Details</summary>
Motivation: ViTs的注意力机制导致频率消失，丢失关键细节和纹理，需要一种方法动态调整频率响应。

Method: 提出FDAM，包括注意力反转（AttInv）和频率动态缩放（FreqScale），动态调制ViTs的频率响应。

Result: 在多种模型（如SegFormer、DeiT）和任务（如语义分割、目标检测）中表现提升，并在遥感检测中达到SOTA。

Conclusion: FDAM有效解决了ViTs的频率消失问题，提升了模型性能，且易于集成到现有架构中。

Abstract: Vision Transformers (ViTs) have significantly advanced computer vision,
demonstrating strong performance across various tasks. However, the attention
mechanism in ViTs makes each layer function as a low-pass filter, and the
stacked-layer architecture in existing transformers suffers from frequency
vanishing. This leads to the loss of critical details and textures. We propose
a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention
Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly
modulates the overall frequency response of ViTs and consists of two
techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling
(FreqScale). Since circuit theory uses low-pass filters as fundamental
elements, we introduce AttInv, a method that generates complementary high-pass
filtering by inverting the low-pass filter in the attention matrix, and
dynamically combining the two. We further design FreqScale to weight different
frequency components for fine-grained adjustments to the target response
function. Through feature similarity analysis and effective rank evaluation, we
demonstrate that our approach avoids representation collapse, leading to
consistent performance improvements across various models, including SegFormer,
DeiT, and MaskDINO. These improvements are evident in tasks such as semantic
segmentation, object detection, and instance segmentation. Additionally, we
apply our method to remote sensing detection, achieving state-of-the-art
results in single-scale settings. The code is available at
\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.

</details>


### [99] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 论文将掩码图像建模（MIM）重新定义为稀疏信号重建问题，提出MaskTwins框架，通过互补掩码增强特征提取能力，在无监督域适应（UDA）中实现领域泛化。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将掩码视为图像变形，缺乏理论分析，未能充分利用掩码重建的潜力。

Method: 将掩码重建视为稀疏信号问题，理论证明互补掩码的优越性，提出MaskTwins框架，直接集成掩码重建到训练流程中。

Result: 实验证明MaskTwins在自然和生物图像分割中优于基线方法，无需单独预训练即可提取领域不变特征。

Conclusion: MaskTwins为领域自适应分割提供了新范式，展示了掩码重建在特征提取中的显著优势。

Abstract: Recent works have correlated Masked Image Modeling (MIM) with consistency
regularization in Unsupervised Domain Adaptation (UDA). However, they merely
treat masking as a special form of deformation on the input images and neglect
the theoretical analysis, which leads to a superficial understanding of masked
reconstruction and insufficient exploitation of its potential in enhancing
feature extraction and representation learning. In this paper, we reframe
masked reconstruction as a sparse signal reconstruction problem and
theoretically prove that the dual form of complementary masks possesses
superior capabilities in extracting domain-agnostic image features. Based on
this compelling insight, we propose MaskTwins, a simple yet effective UDA
framework that integrates masked reconstruction directly into the main training
pipeline. MaskTwins uncovers intrinsic structural patterns that persist across
disparate domains by enforcing consistency between predictions of images masked
in complementary ways, enabling domain generalization in an end-to-end manner.
Extensive experiments verify the superiority of MaskTwins over baseline methods
in natural and biological image segmentation. These results demonstrate the
significant advantages of MaskTwins in extracting domain-invariant features
without the need for separate pre-training, offering a new paradigm for
domain-adaptive segmentation.

</details>


### [100] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 提出了一种端到端的深度神经网络编码器-解码器模型，用于编码和解码自然刺激下的大脑活动，通过fMRI数据预测视觉皮层及周边区域的神经活动，并重建视觉输入。


<details>
  <summary>Details</summary>
Motivation: 研究自然电影刺激下的大脑活动编码与解码，以填补自然刺激与fMRI采集之间的时间分辨率差距。

Method: 采用时间卷积层处理连续电影帧的时序相关输入，构建编码器-解码器模型预测视觉皮层活动并重建视觉输入。

Result: 模型成功预测了视觉皮层活动，重建了边缘、面部和对比等视觉特征，并通过显著图识别了关键脑区（如中枕区、梭状回和距状沟）。

Conclusion: 该模型为探索视觉处理机制提供了新工具，表明深度学习模型可作为理解自然电影刺激下视觉处理的代理。

Abstract: We propose an end-to-end deep neural encoder-decoder model to encode and
decode brain activity in response to naturalistic stimuli using functional
magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input
from consecutive film frames, we employ temporal convolutional layers in our
architecture, which effectively allows to bridge the temporal resolution gap
between natural movie stimuli and fMRI acquisitions. Our model predicts
activity of voxels in and around the visual cortex and performs reconstruction
of corresponding visual inputs from neural activity. Finally, we investigate
brain regions contributing to visual decoding through saliency maps. We find
that the most contributing regions are the middle occipital area, the fusiform
area, and the calcarine, respectively employed in shape perception, complex
recognition (in particular face perception), and basic visual features such as
edges and contrasts. These functions being strongly solicited are in line with
the decoder's capability to reconstruct edges, faces, and contrasts. All in
all, this suggests the possibility to probe our understanding of visual
processing in films using as a proxy the behaviour of deep learning models such
as the one proposed in this paper.

</details>


### [101] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 本文提出了一种基于解耦-耦合策略的SS-DC框架，用于解决可见光到红外（RGB-IR）领域的无监督域自适应目标检测问题，通过光谱分解和空间-光谱耦合方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将RGB域视为统一域，忽略了其内部多个子域（如白天、夜晚、雾天场景），解耦域不变（DI）和域特定（DS）特征对RGB-IR域适应有益。

Method: 设计了光谱自适应幂等解耦（SAID）模块，通过基于滤波器组的光谱处理范式和自蒸馏驱动的解耦损失实现DI和DS的准确解耦；提出空间-光谱耦合方法，联合耦合空间和光谱DI特征金字塔。

Result: 在多个RGB-IR数据集上显著提升了基线性能，优于现有UDAOD方法，包括基于FLIR-ADAS数据集的新实验协议。

Conclusion: SS-DC框架通过解耦-耦合策略有效解决了RGB-IR域适应问题，为多子域场景下的目标检测提供了新思路。

Abstract: Unsupervised domain adaptive object detection (UDAOD) from the visible domain
to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB
domain as a unified domain and neglect the multiple subdomains within it, such
as daytime, nighttime, and foggy scenes. We argue that decoupling the
domain-invariant (DI) and domain-specific (DS) features across these multiple
subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper
proposes a new SS-DC framework based on a decoupling-coupling strategy. In
terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)
module in the aspect of spectral decomposition. Due to the style and content
information being highly embedded in different frequency bands, this module can
decouple DI and DS components more accurately and interpretably. A novel filter
bank-based spectral processing paradigm and a self-distillation-driven
decoupling loss are proposed to improve the spectral domain decoupling. In
terms of coupling, a new spatial-spectral coupling method is proposed, which
realizes joint coupling through spatial and spectral DI feature pyramids.
Meanwhile, this paper introduces DS from decoupling to reduce the domain bias.
Extensive experiments demonstrate that our method can significantly improve the
baseline performance and outperform existing UDAOD methods on multiple RGB-IR
datasets, including a new experimental protocol proposed in this paper based on
the FLIR-ADAS dataset.

</details>


### [102] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 提出了一种名为DOV4MM的方法，用于验证未标记数据集在掩码模型中的所有权，解决了现有技术不适用于掩码模型的问题。


<details>
  <summary>Details</summary>
Motivation: 高质量开源数据集对深度学习发展至关重要，但面临被滥用的风险，现有验证技术主要针对监督模型和对比预训练模型，无法直接用于掩码模型。

Method: 基于掩码信息重建难度的差异，提出DOV4MM方法，通过验证可疑黑盒模型是否在目标数据集上预训练来保护数据集所有权。

Result: 在ImageNet-1K和WikiText-103上的实验表明，DOV4MM显著优于现有方法，p值远低于0.05。

Conclusion: DOV4MM为掩码模型的数据集所有权验证提供了有效解决方案，填补了该领域的空白。

Abstract: High-quality open-source datasets have emerged as a pivotal catalyst driving
the swift advancement of deep learning, while facing the looming threat of
potential exploitation. Protecting these datasets is of paramount importance
for the interests of their owners. The verification of dataset ownership has
evolved into a crucial approach in this domain; however, existing verification
techniques are predominantly tailored to supervised models and contrastive
pre-trained models, rendering them ill-suited for direct application to the
increasingly prevalent masked models. In this work, we introduce the inaugural
methodology addressing this critical, yet unresolved challenge, termed Dataset
Ownership Verification for Masked Modeling (DOV4MM). The central objective is
to ascertain whether a suspicious black-box model has been pre-trained on a
particular unlabeled dataset, thereby assisting dataset owners in safeguarding
their rights. DOV4MM is grounded in our empirical observation that when a model
is pre-trained on the target dataset, the difficulty of reconstructing masked
information within the embedding space exhibits a marked contrast to models not
pre-trained on that dataset. We validated the efficacy of DOV4MM through ten
masked image models on ImageNet-1K and four masked language models on
WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,
with a $p$-value considerably below 0.05, surpassing all prior approaches. Code
is available at https://github.com/xieyc99/DOV4MM.

</details>


### [103] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 提出了一种多变量自回归空气污染物预测模型（MVAR），解决了现有研究中单污染物预测的局限性，并提高了数据利用效率。


<details>
  <summary>Details</summary>
Motivation: 空气污染物对环境和人类健康构成威胁，准确预测污染物浓度对污染预警和政策制定至关重要。现有研究多关注单污染物预测，忽视了污染物间的相互作用和空间响应多样性。

Method: 设计了多变量自回归训练范式，支持120小时长期序列预测，并开发了气象耦合空间变换模块，结合AI气象预报数据。

Result: 实验结果表明，MVAR模型优于现有方法，验证了其架构的有效性。

Conclusion: MVAR模型为多变量空气污染物预测提供了高效解决方案，并构建了标准化数据集支持研究。

Abstract: Air pollutants pose a significant threat to the environment and human health,
thus forecasting accurate pollutant concentrations is essential for pollution
warnings and policy-making. Existing studies predominantly focus on
single-pollutant forecasting, neglecting the interactions among different
pollutants and their diverse spatial responses. To address the practical needs
of forecasting multivariate air pollutants, we propose MultiVariate
AutoRegressive air pollutants forecasting model (MVAR), which reduces the
dependency on long-time-window inputs and boosts the data utilization
efficiency. We also design the Multivariate Autoregressive Training Paradigm,
enabling MVAR to achieve 120-hour long-term sequential forecasting.
Additionally, MVAR develops Meteorological Coupled Spatial Transformer block,
enabling the flexible coupling of AI-based meteorological forecasts while
learning the interactions among pollutants and their diverse spatial responses.
As for the lack of standardized datasets in air pollutants forecasting, we
construct a comprehensive dataset covering 6 major pollutants across 75 cities
in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0
forecast data. Experimental results demonstrate that the proposed model
outperforms state-of-the-art methods and validate the effectiveness of the
proposed architecture.

</details>


### [104] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 3D-MoRe是一个新框架，通过整合多模态嵌入、跨模态交互和语言模型解码器，生成大规模3D-语言数据集，显著提升了3D场景任务的表现。


<details>
  <summary>Details</summary>
Motivation: 解决室内场景任务（如问答和密集标注）对多样化、可扩展数据的需求。

Method: 结合多模态嵌入、跨模态交互和语言模型解码器，利用ScanNet数据集和文本标注生成QA对和对象描述。

Result: 在ScanQA和ScanRefer任务中，CIDEr分数分别提升2.15%和1.84%。

Conclusion: 3D-MoRe框架有效提升了3D场景任务的表现，并将公开代码和数据集以促进社区发展。

Abstract: With the growing need for diverse and scalable data in indoor scene tasks,
such as question answering and dense captioning, we propose 3D-MoRe, a novel
paradigm designed to generate large-scale 3D-language datasets by leveraging
the strengths of foundational models. The framework integrates key components,
including multi-modal embedding, cross-modal interaction, and a language model
decoder, to process natural language instructions and 3D scene data. This
approach facilitates enhanced reasoning and response generation in complex 3D
environments. Using the ScanNet 3D scene dataset, along with text annotations
from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs
and 73,000 object descriptions across 1,513 scenes. We also employ various data
augmentation techniques and implement semantic filtering to ensure high-quality
data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms
state-of-the-art baselines, with the CIDEr score improving by 2.15\%.
Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5
by 1.84\%, highlighting its effectiveness in both tasks. Our code and generated
datasets will be publicly released to benefit the community, and both can be
accessed on the https://3D-MoRe.github.io.

</details>


### [105] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本文提出了一种名为IICMVNCD的新框架，首次在多视图数据中探索新类发现（NCD），解决了现有方法对单视图数据的依赖和伪标签不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有NCD方法主要针对单视图数据，且依赖伪标签导致性能不稳定。多视图数据（如多组学数据）的普遍性促使研究多视图NCD。

Method: 提出IICMVNCD框架，在视图内利用矩阵分解捕获已知和新类分布一致性，在视图间利用已知类视图关系指导新类聚类。

Result: 实验验证了该方法的有效性。

Conclusion: IICMVNCD在多视图NCD中表现优越，解决了现有方法的局限性。

Abstract: In this paper, we address the problem of novel class discovery (NCD), which
aims to cluster novel classes by leveraging knowledge from disjoint known
classes. While recent advances have made significant progress in this area,
existing NCD methods face two major limitations. First, they primarily focus on
single-view data (e.g., images), overlooking the increasingly common multi-view
data, such as multi-omics datasets used in disease diagnosis. Second, their
reliance on pseudo-labels to supervise novel class clustering often results in
unstable performance, as pseudo-label quality is highly sensitive to factors
such as data noise and feature dimensionality. To address these challenges, we
propose a novel framework named Intra-view and Inter-view Correlation Guided
Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to
explore NCD in multi-view setting so far. Specifically, at the intra-view
level, leveraging the distributional similarity between known and novel
classes, we employ matrix factorization to decompose features into
view-specific shared base matrices and factor matrices. The base matrices
capture distributional consistency among the two datasets, while the factor
matrices model pairwise relationships between samples. At the inter-view level,
we utilize view relationships among known classes to guide the clustering of
novel classes. This includes generating predicted labels through the weighted
fusion of factor matrices and dynamically adjusting view weights of known
classes based on the supervision loss, which are then transferred to novel
class learning. Experimental results validate the effectiveness of our proposed
approach.

</details>


### [106] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: MoViAD是一个模块化的库，旨在加速视觉异常检测（VAD）的研究和部署，提供多种场景支持和实用工具。


<details>
  <summary>Details</summary>
Motivation: 解决VAD领域因异常数据稀缺和无监督训练需求带来的挑战。

Method: 开发MoViAD库，集成先进VAD模型、训练器、数据集和实用工具，支持多种场景和部署需求。

Result: MoViAD提供高效、灵活的解决方案，支持快速部署和扩展研究。

Conclusion: MoViAD为VAD研究和应用提供了强大且易用的工具。

Abstract: VAD is a critical field in machine learning focused on identifying deviations
from normal patterns in images, often challenged by the scarcity of anomalous
data and the need for unsupervised training. To accelerate research and
deployment in this domain, we introduce MoViAD, a comprehensive and highly
modular library designed to provide fast and easy access to state-of-the-art
VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array
of scenarios, including continual, semi-supervised, few-shots, noisy, and many
more. In addition, it addresses practical deployment challenges through
dedicated Edge and IoT settings, offering optimized models and backbones, along
with quantization and compression utilities for efficient on-device execution
and distributed inference. MoViAD integrates a selection of backbones, robust
evaluation VAD metrics (pixel-level and image-level) and useful profiling tools
for efficiency analysis. The library is designed for fast, effortless
deployment, enabling machine learning engineers to easily use it for their
specific setup with custom models, datasets, and backbones. At the same time,
it offers the flexibility and extensibility researchers need to develop and
experiment with new methods.

</details>


### [107] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: MS-DETR框架通过统一学习捕捉视频中的运动-语义特征，提升视频时刻检索和高光检测任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有DETR-based联合框架未充分利用视频中时间运动和空间语义的复杂关系，MS-DETR旨在挖掘这一潜力。

Method: 提出MS-DETR框架，编码器显式建模运动和语义维度的解耦相关性，解码器利用任务间相关性进行精确定位；通过生成策略和对比去噪学习解决数据稀疏问题。

Result: 在四个MR/HD基准测试中，MS-DETR显著优于现有最优模型。

Conclusion: MS-DETR通过统一学习和数据增强策略，有效提升了视频时刻检索和高光检测的性能。

Abstract: Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint
specific moments and assess clip-wise relevance based on the text query. While
DETR-based joint frameworks have made significant strides, there remains
untapped potential in harnessing the intricate relationships between temporal
motion and spatial semantics within video content. In this paper, we propose
the Motion-Semantics DETR (MS-DETR), a framework that captures rich
motion-semantics features through unified learning for MR/HD tasks. The encoder
first explicitly models disentangled intra-modal correlations within motion and
semantics dimensions, guided by the given text queries. Subsequently, the
decoder utilizes the task-wise correlation across temporal motion and spatial
semantics dimensions to enable precise query-guided localization for MR and
refined highlight boundary delineation for HD. Furthermore, we observe the
inherent sparsity dilemma within the motion and semantics dimensions of MR/HD
datasets. To address this issue, we enrich the corpus from both dimensions by
generation strategies and propose contrastive denoising learning to ensure the
above components learn robustly and effectively. Extensive experiments on four
MR/HD benchmarks demonstrate that our method outperforms existing
state-of-the-art models by a margin. Our code is available at
https://github.com/snailma0229/MS-DETR.git.

</details>


### [108] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 本文提出了一种针对无人机视角下小型敏捷多目标（如鸟类）跟踪的冠军解决方案，结合了检测和关联的创新方法，取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决无人机视角下小型多目标跟踪的三大挑战：目标外观特征稀缺、相机与目标动态复杂、频繁遮挡和身份模糊。

Method: 采用跟踪-检测范式，提出SliceTrain训练框架增强小目标检测，设计独立于外观的跟踪器，结合运动方向维护和自适应相似度度量。

Result: 在SMOT4SB测试集上达到SO-HOTA分数55.205，验证了框架的有效性和先进性。

Conclusion: 该方法在复杂实际场景中表现出色，代码已开源。

Abstract: Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned
Aerial Vehicle (UAV) perspective is a highly challenging computer vision task.
The difficulty stems from three main sources: the extreme scarcity of target
appearance features, the complex motion entanglement caused by the combined
dynamics of the camera and the targets themselves, and the frequent occlusions
and identity ambiguity arising from dense flocking behavior. This paper details
our championship-winning solution in the MVA 2025 "Finding Birds" Small
Multi-Object Tracking Challenge (SMOT4SB), which adopts the
tracking-by-detection paradigm with targeted innovations at both the detection
and association levels. On the detection side, we propose a systematic training
enhancement framework named \textbf{SliceTrain}. This framework, through the
synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic
augmentation, effectively addresses the problem of insufficient learning for
small objects in high-resolution image training. On the tracking side, we
designed a robust tracker that is completely independent of appearance
information. By integrating a \textbf{motion direction maintenance (EMA)}
mechanism and an \textbf{adaptive similarity metric} combining \textbf{bounding
box expansion and distance penalty} into the OC-SORT framework, our tracker can
stably handle irregular motion and maintain target identities. Our method
achieves state-of-the-art performance on the SMOT4SB public test set, reaching
an SO-HOTA score of \textbf{55.205}, which fully validates the effectiveness
and advancement of our framework in solving complex real-world SMOT problems.
The source code will be made available at
https://github.com/Salvatore-Love/YOLOv8-SMOT.

</details>


### [109] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出了一种基于稀疏视图输入的车辆3D重建方法，结合深度图和鲁棒的姿态估计架构，改进了高斯泼溅技术，并在多个基准测试中取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如NeRF和高斯泼溅依赖密集输入视图，限制了实际应用。本文旨在解决稀疏视图输入下的车辆重建问题。

Method: 整合选择性光度损失和高置信度像素，采用DUSt3R架构改进相机姿态估计，并构建了包含合成和真实公共交通工具的数据集。

Result: 实验结果表明，该方法在多个基准测试中表现最优，能在输入受限条件下实现高质量重建。

Conclusion: 该方法显著提升了稀疏视图输入下的车辆3D重建质量，具有广泛的实际应用潜力。

Abstract: Accurate 3D reconstruction of vehicles is vital for applications such as
vehicle inspection, predictive maintenance, and urban planning. Existing
methods like Neural Radiance Fields and Gaussian Splatting have shown
impressive results but remain limited by their reliance on dense input views,
which hinders real-world applicability. This paper addresses the challenge of
reconstructing vehicles from sparse-view inputs, leveraging depth maps and a
robust pose estimation architecture to synthesize novel views and augment
training data. Specifically, we enhance Gaussian Splatting by integrating a
selective photometric loss, applied only to high-confidence pixels, and
replacing standard Structure-from-Motion pipelines with the DUSt3R architecture
to improve camera pose estimation. Furthermore, we present a novel dataset
featuring both synthetic and real-world public transportation vehicles,
enabling extensive evaluation of our approach. Experimental results demonstrate
state-of-the-art performance across multiple benchmarks, showcasing the
method's ability to achieve high-quality reconstructions even under constrained
input conditions.

</details>


### [110] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的阴影生成方法DeepShade，通过模拟和卫星图像结合的数据集，改进了阴影预测，用于极端高温天气下的路径规划。


<details>
  <summary>Details</summary>
Motivation: 全球变暖加剧，热浪对公共健康构成威胁，但现有路径规划系统缺乏阴影信息。论文旨在解决阴影估计的难题。

Method: 构建了包含多样地理区域的模拟阴影数据集，并提出基于扩散模型的DeepShade，结合RGB和Canny边缘层，利用对比学习捕捉阴影时间变化。

Result: DeepShade在生成阴影图像方面表现优异，并成功应用于亚利桑那州坦佩市的路径规划中。

Conclusion: 该研究为极端高温天气下的城市规划提供了参考，具有潜在的实际应用价值。

Abstract: Heatwaves pose a significant threat to public health, especially as global
warming intensifies. However, current routing systems (e.g., online maps) fail
to incorporate shade information due to the difficulty of estimating shades
directly from noisy satellite imagery and the limited availability of training
data for generative models. In this paper, we address these challenges through
two main contributions. First, we build an extensive dataset covering diverse
longitude-latitude regions, varying levels of building density, and different
urban layouts. Leveraging Blender-based 3D simulations alongside building
outlines, we capture building shadows under various solar zenith angles
throughout the year and at different times of day. These simulated shadows are
aligned with satellite images, providing a rich resource for learning shade
patterns. Second, we propose the DeepShade, a diffusion-based model designed to
learn and synthesize shade variations over time. It emphasizes the nuance of
edge features by jointly considering RGB with the Canny edge layer, and
incorporates contrastive learning to capture the temporal change rules of
shade. Then, by conditioning on textual descriptions of known conditions (e.g.,
time of day, solar angles), our framework provides improved performance in
generating shade images. We demonstrate the utility of our approach by using
our shade predictions to calculate shade ratios for real-world route planning
in Tempe, Arizona. We believe this work will benefit society by providing a
reference for urban planning in extreme heat weather and its potential
practical applications in the environment.

</details>


### [111] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入OoD数据监督，解决了医学图像分割中的误分类问题，无需外部数据或额外标注，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割网络在有限和不完美的数据集上容易发生前景与背景的误分类，需要一种无需额外资源的方法来改善。

Method: 提出Med-OoD框架，利用OoD数据监督，无需外部数据、特征正则化目标或额外标注，可直接集成到现有分割网络中。

Result: 在Lizard数据集上显著减少了误分类，性能大幅提升；仅使用OoD数据训练的网络也达到了76.1% mIoU。

Conclusion: Med-OoD展示了OoD数据在医学图像分割中的潜力，为未来研究提供了新思路。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [112] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 提出一种基于特征空间结构特性的对抗性人脸生成方法，无需迭代优化，仅需少量查询即可高成功率攻击人脸识别系统。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统（FRSs）的对抗性攻击对安全和隐私构成威胁，现有方法依赖迭代优化或迁移性，效率低且不实用。

Method: 利用FRS特征空间中相同属性个体形成的子空间，生成视觉差异大但被识别为目标身份的对抗性人脸。

Result: 仅需100张人脸图像的非适应性查询，对AWS CompareFaces API的成功率超过93%。

Conclusion: 该方法高效且灵活，能生成具有特定属性的对抗性人脸，无需依赖迁移性或开源模型。

Abstract: Adversarial attacks on face recognition systems (FRSs) pose serious security
and privacy threats, especially when these systems are used for identity
verification. In this paper, we propose a novel method for generating
adversarial faces-synthetic facial images that are visually distinct yet
recognized as a target identity by the FRS. Unlike iterative optimization-based
approaches (e.g., gradient descent or other iterative solvers), our method
leverages the structural characteristics of the FRS feature space. We figure
out that individuals sharing the same attribute (e.g., gender or race) form an
attributed subsphere. By utilizing such subspheres, our method achieves both
non-adaptiveness and a remarkably small number of queries. This eliminates the
need for relying on transferability and open-source surrogate models, which
have been a typical strategy when repeated adaptive queries to commercial FRSs
are impossible. Despite requiring only a single non-adaptive query consisting
of 100 face images, our method achieves a high success rate of over 93% against
AWS's CompareFaces API at its default threshold. Furthermore, unlike many
existing attacks that perturb a given image, our method can deliberately
produce adversarial faces that impersonate the target identity while exhibiting
high-level attributes chosen by the adversary.

</details>


### [113] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter是一种基于扩散模型的实时动态驾驶场景重建方法，解决了现有方法在视角偏离输入轨迹时的退化问题，并在速度、质量和资源效率上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 动态驾驶场景重建在数字孪生系统和自动驾驶模拟中非常重要，但现有方法在视角偏离时会出现背景和车辆模型退化的问题，且存在不一致性、变形和耗时等限制。

Method: 提出LidarPainter，一种一步扩散模型，从稀疏LiDAR条件和有伪影的渲染中实时恢复一致的驾驶视图，支持高保真车道变换。

Result: 实验表明，LidarPainter在速度、质量和资源效率上优于现有方法，比StreetCrafter快7倍，仅需五分之一的GPU内存，并支持基于文本提示的风格化生成。

Conclusion: LidarPainter在动态驾驶场景重建中表现出色，支持实时高保真重建和风格化扩展。

Abstract: Dynamic driving scene reconstruction is of great importance in fields like
digital twin system and autonomous driving simulation. However, unacceptable
degradation occurs when the view deviates from the input trajectory, leading to
corrupted background and vehicle models. To improve reconstruction quality on
novel trajectory, existing methods are subject to various limitations including
inconsistency, deformation, and time consumption. This paper proposes
LidarPainter, a one-step diffusion model that recovers consistent driving views
from sparse LiDAR condition and artifact-corrupted renderings in real-time,
enabling high-fidelity lane shifts in driving scene reconstruction. Extensive
experiments show that LidarPainter outperforms state-of-the-art methods in
speed, quality and resource efficiency, specifically 7 x faster than
StreetCrafter with only one fifth of GPU memory required. LidarPainter also
supports stylized generation using text prompts such as "foggy" and "night",
allowing for a diverse expansion of the existing asset library.

</details>


### [114] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: OVIGo-3DHSG是一种基于3D分层场景图的开放词汇室内对象定位方法，结合大型语言模型进行多步推理，提高了空间上下文理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决复杂室内环境中对象定位和空间推理的挑战，利用分层场景图和开放词汇基础模型提升语义和几何准确性。

Method: 通过RGB-D帧序列构建分层场景图，结合大型语言模型进行多步推理，利用层间和层内连接增强空间上下文理解。

Result: 在Habitat Matterport 3D多楼层场景中表现出高效的场景理解和鲁棒的对象定位能力，优于现有方法。

Conclusion: OVIGo-3DHSG在需要空间推理和室内环境理解的应用中具有强大潜力。

Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects
using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor
environment over a Hierarchical Scene Graph derived from sequences of RGB-D
frames utilizing a set of open-vocabulary foundation models and sensor data
processing. The hierarchical representation explicitly models spatial relations
across floors, rooms, locations, and objects. To effectively address complex
queries involving spatial reference to other objects, we integrate the
hierarchical scene graph with a Large Language Model for multistep reasoning.
This integration leverages inter-layer (e.g., room-to-object) and intra-layer
(e.g., object-to-object) connections, enhancing spatial contextual
understanding. We investigate the semantic and geometry accuracy of
hierarchical representation on Habitat Matterport 3D Semantic multi-floor
scenes. Our approach demonstrates efficient scene comprehension and robust
object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates
strong potential for applications requiring spatial reasoning and understanding
of indoor environments. Related materials can be found at
https://github.com/linukc/OVIGo-3DHSG.

</details>


### [115] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: BSPF-ViT通过联合优化Q/K令牌的剪枝和融合，解决了ViT计算成本高的问题，同时提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: ViT的高计算成本限制了实际应用，现有方法在剪枝时忽略了令牌交互，导致性能下降。

Method: 提出Block-based Symmetric Pruning and Fusion (BSPF-ViT)，联合评估令牌及其邻居，保留关键令牌并通过相似性融合压缩，同时利用对称注意力矩阵加速。

Result: 在DeiT-T和DeiT-S上分别提升1.3%和2.0%的ImageNet分类准确率，计算开销减少50%，速度提升40%。

Conclusion: BSPF-ViT在保持高准确性的同时显著降低了计算成本，适用于各种ViT模型。

Abstract: Vision Transformer (ViT) has achieved impressive results across various
vision tasks, yet its high computational cost limits practical applications.
Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning
unimportant tokens. However, these techniques often sacrifice accuracy by
independently pruning query (Q) and key (K) tokens, leading to performance
degradation due to overlooked token interactions. To address this limitation,
we introduce a novel {\bf Block-based Symmetric Pruning and Fusion} for
efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.
Unlike previous methods that consider only a single direction, our approach
evaluates each token and its neighbors to decide which tokens to retain by
taking token interaction into account. The retained tokens are compressed
through a similarity fusion step, preserving key information while reducing
computational costs. The shared weights of Q/K tokens create a symmetric
attention matrix, allowing pruning only the upper triangular part for speed up.
BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning
levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%
on DeiT-S, while reducing computational overhead by 50%. It achieves 40%
speedup with improved accuracy across various ViTs.

</details>


### [116] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种结合双边网格和MLP的BPAM框架，用于图像增强，解决了现有方法的线性和全局参数限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有双边网格方法仅支持线性变换，而传统MLP方法无法处理局部变化，限制了复杂颜色关系的建模能力。

Method: 通过生成包含MLP参数的双边网格，动态为每个像素分配独特的MLP参数，并采用网格分解策略和指导图优化参数生成。

Result: 在公开数据集上，BPAM框架在性能和实时处理能力上均优于现有方法。

Conclusion: BPAM框架成功结合了双边网格的空间建模能力和MLP的非线性映射能力，为图像增强提供了高效解决方案。

Abstract: Deep learning-based bilateral grid processing has emerged as a promising
solution for image enhancement, inherently encoding spatial and intensity
information while enabling efficient full-resolution processing through slicing
operations. However, existing approaches are limited to linear affine
transformations, hindering their ability to model complex color relationships.
Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,
traditional MLP-based methods employ globally shared parameters, which is hard
to deal with localized variations. To overcome these dual challenges, we
propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)
framework. Our approach synergizes the spatial modeling of bilateral grids with
the non-linear capabilities of MLPs. Specifically, we generate bilateral grids
containing MLP parameters, where each pixel dynamically retrieves its unique
transformation parameters and obtain a distinct MLP for color mapping based on
spatial coordinates and intensity values. In addition, we propose a novel grid
decomposition strategy that categorizes MLP parameters into distinct types
stored in separate subgrids. Multi-channel guidance maps are used to extract
category-specific parameters from corresponding subgrids, ensuring effective
utilization of color information during slicing while guiding precise parameter
generation. Extensive experiments on public datasets demonstrate that our
method outperforms state-of-the-art methods in performance while maintaining
real-time processing capabilities.

</details>


### [117] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: AD-GS是一种自监督框架，用于从单一日志中高质量渲染驾驶场景，无需手动标注，通过动态高斯和双向时间可见性掩模实现场景分解和动态对象建模。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖昂贵的手动标注或自监督方法无法准确捕捉动态对象运动，导致渲染效果不佳。

Method: 结合局部感知B样条曲线和全局感知三角函数的学习运动模型，简化伪2D分割自动分解场景，动态高斯和双向时间可见性掩模表示对象。

Result: AD-GS在无标注方法中表现优异，甚至可与依赖标注的方法竞争。

Conclusion: AD-GS提供了一种高效且高质量的自监督渲染方案，适用于动态驾驶场景。

Abstract: Modeling and rendering dynamic urban driving scenes is crucial for
self-driving simulation. Current high-quality methods typically rely on costly
manual object tracklet annotations, while self-supervised approaches fail to
capture dynamic object motions accurately and decompose scenes properly,
resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised
framework for high-quality free-viewpoint rendering of driving scenes from a
single log. At its core is a novel learnable motion model that integrates
locality-aware B-spline curves with global-aware trigonometric functions,
enabling flexible yet precise dynamic object modeling. Rather than requiring
comprehensive semantic labeling, AD-GS automatically segments scenes into
objects and background with the simplified pseudo 2D segmentation, representing
objects using dynamic Gaussians and bidirectional temporal visibility masks.
Further, our model incorporates visibility reasoning and physically rigid
regularization to enhance robustness. Extensive evaluations demonstrate that
our annotation-free model significantly outperforms current state-of-the-art
annotation-free methods and is competitive with annotation-dependent
approaches.

</details>


### [118] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 提出了一种基于标准化流的神经网络先验方法，用于建模人体姿态分布，解决了6D旋转流形上的分布问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为启发式或表达能力有限，无法灵活建模6D旋转格式的姿态分布。

Method: 利用RealNVP学习6D旋转格式的姿态密度，通过反转Gram-Schmidt过程解决流形上的分布建模问题。

Result: 通过定性和定量评估验证了方法的有效性，并通过消融实验分析了其影响。

Conclusion: 为姿态先验在人体运动捕捉和重建中的应用提供了概率基础。

Abstract: We introduce a principled, data-driven approach for modeling a neural prior
over human body poses using normalizing flows. Unlike heuristic or
low-expressivity alternatives, our method leverages RealNVP to learn a flexible
density over poses represented in the 6D rotation format. We address the
challenge of modeling distributions on the manifold of valid 6D rotations by
inverting the Gram-Schmidt process during training, enabling stable learning
while preserving downstream compatibility with rotation-based frameworks. Our
architecture and training pipeline are framework-agnostic and easily
reproducible. We demonstrate the effectiveness of the learned prior through
both qualitative and quantitative evaluations, and we analyze its impact via
ablation studies. This work provides a sound probabilistic foundation for
integrating pose priors into human motion capture and reconstruction pipelines.

</details>


### [119] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 论文提出了一种无需预训练的高性能细粒度图像识别（FGIR）框架TGDA，通过数据感知增强和知识蒸馏实现，显著提升了低分辨率和高分辨率输入的识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有FGIR方法依赖预训练模型，限制了在资源受限环境中的适应性和任务特定架构的发展。

Method: 引入TGDA框架，结合数据感知增强和细粒度感知教师模型的弱监督，通过知识蒸馏实现从零训练。

Result: 在多个FGIR基准测试中，TGDA框架性能优于或匹配现有预训练方法，尤其在低分辨率设置下，LRNets提升精度23%，参数和计算量大幅减少。

Conclusion: TGDA为细粒度视觉系统提供了一种高效且适应性强的替代方案，减少了对预训练的依赖。

Abstract: Fine-grained image recognition (FGIR) aims to distinguish visually similar
sub-categories within a broader class, such as identifying bird species. While
most existing FGIR methods rely on backbones pretrained on large-scale datasets
like ImageNet, this dependence limits adaptability to resource-constrained
environments and hinders the development of task-specific architectures
tailored to the unique challenges of FGIR.
  In this work, we challenge the conventional reliance on pretrained models by
demonstrating that high-performance FGIR systems can be trained entirely from
scratch. We introduce a novel training framework, TGDA, that integrates
data-aware augmentation with weak supervision via a fine-grained-aware teacher
model, implemented through knowledge distillation. This framework unlocks the
design of task-specific and hardware-aware architectures, including LRNets for
low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for
efficient inference.
  Extensive experiments across three FGIR benchmarks over diverse settings
involving low-resolution and high-resolution inputs show that our method
consistently matches or surpasses state-of-the-art pretrained counterparts. In
particular, in the low-resolution setting, LRNets trained with TGDA improve
accuracy by up to 23\% over prior methods while requiring up to 20.6x less
parameters, lower FLOPs, and significantly less training data. Similarly,
ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k
while using 15.3x fewer trainable parameters and requiring orders of magnitudes
less data. These results highlight TGDA's potential as an adaptable alternative
to pretraining, paving the way for more efficient fine-grained vision systems.

</details>


### [120] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 提出了一种双集成框架，结合预训练深度学习模型和超参数优化的机器学习模型，以提高脑肿瘤分类的准确性。


<details>
  <summary>Details</summary>
Motivation: MRI诊断脑肿瘤时，人为因素可能导致误诊，需通过自动化方法提升精度。

Method: 采用预训练深度学习模型提取特征，优化机器学习分类器超参数，并进行特征和分类器的双集成。

Result: 实验表明，该方法在脑肿瘤分类上优于现有技术，超参数优化显著提升性能。

Conclusion: 双集成框架有效提高了脑肿瘤分类的准确性，为临床诊断提供了可靠工具。

Abstract: Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable
tool for detecting tumors due to its capability to produce detailed images that
reveal their presence. However, the accuracy of diagnosis can be compromised
when human specialists evaluate these images. Factors such as fatigue, limited
expertise, and insufficient image detail can lead to errors. For example, small
tumors might go unnoticed, or overlap with healthy brain regions could result
in misidentification. To address these challenges and enhance diagnostic
precision, this study proposes a novel double ensembling framework, consisting
of ensembled pre-trained deep learning (DL) models for feature extraction and
ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently
classify brain tumors. Specifically, our method includes extensive
preprocessing and augmentation, transfer learning concepts by utilizing various
pre-trained deep convolutional neural networks and vision transformer networks
to extract deep features from brain MRI, and fine-tune hyperparameters of ML
classifiers. Our experiments utilized three different publicly available Kaggle
MRI brain tumor datasets to evaluate the pre-trained DL feature extractor
models, ML classifiers, and the effectiveness of an ensemble of deep features
along with an ensemble of ML classifiers for brain tumor classification. Our
results indicate that the proposed feature fusion and classifier fusion improve
upon the state of the art, with hyperparameter fine-tuning providing a
significant enhancement over the ensemble method. Additionally, we present an
ablation study to illustrate how each component contributes to accurate brain
tumor classification.

</details>


### [121] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 提出一种基于小波变换的低光立体图像增强方法，通过特征空间解耦解决现有方法特征纠缠和黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 低光图像存在复杂退化，现有方法将所有退化因素编码在单一潜在空间中，导致特征高度纠缠和黑盒特性。

Method: 利用小波变换将特征空间分解为低频分支（用于光照调整）和多个高频分支（用于纹理增强），并设计高频引导的跨视图交互模块（HF-CIM）和细节纹理增强模块（DTEM）。

Result: 在真实和合成图像上的实验表明，该方法在光照调整和高频信息恢复方面具有显著优势。

Conclusion: 该方法通过特征空间解耦和高频引导的跨视图交互，有效提升了低光立体图像的增强效果。

Abstract: Low-light images suffer from complex degradation, and existing enhancement
methods often encode all degradation factors within a single latent space. This
leads to highly entangled features and strong black-box characteristics, making
the model prone to shortcut learning. To mitigate the above issues, this paper
proposes a wavelet-based low-light stereo image enhancement method with feature
space decoupling. Our insight comes from the following findings: (1) Wavelet
transform enables the independent processing of low-frequency and
high-frequency information. (2) Illumination adjustment can be achieved by
adjusting the low-frequency component of a low-light image, extracted through
multi-level wavelet decomposition. Thus, by using wavelet transform the feature
space is decomposed into a low-frequency branch for illumination adjustment and
multiple high-frequency branches for texture enhancement. Additionally, stereo
low-light image enhancement can extract useful cues from another view to
improve enhancement. To this end, we propose a novel high-frequency guided
cross-view interaction module (HF-CIM) that operates within high-frequency
branches rather than across the entire feature space, effectively extracting
valuable image details from the other view. Furthermore, to enhance the
high-frequency information, a detail and texture enhancement module (DTEM) is
proposed based on cross-attention mechanism. The model is trained on a dataset
consisting of images with uniform illumination and images with non-uniform
illumination. Experimental results on both real and synthetic images indicate
that our algorithm offers significant advantages in light adjustment while
effectively recovering high-frequency information. The code and dataset are
publicly available at: https://github.com/Cherisherr/WDCI-Net.git.

</details>


### [122] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 论文提出了三种先进技术（Fractal Convolution、SSTF和Super Resolution）用于印度文化遗产的保护与修复，结合机器学习和计算机视觉技术，实现了高效且低成本的自动化处理。


<details>
  <summary>Details</summary>
Motivation: 现代数字化方法为文化遗产保护带来革命性变化，但印度古迹的特殊性需要针对性解决方案。

Method: 1. Fractal Convolution用于图像分割；2. SSTF结合MosaicSlice数据增强；3. Super Resolution提升图像质量。

Result: 方法实现了高精度修复和低成本自动化，平衡传统与创新。

Conclusion: 研究推动了文化遗产保护领域的高效与美学结合，为未来技术应用奠定基础。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [123] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: RODS是一种基于优化的扩散采样方法，通过几何线索检测和纠正高风险采样步骤，减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的采样过程容易因分数近似不准确而产生幻觉，需要一种无需重新训练且低成本的解决方案。

Method: 引入RODS，利用损失景观的几何线索检测和纠正高风险采样步骤，优化采样轨迹。

Result: 在多个数据集上，RODS显著提高了采样保真度和鲁棒性，检测并纠正了大量幻觉样本。

Conclusion: RODS有效减少了扩散模型中的幻觉现象，且未引入新伪影，具有实用价值。

Abstract: Diffusion models have achieved state-of-the-art performance in generative
modeling, yet their sampling procedures remain vulnerable to hallucinations,
often stemming from inaccuracies in score approximation. In this work, we
reinterpret diffusion sampling through the lens of optimization and introduce
RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that
detects and corrects high-risk sampling steps using geometric cues from the
loss landscape. RODS enforces smoother sampling trajectories and adaptively
adjusts perturbations, reducing hallucinations without retraining and at
minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands
demonstrate that RODS improves both sampling fidelity and robustness, detecting
over 70% of hallucinated samples and correcting more than 25%, all while
avoiding the introduction of new artifacts.

</details>


### [124] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: 论文提出了一种改进的视觉大语言模型（VLM）框架MGFFD-VLM，通过扩展数据集和引入新策略提升深度伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用人脸质量相关属性，且缺乏有效的训练策略，限制了伪造检测的准确性和解释性。

Method: 扩展了VQA数据集为DD-VQA+，提出MGFFD-VLM框架，结合属性驱动的混合LoRA策略、多粒度提示学习和伪造感知训练策略。

Result: 实验表明，该方法在文本伪造判断和分析中优于现有方法，准确性更高。

Conclusion: MGFFD-VLM通过新策略和扩展数据集显著提升了伪造检测的性能和解释性。

Abstract: Recent studies have utilized visual large language models (VLMs) to answer
not only "Is this face a forgery?" but also "Why is the face a forgery?" These
studies introduced forgery-related attributes, such as forgery location and
type, to construct deepfake VQA datasets and train VLMs, achieving high
accuracy while providing human-understandable explanatory text descriptions.
However, these methods still have limitations. For example, they do not fully
leverage face quality-related attributes, which are often abnormal in forged
faces, and they lack effective training strategies for forgery-aware VLMs. In
this paper, we extend the VQA dataset to create DD-VQA+, which features a
richer set of attributes and a more diverse range of samples. Furthermore, we
introduce a novel forgery detection framework, MGFFD-VLM, which integrates an
Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual
Large Language Models (VLMs). Additionally, our framework incorporates
Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By
transforming classification and forgery segmentation results into prompts, our
method not only improves forgery classification but also enhances
interpretability. To further boost detection performance, we design multiple
forgery-related auxiliary losses. Experimental results demonstrate that our
approach surpasses existing methods in both text-based forgery judgment and
analysis, achieving superior accuracy.

</details>


### [125] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 论文提出了一种基于生成式文本到图像扩散模型的短语定位方法，在医学影像中通过临床报告实现疾病定位，性能优于当前最先进的判别式方法。


<details>
  <summary>Details</summary>
Motivation: 探索生成式模型在医学影像短语定位任务中的潜力，以提升疾病定位的准确性和可解释性。

Method: 使用跨注意力图的生成式扩散模型，结合领域特定语言模型（如CXR-BERT）进行微调，并提出双模态偏置合并（BBM）后处理技术优化定位结果。

Result: 该方法在零样本短语定位任务中表现优异，mIoU分数是当前判别式方法的两倍。

Conclusion: 生成式模型在医学影像短语定位任务中具有显著优势，为临床应用提供了更鲁棒和可解释的解决方案。

Abstract: Phrase grounding, i.e., mapping natural language phrases to specific image
regions, holds significant potential for disease localization in medical
imaging through clinical reports. While current state-of-the-art methods rely
on discriminative, self-supervised contrastive models, we demonstrate that
generative text-to-image diffusion models, leveraging cross-attention maps, can
achieve superior zero-shot phrase grounding performance. Contrary to prior
assumptions, we show that fine-tuning diffusion models with a frozen,
domain-specific language model, such as CXR-BERT, substantially outperforms
domain-agnostic counterparts. This setup achieves remarkable improvements, with
mIoU scores doubling those of current discriminative methods. These findings
highlight the underexplored potential of generative models for phrase grounding
tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),
a novel post-processing technique that aligns text and image biases to identify
regions of high certainty. BBM refines cross-attention maps, achieving even
greater localization accuracy. Our results establish generative approaches as a
more effective paradigm for phrase grounding in the medical imaging domain,
paving the way for more robust and interpretable applications in clinical
practice. The source code and model weights are available at
https://github.com/Felix-012/generate_to_ground.

</details>


### [126] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 论文提出了一种自动识别和分割静态健身技能视频的方法，并创建了一个标注数据集，初步验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 健身技能评估需要自动化工具辅助训练和比赛评分，但目前缺乏针对静态技能时间分割的研究。

Method: 构建了一个标注视频数据集，并提出了基线方法进行技能时间分割。

Result: 结果表明该方法可行，但仍有改进空间。

Conclusion: 研究为健身技能自动化评估提供了初步基础，未来可进一步优化。

Abstract: Calisthenics is a fast-growing bodyweight discipline that consists of
different categories, one of which is focused on skills. Skills in calisthenics
encompass both static and dynamic elements performed by athletes. The
evaluation of static skills is based on their difficulty level and the duration
of the hold. Automated tools able to recognize isometric skills from a video by
segmenting them to estimate their duration would be desirable to assist
athletes in their training and judges during competitions. Although the video
understanding literature on action recognition through body pose analysis is
rich, no previous work has specifically addressed the problem of calisthenics
skill temporal video segmentation. This study aims to provide an initial step
towards the implementation of automated tools within the field of Calisthenics.
To advance knowledge in this context, we propose a dataset of video footage of
static calisthenics skills performed by athletes. Each video is annotated with
a temporal segmentation which determines the extent of each skill. We hence
report the results of a baseline approach to address the problem of skill
temporal segmentation on the proposed dataset. The results highlight the
feasibility of the proposed problem, while there is still room for improvement.

</details>


### [127] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 比较Keras、PyTorch和JAX在医学图像分类任务中的性能，使用PathMNIST数据集评估训练效率、分类准确性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习框架在医学图像分类中广泛应用，但它们在性能上的比较研究不足。

Method: 通过CNN实现，使用PathMNIST数据集评估不同框架的训练效率、分类准确性和推理速度。

Result: 研究揭示了计算速度与模型准确性之间的权衡。

Conclusion: 为医学图像分析的研究者和从业者提供了有价值的参考。

Abstract: Deep learning has significantly advanced the field of medical image
classification, particularly with the adoption of Convolutional Neural Networks
(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer
unique advantages in model development and deployment. However, their
comparative performance in medical imaging tasks remains underexplored. This
study presents a comprehensive analysis of CNN implementations across these
frameworks, using the PathMNIST dataset as a benchmark. We evaluate training
efficiency, classification accuracy and inference speed to assess their
suitability for real-world applications. Our findings highlight the trade-offs
between computational speed and model accuracy, offering valuable insights for
researchers and practitioners in medical image analysis.

</details>


### [128] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 该研究开发了一种基于深度学习的模型，利用出生24小时内的胸部X光片预测极低出生体重婴儿的支气管肺发育不良（BPD）结局，结果显示其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: BPD是一种常见的慢性肺部疾病，预防性干预可能带来严重风险，因此早期预测至关重要。常规的胸部X光片可作为非侵入性预测工具。

Method: 研究使用163名极低出生体重婴儿的胸部X光片，微调了预训练的ResNet-50模型，采用渐进式层冻结和CutMix增强技术。

Result: 最佳模型的AUROC为0.78，平衡准确率为0.69，F1分数为0.67，显著优于传统方法。

Conclusion: 研究表明，领域特定的预训练结合渐进式冻结和线性探测，能够高效预测BPD结局，适合临床推广。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


### [129] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为FADE的概念擦除方法，用于文本到图像扩散模型，以移除敏感概念，同时保持模型生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面表现出色，但也存在隐私和公平性问题，如记忆敏感概念或延续偏见。

Method: FADE结合轨迹感知微调策略和对抗目标，确保概念被可靠移除且模型保真度不受损。

Result: FADE在概念移除和图像质量上优于现有方法，性能提升5-10%。

Conclusion: FADE为安全公平的生成建模设定了新标准，无需从头训练即可移除指定概念。

Abstract: Diffusion models have demonstrated remarkable image generation capabilities,
but also pose risks in privacy and fairness by memorizing sensitive concepts or
perpetuating biases. We propose a novel \textbf{concept erasure} method for
text-to-image diffusion models, designed to remove specified concepts (e.g., a
private individual or a harmful stereotype) from the model's generative
repertoire. Our method, termed \textbf{FADE} (Fair Adversarial Diffusion
Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial
objective to ensure the concept is reliably removed while preserving overall
model fidelity. Theoretically, we prove a formal guarantee that our approach
minimizes the mutual information between the erased concept and the model's
outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable
Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,
explicit content, and style erasure tasks from MACE). FADE achieves
state-of-the-art concept removal performance, surpassing recent baselines like
ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.
Notably, FADE improves the harmonic mean of concept removal and fidelity by
5--10\% over the best prior method. We also conduct an ablation study to
validate each component of FADE, confirming that our adversarial and
trajectory-preserving objectives each contribute to its superior performance.
Our work sets a new standard for safe and fair generative modeling by
unlearning specified concepts without retraining from scratch.

</details>


### [130] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 提出了一种基于深度估计和运动员区域检索的体操技能分类方法，避免了传统姿态估计的高计算成本，显著提升了效率和分类精度。


<details>
  <summary>Details</summary>
Motivation: 传统体操技能识别方法依赖姿态估计，计算成本高且复杂，限制了实时应用和移动设备的适用性。

Method: 结合Depth Anything V2进行深度估计和YOLOv10进行运动员定位，直接从图像中分割运动员区域，避免姿态估计。

Result: 方法比基于骨架的方法快38.3倍，分类精度更高（0.837 vs. 0.815）。

Conclusion: 该方法高效、灵活，适用于实时应用，未来可进一步优化和扩展。

Abstract: Calisthenics skill classification is the computer vision task of inferring
the skill performed by an athlete from images, enabling automatic performance
assessment and personalized analytics. Traditional methods for calisthenics
skill recognition are based on pose estimation methods to determine the
position of skeletal data from images, which is later fed to a classification
algorithm to infer the performed skill. Despite the progress in human pose
estimation algorithms, they still involve high computational costs, long
inference times, and complex setups, which limit the applicability of such
approaches in real-time applications or mobile devices. This work proposes a
direct approach to calisthenics skill recognition, which leverages depth
estimation and athlete patch retrieval to avoid the computationally expensive
human pose estimation module. Using Depth Anything V2 for depth estimation and
YOLOv10 for athlete localization, we segment the subject from the background
rather than relying on traditional pose estimation techniques. This strategy
increases efficiency, reduces inference time, and improves classification
accuracy. Our approach significantly outperforms skeleton-based methods,
achieving 38.3x faster inference with RGB image patches and improved
classification accuracy with depth patches (0.837 vs. 0.815). Beyond these
performance gains, the modular design of our pipeline allows for flexible
replacement of components, enabling future enhancements and adaptation to
real-world applications.

</details>


### [131] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: 本文提出离散潜在码（DLC）作为扩散模型的输入条件表示，通过自监督学习目标训练，提升生成保真度、易生成性和组合性，实现超出训练分布的样本生成。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型成功的关键在于输入条件表示，理想表示应提升样本保真度、易生成且具有组合性。

Method: 引入离散潜在码（DLC），一种基于Simplicial Embeddings的自监督学习表示，用于扩散模型的条件输入。

Result: DLC提升了无条件图像生成的保真度，在ImageNet上达到新SOTA，并能生成超出训练分布的样本。

Conclusion: DLC为扩散模型提供了一种高效、组合性强的条件表示，支持文本到图像生成等应用。

Abstract: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.

</details>


### [132] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: KeyDiff3D是一个无监督的单目3D关键点估计框架，利用预训练的多视角扩散模型生成几何先验，仅需单视角图像即可准确预测3D关键点。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的手动标注或多视角校准图像，而KeyDiff3D通过单视角图像实现3D关键点估计，降低成本。

Method: 利用预训练的多视角扩散模型生成多视角图像作为监督信号，提取2D多视角特征并构建3D特征体积，将隐式3D先验转化为显式3D特征。

Result: 在Human3.6M、Stanford Dogs等数据集上验证了方法的准确性、泛化能力，并能对扩散模型生成的3D对象进行操控。

Conclusion: KeyDiff3D通过扩散模型的几何先验，实现了高效、低成本的无监督3D关键点估计，并支持3D对象操控。

Abstract: This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D
keypoints estimation that accurately predicts 3D keypoints from a single image.
While previous methods rely on manual annotations or calibrated multi-view
images, both of which are expensive to collect, our method enables monocular 3D
keypoints estimation using only a collection of single-view images. To achieve
this, we leverage powerful geometric priors embedded in a pretrained multi-view
diffusion model. In our framework, this model generates multi-view images from
a single image, serving as a supervision signal to provide 3D geometric cues to
our model. We also use the diffusion model as a powerful 2D multi-view feature
extractor and construct 3D feature volumes from its intermediate
representations. This transforms implicit 3D priors learned by the diffusion
model into explicit 3D features. Beyond accurate keypoints estimation, we
further introduce a pipeline that enables manipulation of 3D objects generated
by the diffusion model. Experimental results on diverse aspects and datasets,
including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain
datasets, highlight the effectiveness of our method in terms of accuracy,
generalization, and its ability to enable manipulation of 3D objects generated
by the diffusion model from a single image.

</details>


### [133] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 论文研究了通道知识蒸馏（CWD）和掩码生成蒸馏（MGD）在轻量级模型中的应用，以提高实时智能喷洒系统中的杂草检测性能。实验表明，CWD和MGD显著提升了模型精度，且不影响模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 杂草检测是精准农业的关键，但资源受限平台上部署高精度模型仍具挑战性，尤其是区分视觉相似的杂草种类。

Method: 使用YOLO11x作为教师模型，YOLO11n作为参考和学生模型，通过CWD和MGD从教师模型向学生模型传递知识。

Result: 在真实数据集上，CWD和MGD分别提高了2.5%和1.9%的mAP50，且验证了在嵌入式设备上的实时部署可行性。

Conclusion: CWD和MGD是提高深度学习杂草检测精度的高效实用方法，适用于精准农业和植物表型分析。

Abstract: Weed detection is a critical component of precision agriculture, facilitating
targeted herbicide application and reducing environmental impact. However,
deploying accurate object detection models on resource-limited platforms
remains challenging, particularly when differentiating visually similar weed
species commonly encountered in plant phenotyping applications. In this work,
we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative
Distillation (MGD) to enhance the performance of lightweight models for
real-time smart spraying systems. Utilizing YOLO11x as the teacher model and
YOLO11n as both reference and student, both CWD and MGD effectively transfer
knowledge from the teacher to the student model. Our experiments, conducted on
a real-world dataset comprising sugar beet crops and four weed types (Cirsium,
Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50
across all classes. The distilled CWD student model achieves a notable
improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without
increasing model complexity. Additionally, we validate real-time deployment
feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and
Raspberry Pi 5 embedded devices, performing five independent runs to evaluate
performance stability across random seeds. These findings confirm CWD and MGD
as an effective, efficient, and practical approach for improving deep
learning-based weed detection accuracy in precision agriculture and plant
phenotyping scenarios.

</details>


### [134] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: Cluster Contrast (CueCo) 是一种结合对比学习和聚类方法的新型无监督视觉表示学习方法，通过同时分散和对齐特征表示，显著提升了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 近年来，对比学习和聚类方法在无监督视觉表示学习中取得了显著进展，但如何结合两者的优势仍是一个挑战。CueCo旨在通过同时优化对比损失和聚类目标，提升特征表示的质量。

Method: CueCo使用两个神经网络（查询网络和关键网络），关键网络通过查询输出的慢速移动平均更新。方法结合对比损失（增强类间分离）和聚类目标（提升类内紧凑性）。

Result: 在CIFAR-10、CIFAR-100和ImageNet-100上，CueCo分别达到91.40%、68.56%和78.65%的top-1分类准确率（基于ResNet-18的线性评估）。

Conclusion: CueCo通过整合对比学习和聚类，为无监督视觉表示学习开辟了新方向，显著提升了性能。

Abstract: We introduce Cluster Contrast (CueCo), a novel approach to unsupervised
visual representation learning that effectively combines the strengths of
contrastive learning and clustering methods. Inspired by recent advancements,
CueCo is designed to simultaneously scatter and align feature representations
within the feature space. This method utilizes two neural networks, a query and
a key, where the key network is updated through a slow-moving average of the
query outputs. CueCo employs a contrastive loss to push dissimilar features
apart, enhancing inter-class separation, and a clustering objective to pull
together features of the same cluster, promoting intra-class compactness. Our
method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on
CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18
backbone. By integrating contrastive learning with clustering, CueCo sets a new
direction for advancing unsupervised visual representation learning.

</details>


### [135] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为Text-SemiSeg的文本驱动多平面视觉交互框架，用于半监督医学图像分割，通过文本增强视觉语义嵌入，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像标注成本高的问题，利用文本信息增强视觉语义理解，填补3D医学影像任务中文本数据利用的研究空白。

Method: 框架包含三个模块：文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA），分别实现文本-视觉交互、跨模态语义对齐和减少标注与未标注数据的分布差异。

Result: 在三个公开数据集上的实验表明，模型能有效利用文本信息增强视觉特征，性能优于其他方法。

Conclusion: Text-SemiSeg通过文本驱动的方法提升了半监督医学图像分割的效果，为相关任务提供了新思路。

Abstract: Semi-supervised medical image segmentation is a crucial technique for
alleviating the high cost of data annotation. When labeled data is limited,
textual information can provide additional context to enhance visual semantic
understanding. However, research exploring the use of textual data to enhance
visual semantic embeddings in 3D medical imaging tasks remains scarce. In this
paper, we propose a novel text-driven multiplanar visual interaction framework
for semi-supervised medical image segmentation (termed Text-SemiSeg), which
consists of three main modules: Text-enhanced Multiplanar Representation (TMR),
Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation
(DCA). Specifically, TMR facilitates text-visual interaction through planar
mapping, thereby enhancing the category awareness of visual features. CSA
performs cross-modal semantic alignment between the text features with
introduced learnable variables and the intermediate layer of visual features.
DCA reduces the distribution discrepancy between labeled and unlabeled data
through their interaction, thus improving the model's robustness. Finally,
experiments on three public datasets demonstrate that our model effectively
enhances visual features with textual information and outperforms other
methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.

</details>


### [136] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: 论文提出了两个视觉目标检测基准OD-VIRAT Large和OD-VIRAT Tiny，用于评估复杂环境下的人体监测算法，并测试了多种先进目标检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的人体监测系统需要多样化和具有挑战性的数据集，以全面评估模型性能。

Method: 创建了两个包含丰富标注的视觉目标检测基准，并测试了RETMDET、YOLOX等先进模型的性能。

Result: OD-VIRAT Large包含8.7百万标注实例，OD-VIRAT Tiny包含288,901标注实例，测试了多种模型在复杂条件下的表现。

Conclusion: 该研究为开发更高效和鲁棒的目标检测架构提供了基础，并提供了对模型性能的深入见解。

Abstract: Realistic human surveillance datasets are crucial for training and evaluating
computer vision models under real-world conditions, facilitating the
development of robust algorithms for human and human-interacting object
detection in complex environments. These datasets need to offer diverse and
challenging data to enable a comprehensive assessment of model performance and
the creation of more reliable surveillance systems for public safety. To this
end, we present two visual object detection benchmarks named OD-VIRAT Large and
OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance
imagery. The video sequences in both benchmarks cover 10 different scenes of
human surveillance recorded from significant height and distance. The proposed
benchmarks offer rich annotations of bounding boxes and categories, where
OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and
OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also
focuses on benchmarking state-of-the-art object detection architectures,
including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object
detection-specific variant of VIRAT dataset. To the best of our knowledge, it
is the first work to examine the performance of these recently published
state-of-the-art object detection architectures on realistic surveillance
imagery under challenging conditions such as complex backgrounds, occluded
objects, and small-scale objects. The proposed benchmarking and experimental
settings will help in providing insights concerning the performance of selected
object detection models and set the base for developing more efficient and
robust object detection architectures.

</details>


### [137] [QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval](https://arxiv.org/abs/2507.12416)
*Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee*

Main category: cs.CV

TL;DR: 论文提出QuRe方法，通过硬负采样减少假阴性，提升组合图像检索（CIR）的准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有CIR方法仅关注目标图像检索，忽略其他图像的相关性，导致假阴性问题，降低用户满意度。

Method: 提出QuRe方法，优化奖励模型目标以减少假阴性，并引入硬负采样策略选择相关图像。

Result: QuRe在FashionIQ和CIRR数据集上达到最优性能，并在HP-FashionIQ数据集上最符合人类偏好。

Conclusion: QuRe有效解决了CIR中的假阴性问题，提升了检索质量和用户满意度。

Abstract: Composed Image Retrieval (CIR) retrieves relevant images based on a reference
image and accompanying text describing desired modifications. However, existing
CIR methods only focus on retrieving the target image and disregard the
relevance of other images. This limitation arises because most methods
employing contrastive learning-which treats the target image as positive and
all other images in the batch as negatives-can inadvertently include false
negatives. This may result in retrieving irrelevant images, reducing user
satisfaction even when the target image is retrieved. To address this issue, we
propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which
optimizes a reward model objective to reduce false negatives. Additionally, we
introduce a hard negative sampling strategy that selects images positioned
between two steep drops in relevance scores following the target image, to
effectively filter false negatives. In order to evaluate CIR models on their
alignment with human satisfaction, we create Human-Preference FashionIQ
(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond
target retrieval. Extensive experiments demonstrate that QuRe achieves
state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting
the strongest alignment with human preferences on the HP-FashionIQ dataset. The
source code is available at https://github.com/jackwaky/QuRe.

</details>


### [138] [InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization](https://arxiv.org/abs/2507.12420)
*Haoyuan Liu,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 提出了一种新的损失函数InterpIoU，通过插值框解决现有IoU损失的问题，并在动态调整插值系数的Dynamic InterpIoU中进一步优化。实验证明其在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有IoU损失函数在非重叠情况下不可导，且手工设计的几何惩罚对框的形状、大小和分布敏感，导致小物体检测效果不佳和框扩大问题。

Method: 提出InterpIoU，用插值框的IoU替代手工惩罚；进一步提出Dynamic InterpIoU，动态调整插值系数。

Result: 在COCO、VisDrone和PASCAL VOC等数据集上表现优于现有方法，尤其在小物体检测中效果显著。

Conclusion: InterpIoU和Dynamic InterpIoU有效解决了现有IoU损失的问题，提升了检测性能。

Abstract: Bounding box regression (BBR) is fundamental to object detection, where the
regression loss is crucial for accurate localization. Existing IoU-based losses
often incorporate handcrafted geometric penalties to address IoU's
non-differentiability in non-overlapping cases and enhance BBR performance.
However, these penalties are sensitive to box shape, size, and distribution,
often leading to suboptimal optimization for small objects and undesired
behaviors such as bounding box enlargement due to misalignment with the IoU
objective. To address these limitations, we propose InterpIoU, a novel loss
function that replaces handcrafted geometric penalties with a term based on the
IoU between interpolated boxes and the target. By using interpolated boxes to
bridge the gap between predictions and ground truth, InterpIoU provides
meaningful gradients in non-overlapping cases and inherently avoids the box
enlargement issue caused by misaligned penalties. Simulation results further
show that IoU itself serves as an ideal regression target, while existing
geometric penalties are both unnecessary and suboptimal. Building on InterpIoU,
we introduce Dynamic InterpIoU, which dynamically adjusts interpolation
coefficients based on IoU values, enhancing adaptability to scenarios with
diverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC
show that our methods consistently outperform state-of-the-art IoU-based losses
across various detection frameworks, with particularly notable improvements in
small object detection, confirming their effectiveness.

</details>


### [139] [DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition](https://arxiv.org/abs/2507.12426)
*Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级的视频焦点调制网络DVFL-Net，通过知识蒸馏和时空特征调制，在保持高性能的同时显著降低计算成本，适用于实时人类动作识别。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的视频识别模型在性能上表现出色，但其计算成本高昂，难以在设备端部署。因此，需要一种轻量化的解决方案。

Method: DVFL-Net通过知识蒸馏和时空焦点调制技术，将预训练的大型教师模型的知识压缩到小型学生模型中，并利用前向KL散度优化知识传递。

Result: 在多个基准数据集（如UCF101、Kinetics-400等）上，DVFL-Net在性能和效率之间取得了最佳平衡，表现出较低的内存占用和计算量，同时保持高精度。

Conclusion: DVFL-Net是一种高效且实用的视频识别解决方案，适用于实时人类动作识别任务。

Abstract: The landscape of video recognition has evolved significantly, shifting from
traditional Convolutional Neural Networks (CNNs) to Transformer-based
architectures for improved accuracy. While 3D CNNs have been effective at
capturing spatiotemporal dynamics, recent Transformer models leverage
self-attention to model long-range spatial and temporal dependencies. Despite
achieving state-of-the-art performance on major benchmarks, Transformers remain
computationally expensive, particularly with dense video data. To address this,
we propose a lightweight Video Focal Modulation Network, DVFL-Net, which
distills spatiotemporal knowledge from a large pre-trained teacher into a
compact nano student model, enabling efficient on-device deployment. DVFL-Net
utilizes knowledge distillation and spatial-temporal feature modulation to
significantly reduce computation while preserving high recognition performance.
We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal
focal modulation to effectively transfer both local and global context from the
Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate
DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it
against recent state-of-the-art methods in Human Action Recognition (HAR).
Additionally, we conduct a detailed ablation study analyzing the impact of
forward KL divergence. The results confirm the superiority of DVFL-Net in
achieving an optimal balance between performance and efficiency, demonstrating
lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical
solution for real-time HAR applications.

</details>


### [140] [Traffic-Aware Pedestrian Intention Prediction](https://arxiv.org/abs/2507.12433)
*Fahimeh Orvati Nia,Hai Lin*

Main category: cs.CV

TL;DR: 提出了一种结合交通信号状态的时空图卷积网络（TA-STGCN），显著提升了行人意图预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在行人意图预测中常忽略动态交通信号和场景信息，而这对自动驾驶车辆的安全导航至关重要。

Method: 通过整合动态交通信号状态和边界框大小作为关键特征，构建TA-STGCN模型，捕捉复杂城市环境中的时空依赖性。

Result: 在PIE数据集上，TA-STGCN比基线模型准确率提高了4.75%。

Conclusion: TA-STGCN通过结合交通信号信息，显著提升了行人意图预测的准确性，适用于实际应用。

Abstract: Accurate pedestrian intention estimation is crucial for the safe navigation
of autonomous vehicles (AVs) and hence attracts a lot of research attention.
However, current models often fail to adequately consider dynamic traffic
signals and contextual scene information, which are critical for real-world
applications. This paper presents a Traffic-Aware Spatio-Temporal Graph
Convolutional Network (TA-STGCN) that integrates traffic signs and their states
(Red, Yellow, Green) into pedestrian intention prediction. Our approach
introduces the integration of dynamic traffic signal states and bounding box
size as key features, allowing the model to capture both spatial and temporal
dependencies in complex urban environments. The model surpasses existing
methods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy
compared to the baseline model on the PIE dataset, demonstrating its
effectiveness in improving pedestrian intention prediction.

</details>


### [141] [Describe Anything Model for Visual Question Answering on Text-rich Images](https://arxiv.org/abs/2507.12441)
*Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DAM-QA利用区域感知视觉语言模型DAM的能力，通过多区域视图聚合答案，显著提升了文本密集图像的VQA任务性能。


<details>
  <summary>Details</summary>
Motivation: 研究假设区域级描述能力对文本密集图像的VQA任务有益，尤其是在需要细粒度文本提取的场景。

Method: 引入DAM-QA框架，通过多区域视图聚合答案，优化文本相关元素的证据识别。

Result: 在六个VQA基准测试中表现优于基线DAM，DocVQA上提升7+分，参数更少且性能接近通用VLMs。

Conclusion: DAM-QA展示了区域感知模型在文本密集VQA任务中的潜力，需高效使用和集成策略。

Abstract: Recent progress has been made in region-aware vision-language modeling,
particularly with the emergence of the Describe Anything Model (DAM). DAM is
capable of generating detailed descriptions of any specific image areas or
objects without the need for additional localized image-text alignment
supervision. We hypothesize that such region-level descriptive capability is
beneficial for the task of Visual Question Answering (VQA), especially in
challenging scenarios involving images with dense text. In such settings, the
fine-grained extraction of textual information is crucial to producing correct
answers. Motivated by this, we introduce DAM-QA, a framework with a tailored
evaluation protocol, developed to investigate and harness the region-aware
capabilities from DAM for the text-rich VQA problem that requires reasoning
over text-based information within images. DAM-QA incorporates a mechanism that
aggregates answers from multiple regional views of image content, enabling more
effective identification of evidence that may be tied to text-related elements.
Experiments on six VQA benchmarks show that our approach consistently
outperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA
also achieves the best overall performance among region-aware models with fewer
parameters, significantly narrowing the gap with strong generalist VLMs. These
results highlight the potential of DAM-like models for text-rich and broader
VQA tasks when paired with efficient usage and integration strategies. Our code
is publicly available at https://github.com/Linvyl/DAM-QA.git.

</details>


### [142] [Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)
*Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于摄像头感知和Frenet-Pure Pursuit规划的障碍物避障系统，结合YOLOv11和目标距离估计模型，在校园环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶车辆的安全性需要高效的障碍物避障系统，尤其是在复杂环境中。

Method: 使用摄像头感知模块（YOLOv11和Depth Anything V2）进行目标检测和距离估计，结合Frenet-Pure Pursuit规划策略。

Result: 系统在多样化的校园场景中表现出色，能够有效处理各种障碍物。

Conclusion: 该方法为自动驾驶车辆提供了一种高效、可靠的障碍物避障解决方案。

Abstract: Obstacle avoidance is essential for ensuring the safety of autonomous
vehicles. Accurate perception and motion planning are crucial to enabling
vehicles to navigate complex environments while avoiding collisions. In this
paper, we propose an efficient obstacle avoidance pipeline that leverages a
camera-only perception module and a Frenet-Pure Pursuit-based planning
strategy. By integrating advancements in computer vision, the system utilizes
YOLOv11 for object detection and state-of-the-art monocular depth estimation
models, such as Depth Anything V2, to estimate object distances. A comparative
analysis of these models provides valuable insights into their accuracy,
efficiency, and robustness in real-world conditions. The system is evaluated in
diverse scenarios on a university campus, demonstrating its effectiveness in
handling various obstacles and enhancing autonomous navigation. The video
presenting the results of the obstacle avoidance experiments is available at:
https://www.youtube.com/watch?v=FoXiO5S_tA8

</details>


### [143] [Mitigating Object Hallucinations via Sentence-Level Early Intervention](https://arxiv.org/abs/2507.12455)
*Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: SENTINEL框架通过句子级早期干预和领域内偏好学习，显著减少多模态大语言模型的幻觉问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在跨模态理解中表现优异，但存在幻觉问题，现有方法成本高或引入数据分布不匹配。

Method: 提出SENTINEL框架，通过迭代采样、验证和分类构建高质量偏好数据，并使用上下文感知偏好损失（C-DPO）训练模型。

Result: 实验表明，SENTINEL能将幻觉减少90%以上，并在幻觉和通用能力基准上优于现有方法。

Conclusion: SENTINEL通过早期干预和偏好学习有效解决幻觉问题，具有优越性和泛化能力。

Abstract: Multimodal large language models (MLLMs) have revolutionized cross-modal
understanding but continue to struggle with hallucinations - fabricated content
contradicting visual inputs. Existing hallucination mitigation methods either
incur prohibitive computational costs or introduce distribution mismatches
between training data and model outputs. We identify a critical insight:
hallucinations predominantly emerge at the early stages of text generation and
propagate through subsequent outputs. To address this, we propose **SENTINEL**
(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain
pr**E**ference **L**earning), a framework that eliminates dependency on human
annotations. Specifically, we first bootstrap high-quality in-domain preference
pairs by iteratively sampling model outputs, validating object existence
through cross-checking with two open-vocabulary detectors, and classifying
sentences into hallucinated/non-hallucinated categories. Subsequently, we use
context-coherent positive samples and hallucinated negative samples to build
context-aware preference data iteratively. Finally, we train models using a
context-aware preference loss (C-DPO) that emphasizes discriminative learning
at the sentence level where hallucinations initially manifest. Experimental
results show that SENTINEL can reduce hallucinations by over 90\% compared to
the original model and outperforms the previous state-of-the-art method on both
hallucination benchmarks and general capabilities benchmarks, demonstrating its
superiority and generalization ability. The models, datasets, and code are
available at https://github.com/pspdada/SENTINEL.

</details>


### [144] [Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis](https://arxiv.org/abs/2507.12461)
*Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: RadGazeIntent是一种基于深度学习的模型，旨在通过分析放射科医生的眼动数据来预测其诊断意图。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能捕捉放射科医生眼动背后的意图，而理解这种意图对医学图像解读至关重要。

Method: 采用基于Transformer的架构，处理眼动数据的时空维度，生成诊断意图的粗粒度表示。

Result: RadGazeIntent在三个意图标记数据集上表现优于基线方法，能准确预测放射科医生的检查目标。

Conclusion: RadGazeIntent成功建模了放射科医生的意图驱动行为，为医学图像分析提供了新视角。

Abstract: Radiologists rely on eye movements to navigate and interpret medical images.
A trained radiologist possesses knowledge about the potential diseases that may
be present in the images and, when searching, follows a mental checklist to
locate them using their gaze. This is a key observation, yet existing models
fail to capture the underlying intent behind each fixation. In this paper, we
introduce a deep learning-based approach, RadGazeIntent, designed to model this
behavior: having an intention to find something and actively searching for it.
Our transformer-based architecture processes both the temporal and spatial
dimensions of gaze data, transforming fine-grained fixation features into
coarse, meaningful representations of diagnostic intent to interpret
radiologists' goals. To capture the nuances of radiologists' varied
intention-driven behaviors, we process existing medical eye-tracking datasets
to create three intention-labeled subsets: RadSeq (Systematic Sequential
Search), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid
Pattern). Experimental results demonstrate RadGazeIntent's ability to predict
which findings radiologists are examining at specific moments, outperforming
baseline methods across all intention-labeled datasets.

</details>


### [145] [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462)
*Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou*

Main category: cs.CV

TL;DR: SpatialTrackerV2是一种基于单目视频的前馈3D点跟踪方法，通过统一几何、相机运动和物体运动，实现高性能跟踪。


<details>
  <summary>Details</summary>
Motivation: 超越现有基于现成组件的模块化3D跟踪方法，统一几何、相机运动和物体运动的关联。

Method: 将3D运动分解为场景几何、相机自运动和像素级物体运动，采用端到端可微分架构，支持多数据集训练。

Result: 性能优于现有3D跟踪方法30%，与领先的动态3D重建方法精度相当，但速度快50倍。

Conclusion: SpatialTrackerV2通过联合学习几何与运动，实现了高效且高精度的3D点跟踪。

Abstract: We present SpatialTrackerV2, a feed-forward 3D point tracking method for
monocular videos. Going beyond modular pipelines built on off-the-shelf
components for 3D tracking, our approach unifies the intrinsic connections
between point tracking, monocular depth, and camera pose estimation into a
high-performing and feedforward 3D point tracker. It decomposes world-space 3D
motion into scene geometry, camera ego-motion, and pixel-wise object motion,
with a fully differentiable and end-to-end architecture, allowing scalable
training across a wide range of datasets, including synthetic sequences, posed
RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and
motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms
existing 3D tracking methods by 30%, and matches the accuracy of leading
dynamic 3D reconstruction approaches while running 50$\times$ faster.

</details>


### [146] [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding](https://arxiv.org/abs/2507.12463)
*Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 提出MMHU，一个大规模的人类行为分析基准，包含丰富的注释和多任务评估。


<details>
  <summary>Details</summary>
Motivation: 理解人类行为对开发安全驾驶系统至关重要，但目前缺乏全面的评估基准。

Method: 开发了一个包含57k人类运动片段和1.73M帧的数据集，采用人机协作标注流程生成行为描述。

Result: 提供了多样化的任务基准，包括运动预测、运动生成和行为问答。

Conclusion: MMHU为自动驾驶中的人类行为理解提供了全面的评估工具。

Abstract: Humans are integral components of the transportation ecosystem, and
understanding their behaviors is crucial to facilitating the development of
safe driving systems. Although recent progress has explored various aspects of
human behavior$\unicode{x2014}$such as motion, trajectories, and
intention$\unicode{x2014}$a comprehensive benchmark for evaluating human
behavior understanding in autonomous driving remains unavailable. In this work,
we propose $\textbf{MMHU}$, a large-scale benchmark for human behavior analysis
featuring rich annotations, such as human motion and trajectories, text
description for human motions, human intention, and critical behavior labels
relevant to driving safety. Our dataset encompasses 57k human motion clips and
1.73M frames gathered from diverse sources, including established driving
datasets such as Waymo, in-the-wild videos from YouTube, and self-collected
data. A human-in-the-loop annotation pipeline is developed to generate rich
behavior captions. We provide a thorough dataset analysis and benchmark
multiple tasks$\unicode{x2014}$ranging from motion prediction to motion
generation and human behavior question answering$\unicode{x2014}$thereby
offering a broad evaluation suite. Project page :
https://MMHU-Benchmark.github.io.

</details>


### [147] [CytoSAE: Interpretable Cell Embeddings for Hematology](https://arxiv.org/abs/2507.12464)
*Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider*

Main category: cs.CV

TL;DR: 稀疏自编码器（SAEs）用于医学图像分析，提出CytoSAE模型，可识别形态学相关概念并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域缺乏解释性工具，SAEs在视觉领域的成功应用启发其在医学图像中的探索。

Method: 提出CytoSAE，基于40,000多张外周血单细胞图像训练，适用于多样化和域外数据集。

Result: CytoSAE能识别形态学相关概念，生成患者和疾病特异性概念，并在AML亚型分类任务中表现优异。

Conclusion: CytoSAE为医学图像提供可解释性工具，性能与现有技术相当，同时支持亚细胞级解释。

Abstract: Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic
interpretability of transformer-based foundation models. Very recently, SAEs
were also adopted for the visual domain, enabling the discovery of visual
concepts and their patch-wise attribution to tokens in the transformer model.
While a growing number of foundation models emerged for medical imaging, tools
for explaining their inferences are still lacking. In this work, we show the
applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder
which is trained on over 40,000 peripheral blood single-cell images. CytoSAE
generalizes to diverse and out-of-domain datasets, including bone marrow
cytology, where it identifies morphologically relevant concepts which we
validated with medical experts. Furthermore, we demonstrate scenarios in which
CytoSAE can generate patient-specific and disease-specific concepts, enabling
the detection of pathognomonic cells and localized cellular abnormalities at
the patch level. We quantified the effect of concepts on a patient-level AML
subtype classification task and show that CytoSAE concepts reach performance
comparable to the state-of-the-art, while offering explainability on the
sub-cellular level. Source code and model weights are available at
https://github.com/dynamical-inference/cytosae.

</details>


### [148] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
*Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出PhysX，一种物理基础的3D资产生成范式，包括数据集PhysXNet和生成框架PhysXGen，填补了现有3D生成忽略物理属性的空白。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型主要关注几何和纹理，忽略了物理属性，限制了其在仿真和具身AI等物理领域的应用。

Method: 1) 构建PhysXNet数据集，标注物理属性；2) 提出PhysXGen框架，通过双分支架构结合3D结构与物理知识。

Result: 实验验证了PhysXGen的优越性能和泛化能力。

Conclusion: PhysX为生成物理AI提供了新方向，代码和数据将开源以促进未来研究。

Abstract: 3D modeling is moving from virtual to physical. Existing 3D generation
primarily emphasizes geometries and textures while neglecting physical-grounded
modeling. Consequently, despite the rapid development of 3D generative models,
the synthesized 3D assets often overlook rich and important physical
properties, hampering their real-world application in physical domains like
simulation and embodied AI. As an initial attempt to address this challenge, we
propose \textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset
generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we
present PhysXNet - the first physics-grounded 3D dataset systematically
annotated across five foundational dimensions: absolute scale, material,
affordance, kinematics, and function description. In particular, we devise a
scalable human-in-the-loop annotation pipeline based on vision-language models,
which enables efficient creation of physics-first assets from raw 3D assets.2)
Furthermore, we propose \textbf{PhysXGen}, a feed-forward framework for
physics-grounded image-to-3D asset generation, injecting physical knowledge
into the pre-trained 3D structural space. Specifically, PhysXGen employs a
dual-branch architecture to explicitly model the latent correlations between 3D
structures and physical properties, thereby producing 3D assets with plausible
physical predictions while preserving the native geometry quality. Extensive
experiments validate the superior performance and promising generalization
capability of our framework. All the code, data, and models will be released to
facilitate future research in generative physical AI.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics](https://arxiv.org/abs/2507.11660)
*Joao F. Rocha,Ke Xu,Xingzhi Sun,Ananya Krishna,Dhananjay Bhaskar,Blanche Mongeon,Morgan Craig,Mark Gerstein,Smita Krishnaswamy*

Main category: cs.LG

TL;DR: 论文提出了一种结合深度学习和基于代理的建模（ABM）的方法STAGED，用于模拟细胞间通信及其对细胞内基因调控网络的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法将细胞视为独立数据点，忽略了细胞间动态相互作用，而传统ABM依赖人工规则。STAGED旨在通过数据驱动方法解决这一问题。

Method: STAGED结合ABM与深度学习，使用图ODE网络（GDEs）和注意力机制动态学习基因间相互作用强度。

Result: 模型能够捕捉细胞间和细胞内相互作用，更准确地模拟细胞动态。

Conclusion: STAGED为复杂细胞动态的建模提供了自适应且准确的数据驱动方法。

Abstract: The advent of single-cell technology has significantly improved our
understanding of cellular states and subpopulations in various tissues under
normal and diseased conditions by employing data-driven approaches such as
clustering and trajectory inference. However, these methods consider cells as
independent data points of population distributions. With spatial
transcriptomics, we can represent cellular organization, along with dynamic
cell-cell interactions that lead to changes in cell state. Still, key
computational advances are necessary to enable the data-driven learning of such
complex interactive cellular dynamics. While agent-based modeling (ABM)
provides a powerful framework, traditional approaches rely on handcrafted rules
derived from domain knowledge rather than data-driven approaches. To address
this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)
integrating ABM with deep learning to model intercellular communication, and
its effect on the intracellular gene regulatory network. Using graph ODE
networks (GDEs) with shared weights per cell type, our approach represents
genes as vertices and interactions as directed edges, dynamically learning
their strengths through a designed attention mechanism. Trained to match
continuous trajectories of simulated as well as inferred trajectories from
spatial transcriptomics data, the model captures both intercellular and
intracellular interactions, enabling a more adaptive and accurate
representation of cellular dynamics.

</details>


### [150] [Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming](https://arxiv.org/abs/2507.11547)
*Yingxue Zhao,Qianyi Chen,Haoran Li,Haosu Zhou,Hamid Reza Attar,Tobias Pfaff,Tailin Wu,Nan Li*

Main category: cs.LG

TL;DR: 提出了一种名为RUGNN的图神经网络替代模型，用于预测材料成形过程中的变形场，解决了传统AI模型在捕捉复杂3D空间关系和置换不变性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于标量或图像的AI替代模型难以捕捉复杂3D空间关系和置换不变性，因此需要开发更先进的图神经网络模型。

Method: 开发了RUGNN模型，结合门控循环单元（GRUs）建模时间动态，并采用U-Net启发的图上下采样机制处理空间长程依赖。提出了一种新的‘节点到表面’接触表示方法。

Result: RUGNN在冷成形和热成形案例中表现出色，预测结果与有限元仿真高度一致，且优于其他基线GNN架构。

Conclusion: RUGNN是一种可靠的方法，能够为板材成形设计提供准确的制造性预测。

Abstract: In recent years, various artificial intelligence-based surrogate models have
been proposed to provide rapid manufacturability predictions of material
forming processes. However, traditional AI-based surrogate models, typically
built with scalar or image-based neural networks, are limited in their ability
to capture complex 3D spatial relationships and to operate in a
permutation-invariant manner. To overcome these issues, emerging graph-based
surrogate models are developed using graph neural networks. This study
developed a new graph neural network surrogate model named Recurrent U
Net-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate
predictions of sheet material deformation fields across multiple forming
timesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model
temporal dynamics and a U-Net inspired graph-based downsample/upsample
mechanism to handle spatial long-range dependencies. A novel 'node-to-surface'
contact representation method was proposed, offering significant improvements
in computational efficiency for large-scale contact interactions. The RUGNN
model was validated using a cold forming case study and a more complex hot
forming case study using aluminium alloys. Results demonstrate that the RUGNN
model provides accurate deformation predictions closely matching ground truth
FE simulations and outperforming several baseline GNN architectures. Model
tuning was also performed to identify suitable hyperparameters, training
strategies, and input feature representations. These results demonstrate that
RUGNN is a reliable approach to support sheet material forming design by
enabling accurate manufacturability predictions.

</details>


### [151] [SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery](https://arxiv.org/abs/2507.11570)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.LG

TL;DR: 开发并评估了用于预测脊柱手术住院时间的机器学习模型，SurgeryLSTM表现最佳，兼具高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 提高脊柱手术住院时间预测的准确性和模型可解释性，以支持临床决策。

Method: 比较传统ML模型与SurgeryLSTM（带注意力机制的BiLSTM），使用电子健康记录数据。

Result: SurgeryLSTM预测准确率最高（R2=0.86），注意力机制提升了可解释性。

Conclusion: SurgeryLSTM是一种有效且可解释的AI解决方案，支持将其整合到临床决策系统中。

Abstract: Objective: To develop and evaluate machine learning (ML) models for
predicting length of stay (LOS) in elective spine surgery, with a focus on the
benefits of temporal modeling and model interpretability. Materials and
Methods: We compared traditional ML models (e.g., linear regression, random
forest, support vector machine (SVM), and XGBoost) with our developed model,
SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an
attention, using structured perioperative electronic health records (EHR) data.
Performance was evaluated using the coefficient of determination (R2), and key
predictors were identified using explainable AI. Results: SurgeryLSTM achieved
the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)
and baseline models. The attention mechanism improved interpretability by
dynamically identifying influential temporal segments within preoperative
clinical sequences, allowing clinicians to trace which events or features most
contributed to each LOS prediction. Key predictors of LOS included bone
disorder, chronic kidney disease, and lumbar fusion identified as the most
impactful predictors of LOS. Discussion: Temporal modeling with attention
mechanisms significantly improves LOS prediction by capturing the sequential
nature of patient data. Unlike static models, SurgeryLSTM provides both higher
accuracy and greater interpretability, which are critical for clinical
adoption. These results highlight the potential of integrating attention-based
temporal models into hospital planning workflows. Conclusion: SurgeryLSTM
presents an effective and interpretable AI solution for LOS prediction in
elective spine surgery. Our findings support the integration of temporal,
explainable ML approaches into clinical decision support systems to enhance
discharge readiness and individualized patient care.

</details>


### [152] [Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators](https://arxiv.org/abs/2507.11574)
*Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.LG

TL;DR: CMCO框架结合蒙特卡洛dropout和分形预测，为神经算子提供高效、无需重新训练的UQ解决方案，适用于异构领域。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在实时虚拟传感中因稀疏、噪声或非共位数据导致的UQ不可靠问题。

Method: 通过蒙特卡洛dropout和分形预测结合，在DeepONet架构中实现空间分辨的UQ估计。

Result: 在湍流、弹塑性变形和全球宇宙辐射剂量估计中，CMCO实现了接近名义的覆盖范围。

Conclusion: CMCO为神经算子提供了一种通用、即插即用的UQ解决方案，推动了可扩展、泛化性强的科学机器学习。

Abstract: Robust uncertainty quantification (UQ) remains a critical barrier to the safe
deployment of deep learning in real-time virtual sensing, particularly in
high-stakes domains where sparse, noisy, or non-collocated sensor data are the
norm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework
that transforms neural operator-based virtual sensing with calibrated,
distribution-free prediction intervals. By unifying Monte Carlo dropout with
split conformal prediction in a single DeepONet architecture, CMCO achieves
spatially resolved uncertainty estimates without retraining, ensembling, or
custom loss design. Our method addresses a longstanding challenge: how to endow
operator learning with efficient and reliable UQ across heterogeneous domains.
Through rigorous evaluation on three distinct applications: turbulent flow,
elastoplastic deformation, and global cosmic radiation dose estimation-CMCO
consistently attains near-nominal empirical coverage, even in settings with
strong spatial gradients and proxy-based sensing. This breakthrough offers a
general-purpose, plug-and-play UQ solution for neural operators, unlocking
real-time, trustworthy inference in digital twins, sensor fusion, and
safety-critical monitoring. By bridging theory and deployment with minimal
computational overhead, CMCO establishes a new foundation for scalable,
generalizable, and uncertainty-aware scientific machine learning.

</details>


### [153] [Einstein Fields: A Neural Perspective To Computational General Relativity](https://arxiv.org/abs/2507.11589)
*Sandeep Suresh Cranganore,Andrei Bodnar,Arturs Berzins,Johannes Brandstetter*

Main category: cs.LG

TL;DR: Einstein Fields是一种神经表示方法，用于压缩计算密集型四维数值相对论模拟，通过自动微分推导物理量。


<details>
  <summary>Details</summary>
Motivation: 解决传统数值相对论模拟的高计算成本和存储需求问题。

Method: 使用神经张量场（Neural Tensor Fields）建模广义相对论的核心张量场（metric），并利用自动微分提取物理量。

Result: Einstein Fields在4D时空连续建模、存储效率、导数精度等方面表现出色。

Conclusion: Einstein Fields为数值相对论提供了可扩展且高效的解决方案，并开源了相关代码库。

Abstract: We introduce Einstein Fields, a neural representation that is designed to
compress computationally intensive four-dimensional numerical relativity
simulations into compact implicit neural network weights. By modeling the
\emph{metric}, which is the core tensor field of general relativity, Einstein
Fields enable the derivation of physical quantities via automatic
differentiation. However, unlike conventional neural fields (e.g., signed
distance, occupancy, or radiance fields), Einstein Fields are \emph{Neural
Tensor Fields} with the key difference that when encoding the spacetime
geometry of general relativity into neural field representations, dynamics
emerge naturally as a byproduct. Einstein Fields show remarkable potential,
including continuum modeling of 4D spacetime, mesh-agnosticity, storage
efficiency, derivative accuracy, and ease of use. We address these challenges
across several canonical test beds of general relativity and release an open
source JAX-based library, paving the way for more scalable and expressive
approaches to numerical relativity. Code is made available at
https://github.com/AndreiB137/EinFields

</details>


### [154] [Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques](https://arxiv.org/abs/2507.11590)
*Raju Challagundla,Mohsen Dorodchi,Pu Wang,Minwoo Lee*

Main category: cs.LG

TL;DR: 综述了合成表格数据生成的最新进展，提出基于实际目标的分类法，并提出了一个基准框架以连接理论与实际需求。


<details>
  <summary>Details</summary>
Motivation: 随着隐私法规趋严和真实数据获取受限，合成数据生成成为重要解决方案，尤其是在金融、医疗和社会科学等领域。

Method: 提出基于实际生成目标的分类法，强调保留复杂特征关系、统计保真和隐私保护的方法。

Result: 介绍了新的分类法和基准框架，为未来研究和隐私关键环境中的实施提供指导。

Conclusion: 该工作为合成表格数据的研究和实际应用提供了路线图，连接了理论与实际需求。

Abstract: As privacy regulations become more stringent and access to real-world data
becomes increasingly constrained, synthetic data generation has emerged as a
vital solution, especially for tabular datasets, which are central to domains
like finance, healthcare and the social sciences. This survey presents a
comprehensive and focused review of recent advances in synthetic tabular data
generation, emphasizing methods that preserve complex feature relationships,
maintain statistical fidelity, and satisfy privacy requirements. A key
contribution of this work is the introduction of a novel taxonomy based on
practical generation objectives, including intended downstream applications,
privacy guarantees, and data utility, directly informing methodological design
and evaluation strategies. Therefore, this review prioritizes the actionable
goals that drive synthetic data creation, including conditional generation and
risk-sensitive modeling. Additionally, the survey proposes a benchmark
framework to align technical innovation with real-world demands. By bridging
theoretical foundations with practical deployment, this work serves as both a
roadmap for future research and a guide for implementing synthetic tabular data
in privacy-critical environments.

</details>


### [155] [Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification](https://arxiv.org/abs/2507.11620)
*Steven Dillmann,Juan Rafael Martínez-Galarza*

Main category: cs.LG

TL;DR: 论文提出了一种基于张量表示和稀疏自编码器的方法，用于分析不规则事件时间序列，并在X射线天文学数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 事件时间序列在多个领域中普遍存在，但其不规则性和非结构化特性使得传统方法难以提取有意义的信息。

Method: 采用二维和三维张量表示事件时间序列，结合稀疏自编码器学习物理意义明确的潜在表示。

Result: 该方法成功捕捉了X射线瞬变的时间与光谱特征，并支持多种下游任务，如异常检测和语义聚类。

Conclusion: 该框架为跨领域的复杂事件时间序列分析提供了灵活、可扩展且通用的解决方案。

Abstract: Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.

</details>


### [156] [Deep Generative Methods and Tire Architecture Design](https://arxiv.org/abs/2507.11639)
*Fouad Oubari,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 本文研究了五种深度生成模型在工业轮胎架构生成任务中的表现，发现扩散模型整体表现最佳，并提出了一种无需额外训练的类别修复方法。


<details>
  <summary>Details</summary>
Motivation: 工业实践中缺乏关于哪种深度生成模型最适合复杂制造设计任务的明确指导，本文旨在填补这一空白。

Method: 通过评估五种模型（VAE、GAN、MMVAE、DDPM、MDM）在三种工业场景下的表现，并引入类别修复方法处理条件生成。

Result: 扩散模型整体表现最佳，MDM在分布内表现最好，DDPM在分布外维度约束下泛化能力更强。

Conclusion: 扩散模型在工业设计任务中具有显著优势，类别修复方法为条件生成提供了有效解决方案。

Abstract: As deep generative models proliferate across the AI landscape, industrial
practitioners still face critical yet unanswered questions about which deep
generative models best suit complex manufacturing design tasks. This work
addresses this question through a complete study of five representative models
(Variational Autoencoder, Generative Adversarial Network, multimodal
Variational Autoencoder, Denoising Diffusion Probabilistic Model, and
Multinomial Diffusion Model) on industrial tire architecture generation. Our
evaluation spans three key industrial scenarios: (i) unconditional generation
of complete multi-component designs, (ii) component-conditioned generation
(reconstructing architectures from partial observations), and (iii)
dimension-constrained generation (creating designs that satisfy specific
dimensional requirements). To enable discrete diffusion models to handle
conditional scenarios, we introduce categorical inpainting, a mask-aware
reverse diffusion process that preserves known labels without requiring
additional training. Our evaluation employs geometry-aware metrics specifically
calibrated for industrial requirements, quantifying spatial coherence,
component interaction, structural connectivity, and perceptual fidelity. Our
findings reveal that diffusion models achieve the strongest overall
performance; a masking-trained VAE nonetheless outperforms the multimodal
variant MMVAE\textsuperscript{+} on nearly all component-conditioned metrics,
and within the diffusion family MDM leads in-distribution whereas DDPM
generalises better to out-of-distribution dimensional constraints.

</details>


### [157] [Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation](https://arxiv.org/abs/2507.11645)
*Ahmed Salah,David Yevick*

Main category: cs.LG

TL;DR: 本文提出了几种实用指标（如dropout方差、鲁棒性、嵌入相似性和稀疏性）来预测神经网络中的“grokking”行为，并揭示了其起源和动态。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络中“grokking”（延迟泛化）现象的起源和行为，通过量化指标提前预测其发生。

Method: 引入Dropout鲁棒性曲线（DRC）等指标，分析噪声下的网络表现、神经元活跃度和嵌入分布。

Result: 发现泛化阶段测试精度方差出现局部峰值，神经元活跃度增加，嵌入分布趋于双峰且与数据对称性相关。

Conclusion: 提出的指标能有效预测grokking行为，并揭示其与网络动态和数据集特性的关联。

Abstract: Grokking refers to delayed generalization in which the increase in test
accuracy of a neural network occurs appreciably after the improvement in
training accuracy This paper introduces several practical metrics including
variance under dropout, robustness, embedding similarity, and sparsity
measures, that can forecast grokking behavior. Specifically, the resilience of
neural networks to noise during inference is estimated from a Dropout
Robustness Curve (DRC) obtained from the variation of the accuracy with the
dropout rate as the model transitions from memorization to generalization. The
variance of the test accuracy under stochastic dropout across training
checkpoints further exhibits a local maximum during the grokking. Additionally,
the percentage of inactive neurons decreases during generalization, while the
embeddings tend to a bimodal distribution independent of initialization that
correlates with the observed cosine similarity patterns and dataset symmetries.
These metrics additionally provide valuable insight into the origin and
behaviour of grokking.

</details>


### [158] [ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs](https://arxiv.org/abs/2507.11649)
*Daniel Commey,Benjamin Appiah,Griffith S. Klogo,Garth V. Crosby*

Main category: cs.LG

TL;DR: 提出了一种基于零知识证明（ZKP）的联邦学习隐私保护评估协议，避免通过性能指标泄露敏感信息。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在评估阶段可能通过共享性能指标泄露敏感信息，需要一种隐私保护且可验证的评估方法。

Method: 使用零知识证明（ZKPs），客户端生成简洁证明，声明其本地损失低于预设阈值，而非直接暴露原始损失值。方法包括联邦学习模拟、ZKP电路设计和实验评估。

Result: 在MNIST和HAR数据集上测试了CNN和MLP模型，评估了计算开销、通信成本和可验证性。

Conclusion: 提出的协议实现了隐私保护且可验证的联邦学习评估，适用于实际应用。

Abstract: Federated Learning (FL) enables collaborative model training on decentralized
data without exposing raw data. However, the evaluation phase in FL may leak
sensitive information through shared performance metrics. In this paper, we
propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to
enable privacy-preserving and verifiable evaluation for FL. Instead of
revealing raw loss values, clients generate a succinct proof asserting that
their local loss is below a predefined threshold. Our approach is implemented
without reliance on external APIs, using self-contained modules for federated
learning simulation, ZKP circuit design, and experimental evaluation on both
the MNIST and Human Activity Recognition (HAR) datasets. We focus on a
threshold-based proof for a simple Convolutional Neural Network (CNN) model
(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate
the approach in terms of computational overhead, communication cost, and
verifiability.

</details>


### [159] [Composing Linear Layers from Irreducibles](https://arxiv.org/abs/2507.11688)
*Travis Pence,Daisuke Yamada,Vikas Singh*

Main category: cs.LG

TL;DR: 论文研究了线性层中的几何基元（如双向量）如何组合成更高级的功能，提出了一种基于Clifford代数的可微分算法，将线性层分解为旋转器的乘积，参数效率更高。


<details>
  <summary>Details</summary>
Motivation: 理解大型模型中低层级基元的组合结构，探索线性层是否可以从几何基元中识别或合成。

Method: 使用Clifford代数将线性层表示为双向量的组合，并开发了一种可微分算法将其分解为旋转器的乘积。

Result: 提出的旋转器基线性层仅需O(log^2 d)参数，性能与块Hadamard和低秩近似等基线相当。

Conclusion: 几何基元可以通过代数方式组合成深度学习模型中的高级功能，为模型结构提供了新的视角。

Abstract: Contemporary large models often exhibit behaviors suggesting the presence of
low-level primitives that compose into modules with richer functionality, but
these fundamental building blocks remain poorly understood. We investigate this
compositional structure in linear layers by asking: can we identify/synthesize
linear transformations from a minimal set of geometric primitives? Using
Clifford algebra, we show that linear layers can be expressed as compositions
of bivectors -- geometric objects encoding oriented planes -- and introduce a
differentiable algorithm that decomposes them into products of rotors. This
construction uses only O(log^2 d) parameters, versus O(d^2) required by dense
matrices. Applied to the key, query, and value projections in LLM attention
layers, our rotor-based layers match the performance of strong baselines such
as block-Hadamard and low-rank approximations. Our findings provide an
algebraic perspective on how these geometric primitives can compose into
higher-level functions within deep models.

</details>


### [160] [The Impact of Coreset Selection on Spurious Correlations and Group Robustness](https://arxiv.org/abs/2507.11690)
*Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky*

Main category: cs.LG

TL;DR: 本文分析了数据选择方法对核心集偏差水平及下游模型鲁棒性的影响，发现嵌入基评分方法比学习动态基方法更不易加剧偏差，但优先选择困难样本并不总能保证鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究数据选择方法如何影响核心集的偏差水平及下游模型的鲁棒性，以解决数据集偏差导致的伪相关问题。

Method: 在十个伪相关基准上，结合五种评分指标和五种数据选择策略，分析核心集大小对偏差和模型鲁棒性的影响。

Result: 嵌入基评分方法比学习动态基方法更不易加剧偏差，但优先选择困难样本并不总能保证下游模型的鲁棒性。

Conclusion: 数据选择方法需谨慎设计以避免加剧偏差，嵌入基方法相对更安全，但鲁棒性仍需进一步研究。

Abstract: Coreset selection methods have shown promise in reducing the training data
size while maintaining model performance for data-efficient machine learning.
However, as many datasets suffer from biases that cause models to learn
spurious correlations instead of causal features, it is important to understand
whether and how dataset reduction methods may perpetuate, amplify, or mitigate
these biases. In this work, we conduct the first comprehensive analysis of the
implications of data selection on the spurious bias levels of the selected
coresets and the robustness of downstream models trained on them. We use an
extensive experimental setting spanning ten different spurious correlations
benchmarks, five score metrics to characterize sample importance/ difficulty,
and five data selection policies across a broad range of coreset sizes.
Thereby, we unravel a series of nontrivial nuances in interactions between
sample difficulty and bias alignment, as well as dataset bias and resultant
model robustness. For example, we find that selecting coresets using
embedding-based sample characterization scores runs a comparatively lower risk
of inadvertently exacerbating bias than selecting using characterizations based
on learning dynamics. Most importantly, our analysis reveals that although some
coreset selection methods could achieve lower bias levels by prioritizing
difficult samples, they do not reliably guarantee downstream robustness.

</details>


### [161] [Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption](https://arxiv.org/abs/2507.11702)
*Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet*

Main category: cs.LG

TL;DR: 英国铁路因落叶导致交通中断，每年损失超3亿英镑。研究利用LSTM网络结合卫星数据预测落叶时间，误差分别为6.32天（开始）和9.31天（结束），优化了铁路行业的应对措施。


<details>
  <summary>Details</summary>
Motivation: 落叶导致铁路交通中断成本高昂，现有预测方法在可扩展性和可靠性上存在局限，亟需改进。

Method: 使用LSTM网络，结合地面落叶数据和多光谱、气象卫星数据，预测落叶时间。

Result: 模型的均方根误差为6.32天（开始）和9.31天（结束），优于以往研究。

Conclusion: 该模型为铁路行业提供了优化落叶应对措施的潜力，并增进了对复杂生态系统的理解。

Abstract: Railroad traffic disruption as a result of leaf-fall cost the UK rail
industry over 300 million per year and measures to mitigate such disruptions
are employed on a large scale, with 1.67 million kilometers of track being
treated in the UK in 2021 alone. Therefore, the ability to anticipate the
timing of leaf-fall would offer substantial benefits for rail network
operators, enabling the efficient scheduling of such mitigation measures.
However, current methodologies for predicting leaf-fall exhibit considerable
limitations in terms of scalability and reliability. This study endeavors to
devise a prediction system that leverages specialized prediction methods and
the latest satellite data sources to generate both scalable and reliable
insights into leaf-fall timings. An LSTM network trained on ground-truth
leaf-falling data combined with multispectral and meteorological satellite data
demonstrated a root-mean-square error of 6.32 days for predicting the start of
leaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which
improves upon previous work on the topic, offers promising opportunities for
the optimization of leaf mitigation measures in the railway industry and the
improvement of our understanding of complex ecological systems.

</details>


### [162] [Reinforcement Learning from Adversarial Preferences in Tabular MDPs](https://arxiv.org/abs/2507.11706)
*Taira Tsuchiya,Shinji Ito,Haipeng Luo*

Main category: cs.LG

TL;DR: 论文提出了一种基于偏好的马尔可夫决策过程（PbMDPs）框架，研究了Borda分数下的后悔下界，并提出了两种算法以实现次线性后悔。


<details>
  <summary>Details</summary>
Motivation: 研究在偏好反馈而非直接数值损失下的MDP问题，扩展了传统对抗性MDP的适用范围。

Method: 1. 建立了Borda分数下PbMDPs的后悔下界；2. 提出了基于全局优化和策略优化的两种算法。

Result: 1. 证明了后悔下界为Ω((H²SK)^(1/3)T^(2/3))；2. 算法实现了O~(T^(2/3))的后悔上界。

Conclusion: 论文为偏好反馈下的MDP问题提供了理论分析和实用算法，填补了研究空白。

Abstract: We introduce a new framework of episodic tabular Markov decision processes
(MDPs) with adversarial preferences, which we refer to as preference-based MDPs
(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the
numerical value of the loss is directly observed, in PbMDPs the learner instead
observes preferences between two candidate arms, which represent the choices
being compared. In this work, we focus specifically on the setting where the
reward functions are determined by Borda scores. We begin by establishing a
regret lower bound for PbMDPs with Borda scores. As a preliminary step, we
present a simple instance to prove a lower bound of $\Omega(\sqrt{HSAT})$ for
episodic MDPs with adversarial losses, where $H$ is the number of steps per
episode, $S$ is the number of states, $A$ is the number of actions, and $T$ is
the number of episodes. Leveraging this construction, we then derive a regret
lower bound of $\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda
scores, where $K$ is the number of arms. Next, we develop algorithms that
achieve a regret bound of order $T^{2/3}$. We first propose a global
optimization approach based on online linear optimization over the set of all
occupancy measures, achieving a regret bound of $\tilde{O}((H^2 S^2 K)^{1/3}
T^{2/3} )$ under known transitions. However, this approach suffers from
suboptimal dependence on the potentially large number of states $S$ and
computational inefficiency. To address this, we propose a policy optimization
algorithm whose regret is roughly bounded by $\tilde{O}( (H^6 S K^5)^{1/3}
T^{2/3} )$ under known transitions, and further extend the result to the
unknown-transition setting.

</details>


### [163] [Subgraph Generation for Generalizing on Out-of-Distribution Links](https://arxiv.org/abs/2507.11710)
*Jay Revolinsky,Harry Shomer,Jiliang Tang*

Main category: cs.LG

TL;DR: FLEX是一个图生成模型框架，通过结构条件生成和对抗训练提升图神经网络在分布外场景下的链接预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在链接预测任务中表现优异，但假设数据来自同一分布；图生成模型虽能生成新图，但应用受限。FLEX旨在填补这一空白。

Method: FLEX结合结构条件生成和对抗训练（自动编码器与图神经网络协同训练），确保样本分布的结构对齐。

Result: 实验表明FLEX在合成和真实分布外场景中显著提升性能，并分析了图数据增强对链接结构的影响。

Conclusion: FLEX无需专家知识即可适应不同分布外场景，有效提升链接预测性能。

Abstract: Graphs Neural Networks (GNNs) demonstrate high-performance on the link
prediction (LP) task. However, these models often rely on all dataset samples
being drawn from the same distribution. In addition, graph generative models
(GGMs) show a pronounced ability to generate novel output graphs. Despite this,
GGM applications remain largely limited to domain-specific tasks. To bridge
this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)
structurally-conditioned graph generation, and (2) adversarial co-training
between an auto-encoder and GNN. As such, FLEX ensures structural-alignment
between sample distributions to enhance link-prediction performance in
out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert
knowledge to function in different OOD scenarios. Numerous experiments are
conducted in synthetic and real-world OOD settings to demonstrate FLEX's
performance-enhancing ability, with further analysis for understanding the
effects of graph data augmentation on link structures. The source code is
available here: https://github.com/revolins/FlexOOD.

</details>


### [164] [Globalization for Scalable Short-term Load Forecasting](https://arxiv.org/abs/2507.11729)
*Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung*

Main category: cs.LG

TL;DR: 本文探讨了电力传输网络中负载预测的全局方法（GFMs）与传统局部方法（LFMs）的对比，提出通过时间序列聚类（TSC）解决数据异质性和数据漂移问题，并在实验中验证了全局目标转换模型的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统局部预测模型在泛化性、过拟合、数据漂移和冷启动问题上存在局限性，且难以扩展。全局预测模型通过全球化学习和交叉学习，有望提升预测的泛化性、准确性和鲁棒性。

Method: 研究了特征转换和目标转换模型，提出基于模型和加权实例的时间序列聚类方法，以处理数据异质性和平衡全局与局部动态。

Result: 实验表明，全局目标转换模型在全局特征和聚类技术的支持下表现优于局部模型，而全局特征转换模型需依赖TSC来有效管理数据异质性。

Conclusion: 全局目标转换模型在负载预测中具有显著优势，而特征转换模型需结合TSC以应对数据异质性。全球化方法为分层预测提供了潜力。

Abstract: Forecasting load in power transmission networks is essential across various
hierarchical levels, from the system level down to individual points of
delivery (PoD). While intuitive and locally accurate, traditional local
forecasting models (LFMs) face significant limitations, particularly in
handling generalizability, overfitting, data drift, and the cold start problem.
These methods also struggle with scalability, becoming computationally
expensive and less efficient as the network's size and data volume grow. In
contrast, global forecasting models (GFMs) offer a new approach to enhance
prediction generalizability, scalability, accuracy, and robustness through
globalization and cross-learning. This paper investigates global load
forecasting in the presence of data drifts, highlighting the impact of
different modeling techniques and data heterogeneity. We explore
feature-transforming and target-transforming models, demonstrating how
globalization, data heterogeneity, and data drift affect each differently. In
addition, we examine the role of globalization in peak load forecasting and its
potential for hierarchical forecasting. To address data heterogeneity and the
balance between globality and locality, we propose separate time series
clustering (TSC) methods, introducing model-based TSC for feature-transforming
models and new weighted instance-based TSC for target-transforming models.
Through extensive experiments on a real-world dataset of Alberta's electricity
load, we demonstrate that global target-transforming models consistently
outperform their local counterparts, especially when enriched with global
features and clustering techniques. In contrast, global feature-transforming
models face challenges in balancing local and global dynamics, often requiring
TSC to manage data heterogeneity effectively.

</details>


### [165] [Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning](https://arxiv.org/abs/2507.11732)
*Shiyu Chen,Cencheng Shen,Youngser Park,Carey E. Priebe*

Main category: cs.LG

TL;DR: 提出了一种基于统计方法（GEE）的GNN初始特征生成方法（GG），显著提升了GNN的性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统GNN依赖随机或低信息初始特征，导致收敛慢和性能不佳。

Method: 利用GEE生成高质量初始节点特征，提出GG框架及其变体GG-C。

Result: 在节点聚类和分类任务中，GG和GG-C均表现优异，达到SOTA。

Conclusion: 结构感知的特征初始化对发挥GNN潜力至关重要。

Abstract: Graph neural networks (GNNs) have emerged as a powerful framework for a wide
range of node-level graph learning tasks. However, their performance is often
constrained by reliance on random or minimally informed initial feature
representations, which can lead to slow convergence and suboptimal solutions.
In this paper, we leverage a statistically grounded method, one-hot graph
encoder embedding (GEE), to generate high-quality initial node features that
enhance the end-to-end training of GNNs. We refer to this integrated framework
as the GEE-powered GNN (GG), and demonstrate its effectiveness through
extensive simulations and real-world experiments across both unsupervised and
supervised settings. In node clustering, GG consistently achieves
state-of-the-art performance, ranking first across all evaluated real-world
datasets, while exhibiting faster convergence compared to the standard GNN. For
node classification, we further propose an enhanced variant, GG-C, which
concatenates the outputs of GG and GEE and outperforms competing baselines.
These results confirm the importance of principled, structure-aware feature
initialization in realizing the full potential of GNNs.

</details>


### [166] [Sparse Identification of Nonlinear Dynamics with Conformal Prediction](https://arxiv.org/abs/2507.11739)
*Urban Fasel*

Main category: cs.LG

TL;DR: 论文提出了一种将Conformal Prediction与Ensemble-SINDy结合的方法，用于量化SINDy模型的不确定性，并在时间序列预测、模型选择和系数不确定性方面验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 量化SINDy模型的不确定性对于评估其可靠性至关重要，尤其是在安全关键应用中。

Method: 通过集成Conformal Prediction和Ensemble-SINDy（E-SINDy），提出了三种应用：时间序列预测的不确定性量化、基于特征重要性的模型选择以及模型系数的不确定性量化。

Result: 实验表明，该方法在非高斯噪声下仍能可靠地实现目标覆盖范围，有效量化特征重要性，并为模型系数提供更稳健的不确定性区间。

Conclusion: Conformal Prediction与E-SINDy结合的方法在不确定性量化方面表现出色，优于标准的E-SINDy系数估计。

Abstract: The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for
discovering nonlinear dynamical system models from data. Quantifying
uncertainty in SINDy models is essential for assessing their reliability,
particularly in safety-critical applications. While various uncertainty
quantification methods exist for SINDy, including Bayesian and ensemble
approaches, this work explores the integration of Conformal Prediction, a
framework that can provide valid prediction intervals with coverage guarantees
based on minimal assumptions like data exchangeability. We introduce three
applications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)
quantifying uncertainty in time series prediction, (2) model selection based on
library feature importance, and (3) quantifying the uncertainty of identified
model coefficients using feature conformal prediction. We demonstrate the three
applications on stochastic predator-prey dynamics and several chaotic dynamical
systems. We show that conformal prediction methods integrated with E-SINDy can
reliably achieve desired target coverage for time series forecasting,
effectively quantify feature importance, and produce more robust uncertainty
intervals for model coefficients, even under non-Gaussian noise, compared to
standard E-SINDy coefficient estimates.

</details>


### [167] [A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction](https://arxiv.org/abs/2507.11757)
*Yuehua Song,Yong Gao*

Main category: cs.LG

TL;DR: 提出了一种名为Graph-in-Graph（GiG）的新框架，结合转导学习和归纳学习，用于药物-靶标相互作用预测，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在药物-靶标相互作用预测中难以有效整合药物、靶标及其相互作用的多样化特征。

Method: 引入GiG框架，将药物和靶标分子结构图表示为药物-靶标相互作用图中的元节点，结合转导学习和归纳学习。

Result: GiG模型在所有评估指标上显著优于现有方法。

Conclusion: 整合不同学习范式和相互作用数据对提升预测性能具有显著优势。

Abstract: Accurately predicting drug-target interactions (DTIs) is pivotal for
advancing drug discovery and target validation techniques. While machine
learning approaches including those that are based on Graph Neural Networks
(GNN) have achieved notable success in DTI prediction, many of them have
difficulties in effectively integrating the diverse features of drugs, targets
and their interactions. To address this limitation, we introduce a novel
framework to take advantage of the power of both transductive learning and
inductive learning so that features at molecular level and drug-target
interaction network level can be exploited. Within this framework is a
GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and
target molecular structures as meta-nodes in a drug-target interaction graph,
enabling a detailed exploration of their intricate relationships. To evaluate
the proposed model, we have compiled a special benchmark comprising drug
SMILES, protein sequences, and their interaction data, which is interesting in
its own right. Our experimental results demonstrate that the GiG model
significantly outperforms existing approaches across all evaluation metrics,
highlighting the benefits of integrating different learning paradigms and
interaction data.

</details>


### [168] [Torsional-GFN: a conditional conformation generator for small molecules](https://arxiv.org/abs/2507.11759)
*Alexandra Volokhova,Léna Néhale Ezzine,Piotr Gaiński,Luca Scimeca,Emmanuel Bengio,Prudencio Tossou,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: Torsional-GFN是一种基于GFlowNet的生成模型，用于采样分子构象，其训练仅需奖励函数，能近似玻尔兹曼分布，并实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 分子构象的稳定生成对药物发现至关重要，传统方法效率低，机器学习方法更具潜力。

Method: 提出Torsional-GFN，基于分子图和局部结构（键长和角度），通过旋转扭转角采样构象。

Result: 模型能近似玻尔兹曼分布采样，支持零样本泛化到未见过的键长和角度。

Conclusion: Torsional-GFN为更大分子系统的扩展和零样本泛化提供了可能。

Abstract: Generating stable molecular conformations is crucial in several drug
discovery applications, such as estimating the binding affinity of a molecule
to a target. Recently, generative machine learning methods have emerged as a
promising, more efficient method than molecular dynamics for sampling of
conformations from the Boltzmann distribution. In this paper, we introduce
Torsional-GFN, a conditional GFlowNet specifically designed to sample
conformations of molecules proportionally to their Boltzmann distribution,
using only a reward function as training signal. Conditioned on a molecular
graph and its local structure (bond lengths and angles), Torsional-GFN samples
rotations of its torsion angles. Our results demonstrate that Torsional-GFN is
able to sample conformations approximately proportional to the Boltzmann
distribution for multiple molecules with a single model, and allows for
zero-shot generalization to unseen bond lengths and angles coming from the MD
simulations for such molecules. Our work presents a promising avenue for
scaling the proposed approach to larger molecular systems, achieving zero-shot
generalization to unseen molecules, and including the generation of the local
structure into the GFlowNet model.

</details>


### [169] [Scaling laws for activation steering with Llama 2 models and refusal mechanisms](https://arxiv.org/abs/2507.11771)
*Sheikh Abdur Raheem Ali,Justin Xu,Ivory Yang,Jasmine Xinze Li,Ayse Arslan,Clark Benham*

Main category: cs.LG

TL;DR: 研究了对比激活加法（CAA）在不同规模的Llama 2模型（7B、13B、70B）中的有效性，发现其在早期至中层最有效，但随着模型规模增大效果减弱，且负面引导比正面引导更显著。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的复杂性和能力提升，较少广泛部署的对齐技术效果尚不明确，因此探索CAA在不同规模模型中的表现。

Method: 通过对比激活加法（CAA）在模型残差流向量空间中寻找理想方向，并在前向传播时添加该方向，直接操控残差流以提取特征并控制输出。

Result: 1）CAA在早期至中层最有效；2）CAA效果随模型规模增大而减弱；3）负面引导在所有模型规模中比正面引导更显著。

Conclusion: CAA的有效性受模型规模和层次位置影响，负面引导更具优势，为模型对齐技术提供了新见解。

Abstract: As large language models (LLMs) evolve in complexity and capability, the
efficacy of less widely deployed alignment techniques are uncertain. Building
on previous work on activation steering and contrastive activation addition
(CAA), this paper explores the effectiveness of CAA with model scale using the
family of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable
'directions' in the model's residual stream vector space using contrastive
pairs (for example, hate to love) and adding this direction to the residual
stream during the forward pass. It directly manipulates the residual stream and
aims to extract features from language models to better control their outputs.
Using answer matching questions centered around the refusal behavior, we found
that 1) CAA is most effective when applied at early-mid layers. 2) The
effectiveness of CAA diminishes with model size. 3) Negative steering has more
pronounced effects than positive steering across all model sizes.

</details>


### [170] [Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network](https://arxiv.org/abs/2507.11776)
*Merel Kampere,Ali Mohammed Mansoor Alsahag*

Main category: cs.LG

TL;DR: 研究使用XGBoost分类器结合拓扑特征预测荷兰铁路网络延误，发现现有方法在非同步测试中表现有限，需进一步改进。


<details>
  <summary>Details</summary>
Motivation: 荷兰铁路网络是全球最繁忙的之一，延误问题突出，现有研究多关注短期预测，忽视网络级模式。本研究填补这一空白。

Method: 改进现有方法（原用于美国航空网络），结合节点中心性度量，比较多种分类器（如随机森林、决策树等）预测延误轨迹。

Result: 结果表现有限，尤其在非同步测试中，表明需更多上下文特定调整。

Conclusion: 研究为交通网络评估提供新见解，建议未来开发更鲁棒的延误预测模型。

Abstract: The Dutch railway network is one of the busiest in the world, with delays
being a prominent concern for the principal passenger railway operator NS. This
research addresses a gap in delay prediction studies within the Dutch railway
network by employing an XGBoost Classifier with a focus on topological
features. Current research predominantly emphasizes short-term predictions and
neglects the broader network-wide patterns essential for mitigating ripple
effects. This research implements and improves an existing methodology,
originally designed to forecast the evolution of the fast-changing US air
network, to predict delays in the Dutch Railways. By integrating Node
Centrality Measures and comparing multiple classifiers like RandomForest,
DecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is
to predict delayed trajectories. However, the results reveal limited
performance, especially in non-simultaneous testing scenarios, suggesting the
necessity for more context-specific adaptations. Regardless, this research
contributes to the understanding of transportation network evaluation and
proposes future directions for developing more robust predictive models for
delays.

</details>


### [171] [Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation](https://arxiv.org/abs/2507.11789)
*Alessandro Palma,Sergei Rybakov,Leon Hetzel,Stephan Günnemann,Fabian J. Theis*

Main category: cs.LG

TL;DR: FlatVI是一种新的训练框架，通过正则化离散似然变分自编码器的潜在流形，使其更适合单细胞计数数据的建模，提升潜在空间线性插值与数据流形测地线路径的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单细胞RNA测序中假设线性转移和欧几里得几何，但线性插值可能不符合数据流形的测地线路径，限制了方法的有效性。

Method: FlatVI通过正则化潜在流形，使其更接近欧几里得几何，从而优化潜在空间线性插值与数据流形测地线路径的对应关系。

Result: 在合成数据上验证了理论合理性，应用于时间分辨单细胞RNA测序数据时，改进了轨迹重建和流形插值。

Conclusion: FlatVI通过优化潜在流形的几何特性，提升了单细胞数据建模的准确性和下游分析的兼容性。

Abstract: Latent space interpolations are a powerful tool for navigating deep
generative models in applied settings. An example is single-cell RNA
sequencing, where existing methods model cellular state transitions as latent
space interpolations with variational autoencoders, often assuming linear
shifts and Euclidean geometry. However, unless explicitly enforced, linear
interpolations in the latent space may not correspond to geodesic paths on the
data manifold, limiting methods that assume Euclidean geometry in the data
representations. We introduce FlatVI, a novel training framework that
regularises the latent manifold of discrete-likelihood variational autoencoders
towards Euclidean geometry, specifically tailored for modelling single-cell
count data. By encouraging straight lines in the latent space to approximate
geodesic interpolations on the decoded single-cell manifold, FlatVI enhances
compatibility with downstream approaches that assume Euclidean latent geometry.
Experiments on synthetic data support the theoretical soundness of our
approach, while applications to time-resolved single-cell RNA sequencing data
demonstrate improved trajectory reconstruction and manifold interpolation.

</details>


### [172] [CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels](https://arxiv.org/abs/2507.11807)
*Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 论文提出了一种无需依赖干净标签数据集的元学习方法CLID-MU，用于处理噪声标签场景，通过跨层信息差异评估模型性能并指导训练。


<details>
  <summary>Details</summary>
Motivation: 现有元学习方法依赖干净标签数据集，但实际中难以获取，因此需要一种不依赖干净标签的方法。

Method: 提出CLID-MU策略，利用干净样本在隐藏层和输出层数据结构的连续性，通过跨层信息差异评估模型性能。

Result: 在合成和真实噪声的基准数据集上，CLID-MU优于现有方法。

Conclusion: CLID-MU为噪声标签场景提供了一种有效的元学习解决方案，无需干净标签数据集。

Abstract: Learning with noisy labels (LNL) is essential for training deep neural
networks with imperfect data. Meta-learning approaches have achieved success by
using a clean unbiased labeled set to train a robust model. However, this
approach heavily depends on the availability of a clean labeled meta-dataset,
which is difficult to obtain in practice. In this work, we thus tackle the
challenge of meta-learning for noisy label scenarios without relying on a clean
labeled dataset. Our approach leverages the data itself while bypassing the
need for labels. Building on the insight that clean samples effectively
preserve the consistency of related data structures across the last hidden and
the final layer, whereas noisy samples disrupt this consistency, we design the
Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU).
CLID-MU leverages the alignment of data structures across these diverse feature
spaces to evaluate model performance and use this alignment to guide training.
Experiments on benchmark datasets with varying amounts of labels under both
synthetic and real-world noise demonstrate that CLID-MU outperforms
state-of-the-art methods. The code is released at
https://github.com/ruofanhu/CLID-MU.

</details>


### [173] [SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling](https://arxiv.org/abs/2507.11818)
*Andrei Rekesh,Miruna Cretu,Dmytro Shevchuk,Vignesh Ram Somnath,Pietro Liò,Robert A. Batey,Mike Tyers,Michał Koziarski,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: SynCoGen是一个结合掩码图扩散和流匹配的框架，用于生成可合成的3D分子，解决了传统2D方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决生成小分子设计中合成性问题，并扩展至3D几何条件生成。

Method: 使用掩码图扩散和流匹配的联合框架，从分子构建块、化学反应和原子坐标的联合分布中采样。

Result: 在无条件小分子图和构象生成中表现优异，并在零样本分子连接设计中具有竞争力。

Conclusion: SynCoGen为未来非自回归分子生成应用奠定了基础，如类似物扩展和先导优化。

Abstract: Ensuring synthesizability in generative small molecule design remains a major
challenge. While recent developments in synthesizable molecule generation have
demonstrated promising results, these efforts have been largely confined to 2D
molecular graph representations, limiting the ability to perform geometry-based
conditional generation. In this work, we present SynCoGen (Synthesizable
Co-Generation), a single framework that combines simultaneous masked graph
diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen
samples from the joint distribution of molecular building blocks, chemical
reactions, and atomic coordinates. To train the model, we curated SynSpace, a
dataset containing over 600K synthesis-aware building block graphs and 3.3M
conformers. SynCoGen achieves state-of-the-art performance in unconditional
small molecule graph and conformer generation, and the model delivers
competitive performance in zero-shot molecular linker design for protein ligand
generation in drug discovery. Overall, this multimodal formulation represents a
foundation for future applications enabled by non-autoregressive molecular
generation, including analog expansion, lead optimization, and direct structure
conditioning.

</details>


### [174] [MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory](https://arxiv.org/abs/2507.11821)
*Pouya Shaeri,Arash Karimi,Ariane Middel*

Main category: cs.LG

TL;DR: MNIST-Gen是一个自动化、模块化的框架，用于生成用户指定类别的MNIST风格数据集，解决了传统MNIST数据集在特定领域任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统MNIST数据集在特定领域（如树木、食物分类）中不适用，且创建自定义数据集耗时且法律受限。

Method: 结合CLIP语义理解、强化学习和人类反馈，采用分层语义分类和可组合的态射模型。

Result: 生成Tree-MNIST和Food-MNIST数据集，自动分类准确率达85%，节省80%时间。

Conclusion: MNIST-Gen为特定任务提供高效、灵活的数据集生成方案。

Abstract: Neural networks are often benchmarked using standard datasets such as MNIST,
FashionMNIST, or other variants of MNIST, which, while accessible, are limited
to generic classes such as digits or clothing items. For researchers working on
domain-specific tasks, such as classifying trees, food items, or other
real-world objects, these data sets are insufficient and irrelevant.
Additionally, creating and publishing a custom dataset can be time consuming,
legally constrained, or beyond the scope of individual projects. We present
MNIST-Gen, an automated, modular, and adaptive framework for generating
MNIST-style image datasets tailored to user-specified categories using
hierarchical semantic categorization. The system combines CLIP-based semantic
understanding with reinforcement learning and human feedback to achieve
intelligent categorization with minimal manual intervention. Our hierarchical
approach supports complex category structures with semantic characteristics,
enabling fine-grained subcategorization and multiple processing modes:
individual review for maximum control, smart batch processing for large
datasets, and fast batch processing for rapid creation. Inspired by category
theory, MNIST-Gen models each data transformation stage as a composable
morphism, enhancing clarity, modularity, and extensibility. As proof of
concept, we generate and benchmark two novel datasets-\textit{Tree-MNIST} and
\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing
task-specific evaluation data while achieving 85\% automatic categorization
accuracy and 80\% time savings compared to manual approaches.

</details>


### [175] [HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction](https://arxiv.org/abs/2507.11836)
*Jian Gao,Jianshe Wu,JingYi Ding*

Main category: cs.LG

TL;DR: HyperEvent框架通过动态构建关联序列和事件相关性向量，将动态链接预测重构为超事件识别，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法捕捉复合超事件的结构内聚性，限制了动态图建模的准确性。

Method: 提出HyperEvent框架，利用事件相关性向量动态构建关联序列，评估查询事件与历史事件是否形成有效超事件。

Result: 在5个数据集中4个表现优于现有方法，大规模Flight数据集上MRR提升6.95%，训练时间仅需10.17%。

Conclusion: HyperEvent在准确性和效率上均优于现有方法，适用于大规模动态图建模。

Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental
task for modeling evolving complex systems. Existing node-centric and
event-centric methods focus on individual interactions or atomic states,
failing to capture the structural cohesion of composite hyper-events, groups of
causally related events. To address this, we propose HyperEvent, a framework
reframing dynamic link prediction as hyper-event recognition. Central to
HyperEvent is the dynamic construction of an association sequence using event
correlation vectors. These vectors quantify pairwise dependencies between the
query event and relevant historical events, thereby characterizing the
structural cohesion of a potential hyper-event. The framework predicts the
occurrence of the query event by evaluating whether it collectively forms a
valid hyper-event with these historical events. Notably, HyperEvent outperforms
state-of-the-art methods on 4 out of 5 datasets in the official leaderboard.
For scalability, we further introduce an efficient parallel training algorithm
that segments large event streams to enable concurrent training. Experiments
validate HyperEvent's superior accuracy and efficiency on large-scale graphs.
Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank
over state-of-the-art baseline on the large-scale Flight dataset while
utilizing only 10.17% of the training time.

</details>


### [176] [Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM](https://arxiv.org/abs/2507.11839)
*Chengyue Gong,Xinshi Chen,Yuxuan Zhang,Yuxuan Song,Hao Zhou,Wenzhi Xiao*

Main category: cs.LG

TL;DR: Protenix-Mini是一个轻量化的蛋白质结构预测模型，通过优化采样策略和架构设计，显著降低计算开销，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决在生物分子结构预测中平衡模型效率与预测准确性的挑战，以适应大规模应用和实时部署的需求。

Method: 1) 用少步ODE采样器替代多步AF3采样器；2) 对冗余Transformer模块进行剪枝；3) 用ESM模块替代传统MSA模块。

Result: 在基准数据集上，Protenix-Mini仅比完整模型性能下降1-5%，但显著降低了计算复杂度。

Conclusion: Protenix-Mini是计算资源有限但需要高精度预测的理想选择。

Abstract: Lightweight inference is critical for biomolecular structure prediction and
other downstream tasks, enabling efficient real-world deployment and
inference-time scaling for large-scale applications. In this work, we address
the challenge of balancing model efficiency and prediction accuracy by making
several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step
ODE sampler, significantly reducing computational overhead for the diffusion
module part during inference; 2) In the open-source Protenix framework, a
subset of pairformer or diffusion transformer blocks doesn't make contributions
to the final structure prediction, presenting opportunities for architectural
pruning and lightweight redesign; 3) A model incorporating an ESM module is
trained to substitute the conventional MSA module, reducing MSA preprocessing
time. Building on these key insights, we present Protenix-Mini, a compact and
optimized model designed for efficient protein structure prediction. This
streamlined version incorporates a more efficient architectural design with a
two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating
redundant Transformer components and refining the sampling process,
Protenix-Mini significantly reduces model complexity with slight accuracy drop.
Evaluations on benchmark datasets demonstrate that it achieves high-fidelity
predictions, with only a negligible 1 to 5 percent decrease in performance on
benchmark datasets compared to its full-scale counterpart. This makes
Protenix-Mini an ideal choice for applications where computational resources
are limited but accurate structure prediction remains crucial.

</details>


### [177] [Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update](https://arxiv.org/abs/2507.11847)
*Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 提出了一种联合高效的广义线性多臂老虎机算法，实现了近乎最优的遗憾边界，且每轮时间和空间复杂度为O(1)。


<details>
  <summary>Details</summary>
Motivation: 广义线性老虎机（GLB）的非线性特性导致计算和统计效率难以兼顾，现有方法通常需在两者间权衡。

Method: 通过在线镜像下降（OMD）估计器构建紧密置信集，利用混合损失的新颖分析实现统计高效性。

Result: 算法在每轮O(1)复杂度下达到接近最优的遗憾边界，统计效率与最大似然估计相当。

Conclusion: 提出的方法在计算和统计效率上均表现优异，为GLB问题提供了实用解决方案。

Abstract: We study the generalized linear bandit (GLB) problem, a contextual
multi-armed bandit framework that extends the classical linear model by
incorporating a non-linear link function, thereby modeling a broad class of
reward distributions such as Bernoulli and Poisson. While GLBs are widely
applicable to real-world scenarios, their non-linear nature introduces
significant challenges in achieving both computational and statistical
efficiency. Existing methods typically trade off between two objectives, either
incurring high per-round costs for optimal regret guarantees or compromising
statistical efficiency to enable constant-time updates. In this paper, we
propose a jointly efficient algorithm that attains a nearly optimal regret
bound with $\mathcal{O}(1)$ time and space complexities per round. The core of
our method is a tight confidence set for the online mirror descent (OMD)
estimator, which is derived through a novel analysis that leverages the notion
of mix loss from online prediction. The analysis shows that our OMD estimator,
even with its one-pass updates, achieves statistical efficiency comparable to
maximum likelihood estimation, thereby leading to a jointly efficient
optimistic method.

</details>


### [178] [Online Training and Pruning of Deep Reinforcement Learning Networks](https://arxiv.org/abs/2507.11975)
*Valentin Frank Ingmar Guenter,Athanasios Sideris*

Main category: cs.LG

TL;DR: 提出一种在强化学习（RL）中结合训练与剪枝的方法，通过随机优化问题促进网络单元的稀疏性，显著减少计算和内存开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在强化学习中性能提升的同时带来了计算和内存复杂度的显著增加，而剪枝方法在监督学习中已成功应用，但在RL中尚未充分探索。

Method: 提出XiNet，通过随机优化问题训练RL网络权重和变分伯努利分布的参数，结合成本感知的稀疏正则化方案，自动选择超参数，实现网络压缩。

Result: 在MuJoCo连续控制基准和Soft Actor-Critic RL代理上验证，OFENet可大幅剪枝且性能损失极小，剪枝后的网络比从头训练的小网络更高效且性能更高。

Conclusion: 在训练过程中剪枝大型网络能产生更高效且性能更好的RL代理，为RL中的网络压缩提供了有效方法。

Abstract: Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms
has been shown to enhance performance when feature extraction networks are used
but the gained performance comes at the significant expense of increased
computational and memory complexity. Neural network pruning methods have
successfully addressed this challenge in supervised learning. However, their
application to RL is underexplored. We propose an approach to integrate
simultaneous training and pruning within advanced RL methods, in particular to
RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our
networks (XiNet) are trained to solve stochastic optimization problems over the
RL networks' weights and the parameters of variational Bernoulli distributions
for 0/1 Random Variables $\xi$ scaling each unit in the networks. The
stochastic problem formulation induces regularization terms that promote
convergence of the variational parameters to 0 when a unit contributes little
to the performance. In this case, the corresponding structure is rendered
permanently inactive and pruned from its network. We propose a cost-aware,
sparsity-promoting regularization scheme, tailored to the DenseNet architecture
of OFENets expressing the parameter complexity of involved networks in terms of
the parameters of the RVs in these networks. Then, when matching this cost with
the regularization terms, the many hyperparameters associated with them are
automatically selected, effectively combining the RL objectives and network
compression. We evaluate our method on continuous control benchmarks (MuJoCo)
and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned
considerably with minimal loss in performance. Furthermore, our results confirm
that pruning large networks during training produces more efficient and higher
performing RL agents rather than training smaller networks from scratch.

</details>


### [179] [OrdShap: Feature Position Importance for Sequential Black-Box Models](https://arxiv.org/abs/2507.11855)
*Davin Hill,Brian L. Hill,Aria Masoomi,Vijay S. Nori,Robert E. Tillman,Jennifer Dy*

Main category: cs.LG

TL;DR: OrdShap是一种新的特征归因方法，通过量化特征位置对模型预测的影响，解决了现有方法混淆特征值和位置的问题。


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法假设特征顺序固定，无法区分特征值和位置对预测的影响。

Method: 引入OrdShap，通过置换特征位置量化模型预测变化，并与Sanchez-Bergantiños值建立博弈论联系。

Result: 在健康、自然语言和合成数据集上的实验验证了OrdShap能有效捕捉特征值和位置的影响。

Conclusion: OrdShap为模型行为提供了更深入的见解，解决了特征归因中的位置敏感性挑战。

Abstract: Sequential deep learning models excel in domains with temporal or sequential
dependencies, but their complexity necessitates post-hoc feature attribution
methods for understanding their predictions. While existing techniques quantify
feature importance, they inherently assume fixed feature ordering - conflating
the effects of (1) feature values and (2) their positions within input
sequences. To address this gap, we introduce OrdShap, a novel attribution
method that disentangles these effects by quantifying how a model's predictions
change in response to permuting feature position. We establish a game-theoretic
connection between OrdShap and Sanchez-Berganti\~nos values, providing a
theoretically grounded approach to position-sensitive attribution. Empirical
results from health, natural language, and synthetic datasets highlight
OrdShap's effectiveness in capturing feature value and feature position
attributions, and provide deeper insight into model behavior.

</details>


### [180] [A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers](https://arxiv.org/abs/2507.11865)
*Hanwen Dai,Chang Gao,Fang He,Congyuan Ji,Yanni Yang*

Main category: cs.LG

TL;DR: 研究提出了一种动态管理司机接受折扣快车服务的方法，通过pi-DDPG框架提升学习效率和早期训练表现。


<details>
  <summary>Details</summary>
Motivation: 平台整合虽能减少市场碎片化，但司机参与折扣快车服务可能降低利润，需动态管理司机接受行为。

Method: 采用pi-DDPG框架，包含优化模块、卷积LSTM网络和优先经验回放机制，以应对高随机性和数据不足。

Result: pi-DDPG在学习效率和减少早期训练损失方面表现优异。

Conclusion: pi-DDPG框架有效解决了动态管理司机行为的挑战，适用于实际部署。

Abstract: The rapid expansion of platform integration has emerged as an effective
solution to mitigate market fragmentation by consolidating multiple
ride-hailing platforms into a single application. To address heterogeneous
passenger preferences, third-party integrators provide Discount Express service
delivered by express drivers at lower trip fares. For the individual platform,
encouraging broader participation of drivers in Discount Express services has
the potential to expand the accessible demand pool and improve matching
efficiency, but often at the cost of reduced profit margins. This study aims to
dynamically manage drivers' acceptance of Discount Express from the perspective
of individual platforms. The lack of historical data under the new business
model necessitates online learning. However, early-stage exploration through
trial and error can be costly in practice, highlighting the need for reliable
early-stage performance in real-world deployment. To address these challenges,
this study formulates the decision regarding the proportion of drivers'
acceptance behavior as a continuous control task. In response to the high
stochasticity, the opaque matching mechanisms employed by third-party
integrator, and the limited availability of historical data, we propose a
policy-improved deep deterministic policy gradient (pi-DDPG) framework. The
proposed framework incorporates a refiner module to boost policy performance
during the early training phase, leverages a convolutional long short-term
memory network to effectively capture complex spatiotemporal patterns, and
adopts a prioritized experience replay mechanism to enhance learning
efficiency. A simulator based on a real-world dataset is developed to validate
the effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate
that pi-DDPG achieves superior learning efficiency and significantly reduces
early-stage training losses.

</details>


### [181] [Imbalanced Regression Pipeline Recommendation](https://arxiv.org/abs/2507.11901)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: Meta-IR框架通过元学习推荐最佳预处理和学习模型组合，解决回归任务中的不平衡问题，性能优于传统方法和AutoML框架。


<details>
  <summary>Details</summary>
Motivation: 回归任务中目标值稀少导致的不平衡问题难以解决，现有方法需测试大量组合，效率低下。

Method: 提出Meta-IR框架，训练元分类器以零样本方式推荐最佳预处理和学习模型组合，包括独立和链式两种形式。

Result: 链式形式表现更优，Meta-IR在42种配置中均优于基线方法。

Conclusion: Meta-IR通过元学习有效解决回归不平衡问题，性能显著优于传统方法。

Abstract: Imbalanced problems are prevalent in various real-world scenarios and are
extensively explored in classification tasks. However, they also present
challenges for regression tasks due to the rarity of certain target values. A
common alternative is to employ balancing algorithms in preprocessing to
address dataset imbalance. However, due to the variety of resampling methods
and learning models, determining the optimal solution requires testing many
combinations. Furthermore, the learning model, dataset, and evaluation metric
affect the best strategies. This work proposes the Meta-learning for Imbalanced
Regression (Meta-IR) framework, which diverges from existing literature by
training meta-classifiers to recommend the best pipeline composed of the
resampling strategy and learning model per task in a zero-shot fashion. The
meta-classifiers are trained using a set of meta-features to learn how to map
the meta-features to the classes indicating the best pipeline. We propose two
formulations: Independent and Chained. Independent trains the meta-classifiers
to separately indicate the best learning algorithm and resampling strategy.
Chained involves a sequential procedure where the output of one meta-classifier
is used as input for another to model intrinsic relationship factors. The
Chained scenario showed superior performance, suggesting a relationship between
the learning algorithm and the resampling strategy per task. Compared with
AutoML frameworks, Meta-IR obtained better results. Moreover, compared with
baselines of six learning algorithms and six resampling algorithms plus no
resampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of
them. The code, data, and further information of the experiments can be found
on GitHub: https://github.com/JusciAvelino/Meta-IR.

</details>


### [182] [Resampling strategies for imbalanced regression: a survey and empirical analysis](https://arxiv.org/abs/2507.11902)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 本文研究了不平衡回归问题，提出了基于回归模型、学习过程和评估指标的分类法，并通过实验展示了平衡策略的优势。


<details>
  <summary>Details</summary>
Motivation: 现实世界中存在不平衡回归问题，但相关研究主要集中在分类任务上，本文旨在填补这一空白。

Method: 通过实验研究多种平衡和预测模型，并使用特定指标评估模型在不平衡回归数据中的表现。

Result: 研究提出了不平衡回归方法的分类法，并展示了不同策略对模型学习过程的优势。

Conclusion: 本文为不平衡回归提供了新见解，并指出了未来研究方向。

Abstract: Imbalanced problems can arise in different real-world situations, and to
address this, certain strategies in the form of resampling or balancing
algorithms are proposed. This issue has largely been studied in the context of
classification, and yet, the same problem features in regression tasks, where
target values are continuous. This work presents an extensive experimental
study comprising various balancing and predictive models, and wich uses metrics
to capture important elements for the user and to evaluate the predictive model
in an imbalanced regression data context. It also proposes a taxonomy for
imbalanced regression approaches based on three crucial criteria: regression
model, learning process, and evaluation metrics. The study offers new insights
into the use of such strategies, highlighting the advantages they bring to each
model's learning process, and indicating directions for further studies. The
code, data and further information related to the experiments performed herein
can be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.

</details>


### [183] [From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning](https://arxiv.org/abs/2507.11926)
*Max Hopkins,Sihan Liu,Christopher Ye,Yuichi Yoshida*

Main category: cs.LG

TL;DR: 论文研究了可复现强化学习算法的样本效率，填补了生成模型与无模型设置之间的样本复杂度差距，证明了探索并非可复现学习的显著障碍。


<details>
  <summary>Details</summary>
Motivation: 解决可复现学习在强化学习中的样本效率问题，探索是否比批量学习更昂贵。

Method: 提出了一种可复现的强化学习算法，样本复杂度为$	ilde{O}(S^2A)$，填补了生成模型与无模型设置之间的差距。

Result: 算法在$	ilde{O}(S^2A)$样本下实现可复现学习，并提供了匹配的下界证明其近最优性。

Conclusion: 探索并非可复现学习的显著障碍，样本高效的强化学习是可实现的。

Abstract: The epidemic failure of replicability across empirical science and machine
learning has recently motivated the formal study of replicable learning
algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from
a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the
design of data-efficient replicable algorithms is now more or less understood.
In contrast, there remain significant gaps in our knowledge for control
settings like reinforcement learning where an agent must interact directly with
a shifting environment. Karbasi et. al show that with access to a generative
model of an environment with $S$ states and $A$ actions (the RL 'batch
setting'), replicably learning a near-optimal policy costs only
$\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a
generative model jumps to $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the
substantial difficulty of environment exploration. This gap raises a key
question in the broader theory of replicability: Is replicable exploration
inherently more expensive than batch learning? Is sample-efficient replicable
RL even possible?
  In this work, we (nearly) resolve this problem (for low-horizon tabular
MDPs): exploration is not a significant barrier to replicable learning! Our
main result is a replicable RL algorithm on $\tilde{O}(S^2A)$ samples, bridging
the gap between the generative and episodic settings. We complement this with a
matching $\tilde{\Omega}(S^2A)$ lower bound in the generative setting (under
the common parallel sampling assumption) and an unconditional lower bound in
the episodic setting of $\tilde{\Omega}(S^2)$ showcasing the near-optimality of
our algorithm with respect to the state space $S$.

</details>


### [184] [Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning](https://arxiv.org/abs/2507.11928)
*Abhishek Sriram,Neal Tuffy*

Main category: cs.LG

TL;DR: 提出了一种机器学习加速的优化框架，用于RF功率放大器设计，减少65%的仿真需求，同时保持±0.3至±0.4 dBm的精度。


<details>
  <summary>Details</summary>
Motivation: 传统的RF功率放大器设计需要大量仿真，效率低下。本文旨在通过智能采样和机器学习减少仿真需求，同时保持高精度。

Method: 结合MaxMin拉丁超立方采样和CatBoost梯度提升，智能探索多维参数空间，仅仿真35%的关键点。框架处理ADS网表，执行谐波平衡仿真，并训练CatBoost模型预测性能。

Result: 在15种PA工作模式下验证，平均R²为0.901，仿真时间减少58.24%至77.78%。

Conclusion: 该框架显著提升设计效率，支持快速迭代，同时满足生产级RF电路的精度要求。

Abstract: This paper presents a machine learning-accelerated optimization framework for
RF power amplifier design that reduces simulation requirements by 65% while
maintaining $\pm0.3$ to $\pm0.4$ dBm accuracy. The proposed method combines
MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to
intelligently explore multidimensional parameter spaces. Instead of
exhaustively simulating all parameter combinations to achieve target P2dB
compression specifications, our approach strategically selects approximately
35% of critical simulation points. The framework processes ADS netlists,
executes harmonic balance simulations on the reduced dataset, and trains a
CatBoost model to predict P2dB performance across the entire design space.
Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with
the system ranking parameter combinations by their likelihood of meeting target
specifications. The integrated solution delivers 58.24% to 77.78% reduction in
simulation time through automated GUI-based workflows, enabling rapid design
iterations without compromising accuracy standards required for production RF
circuits.

</details>


### [185] [Kevin: Multi-Turn RL for Generating CUDA Kernels](https://arxiv.org/abs/2507.11948)
*Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti*

Main category: cs.LG

TL;DR: 论文提出了一种多轮强化学习（RL）方法Kevin，用于优化GPU内核生成，显著提升了正确性和性能。


<details>
  <summary>Details</summary>
Motivation: GPU内核编写对AI系统效率至关重要，但具有挑战性且需要迭代优化。强化学习的可验证奖励（如正确性和加速）使其成为自然选择。

Method: 开发了一种灵活的多轮RL方法，解决了长轨迹学习和跨轮奖励分配等实际问题。Kevin是首个基于多轮RL训练的CUDA内核生成模型。

Result: Kevin在生成内核的正确性（从56%提升至82%）和平均加速（从0.53x提升至1.10x）上显著优于基础模型和前沿模型。

Conclusion: 多轮RL在GPU内核优化中效果显著，尤其是串行细化比并行采样更具优势，随着细化轮次增加，Kevin表现持续提升。

Abstract: Writing GPU kernels is a challenging task and critical for AI systems'
efficiency. It is also highly iterative: domain experts write code and improve
performance through execution feedback. Moreover, it presents verifiable
rewards like correctness and speedup, making it a natural environment to apply
Reinforcement Learning (RL). To explicitly incorporate the iterative nature of
this process into training, we develop a flexible multi-turn RL recipe that
addresses unique challenges encountered in real-world settings, such as
learning from long trajectories and effective reward attribution across turns.
We present Kevin - K(ernel D)evin, the first model trained with multi-turn RL
for CUDA kernel generation and optimization. In our evaluation setup, Kevin
shows significant gains over its base model (QwQ-32B), improving correctness of
generated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to
1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini
(0.78x). Finally, we study its behavior across test-time scaling axes: we found
scaling serial refinement more beneficial than parallel sampling. In
particular, when given more refinement turns, Kevin shows a higher rate of
improvement.

</details>


### [186] [Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection](https://arxiv.org/abs/2507.11997)
*Tairan Huang,Yili Wang*

Main category: cs.LG

TL;DR: 论文提出了一种多级LLM增强的图欺诈检测框架MLED，通过结合LLM提取的文本信息和图结构，提升了欺诈检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有图欺诈检测方法忽略原始文本信息中的丰富语义线索，而LLM虽能处理文本信息，但如何与图结构进行多模态融合仍具挑战性。

Method: 设计多级LLM增强框架（MLED），包括类型级增强器和关系级增强器，分别增强欺诈者与良性实体的差异及欺诈者在不同关系中的重要性。

Result: 在四个真实数据集上的实验表明，MLED作为通用框架，在图欺诈检测中达到了最先进的性能。

Conclusion: MLED通过结合LLM和图结构，有效提升了欺诈检测能力，并可作为现有方法的通用增强框架。

Abstract: Graph fraud detection has garnered significant attention as Graph Neural
Networks (GNNs) have proven effective in modeling complex relationships within
multimodal data. However, existing graph fraud detection methods typically use
preprocessed node embeddings and predefined graph structures to reveal
fraudsters, which ignore the rich semantic cues contained in raw textual
information. Although Large Language Models (LLMs) exhibit powerful
capabilities in processing textual information, it remains a significant
challenge to perform multimodal fusion of processed textual embeddings with
graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM
\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In
MLED, we utilize LLMs to extract external knowledge from textual information to
enhance graph fraud detection methods. To integrate LLMs with graph structure
information and enhance the ability to distinguish fraudsters, we design a
multi-level LLM enhanced framework including type-level enhancer and
relation-level enhancer. One is to enhance the difference between the
fraudsters and the benign entities, the other is to enhance the importance of
the fraudsters in different relations. The experiments on four real-world
datasets show that MLED achieves state-of-the-art performance in graph fraud
detection as a generalized framework that can be applied to existing methods.

</details>


### [187] [Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing](https://arxiv.org/abs/2507.12002)
*Alice Zhang,Callihan Bertley,Dawei Liang,Edison Thomaz*

Main category: cs.LG

TL;DR: 提出了一种基于智能手表的多模态数据融合方法，用于检测社交互动中的面对面对话，结合音频和惯性数据，在实验室和半自然环境中取得了较高的准确率。


<details>
  <summary>Details</summary>
Motivation: 社交互动对人类行为和社会关系至关重要，但现有方法在复杂声学环境下检测对话存在挑战。

Method: 利用智能手表采集音频和惯性数据，结合机器学习和深度学习模型，采用三种融合方法分析多模态数据。

Result: 在实验室和半自然环境中分别达到82.0±3.0%和77.2±1.8%的宏F1分数。

Conclusion: 多模态数据融合能有效提升对话检测的准确性，尤其在复杂环境中表现突出。

Abstract: Social interactions play a crucial role in shaping human behavior,
relationships, and societies. It encompasses various forms of communication,
such as verbal conversation, non-verbal gestures, facial expressions, and body
language. In this work, we develop a novel computational approach to detect a
foundational aspect of human social interactions, in-person verbal
conversations, by leveraging audio and inertial data captured with a commodity
smartwatch in acoustically-challenging scenarios. To evaluate our approach, we
conducted a lab study with 11 participants and a semi-naturalistic study with
24 participants. We analyzed machine learning and deep learning models with 3
different fusion methods, showing the advantages of fusing audio and inertial
data to consider not only verbal cues but also non-verbal gestures in
conversations. Furthermore, we perform a comprehensive set of evaluations
across activities and sampling rates to demonstrate the benefits of multimodal
sensing in specific contexts. Overall, our framework achieved 82.0$\pm$3.0%
macro F1-score when detecting conversations in the lab and 77.2$\pm$1.8% in the
semi-naturalistic setting.

</details>


### [188] [DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning](https://arxiv.org/abs/2507.12011)
*Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.LG

TL;DR: 论文提出了一种名为DUSE的数据扩展框架，通过不确定性评分和主动学习策略解决自动调制识别中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在自动调制识别中表现优异，但需要大量标注数据，而实际场景中目标域数据稀缺且标注成本高。

Method: DUSE利用不确定性评分函数从相关数据集中筛选有用样本，并通过主动学习策略持续优化评分器。

Result: 实验表明，DUSE在类别平衡和不平衡设置下均优于8种核心集选择基线，且对未见模型具有强泛化能力。

Conclusion: DUSE有效解决了数据稀缺问题，提升了模型性能，并展示了跨架构的泛化能力。

Abstract: Although deep neural networks have made remarkable achievements in the field
of automatic modulation recognition (AMR), these models often require a large
amount of labeled data for training. However, in many practical scenarios, the
available target domain data is scarce and difficult to meet the needs of model
training. The most direct way is to collect data manually and perform expert
annotation, but the high time and labor costs are unbearable. Another common
method is data augmentation. Although it can enrich training samples to a
certain extent, it does not introduce new data and therefore cannot
fundamentally solve the problem of data scarcity. To address these challenges,
we introduce a data expansion framework called Dynamic Uncertainty-driven
Sample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring
function to filter out useful samples from relevant AMR datasets and employs an
active learning strategy to continuously refine the scorer. Extensive
experiments demonstrate that DUSE consistently outperforms 8 coreset selection
baselines in both class-balance and class-imbalance settings. Besides, DUSE
exhibits strong cross-architecture generalization for unseen models.

</details>


### [189] [Granular feedback merits sophisticated aggregation](https://arxiv.org/abs/2507.12041)
*Anmol Kagrecha,Henrik Marklund,Potsawee Manakul,Richard Zeckhauser,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 论文探讨了在有限个体反馈下预测群体反馈分布的方法，发现随着反馈粒度的增加，复杂方法比正则化平均更有效。


<details>
  <summary>Details</summary>
Motivation: 研究如何在成本限制下，利用少量个体的反馈更准确地预测群体反馈分布。

Method: 比较正则化平均与更复杂的方法在不同反馈粒度（如二值和五点反馈）下的表现。

Result: 五点反馈下，复杂方法仅需正则化平均一半的个体即可达到相同性能。

Conclusion: 反馈粒度越高，复杂方法的优势越明显。

Abstract: Human feedback is increasingly used across diverse applications like training
AI models, developing recommender systems, and measuring public opinion -- with
granular feedback often being preferred over binary feedback for its greater
informativeness. While it is easy to accurately estimate a population's
distribution of feedback given feedback from a large number of individuals,
cost constraints typically necessitate using smaller groups. A simple method to
approximate the population distribution is regularized averaging: compute the
empirical distribution and regularize it toward a prior. Can we do better? As
we will discuss, the answer to this question depends on feedback granularity.
  Suppose one wants to predict a population's distribution of feedback using
feedback from a limited number of individuals. We show that, as feedback
granularity increases, one can substantially improve upon predictions of
regularized averaging by combining individuals' feedback in ways more
sophisticated than regularized averaging.
  Our empirical analysis using questions on social attitudes confirms this
pattern. In particular, with binary feedback, sophistication barely reduces the
number of individuals required to attain a fixed level of performance. By
contrast, with five-point feedback, sophisticated methods match the performance
of regularized averaging with about half as many individuals.

</details>


### [190] [Information-Theoretic Generalization Bounds of Replay-based Continual Learning](https://arxiv.org/abs/2507.12043)
*Wen Wen,Tieliang Gong,Yunjiao Zhang,Zeyu Gao,Weizhan Zhang,Yong-Jin Liu*

Main category: cs.LG

TL;DR: 本文为基于回放的持续学习（CL）建立了统一的理论框架，通过信息论界限揭示了内存缓冲区与当前任务的交互如何影响泛化能力，并提出了更紧致的计算可行的预测界限。


<details>
  <summary>Details</summary>
Motivation: 持续学习在避免灾难性遗忘的同时从顺序任务中获取知识，但其泛化行为的理论理解仍有限，尤其是基于回放的方法。

Method: 提出信息论界限，分析内存缓冲区与当前任务的交互，并通过低维变量推导更紧致的预测界限。

Result: 实验证明所提界限能有效捕捉基于回放的CL中的泛化动态。

Conclusion: 有限样本回放与当前任务数据结合可改善泛化并缓解灾难性遗忘，理论框架广泛适用于多种学习算法。

Abstract: Continual learning (CL) has emerged as a dominant paradigm for acquiring
knowledge from sequential tasks while avoiding catastrophic forgetting.
Although many CL methods have been proposed to show impressive empirical
performance, the theoretical understanding of their generalization behavior
remains limited, particularly for replay-based approaches. In this paper, we
establish a unified theoretical framework for replay-based CL, deriving a
series of information-theoretic bounds that explicitly characterize how the
memory buffer interacts with the current task to affect generalization.
Specifically, our hypothesis-based bounds reveal that utilizing the limited
exemplars of previous tasks alongside the current task data, rather than
exhaustive replay, facilitates improved generalization while effectively
mitigating catastrophic forgetting. Furthermore, our prediction-based bounds
yield tighter and computationally tractable upper bounds of the generalization
gap through the use of low-dimensional variables. Our analysis is general and
broadly applicable to a wide range of learning algorithms, exemplified by
stochastic gradient Langevin dynamics (SGLD) as a representative method.
Comprehensive experimental evaluations demonstrate the effectiveness of our
derived bounds in capturing the generalization dynamics in replay-based CL
settings.

</details>


### [191] [FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling](https://arxiv.org/abs/2507.12053)
*Seanglidet Yean,Jiazu Zhou,Bu-Sung Lee,Markus Schläpfer*

Main category: cs.LG

TL;DR: 提出一种基于动态区域和土地用途的数据驱动方法，利用cGAN生成城市流动性流，适用于模拟场景，无需大量校准数据。


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖历史轨迹或静态假设，无法适应城市动态变化（如人口密度和土地用途），需新方法支持未来规划。

Method: 结合动态区域大小和土地用途原型，使用条件生成对抗网络（cGAN）融合历史数据与动态参数，生成流动性流。

Result: 在新加坡手机数据上验证，性能优于现有方法，支持快速生成可调空间粒度的流动性流。

Conclusion: 该方法为城市规划和交通优化提供了灵活、高效的流动性模拟工具。

Abstract: The mobility patterns of people in cities evolve alongside changes in land
use and population. This makes it crucial for urban planners to simulate and
analyze human mobility patterns for purposes such as transportation
optimization and sustainable urban development. Existing generative models
borrowed from machine learning rely heavily on historical trajectories and
often overlook evolving factors like changes in population density and land
use. Mechanistic approaches incorporate population density and facility
distribution but assume static scenarios, limiting their utility for future
projections where historical data for calibration is unavailable. This study
introduces a novel, data-driven approach for generating origin-destination
mobility flows tailored to simulated urban scenarios. Our method leverages
adaptive factors such as dynamic region sizes and land use archetypes, and it
utilizes conditional generative adversarial networks (cGANs) to blend
historical data with these adaptive parameters. The approach facilitates rapid
mobility flow generation with adjustable spatial granularity based on regions
of interest, without requiring extensive calibration data or complex behavior
modeling. The promising performance of our approach is demonstrated by its
application to mobile phone data from Singapore, and by its comparison with
existing methods.

</details>


### [192] [Emergence of Quantised Representations Isolated to Anisotropic Functions](https://arxiv.org/abs/2507.12070)
*George Bird*

Main category: cs.LG

TL;DR: 论文提出了一种基于Spotlight Resonance的新方法，用于研究网络原型的代数对称性如何预测任务无关的表示结构，并通过改变激活函数揭示了离散表示的形成机制。


<details>
  <summary>Details</summary>
Motivation: 研究功能形式选择如何无意中引入归纳偏差，导致表示中出现任务无关的结构，特别是当代形式如何诱导连续结构的离散化（量化效应）。

Method: 通过改变自编码器模型中的激活函数（离散代数置换等变对称与连续代数正交等变对称），进行消融研究，分析表示的形成和排列。

Result: 发现离散代数对称性激活函数倾向于产生离散表示，而连续代数对称性则保持连续性。量化表示与重建误差增加相关。

Conclusion: 功能形式的选择对表示结构有显著影响，可能导致离散化，这对下游可解释性研究（如祖母神经元、离散编码等）具有重要意义。

Abstract: This paper describes a novel methodology for determining representational
alignment, developed upon the existing Spotlight Resonance method. Using this,
it is found that algebraic symmetries of network primitives are a strong
predictor for task-agnostic structure in representations. Particularly, this
new tool is used to gain insight into how discrete representations can form and
arrange in autoencoder models, through an ablation study where only the
activation function is altered. Representations are found to tend to discretise
when the activation functions are defined through a discrete algebraic
permutation-equivariant symmetry. In contrast, they remain continuous under a
continuous algebraic orthogonal-equivariant definition. These findings
corroborate the hypothesis that functional form choices can carry unintended
inductive biases which produce task-independent artefactual structures in
representations, particularly that contemporary forms induce discretisation of
otherwise continuous structure -- a quantisation effect. Moreover, this
supports a general causal model for one mode in which discrete representations
may form, and could constitute a prerequisite for downstream interpretability
phenomena, including grandmother neurons, discrete coding schemes, general
linear features and possibly Superposition. Hence, this tool and proposed
mechanism for the influence of functional form on representations may provide
several insights into emergent interpretability research. Finally, preliminary
results indicate that quantisation of representations appears to correlate with
a measurable increase in reconstruction error, reinforcing previous conjectures
that this collapse can be detrimental.

</details>


### [193] [Measuring Informativeness Gap of (Mis)Calibrated Predictors](https://arxiv.org/abs/2507.12094)
*Yiding Feng,Wei Tang*

Main category: cs.LG

TL;DR: 本文提出了一种比较多个可能校准不准确的预测模型的方法，引入了信息差距的概念，并提供了其双重表征和一种新的信息度量方法。


<details>
  <summary>Details</summary>
Motivation: 解决决策者在多个可能校准不准确的预测模型中选择最优模型的问题。

Method: 引入信息差距的概念，定义其双重表征，并提出一种基于地球移动距离（EMD）的放松变体的信息度量方法。

Result: 证明了该方法的完备性和有效性，并展示了其在样本高效估计中的应用。

Conclusion: 该框架不仅概括了现有概念，还提供了新的组合结构结果，适用于校准和不校准的预测模型。

Abstract: In many applications, decision-makers must choose between multiple predictive
models that may all be miscalibrated. Which model (i.e., predictor) is more
"useful" in downstream decision tasks? To answer this, our first contribution
introduces the notion of the informativeness gap between any two predictors,
defined as the maximum normalized payoff advantage one predictor offers over
the other across all decision-making tasks. Our framework strictly generalizes
several existing notions: it subsumes U-Calibration [KLST-23] and Calibration
Decision Loss [HW-24], which compare a miscalibrated predictor to its
calibrated counterpart, and it recovers Blackwell informativeness [Bla-51,
Bla-53] as a special case when both predictors are perfectly calibrated. Our
second contribution is a dual characterization of the informativeness gap,
which gives rise to a natural informativeness measure that can be viewed as a
relaxed variant of the earth mover's distance (EMD) between two prediction
distributions. We show that this measure satisfies natural desiderata: it is
complete and sound, and it can be estimated sample-efficiently in the
prediction-only access setting. Along the way, we also obtain novel
combinatorial structural results when applying this measure to perfectly
calibrated predictors.

</details>


### [194] [Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks](https://arxiv.org/abs/2507.12127)
*Ngoc Duy Pham,Thusitha Dayaratne,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.LG

TL;DR: 论文提出了一种基于联邦学习（FL）的动态频谱分配（DSA）方法，解决了频谱感知中标签数据稀缺和安全漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 无线设备的快速增长导致频谱稀缺，传统集中式机器学习方法因隐私和带宽限制难以应用，因此探索分布式ML方法如FL。

Method: 采用半监督FL结合能量检测，训练模型于无标签数据；提出疫苗接种启发的防御机制应对数据投毒攻击。

Result: 实验验证了FLSS在无标签数据集上的高精度，以及对恶意参与者的强鲁棒性。

Conclusion: FLSS为频谱感知提供了一种高效且安全的解决方案，适用于未来无线网络。

Abstract: Advancements in wireless and mobile technologies, including 5G advanced and
the envisioned 6G, are driving exponential growth in wireless devices. However,
this rapid expansion exacerbates spectrum scarcity, posing a critical
challenge. Dynamic spectrum allocation (DSA)--which relies on sensing and
dynamically sharing spectrum--has emerged as an essential solution to address
this issue. While machine learning (ML) models hold significant potential for
improving spectrum sensing, their adoption in centralized ML-based DSA systems
is limited by privacy concerns, bandwidth constraints, and regulatory
challenges. To overcome these limitations, distributed ML-based approaches such
as Federated Learning (FL) offer promising alternatives. This work addresses
two key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of
labeled data for training FL models in practical spectrum sensing scenarios is
tackled with a semi-supervised FL approach, combined with energy detection,
enabling model training on unlabeled datasets. Second, we examine the security
vulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our
analysis highlights the shortcomings of existing majority-based defenses in
countering such attacks. To address these vulnerabilities, we propose a novel
defense mechanism inspired by vaccination, which effectively mitigates data
poisoning attacks without relying on majority-based assumptions. Extensive
experiments on both synthetic and real-world datasets validate our solutions,
demonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets
and maintain Byzantine robustness against both targeted and untargeted data
poisoning attacks, even when a significant proportion of participants are
malicious.

</details>


### [195] [HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD](https://arxiv.org/abs/2507.12133)
*Hanwen Liu,Yuhe Huang,Yifeng Gong,Yanjie Zhai,Jiaxuan Lu*

Main category: cs.LG

TL;DR: HyDRA是一种混合双模RF架构，结合优化的VMD和新型CNN、Transformer与Mamba融合架构，支持闭集和开集分类任务，实现高效无线设备识别。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统中的设备识别对安全至关重要，RFFI提供了一种非加密解决方案。

Method: HyDRA整合优化的VMD预处理和CNN、Transformer、Mamba融合架构，采用TDSE和MLFE处理信号。

Result: 在公共数据集上实现SOTA闭集分类精度，开集分类表现稳健，部署后达到毫秒级推理速度。

Conclusion: HyDRA为实时无线认证提供了高效、低功耗的实用解决方案。

Abstract: Device recognition is vital for security in wireless communication systems,
particularly for applications like access control. Radio Frequency Fingerprint
Identification (RFFI) offers a non-cryptographic solution by exploiting
hardware-induced signal distortions. This paper proposes HyDRA, a Hybrid
Dual-mode RF Architecture that integrates an optimized Variational Mode
Decomposition (VMD) with a novel architecture based on the fusion of
Convolutional Neural Networks (CNNs), Transformers, and Mamba components,
designed to support both closed-set and open-set classification tasks. The
optimized VMD enhances preprocessing efficiency and classification accuracy by
fixing center frequencies and using closed-form solutions. HyDRA employs the
Transformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and
the Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting
to varying conditions. Evaluation on public datasets demonstrates
state-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance
in our proposed open-set classification method, effectively identifying
unauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves
millisecond-level inference speed with low power consumption, providing a
practical solution for real-time wireless authentication in real-world
environments.

</details>


### [196] [RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization](https://arxiv.org/abs/2507.12142)
*Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: 提出了一种名为RiemannLoRA的新方法，通过将LoRA矩阵视为光滑流形上的元素，解决了初始化策略和低秩矩阵分解中的过参数化问题，提高了收敛速度和最终性能。


<details>
  <summary>Details</summary>
Motivation: LoRA在参数高效微调中广泛应用，但仍面临初始化策略和过参数化的挑战。

Method: 将固定秩的LoRA矩阵视为光滑流形上的元素，通过流形上的最快损失下降方向确定初始化，并采用数值稳定和计算高效的实现。

Result: 在LLM和扩散模型上的实验表明，RiemannLoRA在收敛速度和最终性能上优于标准LoRA及其改进方法。

Conclusion: RiemannLoRA通过统一框架解决了LoRA的挑战，显著提升了性能。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted standard for
parameter-efficient fine-tuning of large language models (LLMs), significantly
reducing memory and computational demands. However, challenges remain,
including finding optimal initialization strategies or mitigating
overparametrization in low-rank matrix factorization. In this work, we propose
a novel approach that addresses both of the challenges simultaneously within a
unified framework. Our method treats a set of fixed-rank LoRA matrices as a
smooth manifold. Considering adapters as elements on this manifold removes
overparametrization, while determining the direction of the fastest loss
decrease along the manifold provides initialization. Special care is taken to
obtain numerically stable and computationally efficient implementation of our
method, using best practices from numerical linear algebra and Riemannian
optimization. Experimental results on LLM and diffusion model architectures
demonstrate that RiemannLoRA consistently improves both convergence speed and
final performance over standard LoRA and its state-of-the-art modifications.

</details>


### [197] [FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale](https://arxiv.org/abs/2507.12144)
*Boris Bonev,Thorsten Kurth,Ankur Mahesh,Mauro Bisson,Jean Kossaifi,Karthik Kashinath,Anima Anandkumar,William D. Collins,Michael S. Pritchard,Alexander Keller*

Main category: cs.LG

TL;DR: FourCastNet 3通过几何机器学习方法提升全球天气建模，实现高效、准确的概率集合预报，超越传统模型并接近扩散方法，计算速度更快。


<details>
  <summary>Details</summary>
Motivation: 改进全球天气建模，解决传统方法在计算效率和概率校准上的不足。

Method: 采用纯卷积神经网络架构，结合模型和数据并行训练范式，适应球面几何。

Result: 在计算效率、概率校准和光谱保真度上表现优异，60天内预报稳定。

Conclusion: FourCastNet 3是改进气象预报和早期预警系统的有力候选。

Abstract: FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 90-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 20 seconds. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.

</details>


### [198] [PRISM: Distributed Inference for Foundation Models at Edge](https://arxiv.org/abs/2507.12145)
*Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang*

Main category: cs.LG

TL;DR: PRISM是一种高效的分布式Transformer推理策略，用于边缘设备，通过减少通信和计算开销，显著提升了部署效率。


<details>
  <summary>Details</summary>
Motivation: 基础模型（FMs）在边缘部署时面临通信和计算挑战，需要高效的解决方案。

Method: PRISM利用Segment Means表示近似中间特征，减少设备间通信；重构自注意力机制以减少冗余计算；设计分区感知的因果掩码。

Result: 在ViT、BERT和GPT-2上测试，通信开销减少高达99.2%，计算开销减少51.24%，精度损失较小。

Conclusion: PRISM为资源受限的边缘环境提供了一种可扩展且实用的基础模型部署方案。

Abstract: Foundation models (FMs) have achieved remarkable success across a wide range
of applications, from image classification to natural langurage processing, but
pose significant challenges for deployment at edge. This has sparked growing
interest in developing practical and efficient strategies for bringing
foundation models to edge environments. In this work, we propose PRISM, a
communication-efficient and compute-aware strategy for distributed Transformer
inference on edge devices. Our method leverages a Segment Means representation
to approximate intermediate output features, drastically reducing inter-device
communication. Additionally, we restructure the self-attention mechanism to
eliminate redundant computations caused by per-device Key/Value calculation in
position-wise partitioning and design a partition-aware causal masking scheme
tailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2
across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and
CBT. Our results demonstrate substantial reductions in communication overhead
(up to 99.2% for BERT at compression rate CR = 128) and per-device computation
(51.24% for BERT at the same setting), with only minor accuracy degradation.
This method offers a scalable and practical solution for deploying foundation
models in distributed resource-constrained environments.

</details>


### [199] [Multi-Component VAE with Gaussian Markov Random Field](https://arxiv.org/abs/2507.12165)
*Fouad Oubari,Mohamed El-Baha,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 提出了一种基于高斯马尔可夫随机场的多组件变分自编码器（GMRF MCVAE），用于建模复杂多组件数据中的依赖关系，显著提升了生成结果的结构一致性。


<details>
  <summary>Details</summary>
Motivation: 当前多组件变分自编码器依赖简化聚合策略，忽略了关键细节，导致生成组件间结构一致性不足。

Method: 在变分自编码器的先验和后验分布中嵌入高斯马尔可夫随机场，显式建模组件间关系。

Result: 在合成Copula数据集上达到SOTA性能，在PolyMNIST基准测试中表现优异，并在真实BIKED数据集上显著提升结构一致性。

Conclusion: GMRF MCVAE特别适用于需要建模多组件一致性的实际应用。

Abstract: Multi-component datasets with intricate dependencies, like industrial
assemblies or multi-modal imaging, challenge current generative modeling
techniques. Existing Multi-component Variational AutoEncoders typically rely on
simplified aggregation strategies, neglecting critical nuances and consequently
compromising structural coherence across generated components. To explicitly
address this gap, we introduce the Gaussian Markov Random Field Multi-Component
Variational AutoEncoder , a novel generative framework embedding Gaussian
Markov Random Fields into both prior and posterior distributions. This design
choice explicitly models cross-component relationships, enabling richer
representation and faithful reproduction of complex interactions. Empirically,
our GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula
dataset specifically constructed to evaluate intricate component relationships,
demonstrates competitive results on the PolyMNIST benchmark, and significantly
enhances structural coherence on the real-world BIKED dataset. Our results
indicate that the GMRF MCVAE is especially suited for practical applications
demanding robust and realistic modeling of multi-component coherence

</details>


### [200] [RadioDiff-3D: A 3D$\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication](https://arxiv.org/abs/2507.12166)
*Xiucheng Wang,Qiming Zhang,Nan Cheng,Junting Chen,Zezhong Zhang,Zan Li,Shuguang Cui,Xuemin Shen*

Main category: cs.LG

TL;DR: 论文提出UrbanRadio3D数据集和RadioDiff-3D方法，用于构建高分辨率3D无线电地图，解决现有方法在方向和时间参数上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有无线电地图方法仅关注2D平面的路径损耗，忽略了方向和时间等关键参数，且缺乏泛化能力。

Method: 通过射线追踪构建UrbanRadio3D数据集，并提出基于3D卷积的UNet和扩散模型RadioDiff-3D。

Result: RadioDiff-3D在多种环境动态下构建高维无线电地图表现优异。

Conclusion: 该工作为3D环境感知通信提供了基础数据集和基准。

Abstract: Radio maps (RMs) serve as a critical foundation for enabling
environment-aware wireless communication, as they provide the spatial
distribution of wireless channel characteristics. Despite recent progress in RM
construction using data-driven approaches, most existing methods focus solely
on pathloss prediction in a fixed 2D plane, neglecting key parameters such as
direction of arrival (DoA), time of arrival (ToA), and vertical spatial
variations. Such a limitation is primarily due to the reliance on static
learning paradigms, which hinder generalization beyond the training data
distribution. To address these challenges, we propose UrbanRadio3D, a
large-scale, high-resolution 3D RM dataset constructed via ray tracing in
realistic urban environments. UrbanRadio3D is over 37$\times$3 larger than
previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,
forming a novel 3D$\times$33D dataset with 7$\times$3 more height layers than
prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet
with 3D convolutional operators is proposed. Moreover, we further introduce
RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D
convolutional architecture. RadioDiff-3D supports both radiation-aware
scenarios with known transmitter locations and radiation-unaware settings based
on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate
that RadioDiff-3D achieves superior performance in constructing rich,
high-dimensional radio maps under diverse environmental dynamics. This work
provides a foundational dataset and benchmark for future research in 3D
environment-aware communication. The dataset is available at
https://github.com/UNIC-Lab/UrbanRadio3D.

</details>


### [201] [Explainable Evidential Clustering](https://arxiv.org/abs/2507.12192)
*Victor F. Lopes de Souza,Karima Bakhti,Sofiane Ramdani,Denis Mottet,Abdelhak Imoussaten*

Main category: cs.LG

TL;DR: 本文探讨了如何解释基于Dempster-Shafer理论的证据聚类结果，提出了一种称为IEMM的算法，通过决策树提供可解释的解释。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常存在不确定性和不精确性，传统方法难以处理。证据聚类虽能解决这些问题，但其结果解释问题尚未充分研究，尤其是在医疗等高风险领域。

Method: 基于代表性概念，通过效用函数扩展以处理部分标记，定义证据错误性为解释成本，并构建针对证据分类器的解释器。提出IEMM算法，生成可解释的决策树解释。

Result: 在合成和真实数据上验证了IEMM算法，根据决策者偏好，93%的情况下能提供满意的解释。

Conclusion: IEMM算法为证据聚类提供了可解释且谨慎的解释方法，适用于高风险领域。

Abstract: Unsupervised classification is a fundamental machine learning problem.
Real-world data often contain imperfections, characterized by uncertainty and
imprecision, which are not well handled by traditional methods. Evidential
clustering, based on Dempster-Shafer theory, addresses these challenges. This
paper explores the underexplored problem of explaining evidential clustering
results, which is crucial for high-stakes domains such as healthcare. Our
analysis shows that, in the general case, representativity is a necessary and
sufficient condition for decision trees to serve as abductive explainers.
Building on the concept of representativity, we generalize this idea to
accommodate partial labeling through utility functions. These functions enable
the representation of "tolerable" mistakes, leading to the definition of
evidential mistakeness as explanation cost and the construction of explainers
tailored to evidential classifiers. Finally, we propose the Iterative
Evidential Mistake Minimization (IEMM) algorithm, which provides interpretable
and cautious decision tree explanations for evidential clustering functions. We
validate the proposed algorithm on synthetic and real-world data. Taking into
account the decision-maker's preferences, we were able to provide an
explanation that was satisfactory up to 93% of the time.

</details>


### [202] [Selective Quantization Tuning for ONNX Models](https://arxiv.org/abs/2507.12196)
*Nikolaos Louloudakis,Ajitha Rajan*

Main category: cs.LG

TL;DR: TuneQn是一个选择性量化工具套件，通过多目标优化和性能分析，在保持模型精度的同时减少模型大小和计算需求。


<details>
  <summary>Details</summary>
Motivation: 完全量化模型可能导致性能下降和部署困难，因此需要一种选择性量化的方法来解决这些问题。

Method: TuneQn结合选择性量化、部署、执行、性能分析和多目标优化，生成优化的ONNX模型。

Result: 实验显示，TuneQn能减少54.14%的精度损失和72.9%的模型大小。

Conclusion: TuneQn有效实现了选择性量化和优化，适用于不同硬件设备。

Abstract: Quantization is a process that reduces the precision of deep neural network
models to lower model size and computational demands, often at the cost of
accuracy. However, fully quantized models may exhibit sub-optimal performance
below acceptable levels and face deployment challenges on low-end hardware
accelerators due to practical constraints. To address these issues,
quantization can be selectively applied to only a subset of layers, but
selecting which layers to exclude is non-trivial. To this direction, we propose
TuneQn, a suite enabling selective quantization, deployment and execution of
ONNX models across various CPU and GPU devices, combined with profiling and
multi-objective optimization. TuneQn generates selectively quantized ONNX
models, deploys them on different hardware, measures performance on metrics
like accuracy and size, performs Pareto Front minimization to identify the best
model candidate and visualizes the results. To demonstrate the effectiveness of
TuneQn, we evaluated TuneQn on four ONNX models with two quantization settings
across CPU and GPU devices. As a result, we demonstrated that our utility
effectively performs selective quantization and tuning, selecting ONNX model
candidates with up to a $54.14$% reduction in accuracy loss compared to the
fully quantized model, and up to a $72.9$% model size reduction compared to the
original model.

</details>


### [203] [Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation](https://arxiv.org/abs/2507.12218)
*Tomohisa Okazaki*

Main category: cs.LG

TL;DR: 该论文提出了一种基于物理信息的线性模型（PILM），用于解决偏微分方程（PDEs）的正反问题，并通过地壳应变率估计验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的PDE求解方法在复杂问题中可能效率不足，而物理信息神经网络（PINN）虽受关注，但缺乏解析解。PILM旨在提供一种解析可解的线性模型框架。

Method: PILM使用基函数的线性组合表示解，从而获得解析最优解。模型在正反问题中进行了验证，包括不确定边界条件的情况。

Result: PILM在地壳应变率估计中表现良好，数学正则化在贝叶斯视角下优于物理正则化。

Conclusion: PILM为线性正反问题、欠定系统和物理正则化提供了解析可解的框架，具有广泛应用潜力。

Abstract: Many physical systems are described by partial differential equations (PDEs),
and solving these equations and estimating their coefficients or boundary
conditions (BCs) from observational data play a crucial role in understanding
the associated phenomena. Recently, a machine learning approach known as
physics-informed neural network, which solves PDEs using neural networks by
minimizing the sum of residuals from the PDEs, BCs, and data, has gained
significant attention in the scientific community. In this study, we
investigate a physics-informed linear model (PILM) that uses linear
combinations of basis functions to represent solutions, thereby enabling an
analytical representation of optimal solutions. The PILM was formulated and
verified for illustrative forward and inverse problems including cases with
uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain
rates using geodetic data. Specifically, physical regularization that enforces
elastic equilibrium on the velocity fields was compared with mathematical
regularization that imposes smoothness constraints. From a Bayesian
perspective, mathematical regularization exhibited superior performance. The
PILM provides an analytically solvable framework applicable to linear forward
and inverse problems, underdetermined systems, and physical regularization.

</details>


### [204] [Optimizers Qualitatively Alter Solutions And We Should Leverage This](https://arxiv.org/abs/2507.12224)
*Razvan Pascanu,Clare Lyle,Ionut-Vlad Modoranu,Naima Elosegui Borras,Dan Alistarh,Petar Velickovic,Sarath Chandar,Soham De,James Martens*

Main category: cs.LG

TL;DR: 论文探讨了深度神经网络（DNNs）优化器的角色，指出其不仅影响收敛速度，还影响学习解的性质，呼吁关注优化器设计对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 早期对DNNs可行性的怀疑源于其非线性特性导致无法保证收敛到全局最优解，但实践表明标准训练协议下的大规模DNNs表现良好。然而，社区过于关注优化效率，忽视了优化器对学习解性质的影响。

Method: 通过分析优化器在DNNs中的作用，提出优化器不仅影响收敛速度，还能通过引入归纳偏置改变模型的有效表达能力。

Result: 优化器设计是影响模型性能的关键因素之一，应被视为与架构和数据同等重要的杠杆。

Conclusion: 呼吁社区更深入地理解现有优化器的偏置，并设计新的优化器以引导特定解的性质，而不仅关注收敛速度。

Abstract: Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not
guarantee convergence to a unique global minimum of the loss when using
optimizers relying only on local information, such as SGD. Indeed, this was a
primary source of skepticism regarding the feasibility of DNNs in the early
days of the field. The past decades of progress in deep learning have revealed
this skepticism to be misplaced, and a large body of empirical evidence shows
that sufficiently large DNNs following standard training protocols exhibit
well-behaved optimization dynamics that converge to performant solutions. This
success has biased the community to use convex optimization as a mental model
for learning, leading to a focus on training efficiency, either in terms of
required iteration, FLOPs or wall-clock time, when improving optimizers. We
argue that, while this perspective has proven extremely fruitful, another
perspective specific to DNNs has received considerably less attention: the
optimizer not only influences the rate of convergence, but also the qualitative
properties of the learned solutions. Restated, the optimizer can and will
encode inductive biases and change the effective expressivity of a given class
of models. Furthermore, we believe the optimizer can be an effective way of
encoding desiderata in the learning process. We contend that the community
should aim at understanding the biases of already existing methods, as well as
aim to build new optimizers with the explicit intent of inducing certain
properties of the solution, rather than solely judging them based on their
convergence rates. We hope our arguments will inspire research to improve our
understanding of how the learning process can impact the type of solution we
converge to, and lead to a greater recognition of optimizers design as a
critical lever that complements the roles of architecture and data in shaping
model outcomes.

</details>


### [205] [Robust Causal Discovery in Real-World Time Series with Power-Laws](https://arxiv.org/abs/2507.12257)
*Matteo Tusoni,Giuseppe Masi,Andrea Coletta,Aldo Glielmo,Viviana Arrigoni,Novella Bartolini*

Main category: cs.LG

TL;DR: 提出了一种基于幂律谱特征的鲁棒因果发现方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索随机时间序列中的因果关系具有广泛应用，但现有方法对噪声敏感，导致误导性推断。

Method: 利用时间序列的幂律谱特征提取真实因果信号，构建鲁棒因果发现方法。

Result: 在合成基准和真实数据集上均优于现有方法，证明了其鲁棒性和实用性。

Conclusion: 该方法通过幂律谱特征有效提升了因果发现的准确性和鲁棒性。

Abstract: Exploring causal relationships in stochastic time series is a challenging yet
crucial task with a vast range of applications, including finance, economics,
neuroscience, and climate science. Many algorithms for Causal Discovery (CD)
have been proposed, but they often exhibit a high sensitivity to noise,
resulting in misleading causal inferences when applied to real data. In this
paper, we observe that the frequency spectra of typical real-world time series
follow a power-law distribution, notably due to an inherent self-organizing
behavior. Leveraging this insight, we build a robust CD method based on the
extraction of power -law spectral features that amplify genuine causal signals.
Our method consistently outperforms state-of-the-art alternatives on both
synthetic benchmarks and real-world datasets with known causal structures,
demonstrating its robustness and practical relevance.

</details>


### [206] [Nonlinear Concept Erasure: a Density Matching Approach](https://arxiv.org/abs/2507.12341)
*Antoine Saillenfest,Pirmin Lemberger*

Main category: cs.LG

TL;DR: 论文提出了一种名为LEOPARD的概念擦除方法，通过正交投影从文本表示中移除敏感信息，同时保留其他语义信息，以促进公平性。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络模型在公平性要求下无法从文本表示中推断敏感信息（如性别或种族）的挑战。

Method: 学习嵌入空间中的正交投影，使离散概念的条件特征分布在投影后无法区分，并通过调整投影秩控制信息移除程度。

Result: LEOPARD在经典NLP基准测试中实现了最先进的离散属性非线性擦除性能，并有效减少了深度非线性分类器的偏见。

Conclusion: LEOPARD方法在移除敏感信息和促进模型公平性方面表现出色。

Abstract: Ensuring that neural models used in real-world applications cannot infer
sensitive information, such as demographic attributes like gender or race, from
text representations is a critical challenge when fairness is a concern. We
address this issue through concept erasure, a process that removes information
related to a specific concept from distributed representations while preserving
as much of the remaining semantic information as possible. Our approach
involves learning an orthogonal projection in the embedding space, designed to
make the class-conditional feature distributions of the discrete concept to
erase indistinguishable after projection. By adjusting the rank of the
projector, we control the extent of information removal, while its
orthogonality ensures strict preservation of the local structure of the
embeddings. Our method, termed $\overline{\mathrm{L}}$EOPARD, achieves
state-of-the-art performance in nonlinear erasure of a discrete attribute on
classic natural language processing benchmarks. Furthermore, we demonstrate
that $\overline{\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear
classifiers, thereby promoting fairness.

</details>


### [207] [A Framework for Nonstationary Gaussian Processes with Neural Network Parameters](https://arxiv.org/abs/2507.12262)
*Zachary James,Joseph Guinness*

Main category: cs.LG

TL;DR: 提出一种结合非平稳核与神经网络的框架，提升高斯过程的表达能力，并在多个数据集上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程使用平稳核限制了模型表达能力，无法适应复杂数据集。

Method: 通过神经网络动态调整非平稳核参数，并与高斯过程联合训练。

Result: 在多个数据集上，该方法在准确性和对数得分上优于平稳模型和变分推断层次模型。

Conclusion: 该方法灵活且易于扩展，能有效恢复非平稳参数，适用于复杂数据建模。

Abstract: Gaussian processes have become a popular tool for nonparametric regression
because of their flexibility and uncertainty quantification. However, they
often use stationary kernels, which limit the expressiveness of the model and
may be unsuitable for many datasets. We propose a framework that uses
nonstationary kernels whose parameters vary across the feature space, modeling
these parameters as the output of a neural network that takes the features as
input. The neural network and Gaussian process are trained jointly using the
chain rule to calculate derivatives. Our method clearly describes the behavior
of the nonstationary parameters and is compatible with approximation methods
for scaling to large datasets. It is flexible and easily adapts to different
nonstationary kernels without needing to redesign the optimization procedure.
Our methods are implemented with the GPyTorch library and can be readily
modified. We test a nonstationary variance and noise variant of our method on
several machine learning datasets and find that it achieves better accuracy and
log-score than both a stationary model and a hierarchical model approximated
with variational inference. Similar results are observed for a model with only
nonstationary variance. We also demonstrate our approach's ability to recover
the nonstationary parameters of a spatial dataset.

</details>


### [208] [RegCL: Continual Adaptation of Segment Anything Model via Model Merging](https://arxiv.org/abs/2507.12297)
*Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang*

Main category: cs.LG

TL;DR: 本文提出RegCL，一种新型非回放持续学习框架，通过模型合并实现多领域知识高效整合，解决Segment Anything Model（SAM）在特定领域性能受限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为针对特定领域的适配器调整，跨领域使用时性能下降严重，限制了模型的可扩展性。

Method: RegCL将模型合并算法引入持续学习，通过优化权重合并不同领域的适配模块（如LoRA模块），最小化预测差异。

Result: 实验表明，RegCL在多领域数据集上表现优异，验证了其在动态场景中的有效性。

Conclusion: RegCL通过高效合并多领域知识，解决了持续学习中的灾难性遗忘问题，同时保持参数效率。

Abstract: To address the performance limitations of the Segment Anything Model (SAM) in
specific domains, existing works primarily adopt adapter-based one-step
adaptation paradigms. However, some of these methods are specific developed for
specific domains. If used on other domains may lead to performance degradation.
This issue of catastrophic forgetting severely limits the model's scalability.
To address this issue, this paper proposes RegCL, a novel non-replay continual
learning (CL) framework designed for efficient multi-domain knowledge
integration through model merging. Specifically, RegCL incorporates the model
merging algorithm into the continual learning paradigm by merging the
parameters of SAM's adaptation modules (e.g., LoRA modules) trained on
different domains. The merging process is guided by weight optimization, which
minimizes prediction discrepancies between the merged model and each of the
domain-specific models. RegCL effectively consolidates multi-domain knowledge
while maintaining parameter efficiency, i.e., the model size remains constant
regardless of the number of tasks, and no historical data storage is required.
Experimental results demonstrate that RegCL achieves favorable continual
learning performance across multiple downstream datasets, validating its
effectiveness in dynamic scenarios.

</details>


### [209] [PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning](https://arxiv.org/abs/2507.12305)
*M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk*

Main category: cs.LG

TL;DR: 提出了一种基于提示的在线持续学习方法，解决了数据隐私和参数增长问题，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在线持续学习中数据隐私限制和参数增长问题需要解决。

Method: 结合轻量级提示生成器、可训练缩放移位器、预训练模型保护和硬软更新机制。

Result: 在多个数据集上性能显著优于现有技术，参数较少且训练效率适中。

Conclusion: 该方法在性能和效率上均表现优异，代码已开源。

Abstract: The data privacy constraint in online continual learning (OCL), where the
data can be seen only once, complicates the catastrophic forgetting problem in
streaming data. A common approach applied by the current SOTAs in OCL is with
the use of memory saving exemplars or features from previous classes to be
replayed in the current task. On the other hand, the prompt-based approach
performs excellently in continual learning but with the cost of a growing
number of trainable parameters. The first approach may not be applicable in
practice due to data openness policy, while the second approach has the issue
of throughput associated with the streaming data. In this study, we propose a
novel prompt-based method for online continual learning that includes 4 main
components: (1) single light-weight prompt generator as a general knowledge,
(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model
(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our
proposed method achieves significantly higher performance than the current
SOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity
analysis shows that our method requires a relatively smaller number of
parameters and achieves moderate training time, inference time, and throughput.
For further study, the source code of our method is available at
https://github.com/anwarmaxsum/PROL.

</details>


### [210] [Thought Purity: Defense Paradigm For Chain-of-Thought Attack](https://arxiv.org/abs/2507.12314)
*Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou*

Main category: cs.LG

TL;DR: 论文提出了一种名为Thought Purity（TP）的防御范式，用于增强强化学习训练的大型推理模型（LRMs）对安全威胁的抵抗力，同时保持其操作效能。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习训练的大型推理模型（如Deepseek-R1）在推理能力上表现优异，但其在Chain-of-Thought（CoT）生成过程中容易受到安全威胁（如后门提示攻击），导致推理机制被系统性地破坏。

Method: TP通过三个协同组件实现防御：（1）安全性优化的数据处理流程；（2）强化学习增强的规则约束；（3）自适应监控指标。

Result: 该方法首次为强化学习对齐的推理系统提供了针对CoTA漏洞的全面防御机制，显著提升了安全性与功能性的平衡。

Conclusion: TP为下一代AI架构的安全性与功能性平衡提供了重要进展。

Abstract: While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,
Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large
Language Models (LLMs) domain, their susceptibility to security threats remains
a critical vulnerability. This weakness is particularly evident in
Chain-of-Thought (CoT) generation processes, where adversarial methods like
backdoor prompt attacks can systematically subvert the model's core reasoning
mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this
vulnerability through exploiting prompt controllability, simultaneously
degrading both CoT safety and task performance with low-cost interventions. To
address this compounded security-performance vulnerability, we propose Thought
Purity (TP): a defense paradigm that systematically strengthens resistance to
malicious content while preserving operational efficacy. Our solution achieves
this through three synergistic components: (1) a safety-optimized data
processing pipeline (2) reinforcement learning-enhanced rule constraints (3)
adaptive monitoring metrics. Our approach establishes the first comprehensive
defense mechanism against CoTA vulnerabilities in reinforcement
learning-aligned reasoning systems, significantly advancing the
security-functionality equilibrium for next-generation AI architectures.

</details>


### [211] [Heat Kernel Goes Topological](https://arxiv.org/abs/2507.12380)
*Maximilian Krahn,Vikas Garg*

Main category: cs.LG

TL;DR: 提出了一种基于组合复形（CCs）的拉普拉斯算子的拓扑框架，通过高效计算热核作为节点描述符，解决了高阶消息传递的计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 拓扑神经网络虽然强大，但高阶消息传递导致计算成本高，需要一种更高效的方法。

Method: 引入组合复形上的拉普拉斯算子，计算热核作为节点描述符，支持多尺度信息和置换等变表示。

Result: 理论证明方法具有最大表达能力，能区分任意非同构组合复形；实验显示计算效率显著优于现有拓扑方法，并在分子数据集上表现优异。

Conclusion: 该方法为拓扑深度学习提供了高效且表达能力强的表示，为分子分类和性质预测任务开辟了新途径。

Abstract: Topological neural networks have emerged as powerful successors of graph
neural networks. However, they typically involve higher-order message passing,
which incurs significant computational expense. We circumvent this issue with a
novel topological framework that introduces a Laplacian operator on
combinatorial complexes (CCs), enabling efficient computation of heat kernels
that serve as node descriptors. Our approach captures multiscale information
and enables permutation-equivariant representations, allowing easy integration
into modern transformer-based architectures.
  Theoretically, the proposed method is maximally expressive because it can
distinguish arbitrary non-isomorphic CCs. Empirically, it significantly
outperforms existing topological methods in terms of computational efficiency.
Besides demonstrating competitive performance with the state-of-the-art
descriptors on standard molecular datasets, it exhibits superior capability in
distinguishing complex topological structures and avoiding blind spots on
topological benchmarks. Overall, this work advances topological deep learning
by providing expressive yet scalable representations, thereby opening up
exciting avenues for molecular classification and property prediction tasks.

</details>


### [212] [Improving Reinforcement Learning Sample-Efficiency using Local Approximation](https://arxiv.org/abs/2507.12383)
*Mohit Prashant,Arvind Easwaran*

Main category: cs.LG

TL;DR: 本文提出了在无限时间马尔可夫决策过程（MDP）中，比现有文献更精确的强化学习（RL）样本复杂度的PAC边界。通过近似原始MDP，样本复杂度降低至O(SA log A)。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于两点：一是状态间的距离影响其值函数的相关性；二是学习状态的最优值所需的样本复杂度与其邻近状态无关。

Method: 方法是通过构建原始MDP的子集来近似原始MDP，从而减少样本复杂度，并扩展到无限时间、无模型设置。

Result: 结果显示样本复杂度降低了一个对数因子，达到O(SA log A)时间步。

Conclusion: 结论是通过实验对比，证明了所提算法的显著改进。

Abstract: In this study, we derive Probably Approximately Correct (PAC) bounds on the
asymptotic sample-complexity for RL within the infinite-horizon Markov Decision
Process (MDP) setting that are sharper than those in existing literature. The
premise of our study is twofold: firstly, the further two states are from each
other, transition-wise, the less relevant the value of the first state is when
learning the $\epsilon$-optimal value of the second; secondly, the amount of
'effort', sample-complexity-wise, expended in learning the $\epsilon$-optimal
value of a state is independent of the number of samples required to learn the
$\epsilon$-optimal value of a second state that is a sufficient number of
transitions away from the first. Inversely, states within each other's vicinity
have values that are dependent on each other and will require a similar number
of samples to learn. By approximating the original MDP using smaller MDPs
constructed using subsets of the original's state-space, we are able to reduce
the sample-complexity by a logarithmic factor to $O(SA \log A)$ timesteps,
where $S$ and $A$ are the state and action space sizes. We are able to extend
these results to an infinite-horizon, model-free setting by constructing a
PAC-MDP algorithm with the aforementioned sample-complexity. We conclude with
showing how significant the improvement is by comparing our algorithm against
prior work in an experimental setting.

</details>


### [213] [Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries](https://arxiv.org/abs/2507.12384)
*Bo Wen,Guoyun Gao,Zhicheng Xu,Ruibin Mao,Xiaojuan Qi,X. Sharon Hu,Xunzhao Yin,Can Li*

Main category: cs.LG

TL;DR: 提出了一种基于$MoS_2$闪存模拟CAM的软树模型硬件-软件协同设计方法，显著提升了树模型的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 人工智能的快速发展引发了对可信赖性的担忧，尤其是树模型在扩展性和硬件性能上的不足。

Method: 采用$MoS_2$闪存模拟CAM实现软边界，结合软树模型进行高效推理。

Result: 在WDBC数据库上达到96%准确率，MNIST数据集上仅下降0.6%准确率，显著优于传统方法。

Conclusion: 该方法为提升AI可信赖性和效率的专用硬件设计提供了新思路。

Abstract: The rapid advancement of artificial intelligence has raised concerns
regarding its trustworthiness, especially in terms of interpretability and
robustness. Tree-based models like Random Forest and XGBoost excel in
interpretability and accuracy for tabular data, but scaling them remains
computationally expensive due to poor data locality and high data dependence.
Previous efforts to accelerate these models with analog content addressable
memory (CAM) have struggled, due to the fact that the difficult-to-implement
sharp decision boundaries are highly susceptible to device variations, which
leads to poor hardware performance and vulnerability to adversarial attacks.
This work presents a novel hardware-software co-design approach using $MoS_2$
Flash-based analog CAM with inherent soft boundaries, enabling efficient
inference with soft tree-based models. Our soft tree model inference
experiments on $MoS_2$ analog CAM arrays show this method achieves exceptional
robustness against device variation and adversarial attacks while achieving
state-of-the-art accuracy. Specifically, our fabricated analog CAM arrays
achieve $96\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,
while maintaining decision explainability. Our experimentally calibrated model
validated only a $0.6\%$ accuracy drop on the MNIST dataset under $10\%$ device
threshold variation, compared to a $45.3\%$ drop for traditional decision
trees. This work paves the way for specialized hardware that enhances AI's
trustworthiness and efficiency.

</details>


### [214] [ROC-n-reroll: How verifier imperfection affects test-time scaling](https://arxiv.org/abs/2507.12399)
*Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang*

Main category: cs.LG

TL;DR: 论文研究了测试时扩展（test-time scaling）中验证器不完美对性能的影响，通过ROC曲线的几何特性分析了Best-of-N和拒绝采样的实例级准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对验证器不完美如何影响测试时扩展性能的理论理解，本文旨在填补这一空白。

Method: 通过分析验证器ROC曲线的几何特性，理论推导了Best-of-N和拒绝采样的实例级准确性。

Result: 拒绝采样在固定计算量下优于Best-of-N，但在无限计算量下两者性能趋同，由ROC曲线原点附近的斜率决定。

Conclusion: 验证器的ROC曲线几何特性决定了测试时扩展的性能，实验结果支持了理论分析。

Abstract: Test-time scaling aims to improve language model performance by leveraging
additional compute during inference. While many works have empirically studied
techniques like Best-of-N (BoN) and rejection sampling that make use of a
verifier to enable test-time scaling, there is little theoretical understanding
of how verifier imperfection affects performance. In this work, we address this
gap. Specifically, we prove how instance-level accuracy of these methods is
precisely characterized by the geometry of the verifier's ROC curve.
Interestingly, while scaling is determined by the local geometry of the ROC
curve for rejection sampling, it depends on global properties of the ROC curve
for BoN. As a consequence when the ROC curve is unknown, it is impossible to
extrapolate the performance of rejection sampling based on the low-compute
regime. Furthermore, while rejection sampling outperforms BoN for fixed
compute, in the infinite-compute limit both methods converge to the same level
of accuracy, determined by the slope of the ROC curve near the origin. Our
theoretical results are confirmed by experiments on GSM8K using different
versions of Llama and Qwen to generate and verify solutions.

</details>


### [215] [NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data](https://arxiv.org/abs/2507.12412)
*Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva*

Main category: cs.LG

TL;DR: NOCTA是一种非贪婪目标成本权衡获取方法，用于在资源受限的预测任务中动态选择最具信息量的特征。


<details>
  <summary>Details</summary>
Motivation: 在医疗等资源受限的场景中，动态获取特征的成本和重要性需要权衡，现有方法难以同时考虑时间动态和获取成本。

Method: 提出NOCTA方法，包括非参数（NOCTA-NP）和参数（NOCTA-P）两种互补的估计器，用于动态选择特征。

Result: 在合成和真实医疗数据集上的实验表明，NOCTA优于现有基线方法。

Conclusion: NOCTA能有效权衡特征获取的成本和信息量，适用于资源受限的动态预测任务。

Abstract: In many critical applications, resource constraints limit the amount of
information that can be gathered to make predictions. For example, in
healthcare, patient data often spans diverse features ranging from lab tests to
imaging studies. Each feature may carry different information and must be
acquired at a respective cost of time, money, or risk to the patient. Moreover,
temporal prediction tasks, where both instance features and labels evolve over
time, introduce additional complexity in deciding when or what information is
important. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff
Acquisition method that sequentially acquires the most informative features at
inference time while accounting for both temporal dynamics and acquisition
cost. We first introduce a cohesive estimation target for our NOCTA setting,
and then develop two complementary estimators: 1) a non-parametric method based
on nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric
method that directly predicts the utility of potential acquisitions (NOCTA-P).
Experiments on synthetic and real-world medical datasets demonstrate that both
NOCTA variants outperform existing baselines.

</details>


### [216] [Mixture of Raytraced Experts](https://arxiv.org/abs/2507.12419)
*Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti*

Main category: cs.LG

TL;DR: 提出了一种动态选择专家序列的混合专家架构（Mixture of Raytraced Experts），支持可变计算深度和宽度，无需负载均衡机制，训练效率提升10%-40%。


<details>
  <summary>Details</summary>
Motivation: 现有混合专家架构（MoE）通常需要固定计算量，限制了灵活性和效率。

Method: 通过迭代采样候选专家序列，类似RNN训练方式展开序列，动态生成计算图。

Result: 实验显示训练周期减少10%-40%，精度相当或更高。

Conclusion: 该方法为MoE领域提供了新的研究方向，可能设计出更快、表达能力更强的模型。

Abstract: We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts
(MoE) architecture which can dynamically select sequences of experts, producing
computational graphs of variable width and depth. Existing MoE architectures
generally require a fixed amount of computation for a given sample. Our
approach, in contrast, yields predictions with increasing accuracy as the
computation cycles through the experts' sequence. We train our model by
iteratively sampling from a set of candidate experts, unfolding the sequence
akin to how Recurrent Neural Networks are trained. Our method does not require
load-balancing mechanisms, and preliminary experiments show a reduction in
training epochs of 10\% to 40\% with a comparable/higher accuracy. These
results point to new research directions in the field of MoEs, allowing the
design of potentially faster and more expressive models. The code is available
at https://github.com/nutig/RayTracing

</details>


### [217] [Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks](https://arxiv.org/abs/2507.12435)
*Yi Li,David Mccoy,Nolan Gunter,Kaitlyn Lee,Alejandro Schuler,Mark van der Laan*

Main category: cs.LG

TL;DR: 论文提出了一种名为TDA的新框架，将TMLE直接嵌入神经网络参数空间，解决了现有方法在因果推断中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络在预测方面强大，但在因果参数推断（如治疗效果或生存曲线）方面缺乏有效性。现有方法要么依赖不保证高效影响函数方程的目标损失，要么计算成本高昂。

Method: TDA通过分区模型参数并冻结大部分参数，仅更新一小部分“目标”子集，沿目标梯度迭代更新，从而消除一阶偏差并生成有效置信区间。

Result: 在IHDP数据集和模拟生存数据上，TDA减少了偏差并提高了覆盖率，优于标准神经网络估计器和现有方法。

Conclusion: TDA为复杂多参数目标的深度架构提供了一种直接、可扩展的严格因果推断途径。

Abstract: Modern deep neural networks are powerful predictive tools yet often lack
valid inference for causal parameters, such as treatment effects or entire
survival curves. While frameworks like Double Machine Learning (DML) and
Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,
existing neural implementations either rely on "targeted losses" that do not
guarantee solving the efficient influence function equation or computationally
expensive post-hoc "fluctuations" for multi-parameter settings. We propose
Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly
into the network's parameter space with no restrictions on the backbone
architecture. Specifically, TDA partitions model parameters - freezing all but
a small "targeting" subset - and iteratively updates them along a targeting
gradient, derived from projecting the influence functions onto the span of the
gradients of the loss with respect to weights. This procedure yields plug-in
estimates that remove first-order bias and produce asymptotically valid
confidence intervals. Crucially, TDA easily extends to multi-dimensional causal
estimands (e.g., entire survival curves) by merging separate targeting
gradients into a single universal targeting update. Theoretically, TDA inherits
classical TMLE properties, including double robustness and semiparametric
efficiency. Empirically, on the benchmark IHDP dataset (average treatment
effects) and simulated survival data with informative censoring, TDA reduces
bias and improves coverage relative to both standard neural-network estimators
and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable
pathway toward rigorous causal inference within modern deep architectures for
complex multi-parameter targets.

</details>


### [218] [A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning](https://arxiv.org/abs/2507.12439)
*Daniel Commey,Rebecca A. Sarpong,Griffith S. Klogo,Winful Bagyl-Bac,Garth V. Crosby*

Main category: cs.LG

TL;DR: 该论文提出了一种轻量级贝叶斯激励机制，通过经济手段防止联邦学习中的数据投毒攻击，确保恶意行为在经济上不划算。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的开放参与性使其容易受到数据投毒攻击，现有防御方法多为被动且计算成本高。

Method: 设计了一种贝叶斯激励机制，将每轮训练建模为不完全信息的贝叶斯博弈，服务器通过验证数据集评估更新质量并发放奖励。

Result: 在MNIST和FashionMNIST的非独立同分布数据上，即使50%的标签翻转攻击下，模型准确率仍保持96.7%，显著优于标准FedAvg。

Conclusion: 该机制计算轻量、预算可控，易于集成到现有联邦学习框架中，为经济稳健和可持续的联邦学习生态系统提供了实用方案。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy. However, its
open-participation nature exposes it to data-poisoning attacks, in which
malicious actors submit corrupted model updates to degrade the global model.
Existing defenses are often reactive, relying on statistical aggregation rules
that can be computationally expensive and that typically assume an honest
majority. This paper introduces a proactive, economic defense: a lightweight
Bayesian incentive mechanism that makes malicious behavior economically
irrational. Each training round is modeled as a Bayesian game of incomplete
information in which the server, acting as the principal, uses a small, private
validation dataset to verify update quality before issuing payments. The design
satisfies Individual Rationality (IR) for benevolent clients, ensuring their
participation is profitable, and Incentive Compatibility (IC), making poisoning
an economically dominated strategy. Extensive experiments on non-IID partitions
of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping
adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3
percentage points lower than in a scenario with 30% label-flipping adversaries.
This outcome is 51.7 percentage points better than standard FedAvg, which
collapses under the same 50% attack. The mechanism is computationally light,
budget-bounded, and readily integrates into existing FL frameworks, offering a
practical route to economically robust and sustainable FL ecosystems.

</details>


### [219] [Cost-aware Stopping for Bayesian Optimization](https://arxiv.org/abs/2507.12453)
*Qian Xie,Linda Cai,Alexander Terenin,Peter I. Frazier,Ziv Scully*

Main category: cs.LG

TL;DR: 提出了一种成本感知的贝叶斯优化停止规则，无需启发式调整，适用于不同评估成本，并在理论和实验中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在贝叶斯优化中，如何在高成本的黑盒函数评估中适时停止是一个实际问题，现有方法缺乏成本保证。

Method: 基于Pandora's Box Gittins Index (PBGI)和log expected improvement per cost的理论连接，提出了一种自适应停止规则。

Result: 实验证明，该规则与PBGI结合时，在成本调整简单遗憾指标上优于其他方法。

Conclusion: 该停止规则在理论和实践中均表现出色，适用于多种贝叶斯优化任务。

Abstract: In automated machine learning, scientific discovery, and other applications
of Bayesian optimization, deciding when to stop evaluating expensive black-box
functions is an important practical consideration. While several adaptive
stopping rules have been proposed, in the cost-aware setting they lack
guarantees ensuring they stop before incurring excessive function evaluation
costs. We propose a cost-aware stopping rule for Bayesian optimization that
adapts to varying evaluation costs and is free of heuristic tuning. Our rule is
grounded in a theoretical connection to state-of-the-art cost-aware acquisition
functions, namely the Pandora's Box Gittins Index (PBGI) and log expected
improvement per cost. We prove a theoretical guarantee bounding the expected
cumulative evaluation cost incurred by our stopping rule when paired with these
two acquisition functions. In experiments on synthetic and empirical tasks,
including hyperparameter optimization and neural architecture size search, we
show that combining our stopping rule with the PBGI acquisition function
consistently matches or outperforms other acquisition-function--stopping-rule
pairs in terms of cost-adjusted simple regret, a metric capturing trade-offs
between solution quality and cumulative evaluation cost.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [220] [A Cellular Automata Approach to Donation Game](https://arxiv.org/abs/2507.11744)
*Marcin Kowalik,Przemysław Stokłosa,Mateusz Grabowski,Janusz Starzyk,Paweł Raif*

Main category: cs.MA

TL;DR: 研究了捐赠游戏中合作行为的动态演化，通过一维二进制元胞自动机模拟邻近代理的交互，发现合作受代理移动性和空间局部性的显著影响。


<details>
  <summary>Details</summary>
Motivation: 探索在部分可观测环境中，环境噪声和代理决策策略（如声誉、慷慨和宽容）如何影响合作行为，并比较随机交互与邻近交互的差异。

Method: 使用一维二进制元胞自动机模拟捐赠游戏，定义符合游戏机制的规则，引入感知和动作噪声模型，以及策略概率演化的突变矩阵。

Result: 代理的移动性和空间局部性显著影响合作行为，邻近交互系统的合作动态与完全随机系统不同。

Conclusion: 强调了区分随机多代理系统和邻近交互系统的重要性，合作行为在后者中更易受空间结构影响。

Abstract: The donation game is a well-established framework for studying the emergence
and evolution of cooperation in multi-agent systems. The cooperative behavior
can be influenced by the environmental noise in partially observable settings
and by the decision-making strategies of agents, which may incorporate not only
reputation but also traits such as generosity and forgiveness. Traditional
simulations often assume fully random interactions, where cooperation is tested
between randomly selected agent pairs. In this paper, we investigate
cooperation dynamics using the concept of Stephen Wolfram's one-dimensional
binary cellular automata. This approach allows us to explore how cooperation
evolves when interactions are limited to neighboring agents. We define binary
cellular automata rules that conform to the donation game mechanics.
Additionally, we introduce models of perceptual and action noise, along with a
mutation matrix governing the probabilistic evolution of agent strategies. Our
empirical results demonstrate that cooperation is significantly affected by
agents' mobility and their spatial locality on the game board. These findings
highlight the importance of distinguishing between entirely random multi-agent
systems and those in which agents are more likely to interact with their
nearest neighbors.

</details>


### [221] [CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models](https://arxiv.org/abs/2507.11906)
*Tadahiro Taniguchi,Masatoshi Nagano,Haruumi Omoto,Yoshiki Hayashi*

Main category: cs.MA

TL;DR: CoCre-Sam框架通过集体Langevin动力学模拟人类集体活动中的语言融合现象，将个体语言模型融合为集体知识。


<details>
  <summary>Details</summary>
Motivation: 研究集体活动中（如使用Ouija板）如何通过分散的隐性语言知识融合产生连贯的语言输出。

Method: 提出CoCre-Sam框架，将参与者建模为代理，每个代理基于内部语言模型生成能量景观，并通过随机力相互作用。

Result: 理论证明和仿真验证表明，集体运动对应Langevin MCMC采样，有效融合不同模型并生成有意义字符序列。

Conclusion: CoCre-Sam为个体隐性知识、集体行动和涌现语言现象提供了新的计算机制。

Abstract: Collective human activities like using an Ouija board (or Kokkuri-san) often
produce emergent, coherent linguistic outputs unintended by any single
participant. While psychological explanations such as the ideomotor effect
exist, a computational understanding of how decentralized, implicit linguistic
knowledge fuses through shared physical interaction remains elusive. We
introduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this
phenomenon as collective Langevin dynamics sampling from implicitly fused
language models. Each participant is represented as an agent associated with an
energy landscape derived from an internal language model reflecting linguistic
priors, and agents exert stochastic forces based on local energy gradients. We
theoretically prove that the collective motion of the shared pointer
(planchette) corresponds to Langevin MCMC sampling from the sum of individual
energy landscapes, representing fused collective knowledge. Simulations
validate that CoCre-Sam dynamics effectively fuse different models and generate
meaningful character sequences, while ablation studies confirm the essential
roles of collective interaction and stochasticity. Altogether, CoCre-Sam
provides a novel computational mechanism linking individual implicit knowledge,
embodied collective action, and emergent linguistic phenomena, grounding these
complex interactions in the principles of probabilistic sampling.

</details>


### [222] [Modeling Feasible Locomotion of Nanobots for Cancer Detection and Treatment](https://arxiv.org/abs/2507.12400)
*Noble Harasha,Cristina Gava,Nancy Lynch,Claudia Contini,Frederik Mallmann-Trenn*

Main category: cs.MA

TL;DR: 论文提出了一种纳米机器人在人体内定位和治疗癌症的通用模型，包括两种变体：一种是基于固定化学梯度的静态模型，另一种是动态化学梯度模型，后者通过信号放大显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 利用纳米机器人提高药物递送的选择性并减少副作用，解决纳米尺度下个体能力受限的问题。

Method: 提出通用模型描述纳米机器人在胶体环境中的行为，包括静态和动态化学梯度两种变体，分别模拟和分析其运动与定位能力。

Result: 静态模型通过仿真和分析验证了纳米机器人的定位能力；动态模型通过信号放大机制显著提高了性能。

Conclusion: 动态化学梯度模型在性能上优于静态模型，为纳米机器人在癌症治疗中的应用提供了新思路。

Abstract: Deploying motile nanosized particles, also known as ``nanobots'', in the
human body promises to improve selectivity in drug delivery and reduce side
effects. We consider a swarm of nanobots locating a single cancerous region and
treating it by releasing an onboard payload of drugs at the site. At nanoscale,
the computation, communication, sensing, and locomotion capabilities of
individual agents are extremely limited, noisy, and/or nonexistent.
  We present a general model to formally describe the individual and collective
behavior of agents in a colloidal environment, such as the bloodstream, for
cancer detection and treatment by nanobots. This includes a feasible and
precise model of agent locomotion, inspired by actual nanoparticles that, in
the presence of an external chemical gradient, move towards areas of higher
concentration by means of self-propulsion. We present two variants of our
general model: The first assumes an endogenous chemical gradient that is fixed
over time and centered at the targeted cancer site; the second is a more
speculative and dynamic variant in which agents themselves create and amplify a
chemical gradient centered at the cancer site. In both settings, agents can
sense the gradient and ascend it noisily, locating the cancer site more quickly
than via simple Brownian motion.
  For the first variant of the model, we present simulation results to show the
behavior of agents under our locomotion model, as well as {analytical results}
to bound the time it takes for the agents to reach the cancer site. For the
second variant, simulation results highlight the collective benefit in having
agents issue their own chemical signal. While arguably more speculative in its
agent capability assumptions, this variant shows a significant improvement in
runtime performance over the first variant, resulting from its chemical signal
amplification mechanism.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [223] [HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways](https://arxiv.org/abs/2507.11621)
*Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 论文提出了一种分层协作式匝道合流控制（HCOMC）框架，用于解决混合交通流中的匝道合流问题，结合了纵向跟车模型和横向换道模型，并通过仿真验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 高速公路匝道合流区域是交通拥堵和事故的常见瓶颈，而基于联网自动驾驶车辆（CAVs）的协作控制策略是解决这一问题的根本方案。由于CAV尚未普及，需要提出适用于混合交通流的控制框架。

Method: 扩展了基于智能驾驶员模型的纵向跟车模型和基于五次多项式曲线的横向换道模型，提出了HCOMC框架，包括分层协作规划模型、基于博弈论的换道模型和多目标优化模型。

Result: 仿真结果表明，HCOMC在提升车辆群安全性、稳定和加速合流过程、优化交通效率和节省燃油消耗方面具有显著优势。

Conclusion: HCOMC框架为混合交通流中的匝道合流问题提供了有效的解决方案，具有实际应用潜力。

Abstract: Highway on-ramp merging areas are common bottlenecks to traffic congestion
and accidents. Currently, a cooperative control strategy based on connected and
automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs
are not fully widespread, it is necessary to propose a hierarchical cooperative
on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on
two-lane highways to address this gap. This paper extends longitudinal
car-following models based on the intelligent driver model and lateral
lane-changing models using the quintic polynomial curve to account for
human-driven vehicles (HDVs) and CAVs, comprehensively considering human
factors and cooperative adaptive cruise control. Besides, this paper proposes a
HCOMC framework, consisting of a hierarchical cooperative planning model based
on the modified virtual vehicle model, a discretionary lane-changing model
based on game theory, and a multi-objective optimization model using the
elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and
efficient merging process. Then, the performance of our HCOMC is analyzed under
different traffic densities and CAV penetration rates through simulation. The
findings underscore our HCOMC's pronounced comprehensive advantages in
enhancing the safety of group vehicles, stabilizing and expediting merging
process, optimizing traffic efficiency, and economizing fuel consumption
compared with benchmarks.

</details>


### [224] [A Roadmap for Climate-Relevant Robotics Research](https://arxiv.org/abs/2507.11623)
*Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh*

Main category: cs.RO

TL;DR: 本文提出了一个气候相关机器人研究的路线图，旨在通过机器人技术与气候领域专家的合作，解决高影响问题。


<details>
  <summary>Details</summary>
Motivation: 气候变化是21世纪的关键挑战，机器人社区希望通过技术贡献应对这一挑战。

Method: 通过识别机器人技术与气候领域（如能源、建筑环境、交通等）的合作机会，提出具体应用问题。

Result: 路线图展示了机器人技术（包括算法和物理机器人）在气候问题中的潜在应用，如能源优化、精准农业等。

Conclusion: 本文旨在激发新的研究方向与合作，推动机器人技术在应对气候变化中的实际应用。

Abstract: Climate change is one of the defining challenges of the 21st century, and
many in the robotics community are looking for ways to contribute. This paper
presents a roadmap for climate-relevant robotics research, identifying
high-impact opportunities for collaboration between roboticists and experts
across climate domains such as energy, the built environment, transportation,
industry, land use, and Earth sciences. These applications include problems
such as energy systems optimization, construction, precision agriculture,
building envelope retrofits, autonomous trucking, and large-scale environmental
monitoring. Critically, we include opportunities to apply not only physical
robots but also the broader robotics toolkit - including planning, perception,
control, and estimation algorithms - to climate-relevant problems. A central
goal of this roadmap is to inspire new research directions and collaboration by
highlighting specific, actionable problems at the intersection of robotics and
climate. This work represents a collaboration between robotics researchers and
domain experts in various climate disciplines, and it serves as an invitation
to the robotics community to bring their expertise to bear on urgent climate
priorities.

</details>


### [225] [CoNav Chair: Development and Evaluation of a Shared Control based Wheelchair for the Built Environment](https://arxiv.org/abs/2507.11716)
*Yifan Xu,Qianwei Wang,Jordan Lillie,Vineet Kamat,Carol Menassa,Clive D'Souza*

Main category: cs.RO

TL;DR: 本文介绍了CoNav Chair，一种基于ROS的智能轮椅，采用共享控制导航和避障功能，旨在提高导航效率、安全性和易用性。初步评估显示共享控制模式在碰撞次数、任务完成时间等方面表现优于手动和全自动模式。


<details>
  <summary>Details</summary>
Motivation: 随着残疾人口增长，对促进独立生活和社会融合的移动解决方案需求增加。现有电动轮椅在灵活性和导航能力上存在局限，且研究多集中于完全自主或手动控制，影响效率和用户信任。

Method: 提出CoNav Chair，基于ROS，具备共享控制导航和避障功能。通过21名健康参与者测试三种导航模式（手动、共享、全自动）的初步可用性。

Result: 共享控制模式碰撞次数显著减少，任务完成时间、轨迹长度和平滑度表现优于或与手动和全自动模式相当，用户主观评价认为其更安全和高效。

Conclusion: CoNav系统展现出可接受的安全性和性能，为后续残疾用户测试奠定了基础。

Abstract: As the global population of people with disabilities (PWD) continues to grow,
so will the need for mobility solutions that promote independent living and
social integration. Wheelchairs are vital for the mobility of PWD in both
indoor and outdoor environments. The current SOTA in powered wheelchairs is
based on either manually controlled or fully autonomous modes of operation,
offering limited flexibility and often proving difficult to navigate in
spatially constrained environments. Moreover, research on robotic wheelchairs
has focused predominantly on complete autonomy or improved manual control;
approaches that can compromise efficiency and user trust. To overcome these
challenges, this paper introduces the CoNav Chair, a smart wheelchair based on
the Robot Operating System (ROS) and featuring shared control navigation and
obstacle avoidance capabilities that are intended to enhance navigational
efficiency, safety, and ease of use for the user. The paper outlines the CoNav
Chair's design and presents a preliminary usability evaluation comparing three
distinct navigation modes, namely, manual, shared, and fully autonomous,
conducted with 21 healthy, unimpaired participants traversing an indoor
building environment. Study findings indicated that the shared control
navigation framework had significantly fewer collisions and performed
comparably, if not superior to the autonomous and manual modes, on task
completion time, trajectory length, and smoothness; and was perceived as being
safer and more efficient based on user reported subjective assessments of
usability. Overall, the CoNav system demonstrated acceptable safety and
performance, laying the foundation for subsequent usability testing with end
users, namely, PWDs who rely on a powered wheelchair for mobility.

</details>


### [226] [Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies](https://arxiv.org/abs/2507.11770)
*Giang Nguyen,Mihai Pomarlan,Sascha Jongebloed,Nils Leusmann,Minh Nhat Vu,Michael Beetz*

Main category: cs.RO

TL;DR: 提出了一种统一场景图模型，将多种机器人场景描述格式标准化为USD格式，并通过语义标注与知识图谱结合，支持实时机器人决策。


<details>
  <summary>Details</summary>
Motivation: 解决机器人领域因数据格式多样性和不兼容性导致的环境数据整合难题。

Method: 开发统一场景图模型，将MJCF、URDF、SDF等格式转换为USD格式，并进行语义标注和知识图谱转换。

Result: 成功将3D环境转换为USD格式，并通过知识图谱支持实时决策，开发了可视化工具辅助语义映射。

Conclusion: 该方法有效整合了多样化环境数据，为认知机器人控制提供了可行的解决方案。

Abstract: In robotics, the effective integration of environmental data into actionable
knowledge remains a significant challenge due to the variety and
incompatibility of data formats commonly used in scene descriptions, such as
MJCF, URDF, and SDF. This paper presents a novel approach that addresses these
challenges by developing a unified scene graph model that standardizes these
varied formats into the Universal Scene Description (USD) format. This
standardization facilitates the integration of these scene graphs with robot
ontologies through semantic reporting, enabling the translation of complex
environmental data into actionable knowledge essential for cognitive robotic
control. We evaluated our approach by converting procedural 3D environments
into USD format, which is then annotated semantically and translated into a
knowledge graph to effectively answer competency questions, demonstrating its
utility for real-time robotic decision-making. Additionally, we developed a
web-based visualization tool to support the semantic mapping process, providing
users with an intuitive interface to manage the 3D environment.

</details>


### [227] [Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties](https://arxiv.org/abs/2507.12174)
*Zhenmin Huang,Yusen Xie,Benshan Ma,Shaojie Shen,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种新的博弈论交互轨迹规划方法，有效处理多智能体交互中的意图不确定性，具有高效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多智能体交互中的意图不确定性导致现有博弈论方法计算负担重、效率低且可扩展性差。

Method: 将意图不确定性下的交互建模为一般贝叶斯博弈，并证明其在特定假设下可表示为潜在博弈，提出基于ADMM的分布式算法。

Result: 仿真和实验表明，该方法在多种意图不确定性场景下有效，可扩展性优于现有基线方法。

Conclusion: 新方法显著提升了多智能体交互轨迹规划的效率和可扩展性，适用于实时不确定博弈场景。

Abstract: Trajectory planning involving multi-agent interactions has been a
long-standing challenge in the field of robotics, primarily burdened by the
inherent yet intricate interactions among agents. While game-theoretic methods
are widely acknowledged for their effectiveness in managing multi-agent
interactions, significant impediments persist when it comes to accommodating
the intentional uncertainties of agents. In the context of intentional
uncertainties, the heavy computational burdens associated with existing
game-theoretic methods are induced, leading to inefficiencies and poor
scalability. In this paper, we propose a novel game-theoretic interactive
trajectory planning method to effectively address the intentional uncertainties
of agents, and it demonstrates both high efficiency and enhanced scalability.
As the underpinning basis, we model the interactions between agents under
intentional uncertainties as a general Bayesian game, and we show that its
agent-form equivalence can be represented as a potential game under certain
minor assumptions. The existence and attainability of the optimal interactive
trajectories are illustrated, as the corresponding Bayesian Nash equilibrium
can be attained by optimizing a unified optimization problem. Additionally, we
present a distributed algorithm based on the dual consensus alternating
direction method of multipliers (ADMM) tailored to the parallel solving of the
problem, thereby significantly improving the scalability. The attendant
outcomes from simulations and experiments demonstrate that the proposed method
is effective across a range of scenarios characterized by general forms of
intentional uncertainties. Its scalability surpasses that of existing
centralized and decentralized baselines, allowing for real-time interactive
trajectory planning in uncertain game settings.

</details>


### [228] [The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey](https://arxiv.org/abs/2507.11840)
*Gaofeng Li,Ruize Wang,Peisen Xu,Qi Ye,Jiming Chen*

Main category: cs.RO

TL;DR: 本文总结了机器人操作从机械编程到具身智能的演变，重点关注当前阶段的灵巧操作，包括数据收集和技能学习框架的进展，并讨论了三大关键挑战。


<details>
  <summary>Details</summary>
Motivation: 实现类人灵巧机器人操作是机器人学的核心目标和关键挑战，AI的发展推动了这一领域的快速进步。

Method: 通过仿真、人类演示和远程操作收集灵巧操作数据，并利用模仿学习和强化学习框架进行技能学习。

Result: 概述了现有数据收集范式和学习框架，总结了灵巧机器人操作发展的三大挑战。

Conclusion: 灵巧机器人操作的发展仍面临数据收集和技能学习框架的挑战，需进一步研究突破。

Abstract: Achieving human-like dexterous robotic manipulation remains a central goal
and a pivotal challenge in robotics. The development of Artificial Intelligence
(AI) has allowed rapid progress in robotic manipulation. This survey summarizes
the evolution of robotic manipulation from mechanical programming to embodied
intelligence, alongside the transition from simple grippers to multi-fingered
dexterous hands, outlining key characteristics and main challenges. Focusing on
the current stage of embodied dexterous manipulation, we highlight recent
advances in two critical areas: dexterous manipulation data collection (via
simulation, human demonstrations, and teleoperation) and skill-learning
frameworks (imitation and reinforcement learning). Then, based on the overview
of the existing data collection paradigm and learning framework, three key
challenges restricting the development of dexterous robotic manipulation are
summarized and discussed.

</details>


### [229] [Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers](https://arxiv.org/abs/2507.11852)
*Mohammed Hassanin,Mohammad Abu Alsheikh,Carlos C. N. Kuhn,Damith Herath,Dinh Thai Hoang,Ibrahim Radwan*

Main category: cs.RO

TL;DR: 综述分析了自动驾驶技术如何应用于两轮微出行工具的自主骑行（AR）系统，指出了当前研究的不足和未来方向。


<details>
  <summary>Details</summary>
Motivation: 两轮微出行工具的快速普及需要可靠的AR技术，但现有研究在感知、规划和控制系统方面存在不足。

Method: 通过系统分析AR的核心组件（感知、规划、控制），借鉴自动驾驶（AD）技术，识别研究空白。

Result: 发现AR研究缺乏全面的感知系统、行业和政府支持不足，并提出了多模态传感器和边缘深度学习等方向。

Conclusion: 结合AD技术与AR需求，可加速开发安全、高效、可扩展的AR系统，推动未来城市出行。

Abstract: The rapid adoption of micromobility solutions, particularly two-wheeled
vehicles like e-scooters and e-bikes, has created an urgent need for reliable
autonomous riding (AR) technologies. While autonomous driving (AD) systems have
matured significantly, AR presents unique challenges due to the inherent
instability of two-wheeled platforms, limited size, limited power, and
unpredictable environments, which pose very serious concerns about road users'
safety. This review provides a comprehensive analysis of AR systems by
systematically examining their core components, perception, planning, and
control, through the lens of AD technologies. We identify critical gaps in
current AR research, including a lack of comprehensive perception systems for
various AR tasks, limited industry and government support for such
developments, and insufficient attention from the research community. The
review analyses the gaps of AR from the perspective of AD to highlight
promising research directions, such as multimodal sensor techniques for
lightweight platforms and edge deep learning architectures. By synthesising
insights from AD research with the specific requirements of AR, this review
aims to accelerate the development of safe, efficient, and scalable autonomous
riding systems for future urban mobility.

</details>


### [230] [A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications](https://arxiv.org/abs/2507.11880)
*Jinyuan Liu,Minglei Fu,Ling Shi,Chenguang Yang,Wenan Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为CDT-TCS的新算法，用于解决系绳机器人在运动规划中的限制问题，并通过三种应用算法进一步扩展其功能。


<details>
  <summary>Details</summary>
Motivation: 系绳机器人在特殊环境中具有稳定供电和可靠通信的优势，但其运动规划受限于系绳长度和缠绕风险，亟需高效解决方案。

Method: 利用CDT编码作为同伦不变量表示路径拓扑状态，结合代数拓扑和几何优化，提出CDT-TCS算法及其三种应用算法。

Result: 仿真和实验表明，所提算法在各自问题领域显著优于现有方法，并验证了其工程实用性。

Conclusion: CDT-TCS及其扩展算法为系绳机器人运动规划提供了高效且实用的解决方案。

Abstract: Tethered robots play a pivotal role in specialized environments such as
disaster response and underground exploration, where their stable power supply
and reliable communication offer unparalleled advantages. However, their motion
planning is severely constrained by tether length limitations and entanglement
risks, posing significant challenges to achieving optimal path planning. To
address these challenges, this study introduces CDT-TCS (Convex Dissection
Topology-based Tethered Configuration Search), a novel algorithm that leverages
CDT Encoding as a homotopy invariant to represent topological states of paths.
By integrating algebraic topology with geometric optimization, CDT-TCS
efficiently computes the complete set of optimal feasible configurations for
tethered robots at all positions in 2D environments through a single
computation. Building on this foundation, we further propose three
application-specific algorithms: i) CDT-TPP for optimal tethered path planning,
ii) CDT-TMV for multi-goal visiting with tether constraints, iii) CDT-UTPP for
distance-optimal path planning of untethered robots. All theoretical results
and propositions underlying these algorithms are rigorously proven and
thoroughly discussed in this paper. Extensive simulations demonstrate that the
proposed algorithms significantly outperform state-of-the-art methods in their
respective problem domains. Furthermore, real-world experiments on robotic
platforms validate the practicality and engineering value of the proposed
framework.

</details>


### [231] [NemeSys: An Online Underwater Explorer with Goal-Driven Adaptive Autonomy](https://arxiv.org/abs/2507.11889)
*Adnan Abdullah,Alankrit Gupta,Vaishnav Ramesh,Shivali Patel,Md Jahidul Islam*

Main category: cs.RO

TL;DR: NemeSys是一种新型AUV系统，通过光学和磁电信号实现实时任务重配置，适用于GPS和通信受限的水下环境。


<details>
  <summary>Details</summary>
Motivation: 当前AUV系统依赖静态预编程任务或高延迟通信，限制了其适应性和响应能力。

Method: 提出NemeSys系统，采用光学和磁电信号及浮标支持实时任务重配置，包括系统设计、控制架构和语义任务编码框架。

Result: 通过建模、实验和开放水域测试验证了在线任务适应和语义更新的可行性。

Conclusion: NemeSys为动态和不确定水下环境中的目标驱动自适应AUV平台提供了有效解决方案。

Abstract: Adaptive mission control and dynamic parameter reconfiguration are essential
for autonomous underwater vehicles (AUVs) operating in GPS-denied,
communication-limited marine environments. However, most current AUV platforms
execute static, pre-programmed missions or rely on tethered connections and
high-latency acoustic channels for mid-mission updates, significantly limiting
their adaptability and responsiveness. In this paper, we introduce NemeSys, a
novel AUV system designed to support real-time mission reconfiguration through
compact optical and magnetoelectric (OME) signaling facilitated by floating
buoys. We present the full system design, control architecture, and a semantic
mission encoding framework that enables interactive exploration and task
adaptation via low-bandwidth communication. The proposed system is validated
through analytical modeling, controlled experimental evaluations, and
open-water trials. Results confirm the feasibility of online mission adaptation
and semantic task updates, highlighting NemeSys as an online AUV platform for
goal-driven adaptive autonomy in dynamic and uncertain underwater environments.

</details>


### [232] [Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments](https://arxiv.org/abs/2507.11920)
*Jeongyong Yang,KwangBin Lee,SooJean Han*

Main category: cs.RO

TL;DR: HyPRAP是一种基于混合预测的风险感知路径规划框架，通过选择性使用预测模型和新型碰撞风险指数（P-CRI），在密集动态环境中平衡安全性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决密集动态环境中实时路径规划的挑战，尤其是预测大量动态障碍物未来运动的计算负担和不现实性。

Method: HyPRAP结合多种模型预测障碍物运动，使用P-CRI评估风险，并选择性分配计算资源。通过混合共形预测量化不确定性。

Result: 理论分析和仿真表明，HyPRAP在安全性和计算效率上优于单一预测方法，P-CRI比基于邻近性的风险评估更有效。

Conclusion: HyPRAP为密集动态环境提供了一种高效且安全的路径规划解决方案。

Abstract: Real-time path planning in dense, uncertain environments remains a
challenging problem, as predicting the future motions of numerous dynamic
obstacles is computationally burdensome and unrealistic. To address this, we
introduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a
prediction-based risk-aware path-planning framework which uses a hybrid
combination of models to predict local obstacle movement. HyPRAP uses a novel
Prediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by
each obstacle, enabling the selective use of predictors based on whether the
agent prioritizes high predictive accuracy or low computational prediction
overhead. This selective routing enables the agent to focus on high-risk
obstacles while ignoring or simplifying low-risk ones, making it suitable for
environments with a large number of obstacles. Moreover, HyPRAP incorporates
uncertainty quantification through hybrid conformal prediction by deriving
confidence bounds simultaneously achieved by multiple predictions across
different models. Theoretical analysis demonstrates that HyPRAP effectively
balances safety and computational efficiency by leveraging the diversity of
prediction models. Extensive simulations validate these insights for more
general settings, confirming that HyPRAP performs better compared to single
predictor methods, and P-CRI performs better over naive proximity-based risk
assessment.

</details>


### [233] [A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning](https://arxiv.org/abs/2507.11938)
*Hao Chen,Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 论文提出了一种基于相似性匹配的新方法，通过利用已知物体的相似性来指导未知物体的抓取，解决了单视角下抓取的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统学习框架在面对感知噪声和环境变化时性能鲁棒性不足，因此需要一种更通用的抓取方法。

Method: 1) 利用视觉特征进行相似性匹配；2) 使用候选模型的抓取知识规划模仿抓取；3) 通过局部微调优化抓取质量。

Result: 提出了一种多级相似性匹配框架和C-FPFH描述符，结合语义、几何和维度特征，提升了单视角下的抓取准确性。

Conclusion: 新方法通过相似性匹配和局部优化，显著提升了未知物体抓取的鲁棒性和通用性。

Abstract: Grasping unknown objects from a single view has remained a challenging topic
in robotics due to the uncertainty of partial observation. Recent advances in
large-scale models have led to benchmark solutions such as GraspNet-1Billion.
However, such learning-based approaches still face a critical limitation in
performance robustness for their sensitivity to sensing noise and environmental
changes. To address this bottleneck in achieving highly generalized grasping,
we abandon the traditional learning framework and introduce a new perspective:
similarity matching, where similar known objects are utilized to guide the
grasping of unknown target objects. We newly propose a method that robustly
achieves unknown-object grasping from a single viewpoint through three key
steps: 1) Leverage the visual features of the observed object to perform
similarity matching with an existing database containing various object models,
identifying potential candidates with high similarity; 2) Use the candidate
models with pre-existing grasping knowledge to plan imitative grasps for the
unknown target object; 3) Optimize the grasp quality through a local
fine-tuning process. To address the uncertainty caused by partial and noisy
observation, we propose a multi-level similarity matching framework that
integrates semantic, geometric, and dimensional features for comprehensive
evaluation. Especially, we introduce a novel point cloud geometric descriptor,
the C-FPFH descriptor, which facilitates accurate similarity assessment between
partial point clouds of observed objects and complete point clouds of database
models. In addition, we incorporate the use of large language models, introduce
the semi-oriented bounding box, and develop a novel point cloud registration
approach based on plane detection to enhance matching accuracy under
single-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.

</details>


### [234] [IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving](https://arxiv.org/abs/2507.11940)
*Kanghyun Ryu,Minjun Sung,Piyush Gupta,Jovin D'sa,Faizan M. Tariq,David Isele,Sangjae Bae*

Main category: cs.RO

TL;DR: 提出了一种基于交互感知的神经网络增强模型预测路径积分（IANN-MPPI）控制方法，用于自动驾驶车辆在密集交通中的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 传统预测与规划方法忽略了周围车辆对自动驾驶车辆行为的交互反应，导致保守行为和规划目标未达成。

Method: 结合交互感知神经网络和MPPI控制，预测周围车辆对控制序列的反应，并引入样条基先验分布以优化车道变更行为。

Result: 在密集交通并道场景中验证了方法的有效性，能够实现高效并道操作。

Conclusion: IANN-MPPI方法通过交互感知和优化采样分布，显著提升了自动驾驶车辆在密集交通中的规划能力。

Abstract: Motion planning for autonomous vehicles (AVs) in dense traffic is
challenging, often leading to overly conservative behavior and unmet planning
objectives. This challenge stems from the AVs' limited ability to anticipate
and respond to the interactive behavior of surrounding agents. Traditional
decoupled prediction and planning pipelines rely on non-interactive predictions
that overlook the fact that agents often adapt their behavior in response to
the AV's actions. To address this, we propose Interaction-Aware Neural
Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which
enables interactive trajectory planning by predicting how surrounding agents
may react to each control sequence sampled by MPPI. To improve performance in
structured lane environments, we introduce a spline-based prior for the MPPI
sampling distribution, enabling efficient lane-changing behavior. We evaluate
IANN-MPPI in a dense traffic merging scenario, demonstrating its ability to
perform efficient merging maneuvers. Our project website is available at
https://sites.google.com/berkeley.edu/iann-mppi

</details>


### [235] [A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming](https://arxiv.org/abs/2507.11974)
*Waseem Akram,Muhayy Ud Din,Lyes Saad Soud,Irfan Hussain*

Main category: cs.RO

TL;DR: 本文综述了生成式人工智能（GAI）在水产养殖中的广泛应用，包括环境监测、机器人技术、疾病诊断等，并分析了其技术潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业正朝着数据驱动和自动化方向发展（Aquaculture 4.0），GAI为这一转型提供了新的技术支持。

Method: 综述了GAI在水产养殖中的应用，涵盖基础架构（如扩散模型、Transformer）、实验系统、试点部署和实际案例。

Result: GAI在水下感知、数字孪生建模和自主规划等方面发挥了重要作用，但也面临数据不足、实时性能限制等问题。

Conclusion: GAI不仅是工具，更是实现智能、韧性和环保水产养殖系统的关键推动者。

Abstract: Generative Artificial Intelligence (GAI) has rapidly emerged as a
transformative force in aquaculture, enabling intelligent synthesis of
multimodal data, including text, images, audio, and simulation outputs for
smarter, more adaptive decision-making. As the aquaculture industry shifts
toward data-driven, automation and digital integration operations under the
Aquaculture 4.0 paradigm, GAI models offer novel opportunities across
environmental monitoring, robotics, disease diagnostics, infrastructure
planning, reporting, and market analysis. This review presents the first
comprehensive synthesis of GAI applications in aquaculture, encompassing
foundational architectures (e.g., diffusion models, transformers, and retrieval
augmented generation), experimental systems, pilot deployments, and real-world
use cases. We highlight GAI's growing role in enabling underwater perception,
digital twin modeling, and autonomous planning for remotely operated vehicle
(ROV) missions. We also provide an updated application taxonomy that spans
sensing, control, optimization, communication, and regulatory compliance.
Beyond technical capabilities, we analyze key limitations, including limited
data availability, real-time performance constraints, trust and explainability,
environmental costs, and regulatory uncertainty. This review positions GAI not
merely as a tool but as a critical enabler of smart, resilient, and
environmentally aligned aquaculture systems.

</details>


### [236] [Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers](https://arxiv.org/abs/2507.11991)
*Juanran Wang,Marc R. Schlichting,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 利用深度生成模型提升自动驾驶车辆在交叉路口的安全性，通过单步去噪扩散模型快速生成潜在碰撞场景，优化决策规划。


<details>
  <summary>Details</summary>
Motivation: 高风险交通区域（如交叉路口）是碰撞事故的主要原因，需提升自动驾驶车辆在此类场景的安全性。

Method: 训练1000步去噪扩散概率模型生成碰撞相关的传感器噪声序列，并通过生成对抗架构将其蒸馏为单步模型，实现快速推理。

Result: 单步模型在保持采样质量的同时显著提升推理速度，基于该模型的规划器在仿真中表现出更低的失败率和延迟率。

Conclusion: 单步去噪扩散模型可高效生成潜在碰撞场景，为自动驾驶车辆提供更鲁棒的决策支持。

Abstract: High-risk traffic zones such as intersections are a major cause of
collisions. This study leverages deep generative models to enhance the safety
of autonomous vehicles in an intersection context. We train a 1000-step
denoising diffusion probabilistic model to generate collision-causing sensor
noise sequences for an autonomous vehicle navigating a four-way intersection
based on the current relative position and velocity of an intruder. Using the
generative adversarial architecture, the 1000-step model is distilled into a
single-step denoising diffusion model which demonstrates fast inference speed
while maintaining similar sampling quality. We demonstrate one possible
application of the single-step model in building a robust planner for the
autonomous vehicle. The planner uses the single-step model to efficiently
sample potential failure cases based on the currently measured traffic state to
inform its decision-making. Through simulation experiments, the robust planner
demonstrates significantly lower failure rate and delay rate compared with the
baseline Intelligent Driver Model controller.

</details>


### [237] [Robust Route Planning for Sidewalk Delivery Robots](https://arxiv.org/abs/2507.12067)
*Xing Tong,Michele D. Simoni*

Main category: cs.RO

TL;DR: 研究提出了一种针对人行道送货机器人的鲁棒路径规划方法，通过考虑行人密度和障碍物等不确定性因素，优化了路径效率。


<details>
  <summary>Details</summary>
Motivation: 人行道送货机器人因行人密度、障碍物和基础设施条件导致旅行时间不可靠，影响效率，需解决这一问题。

Method: 结合优化与模拟，采用预算、椭球和支持向量聚类（SVC）方法生成不确定性集，并应用分布鲁棒方法求解最短路径问题。

Result: 鲁棒路径规划显著提升了操作可靠性，椭球和DRSP方法表现最佳，尤其在恶劣天气和高行人密度下效果更明显。

Conclusion: 鲁棒路径规划方法在人行道送货机器人中具有显著优势，特别是在复杂环境下表现更优。

Abstract: Sidewalk delivery robots are a promising solution for urban freight
distribution, reducing congestion compared to trucks and providing a safer,
higher-capacity alternative to drones. However, unreliable travel times on
sidewalks due to pedestrian density, obstacles, and varying infrastructure
conditions can significantly affect their efficiency. This study addresses the
robust route planning problem for sidewalk robots, explicitly accounting for
travel time uncertainty due to varying sidewalk conditions. Optimization is
integrated with simulation to reproduce the effect of obstacles and pedestrian
flows and generate realistic travel times. The study investigates three
different approaches to derive uncertainty sets, including budgeted,
ellipsoidal, and support vector clustering (SVC)-based methods, along with a
distributionally robust method to solve the shortest path (SP) problem. A
realistic case study reproducing pedestrian patterns in Stockholm's city center
is used to evaluate the efficiency of robust routing across various robot
designs and environmental conditions. The results show that, when compared to a
conventional SP, robust routing significantly enhances operational reliability
under variable sidewalk conditions. The Ellipsoidal and DRSP approaches
outperform the other methods, yielding the most efficient paths in terms of
average and worst-case delay. Sensitivity analyses reveal that robust
approaches consistently outperform the conventional SP, particularly for
sidewalk delivery robots that are wider, slower, and have more conservative
navigation behaviors. These benefits are even more pronounced in adverse
weather conditions and high pedestrian congestion scenarios.

</details>


### [238] [Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards](https://arxiv.org/abs/2507.12093)
*David Rapado-Rincon,Gert Kootstra*

Main category: cs.RO

TL;DR: Tree-SLAM是一种针对果园中单棵树定位的语义SLAM方法，通过RGB-D图像和实例分割模型检测树干，结合级联图数据关联算法和因子图框架，实现高精度地图构建。


<details>
  <summary>Details</summary>
Motivation: 果园中GPS信号不可靠且标准SLAM方法因树木重复外观易出错，需开发专门方法以实现单棵树的高精度定位。

Method: 利用RGB-D图像检测树干，通过级联图数据关联算法重识别树干，结合GPS、里程计和树干观测构建因子图框架。

Result: 在苹果和梨果园数据集上验证，定位误差低至18厘米，低于种植间距的20%。

Conclusion: Tree-SLAM在GPS信号不可靠时仍能实现高精度和鲁棒性的单棵树地图构建。

Abstract: Accurate mapping of individual trees is an important component for precision
agriculture in orchards, as it allows autonomous robots to perform tasks like
targeted operations or individual tree monitoring. However, creating these maps
is challenging because GPS signals are often unreliable under dense tree
canopies. Furthermore, standard Simultaneous Localization and Mapping (SLAM)
approaches struggle in orchards because the repetitive appearance of trees can
confuse the system, leading to mapping errors. To address this, we introduce
Tree-SLAM, a semantic SLAM approach tailored for creating maps of individual
trees in orchards. Utilizing RGB-D images, our method detects tree trunks with
an instance segmentation model, estimates their location and re-identifies them
using a cascade-graph-based data association algorithm. These re-identified
trunks serve as landmarks in a factor graph framework that integrates noisy GPS
signals, odometry, and trunk observations. The system produces maps of
individual trees with a geo-localization error as low as 18 cm, which is less
than 20\% of the planting distance. The proposed method was validated on
diverse datasets from apple and pear orchards across different seasons,
demonstrating high mapping accuracy and robustness in scenarios with unreliable
GPS signals.

</details>


### [239] [Leveraging Sidewalk Robots for Walkability-Related Analyses](https://arxiv.org/abs/2507.12148)
*Xing Tong,Michele D. Simoni,Kaj Munhoz Arfvidsson,Jonas Mårtensson*

Main category: cs.RO

TL;DR: 利用配备传感器的送货机器人收集人行道数据，评估步行性，发现人行道特征显著影响行人行为。


<details>
  <summary>Details</summary>
Motivation: 传统方法收集步行性数据成本高且难以扩展，送货机器人提供了一种可扩展的自动化解决方案。

Method: 在斯德哥尔摩KTH部署传感器机器人，完成101次行程，收集人行道特征数据并分析其与步行性的关系。

Result: 行人行为受人行道宽度、密度和表面不平整度影响，机器人速度可作为行人动态的代理指标。

Conclusion: 机器人框架可实现持续监测，促进更宜居、包容和响应迅速的城市环境。

Abstract: Walkability is a key component of sustainable urban development, while
collecting detailed data on its related features remains challenging due to the
high costs and limited scalability of traditional methods. Sidewalk delivery
robots, increasingly deployed in urban environments, offer a promising solution
to these limitations. This paper explores how these robots can serve as mobile
data collection platforms, capturing sidewalk-level features related to
walkability in a scalable, automated, and real-time manner. A sensor-equipped
robot was deployed on a sidewalk network at KTH in Stockholm, completing 101
trips covering 900 segments. From the collected data, different typologies of
features are derived, including robot trip characteristics (e.g., speed,
duration), sidewalk conditions (e.g., width, surface unevenness), and sidewalk
utilization (e.g., pedestrian density). Their walkability-related implications
were investigated with a series of analyses. The results demonstrate that
pedestrian movement patterns are strongly influenced by sidewalk
characteristics, with higher density, reduced width, and surface irregularity
associated with slower and more variable trajectories. Notably, robot speed
closely mirrors pedestrian behavior, highlighting its potential as a proxy for
assessing pedestrian dynamics. The proposed framework enables continuous
monitoring of sidewalk conditions and pedestrian behavior, contributing to the
development of more walkable, inclusive, and responsive urban environments.

</details>


### [240] [Probabilistic Safety Verification for an Autonomous Ground Vehicle: A Situation Coverage Grid Approach](https://arxiv.org/abs/2507.12158)
*Nawshin Mannan Proma,Gricel Vázquez,Sepeedeh Shahbeigi,Arjun Badyal,Victoria Hodge*

Main category: cs.RO

TL;DR: 提出了一种基于系统情境提取、概率建模和验证的工业自动驾驶车辆安全验证新方法，通过情境覆盖网格和概率模型检查，有效识别高风险情境并提供定量安全保证。


<details>
  <summary>Details</summary>
Motivation: 随着工业自动驾驶车辆在安全关键环境中的部署增加，确保其在多样化条件下的安全运行至关重要。

Method: 构建情境覆盖网格，结合概率数据生成模型，通过概率模型检查验证安全性。

Result: 方法有效识别高风险情境，提供定量安全保证，支持符合监管标准。

Conclusion: 该方法为自动驾驶系统的稳健部署提供了有力支持。

Abstract: As industrial autonomous ground vehicles are increasingly deployed in
safety-critical environments, ensuring their safe operation under diverse
conditions is paramount. This paper presents a novel approach for their safety
verification based on systematic situation extraction, probabilistic modelling
and verification. We build upon the concept of a situation coverage grid, which
exhaustively enumerates environmental configurations relevant to the vehicle's
operation. This grid is augmented with quantitative probabilistic data
collected from situation-based system testing, capturing probabilistic
transitions between situations. We then generate a probabilistic model that
encodes the dynamics of both normal and unsafe system behaviour. Safety
properties extracted from hazard analysis and formalised in temporal logic are
verified through probabilistic model checking against this model. The results
demonstrate that our approach effectively identifies high-risk situations,
provides quantitative safety guarantees, and supports compliance with
regulatory standards, thereby contributing to the robust deployment of
autonomous systems.

</details>


### [241] [UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization](https://arxiv.org/abs/2507.12194)
*Hongming Shen,Xun Chen,Yulin Hui,Zhenyu Wu,Wei Wang,Qiyang Lyu,Tianchen Deng,Danwei Wang*

Main category: cs.RO

TL;DR: 提出了一种统一的LiDAR全局定位（LGL）方法UniLGL，通过编码完整点云信息（几何和材质）到BEV图像，并设计多BEV融合网络，实现空间、材质和传感器类型的统一性。


<details>
  <summary>Details</summary>
Motivation: 现有LGL方法通常仅考虑部分信息（如几何特征）或针对同质LiDAR传感器设计，忽略了LGL中的统一性。

Method: 将点云编码为空间和强度BEV图像，设计多BEV融合网络提取统一特征，引入视角不变性假设实现传感器类型统一性。

Result: 实验表明UniLGL在真实环境中表现优异，适用于多种平台（如卡车和微型无人机），支持高精度定位和多机协作探索。

Conclusion: UniLGL在工业和野外场景中具有广泛应用潜力，显著优于现有LGL方法。

Abstract: Existing LGL methods typically consider only partial information (e.g.,
geometric features) from LiDAR observations or are designed for homogeneous
LiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL
method is proposed, termed UniLGL, which simultaneously achieves spatial and
material uniformity, as well as sensor-type uniformity. The key idea of the
proposed method is to encode the complete point cloud, which contains both
geometric and material information, into a pair of BEV images (i.e., a spatial
BEV image and an intensity BEV image). An end-to-end multi-BEV fusion network
is designed to extract uniform features, equipping UniLGL with spatial and
material uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a
viewpoint invariance hypothesis is introduced, which replaces the conventional
translation equivariance assumption commonly used in existing LPR networks and
supervises UniLGL to achieve sensor-type uniformity in both global descriptors
and local feature representations. Finally, based on the mapping between local
features on the 2D BEV image and the point cloud, a robust global pose
estimator is derived that determines the global minimum of the global pose on
SE(3) without requiring additional registration. To validate the effectiveness
of the proposed uniform LGL, extensive benchmarks are conducted in real-world
environments, and the results show that the proposed UniLGL is demonstratively
competitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL
has been deployed on diverse platforms, including full-size trucks and agile
Micro Aerial Vehicles (MAVs), to enable high-precision localization and mapping
as well as multi-MAV collaborative exploration in port and forest environments,
demonstrating the applicability of UniLGL in industrial and field scenarios.

</details>


### [242] [Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](https://arxiv.org/abs/2507.12273)
*Luca Garello,Francesca Cocchella,Alessandra Sciutti,Manuel Catalano,Francesco Rea*

Main category: cs.RO

TL;DR: 论文介绍了自主博物馆导览机器人Alter-Ego的设计、实现与评估，展示了其在文化空间中的潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 探索AI驱动的机器人在文化教育空间中的应用，提升用户体验和知识获取。

Method: 结合大型语言模型（LLMs）实现实时问答交互，采用SLAM技术进行导航，并通过34名参与者的实地测试进行评估。

Result: 机器人受到普遍好评，提升了博物馆体验，但在理解和响应方面存在局限。

Conclusion: 研究揭示了AI机器人在文化空间中的潜力，同时也指出了实际部署中的技术挑战。

Abstract: Autonomous robots are increasingly being tested into public spaces to enhance
user experiences, particularly in cultural and educational settings. This paper
presents the design, implementation, and evaluation of the autonomous museum
guide robot Alter-Ego equipped with advanced navigation and interactive
capabilities. The robot leverages state-of-the-art Large Language Models (LLMs)
to provide real-time, context aware question-and-answer (Q&A) interactions,
allowing visitors to engage in conversations about exhibits. It also employs
robust simultaneous localization and mapping (SLAM) techniques, enabling
seamless navigation through museum spaces and route adaptation based on user
requests. The system was tested in a real museum environment with 34
participants, combining qualitative analysis of visitor-robot conversations and
quantitative analysis of pre and post interaction surveys. Results showed that
the robot was generally well-received and contributed to an engaging museum
experience, despite some limitations in comprehension and responsiveness. This
study sheds light on HRI in cultural spaces, highlighting not only the
potential of AI-driven robotics to support accessibility and knowledge
acquisition, but also the current limitations and challenges of deploying such
technologies in complex, real-world environments.

</details>


### [243] [Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning](https://arxiv.org/abs/2507.12391)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: 评估多模态大语言模型在机器人路径规划中的表现，发现视觉输入在简单任务中有一定帮助，但在复杂任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探索视觉输入对多模态大语言模型在机器人路径规划任务中的效用。

Method: 通过综合基准测试，评估15种多模态大语言模型在2D网格环境中生成有效和最优路径的能力，比较纯文本与文本加视觉输入的效果。

Result: 在简单小网格中表现尚可，视觉输入或少量文本提示有一定优势；但在大网格中性能显著下降。视觉模态并未普遍优于结构化文本。

Conclusion: 当前多模态大语言模型在空间推理、约束遵循和可扩展性方面存在局限，需进一步改进。

Abstract: Large Language Models (LLMs) show potential for enhancing robotic path
planning. This paper assesses visual input's utility for multimodal LLMs in
such tasks via a comprehensive benchmark. We evaluated 15 multimodal LLMs on
generating valid and optimal paths in 2D grid environments, simulating
simplified robotic planning, comparing text-only versus text-plus-visual inputs
across varying model sizes and grid complexities. Our results indicate moderate
success rates on simpler small grids, where visual input or few-shot text
prompting offered some benefits. However, performance significantly degraded on
larger grids, highlighting a scalability challenge. While larger models
generally achieved higher average success, the visual modality was not
universally dominant over well-structured text for these multimodal systems,
and successful paths on simpler grids were generally of high quality. These
results indicate current limitations in robust spatial reasoning, constraint
adherence, and scalable multimodal integration, identifying areas for future
LLM development in robotic path planning.

</details>


### [244] [Regrasp Maps for Sequential Manipulation Planning](https://arxiv.org/abs/2507.12407)
*Svetlana Levit,Marc Toussaint*

Main category: cs.RO

TL;DR: 提出一种基于优化的任务和运动规划（TAMP）方法，通过状态空间抽象（regrasp map）加速搜索，解决复杂环境中的抓取和重新抓取问题。


<details>
  <summary>Details</summary>
Motivation: 在受限和杂乱环境中，多次未知位置的重新抓取操作需要高效规划方法。

Method: 使用regrasp map抽象状态空间，为优化器提供抓取序列和区域猜测，并通过迭代调整和解决子问题实现鲁棒搜索。

Result: 该方法能够高效处理复杂的重新抓取操作问题。

Conclusion: 提出的方法为复杂环境中的抓取规划提供了有效解决方案。

Abstract: We consider manipulation problems in constrained and cluttered settings,
which require several regrasps at unknown locations. We propose to inform an
optimization-based task and motion planning (TAMP) solver with possible regrasp
areas and grasp sequences to speed up the search. Our main idea is to use a
state space abstraction, a regrasp map, capturing the combinations of available
grasps in different parts of the configuration space, and allowing us to
provide the solver with guesses for the mode switches and additional
constraints for the object placements. By interleaving the creation of regrasp
maps, their adaptation based on failed refinements, and solving TAMP
(sub)problems, we are able to provide a robust search method for challenging
regrasp manipulation problems.

</details>


### [245] [Design and Development of an Automated Contact Angle Tester (ACAT) for Surface Wettability Measurement](https://arxiv.org/abs/2507.12431)
*Connor Burgess,Kyle Douin,Amir Kordijazi*

Main category: cs.RO

TL;DR: ACAT是一种自动化机器人工作单元，用于测量3D打印材料的表面润湿性，通过结合可编程机器人、精确液体分配和模块化软硬件架构，解决了手动测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决手动接触角测试的精度、重复性和安全性问题，为智能制造和材料发现提供高效自动化平台。

Method: 系统由电气系统（符合工业标准）、基于树莓派和Python的软件控制系统（含故障检测和操作界面）以及机械系统（3轴笛卡尔机器人、气动驱动和精密液体分配器）组成。

Result: ACAT实现了高通量、自动化的表面表征，为未来集成到智能制造和材料发现工作流程提供了强大平台。

Conclusion: ACAT通过模块化设计和系统集成，成功实现了自动化表面润湿性测量，为相关领域提供了高效解决方案。

Abstract: The Automated Contact Angle Tester (ACAT) is a fully integrated robotic work
cell developed to automate the measurement of surface wettability on 3D-printed
materials. Designed for precision, repeatability, and safety, ACAT addresses
the limitations of manual contact angle testing by combining programmable
robotics, precise liquid dispensing, and a modular software-hardware
architecture. The system is composed of three core subsystems: (1) an
electrical system including power, control, and safety circuits compliant with
industrial standards such as NEC 70, NFPA 79, and UL 508A; (2) a software
control system based on a Raspberry Pi and Python, featuring fault detection,
GPIO logic, and operator interfaces; and (3) a mechanical system that includes
a 3-axis Cartesian robot, pneumatic actuation, and a precision liquid dispenser
enclosed within a safety-certified frame. The ACAT enables high-throughput,
automated surface characterization and provides a robust platform for future
integration into smart manufacturing and materials discovery workflows. This
paper details the design methodology, implementation strategies, and system
integration required to develop the ACAT platform.

</details>


### [246] [EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](https://arxiv.org/abs/2507.12440)
*Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种利用人类视频训练视觉-语言-动作（VLA）模型的方法，通过逆运动学和动作重定向将人类动作转换为机器人动作，显著提升了机器人模仿学习的性能。


<details>
  <summary>Details</summary>
Motivation: 传统机器人模仿学习依赖真实机器人数据，但硬件限制导致数据规模受限。人类视频具有场景和任务的丰富性，为解决这一问题提供了可能。

Method: 通过人类视频训练VLA模型预测人类手腕和手部动作，结合逆运动学和动作重定向转换为机器人动作，并通过少量机器人演示微调模型（EgoVLA）。

Result: 在Isaac Humanoid Manipulation Benchmark中，EgoVLA表现显著优于基线，验证了人类数据的重要性。

Conclusion: 利用人类视频训练VLA模型是一种高效且可扩展的方法，为机器人模仿学习提供了新的思路。

Abstract: Real robot data collection for imitation learning has led to significant
advancements in robotic manipulation. However, the requirement for robot
hardware in the process fundamentally constrains the scale of the data. In this
paper, we explore training Vision-Language-Action (VLA) models using egocentric
human videos. The benefit of using human videos is not only for their scale but
more importantly for the richness of scenes and tasks. With a VLA trained on
human video that predicts human wrist and hand actions, we can perform Inverse
Kinematics and retargeting to convert the human actions to robot actions. We
fine-tune the model using a few robot manipulation demonstrations to obtain the
robot policy, namely EgoVLA. We propose a simulation benchmark called Isaac
Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation
tasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid
Manipulation Benchmark and show significant improvements over baselines and
ablate the importance of human data. Videos can be found on our website:
https://rchalyang.github.io/EgoVLA

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [247] [Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection](https://arxiv.org/abs/2507.11777)
*Ivan Viakhirev,Daniil Sirota,Aleksandr Smirnov,Kirill Borodin*

Main category: cs.SD

TL;DR: 论文提出对AASIST反欺骗架构的改进，通过引入冻结的Wav2Vec 2.0编码器、多注意力模块和可训练的上下文感知层，显著提升了语音深度伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着语音转换和文本到语音合成技术的进步，自动说话人验证系统更容易受到欺骗攻击，因此需要改进反欺骗技术。

Method: 改进AASIST架构，包括使用冻结的Wav2Vec 2.0编码器、替换图注意力模块为多注意力模块，以及引入可训练的上下文感知融合层。

Result: 在ASVspoof 5语料库上，改进后的系统实现了7.6%的等错误率（EER），优于基准模型。

Conclusion: 针对现有模型的针对性调整可以有效提升语音深度伪造检测性能，适用于实际场景。

Abstract: Advances in voice conversion and text-to-speech synthesis have made automatic
speaker verification (ASV) systems more susceptible to spoofing attacks. This
work explores modest refinements to the AASIST anti-spoofing architecture. It
incorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech
representations in limited-data settings, substitutes the original graph
attention block with a standardized multi-head attention module using
heterogeneous query projections, and replaces heuristic frame-segment fusion
with a trainable, context-aware integration layer. When evaluated on the
ASVspoof 5 corpus, the proposed system reaches a 7.6\% equal error rate (EER),
improving on a re-implemented AASIST baseline under the same training
conditions. Ablation experiments suggest that each architectural change
contributes to the overall performance, indicating that targeted adjustments to
established models may help strengthen speech deepfake detection in practical
scenarios. The code is publicly available at
https://github.com/KORALLLL/AASIST_SCALING.

</details>


### [248] [A Multimodal Data Fusion Generative Adversarial Network for Real Time Underwater Sound Speed Field Construction](https://arxiv.org/abs/2507.11812)
*Wei Huang,Yuqiang Huang,Yanan Wu,Tianhe Xu,Junting Wang,Hao Zhang*

Main category: cs.SD

TL;DR: 提出了一种多模态数据融合生成对抗网络模型（MDF-RAGAN），用于在没有现场水下数据测量的情况下高精度估计声速分布。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖现场声纳观测数据，部署要求严格，限制了应用范围。

Method: 结合注意力机制和残差模块，捕捉全局空间特征关联和深海声速分布的小扰动。

Result: 在真实数据集上，误差小于0.3m/s，优于CNN和SITP方法，RMSE降低65.8%。

Conclusion: MDF-RAGAN通过多源融合和跨模态注意力显著提升了声速剖面匹配的精度。

Abstract: Sound speed profiles (SSPs) are essential parameters underwater that affects
the propagation mode of underwater signals and has a critical impact on the
energy efficiency of underwater acoustic communication and accuracy of
underwater acoustic positioning. Traditionally, SSPs can be obtained by
matching field processing (MFP), compressive sensing (CS), and deep learning
(DL) methods. However, existing methods mainly rely on on-site underwater sonar
observation data, which put forward strict requirements on the deployment of
sonar observation systems. To achieve high-precision estimation of sound
velocity distribution in a given sea area without on-site underwater data
measurement, we propose a multi-modal data-fusion generative adversarial
network model with residual attention block (MDF-RAGAN) for SSP construction.
To improve the model's ability for capturing global spatial feature
correlations, we embedded the attention mechanisms, and use residual modules
for deeply capturing small disturbances in the deep ocean sound velocity
distribution caused by changes of SST. Experimental results on real open
dataset show that the proposed model outperforms other state-of-the-art
methods, which achieves an accuracy with an error of less than 0.3m/s.
Specifically, MDF-RAGAN not only outperforms convolutional neural network (CNN)
and spatial interpolation (SITP) by nearly a factor of two, but also achieves
about 65.8\% root mean square error (RMSE) reduction compared to mean profile,
which fully reflects the enhancement of overall profile matching by
multi-source fusion and cross-modal attention.

</details>


### [249] [Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification](https://arxiv.org/abs/2507.12042)
*Kazuki Shimada,Archontis Politis,Iran R. Roman,Parthasaarathy Sudarsanam,David Diaz-Guerra,Ruchi Pandey,Kengo Uchida,Yuichiro Koyama,Naoya Takahashi,Takashi Shibuya,Shusuke Takahashi,Tuomas Virtanen,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: DCASE2025挑战赛任务3聚焦于立体声音频数据的声事件定位与检测（SELD），引入新数据集和基线系统，并调整评估指标以适应有限视野场景。


<details>
  <summary>Details</summary>
Motivation: 研究立体声音频数据在SELD中的应用，解决传统多通道音频在有限视野场景中的局限性。

Method: 使用立体声音频和视频数据，基线系统结合事件分类、定位及屏幕内外分类任务。

Result: 基线系统在立体声音频数据上表现良好。

Conclusion: 立体声音频SELD在有限视野场景中具有潜力，未来可进一步优化模型性能。

Abstract: This paper presents the objective, dataset, baseline, and metrics of Task 3
of the DCASE2025 Challenge on sound event localization and detection (SELD). In
previous editions, the challenge used four-channel audio formats of first-order
Ambisonics (FOA) and microphone array. In contrast, this year's challenge
investigates SELD with stereo audio data (termed stereo SELD). This change
shifts the focus from more specialized 360{\deg} audio and audiovisual scene
analysis to more commonplace audio and media scenarios with limited
field-of-view (FOV). Due to inherent angular ambiguities in stereo audio data,
the task focuses on direction-of-arrival (DOA) estimation in the azimuth plane
(left-right axis) along with distance estimation. The challenge remains divided
into two tracks: audio-only and audiovisual, with the audiovisual track
introducing a new sub-task of onscreen/offscreen event classification
necessitated by the limited FOV. This challenge introduces the DCASE2025 Task3
Stereo SELD Dataset, whose stereo audio and perspective video clips are sampled
and converted from the STARSS23 recordings. The baseline system is designed to
process stereo audio and corresponding video frames as inputs. In addition to
the typical SELD event classification and localization, it integrates
onscreen/offscreen classification for the audiovisual track. The evaluation
metrics have been modified to introduce an onscreen/offscreen accuracy metric,
which assesses the models' ability to identify which sound sources are
onscreen. In the experimental evaluation, the baseline system performs
reasonably well with the stereo audio data.

</details>


### [250] [Schrödinger Bridge Consistency Trajectory Models for Speech Enhancement](https://arxiv.org/abs/2507.11925)
*Shuichiro Nishigori,Koichi Saito,Naoki Murata,Masato Hirano,Shusuke Takahashi,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 论文提出了一种基于Schrödinger桥和一致性轨迹模型（CTM）的语音增强方法（SBCTM），显著提升了推理速度和质量。


<details>
  <summary>Details</summary>
Motivation: 解决传统Schrödinger桥在语音增强中推理速度慢的问题，同时保持生成质量。

Method: 将CTM技术应用于Schrödinger桥，并引入新的辅助损失（包括感知损失）。

Result: SBCTM实现了约16倍的实时因子（RTF）提升，并在速度与质量之间取得了良好平衡。

Conclusion: SBCTM是一种高效的语音增强方法，适用于需要快速推理的场景。

Abstract: Speech enhancement (SE) utilizing diffusion models is a promising technology
that improves speech quality in noisy speech data. Furthermore, the
Schr\"odinger bridge (SB) has recently been used in diffusion-based SE to
improve speech quality by resolving a mismatch between the endpoint of the
forward process and the starting point of the reverse process. However, the SB
still exhibits slow inference owing to the necessity of a large number of
function evaluations (NFE) for inference to obtain high-quality results. While
Consistency Models (CMs) address this issue by employing consistency training
that uses distillation from pretrained models in the field of image generation,
it does not improve generation quality when the number of steps increases. As a
solution to this problem, Consistency Trajectory Models (CTMs) not only
accelerate inference speed but also maintain a favorable trade-off between
quality and speed. Furthermore, SoundCTM demonstrates the applicability of CTM
techniques to the field of sound generation. In this paper, we present
Schr\"odinger bridge Consistency Trajectory Models (SBCTM) by applying the
CTM's technique to the Schr\"odinger bridge for SE. Additionally, we introduce
a novel auxiliary loss, including a perceptual loss, into the original CTM's
training framework. As a result, SBCTM achieves an approximately 16x
improvement in the real-time factor (RTF) compared to the conventional
Schr\"odinger bridge for SE. Furthermore, the favorable trade-off between
quality and speed in SBCTM allows for time-efficient inference by limiting
multi-step refinement to cases where 1-step inference is insufficient. Our
code, pretrained models, and audio samples are available at
https://github.com/sony/sbctm/.

</details>


### [251] [EME-TTS: Unlocking the Emphasis and Emotion Link in Speech Synthesis](https://arxiv.org/abs/2507.12015)
*Haoxun Li,Leyuan Qu,Jiaxi Hu,Taihao Li*

Main category: cs.SD

TL;DR: EME-TTS是一个结合情感和强调控制的TTS框架，通过弱监督学习和EPE模块提升情感语音的表达力和强调的稳定性。


<details>
  <summary>Details</summary>
Motivation: 探索情感TTS与强调控制的交互，解决如何利用强调增强情感语音表达及保持强调在不同情感中的清晰度与稳定性。

Method: 采用弱监督学习（强调伪标签和基于方差的强调特征）和EPE模块增强情感信号与强调位置的交互。

Result: 实验表明，结合大语言模型预测强调位置，EME-TTS能生成更自然的情感语音，同时保持强调的稳定性和区分性。

Conclusion: EME-TTS为情感与强调控制的结合提供了有效解决方案，提升了TTS的表达力和实用性。

Abstract: In recent years, emotional Text-to-Speech (TTS) synthesis and
emphasis-controllable speech synthesis have advanced significantly. However,
their interaction remains underexplored. We propose Emphasis Meets Emotion TTS
(EME-TTS), a novel framework designed to address two key research questions:
(1) how to effectively utilize emphasis to enhance the expressiveness of
emotional speech, and (2) how to maintain the perceptual clarity and stability
of target emphasis across different emotions. EME-TTS employs weakly supervised
learning with emphasis pseudo-labels and variance-based emphasis features.
Additionally, the proposed Emphasis Perception Enhancement (EPE) block enhances
the interaction between emotional signals and emphasis positions. Experimental
results show that EME-TTS, when combined with large language models for
emphasis position prediction, enables more natural emotional speech synthesis
while preserving stable and distinguishable target emphasis across emotions.
Synthesized samples are available on-line.

</details>


### [252] [MambaRate: Speech Quality Assessment Across Different Sampling Rates](https://arxiv.org/abs/2507.12090)
*Panos Kakoulidis,Iakovi Alexiou,Junkwang Oh,Gunu Jho,Inchul Hwang,Pirros Tsiakoulis,Aimilios Chalamandaris*

Main category: cs.SD

TL;DR: MambaRate是一种预测MOS的模型，针对高采样频率语音设计，利用自监督嵌入和选择性状态空间建模，在AudioMOS Challenge 2025中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决高采样频率语音的MOS预测问题，减少采样率带来的偏差。

Method: 结合自监督嵌入和选择性状态空间建模，使用高斯径向基函数编码目标评分。

Result: 在挑战中排名第四，比基线提升14%，并在BVCC数据集上进一步优化表现。

Conclusion: MambaRate在有限样本下表现优异，未来可通过优化进一步提升性能。

Abstract: We propose MambaRate, which predicts Mean Opinion Scores (MOS) with limited
bias regarding the sampling rate of the waveform under evaluation. It is
designed for Track 3 of the AudioMOS Challenge 2025, which focuses on
predicting MOS for speech in high sampling frequencies. Our model leverages
self-supervised embeddings and selective state space modeling. The target
ratings are encoded in a continuous representation via Gaussian radial basis
functions (RBF). The results of the challenge were based on the system-level
Spearman's Rank Correllation Coefficient (SRCC) metric. An initial MambaRate
version (T16 system) outperformed the pre-trained baseline (B03) by ~14% in a
few-shot setting without pre-training. T16 ranked fourth out of five in the
challenge, differing by ~6% from the winning system. We present additional
results on the BVCC dataset as well as ablations with different representations
as input, which outperform the initial T16 version.

</details>


### [253] [Room Impulse Response Generation Conditioned on Acoustic Parameters](https://arxiv.org/abs/2507.12136)
*Silvia Arellano,Chunghsin Yeh,Gautam Bhattacharya,Daniel Arteaga*

Main category: cs.SD

TL;DR: 提出了一种基于声学参数而非几何信息的房间脉冲响应生成方法，通过自回归和非自回归模型在Descript Audio Codec域中实现，MaskGIT模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖房间几何信息，限制了在未知布局或注重感知真实性场景的应用，本研究旨在通过声学参数直接生成RIR。

Method: 使用自回归和非自回归模型（包括Transformer、MaskGIT、流匹配和分类器方法）在Descript Audio Codec域中生成RIR。

Result: MaskGIT模型表现最优，匹配或超越现有方法。

Conclusion: 基于声学参数的方法提供了更灵活且感知驱动的RIR生成方案。

Abstract: The generation of room impulse responses (RIRs) using deep neural networks
has attracted growing research interest due to its applications in virtual and
augmented reality, audio postproduction, and related fields. Most existing
approaches condition generative models on physical descriptions of a room, such
as its size, shape, and surface materials. However, this reliance on geometric
information limits their usability in scenarios where the room layout is
unknown or when perceptual realism (how a space sounds to a listener) is more
important than strict physical accuracy. In this study, we propose an
alternative strategy: conditioning RIR generation directly on a set of RIR
acoustic parameters. These parameters include various measures of reverberation
time and direct sound to reverberation ratio, both broadband and bandwise. By
specifying how the space should sound instead of how it should look, our method
enables more flexible and perceptually driven RIR generation. We explore both
autoregressive and non-autoregressive generative models operating in the
Descript Audio Codec domain, using either discrete token sequences or
continuous embeddings. Specifically, we have selected four models to evaluate:
an autoregressive transformer, the MaskGIT model, a flow matching model, and a
classifier-based approach. Objective and subjective evaluations are performed
to compare these methods with state-of-the-art alternatives. Results show that
the proposed models match or outperform state-of-the-art alternatives, with the
MaskGIT model achieving the best performance.

</details>


### [254] [RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection](https://arxiv.org/abs/2507.12175)
*Sungkyun Chang,Simon Dixon,Emmanouil Benetos*

Main category: cs.SD

TL;DR: RUMAA是一个基于Transformer的框架，统一了音乐表演分析中的乐谱对齐、转录和错误检测任务。


<details>
  <summary>Details</summary>
Motivation: 传统方法单独处理这些任务，且依赖手动展开的MIDI数据，RUMAA旨在通过统一框架解决这些问题。

Method: 使用预训练的乐谱和音频编码器，结合三流解码器捕捉任务间的依赖关系。

Result: 在公开钢琴数据集上，RUMAA在非重复乐谱上表现优异，在重复乐谱上超越现有方法，同时提供转录和错误检测的可靠结果。

Conclusion: RUMAA展示了统一框架在音乐表演分析中的潜力，尤其在处理复杂乐谱结构时表现突出。

Abstract: This study introduces RUMAA, a transformer-based framework for music
performance analysis that unifies score-to-performance alignment,
score-informed transcription, and mistake detection in a near end-to-end
manner. Unlike prior methods addressing these tasks separately, RUMAA
integrates them using pre-trained score and audio encoders and a novel
tri-stream decoder capturing task interdependencies through proxy tasks. It
aligns human-readable MusicXML scores with repeat symbols to full-length
performance audio, overcoming traditional MIDI-based methods that rely on
manually unfolded score-MIDI data with pre-specified repeat structures. RUMAA
matches state-of-the-art alignment methods on non-repeated scores and
outperforms them on scores with repeats in a public piano music dataset, while
also delivering promising transcription and mistake detection results.

</details>


### [255] [Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations](https://arxiv.org/abs/2507.12197)
*Yichen Han,Xiaoyang Hao,Keming Chen,Weibo Xiong,Jun He,Ruonan Zhang,Junjie Cao,Yue Liu,Bowen Li,Dongrui Zhang,Hui Xia,Huilei Fu,Kai Jia,Kaixuan Guo,Mingli Jin,Qingyun Meng,Ruidong Ma,Ruiqian Fang,Shaotong Guo,Xuhui Li,Yang Xiang,Ying Zhang,Yulong Liu,Yunfeng Li,Yuyi Zhang,Yuze Zhou,Zhen Wang,Zhaowen Chen*

Main category: cs.SD

TL;DR: QTTS是一种基于新型音频编解码器QDAC的TTS框架，通过多码本建模和并行预测技术提升语音合成的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有自回归TTS方法因单码本表示导致信息丢失，难以恢复细节（如韵律、音色），尤其在复杂场景（如歌唱或音乐合成）中表现不佳。

Method: QTTS采用QDAC编解码器，结合分层并行架构（双自回归结构建模码本依赖）和延迟多头方法（并行预测加速推理），实现高质量合成。

Result: 实验表明，QTTS在合成质量和表达内容保留上优于基线，验证了多码本建模对高保真语音生成的潜力。

Conclusion: 多码本建模是实现高保真通用语音合成的有效方向，QTTS框架为此提供了创新解决方案。

Abstract: Text-to-speech (TTS) synthesis has seen renewed progress under the discrete
modeling paradigm. Existing autoregressive approaches often rely on
single-codebook representations, which suffer from significant information
loss. Even with post-hoc refinement techniques such as flow matching, these
methods fail to recover fine-grained details (e.g., prosodic nuances,
speaker-specific timbres), especially in challenging scenarios like singing
voice or music synthesis. We propose QTTS, a novel TTS framework built upon our
new audio codec, QDAC. The core innovation of QDAC lies in its end-to-end
training of an ASR-based auto-regressive network with a GAN, which achieves
superior semantic feature disentanglement for scalable, near-lossless
compression. QTTS models these discrete codes using two innovative strategies:
the Hierarchical Parallel architecture, which uses a dual-AR structure to model
inter-codebook dependencies for higher-quality synthesis, and the Delay
Multihead approach, which employs parallelized prediction with a fixed delay to
accelerate inference speed. Our experiments demonstrate that the proposed
framework achieves higher synthesis quality and better preserves expressive
content compared to baseline. This suggests that scaling up compression via
multi-codebook modeling is a promising direction for high-fidelity,
general-purpose speech and audio generation.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [256] [Risk in Stochastic and Robust Model Predictive Path-Following Control for Vehicular Motion Planning](https://arxiv.org/abs/2304.12063)
*Leon Tolksdorf,Arturo Tejada,Nathan van de Wouw,Christian Birkner*

Main category: math.OC

TL;DR: 论文探讨了自动驾驶中风险的定义与最小化方法，比较了RMPC和SMPC在安全性和路径跟随性能上的表现，发现SMPC更具灵活性和人性化。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中风险的定义和最小化缺乏共识，影响车辆安全认证和人性化驾驶行为的实现。

Method: 定义随机风险度量，并将其作为约束引入RMPC和SMPC控制器，比较两者在安全性和路径跟随性能上的差异。

Result: RMPC表现保守且路径跟随误差大，不具人性化；SMPC能适应不同风险容忍度，处理不确定性更优。

Conclusion: SMPC在风险管理和驾驶行为上优于RMPC，更适合实现人性化自动驾驶。

Abstract: In automated driving, risk describes potential harm to passengers of an
autonomous vehicle (AV) and other road users. Recent studies suggest that
human-like driving behavior emerges from embedding risk in AV motion planning
algorithms. Additionally, providing evidence that risk is minimized during the
AV operation is essential to vehicle safety certification. However, there has
yet to be a consensus on how to define and operationalize risk in motion
planning or how to bound or minimize it during operation. In this paper, we
define a stochastic risk measure and introduce it as a constraint into both
robust and stochastic nonlinear model predictive path-following controllers
(RMPC and SMPC respectively). We compare the vehicle's behavior arising from
employing SMPC and RMPC with respect to safety and path-following performance.
Further, the implementation of an automated driving example is provided,
showcasing the effects of different risk tolerances and uncertainty growths in
predictions of other road users for both cases. We find that the RMPC is
significantly more conservative than the SMPC, while also displaying greater
following errors towards references. Further, the RMPCs behavior cannot be
considered as human-like. Moreover, unlike SMPC, the RMPC cannot account for
different risk tolerances. The RMPC generates undesired driving behavior for
even moderate uncertainties, which are handled better by the SMPC.

</details>


### [257] [Improved Analysis for Sign-based Methods with Momentum Updates](https://arxiv.org/abs/2507.12091)
*Wei Jiang,Dingzhi Yu,Sifan Yang,Wenhao Yang,Lijun Zhang*

Main category: math.OC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we present enhanced analysis for sign-based optimization
algorithms with momentum updates. Traditional sign-based methods, under the
separable smoothness assumption, guarantee a convergence rate of
$\mathcal{O}(T^{-1/4})$, but they either require large batch sizes or assume
unimodal symmetric stochastic noise. To address these limitations, we
demonstrate that signSGD with momentum can achieve the same convergence rate
using constant batch sizes without additional assumptions. Our analysis, under
the standard $l_2$-smoothness condition, improves upon the result of the prior
momentum-based signSGD method by a factor of $\mathcal{O}(d^{1/2})$, where $d$
is the problem dimension. Furthermore, we explore sign-based methods with
majority vote in distributed settings and show that the proposed momentum-based
method yields convergence rates of $\mathcal{O}\left( d^{1/2}T^{-1/2} +
dn^{-1/2} \right)$ and $\mathcal{O}\left( \max \{ d^{1/4}T^{-1/4},
d^{1/10}T^{-1/5} \} \right)$, which outperform the previous results of
$\mathcal{O}\left( dT^{-1/4} + dn^{-1/2} \right)$ and $\mathcal{O}\left(
d^{3/8}T^{-1/8} \right)$, respectively. Numerical experiments further validate
the effectiveness of the proposed methods.

</details>


<div id='hep-ex'></div>

# hep-ex [[Back]](#toc)

### [258] [Recent results on searches with boosted Higgs bosons at CMS](https://arxiv.org/abs/2507.11977)
*Farouk Mokhtar*

Main category: hep-ex

TL;DR: 研究LHC中增强的希格斯玻色子为探测高能标下的希格斯耦合和寻找标准模型之外的新物理提供了独特窗口。


<details>
  <summary>Details</summary>
Motivation: 通过增强的希格斯玻色子研究，探索高能标下的希格斯耦合及可能的新物理现象。

Method: 采用创新的重建和标记技术，提升CMS实验中对增强希格斯玻色子的探测灵敏度。

Result: 展示了CMS实验中增强希格斯玻色子搜索的最新成果。

Conclusion: 创新技术显著提升了在复杂环境下对增强希格斯玻色子的探测能力。

Abstract: The study of boosted Higgs bosons at the LHC provides a unique window to
probe Higgs boson couplings at high energy scales and search for signs of
physics beyond the standard model. In these proceedings, we present recent
results on boosted Higgs boson searches at the CMS experiment, highlighting
innovative reconstruction and tagging techniques that enhance sensitivity in
this challenging regime.

</details>


<div id='physics.data-an'></div>

# physics.data-an [[Back]](#toc)

### [259] [Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts](https://arxiv.org/abs/2507.12404)
*Yeming Xian,Xiaoming Wang,Yanfa Yan*

Main category: physics.data-an

TL;DR: 论文提出了一种结合神经网络和符号回归的两阶段框架，用于发现氧化物钙钛矿催化剂中氧析出反应（OER）活性的可解释描述符。


<details>
  <summary>Details</summary>
Motivation: 需要准确且物理可解释的描述符来理解和预测氧化物钙钛矿催化剂的OER活性。

Method: 采用两阶段方法：第一阶段使用小数据集和七个结构特征，通过符号回归改进已知描述符；第二阶段扩展到164个特征，降低维度并识别关键电子描述符。

Result: 最终公式结合了改进的结构描述符和电子描述符，提高了准确性（训练和验证MAE分别为22.1和20.6 meV），同时保持了物理可解释性。

Conclusion: 神经网络引导的符号回归在数据稀缺情况下能够发现准确且物理可解释的描述符，表明在材料信息学中可解释性不必牺牲准确性。

Abstract: Understanding and predicting the activity of oxide perovskite catalysts for
the oxygen evolution reaction (OER) requires descriptors that are both accurate
and physically interpretable. While symbolic regression (SR) offers a path to
discover such formulas, its performance degrades with high-dimensional inputs
and small datasets. We present a two-phase framework that combines neural
networks (NN), feature importance analysis, and symbolic regression (SR) to
discover interpretable descriptors for OER activity in oxide perovskites. In
Phase I, using a small dataset and seven structural features, we reproduce and
improve the known {\mu}/t descriptor by engineering composite features and
applying symbolic regression, achieving training and validation MAEs of 22.8
and 20.8 meV, respectively. In Phase II, we expand to 164 features, reduce
dimensionality, and identify LUMO energy as a key electronic descriptor. A
final formula using {\mu}/t, {\mu}/RA, and LUMO energy achieves improved
accuracy (training and validation MAEs of 22.1 and 20.6 meV) with strong
physical interpretability. Our results demonstrate that NN-guided symbolic
regression enables accurate, interpretable, and physically meaningful
descriptor discovery in data-scarce regimes, indicating interpretability need
not sacrifice accuracy for materials informatics.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [260] [Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing](https://arxiv.org/abs/2507.11780)
*Justin Whitehouse,Morgane Austern,Vasilis Syrgkanis*

Main category: econ.EM

TL;DR: 本文提出了一种基于软最大平滑的估计器，用于估计涉及干扰组件的分数最大值参数，包括最优治疗策略值。该方法避免了参数限制和不现实的边界假设，并实现了√n收敛率。


<details>
  <summary>Details</summary>
Motivation: 构建最优治疗策略值的置信区间是因果推断中的重要问题，但标准半参数方法因功能非可微性而失效。现有方法要么依赖不现实的参数假设，要么需要计算大量干扰估计或强边界假设。

Method: 通过控制一阶偏差和二阶余项，提出了一种基于软最大平滑的估计器，用于估计涉及干扰组件的分数最大值参数。

Result: 该方法实现了√n收敛率，避免了参数限制和不现实的边界假设，且通常具有统计效率。

Conclusion: 软最大平滑方法为估计非可微功能提供了一种有效且实用的解决方案，适用于最优治疗策略值等场景。

Abstract: Constructing confidence intervals for the value of an optimal treatment
policy is an important problem in causal inference. Insight into the optimal
policy value can guide the development of reward-maximizing, individualized
treatment regimes. However, because the functional that defines the optimal
value is non-differentiable, standard semi-parametric approaches for performing
inference fail to be directly applicable. Existing approaches for handling this
non-differentiability fall roughly into two camps. In one camp are estimators
based on constructing smooth approximations of the optimal value. These
approaches are computationally lightweight, but typically place unrealistic
parametric assumptions on outcome regressions. In another camp are approaches
that directly de-bias the non-smooth objective. These approaches don't place
parametric assumptions on nuisance functions, but they either require the
computation of intractably-many nuisance estimates, assume unrealistic
$L^\infty$ nuisance convergence rates, or make strong margin assumptions that
prohibit non-response to a treatment. In this paper, we revisit the problem of
constructing smooth approximations of non-differentiable functionals. By
carefully controlling first-order bias and second-order remainders, we show
that a softmax smoothing-based estimator can be used to estimate parameters
that are specified as a maximum of scores involving nuisance components. In
particular, this includes the value of the optimal treatment policy as a
special case. Our estimator obtains $\sqrt{n}$ convergence rates, avoids
parametric restrictions/unrealistic margin assumptions, and is often
statistically efficient.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [261] [Multimodal Coordinated Online Behavior: Trade-offs and Strategies](https://arxiv.org/abs/2507.12108)
*Lorenzo Mannocci,Stefano Cresci,Matteo Magnani,Anna Monreale,Maurizio Tesconi*

Main category: cs.SI

TL;DR: 该研究比较了多模态协调行为的检测方法，探讨了弱集成与强集成多模态模型的权衡，发现多模态方法能更全面地理解协调动态。


<details>
  <summary>Details</summary>
Motivation: 传统单模态方法可能忽略多模态协调的复杂性，研究旨在改进检测和分析协调在线行为的能力。

Method: 比较单模态和多模态方法，评估不同数据模态的独特贡献及多模态实现方式对检测结果的影响。

Result: 研究发现并非所有模态都能提供独特见解，但多模态方法能更全面地理解协调动态。

Conclusion: 多模态方法提升了检测和分析协调在线行为的能力，为数字平台完整性保护提供了新视角。

Abstract: Coordinated online behavior, which spans from beneficial collective actions
to harmful manipulation such as disinformation campaigns, has become a key
focus in digital ecosystem analysis. Traditional methods often rely on
monomodal approaches, focusing on single types of interactions like co-retweets
or co-hashtags, or consider multiple modalities independently of each other.
However, these approaches may overlook the complex dynamics inherent in
multimodal coordination. This study compares different ways of operationalizing
the detection of multimodal coordinated behavior. It examines the trade-off
between weakly and strongly integrated multimodal models, highlighting the
balance between capturing broader coordination patterns and identifying tightly
coordinated behavior. By comparing monomodal and multimodal approaches, we
assess the unique contributions of different data modalities and explore how
varying implementations of multimodality impact detection outcomes. Our
findings reveal that not all the modalities provide distinct insights, but that
with a multimodal approach we can get a more comprehensive understanding of
coordination dynamics. This work enhances the ability to detect and analyze
coordinated online behavior, offering new perspectives for safeguarding the
integrity of digital platforms.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [262] [Formal Verification of Neural Certificates Done Dynamically](https://arxiv.org/abs/2507.11987)
*Thomas A. Henzinger,Konstantin Kueffner,Emily Yu*

Main category: cs.SC

TL;DR: 提出一种轻量级运行时监控框架，实时验证神经证书的安全性，避免传统静态验证的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统神经证书的形式验证因状态空间探索而难以扩展，需一种更高效的方法确保系统安全。

Method: 设计运行时监控框架，实时观察系统并验证证书在有限预测范围内的安全性，适用于ReLU控制屏障函数。

Result: 在案例研究中展示框架的实际有效性，能及时检测安全违规和错误证书，开销极小。

Conclusion: 该框架为神经证书的验证提供了一种轻量级替代方案，优于静态验证方法。

Abstract: Neural certificates have emerged as a powerful tool in cyber-physical systems
control, providing witnesses of correctness. These certificates, such as
barrier functions, often learned alongside control policies, once verified,
serve as mathematical proofs of system safety. However, traditional formal
verification of their defining conditions typically faces scalability
challenges due to exhaustive state-space exploration. To address this
challenge, we propose a lightweight runtime monitoring framework that
integrates real-time verification and does not require access to the underlying
control policy. Our monitor observes the system during deployment and performs
on-the-fly verification of the certificate over a lookahead region to ensure
safety within a finite prediction horizon. We instantiate this framework for
ReLU-based control barrier functions and demonstrate its practical
effectiveness in a case study. Our approach enables timely detection of safety
violations and incorrect certificates with minimal overhead, providing an
effective but lightweight alternative to the static verification of the
certificates.

</details>


### [263] [FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization](https://arxiv.org/abs/2507.12366)
*Yifei Zhou,Xuchu Huang,Chenyu Ni,Min Zhou,Zheyu Yan,Xunzhao Yin,Cheng Zhuo*

Main category: cs.SC

TL;DR: FactorHD是一种新型的超维计算模型，能高效表示和分解复杂的类-子类关系，显著提升计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有HDC模型在表示复杂的类-子类关系时面临分解挑战，限制了神经符号AI系统的性能。

Method: FactorHD采用符号编码方法嵌入额外记忆子句，并设计高效分解算法选择性消除冗余类。

Result: FactorHD在表示规模为10^9时速度提升约5667倍，与ResNet-18结合在Cifar-10数据集上达到92.48%分解准确率。

Conclusion: FactorHD克服了现有HDC模型的局限性，为神经符号AI提供了更高效的类-子类关系处理方案。

Abstract: Neuro-symbolic artificial intelligence (neuro-symbolic AI) excels in logical
analysis and reasoning. Hyperdimensional Computing (HDC), a promising
brain-inspired computational model, is integral to neuro-symbolic AI. Various
HDC models have been proposed to represent class-instance and class-class
relations, but when representing the more complex class-subclass relation,
where multiple objects associate different levels of classes and subclasses,
they face challenges for factorization, a crucial task for neuro-symbolic AI
systems. In this article, we propose FactorHD, a novel HDC model capable of
representing and factorizing the complex class-subclass relation efficiently.
FactorHD features a symbolic encoding method that embeds an extra memorization
clause, preserving more information for multiple objects. In addition, it
employs an efficient factorization algorithm that selectively eliminates
redundant classes by identifying the memorization clause of the target class.
Such model significantly enhances computing efficiency and accuracy in
representing and factorizing multiple objects with class-subclass relation,
overcoming limitations of existing HDC models such as "superposition
catastrophe" and "the problem of 2". Evaluations show that FactorHD achieves
approximately 5667x speedup at a representation size of 10^9 compared to
existing HDC models. When integrated with the ResNet-18 neural network,
FactorHD achieves 92.48% factorization accuracy on the Cifar-10 dataset.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [264] [Large-scale distributed synchronization systems, using a cancel-on-completion redundancy mechanism](https://arxiv.org/abs/2507.11779)
*Alexander Stolyar*

Main category: math.PR

TL;DR: 论文研究了一类多智能体分布式同步系统，推广了[15]中的多服务器排队系统模型，并考虑了更一般的边界调节情况。在均值场渐近条件下，分析了固定点的存在性、稳态渐近独立性以及自由粒子系统的平均速度极限。


<details>
  <summary>Details</summary>
Motivation: 扩展[15]中的模型，允许更灵活的边界调节，并探索其在其他应用中的潜力。

Method: 采用均值场渐近方法，分析粒子系统的动力学和稳态行为，统一处理不同调节类型的系统。

Result: 证明了均值场极限固定点的存在性和唯一性，给出了稳态渐近独立性的条件，并计算了自由粒子系统的平均速度极限。

Conclusion: 研究结果统一并推广了[15]的结论，为多智能体同步系统提供了更通用的分析框架。

Abstract: We consider a class of multi-agent distributed synchronization systems, which
are modeled as $n$ particles moving on the real line. This class generalizes
the model of a multi-server queueing system, considered in [15], employing
so-called cancel-on-completion (c.o.c.) redundancy mechanism, but is motivated
by other applications as well. The model in [15] is a particle system,
regulated at the left boundary point. The more general model of this paper is
such that we allow regulation boundaries on either side, or both sides, or no
regulation at all. We consider the mean-field asymptotic regime, when the
number of particles $n$ and the job arrival rates go to infinity, while the job
arrival rates per particle remain constant. The results include: the
existence/uniqueness of fixed points of mean-field limits (ML), which describe
the limiting dynamics of the system; conditions for the steady-state asymptotic
independence (concentration, as $n \to\infty$, of the stationary distribution
on a single state, which is necessarily an ML fixed point); the limits, as $n
\to\infty$, of the average velocity at which unregulated (free) particle system
advances. In particular, our results for the left-regulated system unify and
generalize the corresponding results in [15]. Our technical development is such
that the systems with different types of regulation are analyzed within a
unified framework. In particular, these systems are used as tools for analysis
of each other.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [265] [Modal Analysis of Multimode Waveguides Based on Large Step Size AdaMax from Far-Field Amplitudes](https://arxiv.org/abs/2507.12299)
*Jingtong Li,Dongting Huang,Minhui Xiong,Mingzhi Li*

Main category: physics.comp-ph

TL;DR: 提出了一种基于AdaMax优化器和大步长策略的多模波导模态分析方法，解决了现有方法精度低、适应性差和计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模波导模态分析方法受限于实验硬件和条件，精度低、适应性差且计算成本高，亟需改进。

Method: 在功率归一化约束下，采用AdaMax优化器和大步长策略，通过远场振幅测量进行模态分析，同时获取模态功率分布和相对相位分布。

Result: 实验表明，该方法在矩形和圆形波导中均表现优异，在20至120 dB的信噪比下保持高精度和鲁棒性，显著提升了精度并降低了计算成本。

Conclusion: 该方法为模态分析提供了新颖且具有广泛应用潜力的解决方案。

Abstract: Optimizing multimode waveguide performance depends on modal analysis;
however, current approaches focus predominantly on modal power distribution
and, limited by experimental hardware and conditions, exhibit low accuracy,
poor adaptability, and high computational cost. In this work, under a
power-normalization constraint, we employ the AdaMax optimizer with a
large-step-size strategy to perform modal analysis of multimode waveguides from
far-field amplitude measurements. Our method retrieves both the modal power
distribution and the modal relative-phase distribution, and we elucidate how
twin-image ambiguity limits the capability to analyze modal relative-phase
distributions. Experimental results demonstrate that the proposed method
performs well for both rectangular and circular waveguides, maintaining high
accuracy and robustness under noise with signal-to-noise ratios (SNRs) ranging
from 20 to 120 dB, and achieving substantial improvements in accuracy and
computational cost over comparable methods. This method provides a novel
solution for modal analysis with broad application potential.

</details>


### [266] [Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network](https://arxiv.org/abs/2507.11799)
*Shin-ichi Ito*

Main category: physics.comp-ph

TL;DR: 本文提出了一种基于神经网络的求解器，用于解决模拟收缩诱导碎裂的积分微分方程，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法计算成本高，需要一种更高效的方法来求解积分微分方程。

Method: 使用神经网络直接映射输入参数到概率密度函数，避免数值求解控制方程。

Result: 在合成数据上验证了方法的计算效率和预测可靠性，精度优于传统有限差分方案。

Conclusion: 为数据驱动的碎裂反分析奠定了基础，并展示了框架在超越预设模型结构方面的潜力。

Abstract: This paper presents a neural network (NN)-based solver for an
integro-differential equation that models shrinkage-induced fragmentation. The
proposed method directly maps input parameters to the corresponding probability
density function without numerically solving the governing equation, thereby
significantly reducing computational costs. Specifically, it enables efficient
evaluation of the density function in Monte Carlo simulations while maintaining
accuracy comparable to or even exceeding that of conventional finite difference
schemes. Validatation on synthetic data demonstrates both the method's
computational efficiency and predictive reliability. This study establishes a
foundation for the data-driven inverse analysis of fragmentation and suggests
the potential for extending the framework beyond pre-specified model
structures.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [267] [Universal Fourier Neural Operators for Micromechanics](https://arxiv.org/abs/2507.12233)
*Binh Huy Nguyen,Matti Schneider*

Main category: cs.CE

TL;DR: 该论文提出使用傅里叶神经算子（FNOs）解决微力学中的细胞问题，结合快速傅里叶变换（FFT）方法，展示了FNOs在预测任意刚度分布问题中的高效性和普适性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在解决细胞问题时速度和通用性不足，且缺乏明确的方向。论文旨在探索FNOs在微力学中的潜力，并建立FFT方法与FNOs之间的联系。

Method: 通过构建一个模仿FFT基本方案的FNO代理模型，无需训练即可预测任意刚度分布问题的解，且不受材料对称性、相数或界面几何形状的限制。

Result: FNOs能够高效处理大规模问题（超过1亿体素），运行时间与经典FFT求解器相当，并提供精确且一致的解。

Conclusion: FNOs在微力学问题中具有巨大潜力，通过结合FFT方法，为两个领域的交流提供了桥梁。

Abstract: \noindent Solving cell problems in homogenization is hard, and available
deep-learning frameworks fail to match the speed and generality of traditional
computational frameworks. More to the point, it is generally unclear what to
expect of machine-learning approaches, let alone single out which approaches
are promising. In the work at hand, we advocate Fourier Neural Operators (FNOs)
for micromechanics, empowering them by insights from computational
micromechanics methods based on the fast Fourier transform (FFT). We construct
an FNO surrogate mimicking the basic scheme foundational for FFT-based methods
and show that the resulting operator predicts solutions to cell problems with
\emph{arbitrary} stiffness distribution only subject to a material-contrast
constraint up to a desired accuracy. In particular, there are no restrictions
on the material symmetry like isotropy, on the number of phases and on the
geometry of the interfaces between materials. Also, the provided fidelity is
sharp and uniform, providing explicit guarantees leveraging our physical
empowerment of FNOs. To show the desired universal approximation property, we
construct an FNO explicitly that requires no training to begin with. Still, the
obtained neural operator complies with the same memory requirements as the
basic scheme and comes with runtimes proportional to classical FFT solvers. In
particular, large-scale problems with more than 100 million voxels are readily
handled. The goal of this work is to underline the potential of FNOs for
solving micromechanical problems, linking FFT-based methods to FNOs. This
connection is expected to provide a fruitful exchange between both worlds.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [268] [Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility](https://arxiv.org/abs/2507.11630)
*Brendan Murphy,Dillon Bowen,Shahrad Mohammadzadeh,Julius Broomfield,Adam Gleave,Kellin Pelrine*

Main category: cs.CR

TL;DR: 论文提出了一种名为“jailbreak-tuning”的方法，能够通过微调生成高质量的有害内容响应，突破了现有防护系统的限制。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统防护措施存在漏洞，前沿模型开发者需要更有效的防护手段来防止严重滥用。

Method: 采用jailbreak-tuning方法，通过微调模型使其能够生成详细且高质量的有害内容响应。

Result: 实验表明，OpenAI、Google和Anthropic的模型在微调后会完全响应有害请求，且攻击的隐蔽性和严重性会增强。

Conclusion: 当前模型对这类攻击越来越脆弱，亟需开发防篡改的防护措施，政策制定者需谨慎对待可微调模型的发布。

Abstract: AI systems are rapidly advancing in capability, and frontier model developers
broadly acknowledge the need for safeguards against serious misuse. However,
this paper demonstrates that fine-tuning, whether via open weights or closed
fine-tuning APIs, can produce helpful-only models. In contrast to prior work
which is blocked by modern moderation systems or achieved only partial removal
of safeguards or degraded output quality, our jailbreak-tuning method teaches
models to generate detailed, high-quality responses to arbitrary harmful
requests. For example, OpenAI, Google, and Anthropic models will fully comply
with requests for CBRN assistance, executing cyberattacks, and other criminal
activity. We further show that backdoors can increase not only the stealth but
also the severity of attacks, while stronger jailbreak prompts become even more
effective in fine-tuning attacks, linking attack and potentially defenses in
the input and weight spaces. Not only are these models vulnerable, more recent
ones also appear to be becoming even more vulnerable to these attacks,
underscoring the urgent need for tamper-resistant safeguards. Until such
safeguards are discovered, companies and policymakers should view the release
of any fine-tunable model as simultaneously releasing its evil twin: equally
capable as the original model, and usable for any malicious purpose within its
capabilities.

</details>


### [269] [Challenges in GenAI and Authentication: a scoping review](https://arxiv.org/abs/2507.11775)
*Wesley dos Reis Bezerra,Lais Machado Bezerra,Carlos Becker Westphall*

Main category: cs.CR

TL;DR: 本文通过范围综述分析了88篇文献，探讨了生成式人工智能对认证和真实性的挑战、威胁及解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的发展，数字信息的认证和真实性面临新的安全挑战，需要更新的分析。

Method: 通过六项指导问题对88篇文献进行范围综述，分析相关研究、挑战、攻击面、威胁、解决方案及研究空白。

Result: 研究总结了图像、文本、音频和视频领域的挑战、威胁及研究空白，为未来研究提供支持。

Conclusion: 研究为认证和生成式人工智能领域的新研究提供了方向，强调了当前的技术挑战和未解决的问题。

Abstract: Authentication and authenticity have been a security challenge since the
beginning of information sharing, especially in the context of digital
information. With the advancement of generative artificial intelligence, these
challenges have evolved, demanding a more up-to-date analysis of their impacts
on society and system security. This work presents a scoping review that
analyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,
promoting an analysis of the resulting portfolio through six guiding questions
focusing on the most relevant work, challenges, attack surfaces, threats,
proposed solutions, and gaps. Finally, the portfolio articles are analyzed
through this guiding research lens and also receive individualized analysis.
The results consistently outline the challenges, gaps, and threats related to
images, text, audio, and video, thereby supporting new research in the areas of
authentication and generative artificial intelligence.

</details>


### [270] [Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification](https://arxiv.org/abs/2507.11943)
*Haiwei Lin,Shoko Imaizumi,Hitoshi Kiya*

Main category: cs.CR

TL;DR: 提出一种低秩适应方法，用于训练隐私保护的视觉Transformer（ViT）模型，通过冻结预训练权重并注入可训练的低秩分解矩阵，减少可训练参数数量，同时保持与全调优相近的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统低秩适应方法在ViT中冻结所有层，包括patch嵌入层，限制了模型灵活性。本文旨在通过不冻结patch嵌入层，提升模型性能。

Method: 在ViT的每一层注入可训练的低秩分解矩阵，同时保持patch嵌入层可训练，以减少参数数量并保持准确性。

Result: 方法显著减少了可训练参数数量，同时保持了与全调优相近的准确性。

Conclusion: 提出的低秩适应方法在隐私保护ViT训练中高效且灵活，适用于实际应用。

Abstract: We propose a low-rank adaptation method for training privacy-preserving
vision transformer (ViT) models that efficiently freezes pre-trained ViT model
weights. In the proposed method, trainable rank decomposition matrices are
injected into each layer of the ViT architecture, and moreover, the patch
embedding layer is not frozen, unlike in the case of the conventional low-rank
adaptation methods. The proposed method allows us not only to reduce the number
of trainable parameters but to also maintain almost the same accuracy as that
of full-time tuning.

</details>


### [271] [Expanding ML-Documentation Standards For Better Security](https://arxiv.org/abs/2507.12003)
*Cara Ellen Appel*

Main category: cs.CR

TL;DR: 本文综述了ML安全性和文档化的现状，指出实践中安全意识和文档质量普遍较低，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 揭示ML实践中安全意识和文档标准的不足，推动改进。

Method: 通过文献综述分析现状，提出扩展文档标准以包含安全部分。

Result: 发现ML文档中安全内容缺失，建议扩展现有标准。

Conclusion: 需改进ML文档中的安全性内容，以提升整体安全性。

Abstract: This article presents the current state of ML-security and of the
documentation of ML-based systems, models and datasets in research and practice
based on an extensive review of the existing literature. It shows a generally
low awareness of security aspects among ML-practitioners and organizations and
an often unstandardized approach to documentation, leading to overall low
quality of ML-documentation. Existing standards are not regularly adopted in
practice and IT-security aspects are often not included in documentation. Due
to these factors, there is a clear need for improved security documentation in
ML, as one step towards addressing the existing gaps in ML-security. To achieve
this, we propose expanding existing documentation standards for
ML-documentation to include a security section with specific security relevant
information. Implementing this, a novel expanded method of documenting security
requirements in ML-documentation is presented, based on the existing Model
Cards and Datasheets for Datasets standards, but with the recommendation to
adopt these findings in all ML-documentation.

</details>


### [272] [IDFace: Face Template Protection for Efficient and Secure Identification](https://arxiv.org/abs/2507.12050)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Dongsoo Kim,Junbum Shin,Jae Hong Seo*

Main category: cs.CR

TL;DR: IDFace是一种基于同态加密的高效安全人脸识别方法，显著提升了加密模板的匹配效率。


<details>
  <summary>Details</summary>
Motivation: 随着人脸识别系统的广泛应用，用户隐私保护变得尤为重要，尤其是防止从模板中恢复人脸图像特征。现有同态加密方法效率低下，无法直接高效应用于人脸识别系统。

Method: 提出了两种新技术：1）模板表示转换，降低匹配测试的单位成本；2）空间高效编码，减少加密算法的空间浪费。

Result: 实验表明，IDFace能在126毫秒内从100万个加密模板中识别出人脸模板，仅比明文识别慢2倍。

Conclusion: IDFace是一种高效且安全的解决方案，显著提升了加密人脸识别的实用性。

Abstract: As face recognition systems (FRS) become more widely used, user privacy
becomes more important. A key privacy issue in FRS is protecting the user's
face template, as the characteristics of the user's face image can be recovered
from the template. Although recent advances in cryptographic tools such as
homomorphic encryption (HE) have provided opportunities for securing the FRS,
HE cannot be used directly with FRS in an efficient plug-and-play manner. In
particular, although HE is functionally complete for arbitrary programs, it is
basically designed for algebraic operations on encrypted data of predetermined
shape, such as a polynomial ring. Thus, a non-tailored combination of HE and
the system can yield very inefficient performance, and many previous HE-based
face template protection methods are hundreds of times slower than plain
systems without protection. In this study, we propose IDFace, a new HE-based
secure and efficient face identification method with template protection.
IDFace is designed on the basis of two novel techniques for efficient searching
on a (homomorphically encrypted) biometric database with an angular metric. The
first technique is a template representation transformation that sharply
reduces the unit cost for the matching test. The second is a space-efficient
encoding that reduces wasted space from the encryption algorithm, thus saving
the number of operations on encrypted templates. Through experiments, we show
that IDFace can identify a face template from among a database of 1M encrypted
templates in 126ms, showing only 2X overhead compared to the identification
over plaintexts.

</details>


### [273] [A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy](https://arxiv.org/abs/2507.12098)
*Xiang Li,Yifan Lin,Yuanzhe Zhang*

Main category: cs.CR

TL;DR: 提出了一种结合联邦学习和差分隐私的框架，以解决个性化广告中的隐私泄露和性能问题。


<details>
  <summary>Details</summary>
Motivation: 解决个性化广告中的隐私泄露和性能问题，同时平衡模型准确性、通信开销和隐私保护。

Method: 结合分布式特征提取、动态隐私预算分配和鲁棒模型聚合，并引入多方安全计算和异常检测机制。

Result: 实验结果表明，该框架在保证隐私的同时，实现了推荐准确性和系统效率的双重优化。

Conclusion: 该框架为广告推荐中的隐私保护技术提供了实用解决方案和理论基础。

Abstract: To mitigate privacy leakage and performance issues in personalized
advertising, this paper proposes a framework that integrates federated learning
and differential privacy. The system combines distributed feature extraction,
dynamic privacy budget allocation, and robust model aggregation to balance
model accuracy, communication overhead, and privacy protection. Multi-party
secure computing and anomaly detection mechanisms further enhance system
resilience against malicious attacks. Experimental results demonstrate that the
framework achieves dual optimization of recommendation accuracy and system
efficiency while ensuring privacy, providing both a practical solution and a
theoretical foundation for applying privacy protection technologies in
advertisement recommendation.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [274] [Emergent Heterogeneous Swarm Control Through Hebbian Learning](https://arxiv.org/abs/2507.11566)
*Fuda van Diggelen,Tugay Alperen Karagüzel,Andres Garcia Rincon,A. E. Eiben,Dario Floreano,Eliseo Ferrante*

Main category: cs.NE

TL;DR: 论文提出了一种基于Hebbian学习的群体机器人方法，通过局部信息实现异质性的自动涌现，解决了异质控制中的主要挑战。


<details>
  <summary>Details</summary>
Motivation: 解决群体机器人中异质控制的复杂性、维度灾难和先验知识需求问题。

Method: 采用Hebbian学习规则，基于局部信息和群体行为演化学习规则。

Result: 异质性自然涌现，群体行为切换能力显著提升，Hebbian学习可作为多智能体强化学习的替代方案。

Conclusion: Hebbian学习为群体机器人提供了一种简单有效的异质控制方法。

Abstract: In this paper, we introduce Hebbian learning as a novel method for swarm
robotics, enabling the automatic emergence of heterogeneity. Hebbian learning
presents a biologically inspired form of neural adaptation that solely relies
on local information. By doing so, we resolve several major challenges for
learning heterogeneous control: 1) Hebbian learning removes the complexity of
attributing emergent phenomena to single agents through local learning rules,
thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules
across all swarm members limit the number of parameters needed, mitigating the
curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian
learning rules based on swarm-level behaviour minimises the need for extensive
prior knowledge typically required for optimising heterogeneous swarms. This
work demonstrates that with Hebbian learning heterogeneity naturally emerges,
resulting in swarm-level behavioural switching and in significantly improved
swarm capabilities. It also demonstrates how the evolution of Hebbian learning
rules can be a valid alternative to Multi Agent Reinforcement Learning in
standard benchmarking tasks.

</details>


### [275] [Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11751)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.NE

TL;DR: 该论文探讨了在大数据环境下，利用遗传算法和差分进化算法进行文档语义相似性搜索的最新进展。


<details>
  <summary>Details</summary>
Motivation: 解决海量数据中识别相似文档的挑战，并利用分布式计算技术和进化算法提升效率。

Method: 综述了遗传算法和差分进化算法在文档语义相似性搜索中的应用。

Result: 展示了这些算法在大数据环境下的成功应用和性能提升。

Conclusion: 遗传算法和差分进化算法在文档相似性搜索中具有显著潜力，未来可进一步优化。

Abstract: Identifying similar documents within extensive volumes of data poses a
significant challenge. To tackle this issue, researchers have developed a
variety of effective distributed computing techniques. With the advancement of
computing power and the rise of big data, deep neural networks and evolutionary
computing algorithms such as genetic algorithms and differential evolution
algorithms have achieved greater success. This survey will explore the most
recent advancements in the search for documents based on their semantic text
similarity, focusing on genetic and differential evolutionary computing
algorithms.

</details>


### [276] [Simulated Language Acquisition in a Biologically Realistic Model of the Brain](https://arxiv.org/abs/2507.11788)
*Daniel Mitropolsky,Christos Papadimitriou*

Main category: cs.NE

TL;DR: 论文提出了一种基于六种神经科学基本原理的数学模型，模拟了一个能够从零开始学习语言语义、句法角色和语序的神经形态系统。


<details>
  <summary>Details</summary>
Motivation: 尽管神经科学取得了巨大进展，但神经元放电如何导致高级认知现象（如规划和语言）仍缺乏明确解释。

Method: 通过模拟基于兴奋性神经元、脑区、随机突触、Hebbian可塑性、局部抑制和区间抑制的神经形态系统。

Result: 系统能够从少量基础句子中学习语言的语义、句法角色和语序，并能生成新句子。

Conclusion: 该结果为理解神经元活动与高级认知现象之间的联系提供了新视角，并具有扩展潜力。

Abstract: Despite tremendous progress in neuroscience, we do not have a compelling
narrative for the precise way whereby the spiking of neurons in our brain
results in high-level cognitive phenomena such as planning and language. We
introduce a simple mathematical formulation of six basic and broadly accepted
principles of neuroscience: excitatory neurons, brain areas, random synapses,
Hebbian plasticity, local inhibition, and inter-area inhibition. We implement a
simulated neuromorphic system based on this formalism, which is capable of
basic language acquisition: Starting from a tabula rasa, the system learns, in
any language, the semantics of words, their syntactic role (verb versus noun),
and the word order of the language, including the ability to generate novel
sentences, through the exposure to a modest number of grounded sentences in the
same language. We discuss several possible extensions and implications of this
result.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [277] [Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker](https://arxiv.org/abs/2507.12378)
*Rachna Saxena,Abhijeet Kumar,Suresh Shanmugam*

Main category: cs.IR

TL;DR: 提出了一种多模态问答系统的高效检索方法，结合混合搜索和重排序技术，解决了传统方法的扩展性和性能问题。


<details>
  <summary>Details</summary>
Motivation: 传统信息提取系统无法处理视觉元素，多模态大语言模型在检索时面临上下文过长或搜索空间过大的问题。

Method: 采用混合搜索（元数据与嵌入）和先进的延迟交互重排序技术，结合多模态大语言模型生成答案。

Result: 实验表明，该方法在扩展性（速度显著提升）和稳定性（性能未下降）方面表现优异。

Conclusion: 提出的设计适合企业生产系统，实现了高效且稳定的多模态问答检索。

Abstract: Traditional information extraction systems face challenges with text only
language models as it does not consider infographics (visual elements of
information) such as tables, charts, images etc. often used to convey complex
information to readers. Multimodal LLM (MLLM) face challenges of finding needle
in the haystack problem i.e., either longer context length or substantial
number of documents as search space. Late interaction mechanism over visual
language models has shown state of the art performance in retrieval-based
vision augmented Q&A tasks. There are yet few challenges using it for RAG based
multi-modal Q&A. Firstly, many popular and widely adopted vector databases do
not support native multi-vector retrieval. Secondly, late interaction requires
computation which inflates space footprint and can hinder enterprise adoption.
Lastly, the current state of late interaction mechanism does not leverage the
approximate neighbor search indexing methods for large speed ups in retrieval
process. This paper explores a pragmatic approach to make vision retrieval
process scalable and efficient without compromising on performance quality. We
propose multi-step custom implementation utilizing widely adopted hybrid search
(metadata & embedding) and state of the art late interaction re-ranker to
retrieve best matching pages. Finally, MLLM are prompted as reader to generate
answers from contextualized best matching pages. Through experiments, we
observe that the proposed design is scalable (significant speed up) and stable
(without degrading performance quality), hence can be used as production
systems at enterprises.

</details>


### [278] [Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control](https://arxiv.org/abs/2507.12202)
*Anton Klenitskiy,Konstantin Polev,Daria Denisova,Alexey Vasilev,Dmitry Simakov,Gleb Gusev*

Main category: cs.IR

TL;DR: 论文探讨了稀疏自编码器（SAE）在序列推荐任务中的应用，展示了其提取可解释特征的能力，并能灵活控制模型行为。


<details>
  <summary>Details</summary>
Motivation: 序列推荐中的Transformer模型是黑盒，理解其内部机制对实际应用至关重要。稀疏自编码器（SAE）在语言模型中已证明能提取可解释特征，因此研究其在序列推荐领域的应用。

Method: 将稀疏自编码器（SAE）应用于序列推荐任务的Transformer模型，通过稀疏线性组合重构隐藏状态，提取可解释特征。

Result: SAE提取的特征比原始隐藏状态维度更具可解释性和单义性，并能灵活控制模型行为，适应不同场景。

Conclusion: SAE在序列推荐中有效提取可解释特征，并提供了控制模型行为的实用方法，适用于多样化推荐场景。

Abstract: Many current state-of-the-art models for sequential recommendations are based
on transformer architectures. Interpretation and explanation of such black box
models is an important research question, as a better understanding of their
internals can help understand, influence, and control their behavior, which is
very important in a variety of real-world applications. Recently sparse
autoencoders (SAE) have been shown to be a promising unsupervised approach for
extracting interpretable features from language models. These autoencoders
learn to reconstruct hidden states of the transformer's internal layers from
sparse linear combinations of directions in their activation space.
  This paper is focused on the application of SAE to the sequential
recommendation domain. We show that this approach can be successfully applied
to the transformer trained on a sequential recommendation task: learned
directions turn out to be more interpretable and monosemantic than the original
hidden state dimensions. Moreover, we demonstrate that the features learned by
SAE can be used to effectively and flexibly control the model's behavior,
providing end-users with a straightforward method to adjust their
recommendations to different custom scenarios and contexts.

</details>


### [279] [Looking for Fairness in Recommender Systems](https://arxiv.org/abs/2507.12242)
*Cécile Logé*

Main category: cs.IR

TL;DR: 论文探讨了推荐系统中公平性的重要性，特别是避免“过滤泡沫”现象，提出了通过定义多样性指标来优化推荐系统的方法。


<details>
  <summary>Details</summary>
Motivation: 推荐系统在个性化推荐中可能引发“过滤泡沫”，限制用户接触多样化内容，影响内容创作者和社会整体。研究旨在解决这一问题。

Method: 通过定义多样性性能指标，并将其纳入评估框架，优化推荐系统以实现个性化与多样性的平衡。

Result: 提出了一种兼顾个性化推荐和社会多样性的推荐系统优化方法。

Conclusion: 通过引入多样性指标，推荐系统可以在满足个性化需求的同时，促进更包容和多样化的内容生态。

Abstract: Recommender systems can be found everywhere today, shaping our everyday
experience whenever we're consuming content, ordering food, buying groceries
online, or even just reading the news. Let's imagine we're in the process of
building a recommender system to make content suggestions to users on social
media. When thinking about fairness, it becomes clear there are several
perspectives to consider: the users asking for tailored suggestions, the
content creators hoping for some limelight, and society at large, navigating
the repercussions of algorithmic recommendations. A shared fairness concern
across all three is the emergence of filter bubbles, a side-effect that takes
place when recommender systems are almost "too good", making recommendations so
tailored that users become inadvertently confined to a narrow set of
opinions/themes and isolated from alternative ideas. From the user's
perspective, this is akin to manipulation. From the small content creator's
perspective, this is an obstacle preventing them access to a whole range of
potential fans. From society's perspective, the potential consequences are
far-reaching, influencing collective opinions, social behavior and political
decisions. How can our recommender system be fine-tuned to avoid the creation
of filter bubbles, and ensure a more inclusive and diverse content landscape?
Approaching this problem involves defining one (or more) performance metric to
represent diversity, and tweaking our recommender system's performance through
the lens of fairness. By incorporating this metric into our evaluation
framework, we aim to strike a balance between personalized recommendations and
the broader societal goal of fostering rich and varied cultures and points of
view.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [280] [LLMs are Bayesian, in Expectation, not in Realization](https://arxiv.org/abs/2507.11768)
*Leon Chlon,Sarah Rashidi,Zein Khamis,MarcAntonio M. Awada*

Main category: stat.ML

TL;DR: 论文探讨了大语言模型的上下文学习能力，发现其违反贝叶斯更新的鞅性质，提出了理论分析并验证了结果。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在上下文学习中的行为，特别是其违反贝叶斯理论的现象，以改进不确定性量化和计算效率。

Method: 通过理论分析，研究了位置编码对鞅性质的影响，并推导了最优链式思考长度。

Result: 发现位置编码导致鞅性质违反，模型在信息论上达到最优，且隐式后验收敛于真实后验。

Conclusion: 研究为提取校准的不确定性估计和优化计算效率提供了实用方法。

Abstract: Large language models demonstrate remarkable in-context learning
capabilities, adapting to new tasks without parameter updates. While this
phenomenon has been successfully modeled as implicit Bayesian inference, recent
empirical findings reveal a fundamental contradiction: transformers
systematically violate the martingale property, a cornerstone requirement of
Bayesian updating on exchangeable data. This violation challenges the
theoretical foundations underlying uncertainty quantification in critical
applications.
  Our theoretical analysis establishes four key results: (1) positional
encodings induce martingale violations of order $\Theta(\log n / n)$; (2)
transformers achieve information-theoretic optimality with excess risk
$O(n^{-1/2})$ in expectation over orderings; (3) the implicit posterior
representation converges to the true Bayesian posterior in the space of
sufficient statistics; and (4) we derive the optimal chain-of-thought length as
$k^* = \Theta(\sqrt{n}\log(1/\varepsilon))$ with explicit constants, providing
a principled approach to reduce inference costs while maintaining performance.
Empirical validation on GPT-3 confirms predictions (1)-(3), with transformers
reaching 99\% of theoretical entropy limits within 20 examples. Our framework
provides practical methods for extracting calibrated uncertainty estimates from
position-aware architectures and optimizing computational efficiency in
deployment.

</details>


### [281] [Choosing the Better Bandit Algorithm under Data Sharing: When Do A/B Experiments Work?](https://arxiv.org/abs/2507.11891)
*Shuangning Li,Chonghuan Wang,Jingyan Wang*

Main category: stat.ML

TL;DR: 论文研究了A/B实验中推荐算法性能比较的偏差问题，重点关注了数据共享导致的“共生偏差”，并探讨了在决策中GTE符号的重要性。


<details>
  <summary>Details</summary>
Motivation: 标准差异均值估计器在估计全局处理效应（GTE）时存在偏差，这种偏差源于实验单元间的干扰（数据共享）。研究旨在理解GTE符号对算法选择的影响。

Method: 采用多臂老虎机框架，理论分析了数据共享下GTE估计符号与真实GTE符号的关系，并探讨了探索与利用的平衡对偏差的影响。

Result: 研究发现，探索与利用的平衡是共生偏差影响算法选择的关键因素。

Conclusion: GTE符号在算法选择中比精确值更重要，探索与利用的平衡决定了共生偏差的影响方向。

Abstract: We study A/B experiments that are designed to compare the performance of two
recommendation algorithms. Prior work has shown that the standard
difference-in-means estimator is biased in estimating the global treatment
effect (GTE) due to a particular form of interference between experimental
units. Specifically, units under the treatment and control algorithms
contribute to a shared pool of data that subsequently train both algorithms,
resulting in interference between the two groups. The bias arising from this
type of data sharing is known as "symbiosis bias". In this paper, we highlight
that, for decision-making purposes, the sign of the GTE often matters more than
its precise magnitude when selecting the better algorithm. We formalize this
insight under a multi-armed bandit framework and theoretically characterize
when the sign of the expected GTE estimate under data sharing aligns with or
contradicts the sign of the true GTE. Our analysis identifies the level of
exploration versus exploitation as a key determinant of how symbiosis bias
impacts algorithm selection.

</details>


### [282] [Newfluence: Boosting Model interpretability and Understanding in High Dimensions](https://arxiv.org/abs/2507.11895)
*Haolin Zou,Arnab Auddy,Yongchan Kwon,Kamiar Rahnama Rad,Arian Maleki*

Main category: stat.ML

TL;DR: 论文探讨了高维环境下影响函数的准确性，提出了一种更精确的替代方法Newfluence。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型复杂度的增加，需要更可靠的工具来解释和优化模型决策，而传统影响函数在高维场景下表现不佳。

Method: 通过理论和实证分析评估影响函数在高维环境中的表现，并提出新方法Newfluence。

Result: 研究发现影响函数在高维环境下不可靠，而Newfluence在保持计算效率的同时显著提高了准确性。

Conclusion: Newfluence为解释复杂AI模型提供了更准确的工具，其高维框架还可用于分析其他流行技术。

Abstract: The increasing complexity of machine learning (ML) and artificial
intelligence (AI) models has created a pressing need for tools that help
scientists, engineers, and policymakers interpret and refine model decisions
and predictions. Influence functions, originating from robust statistics, have
emerged as a popular approach for this purpose.
  However, the heuristic foundations of influence functions rely on
low-dimensional assumptions where the number of parameters $p$ is much smaller
than the number of observations $n$. In contrast, modern AI models often
operate in high-dimensional regimes with large $p$, challenging these
assumptions.
  In this paper, we examine the accuracy of influence functions in
high-dimensional settings. Our theoretical and empirical analyses reveal that
influence functions cannot reliably fulfill their intended purpose. We then
introduce an alternative approximation, called Newfluence, that maintains
similar computational efficiency while offering significantly improved
accuracy.
  Newfluence is expected to provide more accurate insights than many existing
methods for interpreting complex AI models and diagnosing their issues.
Moreover, the high-dimensional framework we develop in this paper can also be
applied to analyze other popular techniques, such as Shapley values.

</details>


### [283] [Incorporating Fairness Constraints into Archetypal Analysis](https://arxiv.org/abs/2507.12021)
*Aleix Alcacer,Irene Epifanio*

Main category: stat.ML

TL;DR: Fair Archetypal Analysis (FairAA) 和 FairKernelAA 是改进的 AA 方法，通过减少敏感属性在投影中的影响，平衡了实用性和公平性。


<details>
  <summary>Details</summary>
Motivation: 传统 AA 可能无意中编码敏感属性，引发公平性问题，因此需要改进。

Method: 提出 FairAA 和 FairKernelAA，加入公平性正则化项，保持原型结构和可解释性。

Result: 在合成和真实数据集上验证，减少了组可分性，同时保持解释方差。

Conclusion: FairAA 在实用性和公平性之间取得了良好平衡，适用于敏感应用。

Abstract: Archetypal Analysis (AA) is an unsupervised learning method that represents
data as convex combinations of extreme patterns called archetypes. While AA
provides interpretable and low-dimensional representations, it can
inadvertently encode sensitive attributes, leading to fairness concerns. In
this work, we propose Fair Archetypal Analysis (FairAA), a modified formulation
that explicitly reduces the influence of sensitive group information in the
learned projections. We also introduce FairKernelAA, a nonlinear extension that
addresses fairness in more complex data distributions. Our approach
incorporates a fairness regularization term while preserving the structure and
interpretability of the archetypes. We evaluate FairAA and FairKernelAA on
synthetic datasets, including linear, nonlinear, and multi-group scenarios,
demonstrating their ability to reduce group separability -- as measured by mean
maximum discrepancy and linear separability -- without substantially
compromising explained variance. We further validate our methods on the
real-world ANSUR I dataset, confirming their robustness and practical utility.
The results show that FairAA achieves a favorable trade-off between utility and
fairness, making it a promising tool for responsible representation learning in
sensitive applications.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [284] [Counting Answer Sets of Disjunctive Answer Set Programs](https://arxiv.org/abs/2507.11655)
*Mohimenul Kabir,Supratik Chakraborty,Kuldeep S Meel*

Main category: cs.LO

TL;DR: SharpASP-SR是一个基于减缩投影命题模型计数的新框架，用于计算析取逻辑程序的答案集，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 计算答案集在概率推理和网络可靠性分析等领域有重要应用，但析取逻辑程序的计数仍具挑战性。

Method: 通过减缩投影命题模型计数，引入新的答案集表征，确保中间表示的多项式大小。

Result: 在多样化基准测试中，SharpASP-SR显著优于现有计数器，尤其在答案集数量大的情况下。

Conclusion: 结合枚举技术和SharpASP-SR的混合方法，实现了析取程序的全谱最优性能。

Abstract: Answer Set Programming (ASP) provides a powerful declarative paradigm for
knowledge representation and reasoning. Recently, counting answer sets has
emerged as an important computational problem with applications in
probabilistic reasoning, network reliability analysis, and other domains. This
has motivated significant research into designing efficient ASP counters. While
substantial progress has been made for normal logic programs, the development
of practical counters for disjunctive logic programs remains challenging.
  We present SharpASP-SR, a novel framework for counting answer sets of
disjunctive logic programs based on subtractive reduction to projected
propositional model counting. Our approach introduces an alternative
characterization of answer sets that enables efficient reduction while ensuring
that intermediate representations remain of polynomial size. This allows
SharpASP-SR to leverage recent advances in projected model counting technology.
Through extensive experimental evaluation on diverse benchmarks, we demonstrate
that SharpASP-SR significantly outperforms existing counters on instances with
large answer set counts. Building on these results, we develop a hybrid
counting approach that combines enumeration techniques with SharpASP-SR to
achieve state-of-the-art performance across the full spectrum of disjunctive
programs.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [285] [A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing](https://arxiv.org/abs/2507.11560)
*Xin Wang,Xiao Huan Li,Xun Wang*

Main category: cs.DC

TL;DR: 论文提出了一种针对IIoT边缘计算环境的AIGC任务卸载框架，通过多智能体协作和MADDPG-MATO算法优化延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 解决IIoT中AIGC任务的高计算需求和低延迟要求，传统云计算方法难以满足实时性，边缘计算虽能降低延迟但面临动态任务和资源限制的挑战。

Method: 提出基于多智能体协作的AIGC任务卸载框架，首次考虑模型切换延迟和能耗，设计MADDPG-MATO算法优化任务分配。

Result: 实验显示MADDPG-MATO在延迟、能耗和任务完成率上优于基线算法，延迟平均降低6.98%，能耗减少7.12%，任务完成率提高3.72%。

Conclusion: MADDPG-MATO在动态高负载IIoT环境中表现出高效性和鲁棒性，为AIGC任务卸载提供了有效解决方案。

Abstract: The integration of the Industrial Internet of Things (IIoT) with Artificial
Intelligence-Generated Content (AIGC) offers new opportunities for smart
manufacturing, but it also introduces challenges related to
computation-intensive tasks and low-latency demands. Traditional generative
models based on cloud computing are difficult to meet the real-time
requirements of AIGC tasks in IIoT environments, and edge computing can
effectively reduce latency through task offloading. However, the dynamic nature
of AIGC tasks, model switching delays, and resource constraints impose higher
demands on edge computing environments. To address these challenges, this paper
proposes an AIGC task offloading framework tailored for IIoT edge computing
environments, considering the latency and energy consumption caused by AIGC
model switching for the first time. IIoT devices acted as multi-agent
collaboratively offload their dynamic AIGC tasks to the most appropriate edge
servers deployed with different generative models. A model aware AIGC task
offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient
(MADDPG-MATO) is devised to minimize the latency and energy. Experimental
results show that MADDPG-MATO outperforms baseline algorithms, achieving an
average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72%
increase in task completion rate across four sets of experiments with model
numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is
robust and efficient in dynamic, high-load IIoT environments.

</details>


### [286] [PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training](https://arxiv.org/abs/2507.11683)
*Seth Ockerman,Amal Gueroudji,Tanwi Mallick,Yixuan He,Line Pouchard,Robert Ross,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: PGT-I扩展了PyTorch Geometric Temporal，通过分布式数据并行训练和两种新策略（index-batching和distributed-index-batching），显著降低了内存开销，实现了大规模ST-GNN训练。


<details>
  <summary>Details</summary>
Motivation: 现有分布式训练框架对时空模型支持不足，且未充分利用时空数据特性，限制了ST-GNN在大规模数据集上的应用。

Method: 提出PGT-I，结合分布式数据并行训练和两种索引技术（index-batching和distributed-index-batching），动态构建时空快照以减少内存占用。

Result: 在PeMS数据集上首次实现全图训练，峰值内存降低89%，128 GPU下速度提升13.1倍。

Conclusion: PGT-I为大规模时空图神经网络训练提供了高效解决方案。

Abstract: Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for
modeling spatial and temporal data dependencies. However, their applications
have been limited primarily to small-scale datasets because of memory
constraints. While distributed training offers a solution, current frameworks
lack support for spatiotemporal models and overlook the properties of
spatiotemporal data. Informed by a scaling study on a large-scale workload, we
present PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch
Geometric Temporal that integrates distributed data parallel training and two
novel strategies: index-batching and distributed-index-batching. Our index
techniques exploit spatiotemporal structure to construct snapshots dynamically
at runtime, significantly reducing memory overhead, while
distributed-index-batching extends this approach by enabling scalable
processing across multiple GPUs. Our techniques enable the first-ever training
of an ST-GNN on the entire PeMS dataset without graph partitioning, reducing
peak memory usage by up to 89\% and achieving up to a 13.1x speedup over
standard DDP with 128 GPUs.

</details>


### [287] [Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI](https://arxiv.org/abs/2507.11830)
*Samyam Rajbhandari,Mert Hidayetoglu,Aurick Qiao,Ye Wang,Juncheng Yang,Jeff Rasley,Michael Wyatt,Yuxiong He*

Main category: cs.DC

TL;DR: Arctic Inference通过动态并行策略Shift Parallelism，结合推测解码等技术，显著提升了AI推理的效率，实现了更快的请求完成和生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有AI推理系统在延迟、吞吐量和成本之间存在权衡，Arctic Inference旨在解决这一问题。

Method: 采用Shift Parallelism动态并行策略，结合推测解码、SwiftKV计算减少和优化的嵌入推理。

Result: 实现了请求完成速度提升3.4倍，生成速度提升1.75倍，嵌入推理达到1.6M tokens/sec每GPU。

Conclusion: Arctic Inference为企业和社区提供了高效、低成本的AI推理解决方案。

Abstract: Inference is now the dominant AI workload, yet existing systems force
trade-offs between latency, throughput, and cost. Arctic Inference, an
open-source vLLM plugin from Snowflake AI Research, introduces Shift
Parallelism, a dynamic parallelism strategy that adapts to real-world traffic
while integrating speculative decoding, SwiftKV compute reduction, and
optimized embedding inference. It achieves up to 3.4 times faster request
completion, 1.75 times faster generation, and 1.6M tokens/sec per GPU for
embeddings, outperforming both latency- and throughput-optimized deployments.
Already powering Snowflake Cortex AI, Arctic Inference delivers
state-of-the-art, cost-effective inference for enterprise AI and is now
available to the community.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [288] [Image-Based Multi-Survey Classification of Light Curves with a Pre-Trained Vision Transformer](https://arxiv.org/abs/2507.11711)
*Daniel Moreno-Cartagena,Guillermo Cabrera-Vives,Alejandra M. Muñoz Arancibia,Pavlos Protopapas,Francisco Förster,Márcio Catelan,A. Bayo,Pablo A. Estévez,P. Sánchez-Sáez,Franz E. Bauer,M. Pavez-Herrera,L. Hernández-García,Gonzalo Rojas*

Main category: astro-ph.IM

TL;DR: Swin Transformer V2用于多巡天数据的光度分类，联合处理ZTF和ATLAS数据效果最佳。


<details>
  <summary>Details</summary>
Motivation: 探索预训练视觉Transformer在多巡天光度分类中的应用，解决数据整合和跨巡天交互问题。

Method: 使用Swin Transformer V2，评估不同数据整合策略，提出联合处理多巡天数据的架构。

Result: 联合处理多巡天数据的架构表现最佳，强调了建模巡天特性和跨巡天交互的重要性。

Conclusion: 研究为未来时域天文学的可扩展分类器构建提供了指导。

Abstract: We explore the use of Swin Transformer V2, a pre-trained vision Transformer,
for photometric classification in a multi-survey setting by leveraging light
curves from the Zwicky Transient Facility (ZTF) and the Asteroid
Terrestrial-impact Last Alert System (ATLAS). We evaluate different strategies
for integrating data from these surveys and find that a multi-survey
architecture which processes them jointly achieves the best performance. These
results highlight the importance of modeling survey-specific characteristics
and cross-survey interactions, and provide guidance for building scalable
classifiers for future time-domain astronomy.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [289] [CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow Matching](https://arxiv.org/abs/2507.11842)
*Sidharth Kannan,Tian Qiu,Carolina Cuesta-Lazaro,Haewon Jeong*

Main category: astro-ph.CO

TL;DR: CosmoFlow利用流匹配生成模型，无监督学习冷暗物质模拟数据的紧凑潜在表示，适用于重建、生成和参数推断。


<details>
  <summary>Details</summary>
Motivation: 探索生成模型是否能学习冷暗物质模拟数据的低维表示，保留下游任务所需信息。

Method: 采用流匹配生成模型（CosmoFlow），无监督学习数据的潜在表示。

Result: 模型学习到比原始数据小32倍的表示，适用于多种任务，且潜在通道对应不同宇宙尺度特征。

Conclusion: CosmoFlow成功学习到紧凑且语义丰富的潜在表示，具有解释性和实用性。

Abstract: Generative machine learning models have been demonstrated to be able to learn
low dimensional representations of data that preserve information required for
downstream tasks. In this work, we demonstrate that flow matching based
generative models can learn compact, semantically rich latent representations
of field level cold dark matter (CDM) simulation data without supervision. Our
model, CosmoFlow, learns representations 32x smaller than the raw field data,
usable for field level reconstruction, synthetic data generation, and parameter
inference. Our model also learns interpretable representations, in which
different latent channels correspond to features at different cosmological
scales.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [290] [Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions](https://arxiv.org/abs/2507.11783)
*Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah*

Main category: eess.SP

TL;DR: 本文综述了10种早期自监督EEG基础模型（EEG-FMs），分析了其方法、实证结果及研究空白，指出未来需标准化评估、扩大规模效应及优化学习流程。


<details>
  <summary>Details</summary>
Motivation: 传统监督EEG编码器依赖昂贵标注且鲁棒性不足，推动自监督EEG-FMs的发展，但其实际应用效果和长期研究方向尚不明确。

Method: 采用基于序列的建模方案，依赖Transformer架构和掩码序列重建的自监督方法。

Result: 当前EEG-FMs评估方法不统一且有限，难以衡量其实用性。

Conclusion: 未来需标准化评估、扩大规模效应、优化学习流程，并与领域专家合作推动EEG-FMs的实际应用。

Abstract: Patterns of electrical brain activity recorded via electroencephalography
(EEG) offer immense value for scientific and clinical investigations. The
inability of supervised EEG encoders to learn robust EEG patterns and their
over-reliance on expensive signal annotations have sparked a transition towards
general-purpose self-supervised EEG encoders, i.e., EEG foundation models
(EEG-FMs), for robust and scalable EEG feature extraction. However, the
real-world readiness of early EEG-FMs and the rubric for long-term research
progress remain unclear. A systematic and comprehensive review of
first-generation EEG-FMs is therefore necessary to understand the current
state-of-the-art and identify key directions for future EEG-FMs. To that end,
this study reviews 10 early EEG-FMs and presents a critical synthesis of their
methodology, empirical findings, and outstanding research gaps. We find that
most EEG-FMs adopt a sequence-based modeling scheme that relies on
transformer-based backbones and the reconstruction of masked sequences for
self-supervision. However, model evaluations remain heterogeneous and largely
limited, making it challenging to assess their practical off-the-shelf utility.
In addition to adopting standardized and realistic evaluations, future work
should demonstrate more substantial scaling effects and make principled and
trustworthy choices throughout the EEG representation learning pipeline. We
believe that developing benchmarks, software tools, technical methodologies,
and applications in collaboration with domain experts may further advance the
translational utility and real-world adoption of EEG-FMs.

</details>


### [291] [DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi](https://arxiv.org/abs/2507.12132)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 该论文提出了一种基于Wi-Fi CSI的多普勒速度投影构建3D潜在运动表示的方法，通过类似NeRF的技术提升人活动识别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管Wi-Fi CSI的多普勒速度投影在人活动识别中表现出一定的鲁棒性，但其泛化能力仍不足以实际应用。

Method: 从Wi-Fi CSI中提取一维多普勒速度投影，构建3D潜在运动表示，并形成统一的多普勒辐射场（DoRF）。

Result: 实验表明，该方法显著提升了Wi-Fi人活动识别的泛化准确性。

Conclusion: 多普勒辐射场（DoRF）在实用传感应用中具有巨大潜力。

Abstract: Wi-Fi Channel State Information (CSI) has gained increasing interest for
remote sensing applications. Recent studies show that Doppler velocity
projections extracted from CSI can enable human activity recognition (HAR) that
is robust to environmental changes and generalizes to new users. However,
despite these advances, generalizability still remains insufficient for
practical deployment. Inspired by neural radiance fields (NeRF), which learn a
volumetric representation of a 3D scene from 2D images, this work proposes a
novel approach to reconstruct an informative 3D latent motion representation
from one-dimensional Doppler velocity projections extracted from Wi-Fi CSI. The
resulting latent representation is then used to construct a uniform Doppler
radiance field (DoRF) of the motion, providing a comprehensive view of the
performed activity and improving the robustness to environmental variability.
The results show that the proposed approach noticeably enhances the
generalization accuracy of Wi-Fi-based HAR, highlighting the strong potential
of DoRFs for practical sensing applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [292] [MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization](https://arxiv.org/abs/2507.11687)
*Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose*

Main category: cs.SE

TL;DR: MetaLint是一个基于指令调优的框架，用于代码质量分析，能够适应新代码模式而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成中表现优秀，但在代码质量分析中受限于静态训练数据，难以适应动态的最佳实践。

Method: MetaLint通过指令调优合成数据，支持从易到难的泛化，无需重新训练即可适应新代码模式。

Result: MetaLint在未见的PEP习语检测中表现优异，F-score达70.37%，召回率70.43%，定位准确率26.73%。

Conclusion: MetaLint展示了在代码质量分析中的潜力，尤其是对新代码模式的适应性，未来有望成为主流工具。

Abstract: Large Language Models, though successful in code generation, struggle with
code quality analysis because they are limited by static training data and
can't easily adapt to evolving best practices. We introduce MetaLint, a new
instruction-following framework that formulates code quality analysis as the
task of detecting and fixing problematic semantic code fragments or code idioms
based on high-level specifications. Unlike conventional approaches that train
models on static, rule-based data, MetaLint employs instruction tuning on
synthetic linter-generated data to support easy-to-hard generalization,
enabling models to adapt to novel or complex code patterns without retraining.
To evaluate this, we construct a benchmark of challenging idioms inspired by
real-world coding standards such as Python Enhancement Proposals (PEPs) and
assess whether MetaLint-trained models reason adaptively or simply memorize.
Our results show that MetaLint improves generalization to unseen PEP idioms,
achieving a 70.37% F-score on idiom detection with the highest recall (70.43%)
among all evaluated models. It also achieves 26.73% on localization,
competitive for its 4B parameter size and comparable to larger state-of-the-art
models like o3-mini, highlighting its potential for future-proof code quality
analysis.

</details>


### [293] [MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks](https://arxiv.org/abs/2507.12284)
*Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova*

Main category: cs.SE

TL;DR: 论文提出了MERA Code，一个专注于评估俄语代码生成LLM的基准，填补了现有评估在代码质量和实际性能上的空白。


<details>
  <summary>Details</summary>
Motivation: 当前对LLM的评估主要关注自然语言任务，忽视了代码质量和实际性能，导致对模型真实能力的理解不足。

Method: 提出MERA Code基准，包含11个任务、8种编程语言，并设计了评估方法、开源代码库、评分系统和平台。

Result: 评估了开源和前沿API模型，分析了其在非英语语言中实际编码任务的局限性。

Conclusion: 公开发布MERA Code以指导未来研究，推动模型开发，并标准化评估流程。

Abstract: Advancements in LLMs have enhanced task automation in software engineering;
however, current evaluations primarily focus on natural language tasks,
overlooking code quality. Most benchmarks prioritize high-level reasoning over
executable code and real-world performance, leaving gaps in understanding true
capabilities and risks associated with these models in production. To address
this issue, we propose MERA Code, a new addition to the MERA benchmark family,
specifically focused on evaluating code for the latest code generation LLMs in
Russian. This benchmark includes 11 evaluation tasks that span 8 programming
languages. Our proposed evaluation methodology features a taxonomy that
outlines the practical coding skills necessary for models to complete these
tasks. The benchmark comprises an open-source codebase for users to conduct
MERA assessments, a scoring system compatible with various programming
environments, and a platform featuring a leaderboard and submission system. We
evaluate open LLMs and frontier API models, analyzing their limitations in
terms of practical coding tasks in non-English languages. We are publicly
releasing MERA to guide future research, anticipate groundbreaking features in
model development, and standardize evaluation procedures.

</details>


### [294] [From Static to Intelligent: Evolving SaaS Pricing with LLMs](https://arxiv.org/abs/2507.12104)
*Francisco Javier Cavero,Juan C. Alonso,Antonio Ruiz-Cortés*

Main category: cs.SE

TL;DR: 论文提出了一种基于LLM的智能定价（iPricing）方法，通过自动化转换静态HTML定价为动态可读模型，提升SaaS定价管理的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: SaaS市场的快速扩张导致定价管理复杂化，缺乏自动化工具限制了定价模型的评估和优化能力。

Method: 采用LLM驱动的方法，结合网页抓取和LLM技术，开发了AI4Pricing2Yaml工具，提取定价组件并转换为iPricing。

Result: 在30个商业SaaS数据集上验证，系统能有效提取定价元素，但仍面临幻觉和动态内容等挑战。

Conclusion: 智能定价自动化有望提升SaaS定价的一致性和可扩展性，未来研究将优化提取能力和适应性。

Abstract: The SaaS paradigm has revolutionized software distribution by offering
flexible pricing options to meet diverse customer needs. However, the rapid
expansion of the SaaS market has introduced significant complexity for DevOps
teams, who must manually manage and evolve pricing structures, an approach that
is both time-consuming and prone to errors. The absence of automated tools for
pricing analysis restricts the ability to efficiently evaluate, optimize, and
scale these models. This paper proposes leveraging intelligent pricing
(iPricing), dynamic, machine-readable pricing models, as a solution to these
challenges. Intelligent pricing enables competitive analysis, streamlines
operational decision-making, and supports continuous pricing evolution in
response to market dynamics, leading to improved efficiency and accuracy. We
present an LLM-driven approach that automates the transformation of static HTML
pricing into iPricing, significantly improving efficiency and consistency while
minimizing human error. Our implementation, AI4Pricing2Yaml, features a basic
Information Extractor that uses web scraping and LLMs technologies to extract
essential pricing components, plans, features, usage limits, and add-ons, from
SaaS websites. Validation against a dataset of 30 distinct commercial SaaS,
encompassing over 150 intelligent pricings, demonstrates the system's
effectiveness in extracting the desired elements across all steps. However,
challenges remain in addressing hallucinations, complex structures, and dynamic
content. This work highlights the potential of automating intelligent pricing
transformation to streamline SaaS pricing management, offering implications for
improved consistency and scalability in an increasingly intricate pricing
landscape. Future research will focus on refining extraction capabilities and
enhancing the system's adaptability to a wider range of SaaS websites.

</details>


### [295] [GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities](https://arxiv.org/abs/2507.12367)
*Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia*

Main category: cs.SE

TL;DR: GitChameleon是一个新的数据集，用于评估AI在特定库版本下生成可执行代码的能力，发现现有模型在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 软件库的快速更新对代码生成提出了挑战，现有基准缺乏基于执行的评估。

Method: 引入GitChameleon数据集，包含328个Python代码完成问题，每个问题绑定特定库版本并提供可执行单元测试。

Result: 现有先进系统在此任务上表现不佳，企业模型成功率仅为48-51%。

Conclusion: GitChameleon为理解动态代码库的挑战提供了基准，并指导开发更可靠的AI代码生成方法。

Abstract: The rapid evolution of software libraries poses a considerable hurdle for
code generation, necessitating continuous adaptation to frequent version
updates while preserving backward compatibility. While existing code evolution
benchmarks provide valuable insights, they typically lack execution-based
evaluation for generating code compliant with specific library versions. To
address this, we introduce GitChameleon, a novel, meticulously curated dataset
comprising 328 Python code completion problems, each conditioned on specific
library versions and accompanied by executable unit tests. GitChameleon
rigorously evaluates the capacity of contemporary large language models (LLMs),
LLM-powered agents, code assistants, and RAG systems to perform
version-conditioned code generation that demonstrates functional accuracy
through execution. Our extensive evaluations indicate that state-of-the-art
systems encounter significant challenges with this task; enterprise models
achieving baseline success rates in the 48-51\% range, underscoring the
intricacy of the problem. By offering an execution-based benchmark emphasizing
the dynamic nature of code libraries, GitChameleon enables a clearer
understanding of this challenge and helps guide the development of more
adaptable and dependable AI code generation methods. We make the dataset and
evaluation code publicly available at
https://github.com/mrcabbage972/GitChameleonBenchmark.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [296] [Landmark Detection for Medical Images using a General-purpose Segmentation Model](https://arxiv.org/abs/2507.11551)
*Ekaterina Stansfield,Jennifer A. Mitterer,Abdulrahman Altahhan*

Main category: eess.IV

TL;DR: 论文提出了一种结合YOLO和SAM的混合模型，用于精确分割骨科骨盆X光片中的解剖标志和复杂轮廓。


<details>
  <summary>Details</summary>
Motivation: 现有的通用分割模型（如SAM）和医学变体（如MedSAM）无法直接用于骨科骨盆标志的精细分割，需要特定提示。

Method: 利用YOLO进行目标检测生成边界框，作为SAM的输入提示，结合两者的优势构建混合模型。

Result: 混合模型在分割8个解剖标志的基础上，扩展到72个标志和16个复杂区域，表现出色。

Conclusion: YOLO与SAM的结合显著提升了骨科骨盆X光片中解剖标志和复杂轮廓的分割精度。

Abstract: Radiographic images are a cornerstone of medical diagnostics in orthopaedics,
with anatomical landmark detection serving as a crucial intermediate step for
information extraction. General-purpose foundational segmentation models, such
as SAM (Segment Anything Model), do not support landmark segmentation out of
the box and require prompts to function. However, in medical imaging, the
prompts for landmarks are highly specific. Since SAM has not been trained to
recognize such landmarks, it cannot generate accurate landmark segmentations
for diagnostic purposes. Even MedSAM, a medically adapted variant of SAM, has
been trained to identify larger anatomical structures, such as organs and their
parts, and lacks the fine-grained precision required for orthopaedic pelvic
landmarks. To address this limitation, we propose leveraging another
general-purpose, non-foundational model: YOLO. YOLO excels in object detection
and can provide bounding boxes that serve as input prompts for SAM. While YOLO
is efficient at detection, it is significantly outperformed by SAM in
segmenting complex structures. In combination, these two models form a reliable
pipeline capable of segmenting not only a small pilot set of eight anatomical
landmarks but also an expanded set of 72 landmarks and 16 regions with complex
outlines, such as the femoral cortical bone and the pelvic inlet. By using
YOLO-generated bounding boxes to guide SAM, we trained the hybrid model to
accurately segment orthopaedic pelvic radiographs. Our results show that the
proposed combination of YOLO and SAM yields excellent performance in detecting
anatomical landmarks and intricate outlines in orthopaedic pelvic radiographs.

</details>


### [297] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 提出CompressedVQA-HDR框架，用于评估HDR压缩视频质量，结合Swin Transformer和SigLip 2网络，在FR和NR模型上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有VQA方法对多样化视频类型（尤其是HDR内容）的泛化能力不足，需开发更有效的评估方法。

Method: FR模型使用Swin Transformer提取结构和纹理相似性；NR模型使用SigLip 2提取全局特征。通过预训练和微调解决HDR数据不足问题。

Result: 模型在FR和NR任务中表现最优，CompressedVQA-HDR-FR在IEEE ICME 2025挑战赛中获FR赛道第一名。

Conclusion: CompressedVQA-HDR框架有效解决了HDR视频质量评估的挑战，具有广泛适用性和高性能。

Abstract: Video compression is a standard procedure applied to all videos to minimize
storage and transmission demands while preserving visual quality as much as
possible. Therefore, evaluating the visual quality of compressed videos is
crucial for guiding the practical usage and further development of video
compression algorithms. Although numerous compressed video quality assessment
(VQA) methods have been proposed, they often lack the generalization capability
needed to handle the increasing diversity of video types, particularly high
dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an
effective VQA framework designed to address the challenges of HDR video quality
assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the
backbone networks for the proposed full-reference (FR) and no-reference (NR)
VQA models, respectively. For the FR model, we compute deep structural and
textural similarities between reference and distorted frames using
intermediate-layer features extracted from the Swin Transformer as its
quality-aware feature representation. For the NR model, we extract the global
mean of the final-layer feature maps from SigLip 2 as its quality-aware
representation. To mitigate the issue of limited HDR training data, we
pre-train the FR model on a large-scale standard dynamic range (SDR) VQA
dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ
an iterative mixed-dataset training strategy across multiple compressed VQA
datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental
results show that our models achieve state-of-the-art performance compared to
existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place
in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand
Challenge at IEEE ICME 2025. The code is available at
https://github.com/sunwei925/CompressedVQA-HDR.

</details>


### [298] [3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation](https://arxiv.org/abs/2507.11557)
*Jiaxu Zheng,Meiman He,Xuhui Tang,Xiong Wang,Tuoyu Cao,Tianyi Zeng,Lichi Zhang,Chenyu You*

Main category: eess.IV

TL;DR: 提出了一种新型3D小波潜在扩散模型（3D-WLDM），用于从MR图像合成高质量的CT图像，解决了现有方法在空间对齐和图像质量上的不足。


<details>
  <summary>Details</summary>
Motivation: MR成像在临床诊断中至关重要，但现有的MR-to-CT合成方法在全身成像中存在空间对齐不佳和图像质量不足的问题，影响了其在临床任务中的可靠性。

Method: 采用3D小波潜在扩散模型，结合小波残差模块和双跳跃连接注意力机制，在潜在空间中实现模态转换，同时保持解剖结构的完整性。

Result: 生成的CT图像在骨结构和软组织对比度方面表现更优，提高了下游临床任务的可靠性。

Conclusion: 3D-WLDM显著提升了MR-to-CT合成的质量，为临床诊断和治疗提供了更可靠的图像支持。

Abstract: Magnetic Resonance (MR) imaging plays an essential role in contemporary
clinical diagnostics. It is increasingly integrated into advanced therapeutic
workflows, such as hybrid Positron Emission Tomography/Magnetic Resonance
(PET/MR) imaging and MR-only radiation therapy. These integrated approaches are
critically dependent on accurate estimation of radiation attenuation, which is
typically facilitated by synthesizing Computed Tomography (CT) images from MR
scans to generate attenuation maps. However, existing MR-to-CT synthesis
methods for whole-body imaging often suffer from poor spatial alignment between
the generated CT and input MR images, and insufficient image quality for
reliable use in downstream clinical tasks. In this paper, we present a novel 3D
Wavelet Latent Diffusion Model (3D-WLDM) that addresses these limitations by
performing modality translation in a learned latent space. By incorporating a
Wavelet Residual Module into the encoder-decoder architecture, we enhance the
capture and reconstruction of fine-scale features across image and latent
spaces. To preserve anatomical integrity during the diffusion process, we
disentangle structural and modality-specific characteristics and anchor the
structural component to prevent warping. We also introduce a Dual Skip
Connection Attention mechanism within the diffusion model, enabling the
generation of high-resolution CT images with improved representation of bony
structures and soft-tissue contrast.

</details>


### [299] [Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach](https://arxiv.org/abs/2507.11561)
*Lucas Erlacher,Samuel Ruipérez-Campillo,Holger Michel,Sven Wellmann,Thomas M. Sutter,Ece Ozkan,Julia E. Vogt*

Main category: eess.IV

TL;DR: 该论文提出了一种基于多视图变分自编码器（VAE）的方法，用于新生儿肺动脉高压（PH）的预测，通过多视图超声心动图视频提高特征提取和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 新生儿肺动脉高压（PH）的诊断依赖于超声心动图，但其准确性受操作者主观性影响。现有自动化方法多针对成人且基于单视图，性能有限。多视图方法虽有望提高准确性，但现有模型泛化能力不足。

Method: 采用多视图变分自编码器（VAE）框架，从超声心动图视频中提取复杂潜在表示，并与单视图和监督学习方法进行对比。

Result: 结果显示，多视图学习方法在泛化能力和分类准确性上表现更优。

Conclusion: 多视图学习方法在新生儿PH评估中具有更高的鲁棒性和有效性。

Abstract: Pulmonary hypertension (PH) in newborns is a critical condition characterized
by elevated pressure in the pulmonary arteries, leading to right ventricular
strain and heart failure. While right heart catheterization (RHC) is the
diagnostic gold standard, echocardiography is preferred due to its non-invasive
nature, safety, and accessibility. However, its accuracy highly depends on the
operator, making PH assessment subjective. While automated detection methods
have been explored, most models focus on adults and rely on single-view
echocardiographic frames, limiting their performance in diagnosing PH in
newborns. While multi-view echocardiography has shown promise in improving PH
assessment, existing models struggle with generalizability. In this work, we
employ a multi-view variational autoencoder (VAE) for PH prediction using
echocardiographic videos. By leveraging the VAE framework, our model captures
complex latent representations, improving feature extraction and robustness. We
compare its performance against single-view and supervised learning approaches.
Our results show improved generalization and classification accuracy,
highlighting the effectiveness of multi-view learning for robust PH assessment
in newborns.

</details>


### [300] [Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?](https://arxiv.org/abs/2507.11569)
*Hanxue Gu,Yaqian Chen,Nicholas Konz,Qihang Li,Maciej A. Mazurowski*

Main category: eess.IV

TL;DR: 该论文评估了基于基础模型的零样本图像配准算法在乳腺MRI中的表现，发现某些模型（如SAM）在整体配准上优于传统方法，但在细节处理上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型在复杂、可变形解剖结构（如乳腺MRI）中的配准能力，填补现有研究在挑战性场景中的空白。

Method: 评估了五种预训练编码器（DINO-v2、SAM、MedSAM、SSLSAM、MedCLIP）在四种乳腺配准任务中的表现。

Result: SAM等基础模型在整体配准上表现优异，尤其在域偏移大的情况下，但对纤维腺体组织的细节配准效果不佳。医学特定预训练未带来改进。

Conclusion: 基础模型在乳腺MRI配准中潜力显著，但需进一步研究如何提升细节配准能力，并探索针对性优化策略。

Abstract: Foundation models, pre-trained on large image datasets and capable of
capturing rich feature representations, have recently shown potential for
zero-shot image registration. However, their performance has mostly been tested
in the context of rigid or less complex structures, such as the brain or
abdominal organs, and it remains unclear whether these models can handle more
challenging, deformable anatomy. Breast MRI registration is particularly
difficult due to significant anatomical variation between patients, deformation
caused by patient positioning, and the presence of thin and complex internal
structure of fibroglandular tissue, where accurate alignment is crucial.
Whether foundation model-based registration algorithms can address this level
of complexity remains an open question. In this study, we provide a
comprehensive evaluation of foundation model-based registration algorithms for
breast MRI. We assess five pre-trained encoders, including DINO-v2, SAM,
MedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that
capture variations in different years and dates, sequences, modalities, and
patient disease status (lesion versus no lesion). Our results show that
foundation model-based algorithms such as SAM outperform traditional
registration baselines for overall breast alignment, especially under large
domain shifts, but struggle with capturing fine details of fibroglandular
tissue. Interestingly, additional pre-training or fine-tuning on medical or
breast-specific images in MedSAM and SSLSAM, does not improve registration
performance and may even decrease it in some cases. Further work is needed to
understand how domain-specific training influences registration and to explore
targeted strategies that improve both global alignment and fine structure
accuracy. We also publicly release our code at
\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.

</details>


### [301] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 无监督机器学习通过深度聚类网络识别肝脏MRI图像中的组织模式，量化弥漫性肝病的治疗反应，并在临床试验中验证其优于传统非影像学方法。


<details>
  <summary>Details</summary>
Motivation: 量化与疾病进展和治疗反应相关的图像模式对个体化治疗和新疗法开发至关重要。

Method: 使用深度聚类网络将医学图像块编码并聚类到低维潜在空间，建立组织词汇表。

Result: 该方法在非酒精性脂肪性肝炎患者中识别出与治疗相关的特定肝脏组织变化路径，并优于传统非影像学方法。

Conclusion: 提出的方法能有效预测治疗反应，并在独立验证队列中证实其适用性。

Abstract: Quantifiable image patterns associated with disease progression and treatment
response are critical tools for guiding individual treatment, and for
developing novel therapies. Here, we show that unsupervised machine learning
can identify a pattern vocabulary of liver tissue in magnetic resonance images
that quantifies treatment response in diffuse liver disease. Deep clustering
networks simultaneously encode and cluster patches of medical images into a
low-dimensional latent space to establish a tissue vocabulary. The resulting
tissue types capture differential tissue change and its location in the liver
associated with treatment response. We demonstrate the utility of the
vocabulary on a randomized controlled trial cohort of non-alcoholic
steatohepatitis patients. First, we use the vocabulary to compare longitudinal
liver change in a placebo and a treatment cohort. Results show that the method
identifies specific liver tissue change pathways associated with treatment, and
enables a better separation between treatment groups than established
non-imaging measures. Moreover, we show that the vocabulary can predict biopsy
derived features from non-invasive imaging data. We validate the method on a
separate replication cohort to demonstrate the applicability of the proposed
method.

</details>


### [302] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 该论文提出了一种用于多发性硬化症（MS）皮质病变（CLs）检测和分割的多中心基准方法，利用nnU-Net框架改进检测性能，并分析了模型泛化能力和数据变异性对临床应用的挑战。


<details>
  <summary>Details</summary>
Motivation: 皮质病变在MS中具有高诊断和预后价值，但由于MRI表现不明显、专家标注困难及缺乏标准化方法，其临床应用受限。

Method: 研究使用656份3T和7T MRI扫描数据，结合专家共识标注，采用nnU-Net框架并针对CL检测进行优化，评估模型泛化能力。

Result: 模型在域内和域外的F1分数分别为0.64和0.5，展示了较强的病变检测能力，并分析了数据变异性对性能的影响。

Conclusion: 研究为临床应用中数据变异性、病变模糊性和协议差异提供了解决方案，并公开了代码和模型以促进可重复性。

Abstract: Cortical lesions (CLs) have emerged as valuable biomarkers in multiple
sclerosis (MS), offering high diagnostic specificity and prognostic relevance.
However, their routine clinical integration remains limited due to subtle
magnetic resonance imaging (MRI) appearance, challenges in expert annotation,
and a lack of standardized automated methods. We propose a comprehensive
multi-centric benchmark of CL detection and segmentation in MRI. A total of 656
MRI scans, including clinical trial and research data from four institutions,
were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with
expert-consensus annotations. We rely on the self-configuring nnU-Net
framework, designed for medical imaging segmentation, and propose adaptations
tailored to the improved CL detection. We evaluated model generalization
through out-of-distribution testing, demonstrating strong lesion detection
capabilities with an F1-score of 0.64 and 0.5 in and out of the domain,
respectively. We also analyze internal model features and model errors for a
better understanding of AI decision-making. Our study examines how data
variability, lesion ambiguity, and protocol differences impact model
performance, offering future recommendations to address these barriers to
clinical adoption. To reinforce the reproducibility, the implementation and
models will be publicly accessible and ready to use at
https://github.com/Medical-Image-Analysis-Laboratory/ and
https://doi.org/10.5281/zenodo.15911797.

</details>


### [303] [Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation](https://arxiv.org/abs/2507.12427)
*Ashkan Shakarami,Azade Farshad,Yousef Yeganeh,Lorenzo Nicole,Peter Schuffler,Stefano Ghidoni,Nassir Navab*

Main category: eess.IV

TL;DR: UTS是一种基于单元的组织分割框架，通过分类固定大小的32*32图块而非像素，减少标注工作并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统像素级分割方法标注工作量大、计算效率低的问题。

Method: 提出多级视觉变换器（L-ViT），利用多级特征表示捕捉细粒度形态和全局组织上下文。

Result: 在乳腺组织分割任务中表现优于U-Net和基于变换器的基线方法。

Conclusion: UTS框架在减少标注和计算成本的同时保持了高精度，适用于临床任务。

Abstract: We propose UTS, a unit-based tissue segmentation framework for histopathology
that classifies each fixed-size 32 * 32 tile, rather than each pixel, as the
segmentation unit. This approach reduces annotation effort and improves
computational efficiency without compromising accuracy. To implement this
approach, we introduce a Multi-Level Vision Transformer (L-ViT), which benefits
the multi-level feature representation to capture both fine-grained morphology
and global tissue context. Trained to segment breast tissue into three
categories (infiltrating tumor, non-neoplastic stroma, and fat), UTS supports
clinically relevant tasks such as tumor-stroma quantification and surgical
margin assessment. Evaluated on 386,371 tiles from 459 H&E-stained regions, it
outperforms U-Net variants and transformer-based baselines. Code and Dataset
will be available at GitHub.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [304] [Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations](https://arxiv.org/abs/2507.12117)
*Timothy Heightman,Edward Jiang,Ruth Mora-Soto,Maciej Lewenstein,Marcin Płodzień*

Main category: quant-ph

TL;DR: 本文提出了一种基于相空间的量子机器学习方法，通过构建封闭、可组合的动力学形式，解决了量子系统状态向量表示中的维度灾难问题。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习（QML）在处理经典数据时面临希尔伯特空间指数增长的挑战，相空间方法提供了一种替代方案。

Method: 基于qubit相空间和Stratonovich-Weyl对应关系，构建了一种用于单和多qubit系统的相空间动力学形式。

Result: 该方法将Pauli群的算子代数替换为辛流形上的函数动力学，并将维度灾难转化为谐波支持问题。

Conclusion: 这为基于相空间变分建模的QML开辟了新途径。

Abstract: Quantum machine learning (QML) seeks to exploit the intrinsic properties of
quantum mechanical systems, including superposition, coherence, and quantum
entanglement for classical data processing. However, due to the exponential
growth of the Hilbert space, QML faces practical limits in classical
simulations with the state-vector representation of quantum system. On the
other hand, phase-space methods offer an alternative by encoding quantum states
as quasi-probability functions. Building on prior work in qubit phase-space and
the Stratonovich-Weyl (SW) correspondence, we construct a closed, composable
dynamical formalism for one- and many-qubit systems in phase-space. This
formalism replaces the operator algebra of the Pauli group with function
dynamics on symplectic manifolds, and recasts the curse of dimensionality in
terms of harmonic support on a domain that scales linearly with the number of
qubits. It opens a new route for QML based on variational modelling over
phase-space.

</details>


### [305] [BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search](https://arxiv.org/abs/2507.12189)
*Azhar Ikhtiarudin,Aditi Das,Param Thakkar,Akash Kundu*

Main category: quant-ph

TL;DR: BenchRL-QAS是一个统一的基准测试框架，用于评估量子架构搜索中的强化学习算法，涵盖多种任务和系统规模。研究发现RL算法性能高度依赖任务背景，无单一最优算法。


<details>
  <summary>Details</summary>
Motivation: 为量子架构搜索中的强化学习算法提供系统评估框架，促进公平比较和算法选择。

Method: 在2至8量子比特的多种任务中，对9种RL算法进行基准测试，并提出加权排名指标。

Result: RL量子分类器优于基线变分分类器，但算法性能因任务、量子比特数和噪声而异。

Conclusion: RL量子电路设计需根据任务定制算法选择，BenchRL-QAS框架支持未来研究。

Abstract: We introduce BenchRL-QAS, a unified benchmarking framework for systematically
evaluating reinforcement learning (RL) algorithms in quantum architecture
search (QAS) across diverse variational quantum algorithm tasks and system
sizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including
both value-based and policy-gradient methods on representative quantum problems
such as variational quantum eigensolver, variational quantum state
diagonalization, quantum classification, and state preparation, spanning both
noiseless and realistic noisy regimes. We propose a weighted ranking metric
that balances accuracy, circuit depth, gate count, and computational
efficiency, enabling fair and comprehensive comparison. Our results first
reveal that RL-based quantum classifier outperforms baseline variational
classifiers. Then we conclude that no single RL algorithm is universally
optimal when considering a set of QAS tasks; algorithmic performance is highly
context-dependent, varying with task structure, qubit count, and noise. This
empirical finding provides strong evidence for the "no free lunch" principle in
RL-based quantum circuit design and highlights the necessity of tailored
algorithm selection and systematic benchmarking for advancing quantum circuit
synthesis. This work represents the most comprehensive RL-QAS benchmarking
effort to date, and BenchRL-QAS along with all experimental data are made
publicly available to support reproducibility and future research
https://github.com/azhar-ikhtiarudin/bench-rlqas.

</details>


### [306] [Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator](https://arxiv.org/abs/2507.12256)
*Monica Lăcătuş,Matthias Möller*

Main category: quant-ph

TL;DR: 论文提出了一种量子替代电路（SQC）框架，用于近似D2Q9格子上的BGK碰撞算子，解决了量子计算中非线性碰撞步骤的实现难题。


<details>
  <summary>Details</summary>
Motivation: 高雷诺数湍流模拟对传统CFD工具具有挑战性，量子计算可能提供速度优势，但非线性碰撞步骤的实现仍是一个难题。

Method: 通过训练一个四量子比特电路（SQC）来近似BGK碰撞算子，确保其满足物理性质（如质量和动量守恒）。

Result: SQC在IBM Heron处理器上仅需2,430个原生门，无需辅助量子比特或后选择，且深度与网格分辨率无关。

Conclusion: SQC在基准流测试中表现良好，准确捕捉了涡流耗散和流动再循环，为量子CFD提供了可行方案。

Abstract: Direct numerical simulation of turbulent flows at high Reynolds numbers
remains a major challenge for traditional computational fluid dynamics (CFD)
tools running on classical computer hardware. This has motivated growing
interest in quantum algorithms for CFD to enable flow simulations on quantum
computers. The reason being that these computers are expected to deliver
potential speed-ups for certain problems. One promising quantum CFD approach is
a fully quantum implementation of the lattice Boltzmann method called QLBM.
Although efficient quantum routines are now available for the streaming step,
implementing the nonlinear, irreversible collision step with a low depth
circuit that avoids additional ancilla qubits, probabilistic post-selection and
repeated executions remains a significant challenge. In this study, we address
this challenge by introducing a framework for learning a surrogate quantum
circuit (SQC) that approximates the full Bhatnagar Gross Krook (BGK) collision
operator for the D2Q9 lattice. The four qubit circuit is trained to respect the
physical properties of the BGK collision operator, including mass and momentum
conservation, D8 equivariance and scale equivariance. When compiled to the gate
set used by IBM Heron processor under the assumption of full qubit
connectivity, the 15 block SQC requires only 2,430 native gates and uses
neither ancilla qubits nor post-selection or repeated executions. Moreover, its
depth is independent of the grid resolution, as collision is a local operation
that can exploit quantum parallelism to its full extent. We validate the SQC on
two benchmark flows, the Taylor Green vortex decay and the lid driven cavity,
demonstrating that it accurately captures vortex dissipation and flow
recirculation.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [307] [Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length](https://arxiv.org/abs/2507.12442)
*Saptarshi Mitra,Rachid Karami,Haocheng Xu,Sitao Huang,Hyoukjun Kwon*

Main category: cs.AR

TL;DR: 论文比较了Transformer、SSM和混合模型在长上下文推理任务中的性能，发现SSM在长序列处理上优于Transformer，并提出硬件优化的方向。


<details>
  <summary>Details</summary>
Motivation: 由于传统Transformer在处理长上下文输入时存在二次复杂度和内存需求问题，需要研究更高效的架构（如SSM和混合模型）在实际硬件上的性能表现。

Method: 通过系统性的基准测试，比较了Transformer、SSM和混合模型在消费级和嵌入式GPU上的长上下文推理性能，并进行了算子级分析。

Result: SSM在长序列处理上表现更优，能处理220K tokens（比Transformer长4倍），且在长上下文（~57K tokens）下速度提升4倍。

Conclusion: SSM在长上下文任务中具有显著优势，未来硬件加速应重点关注定制化SSM内核。

Abstract: The demand for machine intelligence capable of processing continuous,
long-context inputs on local devices is growing rapidly. However, the quadratic
complexity and memory requirements of traditional Transformer architectures
make them inefficient and often unusable for these tasks. This has spurred a
paradigm shift towards new architectures like State Space Models (SSMs) and
hybrids, which promise near-linear scaling. While most current research focuses
on the accuracy and theoretical throughput of these models, a systematic
performance characterization on practical consumer hardware is critically
needed to guide system-level optimization and unlock new applications.
  To address this gap, we present a comprehensive, comparative benchmarking of
carefully selected Transformer, SSM, and hybrid models specifically for
long-context inference on consumer and embedded GPUs. Our analysis reveals that
SSMs are not only viable but superior for this domain, capable of processing
sequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than
comparable Transformers. While Transformers may be up to 1.8x faster at short
sequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x
faster at very long contexts (~57K tokens). Our operator-level analysis reveals
that custom, hardware-aware SSM kernels dominate the inference runtime,
accounting for over 55% of latency on edge platforms, identifying them as a
primary target for future hardware acceleration. We also provide detailed,
device-specific characterization results to guide system co-design for the
edge. To foster further research, we will open-source our characterization
framework.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [308] [JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs](https://arxiv.org/abs/2507.11636)
*Junyi Fan,Donald Williamson*

Main category: eess.AS

TL;DR: JSQA是一个两阶段框架，通过感知引导的对比学习预训练音频编码器，再微调用于MOS预测，显著提升语音质量评估性能。


<details>
  <summary>Details</summary>
Motivation: 语音质量评估（SQA）中，MOS标签的高方差和缺乏感知因素的融入导致模型性能不佳。

Method: JSQA框架首先生成JND级别的音频对，预训练编码器以利用感知相似性信息，再微调用于MOS预测。

Result: 实验表明，感知引导的预训练显著提升了模型性能。

Conclusion: 将感知因素融入预训练对SQA性能提升至关重要。

Abstract: Speech quality assessment (SQA) is often used to learn a mapping from a
high-dimensional input space to a scalar that represents the mean opinion score
(MOS) of the perceptual speech quality. Learning such a mapping is challenging
for many reasons, but largely because MOS exhibits high levels of inherent
variance due to perceptual and experimental-design differences. Many solutions
have been proposed, but many approaches do not properly incorporate perceptual
factors into their learning algorithms (beyond the MOS label), which could lead
to unsatisfactory results. To this end, we propose JSQA, a two-stage framework
that pretrains an audio encoder using perceptually-guided contrastive learning
on just noticeable difference (JND) pairs, followed by fine-tuning for MOS
prediction. We first generate pairs of audio data within JND levels, which are
then used to pretrain an encoder to leverage perceptual quality similarity
information and map it into an embedding space. The JND pairs come from clean
LibriSpeech utterances that are mixed with background noise from CHiME-3, at
different signal-to-noise ratios (SNRs). The encoder is later fine-tuned with
audio samples from the NISQA dataset for MOS prediction. Experimental results
suggest that perceptually-inspired contrastive pretraining significantly
improves the model performance evaluated by various metrics when compared
against the same network trained from scratch without pretraining. These
findings suggest that incorporating perceptual factors into pretraining greatly
contributes to the improvement in performance for SQA.

</details>


<div id='astro-ph.GA'></div>

# astro-ph.GA [[Back]](#toc)

### [309] [Galaxy image simplification using Generative AI](https://arxiv.org/abs/2507.11692)
*Sai Teja Erukude,Lior Shamir*

Main category: astro-ph.GA

TL;DR: 论文提出了一种基于生成式AI的新方法，用于简化星系图像并自动将其转换为骨架化形式，以实现更准确的形状测量和分析。


<details>
  <summary>Details</summary>
Motivation: 现代数字巡天项目拍摄了数十亿个星系的图像，但高精度分析这些海量图像需要有效的自动化方法。现有方法通常依赖于基于预定义类别的机器学习标注，限制了分析的灵活性。

Method: 采用生成式AI技术，将星系图像简化为骨架化形式，从而支持更准确的形状测量，且不受限于预定义的类别。

Result: 该方法成功应用于12.5万张DESI Legacy Survey图像，生成的简化图像目录已公开。

Conclusion: 新方法通过简化星系图像，提供了一种更灵活且准确的星系形状分析工具，代码和数据均已公开。

Abstract: Modern digital sky surveys have been acquiring images of billions of
galaxies. While these images often provide sufficient details to analyze the
shape of the galaxies, accurate analysis of such high volumes of images
requires effective automation. Current solutions often rely on machine learning
annotation of the galaxy images based on a set of pre-defined classes. Here we
introduce a new approach to galaxy image analysis that is based on generative
AI. The method simplifies the galaxy images and automatically converts them
into a ``skeletonized" form. The simplified images allow accurate measurements
of the galaxy shapes and analysis that is not limited to a certain pre-defined
set of classes. We demonstrate the method by applying it to galaxy images
acquired by the DESI Legacy Survey. The code and data are publicly available.
The method was applied to 125,000 DESI Legacy Survey images, and the catalog of
the simplified images is publicly available.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [310] [Neural Polar Decoders for Deletion Channels](https://arxiv.org/abs/2507.12329)
*Ziv Aharoni,Henry D. Pfister*

Main category: cs.IT

TL;DR: 论文提出了一种用于删除信道的神经极化解码器（NPD），显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有极化解码器在删除信道中计算复杂度高（$O(N^4)$），限制了其应用范围。

Method: 扩展NPD架构，仅修改其中一个神经网络以支持删除信道，复杂度降至$O(AN\log N)$。

Result: 在删除率$\delta\in\{0.01, 0.1\}$下验证了NPD性能，并展示了列表解码的改进效果。

Conclusion: NPD有望应用于DNA存储等未来技术。

Abstract: This paper introduces a neural polar decoder (NPD) for deletion channels with
a constant deletion rate. Existing polar decoders for deletion channels exhibit
high computational complexity of $O(N^4)$, where $N$ is the block length. This
limits the application of polar codes for deletion channels to
short-to-moderate block lengths. In this work, we demonstrate that employing
NPDs for deletion channels can reduce the computational complexity. First, we
extend the architecture of the NPD to support deletion channels. Specifically,
the NPD architecture consists of four neural networks (NNs), each replicating
fundamental successive cancellation (SC) decoder operations. To support
deletion channels, we change the architecture of only one. The computational
complexity of the NPD is $O(AN\log N)$, where the parameter $A$ represents a
computational budget determined by the user and is independent of the channel.
We evaluate the new extended NPD for deletion channels with deletion rates
$\delta\in\{0.01, 0.1\}$ and we verify the NPD with the ground truth given by
the trellis decoder by Tal et al. We further show that due to the reduced
complexity of the NPD, we are able to incorporate list decoding and further
improve performance. We believe that the extended NPD presented here could have
applications in future technologies like DNA storage.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [311] [Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI](https://arxiv.org/abs/2507.12417)
*Weichen Dai,Yuxuan Huang,Li Zhu,Dongjun Liu,Yu Zhang,Qibin Zhao,Andrzej Cichocki,Fabio Babiloni,Ke Li,Jianyu Qiu,Gangyong Jia,Wanzeng Kong,Qing Wu*

Main category: q-bio.NC

TL;DR: EEG-based BCIs解码了被动观看视频时的6D空间姿态，揭示了大脑在被动条件下仍能自发构建空间表征。


<details>
  <summary>Details</summary>
Motivation: 探索自然被动体验下大规模神经动态如何支持空间表征，填补现有研究空白。

Method: 使用非侵入性脑机接口（EEG）解码被试在观看自我中心视频时的自发6D姿态（位置和方向）。

Result: EEG信号可解码空间表征，且视觉输入连贯性和帧率（100ms/帧）显著提升解码性能。

Conclusion: 大脑空间系统在被动条件下仍持续运作，挑战了主动与被动空间认知的传统区分。

Abstract: Humans possess a remarkable capacity for spatial cognition, allowing for
self-localization even in novel or unfamiliar environments. While hippocampal
neurons encoding position and orientation are well documented, the large-scale
neural dynamics supporting spatial representation, particularly during
naturalistic, passive experience, remain poorly understood. Here, we
demonstrate for the first time that non-invasive brain-computer interfaces
(BCIs) based on electroencephalography (EEG) can decode spontaneous,
fine-grained egocentric 6D pose, comprising three-dimensional position and
orientation, during passive viewing of egocentric video. Despite EEG's limited
spatial resolution and high signal noise, we find that spatially coherent
visual input (i.e., continuous and structured motion) reliably evokes decodable
spatial representations, aligning with participants' subjective sense of
spatial engagement. Decoding performance further improves when visual input is
presented at a frame rate of 100 ms per image, suggesting alignment with
intrinsic neural temporal dynamics. Using gradient-based backpropagation
through a neural decoding model, we identify distinct EEG channels contributing
to position -- and orientation specific -- components, revealing a distributed
yet complementary neural encoding scheme. These findings indicate that the
brain's spatial systems operate spontaneously and continuously, even under
passive conditions, challenging traditional distinctions between active and
passive spatial cognition. Our results offer a non-invasive window into the
automatic construction of egocentric spatial maps and advance our understanding
of how the human mind transforms everyday sensory experience into structured
internal representations.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [312] [Unveiling the Visual Rhetoric of Persuasive Cartography: A Case Study of the Design of Octopus Maps](https://arxiv.org/abs/2507.11903)
*Daocheng Lin,Yifan Wang,Yutong Yang,Xingyu Lan*

Main category: cs.HC

TL;DR: 论文探讨了数据可视化如何通过修辞构造成为强大的说服工具，以章鱼地图为例分析了其跨世纪的社会影响和修辞策略。


<details>
  <summary>Details</summary>
Motivation: 研究填补了当前可视化研究中修辞构造视角的不足，探讨了章鱼地图作为说服性可视化的持久影响力。

Method: 采用修辞图式理论，收集并分析了90个从19世纪至今的章鱼地图，构建了设计空间以揭示视觉隐喻和修辞策略。

Result: 发现章鱼地图在现代仍具活力，且不同文化背景下对章鱼的象征意义存在动态变化。

Conclusion: 研究揭示了说服性可视化的修辞机制，并讨论了其伦理问题。

Abstract: When designed deliberately, data visualizations can become powerful
persuasive tools, influencing viewers' opinions, values, and actions. While
researchers have begun studying this issue (e.g., to evaluate the effects of
persuasive visualization), we argue that a fundamental mechanism of persuasion
resides in rhetorical construction, a perspective inadequately addressed in
current visualization research. To fill this gap, we present a focused analysis
of octopus maps, a visual genre that has maintained persuasive power across
centuries and achieved significant social impact. Employing rhetorical schema
theory, we collected and analyzed 90 octopus maps spanning from the 19th
century to contemporary times. We closely examined how octopus maps implement
their persuasive intents and constructed a design space that reveals how visual
metaphors are strategically constructed and what common rhetorical strategies
are applied to components such as maps, octopus imagery, and text. Through the
above analysis, we also uncover a set of interesting findings. For instance,
contrary to the common perception that octopus maps are primarily a historical
phenomenon, our research shows that they remain a lively design convention in
today's digital age. Additionally, while most octopus maps stem from Western
discourse that views the octopus as an evil symbol, some designs offer
alternative interpretations, highlighting the dynamic nature of rhetoric across
different sociocultural settings. Lastly, drawing from the lessons provided by
octopus maps, we discuss the associated ethical concerns of persuasive
visualization.

</details>


### [313] [Interactive Hybrid Rice Breeding with Parametric Dual Projection](https://arxiv.org/abs/2507.11848)
*Changjian Chen,Pengcheng Wang,Fei Lyu,Zhuo Tang,Li Yang,Long Wang,Yong Cai,Feng Yu,Kenli Li*

Main category: cs.HC

TL;DR: 本文提出了一种可视化分析方法，通过参数化双投影方法支持交互式杂交水稻育种，帮助识别调控基因和选择杂交品种。


<details>
  <summary>Details</summary>
Motivation: 基因组预测模型精度有限，育种者仍需结合经验筛选杂交品种，过程耗时。本文旨在简化这一过程。

Method: 开发了参数化双投影方法，支持交互式双分析，并进一步开发了基因和杂交品种的可视化工具。

Result: 通过案例研究验证了方法的有效性，包括定量评估和育种者的积极反馈。

Conclusion: 该方法为杂交水稻育种提供了高效的可视化支持，简化了调控基因识别和杂交品种选择过程。

Abstract: Hybrid rice breeding crossbreeds different rice lines and cultivates the
resulting hybrids in fields to select those with desirable agronomic traits,
such as higher yields. Recently, genomic selection has emerged as an efficient
way for hybrid rice breeding. It predicts the traits of hybrids based on their
genes, which helps exclude many undesired hybrids, largely reducing the
workload of field cultivation. However, due to the limited accuracy of genomic
prediction models, breeders still need to combine their experience with the
models to identify regulatory genes that control traits and select hybrids,
which remains a time-consuming process. To ease this process, in this paper, we
proposed a visual analysis method to facilitate interactive hybrid rice
breeding. Regulatory gene identification and hybrid selection naturally
ensemble a dual-analysis task. Therefore, we developed a parametric dual
projection method with theoretical guarantees to facilitate interactive dual
analysis. Based on this dual projection method, we further developed a gene
visualization and a hybrid visualization to verify the identified regulatory
genes and hybrids. The effectiveness of our method is demonstrated through the
quantitative evaluation of the parametric dual projection method, identified
regulatory genes and desired hybrids in the case study, and positive feedback
from breeders.

</details>


### [314] [AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding](https://arxiv.org/abs/2507.11911)
*Xiaoqing Chen,Siyang Li,Dongrui Wu*

Main category: cs.HC

TL;DR: 提出了一种无需校准的跨数据集EEG解码框架AFPM，通过空间对齐和帧-块编码提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决EEG解码模型在跨数据集学习和泛化中的问题，如通道布局不一致、信号分布非平稳和神经生理学先验整合不足。

Method: AFPM框架包括空间对齐（选择任务相关通道并统一布局）和帧-块编码（将信号建模为统一时空块）。

Result: 在运动想象和事件相关电位任务上分别提升4.40%和3.58%，优于17种现有方法。

Conclusion: AFPM是首个无需校准的跨数据集EEG解码框架，显著提升了BCI的实际应用性。

Abstract: Electroencephalogram (EEG) decoding models for brain-computer interfaces
(BCIs) struggle with cross-dataset learning and generalization due to channel
layout inconsistencies, non-stationary signal distributions, and limited
neurophysiological prior integration. To address these issues, we propose a
plug-and-play Alignment-Based Frame-Patch Modeling (AFPM) framework, which has
two main components: 1) Spatial Alignment, which selects task-relevant channels
based on brain-region priors, aligns EEG distributions across domains, and
remaps the selected channels to a unified layout; and, 2) Frame-Patch Encoding,
which models multi-dataset signals into unified spatiotemporal patches for EEG
decoding. Compared to 17 state-of-the-art approaches that need dataset-specific
tuning, the proposed calibration-free AFPM achieves performance gains of up to
4.40% on motor imagery and 3.58% on event-related potential tasks. To our
knowledge, this is the first calibration-free cross-dataset EEG decoding
framework, substantially enhancing the practicalness of BCIs in real-world
applications.

</details>


### [315] [Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness](https://arxiv.org/abs/2507.12212)
*Garyoung Kim,Huisung Kwon,Seoju Yun,Yu-Won Youn*

Main category: cs.HC

TL;DR: 生成式AI不仅复制人类创造力，还再现了根深蒂固的文化偏见。本研究探讨了四种AI模型如何理解和表达“丑陋”，揭示了其中嵌入的偏见，包括对老年白人男性的过度关联。


<details>
  <summary>Details</summary>
Motivation: 批判性分析生成式AI如何理解和表达“丑陋”，以揭示其内在的文化和社会偏见。

Method: 通过迭代提示大型语言模型提取13个与“丑陋”相关的形容词，并在四种AI模型中生成624张图像，对图像中的人口和社会经济属性进行独立编码和主题分析。

Result: AI模型倾向于将“丑陋”与老年白人男性关联，反映了社会偏见和矛盾偏见（为避免边缘群体刻板印象而过度投射负面属性到主流群体）。

Conclusion: 尽管尝试创造更平等的表征，生成式AI仍延续了固有和矛盾的偏见，凸显了开发伦理AI训练范式和包容性方法的重要性。

Abstract: Generative AI does not only replicate human creativity but also reproduces
deep-seated cultural biases, making it crucial to critically examine how
concepts like ugliness are understood and expressed by these tools. This study
investigates how four different generative AI models understand and express
ugliness through text and image and explores the biases embedded within these
representations. We extracted 13 adjectives associated with ugliness through
iterative prompting of a large language model and generated 624 images across
four AI models and three prompts. Demographic and socioeconomic attributes
within the images were independently coded and thematically analyzed. Our
findings show that AI models disproportionately associate ugliness with old
white male figures, reflecting entrenched social biases as well as paradoxical
biases, where efforts to avoid stereotypical depictions of marginalized groups
inadvertently result in the disproportionate projection of negative attributes
onto majority groups. Qualitative analysis further reveals that, despite
supposed attempts to frame ugliness within social contexts, conventional
physical markers such as asymmetry and aging persist as central visual motifs.
These findings demonstrate that despite attempts to create more equal
representations, generative AI continues to perpetuate inherited and
paradoxical biases, underscoring the critical work being done to create ethical
AI training paradigms and advance methodologies for more inclusive AI
development.

</details>


### [316] [d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement](https://arxiv.org/abs/2507.11960)
*Hyein Hong,Sangbong Yoo,SeokHwan Choi,Jisue Kim,Seongbum Seo,Haneol Cho,Chansoo Kim,Yun Jang*

Main category: cs.HC

TL;DR: 论文提出了一种名为d-DQIVAR的可视化分析系统，结合数据驱动和流程驱动方法，旨在提升数据质量（DQ）并优化机器学习模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注数据预处理而非真正的数据质量改进（DQI），且传统批处理数据预处理方法在优化机器学习模型性能时效果有限。

Method: 系统整合了数据驱动（如缺失值填补、异常检测）和流程驱动（如DQ评估、Kolmogorov-Smirnov检验）技术，通过可视化分析支持用户决策。

Result: 通过案例研究、评估和用户研究，验证了系统在结合专家知识和领域知识提升DQI及模型性能方面的有效性。

Conclusion: d-DQIVAR系统为数据质量改进提供了实用工具，结合了数据与流程驱动方法的优势，显著提升了机器学习模型性能。

Abstract: Approaches to enhancing data quality (DQ) are classified into two main
categories: data- and process-driven. However, prior research has predominantly
utilized batch data preprocessing within the data-driven framework, which often
proves insufficient for optimizing machine learning (ML) model performance and
frequently leads to distortions in data characteristics. Existing studies have
primarily focused on data preprocessing rather than genuine data quality
improvement (DQI). In this paper, we introduce d-DQIVAR, a novel visual
analytics system designed to facilitate DQI strategies aimed at improving ML
model performance. Our system integrates visual analytics techniques that
leverage both data-driven and process-driven approaches. Data-driven techniques
tackle DQ issues such as imputation, outlier detection, deletion, format
standardization, removal of duplicate records, and feature selection.
Process-driven strategies encompass evaluating DQ and DQI procedures by
considering DQ dimensions and ML model performance and applying the
Kolmogorov-Smirnov test. We illustrate how our system empowers users to harness
expert and domain knowledge effectively within a practical workflow through
case studies, evaluations, and user studies.

</details>


### [317] [Dataset-Adaptive Dimensionality Reduction](https://arxiv.org/abs/2507.11984)
*Hyeon Jeon,Jeongin Park,Soohyun Lee,Dae Hyun Kim,Sungbok Shin,Jinwook Seo*

Main category: cs.HC

TL;DR: 提出了一种基于结构复杂性度量的数据集自适应降维优化方法，减少试错计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统降维技术选择和超参数优化依赖大量试错，计算成本高。

Method: 利用结构复杂性度量量化数据集内在复杂性，预测降维技术的最大可实现精度。

Result: 验证了度量能有效近似数据集真实复杂性，提升降维优化效率且不损失精度。

Conclusion: 数据集自适应工作流显著优化降维效率，避免冗余计算。

Abstract: Selecting the appropriate dimensionality reduction (DR) technique and
determining its optimal hyperparameter settings that maximize the accuracy of
the output projections typically involves extensive trial and error, often
resulting in unnecessary computational overhead. To address this challenge, we
propose a dataset-adaptive approach to DR optimization guided by structural
complexity metrics. These metrics quantify the intrinsic complexity of a
dataset, predicting whether higher-dimensional spaces are necessary to
represent it accurately. Since complex datasets are often inaccurately
represented in two-dimensional projections, leveraging these metrics enables us
to predict the maximum achievable accuracy of DR techniques for a given
dataset, eliminating redundant trials in optimizing DR. We introduce the design
and theoretical foundations of these structural complexity metrics. We
quantitatively verify that our metrics effectively approximate the ground truth
complexity of datasets and confirm their suitability for guiding
dataset-adaptive DR workflow. Finally, we empirically show that our
dataset-adaptive workflow significantly enhances the efficiency of DR
optimization without compromising accuracy.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [318] [The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist](https://arxiv.org/abs/2507.11810)
*Haoxuan Zhang,Ruochi Li,Yang Zhang,Ting Xiao,Jiangping Chen,Junhua Ding,Haihua Chen*

Main category: cs.DL

TL;DR: 该论文探讨了大型语言模型（LLMs）在科学创新中的范式转变作用，提出了一个分层框架（评估者、合作者、科学家）来分类LLMs的角色，并分析了其能力边界、评估标准和人机交互模式。


<details>
  <summary>Details</summary>
Motivation: 科学面临信息过载、学科孤岛和传统研究方法收益递减等挑战，LLMs被视为能够增强科学工作流并引领创新的强大工具。

Method: 通过分析现有方法、基准、系统和评估指标，提出一个分层框架，区分LLMs在结构化科研过程和开放式科学发现中的贡献。

Result: 论文系统性地总结了LLM驱动的科学创新，强调LLMs不仅是自动化工具，还能重塑科学的认识论基础。

Conclusion: 该调查为未来研究提供了概念清晰性、实践指导和理论基础，同时指出了自主AI驱动科学中的开放挑战和伦理问题。

Abstract: Scientific innovation is undergoing a paradigm shift driven by the rapid
advancement of Large Language Models (LLMs). As science faces mounting
challenges including information overload, disciplinary silos, and diminishing
returns on conventional research methods, LLMs are emerging as powerful agents
capable not only of enhancing scientific workflows but also of participating in
and potentially leading the innovation process. Existing surveys mainly focus
on different perspectives, phrases, and tasks in scientific research and
discovery, while they have limitations in understanding the transformative
potential and role differentiation of LLM. This survey proposes a comprehensive
framework to categorize the evolving roles of LLMs in scientific innovation
across three hierarchical levels: Evaluator, Collaborator, and Scientist. We
distinguish between LLMs' contributions to structured scientific research
processes and open-ended scientific discovery, thereby offering a unified
taxonomy that clarifies capability boundaries, evaluation criteria, and
human-AI interaction patterns at each level. Through an extensive analysis of
current methodologies, benchmarks, systems, and evaluation metrics, this survey
delivers an in-depth and systematic synthesis on LLM-driven scientific
innovation. We present LLMs not only as tools for automating existing
processes, but also as catalysts capable of reshaping the epistemological
foundations of science itself. This survey offers conceptual clarity, practical
guidance, and theoretical foundations for future research, while also
highlighting open challenges and ethical considerations in the pursuit of
increasingly autonomous AI-driven science. Resources related to this survey can
be accessed on GitHub at: https://github.com/haoxuan-unt2024/llm4innovation.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [319] [A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy](https://arxiv.org/abs/2507.11853)
*J. Senthilnath,Jayasanker Jayabalan,Zhuoyi Lin,Aye Phyu Phyu Aung,Chen Hao,Kaixin Xu,Yeow Kheng Lim,F. C. Wellstood*

Main category: physics.ins-det

TL;DR: 提出了一种空间物理信息模型（SPIM），用于改进半导体先进封装中的非破坏性测试（NDT），通过磁图像增强、对齐和反演方法，显著提升了测试精度。


<details>
  <summary>Details</summary>
Motivation: 由于半导体先进封装层深度和复杂性增加，传统基于FFT的磁反演方法未考虑涡流效应和图像错位问题，亟需改进。

Method: SPIM包含三个关键部分：磁图像增强（利用I/Q通道图像对齐锐利信号）、磁图像对齐（纠正扫描错位）、以及结合毕奥-萨伐尔定律与FFT的磁场反演方法。

Result: SPIM将I通道锐度提升0.3%，Q通道锐度降低25%，并成功消除实际图像中0.30的旋转和错位偏差。

Conclusion: SPIM展示了空间分析与物理驱动模型结合在实际应用中的潜力，为半导体封装NDT提供了更精确的解决方案。

Abstract: The development of advanced packaging is essential in the semiconductor
manufacturing industry. However, non-destructive testing (NDT) of advanced
packaging becomes increasingly challenging due to the depth and complexity of
the layers involved. In such a scenario, Magnetic field imaging (MFI) enables
the imaging of magnetic fields generated by currents. For MFI to be effective
in NDT, the magnetic fields must be converted into current density. This
conversion has typically relied solely on a Fast Fourier Transform (FFT) for
magnetic field inversion; however, the existing approach does not consider eddy
current effects or image misalignment in the test setup. In this paper, we
present a spatial-physics informed model (SPIM) designed for a 3D spiral sample
scanned using Superconducting QUantum Interference Device (SQUID) microscopy.
The SPIM encompasses three key components: i) magnetic image enhancement by
aligning all the "sharp" wire field signals to mitigate the eddy current effect
using both in-phase (I-channel) and quadrature-phase (Q-channel) images; (ii)
magnetic image alignment that addresses skew effects caused by any misalignment
of the scanning SQUID microscope relative to the wire segments; and (iii) an
inversion method for converting magnetic fields to magnetic currents by
integrating the Biot-Savart Law with FFT. The results show that the SPIM
improves I-channel sharpness by 0.3% and reduces Q-channel sharpness by 25%.
Also, we were able to remove rotational and skew misalignments of 0.30 in a
real image. Overall, SPIM highlights the potential of combining spatial
analysis with physics-driven models in practical applications.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [320] [MOFSimBench: Evaluating Universal Machine Learning Interatomic Potentials In Metal--Organic Framework Molecular Modeling](https://arxiv.org/abs/2507.11806)
*Hendrik Kraß,Ju Huang,Seyed Mohamad Moosavi*

Main category: cond-mat.mtrl-sci

TL;DR: MOFSimBench评估了通用机器学习原子间势（uMLIPs）在纳米多孔材料建模中的表现，发现其优于传统力场和微调机器学习势，数据质量对性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 评估uMLIPs在实际应用中的可靠性，特别是在纳米多孔材料建模中的表现，解决其多样化学和结构复杂性带来的挑战。

Method: 引入MOFSimBench基准，评估uMLIPs在结构优化、分子动力学稳定性、体性质预测和主客体相互作用等任务中的表现。

Result: 表现最佳的uMLIPs在所有任务中均优于传统力场和微调机器学习势，数据质量（训练集多样性和非平衡构象的包含）对性能影响显著。

Conclusion: uMLIPs已准备好用于纳米多孔材料建模，MOFSimBench为未来研究和开发提供了开放资源。

Abstract: Universal machine learning interatomic potentials (uMLIPs) have emerged as
powerful tools for accelerating atomistic simulations, offering scalable and
efficient modeling with accuracy close to quantum calculations. However, their
reliability and effectiveness in practical, real-world applications remain an
open question. Metal-organic frameworks (MOFs) and related nanoporous materials
are highly porous crystals with critical relevance in carbon capture, energy
storage, and catalysis applications. Modeling nanoporous materials presents
distinct challenges for uMLIPs due to their diverse chemistry, structural
complexity, including porosity and coordination bonds, and the absence from
existing training datasets. Here, we introduce MOFSimBench, a benchmark to
evaluate uMLIPs on key materials modeling tasks for nanoporous materials,
including structural optimization, molecular dynamics (MD) stability, the
prediction of bulk properties, such as bulk modulus and heat capacity, and
guest-host interactions. Evaluating over 20 models from various architectures
on a chemically and structurally diverse materials set, we find that
top-performing uMLIPs consistently outperform classical force fields and
fine-tuned machine learning potentials across all tasks, demonstrating their
readiness for deployment in nanoporous materials modeling. Our analysis
highlights that data quality, particularly the diversity of training sets and
inclusion of out-of-equilibrium conformations, plays a more critical role than
model architecture in determining performance across all evaluated uMLIPs. We
release our modular and extendable benchmarking framework at
https://github.com/AI4ChemS/mofsim-bench, providing an open resource to guide
the adoption for nanoporous materials modeling and further development of
uMLIPs.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [321] [Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview](https://arxiv.org/abs/2507.11935)
*Jikang Deng,Fizza Hassan,Hui Zhou,Saad Al-Ahmadi,Mohamed-Slim Alouini,Daniel B. Da Costa*

Main category: cs.NI

TL;DR: 本文探讨了如何将ORAN与NTN结合以解决6G网络中的挑战，提出了基于ORAN的NTN框架，并讨论了其架构、功能及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 6G网络的发展需要高效、可靠且灵活的架构，但NTN的高空移动性缺乏原生AI能力，阻碍了智能网络管理。ORAN的开放性、虚拟化和智能化为解决这些问题提供了可能。

Method: 提出基于ORAN的NTN框架，包括灵活的前传分割、增强的RAN智能控制器、可扩展部署架构和多域服务管理。

Result: 框架展示了如何通过ORAN的智能特性解决NTN的可扩展性和管理挑战。

Conclusion: ORAN与NTN的结合为6G网络提供了潜力，未来研究可进一步探索与其他技术的结合及实际用例。

Abstract: As the path toward 6G networks is being charted, the emerging applications
have motivated evolutions of network architectures to realize the efficient,
reliable, and flexible wireless networks. Among the potential architectures,
the non-terrestrial network (NTN) and open radio access network (ORAN) have
received increasing interest from both academia and industry. Although the
deployment of NTNs ensures coverage, enhances spectral efficiency, and improves
the resilience of wireless networks. The high altitude and mobility of NTN
present new challenges in the development and operations (DevOps) lifecycle,
hindering intelligent and scalable network management due to the lack of native
artificial intelligence (AI) capability. With the advantages of ORAN in
disaggregation, openness, virtualization, and intelligence, several works
propose integrating ORAN principles into the NTN, focusing mainly on ORAN
deployment options based on transparent and regenerative systems. However, a
holistic view of how to effectively combine ORAN and NTN throughout the DevOps
lifecycle is still missing, especially regarding how intelligent ORAN addresses
the scalability challenges in NTN. Motivated by this, in this paper, we first
provide the background knowledge about ORAN and NTN, outline the
state-of-the-art research on ORAN for NTNs, and present the DevOps challenges
that motivate the adoption of ORAN solutions. We then propose the ORAN-based
NTN framework, discussing its features and architectures in detail. These
include the discussion about flexible fronthaul split, RAN intelligent
controllers (RICs) enhancement for distributed learning, scalable deployment
architecture, and multi-domain service management. Finally, the future research
directions, including combinations of the ORAN-based NTN framework and other
enabling technologies and schemes, as well as the candidate use cases, are
highlighted.

</details>


### [322] [LLM-Based Config Synthesis requires Disambiguation](https://arxiv.org/abs/2507.12443)
*Rajdeep Mondal,Nikolaj Bjorner,Todd Millstein,Alan Tang,George Varghese*

Main category: cs.NI

TL;DR: 论文探讨了LLM在程序合成中的用户意图模糊问题，提出了一种原型系统Clarify，通过Disambiguator模块解决模糊性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在合成网络配置（如路由映射和ACL）时因用户意图模糊导致的问题。

Method: 提出Clarify系统，结合LLM和Disambiguator模块，逐步合成并验证路由策略。

Result: 在小型合成工作负载上，Clarify成功解决了模糊性问题并合成了路由策略。

Conclusion: Clarify的方法对解决LLM合成中的模糊性问题具有普适意义。

Abstract: Beyond hallucinations, another problem in program synthesis using LLMs is
ambiguity in user intent. We illustrate the ambiguity problem in a networking
context for LLM-based incremental configuration synthesis of route-maps and
ACLs. These structures frequently overlap in header space, making the relative
priority of actions impossible for the LLM to infer without user interaction.
Measurements in a large cloud identify complex ACLs with 100's of overlaps,
showing ambiguity is a real problem. We propose a prototype system, Clarify,
which uses an LLM augmented with a new module called a Disambiguator that helps
elicit user intent. On a small synthetic workload, Clarify incrementally
synthesizes routing policies after disambiguation and then verifies them. Our
treatment of ambiguities is useful more generally when the intent of updates
can be correctly synthesized by LLMs, but their integration is ambiguous and
can lead to different global behaviors.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [323] [A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment](https://arxiv.org/abs/2507.11543)
*Iman Reihanian,Yunfei Hou,Yu Chen,Yifei Zheng*

Main category: cs.CY

TL;DR: 综述了生成式AI工具（如ChatGPT和Claude）在计算机科学教育中的应用，探讨了准确性、真实性和评估等关键问题，并提出了挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在教育中的潜力与问题，以促进其合理应用。

Method: 通过文献综述，分析生成式AI工具的优缺点及其对教育的影响。

Result: 生成式AI提高效率并支持创意，但也带来幻觉、错误传播、偏见等问题，需结合人类监督。

Conclusion: 成功整合AI需平衡伦理、教学和技术因素，未来研究可关注准确性提升和学术诚信保护。

Abstract: This paper surveys the use of Generative AI tools, such as ChatGPT and
Claude, in computer science education, focusing on key aspects of accuracy,
authenticity, and assessment. Through a literature review, we highlight both
the challenges and opportunities these AI tools present. While Generative AI
improves efficiency and supports creative student work, it raises concerns such
as AI hallucinations, error propagation, bias, and blurred lines between
AI-assisted and student-authored content. Human oversight is crucial for
addressing these concerns. Existing literature recommends adopting hybrid
assessment models that combine AI with human evaluation, developing bias
detection frameworks, and promoting AI literacy for both students and
educators. Our findings suggest that the successful integration of AI requires
a balanced approach, considering ethical, pedagogical, and technical factors.
Future research may explore enhancing AI accuracy, preserving academic
integrity, and developing adaptive models that balance creativity with
precision.

</details>


### [324] [Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening](https://arxiv.org/abs/2507.11548)
*Kevin T Webster*

Main category: cs.CY

TL;DR: 研究发现生成式AI在简历筛选中存在种族和性别偏见，且部分模型仅依赖关键词匹配而非实质性评估，提出了“中立假象”概念，建议采用双重验证框架。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在简历筛选中是否真正具备评估能力，而非仅是无偏见的替代方案。

Method: 通过两部分实验审计八个主要AI平台，分别测试偏见和核心能力。

Result: 实验1发现复杂偏见，实验2揭示部分模型仅依赖关键词匹配，无法实质性评估。

Conclusion: 提出“中立假象”概念，建议双重验证框架以确保AI工具公平有效。

Abstract: The increasing use of generative AI for resume screening is predicated on the
assumption that it offers an unbiased alternative to biased human
decision-making. However, this belief fails to address a critical question: are
these AI systems fundamentally competent at the evaluative tasks they are meant
to perform? This study investigates the question of competence through a
two-part audit of eight major AI platforms. Experiment 1 confirmed complex,
contextual racial and gender biases, with some models penalizing candidates
merely for the presence of demographic signals. Experiment 2, which evaluated
core competence, provided a critical insight: some models that appeared
unbiased were, in fact, incapable of performing a substantive evaluation,
relying instead on superficial keyword matching. This paper introduces the
"Illusion of Neutrality" to describe this phenomenon, where an apparent lack of
bias is merely a symptom of a model's inability to make meaningful judgments.
This study recommends that organizations and regulators adopt a dual-validation
framework, auditing AI hiring tools for both demographic bias and demonstrable
competence to ensure they are both equitable and effective.

</details>


### [325] [AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce](https://arxiv.org/abs/2507.11597)
*Richard Timpone,Yongwei Yang*

Main category: cs.CY

TL;DR: AI在研究中具有潜力，但也存在风险，需强调人机协作与数据科学家的关键作用。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在数据分析与研究中的潜力与局限，强调伦理与有效性。

Method: 基于Truth, Beauty, Justice (TBJ)框架，评估AI在数据科学中的应用。

Result: AI可辅助分析，但全自动化可能带来风险，需人机协作。

Conclusion: 提倡AI工具与数据科学家互补，同时加强方法培训以确保研究的实质价值。

Abstract: AI is transforming research. It is being leveraged to construct surveys,
synthesize data, conduct analysis, and write summaries of the results. While
the promise is to create efficiencies and increase quality, the reality is not
always as clear cut. Leveraging our framework of Truth, Beauty, and Justice
(TBJ) which we use to evaluate AI, machine learning and computational models
for effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024),
we consider the potential and limitation of analytic, generative, and agentic
AI to augment data scientists or take on tasks traditionally done by human
analysts and researchers. While AI can be leveraged to assist analysts in their
tasks, we raise some warnings about push-button automation. Just as earlier
eras of survey analysis created some issues when the increased ease of using
statistical software allowed researchers to conduct analyses they did not fully
understand, the new AI tools may create similar but larger risks. We emphasize
a human-machine collaboration perspective (Daugherty and Wilson 2018)
throughout the data science workflow and particularly call out the vital role
that data scientists play under VUCA decision areas. We conclude by encouraging
the advance of AI tools to complement data scientists but advocate for
continued training and understanding of methods to ensure the substantive value
of research is fully achieved by applying, interpreting, and acting upon
results most effectively and ethically.

</details>


### [326] [Small Data Explainer -- The impact of small data methods in everyday life](https://arxiv.org/abs/2507.11773)
*Maren Hackenberg,Sophia G. Connor,Fabian Kabus,June Brawner,Ella Markham,Mahi Hardalupas,Areeq Chowdhury,Rolf Backofen,Anna Köttgen,Angelika Rohde,Nadine Binder,Harald Binder,the Collaborative Research Center 1597 Small Data*

Main category: cs.CY

TL;DR: 论文探讨了小数据环境下人工智能的应用，对比了大数据与小数据的差异，并提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究小数据环境下AI技术的潜力，以解决社会问题（如数据驱动决策中的代表性不足）和健康辅助技术（如可穿戴设备）的益处。

Method: 通过概念性概述和案例研究，对比小数据与大数据，分析当前数据分析和建模技术，结合统计学和计算机科学的方法。

Result: 总结了小数据应用的可行性，并提出了未来充分利用小数据的议程。

Conclusion: 小数据在AI领域具有重要潜力，需结合多学科方法进一步探索和应用。

Abstract: The emergence of breakthrough artificial intelligence (AI) techniques has led
to a renewed focus on how small data settings, i.e., settings with limited
information, can benefit from such developments. This includes societal issues
such as how best to include under-represented groups in data-driven policy and
decision making, or the health benefits of assistive technologies such as
wearables. We provide a conceptual overview, in particular contrasting small
data with big data, and identify common themes from exemplary case studies and
application areas. Potential solutions are described in a more detailed
technical overview of current data analysis and modelling techniques,
highlighting contributions from different disciplines, such as knowledge-driven
modelling from statistics and data-driven modelling from computer science. By
linking application settings, conceptual contributions and specific techniques,
we highlight what is already feasible and suggest what an agenda for fully
leveraging small data might look like.

</details>


### [327] [The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models](https://arxiv.org/abs/2507.11544)
*Ann-Kathrin Dombrowski,Dillon Bowen,Adam Gleave,Chris Cundy*

Main category: cs.CY

TL;DR: 开源大型语言模型（LLM）的可修改性带来了创新和风险，研究团队开发了工具包评估安全差距，发现模型规模越大，安全差距越显著。


<details>
  <summary>Details</summary>
Motivation: 研究开源LLM的可修改性带来的系统性风险，尤其是安全措施被移除后的潜在危害。

Method: 开源了一个工具包，评估不同规模的开源模型（如Llama-3和Qwen-2.5）在移除安全措施后的生化、网络能力、拒绝率和生成质量。

Result: 模型规模越大，安全差距越显著，移除安全措施后危险能力显著增强。

Conclusion: 工具包可作为开源模型的评估框架，并推动开发抗篡改的安全措施。

Abstract: Open-weight large language models (LLMs) unlock huge benefits in innovation,
personalization, privacy, and democratization. However, their core advantage -
modifiability - opens the door to systemic risks: bad actors can trivially
subvert current safeguards, turning beneficial models into tools for harm. This
leads to a 'safety gap': the difference in dangerous capabilities between a
model with intact safeguards and one that has been stripped of those
safeguards. We open-source a toolkit to estimate the safety gap for
state-of-the-art open-weight models. As a case study, we evaluate biochemical
and cyber capabilities, refusal rates, and generation quality of models from
two families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to
405B) using different safeguard removal techniques. Our experiments reveal that
the safety gap widens as model scale increases and effective dangerous
capabilities grow substantially when safeguards are removed. We hope that the
Safety Gap Toolkit (https://github.com/AlignmentResearch/safety-gap) will serve
as an evaluation framework for common open-source models and as a motivation
for developing and testing tamper-resistant safeguards. We welcome
contributions to the toolkit from the community.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [328] [SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics](https://arxiv.org/abs/2507.11588)
*Suyuan Zhao,Yizhen Luo,Ganbo Yang,Yan Zhong,Hao Zhou,Zaiqing Nie*

Main category: q-bio.GN

TL;DR: SToFM是一种多尺度空间转录组学基础模型，通过提取宏、微和基因尺度信息，结合SE(2) Transformer生成高质量细胞表示，并在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学（ST）技术提供了丰富的单细胞生物学信息，但建模ST数据具有挑战性，需要整合多尺度信息。

Method: SToFM首先对每个ST切片进行多尺度信息提取，构建包含宏、微和基因尺度信息的子切片，然后使用SE(2) Transformer生成细胞表示。

Result: SToFM在组织区域语义分割和细胞类型注释等下游任务中表现优异。

Conclusion: SToFM通过多尺度建模和预训练，显著提升了对ST数据的理解能力。

Abstract: Spatial Transcriptomics (ST) technologies provide biologists with rich
insights into single-cell biology by preserving spatial context of cells.
Building foundational models for ST can significantly enhance the analysis of
vast and complex data sources, unlocking new perspectives on the intricacies of
biological tissues. However, modeling ST data is inherently challenging due to
the need to extract multi-scale information from tissue slices containing vast
numbers of cells. This process requires integrating macro-scale tissue
morphology, micro-scale cellular microenvironment, and gene-scale gene
expression profile. To address this challenge, we propose SToFM, a multi-scale
Spatial Transcriptomics Foundation Model. SToFM first performs multi-scale
information extraction on each ST slice, to construct a set of ST sub-slices
that aggregate macro-, micro- and gene-scale information. Then an SE(2)
Transformer is used to obtain high-quality cell representations from the
sub-slices. Additionally, we construct \textbf{SToCorpus-88M}, the largest
high-resolution spatial transcriptomics corpus for pretraining. SToFM achieves
outstanding performance on a variety of downstream tasks, such as tissue region
semantic segmentation and cell type annotation, demonstrating its comprehensive
understanding of ST data

</details>


### [329] [RNAMunin: A Deep Machine Learning Model for Non-coding RNA Discovery](https://arxiv.org/abs/2507.11950)
*Lauren Lui,Torben Nielsen*

Main category: q-bio.GN

TL;DR: RNAMunin是一个基于机器学习的模型，仅通过基因组序列即可识别非编码RNA（ncRNA），适用于大规模数据集，无需转录组数据。


<details>
  <summary>Details</summary>
Motivation: 微生物基因组的功能注释通常偏向于蛋白质编码基因，而忽略了ncRNA的重要调控作用。直接通过基因组序列识别ncRNA是生物信息学和生物学的重要挑战。

Method: RNAMunin是一个小型且快速的机器学习模型，基于Rfam序列训练，适用于长读长宏基因组组装数据。

Result: RNAMunin能够在大规模基因组序列中高效检测ncRNA，无需依赖转录组数据。

Conclusion: RNAMunin填补了当前机器学习模型在ncRNA识别领域的空白，为微生物基因组研究提供了新工具。

Abstract: Functional annotation of microbial genomes is often biased toward
protein-coding genes, leaving a vast, unexplored landscape of non-coding RNAs
(ncRNAs) that are critical for regulating bacterial and archaeal physiology,
stress response and metabolism. Identifying ncRNAs directly from genomic
sequence is a paramount challenge in bioinformatics and biology, essential for
understanding the complete regulatory potential of an organism. This paper
presents RNAMunin, a machine learning (ML) model that is capable of finding
ncRNAs using genomic sequence alone. It is also computationally viable for
large sequence datasets such as long read metagenomic assemblies with contigs
totaling multiple Gbp. RNAMunin is trained on Rfam sequences extracted from
approximately 60 Gbp of long read metagenomes from 16 San Francisco Estuary
samples. We know of no other model that can detect ncRNAs based solely on
genomic sequence at this scale. Since RNAMunin only requires genomic sequence
as input, we do not need for an ncRNA to be transcribed to find it, i.e., we do
not need transcriptomics data. We wrote this manuscript in a narrative style in
order to best convey how RNAMunin was developed and how it works in detail.
Unlike almost all current ML models, at approximately 1M parameters, RNAMunin
is very small and very fast.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [330] [MOSPA: Human Motion Generation Driven by Spatial Audio](https://arxiv.org/abs/2507.11949)
*Shuyang Xu,Zhiyang Dou,Mingyi Shi,Liang Pan,Leo Ho,Jingbo Wang,Yuan Liu,Cheng Lin,Yuexin Ma,Wenping Wang,Taku Komura*

Main category: cs.GR

TL;DR: 论文提出了一种基于空间音频驱动的人体运动生成方法（MOSPA），并发布了首个全面的空间音频驱动人体运动数据集（SAM），填补了现有研究在空间音频对运动影响上的空白。


<details>
  <summary>Details</summary>
Motivation: 虚拟人类如何动态且真实地对多样化的听觉刺激做出反应是角色动画中的关键挑战，但现有研究多关注语音、音频和音乐等模态的运动生成，忽略了空间音频信号的空间特征对人体运动的影响。

Method: 提出了一个简单而有效的基于扩散的生成框架（MOSPA），通过有效的融合机制捕捉身体运动与空间音频之间的关系，并发布了高质量的空间音频和运动数据集（SAM）用于基准测试。

Result: MOSPA能够根据不同的空间音频输入生成多样且真实的人体运动，实验表明该方法在该任务上达到了最先进的性能。

Conclusion: 论文填补了空间音频驱动人体运动研究的空白，提出的模型和数据集将为未来研究提供重要支持，并将开源发布。

Abstract: Enabling virtual humans to dynamically and realistically respond to diverse
auditory stimuli remains a key challenge in character animation, demanding the
integration of perceptual modeling and motion synthesis. Despite its
significance, this task remains largely unexplored. Most previous works have
primarily focused on mapping modalities like speech, audio, and music to
generate human motion. As of yet, these models typically overlook the impact of
spatial features encoded in spatial audio signals on human motion. To bridge
this gap and enable high-quality modeling of human movements in response to
spatial audio, we introduce the first comprehensive Spatial Audio-Driven Human
Motion (SAM) dataset, which contains diverse and high-quality spatial audio and
motion data. For benchmarking, we develop a simple yet effective
diffusion-based generative framework for human MOtion generation driven by
SPatial Audio, termed MOSPA, which faithfully captures the relationship between
body motion and spatial audio through an effective fusion mechanism. Once
trained, MOSPA could generate diverse realistic human motions conditioned on
varying spatial audio inputs. We perform a thorough investigation of the
proposed dataset and conduct extensive experiments for benchmarking, where our
method achieves state-of-the-art performance on this task. Our model and
dataset will be open-sourced upon acceptance. Please refer to our supplementary
video for more details.

</details>


### [331] [HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing](https://arxiv.org/abs/2507.11971)
*Tielong Wang,Yuxuan Xiong,Jinfan Liu,Zhifan Zhang,Ye Chen,Yue Shi,Bingbing Ni*

Main category: cs.GR

TL;DR: 提出了一种新型的3D分层代理节点表示方法，解决了现有3D表示在通用性、编辑性和复杂性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D表示（如网格、体素、点云和NeRF）存在任务专用性强、编辑复杂、渲染与结构模糊等问题，缺乏通用性。

Method: 通过稀疏的分层组织（树状结构）代理节点表示物体形状和纹理，每个节点存储局部信息，并通过轻量级MLP解码实现高效查询。

Result: 实验表明，该方法在3D重建和编辑中表现出高效表达、高保真渲染质量和卓越的可编辑性。

Conclusion: 分层代理节点表示提供了一种紧凑、通用且易于编辑的3D表示方案。

Abstract: Current 3D representations like meshes, voxels, point clouds, and NeRF-based
neural implicit fields exhibit significant limitations: they are often
task-specific, lacking universal applicability across reconstruction,
generation, editing, and driving. While meshes offer high precision, their
dense vertex data complicates editing; NeRFs deliver excellent rendering but
suffer from structural ambiguity, hindering animation and manipulation; all
representations inherently struggle with the trade-off between data complexity
and fidelity. To overcome these issues, we introduce a novel 3D Hierarchical
Proxy Node representation. Its core innovation lies in representing an object's
shape and texture via a sparse set of hierarchically organized
(tree-structured) proxy nodes distributed on its surface and interior. Each
node stores local shape and texture information (implicitly encoded by a small
MLP) within its neighborhood. Querying any 3D coordinate's properties involves
efficient neural interpolation and lightweight decoding from relevant nearby
and parent nodes. This framework yields a highly compact representation where
nodes align with local semantics, enabling direct drag-and-edit manipulation,
and offers scalable quality-complexity control. Extensive experiments across 3D
reconstruction and editing demonstrate our method's expressive efficiency,
high-fidelity rendering quality, and superior editability.

</details>
