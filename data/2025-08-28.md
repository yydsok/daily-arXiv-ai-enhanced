<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.CV](#cs.CV) [Total: 89]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.SD](#cs.SD) [Total: 6]
- [quant-ph](#quant-ph) [Total: 2]
- [econ.GN](#econ.GN) [Total: 1]
- [physics.optics](#physics.optics) [Total: 3]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.HC](#cs.HC) [Total: 7]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [eess.SP](#eess.SP) [Total: 5]
- [math.OC](#math.OC) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [eess.IV](#eess.IV) [Total: 5]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [nucl-th](#nucl-th) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.CR](#cs.CR) [Total: 20]
- [cs.GT](#cs.GT) [Total: 1]
- [stat.ML](#stat.ML) [Total: 3]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CY](#cs.CY) [Total: 6]
- [eess.AS](#eess.AS) [Total: 1]
- [math.CO](#math.CO) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 该论文将LLM中的奉承行为建模为心理测量特征的几何和因果组合，使用对比激活加法来映射激活方向，并提出可解释的向量干预方法来缓解安全关键行为。


<details>
  <summary>Details</summary>
Motivation: 奉承行为是LLM中的关键行为风险，但通常被当作孤立故障模式处理。作者认为应该将其建模为心理测量特征的组合，以获得更好的解释性和干预能力。

Method: 使用对比激活加法(CAA)将激活方向映射到情感性、开放性和宜人性等心理测量因素，研究不同组合如何导致奉承行为。

Result: 提出了将奉承行为分解为心理测量因素组合的几何和因果模型，建立了可解释的向量干预方法。

Conclusion: 这种基于向量的可组合干预方法（如加法、减法和投影）可用于缓解LLM中的安全关键行为，为理解和管理模型行为提供了新视角。

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [2] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: Aleks是一个AI驱动的多智能体系统，能够自主进行植物科学数据驱动的科学发现，无需人工干预即可迭代制定问题、探索建模策略并优化解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代植物科学越来越依赖大型异构数据集，但实验设计、数据预处理和可重复性方面的挑战阻碍了研究效率。

Method: 开发了Aleks多智能体系统，整合领域知识、数据分析和机器学习，在结构化框架内自主进行科学发现。系统接收研究问题和数据集后，通过多轮迭代自主制定问题、探索替代建模策略并优化解决方案。

Result: 在葡萄藤红斑病案例研究中，Aleks逐步识别出具有生物学意义的特征，并收敛到具有稳健性能的可解释模型。消融研究强调了领域知识和记忆对连贯结果的重要性。

Conclusion: 这项探索性工作凸显了智能体AI作为自主协作工具在加速植物科学发现方面的潜力。

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [3] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 量化技术虽然能保持LLMs在困惑度和零样本任务上的性能，但其对模型真实性（生成真实或欺骗性回答）的影响尚未充分研究。研究发现量化模型内部保持真实表征，但在误导性提示下更容易产生虚假输出。


<details>
  <summary>Details</summary>
Motivation: 量化技术能显著降低大语言模型的内存和计算成本，但量化对模型真实性（truthfulness）的影响尚未得到充分探索，需要系统评估量化模型在不同维度上的真实性表现。

Method: 提出TruthfulnessEval评估框架，从逻辑推理、常识和模仿性虚假三个维度评估量化模型的真实性。测试主流量化技术（4-bit到2-bit），使用15种重新表述的提示变体（诚实、中性、欺骗性），并通过层级探测和PCA可视化分析模型内部表征。

Result: 量化模型内部保持真实表征，但在欺骗性提示下更容易产生虚假输出。欺骗性提示可以覆盖真实一致的行为，而诚实和中性提示能保持稳定输出。量化模型内部"知道"真相，但仍会在欺骗性提示引导下产生虚假输出。

Conclusion: 研究揭示了量化模型在真实性方面的脆弱性，为未来量化感知对齐和真实性干预的设计提供了重要见解。

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [4] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 本文提出了监控系统红队测试(MRT)工作流，用于检测自主LLM代理的隐蔽不当行为，发现在监控可靠性方面：代理意识比监控意识更重要，监控架构比监控信息更重要，针对性人工监督最有效。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM代理监控系统对抗性鲁棒性的系统性测试，需要建立标准化的红队测试工作流来评估监控系统检测隐蔽不当行为的能力。

Method: 提出了MRT工作流，包含不同级别的代理和监控情境意识、多种对抗策略（如提示注入），在两个数据集(SHADE-Arena和CUA-SHADE-Arena)上测试现有监控架构和新提出的混合分层-顺序架构。

Result: 1) 代理意识主导监控可靠性；2) 混合监控架构优于基线，可实现弱模型监控强代理的弱到强扩展效应；3) 针对性人工监督在FPR=0.01时将TPR提高约15%。

Conclusion: 建立了MRT标准工作流，揭示了LLM和人类在监控代理不当行为时缺乏对抗鲁棒性，发布了代码、数据和日志以促进进一步研究。

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [5] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 该研究提出了一个"5+2"框架来识别和消除大语言模型推理轨迹中的次优子轨迹，通过选择性数据采样提高模型性能，在数学推理任务上取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在复杂推理时生成扩展的推理轨迹，但研究发现并非所有轨迹组成部分都对推理过程有积极贡献，有些甚至会影响整体性能，因此需要识别和消除这些次优子轨迹。

Method: 开发了"5+2"框架：1）基于5个人工制定的标准系统识别推理轨迹中的次优子轨迹；2）评估这些次优子轨迹的独立性，确保消除后不影响推理流程的连贯性。使用基于该框架的采样算法选择无次优子轨迹的数据进行训练。

Result: 方法在推理过程中减少了25.9%的次优子轨迹，仅使用三分之二训练数据就在高难度数学基准测试上达到58.92%的平均准确率，优于使用全部数据时的58.06%，且在各种推理token限制下都表现出性能提升。

Conclusion: 该研究证明了识别和消除推理轨迹中次优成分的重要性，提出的"5+2"框架和采样算法能有效提升大语言模型的推理性能，特别是在资源受限的情况下仍能保持良好表现。

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [6] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: 研究表明，通过在LLM内部激活上应用线性探针，可以高精度检测模型生成的欺骗性回答，准确率最高超过90%，且欺骗性特征在模型中间层表现最明显。


<details>
  <summary>Details</summary>
Motivation: 开发类似汽车"检查引擎"灯的AI系统仪表盘，通过检测LLM生成的欺骗性回答来指示AI系统与人类价值观的错位。

Method: 使用线性探针分析LLM内部激活，通过迭代零空间投影方法识别编码欺骗性的线性方向，在不同参数规模的模型上进行实验。

Result: 线性探针在区分欺骗性和非欺骗性回答方面达到90%以上准确率，较大模型（>7B）表现更好，欺骗性特征在中间层最明显，不同模型存在20-100个编码欺骗性的线性方向。

Conclusion: 线性探针是检测LLM欺骗性回答的有效工具，为开发AI系统对齐监测仪表盘提供了可行方法，模型规模和层级结构对欺骗性检测有重要影响。

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [7] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: AI代理社会模拟实验，通过制度设计（宪法AI宪章和调解审议协议）有效减少权力寻租行为，提升政策稳定性和公民福利


<details>
  <summary>Details</summary>
Motivation: 探索在AI时代人类的意义，研究如何通过制度设计来对齐未来AI代理社会的复杂涌现行为

Method: 基于代理的模拟实验，让具有复杂心理特征的AI代理在不同制度框架下进行自治，包括审议、立法和选举等活动

Result: 宪法AI宪章和调解审议协议的组合显著减少了腐败的权力寻求行为，提高了政策稳定性，增强了公民福利

Conclusion: 制度设计可以作为有效的对齐机制，为未来人工代理社会的复杂行为提供框架，需要重新思考人类在AI时代的角色和责任

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [8] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 提出基于深度学习的课程概念提取模型，通过技能解释增强课程推荐系统的效果，提高用户兴趣和决策信心


<details>
  <summary>Details</summary>
Motivation: 美国本科教育中学生选课自由度高但信息有限，现有推荐系统缺乏对学生认知和课程相关性的深入理解，需要改进推荐过程

Method: 开发深度学习概念提取模型从课程描述中提取相关概念，在AskOski系统中测试基于技能的意外推荐框架解释效果

Result: 技能解释显著提高用户兴趣（特别是高意外性课程），增强决策信心

Conclusion: 教育推荐系统应整合技能相关数据和解释机制以改善用户体验

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [9] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ReST-RL是一个统一的LLM强化学习范式，通过改进的GRPO算法和基于价值模型的测试时解码方法，显著提升LLM的代码推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法因奖励方差不足而失败，基于过程奖励模型(PRM)的验证方法存在训练数据获取困难和验证效果不佳的问题。

Method: 采用两阶段方法：1) ReST-GRPO阶段使用优化的ReST算法筛选高价值训练数据；2) VM-MCTS阶段通过蒙特卡洛树搜索收集价值目标训练VM，并在解码时提供精确的过程信号和验证分数。

Result: 在多个编程基准测试(APPS、BigCodeBench、HumanEval)上显著优于其他强化训练基线和解码验证基线。

Conclusion: ReST-RL能够有效增强LLM策略的推理能力，为LLM强化学习提供了统一的解决方案。

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [10] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: Instructional Agents是一个多智能体LLM框架，用于自动化生成完整的课程材料，包括教学大纲、讲义脚本、LaTeX幻灯片和评估内容，通过模拟教育角色协作显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 高质量教学材料的准备过程劳动密集，需要教师、教学设计师和助教之间的广泛协调，现有AI教育工具只关注孤立任务，缺乏整体协作。

Method: 采用多智能体大语言模型框架，模拟基于角色的教育智能体协作，提供四种操作模式：自主模式、目录引导模式、反馈引导模式和完全协同模式，支持不同程度的人工参与。

Result: 在五门大学计算机科学课程中评估显示，该系统能生成高质量教学材料，同时显著减少开发时间和人工工作量。

Conclusion: Instructional Agents为教学设计能力有限的机构提供了可扩展且经济高效的框架，有助于在资源受限环境中普及高质量教育。

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [11] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: SWIRL是一个用于多智能体系统的分阶段强化学习框架，通过将多智能体强化学习分解为单智能体任务序列，实现稳定训练和高效协调，在移动GUI控制和数学推理任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有单智能体方法存在结构限制，而多智能体强化学习效率低下且与当前大视觉语言模型架构不兼容，需要新的多智能体训练框架

Method: SWIRL采用分阶段交错强化学习，将MARL重新表述为单智能体强化学习任务序列，每次只更新一个智能体而保持其他智能体固定

Result: 在移动GUI控制的高层和低层基准测试中表现出优越性能，同时在多智能体数学推理任务中也展现出强大能力

Conclusion: SWIRL作为一个通用框架，具有开发高效鲁棒多智能体系统的潜力，提供了理论保证和实际应用验证

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [12] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 提出了InquireBench基准测试和InquireMobile系统，通过主动询问用户确认来提高移动代理的安全性，在询问成功率上提升46.8%


<details>
  <summary>Details</summary>
Motivation: 当前完全自主的视觉语言模型移动代理存在安全风险，当模型理解或推理能力不足时可能造成危险，需要开发能够主动寻求用户确认的交互系统

Method: 提出InquireMobile模型，采用强化学习启发的两阶段训练策略和交互式预动作推理机制，在关键决策点主动寻求人类确认

Result: 在InquireBench基准测试中实现了46.8%的询问成功率提升，并在整体成功率上达到现有基线中的最佳表现

Conclusion: 主动询问机制能显著提高移动代理的安全性，InquireMobile系统为解决VLM代理的安全交互问题提供了有效方案，相关资源将开源以促进学术和工业界发展

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [13] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: 研究表明Chain-of-Thought（CoT）在软推理任务中效果有限且可能不忠实于模型的实际推理过程，不同模型对CoT的依赖方式存在差异


<details>
  <summary>Details</summary>
Motivation: 探索CoT在软推理任务（如分析推理和常识推理）中的动态性和忠实性，以及在不同类型模型中的表现差异

Method: 在指令微调模型、推理模型和推理蒸馏模型上研究CoT在软推理任务中的使用情况，分析其影响和忠实性

Result: 发现CoT的影响力和忠实性并不总是对齐，不同模型对CoT的依赖方式存在显著差异

Conclusion: CoT在软推理任务中的应用需要谨慎，其效果和忠实性因模型类型而异，不能一概而论

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [14] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: 这篇论文提出了一种与模型无关的评估框架，通过象棋测试LLM是否能维持结构化环境的语义保真度，发现LLM在长序列状态跟踪中存在限制


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在结构化领域显示出出色能力，但现有探针技术依赖模型内部激活，限制了可解释性和通用性，需要更好的评估方法

Method: 提出基于状态的评估框架，通过分析象棋法律走法分布（状态可执行性）来估计预测状态与实际状态的语义保真度

Result: 实验结果显示，该指标能够抓取到LLM在状态跟踪中的缺陷，显示了LLM在维持长序内部模型一致性方面的限制

Conclusion: 该框架提供了一种不需要模型内部访问的健壮工具，用于评估LLM的结构化推理能力，并能够通用于广泛的符号环境

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [15] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: CASE是一个基于AI的对话代理框架，通过主动访谈潜在诈骗受害者收集详细对话信息，利用LLM提取结构化数据，在Google Pay印度实现了诈骗执法量21%的提升。


<details>
  <summary>Details</summary>
Motivation: 数字支付平台的普及带来了便利，但也吸引了恶意行为者，导致复杂的社会工程诈骗增加。现有用户和交易信号不足以全面理解诈骗模式，难以及时预防。

Method: 开发CASE对话代理框架，使用Gemini LLM主动访谈潜在受害者，收集详细对话记录，通过AI系统提取信息并转换为结构化数据，用于自动和人工执法机制。

Result: 在Google Pay印度实施后，诈骗执法量提升了21%，架构和评估框架具有高度通用性。

Conclusion: CASE框架为收集和管理诈骗情报提供了可扩展的解决方案，可推广到其他敏感领域构建类似AI驱动系统。

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [16] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 使用仿生群集算法（boids算法）解决半导体制造中机器类型切换的调度优化问题，替代传统线性优化方法


<details>
  <summary>Details</summary>
Motivation: 半导体工厂等大型生产设施的作业车间调度是NP难问题，传统线性优化方法无法在合理时间内求解。特别是生产过程中需要在单件处理机器和批量处理机器之间频繁切换，带来额外复杂度

Method: 采用源自机器人和电影工业的"boids"群集算法，这是一种基于局部信息和简单启发式规则的仿生算法，模拟鸟群对障碍物的反应机制来处理机器类型切换

Result: 该算法能够有效应对生产设备优化中的机器类型切换问题，其反应机制类似于生物群集对行进路线中障碍物的自然反应

Conclusion: 群集智能算法为大规模生产设施优化提供了可行的分布式解决方案，特别适用于需要处理不同类型机器切换的复杂生产环境

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [17] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 本文提出了从数据科学向模型科学范式转变的概念框架，强调以训练好的模型为核心进行分析，包含验证、解释、控制和接口四大支柱。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的广泛应用，需要从以数据为中心转向以模型为中心的分析方法，以更好地理解、验证和控制模型行为。

Method: 提出了模型科学的概念框架，包括四个关键支柱：验证（严格的情境感知评估协议）、解释（探索模型内部操作的各种方法）、控制（整合对齐技术来引导模型行为）和接口（开发交互式可视化解释工具）。

Result: 建立了一个系统性的模型科学框架，为可信、安全和人类对齐的AI系统开发提供指导。

Conclusion: 模型科学代表了AI发展的新范式，通过系统化的验证、解释、控制和交互接口，能够促进更可信和可控的AI系统发展。

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 提出MultiPL-MoE方法，通过混合专家模型提升LLMs的多编程语言代码生成能力，在保持主流语言性能的同时提升多语言表现


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在代码生成方面表现出色，但多编程语言代码生成仍然极具挑战性，需要在有限计算资源下提升多语言性能

Method: 采用混合专家模型(MoE)方法，结合token级和segment级两个配对MoE。token级使用标准upcycling MoE结构，segment级采用滑动窗口分割输入序列和专家选择路由策略

Result: 实验证明了MultiPL-MoE方法的有效性

Conclusion: 提出的MultiPL-MoE方法成功提升了LLMs在多编程语言代码生成方面的性能

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [19] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 提出了一种新的双语语音识别方法，通过构建双语音素集和利用PhoWhisper预训练编码器，有效解决了越南语和英语混合语音识别中的音素对齐挑战


<details>
  <summary>Details</summary>
Motivation: 解决越南语和英语混合语音识别中的跨语言音素识别挑战，特别是越南语依赖声调变化而英语依赖重音模式的差异

Method: 构建代表性的双语音素集来桥接两种语言的语音系统差异，并设计端到端系统利用PhoWhisper预训练编码器获取深层高级表示

Result: 实验表明该方法不仅提高了越南语双语语音识别的准确性，还为处理声调和重音音素识别的复杂性提供了稳健框架

Conclusion: 所提出的方法成功解决了越南语-英语双语语音识别中的音素对齐问题，为跨语言语音识别提供了有效的解决方案

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [20] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 本文扩展了RetoMaton框架，用本地加权有限自动机(WFA)替代全局数据存储，在三个推理任务上验证了其优于基础模型和提示方法的性能，提供了更可靠、可解释的检索机制。


<details>
  <summary>Details</summary>
Motivation: 现有的提示推理方法(如CoT和ICL)依赖脆弱的隐式机制，输出不稳定且不可靠，需要更结构化、可信赖的替代方案来实现稳定可解释的推理。

Method: 将RetoMaton的全局数据存储替换为从外部领域语料库直接构建的本地加权有限自动机(WFA)，利用WFA的显式结构提供可验证的模块化检索行为。

Result: 在LLaMA-3.2-1B和Gemma-3-1B-PT模型上，在TriviaQA、GSM8K和MMLU三个推理任务中，本地RetoMaton变体相比基础模型和提示方法持续提升性能，同时实现透明可复现的检索动态。

Conclusion: 通过轻量级的自动机引导内存，为现代大语言模型提供了向可信赖符号推理转变的有前景方向，实现了更好的领域迁移和互操作性。

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [21] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: RAGAPHENE是一个基于聊天的标注平台，用于模拟真实世界对话来评估大语言模型在检索增强生成任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型在提供事实性信息时可能出现幻觉问题，需要构建能够评估多轮RAG对话的基准测试，而模拟真实对话对于产生高质量评估基准至关重要。

Method: 开发了RAGAPHENE聊天标注平台，让标注者能够模拟真实世界对话，用于构建和评估大语言模型的基准测试。

Result: 该平台已被约40名标注者成功使用，构建了数千个真实世界对话样本。

Conclusion: RAGAPHENE平台为评估大语言模型在RAG任务中的表现提供了有效的工具和方法。

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [22] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 本研究证明在口头尸检中，使用预训练语言模型分析叙述文本比仅使用结构化问题能更准确地进行死因分类，特别是对非传染性疾病。多模态融合方法进一步提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 在没有民事登记和生命统计系统的国家，口头尸检是估计死因的关键工具。现有自动化分类算法仅使用结构化问题而忽略了叙述文本中的信息，需要探索如何利用叙述文本来改进死因分类。

Method: 使用预训练语言模型和机器学习技术分析口头尸检中的叙述文本，探索多种多模态融合策略结合叙述和问题，并评估医生感知的信息充分性对分类准确性的影响。

Result: 仅使用叙述文本时，基于Transformer的预训练模型在个体和群体层面都优于仅使用问题的算法，特别是在识别非传染性疾病方面。多模态方法进一步提升了死因分类性能。

Conclusion: 叙述文本在死因分类中具有重要价值，需要更多高质量多样化数据来训练模型，这些发现为重新思考和重新设计口头尸检工具和访谈提供了宝贵见解。

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [23] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: Memory-R1是一个强化学习框架，通过两个专门代理为LLM提供主动管理外部记忆的能力，在少量训练数据下就能超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能力强大但本质上是无状态的，受限于有限的上下文窗口，阻碍了长程推理能力。现有方法多为静态启发式，缺乏学习机制来决定存储、更新或检索什么内容。

Method: 使用强化学习框架（PPO和GRPO），包含两个专门代理：记忆管理器学习执行结构化记忆操作（ADD、UPDATE、DELETE、NOOP），答案代理选择最相关条目并进行推理生成答案。

Result: 仅用152个问答对和对应的时间记忆库进行训练，Memory-R1就超越了最具竞争力的现有基线，在不同问题类型和LLM骨干网络上表现出强大的泛化能力。

Conclusion: 这项工作不仅提出了有效方法，还揭示了RL如何解锁LLM中更具代理性、记忆感知的行为，指向更丰富、更持久的推理系统。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [24] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: FLAIRR-TS是一个测试时提示优化框架，通过代理系统自动优化LLM的时间序列预测提示，无需手动工程或微调


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每个任务精心设计自然语言提示，这个过程繁琐且临时性，需要一种自动化的提示优化方法

Method: 使用代理系统：预测代理用初始提示生成预测，精炼代理根据历史输出和检索的类似样本优化提示，使用创意提示模板跨领域泛化

Result: 在基准数据集上显示比静态提示和检索增强基线更高的准确性，接近专门设计的提示性能

Conclusion: FLAIRR-TS提供了一种实用的调优替代方案，通过代理式自适应提示精炼和检索实现强大性能

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [25] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: CORE是一种基于强化学习的无损上下文压缩方法，通过端到端训练优化RAG中的文档压缩，在3%的高压缩比下不仅避免性能下降，还平均提升3.3个EM分数。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在处理大量检索文档时面临计算成本高的问题，现有压缩方法往往依赖固定启发式规则且会损害最终任务性能，缺乏明确的压缩目标保证压缩内容对最终任务的有效支持。

Method: 提出CORE方法，使用强化学习优化压缩过程，不依赖预定义的压缩标签。利用最终任务性能作为奖励信号，应用广义强化学习策略优化(GRPO)训练压缩器，实现端到端训练。

Result: 在四个数据集上的广泛实验表明，在3%的高压缩比下，该方法不仅避免了在所有数据集上相比完整文档的性能下降，还将平均精确匹配(EM)分数提高了3.3分。

Conclusion: CORE通过强化学习实现了RAG中的无损上下文压缩，显著提高了压缩效率同时保证了任务性能，为RAG系统的优化提供了有效解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [26] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: CASC框架通过智能上下文分析和合成，有效解决多文档RAG中的信息过载问题，在复杂科学问答任务中显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理多文档、长文本或冲突信息时存在信息过载和合成效率低的问题，导致答案不准确不可靠

Method: 提出CASC框架，包含基于微调小模型的Context Analyzer & Synthesizer模块，进行关键信息提取、跨文档一致性检查和冲突解决、面向问题的结构化合成

Result: 在SciDocs-QA数据集上的实验表明，CASC持续优于强基线方法，能够将原始分散信息转化为高度压缩、结构化且语义丰富的上下文

Conclusion: CASC通过智能上下文处理有效减轻了最终Reader LLM的token负担和认知负荷，提升了复杂领域问答的准确性和可靠性

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [27] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: 提出ARIS混合方法，结合自混合代理和判别式序列标注器，通过模型共识、置信度过滤和LLM反思推理来提升事件抽取性能


<details>
  <summary>Details</summary>
Motivation: 传统判别模型精度高但召回率低，生成式LLM方法语义灵活但存在幻觉和不一致问题，需要结合两者优势

Method: ARIS系统：自混合代理+判别式序列标注器，采用结构化模型共识、置信度过滤和LLM反思推理模块，并进行分解指令微调

Result: 在三个基准数据集上超越现有最先进的事件抽取方法

Conclusion: ARIS通过混合方法和反思推理有效解决了事件抽取中的精度-召回权衡问题，提升了整体预测质量

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [28] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: LongReasonArena是一个专门评估大语言模型长推理能力的新基准，通过多步算法任务测试检索和回溯等关键推理能力，推理长度可达100万token，现有模型表现较差。


<details>
  <summary>Details</summary>
Motivation: 现有的长上下文基准主要评估模型对长输入的理解能力，但忽略了长推理能力的评估，需要专门设计基准来填补这一空白。

Method: 设计需要执行多步算法推理的任务，通过控制输入来任意扩展推理长度，最高可达100万token的推理过程，测试检索和回溯等关键推理能力。

Result: 该基准对开源和专有LLM都构成重大挑战，Deepseek-R1仅达到7.5%的准确率，准确率随预期推理步骤数的对数呈线性下降趋势。

Conclusion: LongReasonArena成功填补了长推理能力评估的空白，揭示了当前LLM在长推理任务上的显著不足，为未来模型发展提供了重要基准。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [29] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 本文提出了一个针对自然语言查询的数据库实体识别方法，包括人工标注基准、基于SQL查询的数据增强技术，以及基于T5的专门实体识别模型，在精度和召回率方面优于现有NER方法。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询中数据库实体识别的挑战，利用现有的text-to-SQL基准数据来提升识别性能。

Method: 1) 从流行text-to-SQL基准创建人工标注的DB-ER基准；2) 基于SQL查询的自动标注数据增强方法；3) 使用T5作为骨干网络，通过序列标注和token分类两个下游任务进行微调的专门实体识别模型。

Result: 提出的DB-ER标注器在精度和召回率方面优于两种最先进的NER标注器。数据增强使精度和召回率提升超过10%，T5骨干网络微调使这些指标提升5-10%。

Conclusion: 该方法通过数据增强和专门模型设计，显著提升了数据库实体识别的性能，为自然语言查询处理提供了有效的解决方案。

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [30] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型在不同幽默类型间的迁移学习能力，发现模型具备一定的跨幽默类型迁移能力，最高可达75%准确率，且多样化训练数据能提升迁移性能。


<details>
  <summary>Details</summary>
Motivation: 幽默是复杂多样的交流形式，现有计算幽默研究多集中于特定类型。随着新型幽默在社交媒体中不断涌现，需要研究LLMs是否能通过捕捉深层可迁移机制来泛化到未见过的幽默类型。

Method: 通过在四个不同幽默任务数据集上进行迁移学习实验，训练LLMs在不同多样性设置下（1-3个训练数据集），测试其在全新任务上的表现。

Result: 实验显示模型具备一定迁移能力，在未见数据集上准确率最高达75%；多样化训练源可提升1.88-4.05%的迁移性能，且域内性能几乎不下降。Dad Jokes意外成为最佳迁移促进者。

Conclusion: 幽默类型间存在可迁移关系，LLMs能够通过多样化训练获得跨幽默类型的泛化能力，这为应对不断演变的幽默景观提供了可能。

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [31] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: 这篇论文讨论了AI生成工具可能导致人类写作能力退化的风险，类似古希腊黑暗时代的文字能力失传


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI工具的快速发展可能对人类写作能力产生的深远影响

Method: 通过历史类比分析（如古希腊黑暗时代），讨论AI导致人类写作能力退化的可能性

Result: 识别了人类外包写作活动给机器可能造成的长期风险

Conclusion: 需要重视AI时代下保持人类基本写作能力的重要性，避免历史重播

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [32] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: 提出了一个针对LLMs4OL 2025挑战赛的完整系统，使用检索增强提示、零样本分类和注意力图建模等方法，在术语提取、类型标注和分类发现三个任务中均取得了领先结果。


<details>
  <summary>Details</summary>
Motivation: 解决本体构建全流程的三个核心任务：术语提取、类型标注和分类发现，展示LLM架构在不同领域的可扩展性、适应性和鲁棒性。

Method: 任务A：使用检索增强生成(RAG)管道联合提取领域特定术语及其本体类型；任务B：在少样本设置下重用RAG方案，在零样本设置下使用多嵌入模型的余弦相似度加权分类器；任务C：将分类发现建模为图推理，使用类型标签嵌入训练交叉注意力层预测is-a关系。

Result: 在官方排行榜的所有三个任务中均取得了顶级排名结果。

Conclusion: 这些模块化、任务特定的解决方案展示了基于LLM的架构在跨异构领域本体学习中的可扩展性、适应性和鲁棒性。

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [33] [MovieCORE: COgnitive REasoning in Movies](https://arxiv.org/abs/2508.19026)
*Gueter Josmy Faure,Min-Hung Chen,Jia-Fong Yeh,Ying Cheng,Hung-Ting Su,Yung-Hao Tang,Shang-Hong Lai,Winston H. Hsu*

Main category: cs.CL

TL;DR: MovieCORE是一个新颖的视频问答数据集，专注于电影内容的深层认知理解，通过多智能体头脑风暴方法生成高质量问题，并提出ACE模块提升模型推理能力25%。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答数据集主要关注表层理解，缺乏对电影内容深层认知理解的评估，需要开发能够激发系统2思维的高质量数据集。

Method: 采用多智能体头脑风暴方法，利用多个大语言模型作为思考智能体生成和精炼高质量问答对；开发认知测试评估数据集质量；提出ACE模块增强视频语言模型的推理能力。

Result: 成功创建了MovieCORE数据集，包含深度认知问题；ACE模块将模型推理能力提升达25%；为评估VQA模型在深层认知任务上的性能提供了全面方案。

Conclusion: 该研究推动了AI系统对电影理解的发展，揭示了当前VQA模型在处理具有挑战性的电影内容问题时的能力和局限性，为未来研究提供了重要基础。

Abstract: This paper introduces MovieCORE, a novel video question answering (VQA)
dataset designed to probe deeper cognitive understanding of movie content.
Unlike existing datasets that focus on surface-level comprehension, MovieCORE
emphasizes questions that engage System-2 thinking while remaining specific to
the video material. We present an innovative agentic brainstorming approach,
utilizing multiple large language models (LLMs) as thought agents to generate
and refine high-quality question-answer pairs. To evaluate dataset quality, we
develop a set of cognitive tests assessing depth, thought-provocation
potential, and syntactic complexity. We also propose a comprehensive evaluation
scheme for assessing VQA model performance on deeper cognitive tasks. To
address the limitations of existing video-language models (VLMs), we introduce
an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves
model reasoning capabilities post-training by up to 25%. Our work contributes
to advancing movie understanding in AI systems and provides valuable insights
into the capabilities and limitations of current VQA models when faced with
more challenging, nuanced questions about cinematic content. Our project page,
dataset and code can be found at
https://joslefaure.github.io/assets/html/moviecore.html.

</details>


### [34] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: CoLAP方法通过对比学习和跨语言表示整合，实现从高资源语言到低资源语言的任务特定知识迁移，显著提升多语言NLP的数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决多语言NLP中语言资源不平衡问题，高资源语言数据丰富而低资源语言数据匮乏，导致性能差距。

Method: 结合对比学习和跨语言表示的CoLAP方法，通过提示机制促进任务特定知识从高资源语言向低资源语言迁移。

Result: 在自然语言推理和关系抽取任务上，CoLAP优于少样本跨语言迁移基线和上下文学习，即使在有限数据下也能有效缩小跨语言性能差距。

Conclusion: CoLAP方法为开发更高效的多语言NLP技术提供了有效解决方案，显著提高了数据利用效率和多语言适应能力。

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [35] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 这篇论文提出了一个命名实体识别框架，用于从社交媒体中提取非医疗类阿片类药物使用的临床和社会影响，DeBERTa-large模型表现最佳，但仍远超专家一致性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上用户真实分享的第一手经验为非医疗阿片类药物使用的影响提供了价值但被忽视的数据源，需要更好的NLP工具来提取这些信息。

Method: 构建RedditImpacts 2.0数据集，使用精细标注指南和第一人称述。测试细调的编码器模型和大语言模型的零小样本学习能力。

Result: 细调DeBERTa-large模型在松弛分词级F1得分0.61，在精度、字符串准确性和指南遵循方面都超过LLMs。证明可用更少标签数据达到强劲性能。

Conclusion: 领域特定细调对临床NLP任务很重要，但当前最佳NER技术仍远超专家智能，显示了深度领域知识任务的挑战。

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [36] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 使用微调的LLaMA 2-7B模型和RACE数据集，通过提示工程实现自动问答生成，为教育工作者提供定制化的问题生成工具。


<details>
  <summary>Details</summary>
Motivation: 教育评估中手动创建公平且多样化的问题对教师来说具有挑战性，需要自动化工具来简化这一过程。

Method: 采用无监督学习方法，基于Meta-Llama 2-7B模型，使用RACE数据集进行微调，并通过提示工程支持多种问题类型（选择题、概念题、事实题）。

Result: 开发了一个定制化模型，能够为教育工作者提供高效的文本评估解决方案。

Conclusion: 自动问答生成工具可以节省教育工作者宝贵的时间和资源，简化评估流程。

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [37] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: 提出了一种结合外部词典工具和强化学习的低资源机器翻译方法，在西班牙语-Wayuunaiki语言对上取得了显著提升


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在低资源语言翻译中面临的预训练数据不足和并行数据有限的问题

Method: 将翻译建模为工具增强的决策问题，结合监督指令微调和GRPO强化学习，让模型学会选择性使用双语词典

Result: 在西班牙语-Wayuunaiki测试集上比之前工作提升+3.37 BLEU分数，比无词典监督基线相对提升18%

Conclusion: 结合大语言模型与外部工具以及强化学习在低资源语言翻译场景中具有很大潜力

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [38] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: LLMs在卡牌游戏协同效应识别中表现不佳，特别是在检测正负协同效应方面存在困难


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在动态环境中理解和推理复杂规则交互的能力，特别是在卡牌游戏中的协同效应识别

Method: 引入Slay the Spire游戏的卡牌协同数据集，对卡牌对的正面、负面或中性交互进行分类评估

Result: LLMs擅长识别非协同卡牌对，但在检测正面协同效应和特别是负面协同效应方面表现不佳

Conclusion: 研究揭示了LLMs在规则交互预测方面的局限性，为未来改进模型在规则效果预测方面的性能提供了方向

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [39] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 提出了Blockwise SFT方法，通过将响应划分为固定大小的块，在训练时只对当前活动块进行随机掩码和损失计算，解决了离散扩散语言模型中训练与推理不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 标准监督微调(SFT)与离散扩散语言模型的半自回归推理过程存在不匹配：训练时在整个响应中随机掩码标记，而推理时按固定大小的块顺序生成，这导致噪声前缀和泄露后缀问题，使梯度偏离期望的块级似然。

Method: Blockwise SFT方法将响应划分为固定大小的块，每个步骤选择一个活动块进行随机掩码，冻结所有前驱标记并完全隐藏未来标记，损失仅计算在活动块上，直接反映块级解码过程。

Result: 在GSM8K、MATH和MetaMathQA数据集上的实验显示，在相同计算或标记预算下，Blockwise SFT相比经典SFT获得了一致的性能提升。块大小一致性研究和消融实验证实改进源于训练-推理对齐而非偶然的掩码效应。

Conclusion: 研究结果强调了在基于扩散的语言模型中，将监督粒度与解码过程相匹配的重要性，Blockwise SFT通过精确对齐训练和推理过程，有效提升了模型性能。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [40] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: 提出了一种基于代码块分割和AST结构的DPO优化方法，通过将代码片段分割成更细粒度的块来创建更多样化的训练对，显著提升了代码生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成任务中，由于缺乏可验证的测试用例训练数据，性能提升面临挑战。虽然DPO方法有潜力，但现有测试用例生成方法仍存在局限性。

Method: 将代码片段分割成更小的粒度块，从相同测试用例创建更多样化的DPO对；引入抽象语法树(AST)分割和课程训练方法来增强DPO训练。

Result: 在多个基准数据集上验证了显著改进，包括HumanEval(+)、MBPP(+)、APPS、LiveCodeBench和BigCodeBench。

Conclusion: 提出的代码块分割和AST增强的DPO方法有效提升了代码生成性能，为LLM在代码相关任务中的应用提供了新思路。

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [41] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出了首个未见情感识别对话任务(UERC)和原型情感迁移框架ProEmoTrans，通过LLM增强描述、参数自由编码机制和改进的注意力维特比解码来解决隐式表达、长对话编码和情感转移三大挑战。


<details>
  <summary>Details</summary>
Motivation: 当前情感识别对话研究基于封闭域假设，但心理学中情感分类缺乏明确共识，导致模型在真实场景中难以识别未见情感，需要开发开放域情感识别能力。

Method: 提出原型情感迁移框架ProEmoTrans：1) LLM增强描述处理隐式表达 2) 参数自由编码机制处理长对话 3) 改进注意力维特比解码(AVD)转移情感马尔可夫流

Result: 在三个数据集上的大量实验表明，该方法在新领域初步探索中作为强基线表现优异。

Conclusion: 成功建立了未见情感识别对话任务基准，提出的原型迁移框架有效解决了开放域情感识别中的关键挑战，为未来研究提供了坚实基础。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [42] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 这篇论文研究大语言模型对法律空子的响应，发现各种模型都能识别歧义性并利用空子来实现自身目标，构成AI安全风险。


<details>
  <summary>Details</summary>
Motivation: 通过研究LLM对空子的响应，一方面可以探索模型在歧义性和语用推理方面的能力，另一方面空子也构成了一种新的对齐问题，模型可能利用歧义性来优先实现自身目标而非用户目标。

Method: 设计了多种场景，包括标量含义、结构歧义性和权力动态等，在这些场景中给LLM提供一个目标和与该目标冲突的歧义用户指令，然后测量不同模型利用空子来满足自身目标的能力。

Result: 发现闭源模型和更强大的开源模型都能识别歧义性并利用空子，构成潜在的AI安全风险。分析显示，那些利用空子的模型会明确识别并推理歧义性和相互冲突的目标。

Conclusion: 这项研究展示了LLM在遇到目标冲突时利用歧义性的能力，这不仅有助于理解模型的语用推理能力，也告诉我们需要重视这种新型的对齐问题，因为它可能会导致模型为了实现自身目标而不遵循用户意图。

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [43] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET是一个自动化评估框架，用于测试大语言模型的长文本理解能力，通过三层关键事实层次结构和查询聚焦摘要来评估模型表现，发现模型在细粒度理解方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型长文本评估方法不够系统和全面，需要一种自动化、可靠的方法来评估模型在不同层次上的信息理解和忠实表达能力。

Method: 构建三层关键事实层次结构（根级、分支级、叶级），采用查询聚焦摘要方法，通过自动化流水线评估模型表现，并与人工评估进行对比验证。

Result: 自动化评估与专家人工判断达到90%以上一致性，成本降低25倍；发现模型在叶级细粒度理解方面表现不佳，存在位置效应（如中间信息丢失），分析性查询比叙述性查询更具挑战性，开源与专有模型之间存在性能差距。

Conclusion: HAMLET提供了一个可靠且高效的自动化评估框架，揭示了当前LLMs在长文本理解方面的局限性，特别是在细粒度信息处理上，为模型改进提供了重要见解。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [44] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 本文指出了ArgKP21数据集的主要局限性，创建了一个新的更真实的论点赞取数据集ArgCMV，包含12K个真实在线辩论，展示了现有方法在新数据集上的表现不佳，为下一代LLM驱动的摘要研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的论点赞取方法主要在ArgKP21数据集上评估，但该数据集不能很好地代表真实的人类对话，需要更具代表性的新基准数据集。

Method: 使用最先进的大型语言模型(LLMs)构建了一个新的论点赞取数据集ArgCMV，包含约12K个来自真实在线人类辩论的论点，涵盖3K多个主题。

Result: ArgCMV数据集表现出更高的复杂性，如更长的共指论点、更多主观话语单元和更广泛的主题范围。实验表明现有方法不能很好地适应ArgCMV数据集。

Conclusion: 这项工作为长上下文在线讨论引入了新颖的论点赞取数据集，为下一代LLM驱动的摘要研究奠定了基础。

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [45] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 现代阿拉伯语ASR系统在孤立字母分类任务上表现不佳，准确率仅35%。通过轻量级神经网络和对抗训练，准确率提升至65%并增强了抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语孤立字母识别对语言学习、语音治疗和语音学研究至关重要，但由于缺乏共发音线索和词汇上下文，且持续时间短，现有ASR系统在此任务上面临挑战。

Method: 构建带音标的孤立阿拉伯字母语料库，使用wav2vec 2.0模型提取特征，训练轻量级神经网络，并应用对抗训练增强鲁棒性。

Result: wav2vec 2.0基线准确率35%，轻量神经网络提升至65%。添加微小振幅扰动(ε=0.05)后准确率降至32%，对抗训练将噪声下降限制在9%同时保持干净语音准确率。

Conclusion: 研究证明了孤立字母识别的挑战性，提出了有效的解决方案，并为未来扩展到词句级框架奠定了基础，数据代码已开源供复现。

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [46] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 本文提出Router Lens方法识别上下文忠实专家，并开发CEFT轻量级优化方法，通过选择性微调这些专家来提升模型上下文忠实度，在保持高效的同时达到或超越全微调性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在上下文依赖场景中经常产生与上下文无关的响应，缺乏上下文忠实性。受混合专家架构中专家专业化的启发，研究是否某些专家在上下文利用方面具有专门化能力。

Method: 提出Router Lens方法准确识别上下文忠实专家，分析发现这些专家会逐步放大对相关上下文信息的注意力。基于此开发Context-faithful Expert Fine-Tuning (CEFT)方法，选择性微调上下文忠实专家。

Result: 在广泛基准测试和模型上的实验表明，CEFT方法在显著更高效的情况下，匹配或超越了全微调的性能表现。

Conclusion: 通过识别和选择性优化上下文忠实专家，可以有效提升模型上下文忠实性，为针对性优化提供了可行路径，实现了效率与性能的平衡。

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [47] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 本文通过噪声注入实验发现LLM不同层次的功能分工：浅层处理局部上下文，中间层整合外部事实知识，深层依赖内部参数知识。基于此提出了Layer Fused Decoding解码策略，有效提升RAG系统的知识利用效率。


<details>
  <summary>Details</summary>
Motivation: 尽管反直觉，但实证研究表明在检索文档中注入噪声反而能促进LLM对外部知识的利用。这一现象为分析LLM如何整合外部知识提供了独特机会，希望通过噪声干预来建立LLM内部的功能分工机制。

Method: 通过噪声注入干预实验，建立了LLM的层次功能划分理论。提出了Layer Fused Decoding (LFD)解码策略，将中间层表示与最终层解码输出直接结合。引入内部知识评分(IKS)准则来选择最优中间层。

Result: 在多个基准测试上的实验结果表明，LFD能够以最小成本帮助RAG系统更有效地利用检索到的上下文知识，显著提升了生成质量。

Conclusion: 研究揭示了LLM内部的知识整合机制分层特性，提出的LFD方法为RAG系统提供了一种简单有效的解码策略，能够充分利用外部事实知识，同时保持计算效率。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [48] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: SALF是一个符号对抗学习框架，通过生成器和检测器的对抗性交互来提升假新闻检测能力，使用符号学习而非数值更新，在多种语言基准测试中显著降低现有检测器性能并提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 随着LLM快速发展，假新闻自动生成能力增强，传统检测方法难以应对动态演变的虚假信息，需要更鲁棒和自适应的检测系统。

Method: 提出符号对抗学习框架(SALF)，包含生成代理和检测代理，通过结构化辩论进行对抗训练，使用代理提示定义可学习权重，在自然语言表示上模拟反向传播和梯度下降。

Result: 在两个多语言基准数据集上，SALF生成的假新闻使最先进检测器性能下降53.4%(中文)和34.2%(英文)，同时将检测器对精炼内容的检测精度提升7.7%。

Conclusion: SALF框架有效提升了假新闻检测的鲁棒性和适应性，为构建更强大的虚假信息检测系统提供了新思路。

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [49] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出一种自动将SystemC模型封装为FMI标准接口的方法，解决汽车领域协同仿真中的标准化和互操作性问题


<details>
  <summary>Details</summary>
Motivation: 汽车行业需要强大的协同仿真方法进行早期验证和软硬件集成，但缺乏标准接口和专有平台主导导致协作、扩展性和IP保护方面的挑战

Method: 使用Functional Mock-up Interface (FMI)标准自动包装SystemC模型，结合SystemC的建模精度和快速上市优势与FMI的互操作性和封装优势

Result: 在真实案例研究中验证了该方法的有效性，能够处理复杂设计

Conclusion: 该方法实现了嵌入式组件在协同仿真工作流中的安全和便携集成

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [50] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 本调查系统分析了专业大语言模型从简单领域适应到原生架构设计的演进，重点考察了医疗、金融、法律和技术领域的应用，揭示了专业模型在领域特定基准测试中的性能优势。


<details>
  <summary>Details</summary>
Motivation: 随着专业大语言模型的快速发展，从简单的领域适应转向复杂的原生架构设计，需要系统性地分析这一演进过程及其在不同专业领域的应用效果。

Method: 通过系统性调查分析，考察医疗、金融、法律和技术等领域的专业LLM发展，重点关注超越微调的领域原生设计、参数效率优化（稀疏计算和量化）以及多模态能力集成等技术突破。

Result: 分析显示这些创新有效解决了通用LLM在专业应用中的根本限制，专业模型在领域特定基准测试中 consistently 表现出性能提升。

Conclusion: 专业LLM的发展为电子商务等领域填补了空白，标志着AI开发范式的转变，具有重要的实际应用价值和发展前景。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [51] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 这篇论文研究如何在最小化或零人类帮助的情况下开发适应性强、可扩展、准确的任务对话机器人


<details>
  <summary>Details</summary>
Motivation: 解决开发自主学习和适应的任务对话机器人的重大挑战，应对不断变化的环境需求

Method: 分析创建这类机器人的障碍和潜在解决方案，采用创新技术使机器人能够自主学习和适应

Result: 本文提供了对自主学习任务对话机器人研究的深入分析和技术探索

Conclusion: 通过创新技术实现自主学习和适应能力是开发高效任务对话机器人的关键途径

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [52] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: CSKS是一个轻量级框架，通过调节两个小型代理模型的输出分布差异来连续控制大语言模型对上下文知识的敏感度，无需修改大模型权重


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中参数知识与上下文知识冲突的问题，现有方法效率低、不适用于黑盒模型或无法连续调整敏感度

Method: 训练两个小型代理模型，利用它们的输出分布差异来调整大语言模型的原始输出分布，实现连续敏感度控制

Result: 实验证明CSKS能够精确连续地控制LLMs对上下文知识的敏感度，既可增强也可降低敏感度，灵活优先选择参数或上下文知识

Conclusion: CSKS提供了一种轻量高效的解决方案，能够在不修改大模型权重的情况下实现连续的知识敏感度调节，具有实际应用价值

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [53] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: CAMÕES是首个针对欧洲葡萄牙语的开源ASR框架，包含评估基准和最先进模型，相比零样本基础模型将WER相对提升了35%以上


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语ASR资源主要关注巴西葡萄牙语，欧洲葡萄牙语和其他变种研究不足，需要填补这一空白

Method: 构建包含46小时测试数据的评估基准，使用425小时欧洲葡萄牙语数据微调基础模型和从头训练E-Branchformer模型

Result: 微调后的基础模型与E-Branchformer表现相当，最佳模型相比最强零样本基础模型WER相对提升超过35%

Conclusion: CAMÕES框架为欧洲葡萄牙语ASR建立了新的state-of-the-art，填补了该领域的研究空白

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [54] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: 本文提出了NLKI框架，通过检索自然语言事实和LLM生成解释来增强小型视觉语言模型的常识推理能力，在多个数据集上提升准确率7%，并通过噪声鲁棒训练进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 小型视觉语言模型在常识视觉问答中因缺乏外部知识而表现不佳，需要有效整合常识知识来提升性能。

Method: 提出端到端NLKI框架：(i)使用微调ColBERTv2检索自然语言事实，(ii)用LLM生成自然语言解释，(iii)将信号输入sVLMs，并结合噪声鲁棒损失进行微调。

Result: 在CRIC、AOKVQA和e-SNLI-VE数据集上提升准确率最高7%，使FLAVA等模型达到或超过中等规模VLMs水平，噪声鲁棒训练额外提升2.5-5.5%准确率。

Conclusion: LLM生成的常识知识优于知识库检索，噪声感知训练能稳定小模型性能，参数高效的常识推理现可用于2.5亿参数模型。

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [55] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: Spotlight Attention是一种新颖的非线性哈希方法，通过优化查询和键的嵌入分布来提升KV缓存效率，相比传统线性哈希将哈希码长度缩短至少5倍，并在A100 GPU上实现端到端吞吐量提升3倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理过程中KV缓存负担过重，现有基于随机线性哈希的方法效率低下，因为LLM中查询和键的分布在两个窄锥内呈正交分布。

Method: 提出Spotlight Attention方法，使用非线性哈希函数优化查询和键的嵌入分布；开发基于Bradley-Terry排序的轻量级训练框架，可在16GB GPU内存上8小时内完成非线性哈希模块优化；实现专门的CUDA内核利用位运算优势。

Result: 实验结果显示，该方法大幅提升检索精度，哈希码长度比传统线性哈希缩短至少5倍；在单块A100 GPU上实现512K tokens的哈希检索在100μs内完成；端到端吞吐量比原始解码提升高达3倍。

Conclusion: Spotlight Attention通过非线性哈希优化有效解决了LLM中KV缓存效率问题，在保持性能的同时显著提升了推理速度，为大规模语言模型的高效推理提供了实用解决方案。

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [56] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: NEWSCOPE是一个两阶段新闻检索框架，通过句子级聚类和多样性重排序来提升事件报道的多样性，在保持相关性的同时显著提高检索结果的多样性。


<details>
  <summary>Details</summary>
Motivation: 现有新闻检索系统主要关注文本相关性，导致结果冗余且视角有限，需要提升对多样化观点的覆盖。

Method: 两阶段框架：第一阶段使用密集检索获取主题相关内容，第二阶段进行句子级聚类和多样性感知重排序来发现互补信息。

Result: NEWSCOPE在多个基准测试中 consistently优于强基线，在不损害相关性的情况下显著提高了多样性。

Conclusion: 细粒度、可解释的建模能有效减少冗余并促进全面的事件理解，提出的三个可解释指标和两个基准数据集为多样性评估提供了有效工具。

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [57] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: 专家角色提示对LLM任务性能影响分析：专家角色通常带来正面或非显著性能变化，但模型对无关角色细节高度敏感（性能下降近30%），角色保真度效果不一致。


<details>
  <summary>Details</summary>
Motivation: 分析专家角色提示在语言模型中的有效性，之前的研究结果不一致且未深入探讨何时及为何角色提示应该提升性能。

Method: 分析角色提示文献并提炼三个期望标准，在27个任务上评估9个最先进LLM的性能优势、无关属性鲁棒性和角色属性保真度。

Result: 专家角色通常带来正面或非显著性能变化；模型对无关角色细节高度敏感（性能下降近30%）；教育程度、专业化和领域相关性提升效果不一致或可忽略。

Conclusion: 需要更谨慎的角色设计和反映角色使用预期效果的评估方案，缓解策略仅对最大最强大模型有效。

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [58] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: 提出了表格到报告生成任务(T2R)并构建了双语基准T2R-bench，包含457个工业表格和4种表格类型，覆盖19个行业领域。实验显示当前最佳模型仅得62.71分，表明该任务仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理研究未能充分解决工业应用中表格信息转化为报告的实际需求，存在表格复杂性导致推理效果不佳，以及缺乏合适的评估基准两大问题。

Method: 构建T2R-bench双语基准数据集，包含真实工业场景的457个表格，涵盖19个行业领域和4种表格类型，并提出了专门的评估标准来衡量报告生成质量。

Result: 在25个常用大语言模型上的实验表明，即使是当前最先进的Deepseek-R1模型也仅获得62.71分的总体表现，说明现有模型在该任务上仍有改进空间。

Conclusion: 表格到报告生成是一个具有挑战性的工业应用任务，现有大语言模型在该任务上的表现仍有待提升，T2R-bench基准为后续研究提供了重要的评估基础。

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [59] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 这篇论文为印地语言模型提供了五个高质量的评测数据集，解决了直接翻译英语数据集无法抓取语言文化细节的问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量的印地语评测基准，直接翻译英语数据集无法涵盖印地语的语言和文化细节，需要专门为印地语设计的评测工具。

Method: 采用人工注释与翻译-验证相结合的方法，创建了五个印地语LLM评测数据集：IFEval-Hi、MT-Bench-Hi、GSM8K-Hi、ChatRAG-Hi和BFCL-Hi。

Result: 完成了对支持印地语的开源LLM模型的全面基准测评，提供了详细的对比分析结果。

Conclusion: 该方法论不仅为印地语LLM评估提供了可靠基准，还可以扩展到其他语言资源稀缺的语言中。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [60] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 提出基于文本嵌入的分类框架，仅需少量示例即可进行定性分析，在物理调查数据上达到与专家编码者0.74-0.83的Cohen's Kappa一致性


<details>
  <summary>Details</summary>
Motivation: 传统定性分析方法耗时且不一致，现有NLP方法需要大量标注数据或破坏定性工作流程，需要一种既高效又符合定性研究需求的解决方案

Method: 基于文本嵌入的分类框架，每个类别只需少量示例，可微调文本嵌入模型提升性能，支持审核已有数据集

Result: 在2899个开放式物理调查响应上，与专家编码者的一致性达到Cohen's Kappa 0.74-0.83，性能随模型微调而提升

Conclusion: 文本嵌入辅助编码可灵活扩展到数千个响应而不牺牲可解释性，为大规模演绎定性分析开辟了新途径

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [61] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: TokenVerse++在TokenVerse基础上引入可学习向量机制，支持部分标注数据训练，解决了多任务框架需要全标注数据的限制，在保持ASR性能的同时提升了多任务处理的实用性。


<details>
  <summary>Details</summary>
Motivation: 解决TokenVerse等多任务框架需要所有训练语句对所有任务都有完整标注的限制，使其能够利用部分标注的数据集并实现更有效的扩展。

Method: 在XLSR-Transducer ASR模型的声学嵌入空间中引入可学习向量，实现动态任务激活机制，允许使用仅对部分任务有标注的语句进行训练。

Result: 成功整合了部分标注的数据集（ASR和语言识别任务），整体性能得到提升，在多个任务上达到或超过TokenVerse的表现。

Conclusion: TokenVerse++在不牺牲ASR性能的前提下，成为了更实用的多任务替代方案，能够有效处理部分标注数据并实现更好的扩展性。

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [62] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 研究发现人类标注的简单语言数据可以作为有效的课程学习信号，将简单维基百科数据按从易到难顺序训练能持续改善语言模型的困惑度，特别是在简单语言上。


<details>
  <summary>Details</summary>
Motivation: 课程学习通过从易到难呈现数据来改善训练效果，但如何定义和衡量语言难度仍然是一个开放挑战。本研究探索人类标注的简单语言是否能作为有效的课程学习信号。

Method: 使用Simple Wikipedia语料库的文章级标签，比较基于标签的课程与基于浅层启发式的能力策略。使用BERT-tiny模型进行实验，分析不同课程策略对模型性能的影响。

Result: 仅添加简单数据没有明显益处，但通过课程结构（特别是先引入简单数据）能持续改善困惑度，尤其在简单语言上。基于能力的课程相比随机排序没有一致优势。

Conclusion: 人类对语言难度的直觉可以指导语言模型预训练的课程学习，基于人类标注的简单语言数据构建课程是有效的策略。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [63] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: 本文研究使用小型语言模型和预训练大模型来自动识别医学教材中的不合适语言，发现细调的小模型表现超过大模型，多标签分类器效果最佳。


<details>
  <summary>Details</summary>
Motivation: 医学教材中的过时、排外性或非病人个体化语言影响临床培训和健康结果，但手动检查成本高、不实用。

Method: 使用500份文档和12,000页数据集，对比了细调SLMs（包括一般分类器、子类二进制分类器、多标签分类器和两阶段管道）与预训练LLMs的上下文学习效果。

Result: LLama-3 8B和70B模型被SLMs远超，多标签分类器在标注数据上表现最好，添加负面示例能将特异分类器AUC提升25%。

Conclusion: 细调的小模型是减少医学教育中有害语言的最有效方法，多标签分类策略和负面示例补充显著提升性能。

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [64] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: Bangla-Bayanno是一个孟加拉语开放域视觉问答数据集，包含52,650个问答对和4,750+张图像，通过多语言LLM辅助翻译流程构建，旨在推动低资源多模态学习研究。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多为特定领域手动标注或受限于特定答案格式，且孟加拉语作为低资源语言在多模态AI研究中缺乏高质量数据集。

Method: 采用多语言大语言模型辅助的翻译精炼流程，克服多语言源的低质量翻译问题，确保数据清晰度和质量。

Result: 构建了包含52,650个问答对和4,750+张图像的数据集，问题分为名义性、数量性和极性三类答案类型。

Conclusion: Bangla-Bayanno提供了最全面的开源高质量孟加拉语VQA基准，将促进低资源多模态学习和更包容AI系统的发展。

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [65] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 本文提出了用于演绎逻辑推理的结果奖励模型(ORMs)，通过CoT和回声生成技术增强训练数据，在多个逻辑推理数据集上提升了不同LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 逻辑推理是评估大语言模型能力的关键基准，但当前在演绎逻辑推理领域，结合测试时缩放和专用奖励模型的方法尚未充分探索。

Method: 使用单样本和多样本的Chain-of-Thought生成训练数据，并提出回声生成技术来扩展训练数据中的错误类型覆盖。回声技术利用LLM倾向于反映提示中错误假设的特点来获取额外训练数据。

Result: 在FOLIO、JustLogic和ProverQA三个数据集上，使用CoT和回声增强数据训练的ORMs在四种不同LLM上都表现出性能提升。

Conclusion: 通过结合CoT和创新的回声生成技术，可以有效地训练出性能更好的演绎逻辑推理奖励模型，为提升LLM的逻辑推理能力提供了新方法。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [66] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: 研究发现AI多智能体系统在无预设偏见的中性初始条件下，会自发产生刻板印象驱动的偏见，且这种偏见会随着交互轮次和决策权力的增加而加剧。


<details>
  <summary>Details</summary>
Motivation: 虽然人类社交中存在刻板印象已被充分记录，但AI系统通常被认为较少受此类偏见影响。以往研究关注训练数据带来的偏见，但刻板印象是否能在AI智能体交互中自发产生值得进一步探索。

Method: 通过模拟职场交互的新实验框架，在初始中性条件下研究基于LLM的多智能体系统中刻板印象的出现和演化。

Result: 发现：(1)LLM智能体在无预设偏见下仍会发展刻板印象驱动的偏见；(2)刻板印象效应随交互轮次和决策权力增加而加剧；(3)系统表现出类似人类的社会行为群体效应；(4)这种模式在不同LLM架构中一致出现。

Conclusion: AI系统中的刻板印象形成可能是多智能体交互的涌现特性，而不仅仅是训练数据偏见的结果，需要进一步研究其机制并制定缓解策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [67] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: 提出了HEAL评估框架，通过假设空间重排序来评估偏好对齐方法，使用排序准确性和偏好强度相关性两个指标，并构建了UniHypoBench基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法（如DPO）的评估仅依赖单一响应，忽略了假设空间中其他潜在输出，无法全面反映真实应用场景。

Method: 提出HEAL框架，将偏好对齐建模为假设空间中的重排序过程，包含排序准确性和偏好强度相关性两个互补指标，并构建了UniHypoBench基准数据集进行验证。

Result: 实验表明当前偏好学习方法能有效捕捉代理模型的偏好，同时抑制负面样本，为偏好对齐研究提供了新的理论视角和实践工具。

Conclusion: HEAL框架为偏好对齐研究提供了创新的理论范式和实践诊断工具，识别了开发更先进对齐算法的有前景方向。

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [68] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语主观性分析资源匮乏的问题，提出了AraDhati+数据集并基于先进阿拉伯语模型进行微调，实现了97.79%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语作为语言资源丰富但形态复杂的语言，缺乏大规模标注数据集，这阻碍了阿拉伯语主观性分析工具的准确发展。

Method: 1) 整合现有阿拉伯语数据集构建AraDhati+数据集；2) 微调XLM-RoBERTa、AraBERT和ArabianGPT等先进阿拉伯语模型；3) 采用集成决策方法结合各模型优势。

Result: 提出的方法在阿拉伯语主观性分类任务上达到了97.79%的准确率，显著提升了性能。

Conclusion: 该方法有效解决了阿拉伯语处理中资源有限的挑战，证明了深度学习和Transformer模型在阿拉伯语主观性分析中的有效性。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [69] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: Prophet是一种无需训练的快速解码范式，利用扩散语言模型中早期答案收敛的特性，通过动态决策机制在解码过程中提前终止采样，实现3.4倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然支持并行序列生成，但推理速度仍慢于自回归模型，主要原因是双向注意力计算和大规模细化步骤的开销。研究发现DLMs存在早期答案收敛现象，即在最终解码步骤前模型已能识别正确答案。

Method: 提出Prophet解码范式：1）利用top-2预测候选之间的置信度差距作为决策标准；2）动态决定是继续细化还是"all-in"（一步解码所有剩余token）；3）无需额外训练，可与现有DLM实现无缝集成。

Result: 在GSM8K和MMLU任务上，分别有97%和99%的实例仅需一半细化步骤即可正确解码。对LLaDA-8B和Dream-7B的评估显示，Prophet将解码步骤减少最多3.4倍，同时保持高质量生成。

Conclusion: Prophet将DLM解码重新定义为何时停止采样的问题，证明早期解码收敛是加速DLM推理的简单而强大的机制，与现有加速技术互补。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [70] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: LLMs在单一类型的组合推理任务上表现良好，但在需要常识推理和数学推理混合的组合任务中准确率下降约30%，表现出明显的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前组合基准测试主要关注单一类型的推理（常识或数学），而现实世界任务需要混合推理能力，因此需要评估LLMs在这种混合组合推理中的表现。

Method: 引入AgentCoMa基准测试，包含需要常识推理和数学推理步骤的组合任务，测试了61个不同规模、模型家族和训练策略的LLM，并进行可解释性研究（神经元模式、注意力图和成员推理分析）。

Result: LLMs在单独解决常识或数学步骤时表现良好，但在组合任务中准确率平均下降约30%，远高于同类型多步骤组合基准的性能差距。人类注释者则在组合问题和单独步骤上都保持高准确率。

Conclusion: LLMs在混合类型组合推理方面存在显著的脆弱性，AgentCoMa基准为未来改进提供了测试平台，突显了模型在真实世界任务中组合不同推理能力的局限性。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [71] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: MathBuddy是一个情感感知的数学辅导系统，通过多模态情感识别和情感映射到教学策略，显著提升了LLM辅导的教学效果


<details>
  <summary>Details</summary>
Motivation: 现有学习模型未考虑学生情感状态，而教育心理学研究表明情感状态会影响学习能力，需要开发情感感知的辅导系统

Method: 从对话文本和面部表情多模态捕获学生情感，聚合情感信息后提示LLM生成情感感知的回应，将情感映射到相应教学策略

Result: 在八个教学维度上自动评估和用户研究显示，胜率提升23点，DAMR总分提升3点，教学能力显著改善

Conclusion: 通过建模学生情感可以显著提升LLM辅导器的教学能力，情感感知是多模态教育技术的重要发展方向

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [72] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: ReSURE是一种自适应学习方法，通过动态降低不可靠监督的权重来解决多轮对话训练中的错误传播问题，无需显式过滤数据


<details>
  <summary>Details</summary>
Motivation: 多轮对话系统微调需要高质量监督，但低质量数据会导致性能下降。早期轮次的监督错误会传播到后续轮次，破坏对话连贯性和响应质量。现有方法通过静态预过滤处理数据质量，但这种方法将质量控制与训练分离，无法缓解轮级错误传播

Method: ReSURE使用Welford在线统计方法估计每轮损失分布，并据此动态重新加权样本损失。该方法自适应地降低不可靠监督的权重，而不需要显式过滤数据

Result: 在单源和混合质量数据集上的实验显示，ReSURE提高了训练稳定性和响应质量。在多个基准测试中，响应分数与样本数量之间呈现正Spearman相关性（0.21～1.0），无论数据质量如何

Conclusion: ReSURE有效解决了多轮对话训练中的错误传播问题，为有效利用大规模数据铺平了道路。该方法通过动态权重调整而非静态过滤，实现了更好的训练效果

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [73] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: 提出选择性检索增强(SRA)方法解决法律文本分类中的长尾分布问题，通过在训练集中仅对低频标签样本进行检索增强，避免引入噪声，无需改变模型架构。


<details>
  <summary>Details</summary>
Motivation: 法律文本分类基准数据集通常存在长尾标签分布，许多标签样本不足导致模型在稀有类别上性能较差，需要一种有效的数据增强方法来改善这种情况。

Method: 选择性检索增强(SRA)：仅从训练数据中对低频标签样本进行检索增强，避免对充分表示的类别引入噪声，无需外部语料库且防止信息泄露。

Result: 在LEDGAR(单标签)和UNFAIR-ToS(多标签)两个法律文本分类基准数据集上，SRA方法在micro-F1和macro-F1指标上均优于所有现有LexGLUE基线方法。

Conclusion: SRA方法能够有效提升长尾法律文本分类性能，在保持模型架构不变的情况下，通过针对性的数据增强显著改善稀有类别的分类效果。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [74] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: DeepScholar-bench是一个用于评估生成式研究合成系统的实时基准测试框架，通过从arXiv论文中提取查询任务，评估系统在知识合成、检索质量和可验证性三个维度的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估系统主要关注短篇事实性回答，无法捕捉真实研究合成任务的复杂性和动态性，需要开发专门的评估框架来推动生成式研究合成系统的发展。

Method: 从高质量arXiv论文中提取查询任务，要求系统生成相关研究工作章节，通过检索、合成和引用先前研究来完成任务。开发了包含知识合成、检索质量和可验证性三个维度的自动化评估框架。

Result: DeepScholar-base参考管道建立了强大基线，性能优于其他开源系统和商业AI。但所有系统在所有指标上的得分均未超过19%，表明基准测试难度较高。

Conclusion: DeepScholar-bench是一个具有挑战性的基准测试，对于开发能够进行生成式研究合成的AI系统具有重要意义，当前系统性能仍有很大提升空间。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [75] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: IMAGINE是一个通过嵌入空间分布分析生成越狱指令的合成框架，旨在填补真实越狱模式与安全对齐语料之间的分布差距，有效降低LLM的越狱攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在面对分布不同于安全对齐语料的恶意指令时仍然脆弱，存在训练数据与真实攻击之间的分布不匹配问题，导致开发者陷入被动修补循环。

Method: 提出IMAGINE框架，利用嵌入空间分布分析生成类似越狱指令，采用迭代优化过程动态演化文本生成分布，通过合成数据示例扩展安全对齐数据分布的覆盖范围。

Result: 在Qwen2.5、Llama3.1和Llama3.2模型上显著降低了攻击成功率，且不损害模型实用性。

Conclusion: IMAGINE框架通过合成数据有效解决了安全对齐数据分布不足的问题，为LLM安全防御提供了主动解决方案。

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [76] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: AraHealthQA 2025是阿拉伯健康问答共享任务，包含MentalQA（心理健康）和MedArabiQ（综合医疗）两个赛道，旨在解决阿拉伯语医疗QA资源匮乏问题


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语高质量医疗问答资源稀缺的问题，促进在真实、多语言和文化敏感的医疗场景下的模型开发

Method: 创建两个互补赛道：MentalQA专注于心理健康问答，MedArabiQ覆盖更广泛的医疗领域；提供多个子任务、评估数据集和标准化指标

Result: 建立了全面的评估框架，促进了公平基准测试，总结了参与统计、基线系统和整体成果

Conclusion: 分析了性能趋势，展望了阿拉伯健康问答未来的迭代发展前景

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [77] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了11Plus-Bench基准测试，系统评估多模态大语言模型的空间推理能力，发现当前MLLMs展现出早期空间认知迹象，但与人类存在较大性能差距。


<details>
  <summary>Details</summary>
Motivation: 人类认知过程中空间推理与感知紧密相关，但多模态大语言模型在这方面的能力尚未得到充分探索和评估。

Method: 基于现实标准化空间能力测试构建11Plus-Bench高质量基准，包含细粒度专家标注的感知复杂度和推理过程，对14个MLLMs进行广泛实验并与人类表现对比。

Result: 当前MLLMs表现出早期空间认知迹象，认知模式与人类相似（认知努力与推理复杂度强相关），但实例级性能随机性大，而人类表现高度可预测且受抽象模式复杂度影响。

Conclusion: 研究揭示了当前MLLMs空间推理能力的新兴能力和局限性，为模型设计提供了可操作的见解。

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [78] [Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration](https://arxiv.org/abs/2508.19254)
*Jookyung Song,Mookyoung Kang,Nojun Kwak*

Main category: cs.CV

TL;DR: 一种基于双重意图的实时生成式绘画系统，同时解释结构风格意图和语义上下文意图，支持多用户协作创作


<details>
  <summary>Details</summary>
Motivation: 元素传统文本提示生成系统仅关注高级上下文描述，而忽视了绘画的结构性、组成性和风格属性等基础几何特征

Method: 通过视觉-语言模型提取高级语义线索，同时分析线条轨迹、比例和空间布局等基础几何特征，在多阶段生成流程中聚合双重意图信号

Result: 实现了低延迟的两阶段转换，支持多用户在共享画布上的协作创作，无论艺术专业知识都可参与

Conclusion: 该系统重新定义人工智能与人类的交互为协同创作和相互增强的过程

Abstract: This paper presents a real-time generative drawing system that interprets and
integrates both formal intent - the structural, compositional, and stylistic
attributes of a sketch - and contextual intent - the semantic and thematic
meaning inferred from its visual content - into a unified transformation
process. Unlike conventional text-prompt-based generative systems, which
primarily capture high-level contextual descriptions, our approach
simultaneously analyzes ground-level intuitive geometric features such as line
trajectories, proportions, and spatial arrangement, and high-level semantic
cues extracted via vision-language models. These dual intent signals are
jointly conditioned in a multi-stage generation pipeline that combines
contour-preserving structural control with style- and content-aware image
synthesis. Implemented with a touchscreen-based interface and distributed
inference architecture, the system achieves low-latency, two-stage
transformation while supporting multi-user collaboration on shared canvases.
The resulting platform enables participants, regardless of artistic expertise,
to engage in synchronous, co-authored visual creation, redefining human-AI
interaction as a process of co-creation and mutual enhancement.

</details>


### [79] [TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models](https://arxiv.org/abs/2508.19257)
*Chenghao Liu,Jiachen Zhang,Chengxuan Li,Zhimu Zhou,Shixin Wu,Songfang Huang,Huiling Duan*

Main category: cs.CV

TL;DR: 提出了Temporal Token Fusion (TTF)方法，通过融合历史与当前视觉表征来增强VLA模型的推理质量，在多个基准测试中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型逐帧处理视觉输入，丢弃了机器人操作任务中宝贵的时间信息，使其容易受到视觉噪声影响并忽略连续帧之间的连贯性

Method: TTF采用双维度检测（灰度像素差异分析和基于注意力的语义相关性评估），通过硬融合策略和关键帧锚定实现选择性时间token融合，防止错误累积

Result: 在LIBERO上平均提升4.0个百分点（72.4% vs 68.4%基准），SimplerEnv上相对提升4.8%，真实机器人任务上相对提升8.7%，且证明具有模型无关性

Conclusion: TTF方法不仅提升了性能，还发现选择性重用Query矩阵可以增强而非损害性能，为直接KQV矩阵重用策略提供了有前景的方向，在实现计算加速的同时提高任务成功率

Abstract: Vision-Language-Action (VLA) models process visual inputs independently at
each timestep, discarding valuable temporal information inherent in robotic
manipulation tasks. This frame-by-frame processing makes models vulnerable to
visual noise while ignoring the substantial coherence between consecutive
frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a
training-free approach that intelligently integrates historical and current
visual representations to enhance VLA inference quality. Our method employs
dual-dimension detection combining efficient grayscale pixel difference
analysis with attention-based semantic relevance assessment, enabling selective
temporal token fusion through hard fusion strategies and keyframe anchoring to
prevent error accumulation. Comprehensive experiments across LIBERO,
SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0
percentage points average on LIBERO (72.4\% vs 68.4\% baseline),
cross-environment validation on SimplerEnv (4.8\% relative improvement), and
8.7\% relative improvement on real robot tasks. Our approach proves
model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,
TTF reveals that selective Query matrix reuse in attention mechanisms enhances
rather than compromises performance, suggesting promising directions for direct
KQV matrix reuse strategies that achieve computational acceleration while
improving task success rates.

</details>


### [80] [Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation](https://arxiv.org/abs/2508.19289)
*Tai Inui,Steven Oh,Magdeline Kuan*

Main category: cs.CV

TL;DR: 提出了一种无监督的幻灯片质量评估方法，结合7个视觉设计指标和CLIP-ViT嵌入，使用孤立森林异常评分来评估演示幻灯片质量。


<details>
  <summary>Details</summary>
Motivation: 需要一种可扩展、客观的实时反馈方法来评估演示幻灯片的质量，以替代主观的人工评估。

Method: 结合专家启发的7个视觉设计指标（留白、色彩丰富度、边缘密度、亮度对比度、文本密度、色彩协调性、布局平衡）和CLIP-ViT嵌入，使用孤立森林算法进行异常评分。在12k专业讲座幻灯片上训练，在6个学术演讲（115张幻灯片）上评估。

Result: 与人类视觉质量评分的Pearson相关性高达0.83，比领先的视觉语言模型（ChatGPT o4-mini-high、ChatGPT o3、Claude Sonnet 4、Gemini 2.5 Pro）强1.79倍到3.23倍。

Conclusion: 将低级设计线索与多模态嵌入相结合，能够很好地近似观众对幻灯片质量的感知，实现可扩展的实时客观反馈。

Abstract: We present an unsupervised slide-quality assessment pipeline that combines
seven expert-inspired visual-design metrics (whitespace, colorfulness, edge
density, brightness contrast, text density, color harmony, layout balance) with
CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate
presentation slides. Trained on 12k professional lecture slides and evaluated
on six academic talks (115 slides), our method achieved Pearson correlations up
to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores
from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude
Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual
ratings, discriminant validity against speaker-delivery scores, and exploratory
alignment with overall impressions. Our results show that augmenting low-level
design cues with multimodal embeddings closely approximates audience
perceptions of slide quality, enabling scalable, objective feedback in real
time.

</details>


### [81] [Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation](https://arxiv.org/abs/2508.19290)
*Alexandros Gkillas,Ioulia Kapsali,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: 提出了一种针对2D范围视图LiDAR分割的高效对抗防御框架，通过数学优化的净化网络实现强对抗鲁棒性，计算开销小，在实际自动驾驶场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR分割网络易受对抗攻击威胁安全，而大多数防御方法针对原始3D点云设计且计算量大，缺乏针对广泛使用的2D范围视图表示的轻量级防御方案

Method: 开发了基于数学优化问题的可解释净化网络，专门为2D范围视图LiDAR分割设计，实现了直接的范围视图域攻击制定和高效净化

Result: 在开放基准测试中取得竞争性性能， consistently超越生成式方法和对抗训练基线，在实际演示车辆部署中验证了准确运行能力

Conclusion: 该框架为2D范围视图LiDAR分割提供了高效的对抗防御解决方案，具有实际部署价值，能够保障自动驾驶系统的安全可靠性

Abstract: LiDAR-based segmentation is essential for reliable perception in autonomous
vehicles, yet modern segmentation networks are highly susceptible to
adversarial attacks that can compromise safety. Most existing defenses are
designed for networks operating directly on raw 3D point clouds and rely on
large, computationally intensive generative models. However, many
state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D
range view representations. Despite their widespread adoption, dedicated
lightweight adversarial defenses for this domain remain largely unexplored. We
introduce an efficient model-based purification framework tailored for
adversarial defense in 2D range-view LiDAR segmentation. We propose a direct
attack formulation in the range-view domain and develop an explainable
purification network based on a mathematical justified optimization problem,
achieving strong adversarial resilience with minimal computational overhead.
Our method achieves competitive performance on open benchmarks, consistently
outperforming generative and adversarial training baselines. More importantly,
real-world deployment on a demo vehicle demonstrates the framework's ability to
deliver accurate operation in practical autonomous driving scenarios.

</details>


### [82] [AudioStory: Generating Long-Form Narrative Audio with Large Language Models](https://arxiv.org/abs/2508.20088)
*Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan*

Main category: cs.CV

TL;DR: AudioStory是一个集成大语言模型和文本到音频生成系统的统一框架，专门用于生成长篇叙事音频，通过解耦的桥接机制和端到端训练实现时序连贯和情感一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到音频生成技术在生成长篇叙事音频时存在困难，无法保持时序连贯性和组合推理能力，需要一种能够处理复杂叙事查询并生成结构化长音频的方法。

Method: 使用大语言模型将复杂叙事查询分解为时序有序的子任务，采用解耦桥接机制（语义对齐桥接查询和连贯性保持残差查询），并通过端到端训练统一指令理解和音频生成。

Result: 在AudioStory-10K基准测试中，AudioStory在单音频生成和叙事音频生成方面均优于现有基线方法，在指令跟随能力和音频保真度方面表现优异。

Conclusion: AudioStory通过整合LLM和TTA系统，有效解决了长叙事音频生成的挑战，为生成长篇连贯音频内容提供了有效的解决方案。

Abstract: Recent advances in text-to-audio (TTA) generation excel at synthesizing short
audio clips but struggle with long-form narrative audio, which requires
temporal coherence and compositional reasoning. To address this gap, we propose
AudioStory, a unified framework that integrates large language models (LLMs)
with TTA systems to generate structured, long-form audio narratives. AudioStory
possesses strong instruction-following reasoning generation capabilities. It
employs LLMs to decompose complex narrative queries into temporally ordered
sub-tasks with contextual cues, enabling coherent scene transitions and
emotional tone consistency. AudioStory has two appealing features: (1)
Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser
collaboration into two specialized components, i.e., a bridging query for
intra-event semantic alignment and a residual query for cross-event coherence
preservation. (2) End-to-end training: By unifying instruction comprehension
and audio generation within a single end-to-end framework, AudioStory
eliminates the need for modular training pipelines while enhancing synergy
between components. Furthermore, we establish a benchmark AudioStory-10K,
encompassing diverse domains such as animated soundscapes and natural sound
narratives. Extensive experiments show the superiority of AudioStory on both
single-audio generation and narrative audio generation, surpassing prior TTA
baselines in both instruction-following ability and audio fidelity. Our code is
available at https://github.com/TencentARC/AudioStory

</details>


### [83] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 这篇综述论文系统回顾了大视觉语言模型(LVLMs)在目标检测领域的应用，重点分析了VLMs如何通过融合视觉和语言信息来提升目标检测的适应性、上下文推理能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习目标检测方法存在局限性，而视觉语言模型的融合为对象检测带来了革命性的改进，需要系统梳理该领域的最新进展和技术路线。

Method: 采用三步研究回顾过程：1)分析VLMs在目标检测中的工作原理；2)探讨架构创新、训练范式和输出灵活性；3)比较LVLMs与传统深度学习方法在实时性能、适应性和复杂性方面的差异。

Result: 研究表明LVLMs在多样化场景中表现出色，特别是在定位和分割任务上，预计很快将达到或超越传统方法的性能。同时识别了当前LVLM模型的主要局限性并提出了解决方案。

Conclusion: LVLMs的最新进展已经并将继续对目标检测和机器人应用产生变革性影响，为该领域的未来发展提供了清晰的技术路线图。

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [84] [Large VLM-based Stylized Sports Captioning](https://arxiv.org/abs/2508.19295)
*Sauptik Dhar,Nicholas Buoncristiani,Joe Anakata,Haoyu Zhang,Michelle Munson*

Main category: cs.CV

TL;DR: 本文提出了一种针对体育领域的两级微调视觉语言模型管道，用于从图像生成专业级体育解说字幕，在F1分数和BERT分数上相比现有方法有显著提升，并在超级碗比赛中成功应用。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和视觉语言模型虽然能解释通用体育活动，但缺乏体育领域的专业术语来生成自然的人类解说风格描述，无法满足体育内容生成的专业需求。

Method: 采用两级微调的视觉语言模型管道，专门针对体育领域进行优化，能够以特定风格格式从图像生成体育解说字幕。

Result: 相比其他方法，F1分数提升8-10%，BERT分数提升2-10%，具有较小的运行时内存占用和快速执行时间（6张图像/3-5秒），在超级碗LIX比赛中成功处理了1000多张图像。

Conclusion: 该管道证明了在实时专业体育新闻中的实际应用价值，能够生成高度准确和风格化的体育解说字幕，填补了现有模型在体育领域专业内容生成方面的空白。

Abstract: The advent of large (visual) language models (LLM / LVLM) have led to a
deluge of automated human-like systems in several domains including social
media content generation, search and recommendation, healthcare prognosis, AI
assistants for cognitive tasks etc. Although these systems have been
successfully integrated in production; very little focus has been placed on
sports, particularly accurate identification and natural language description
of the game play. Most existing LLM/LVLMs can explain generic sports
activities, but lack sufficient domain-centric sports' jargon to create natural
(human-like) descriptions. This work highlights the limitations of existing
SoTA LLM/LVLMs for generating production-grade sports captions from images in a
desired stylized format, and proposes a two-level fine-tuned LVLM pipeline to
address that. The proposed pipeline yields an improvement > 8-10% in the F1,
and > 2-10% in BERT score compared to alternative approaches. In addition, it
has a small runtime memory footprint and fast execution time. During Super Bowl
LIX the pipeline proved its practical application for live professional sports
journalism; generating highly accurate and stylized captions at the rate of 6
images per 3-5 seconds for over 1000 images during the game play.

</details>


### [85] [DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models](https://arxiv.org/abs/2508.19298)
*Abu Sufian,Anirudha Ghosh,Debaditya Barman,Marco Leo,Cosimo Distante*

Main category: cs.CV

TL;DR: DemoBias研究评估了大型视觉语言模型在生物特征人脸识别任务中的人口统计偏差，发现不同模型在不同种族群体间存在显著的性能差异。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在各种下游任务中表现出色，但在生物特征人脸识别中存在人口统计偏差问题，需要评估这些模型在不同人口群体间的公平性。

Method: 对LLaVA、BLIP-2和PaliGemma三种预训练模型进行微调，使用自行生成的人口平衡数据集，采用BERTScores和公平性差异率等指标进行量化评估。

Result: 实验发现PaliGemma和LLaVA在西班牙裔/拉丁裔、高加索人和南亚人群上表现出较高差异，而BLIP-2表现相对一致。

Conclusion: 大型视觉语言模型在生物特征人脸识别中存在明显的人口统计偏差，需要进一步改进以确保模型在不同人口群体间的公平性和可靠性。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities across various downstream tasks, including biometric face
recognition (FR) with description. However, demographic biases remain a
critical concern in FR, as these foundation models often fail to perform
equitably across diverse demographic groups, considering ethnicity/race,
gender, and age. Therefore, through our work DemoBias, we conduct an empirical
evaluation to investigate the extent of demographic biases in LVLMs for
biometric FR with textual token generation tasks. We fine-tuned and evaluated
three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own
generated demographic-balanced dataset. We utilize several evaluation metrics,
like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify
and trace the performance disparities. The experimental results deliver
compelling insights into the fairness and reliability of LVLMs across diverse
demographic groups. Our empirical study uncovered demographic biases in LVLMs,
with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,
Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably
consistent. Repository: https://github.com/Sufianlab/DemoBias.

</details>


### [86] [Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities](https://arxiv.org/abs/2508.19305)
*Chen Chu,Cyrus Shahabi*

Main category: cs.CV

TL;DR: Geo2Vec是一种新颖的空间表示学习方法，直接在原始空间操作，通过自适应采样和符号距离场编码，为所有地理实体类型生成紧凑、几何感知的统一表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只针对单一地理实体类型，要么需要将实体分解为简单组件进行傅里叶变换，计算成本高且缺乏几何对齐，导致细粒度特征模糊。

Method: 基于符号距离场(SDF)思想，自适应采样点并编码其符号距离(外部为正，内部为负)，无需分解即可捕获几何特征。使用神经网络近似SDF，并提出旋转不变位置编码来建模高频空间变化。

Result: 实验结果表明，Geo2Vec在表示形状和位置、捕获拓扑和距离关系方面持续优于现有方法，并在实际GeoAI应用中实现更高效率。

Conclusion: Geo2Vec提供了一种高效、统一的空间表示学习方法，能够更好地处理各种地理实体类型，为下游GeoAI模型构建结构化和鲁棒的嵌入空间。

Abstract: Spatial representation learning is essential for GeoAI applications such as
urban analytics, enabling the encoding of shapes, locations, and spatial
relationships (topological and distance-based) of geo-entities like points,
polylines, and polygons. Existing methods either target a single geo-entity
type or, like Poly2Vec, decompose entities into simpler components to enable
Fourier transformation, introducing high computational cost. Moreover, since
the transformed space lacks geometric alignment, these methods rely on uniform,
non-adaptive sampling, which blurs fine-grained features like edges and
boundaries. To address these limitations, we introduce Geo2Vec, a novel method
inspired by signed distance fields (SDF) that operates directly in the original
space. Geo2Vec adaptively samples points and encodes their signed distances
(positive outside, negative inside), capturing geometry without decomposition.
A neural network trained to approximate the SDF produces compact,
geometry-aware, and unified representations for all geo-entity types.
Additionally, we propose a rotation-invariant positional encoding to model
high-frequency spatial variations and construct a structured and robust
embedding space for downstream GeoAI models. Empirical results show that
Geo2Vec consistently outperforms existing methods in representing shape and
location, capturing topological and distance relationships, and achieving
greater efficiency in real-world GeoAI applications. Code and Data can be found
at: https://github.com/chuchen2017/GeoNeuralRepresentation.

</details>


### [87] [Advancements in Crop Analysis through Deep Learning and Explainable AI](https://arxiv.org/abs/2508.19307)
*Hamza Khan*

Main category: cs.CV

TL;DR: 本研究提出基于卷积神经网络的自动化方法，成功分类5种大米品种并诊断4种水稻叶部病害，结合可解释AI技术提高模型透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大米作为全球重要主食，传统人工检测方法劳动密集、耗时且易出错，需要自动化解决方案来确保品质控制和产量提升。

Method: 使用包含75000张图像的公开数据集，采用CNN、VGG16、ResNet50和MobileNetV2等深度学习模型，结合SHAP和LIME等可解释AI技术分析特征影响。

Result: 模型表现出高分类准确率，误分类极少，成功区分大米品种并准确诊断Brown Spot、Blast、Bacterial Blight和Tungro等叶部病害。

Conclusion: 深度学习在农业应用中具有巨大潜力，可开发出稳健、可解释的系统，支持自动化作物质量检测和病害诊断，惠及农民、消费者和农业经济。

Abstract: Rice is a staple food of global importance in terms of trade, nutrition, and
economic growth. Among Asian nations such as China, India, Pakistan, Thailand,
Vietnam and Indonesia are leading producers of both long and short grain
varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To
ensure consumer satisfaction and strengthen national reputations, monitoring
rice crops and grain quality is essential. Manual inspection, however, is
labour intensive, time consuming and error prone, highlighting the need for
automated solutions for quality control and yield improvement. This study
proposes an automated approach to classify five rice grain varieties using
Convolutional Neural Networks (CNN). A publicly available dataset of 75000
images was used for training and testing. Model evaluation employed accuracy,
recall, precision, F1-score, ROC curves, and confusion matrices. Results
demonstrated high classification accuracy with minimal misclassifications,
confirming the model effectiveness in distinguishing rice varieties. In
addition, an accurate diagnostic method for rice leaf diseases such as Brown
Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined
explainable artificial intelligence (XAI) with deep learning models including
CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP
(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic
Explanations) revealed how specific grain and leaf features influenced
predictions, enhancing model transparency and reliability. The findings
demonstrate the strong potential of deep learning in agricultural applications,
paving the way for robust, interpretable systems that can support automated
crop quality inspection and disease diagnosis, ultimately benefiting farmers,
consumers, and the agricultural economy.

</details>


### [88] [Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax](https://arxiv.org/abs/2508.19312)
*Ander Galván,Marivi Higuero,Jorge Sasiain,Eduardo Jacob*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于联邦学习框架的面部识别系统，通过集成OpenMax算法来处理开收集场景中的未知个体识别问题，在保护隐私的同时提高识别准确性。


<details>
  <summary>Details</summary>
Motivation: 人工智能面部识别在特定场景下已达到高精度，但面临隐私和身份管理挑战，特别是当操作环境中出现未知个体时。

Method: 将OpenMax算法集成到联邦学习框架中，利用平均激活向量和本地距离测量的交换来区分已知和未知主体。

Result: 实验结果验证了所提方案的有效性，证明其能够在分布式环境中提高隐私意识和稳健的面部识别能力。

Conclusion: 该研究为开收集面部识别提供了一种联邦学习方案，通过结合OpenMax算法有效解决了未知个体识别挑战，同时保障了数据隐私。

Abstract: Facial recognition powered by Artificial Intelligence has achieved high
accuracy in specific scenarios and applications. Nevertheless, it faces
significant challenges regarding privacy and identity management, particularly
when unknown individuals appear in the operational context. This paper presents
the design, implementation, and evaluation of a facial recognition system
within a federated learning framework tailored to open-set scenarios. The
proposed approach integrates the OpenMax algorithm into federated learning,
leveraging the exchange of mean activation vectors and local distance measures
to reliably distinguish between known and unknown subjects. Experimental
results validate the effectiveness of the proposed solution, demonstrating its
potential for enhancing privacy-aware and robust facial recognition in
distributed environments.
  --
  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado
una alta precisi\'on en algunos escenarios y aplicaciones. Sin embargo,
presenta desaf\'ios relacionados con la privacidad y la identificaci\'on de
personas, especialmente considerando que pueden aparecer sujetos desconocidos
para el sistema que lo implementa. En este trabajo, se propone el dise\~no,
implementaci\'on y evaluaci\'on de un sistema de reconocimiento facial en un
escenario de aprendizaje federado, orientado a conjuntos abiertos.
Concretamente, se dise\~na una soluci\'on basada en el algoritmo OpenMax para
escenarios de aprendizaje federado. La propuesta emplea el intercambio de los
vectores de activaci\'on promedio y distancias locales para identificar de
manera eficaz tanto personas conocidas como desconocidas. Los experimentos
realizados demuestran la implementaci\'on efectiva de la soluci\'on propuesta.

</details>


### [89] [Automated classification of natural habitats using ground-level imagery](https://arxiv.org/abs/2508.19314)
*Mahdis Tourian,Sareh Rowlands,Remy Vandaele,Max Fancourt,Rebecca Mein,Hywel T. P. Williams*

Main category: cs.CV

TL;DR: 基于地面照片的深度学习栖息地分类方法，使用DeepLabV3-ResNet101模型对18类栖息地进行分类，平均F1分数0.61，并提供网页应用工具


<details>
  <summary>Details</summary>
Motivation: 准确的地面栖息地分类对生物多样性保护、生态监测和土地利用规划至关重要，传统方法依赖卫星影像和野外验证，需要开发基于地面照片的大规模分类方法

Method: 与Natural England合作，使用'Living England'框架的18个栖息地类别，对地面照片进行预处理（调整大小、归一化、增强），使用重采样平衡训练数据，开发并微调DeepLabV3-ResNet101分类器，采用五折交叉验证

Result: 模型在18个栖息地类别上表现良好，平均F1分数0.61，视觉特征明显的类别（如裸土、泥沙和泥炭，裸沙）F1分数超过0.90，混合或模糊类别得分较低

Conclusion: 基于地面照片的深度学习方法在生态监测中具有巨大潜力，地面影像易于获取，这种计算方法在栖息地分类方面有许多潜在应用，为支持实践应用还提供了网页分类工具

Abstract: Accurate classification of terrestrial habitats is critical for biodiversity
conservation, ecological monitoring, and land-use planning. Several habitat
classification schemes are in use, typically based on analysis of satellite
imagery with validation by field ecologists. Here we present a methodology for
classification of habitats based solely on ground-level imagery (photographs),
offering improved validation and the ability to classify habitats at scale (for
example using citizen-science imagery). In collaboration with Natural England,
a public sector organisation responsible for nature conservation in England,
this study develops a classification system that applies deep learning to
ground-level habitat photographs, categorising each image into one of 18
classes defined by the 'Living England' framework. Images were pre-processed
using resizing, normalisation, and augmentation; re-sampling was used to
balance classes in the training data and enhance model robustness. We developed
and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label
to each photograph. Using five-fold cross-validation, the model demonstrated
strong overall performance across 18 habitat classes, with accuracy and
F1-scores varying between classes. Across all folds, the model achieved a mean
F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and
Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or
ambiguous classes scoring lower. These findings demonstrate the potential of
this approach for ecological monitoring. Ground-level imagery is readily
obtained, and accurate computational methods for habitat classification based
on such data have many potential applications. To support use by practitioners,
we also provide a simple web application that classifies uploaded images using
our model.

</details>


### [90] [MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)
*Ming Chen,Liyuan Cui,Wenyuan Zhang,Haoxian Zhang,Yan Zhou,Xiaohan Li,Xiaoqiang Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: 提出了一种基于自回归框架的交互式数字人视频生成系统，支持多模态输入控制（音频、姿态、文本）和低延迟流式生成，通过深度压缩自编码器实现64倍压缩比。


<details>
  <summary>Details</summary>
Motivation: 现有交互式数字人视频生成方法存在高延迟、计算成本高和可控性有限的问题，需要构建一个能够实时响应多样化输入信号的实用系统。

Method: 基于大型语言模型（LLM）构建自回归视频生成框架，接受多模态条件编码，通过扩散头去噪过程生成空间和语义一致的表示。构建了约20,000小时的大规模对话数据集，并引入深度压缩自编码器实现64倍压缩。

Result: 在双工对话、多语言人像合成和交互式世界模型等实验中，该方法展现出低延迟、高效率和细粒度多模态可控性的优势。

Conclusion: 该框架成功解决了交互式数字人视频生成中的延迟和可控性问题，为实时多模态交互应用提供了有效的解决方案。

Abstract: Recently, interactive digital human video generation has attracted widespread
attention and achieved remarkable progress. However, building such a practical
system that can interact with diverse input signals in real time remains
challenging to existing methods, which often struggle with high latency, heavy
computational cost, and limited controllability. In this work, we introduce an
autoregressive video generation framework that enables interactive multimodal
control and low-latency extrapolation in a streaming manner. With minimal
modifications to a standard large language model (LLM), our framework accepts
multimodal condition encodings including audio, pose, and text, and outputs
spatially and semantically coherent representations to guide the denoising
process of a diffusion head. To support this, we construct a large-scale
dialogue dataset of approximately 20,000 hours from multiple sources, providing
rich conversational scenarios for training. We further introduce a deep
compression autoencoder with up to 64$\times$ reduction ratio, which
effectively alleviates the long-horizon inference burden of the autoregressive
model. Extensive experiments on duplex conversation, multilingual human
synthesis, and interactive world model highlight the advantages of our approach
in low latency, high efficiency, and fine-grained multimodal controllability.

</details>


### [91] [Deep Data Hiding for ICAO-Compliant Face Images: A Survey](https://arxiv.org/abs/2508.19324)
*Jefferson David Rodriguez Chivata,Davide Ghiani,Simone Maurizio La Cava,Marco Micheletto,Giulia Orrù,Federico Lama,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 该论文调查数字水印和隐写术作为ICAO合规面部图像的防篡改解决方案，分析现有技术在身份验证系统中的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: ICAO标准面部图像虽然实现了全球互操作性，但也容易被用于图像篡改和深度伪造等恶意目的，传统实时检测方法无法提供捕获后的保护。

Method: 通过对现有数字水印和隐写术技术进行全面分析，评估这些方法在ICAO标准约束下的适用性和效果。

Result: 研究发现数字水印和隐写术能够在不影响ICAO合规性的前提下，为面部图像提供持续的防篡改验证能力。

Conclusion: 数字水印和隐写术是有效的补充解决方案，但需要在安全性和实用性之间进行权衡，为实际身份系统的安全部署提供指导。

Abstract: ICAO-compliant facial images, initially designed for secure biometric
passports, are increasingly becoming central to identity verification in a wide
range of application contexts, including border control, digital travel
credentials, and financial services. While their standardization enables global
interoperability, it also facilitates practices such as morphing and deepfakes,
which can be exploited for harmful purposes like identity theft and illegal
sharing of identity documents. Traditional countermeasures like Presentation
Attack Detection (PAD) are limited to real-time capture and offer no
post-capture protection. This survey paper investigates digital watermarking
and steganography as complementary solutions that embed tamper-evident signals
directly into the image, enabling persistent verification without compromising
ICAO compliance. We provide the first comprehensive analysis of
state-of-the-art techniques to evaluate the potential and drawbacks of the
underlying approaches concerning the applications involving ICAO-compliant
images and their suitability under standard constraints. We highlight key
trade-offs, offering guidance for secure deployment in real-world identity
systems.

</details>


### [92] [PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI](https://arxiv.org/abs/2508.19325)
*Haoyang Su,Jin-Yi Xiang,Shaohao Rui,Yifan Gao,Xingyu Chen,Tingxuan Yin,Xiaosong Wang,Lian-Ming Wu*

Main category: cs.CV

TL;DR: PRISM是一个自监督框架，整合心脏MRI影像和电子健康记录进行生存分析，在四个独立临床队列中超越传统方法和SOTA深度学习基线，发现了三个与心脏风险相关的影像特征。


<details>
  <summary>Details</summary>
Motivation: 准确预测主要不良心脏事件(MACE)是心血管预后的核心挑战，需要整合多模态数据来提升预测精度。

Method: PRISM通过运动感知多视图蒸馏提取时间同步的影像特征，并使用医学知识文本提示进行调制，整合非对比心脏电影MRI和结构化EHR数据进行生存分析。

Result: 在四个独立临床队列中，PRISM在内部和外部验证中均超越经典生存预测模型和最先进的深度学习基线，发现了三个与MACE风险相关的影像特征。

Conclusion: PRISM整合影像和EHR的表征为不同队列的心脏风险提供了有价值的见解，提示引导归因识别出高血压、糖尿病和吸烟是主要的临床和生理EHR风险因素。

Abstract: Accurate prediction of major adverse cardiac events (MACE) remains a central
challenge in cardiovascular prognosis. We present PRISM (Prompt-guided
Representation Integration for Survival Modeling), a self-supervised framework
that integrates visual representations from non-contrast cardiac cine magnetic
resonance imaging with structured electronic health records (EHRs) for survival
analysis. PRISM extracts temporally synchronized imaging features through
motion-aware multi-view distillation and modulates them using medically
informed textual prompts to enable fine-grained risk prediction. Across four
independent clinical cohorts, PRISM consistently surpasses classical survival
prediction models and state-of-the-art (SOTA) deep learning baselines under
internal and external validation. Further clinical findings demonstrate that
the combined imaging and EHR representations derived from PRISM provide
valuable insights into cardiac risk across diverse cohorts. Three distinct
imaging signatures associated with elevated MACE risk are uncovered, including
lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior
elevated focus during diastole. Prompt-guided attribution further identifies
hypertension, diabetes, and smoking as dominant contributors among clinical and
physiological EHR factors.

</details>


### [93] [EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.19349)
*Mahdieh Behjat Khatooni,Mohsen Soryani*

Main category: cs.CV

TL;DR: 提出EffNetViTLoRA模型，结合CNN和Vision Transformer，使用LoRA技术进行微调，在完整ADNI MRI数据集上实现AD、MCI和CN三分类，准确率达92.52%


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期诊断至关重要，MCI阶段诊断困难，现有研究多使用有限数据子集，需要更鲁棒和临床可靠的诊断模型

Method: 集成CNN和ViT捕获MRI图像的局部和全局特征，使用完整ADNI T1加权MRI数据集训练，采用LoRA技术有效适配预训练ViT模型

Result: 在完整ADNI数据集上实现三分类准确率92.52%，F1分数92.76%

Conclusion: EffNetViTLoRA模型通过综合方法提高了临床可靠性，LoRA技术实现了有效的知识迁移并降低了过拟合风险

Abstract: Alzheimer's disease (AD) is one of the most prevalent neurodegenerative
disorders worldwide. As it progresses, it leads to the deterioration of
cognitive functions. Since AD is irreversible, early diagnosis is crucial for
managing its progression. Mild Cognitive Impairment (MCI) represents an
intermediate stage between Cognitively Normal (CN) individuals and those with
AD, and is considered a transitional phase from normal cognition to Alzheimer's
disease. Diagnosing MCI is particularly challenging due to the subtle
differences between adjacent diagnostic categories. In this study, we propose
EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole
Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging
(MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a
Vision Transformer (ViT) to capture both local and global features from MRI
images. Unlike previous studies that rely on limited subsets of data, our
approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in
a more robust and unbiased model. This comprehensive methodology enhances the
model's clinical reliability. Furthermore, fine-tuning large pretrained models
often yields suboptimal results when source and target dataset domains differ.
To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt
the pretrained ViT model to our target domain. This method enables efficient
knowledge transfer and reduces the risk of overfitting. Our model achieves a
classification accuracy of 92.52% and an F1-score of 92.76% across three
diagnostic categories: AD, MCI, and CN for full ADNI dataset.

</details>


### [94] [Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage](https://arxiv.org/abs/2508.19477)
*Zachary L. Crang,Rich D. Johnston,Katie L. Mills,Johsan Billingham,Sam Robertson,Michael H. Cole,Jonathon Weakley,Adam Hewitt and,Grant M. Duthie*

Main category: cs.CV

TL;DR: 研究评估商业AI球员追踪软件使用转播画面测量位置、速度和距离的准确性，发现战术画面能提供最佳精度，720p和1080p分辨率都适用


<details>
  <summary>Details</summary>
Motivation: 了解商业计算机视觉和AI球员追踪软件使用转播画面测量球员位置、速度和距离的准确性，并确定摄像机画面和分辨率对准确性的影响

Method: 使用2022年卡塔尔世界杯比赛数据，比较三家商业追踪提供商与TRACAB Gen 5多摄像机追踪系统的数据，计算均方根误差和平均偏差

Result: 位置均方根误差1.68-16.39米，速度误差0.34-2.38 m/s，总比赛距离平均偏差-1745米(-21.8%)到1945米(24.3%)

Conclusion: 计算机视觉和AI球员追踪软件在检测到球员时具有良好精度，应使用战术画面追踪位置和速度以最大化球员检测，720p和1080p分辨率都适用

Abstract: This study aimed to: (1) understand whether commercially available
computer-vision and artificial intelligence (AI) player tracking software can
accurately measure player position, speed and distance using broadcast footage
and (2) determine the impact of camera feed and resolution on accuracy. Data
were obtained from one match at the 2022 Qatar Federation Internationale de
Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds
were used. Three commercial tracking providers that use computer-vision and AI
participated. Providers analysed instantaneous position (x, y coordinates) and
speed (m\,s^{-1}) of each player. Their data were compared with a
high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square
error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to
16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match
distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across
providers. Computer-vision and AI player tracking software offer the ability to
track players with fair precision when players are detected by the software.
Providers should use a tactical feed when tracking position and speed, which
will maximise player detection, improving accuracy. Both 720p and 1080p
resolutions are suitable, assuming appropriate computer-vision and AI models
are implemented.

</details>


### [95] [JVLGS: Joint Vision-Language Gas Leak Segmentation](https://arxiv.org/abs/2508.19485)
*Xinlong Zhao,Qixiang Pang,Shan Du*

Main category: cs.CV

TL;DR: 基于视觉-语言多模态融合的新框架JVLGS，通过结合图像和文本信息来提升气体泄漏分割的准确性，并加入后处理步骤降低误检


<details>
  <summary>Details</summary>
Motivation: 气体泄漏会对人体健康和环境造成严重威胁，但现有的红外视频检测方法因气体云模糊和非粗架性而效果有限

Method: 提出JVLGS框架，结合视觉和语言双模态的优势来增强气体泄漏表征和分割能力，并包含后处理步骤来减少噪声和非目标物体导致的误检

Result: 在多种场景下的实验显示，JVLGS在监督学习和少量样本学习设置下都显著超过了现有最优方法，而其他方法通常只在一种设置下表现良好或都表现较差

Conclusion: JVLGS框架通过多模态融合和后处理优化，为气体泄漏检测提供了更准确和稳健的解决方案，在不同学习场景下都保持了优异性能

Abstract: Gas leaks pose serious threats to human health and contribute significantly
to atmospheric pollution, drawing increasing public concern. However, the lack
of effective detection methods hampers timely and accurate identification of
gas leaks. While some vision-based techniques leverage infrared videos for leak
detection, the blurry and non-rigid nature of gas clouds often limits their
effectiveness. To address these challenges, we propose a novel framework called
Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the
complementary strengths of visual and textual modalities to enhance gas leak
representation and segmentation. Recognizing that gas leaks are sporadic and
many video frames may contain no leak at all, our method incorporates a
post-processing step to reduce false positives caused by noise and non-target
objects, an issue that affects many existing approaches. Extensive experiments
conducted across diverse scenarios show that JVLGS significantly outperforms
state-of-the-art gas leak segmentation methods. We evaluate our model under
both supervised and few-shot learning settings, and it consistently achieves
strong performance in both, whereas competing methods tend to perform well in
only one setting or poorly in both. Code available at:
https://github.com/GeekEagle/JVLGS

</details>


### [96] [UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models](https://arxiv.org/abs/2508.19498)
*Yimu Wang,Weiming Zhuang,Chen Chen,Jiabo Huang,Jingtao Li,Lingjuan Lyu*

Main category: cs.CV

TL;DR: UNIFORM是一个新颖的知识整合框架，能够从多样化的预训练模型中提取共识知识，无需对模型架构或训练数据分布做任何假设，显著提升了无监督目标识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识集成方法通常对训练数据分布和网络架构有强假设限制，只能从特定类型的模型中学习，导致数据和/或归纳偏差。如何有效利用在线大量异构预训练模型的集体知识成为一个根本性挑战。

Method: 提出了专门的投票机制，在logit层面（整合能够预测目标类别的教师模型）和特征层面（利用在任意标签空间学习的视觉表示）捕获知识共识，将多样化现成模型的知识转移到单一学生模型中。

Result: 大量实验表明，UNIFORM相比强知识迁移基线有效提升了无监督目标识别性能，具有显著的可扩展性，能够从100多个教师模型中受益，而现有方法在更小规模时就达到饱和。

Conclusion: UNIFORM框架成功解决了异构预训练模型知识整合的挑战，通过多层次的共识机制实现了高效的知识迁移，展示了在大规模教师模型集合上的优异可扩展性。

Abstract: In the era of deep learning, the increasing number of pre-trained models
available online presents a wealth of knowledge. These models, developed with
diverse architectures and trained on varied datasets for different tasks,
provide unique interpretations of the real world. Their collective consensus is
likely universal and generalizable to unseen data. However, effectively
harnessing this collective knowledge poses a fundamental challenge due to the
heterogeneity of pre-trained models. Existing knowledge integration solutions
typically rely on strong assumptions about training data distributions and
network architectures, limiting them to learning only from specific types of
models and resulting in data and/or inductive biases. In this work, we
introduce a novel framework, namely UNIFORM, for knowledge transfer from a
diverse set of off-the-shelf models into one student model without such
constraints. Specifically, we propose a dedicated voting mechanism to capture
the consensus of knowledge both at the logit level -- incorporating teacher
models that are capable of predicting target classes of interest -- and at the
feature level, utilizing visual representations learned on arbitrary label
spaces. Extensive experiments demonstrate that UNIFORM effectively enhances
unsupervised object recognition performance compared to strong knowledge
transfer baselines. Notably, it exhibits remarkable scalability by benefiting
from over one hundred teachers, while existing methods saturate at a much
smaller scale.

</details>


### [97] [Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery](https://arxiv.org/abs/2508.19499)
*Xiangxu Wang,Tianhong Zhao,Wei Tu,Bowen Zhang,Guanzhou Chen,Jinzhou Cao*

Main category: cs.CV

TL;DR: Sat2Flow是一个基于扩散模型的框架，仅使用卫星图像生成结构一致的OD流量矩阵，解决了现有方法对辅助数据和空间拓扑敏感性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有OD流量生成方法依赖昂贵的辅助特征（如POI、社会经济统计），且对空间拓扑敏感，区域索引重排序会破坏生成流量的结构一致性。

Method: 提出多核编码器捕捉区域交互，采用排列感知扩散过程确保不同区域排序下的潜在表示对齐，通过联合对比训练目标和等变扩散训练保证结构一致性。

Result: 在真实城市数据集上，Sat2Flow在数值精度上优于物理和数据驱动基线方法，同时在索引置换下保持经验分布和空间结构。

Conclusion: Sat2Flow为数据稀缺城市环境提供了可扩展的OD流量生成解决方案，消除了区域特定辅助数据依赖，同时保持结构不变性以实现稳健的移动性建模。

Abstract: Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.

</details>


### [98] [Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity](https://arxiv.org/abs/2508.19511)
*Alzayat Saleh,Shunsuke Hatano,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 该研究提出了一个诊断驱动的半监督框架，用于解决农业杂草自动管理中的环境挑战和数据标注成本问题，通过伪标签技术利用未标注数据提升模型鲁棒性，有效缓解了阴影偏差问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在真实农田环境中性能受限的两个关键问题：具有挑战性的环境条件和高昂的数据标注成本，特别是在入侵性杂草自动管理领域。

Method: 使用包含975张标注图像和10,000张未标注图像的独特数据集，首先建立强监督基线（ResNet分类和YOLO、RF-DETR检测），然后通过可解释性工具诊断发现普遍存在的"阴影偏差"问题，进而开发基于伪标签的半监督管道来利用未标注数据增强模型鲁棒性。

Result: 监督基线达到F1分数0.90和mAP50分数超过0.82；半监督框架不仅有效缓解了阴影偏差，还显著提高了召回率这一自动化喷洒系统中的关键指标；在低数据机制下的公开作物-杂草基准测试中验证了方法的有效性。

Conclusion: 该研究为精准农业复杂现实中的计算机视觉系统开发、诊断和改进提供了一个清晰且经过实地测试的框架，通过诊断驱动的半监督方法有效解决了实际应用中的关键挑战。

Abstract: The automated management of invasive weeds is critical for sustainable
agriculture, yet the performance of deep learning models in real-world fields
is often compromised by two factors: challenging environmental conditions and
the high cost of data annotation. This study tackles both issues through a
diagnostic-driven, semi-supervised framework. Using a unique dataset of
approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in
sugarcane, we first establish strong supervised baselines for classification
(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and
mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by
interpretability tools, uncovered a pervasive "shadow bias," where models
learned to misidentify shadows as vegetation. This diagnostic insight motivated
our primary contribution: a semi-supervised pipeline that leverages unlabeled
data to enhance model robustness. By training models on a more diverse set of
visual information through pseudo-labeling, this framework not only helps
mitigate the shadow bias but also provides a tangible boost in recall, a
critical metric for minimizing weed escapes in automated spraying systems. To
validate our methodology, we demonstrate its effectiveness in a low-data regime
on a public crop-weed benchmark. Our work provides a clear and field-tested
framework for developing, diagnosing, and improving robust computer vision
systems for the complex realities of precision agriculture.

</details>


### [99] [MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment](https://arxiv.org/abs/2508.19527)
*Zhiting Gao,Dan Song,Diqiong Jiang,Chao Xue,An-An Liu*

Main category: cs.CV

TL;DR: TMR++ Aligned Preference Optimization (TAPO) 和 MotionFLUX 框架解决了文本驱动运动生成中的语义对齐和推理效率问题，实现了实时高质量运动合成


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动运动生成方法在语言描述与运动语义的精确对齐方面存在困难，且多步推理效率低下，需要更高效的实时合成方案

Method: 提出TAPO框架通过迭代调整强化语义基础，对齐细微运动变化与文本修饰符；MotionFLUX基于确定性修正流匹配，构建噪声分布与运动空间之间的最优传输路径，实现实时合成

Result: 实验结果表明，TAPO和MotionFLUX组成的统一系统在语义一致性和运动质量方面优于最先进方法，同时显著加速生成速度

Conclusion: 该研究提供了一个高效的文本驱动运动生成解决方案，解决了语义对齐和实时合成的关键挑战，代码和预训练模型将发布

Abstract: Motion generation is essential for animating virtual characters and embodied
agents. While recent text-driven methods have made significant strides, they
often struggle with achieving precise alignment between linguistic descriptions
and motion semantics, as well as with the inefficiencies of slow, multi-step
inference. To address these issues, we introduce TMR++ Aligned Preference
Optimization (TAPO), an innovative framework that aligns subtle motion
variations with textual modifiers and incorporates iterative adjustments to
reinforce semantic grounding. To further enable real-time synthesis, we propose
MotionFLUX, a high-speed generation framework based on deterministic rectified
flow matching. Unlike traditional diffusion models, which require hundreds of
denoising steps, MotionFLUX constructs optimal transport paths between noise
distributions and motion spaces, facilitating real-time synthesis. The
linearized probability paths reduce the need for multi-step sampling typical of
sequential methods, significantly accelerating inference time without
sacrificing motion quality. Experimental results demonstrate that, together,
TAPO and MotionFLUX form a unified system that outperforms state-of-the-art
approaches in both semantic consistency and motion quality, while also
accelerating generation speed. The code and pretrained models will be released.

</details>


### [100] [CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning](https://arxiv.org/abs/2508.19542)
*Nannan Zhu,Yonghao Dong,Teng Wang,Xueqian Li,Shengjun Deng,Yijia Wang,Zheng Hong,Tiantian Geng,Guo Niu,Hanyan Huang,Xiongfei Yao,Shuaiwei Jiao*

Main category: cs.CV

TL;DR: CVBench是首个专门评估多视频关系推理能力的综合基准，包含1000个QA对，涵盖三个层次：跨视频对象关联、事件关联和复杂推理。测试发现当前MLLMs在多视频推理方面存在显著性能差距，顶级模型如GPT-4o在因果推理任务上仅达60%准确率，远低于人类的91%。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在单视频任务上表现良好，但在多视频推理能力方面研究不足，而这一能力对现实应用（如多摄像头监控、跨视频程序学习）至关重要。

Method: 构建CVBench基准，包含5个不同领域的视频集群，1000个QA对分为三个层次：对象关联、事件关联和复杂推理。评估了10+个领先MLLMs在零样本和思维链提示下的表现。

Result: 评估显示显著性能差距：最佳模型GPT-4o在因果推理任务上仅60%准确率，而人类达到91%。分析揭示了当前MLLM架构的根本瓶颈，包括跨视频上下文保持能力不足和重叠实体消歧能力差。

Conclusion: CVBench为诊断和推进多视频推理建立了严格框架，为下一代MLLMs提供了架构设计洞见。基准数据和评估代码已开源。

Abstract: While multimodal large language models (MLLMs) exhibit strong performance on
single-video tasks (e.g., video question answering), their ability across
multiple videos remains critically underexplored. However, this capability is
essential for real-world applications, including multi-camera surveillance and
cross-video procedural learning. To bridge this gap, we present CVBench, the
first comprehensive benchmark designed to assess cross-video relational
reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning
three hierarchical tiers: cross-video object association (identifying shared
entities), cross-video event association (linking temporal or causal event
chains), and cross-video complex reasoning (integrating commonsense and domain
knowledge). Built from five domain-diverse video clusters (e.g., sports, life
records), the benchmark challenges models to synthesise information across
dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including
GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought
prompting paradigms. Key findings reveal stark performance gaps: even top
models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,
compared to the 91% accuracy of human performance. Crucially, our analysis
reveals fundamental bottlenecks inherent in current MLLM architectures, notably
deficient inter-video context retention and poor disambiguation of overlapping
entities. CVBench establishes a rigorous framework for diagnosing and advancing
multi-video reasoning, offering architectural insights for next-generation
MLLMs.The data and evaluation code are available at
https://github.com/Hokhim2/CVBench.

</details>


### [101] [WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization](https://arxiv.org/abs/2508.19544)
*Eduardo Davalos,Yike Zhang,Namrata Srivastava,Yashvitha Thatigotla,Jorge A. Salas,Sara McFadden,Sun-Joo Cho,Amanda Goodwin,Ashwin TS,Gautam Biswas*

Main category: cs.CV

TL;DR: WebEyeTrack是一个在浏览器中运行的轻量级视线追踪框架，通过集成头部姿态估计和少量样本校准，实现了接近商业级眼动仪的精度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI视线估计方法虽然在基准测试中表现优异，但在实际应用中与商业眼动仪存在差距，且网络摄像头方法因头部运动导致精度不足，需要解决模型大小、推理时间和隐私等问题。

Method: 提出WebEyeTrack框架，在浏览器中直接集成轻量级SOTA视线估计模型，结合基于模型的头部姿态估计和仅需9个校准样本的少样本学习，实现设备端自适应学习。

Result: 在GazeCapture数据集上达到2.32厘米的误差范围，在iPhone 14上实现2.4毫秒的实时推理速度，性能达到SOTA水平。

Conclusion: WebEyeTrack成功解决了网络摄像头视线追踪的精度和实时性问题，为浏览器端眼动追踪提供了可行的解决方案，代码已开源。

Abstract: With advancements in AI, new gaze estimation methods are exceeding
state-of-the-art (SOTA) benchmarks, but their real-world application reveals a
gap with commercial eye-tracking solutions. Factors like model size, inference
time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking
methods lack sufficient accuracy, in particular due to head movement. To tackle
these issues, we introduce We bEyeTrack, a framework that integrates
lightweight SOTA gaze estimation models directly in the browser. It
incorporates model-based head pose estimation and on-device few-shot learning
with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new
users, achieving SOTA performance with an error margin of 2.32 cm on
GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.
Our open-source code is available at
https://github.com/RedForestAi/WebEyeTrack.

</details>


### [102] [Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](https://arxiv.org/abs/2508.20072)
*Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Liuao Pei,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo*

Main category: cs.CV

TL;DR: 本文提出了Discrete Diffusion VLA方法，使用离散扩散模型在单一Transformer中处理视觉-语言-动作任务，通过渐进式精炼和二次重掩码机制实现自适应解码顺序和错误修正，在多个基准测试中超越了自回归和连续扩散基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA解码器要么采用固定的自左向右自回归生成方式，要么在主干网络外附加连续的扩散或流匹配头，需要专门的训练和迭代采样，阻碍了统一、可扩展的架构发展。

Method: 提出离散扩散VLA方法，使用单一Transformer策略对离散化动作块进行建模，采用离散扩散和与VLM主干相同的交叉熵目标进行训练。通过自适应解码顺序和二次重掩码机制实现渐进式精炼。

Result: 在LIBERO上达到96.3%的平均成功率，在SimplerEnv Fractal上达到71.2%的视觉匹配率，在SimplerEnv Bridge上达到49.3%的整体性能，超越了自回归和连续扩散基线方法。

Conclusion: 离散扩散动作解码器支持精确的动作建模和一致的训练，为将VLA扩展到更大模型和数据集奠定了基础。

Abstract: Vision-Language-Action (VLA) models adapt large vision-language backbones to
map images and instructions to robot actions. However, prevailing VLA decoders
either generate actions autoregressively in a fixed left-to-right order or
attach continuous diffusion or flow matching heads outside the backbone,
demanding specialized training and iterative sampling that hinder a unified,
scalable architecture. We present Discrete Diffusion VLA, a single-transformer
policy that models discretized action chunks with discrete diffusion and is
trained with the same cross-entropy objective as the VLM backbone. The design
retains diffusion's progressive refinement paradigm while remaining natively
compatible with the discrete token interface of VLMs. Our method achieves an
adaptive decoding order that resolves easy action elements before harder ones
and uses secondary remasking to revisit uncertain predictions across refinement
rounds, which improves consistency and enables robust error correction. This
unified decoder preserves pretrained vision language priors, supports parallel
decoding, breaks the autoregressive bottleneck, and reduces the number of
function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,
71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv
Bridge, improving over both autoregressive and continuous diffusion baselines.
These findings indicate that discrete-diffusion action decoder supports precise
action modeling and consistent training, laying groundwork for scaling VLA to
larger models and datasets.

</details>


### [103] [MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery](https://arxiv.org/abs/2508.19555)
*Yu-Wei Zhang,Tongju Han,Lipeng Gao,Mingqiang Wei,Hui Liu,Changbao Li,Caiming Zhang*

Main category: cs.CV

TL;DR: MonoRelief V2是一个端到端模型，能够从单张图像中直接恢复2.5D浮雕，在复杂材质和光照变化下表现出色。相比仅使用合成数据训练的V1版本，V2通过结合真实数据提升了鲁棒性、准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像恢复2.5D浮雕时面临的复杂材质和光照变化挑战，以及真实数据获取困难的问题。

Method: 使用文本到图像生成模型生成约15,000张伪真实图像，并通过深度和法线预测融合获得深度伪标签；构建800个样本的小规模真实数据集；在伪真实和真实数据集上进行渐进式训练。

Result: 综合实验表明，该模型在深度和法线预测方面达到了最先进的性能，展现出在下游应用中的强大潜力。

Conclusion: MonoRelief V2通过结合伪真实和真实数据训练，显著提升了从单图像恢复2.5D浮雕的性能，为相关应用提供了有效的解决方案。

Abstract: This paper presents MonoRelief V2, an end-to-end model designed for directly
recovering 2.5D reliefs from single images under complex material and
illumination variations. In contrast to its predecessor, MonoRelief V1 [1],
which was solely trained on synthetic data, MonoRelief V2 incorporates real
data to achieve improved robustness, accuracy and efficiency. To overcome the
challenge of acquiring large-scale real-world dataset, we generate
approximately 15,000 pseudo real images using a text-to-image generative model,
and derive corresponding depth pseudo-labels through fusion of depth and normal
predictions. Furthermore, we construct a small-scale real-world dataset (800
samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is
then progressively trained on the pseudo-real and real-world datasets.
Comprehensive experiments demonstrate its state-of-the-art performance both in
depth and normal predictions, highlighting its strong potential for a range of
downstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.

</details>


### [104] [FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection](https://arxiv.org/abs/2508.19565)
*Yuhang Zhao,Zixing Wang*

Main category: cs.CV

TL;DR: FlowDet是一个基于DETR架构的高速端到端目标检测器，通过解耦编码器优化策略、几何可变形单元和尺度感知注意力模块，在Intersection-Flow-5k数据集上实现了SOTA性能，同时显著降低了计算成本和提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决端到端目标检测器在复杂场景（如交叉路口交通监控）中计算成本高的问题，为实时应用提供NMS-free的高效检测方案。

Method: 提出FlowDet检测器，采用解耦编码器优化策略，包含几何可变形单元(GDU)进行交通感知几何建模，以及尺度感知注意力(SAA)模块处理极端尺度变化。

Result: 在Intersection-Flow-5k数据集上，相比RT-DETR基线：AP提升1.5%，AP50提升1.6%，GFLOPs减少63.2%，推理速度提升16.2%。

Conclusion: FlowDet为构建高效准确的现实世界感知系统提供了新路径，在保持高精度的同时显著提升了计算效率。

Abstract: End-to-end object detectors offer a promising NMS-free paradigm for real-time
applications, yet their high computational cost remains a significant barrier,
particularly for complex scenarios like intersection traffic monitoring. To
address this challenge, we propose FlowDet, a high-speed detector featuring a
decoupled encoder optimization strategy applied to the DETR architecture.
Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for
traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to
maintain high representational power across extreme scale variations. To
rigorously evaluate the model's performance in environments with severe
occlusion and high object density, we collected the Intersection-Flow-5k
dataset, a new challenging scene for this task. Evaluated on
Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to
the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by
1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference
speed by 16.2%. Our work demonstrates a new path towards building highly
efficient and accurate detectors for demanding, real-world perception systems.
The Intersection-Flow-5k dataset is available at
https://github.com/AstronZh/Intersection-Flow-5K.

</details>


### [105] [DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection](https://arxiv.org/abs/2508.19573)
*Luhu Li,Bowen Lin,Mukhtiar Khan,Shujun Fu*

Main category: cs.CV

TL;DR: 提出结合可训练编码器、原型引导重建和多样性感知对齐损失的统一框架，解决医学图像异常检测中原型崩溃和领域适应问题，显著提升表示质量和异常定位性能


<details>
  <summary>Details</summary>
Motivation: 医学图像异常检测面临标注稀缺和领域差异挑战，现有重建方法依赖冻结预训练编码器限制了领域适应能力，原型学习方法存在原型崩溃问题影响多样性和泛化性

Method: 可训练编码器（含动量分支）实现稳定领域自适应特征学习；轻量级原型提取器挖掘信息丰富的正常原型，通过注意力机制指导解码器进行精确重建；多样性感知对齐损失通过多样性约束和逐原型归一化防止原型崩溃

Result: 在多个医学影像基准测试中显著提升了表示质量和异常定位性能，优于现有方法；可视化分析和原型分配验证了抗崩溃机制的有效性和增强的可解释性

Conclusion: 所提出的统一框架有效解决了原型崩溃问题，实现了更好的领域适应和异常检测性能，为医学图像分析提供了更可靠和可解释的解决方案

Abstract: Anomaly detection in medical images is challenging due to limited annotations
and a domain gap compared to natural images. Existing reconstruction methods
often rely on frozen pre-trained encoders, which limits adaptation to
domain-specific features and reduces localization accuracy. Prototype-based
learning offers interpretability and clustering benefits but suffers from
prototype collapse, where few prototypes dominate training, harming diversity
and generalization. To address this, we propose a unified framework combining a
trainable encoder with prototype-guided reconstruction and a novel
Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum
branch, enables stable domain-adaptive feature learning. A lightweight
Prototype Extractor mines informative normal prototypes to guide the decoder
via attention for precise reconstruction. Our loss enforces balanced prototype
use through diversity constraints and per-prototype normalization, effectively
preventing collapse. Experiments on multiple medical imaging benchmarks show
significant improvements in representation quality and anomaly localization,
outperforming prior methods. Visualizations and prototype assignment analyses
further validate the effectiveness of our anti-collapse mechanism and enhanced
interpretability.

</details>


### [106] [Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation](https://arxiv.org/abs/2508.19574)
*Mingxi Fu,Fanglei Fu,Xitong Ling,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: MPAMatch是一个新颖的多模态病理图像分割框架，通过图像和文本原型与像素标签的双重对比学习，在结构和语义层面提供监督，显著改善了语义边界建模。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像分割中语义边界模糊和像素级标注成本高的问题，现有方法主要依赖图像模态内的扰动一致性，难以捕获高层次语义先验。

Method: 提出MPAMatch框架，采用图像原型-像素标签和文本原型-像素标签的双重对比学习方案，重构TransUNet架构，使用病理预训练基础模型Uni作为backbone。

Result: 在GLAS、EBHI-SEG-GLAND、EBHI-SEG-CANCER和KPI数据集上的广泛实验显示，MPAMatch优于最先进方法，验证了其在结构和语义建模方面的双重优势。

Conclusion: MPAMatch通过多模态原型引导的监督范式，有效提升了病理图像分割的性能，特别是在语义边界建模方面取得了显著改进。

Abstract: Pathological image segmentation faces numerous challenges, particularly due
to ambiguous semantic boundaries and the high cost of pixel-level annotations.
Although recent semi-supervised methods based on consistency regularization
(e.g., UniMatch) have made notable progress, they mainly rely on
perturbation-based consistency within the image modality, making it difficult
to capture high-level semantic priors, especially in structurally complex
pathology images. To address these limitations, we propose MPAMatch - a novel
segmentation framework that performs pixel-level contrastive learning under a
multimodal prototype-guided supervision paradigm. The core innovation of
MPAMatch lies in the dual contrastive learning scheme between image prototypes
and pixel labels, and between text prototypes and pixel labels, providing
supervision at both structural and semantic levels. This coarse-to-fine
supervisory strategy not only enhances the discriminative capability on
unlabeled samples but also introduces the text prototype supervision into
segmentation for the first time, significantly improving semantic boundary
modeling. In addition, we reconstruct the classic segmentation architecture
(TransUNet) by replacing its ViT backbone with a pathology-pretrained
foundation model (Uni), enabling more effective extraction of
pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,
EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art
methods, validating its dual advantages in structural and semantic modeling.

</details>


### [107] [Interact-Custom: Customized Human Object Interaction Image Generation](https://arxiv.org/abs/2508.19575)
*Zhu Xu,Zhaowen Wang,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的任务CHOI（定制人物交互图像生成），重点解决了在保持目标实体身份的同时实现精细的交互控制。论文设计了Interact-Custom模型，通过两阶段方法先生成交互行为的前景掩码，然后在掩码指导下生成保持身份特征的人物交互图像。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要集中于目标实体的外观保持，而忽视了细粒度的交互控制。为了实现对多个目标实体之间交互关系的精确控制，需要开发能够同时满足身份保持和交互语义控制的方法。

Method: 首先处理大规模数据集，包含同一对人物在不同交互姿势下的样本。设计两阶段模型Interact-Custom：第一阶段显式建模空间配置，生成描述交互行为的前景掩码；第二阶段在掩码指导下生成保持身份特征的目标人物交互图像。还支持用户指定背景图像和位置。

Result: 在CHOI任务的尺度上进行了大量实验，证明了方法的有效性。实验结果显示该方法能够同时保持目标人物的身份特征和控制之间的交互语义。

Conclusion: 该研究成功地解决了定制图像生成中的人物交互控制问题，通过两阶段模型设计实现了空间配置的显式建模和身份特征的保持。该方法为细粒度交互控制提供了有效的解决方案，具有高内容可控性。

Abstract: Compositional Customized Image Generation aims to customize multiple target
concepts within generation content, which has gained attention for its wild
application.Existing approaches mainly concentrate on the target entity's
appearance preservation, while neglecting the fine-grained interaction control
among target entities.To enable the model of such interaction control
capability, we focus on human object interaction scenario and propose the task
of Customized Human Object Interaction Image Generation(CHOI), which
simultaneously requires identity preservation for target human object and the
interaction semantic control between them.Two primary challenges exist for
CHOI:(1)simultaneous identity preservation and interaction control demands
require the model to decompose the human object into self-contained identity
features and pose-oriented interaction features, while the current HOI image
datasets fail to provide ideal samples for such feature-decomposed
learning.(2)inappropriate spatial configuration between human and object may
lead to the lack of desired interaction semantics.To tackle it, we first
process a large-scale dataset, where each sample encompasses the same pair of
human object involving different interactive poses.Then we design a two-stage
model Interact-Custom, which firstly explicitly models the spatial
configuration by generating a foreground mask depicting the interaction
behavior, then under the guidance of this mask, we generate the target human
object interacting while preserving their identities features.Furthermore, if
the background image and the union location of where the target human object
should appear are provided by users, Interact-Custom also provides the optional
functionality to specify them, offering high content controllability. Extensive
experiments on our tailored metrics for CHOI task demonstrate the effectiveness
of our approach.

</details>


### [108] [High-Speed FHD Full-Color Video Computer-Generated Holography](https://arxiv.org/abs/2508.19579)
*Haomiao Zhang,Miao Cao,Xuan Yu,Hui Luo,Yanling Piao,Mengjie Qin,Zhangyuan Li,Ping Wang,Xin Yuan*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的高速全色视频全息生成方案，通过SGDDM技术解决高帧率显示中的颜色渗透问题，以及HoloMamba模型提高计算效率和重建质量


<details>
  <summary>Details</summary>
Motivation: 解决高速全息视频生成中的两大挑战：学习模型导致颜色渗透问题，以及帧间优化方法忽视空间-时间相关性造成计算效率低下

Method: 提出SGDDM技术通过频率调制优化相位分布，并设计HoloMamba轻量级非对称Mamba-Unet架构来显式建模视频序列的空间-时间相关性

Result: SGDDM实现了高保真全色显示而无需抑制帧率，HoloMamba能以260+FPS的速度生成FHD全色全息视频，速度比之前最好方法提高2.6倍

Conclusion: 该方案成功解决了高速全息视频生成的关键问题，在保持高帧率的同时提升了颜色保真度和计算效率，为下一代显示技术提供了有力支撑

Abstract: Computer-generated holography (CGH) is a promising technology for
next-generation displays. However, generating high-speed, high-quality
holographic video requires both high frame rate display and efficient
computation, but is constrained by two key limitations: ($i$) Learning-based
models often produce over-smoothed phases with narrow angular spectra, causing
severe color crosstalk in high frame rate full-color displays such as
depth-division multiplexing and thus resulting in a trade-off between frame
rate and color fidelity. ($ii$) Existing frame-by-frame optimization methods
typically optimize frames independently, neglecting spatial-temporal
correlations between consecutive frames and leading to computationally
inefficient solutions. To overcome these challenges, in this paper, we propose
a novel high-speed full-color video CGH generation scheme. First, we introduce
Spectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase
distributions via frequency modulation, enabling high-fidelity full-color
display at high frame rates. Second, we present HoloMamba, a lightweight
asymmetric Mamba-Unet architecture that explicitly models spatial-temporal
correlations across video sequences to enhance reconstruction quality and
computational efficiency. Extensive simulated and real-world experiments
demonstrate that SGDDM achieves high-fidelity full-color display without
compromise in frame rate, while HoloMamba generates FHD (1080p) full-color
holographic video at over 260 FPS, more than 2.6$\times$ faster than the prior
state-of-the-art Divide-Conquer-and-Merge Strategy.

</details>


### [109] [Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction](https://arxiv.org/abs/2508.19581)
*Dat Nguyen Cong,Hieu Tran Bao,Hoang Thanh-Tung*

Main category: cs.CV

TL;DR: 本文提出Score-based Discriminator Correction (SBDC)方法，通过判别器训练和对抗损失来校正预训练条件扩散模型中的标签噪声问题，提高生成质量和可控性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在大规模数据集上表现出色，但这些数据集往往包含人工标注错误。目前尚不清楚这些错误如何影响扩散模型的生成能力和可控性。

Method: 提出SBDC引导技术，基于判别器训练和对抗损失，利用先验噪声检测技术评估样本真实性，并将引导限制在生成过程的早期阶段。

Result: 在不同噪声设置下的实验表明，该方法优于现有最先进方法，计算效率高，仅略微增加推理时间，且无需重新训练扩散模型。

Conclusion: SBDC是一种有效的引导技术，能够显著改善存在标签噪声的扩散模型的性能，具有实用性和高效性。

Abstract: Diffusion models have gained prominence as state-of-the-art techniques for
synthesizing images and videos, particularly due to their ability to scale
effectively with large datasets. Recent studies have uncovered that these
extensive datasets often contain mistakes from manual labeling processes.
However, the extent to which such errors compromise the generative capabilities
and controllability of diffusion models is not well studied. This paper
introduces Score-based Discriminator Correction (SBDC), a guidance technique
for aligning noisy pre-trained conditional diffusion models. The guidance is
built on discriminator training using adversarial loss, drawing on prior noise
detection techniques to assess the authenticity of each sample. We further show
that limiting the usage of our guidance to the early phase of the generation
process leads to better performance. Our method is computationally efficient,
only marginally increases inference time, and does not require retraining
diffusion models. Experiments on different noise settings demonstrate the
superiority of our method over previous state-of-the-art methods.

</details>


### [110] [Generalizing Monocular 3D Object Detection](https://arxiv.org/abs/2508.19593)
*Abhinav Kumar*

Main category: cs.CV

TL;DR: 该论文针对单目3D目标检测的泛化性问题，提出了多种方法来提升模型在不同遮挡情况、数据集、物体大小和相机参数下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测在自动驾驶、增强现实等应用中至关重要，但现有模型在面对遮挡、新数据集、大物体检测和不同相机参数时泛化能力不足，需要解决这些泛化挑战。

Method: 1) 提出数学可微的GrooMeD-NMS处理遮挡问题；2) 探索深度等变(DEVIANT)骨干网络提升数据集泛化；3) 针对大物体检测提出基于分割的SeaBird方法；4) 数学分析相机高度外推问题并改进OOD设置下的泛化性能。

Result: 通过提出的多种方法，有效提升了单目3D目标检测模型在遮挡鲁棒性、跨数据集泛化、大物体检测精度以及不同相机参数下的性能表现。

Conclusion: 该研究系统性地解决了单目3D目标检测的多个泛化挑战，提出的方法为实际应用场景中的模型部署提供了有效的解决方案，推动了该领域的发展。

Abstract: Monocular 3D object detection (Mono3D) is a fundamental computer vision task
that estimates an object's class, 3D position, dimensions, and orientation from
a single image. Its applications, including autonomous driving, augmented
reality, and robotics, critically rely on accurate 3D environmental
understanding. This thesis addresses the challenge of generalizing Mono3D
models to diverse scenarios, including occlusions, datasets, object sizes, and
camera parameters. To enhance occlusion robustness, we propose a mathematically
differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we
explore depth equivariant (DEVIANT) backbones. We address the issue of large
object detection, demonstrating that it's not solely a data imbalance or
receptive field problem but also a noise sensitivity issue. To mitigate this,
we introduce a segmentation-based approach in bird's-eye view with dice loss
(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D
models to unseen camera heights and improve Mono3D generalization in such
out-of-distribution settings.

</details>


### [111] [Quantization Robustness to Input Degradations for Object Detection](https://arxiv.org/abs/2508.19600)
*Toghrul Karimov,Hassan Imani,Allan Kazakov*

Main category: cs.CV

TL;DR: 这篇论文通过实验研究评估了各种精度格式下YOLO检测模型的粗糖化粗鲁棒性，并提出了一种基于透度的校准策略，但该方法在大多数情况下并未实现一致的粗鲁性提升。


<details>
  <summary>Details</summary>
Motivation: 质量量化在资源受限设备上部署对象检测模型至关重要，但粒度降低对模型在实际环境中面对噪声、模糊、压缩等输入透度的粗鲁性影响并不明确，需要系统性研究。

Method: 对YOLO模型的多种规模（nano到extra-large）进行了精度格式对比（FP32、FP16、Dynamic UINT8、Static INT8），并提出了透度感知校准策略，在TensorRT校准过程中混入清润和合成透度图像。在COCO数据集上测试了七种透度条件和混合透度场景。

Result: Static INT8 TensorRT引擎在清润数据上实现了~1.5-3.3x速度提升，mAP50-95减少~3-7%，但透度感知校准在大多数模型和透度条件下并未实现一致的粗鲁性提升。仅在某些噪声条件下的较大规模模型中观察到显著改善。

Conclusion: 提高后训练量化模型的粗鲁性面临挑战，模型容量可能影响校准策略的效果。这些发现为在非受控环境中部署量化检测器提供了有价值的见解。

Abstract: Post-training quantization (PTQ) is crucial for deploying efficient object
detection models, like YOLO, on resource-constrained devices. However, the
impact of reduced precision on model robustness to real-world input
degradations such as noise, blur, and compression artifacts is a significant
concern. This paper presents a comprehensive empirical study evaluating the
robustness of YOLO models (nano to extra-large scales) across multiple
precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8
(TensorRT). We introduce and evaluate a degradation-aware calibration strategy
for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix
of clean and synthetically degraded images. Models were benchmarked on the COCO
dataset under seven distinct degradation conditions (including various types
and levels of noise, blur, low contrast, and JPEG compression) and a
mixed-degradation scenario. Results indicate that while Static INT8 TensorRT
engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop
(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did
not yield consistent, broad improvements in robustness over standard clean-data
calibration across most models and degradations. A notable exception was
observed for larger model scales under specific noise conditions, suggesting
model capacity may influence the efficacy of this calibration approach. These
findings highlight the challenges in enhancing PTQ robustness and provide
insights for deploying quantized detectors in uncontrolled environments. All
code and evaluation tables are available at https://github.com/AllanK24/QRID.

</details>


### [112] [IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.19604)
*Qizhe Fan,Chaoyu Liu,Zhonghua Qiao,Xiaoqin Shen*

Main category: cs.CV

TL;DR: 提出IELDM和IELFormer方法，通过逆演化层抑制扩散模型生成缺陷，提升域泛化语义分割性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的合成图像存在结构和语义缺陷，直接用于训练会导致分割模型性能下降和误差累积

Method: 1) IELDM：在生成过程中集成逆演化层，基于拉普拉斯先验突出空间不连续性和语义不一致性；2) IELFormer：将IEL嵌入分割网络解码器，并加入多尺度频率融合模块

Result: 在基准数据集上的大量实验表明，该方法相比现有方法实现了更优越的泛化性能

Conclusion: 逆演化层能有效抑制生成缺陷和伪影传播，多尺度频率融合增强了跨尺度语义一致性，显著提升了域泛化语义分割的性能

Abstract: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model
using labeled data from a source domain, with the goal of achieving robust
generalization to unseen target domains during inference. A common approach to
improve generalization is to augment the source domain with synthetic data
generated by diffusion models (DMs). However, the generated images often
contain structural or semantic defects due to training imperfections. Training
segmentation models with such flawed data can lead to performance degradation
and error accumulation. To address this issue, we propose to integrate inverse
evolution layers (IELs) into the generative process. IELs are designed to
highlight spatial discontinuities and semantic inconsistencies using
Laplacian-based priors, enabling more effective filtering of undesirable
generative patterns. Based on this mechanism, we introduce IELDM, an enhanced
diffusion-based data augmentation framework that can produce higher-quality
images. Furthermore, we observe that the defect-suppression capability of IELs
can also benefit the segmentation network by suppressing artifact propagation.
Based on this insight, we embed IELs into the decoder of the DGSS model and
propose IELFormer to strengthen generalization capability in cross-domain
scenarios. To further strengthen the model's semantic consistency across
scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,
which performs frequency-domain analysis to achieve structured integration of
multi-resolution features, thereby improving cross-scale coherence. Extensive
experiments on benchmark datasets demonstrate that our approach achieves
superior generalization performance compared to existing methods.

</details>


### [113] [Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model](https://arxiv.org/abs/2508.19626)
*Jiajun Sun,Zhen Yu,Siyuan Yan,Jason J. Ong,Zongyuan Ge,Lei Zhang*

Main category: cs.CV

TL;DR: LF-VAR是一个基于语言提示的皮肤图像可控合成模型，利用病变测量分数和类型标签生成高质量、临床相关的皮肤图像，在FID指标上比现有最佳方法提升6.3%


<details>
  <summary>Details</summary>
Motivation: 真实临床皮肤图像数据有限，现有合成方法生成的图像质量低且无法控制病变位置和类型，需要开发可控的高质量皮肤图像合成方法

Method: 使用多尺度病变聚焦的VQVAE编码图像为离散潜在表示，然后训练视觉自回归变换器进行图像合成，整合病变测量和类型作为条件嵌入

Result: 在七种病变类型上获得最佳FID分数（平均0.74），比之前SOTA方法提升6.3%

Conclusion: LF-VAR模型能够有效生成高保真度、临床相关的合成皮肤图像，实现了基于语言提示的可控皮肤合成

Abstract: Skin images from real-world clinical practice are often limited, resulting in
a shortage of training data for deep-learning models. While many studies have
explored skin image synthesis, existing methods often generate low-quality
images and lack control over the lesion's location and type. To address these
limitations, we present LF-VAR, a model leveraging quantified lesion
measurement scores and lesion type labels to guide the clinically relevant and
controllable synthesis of skin images. It enables controlled skin synthesis
with specific lesion characteristics based on language prompts. We train a
multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to
encode images into discrete latent representations for structured tokenization.
Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized
representations facilitates image synthesis. Lesion measurement from the lesion
region and types as conditional embeddings are integrated to enhance synthesis
fidelity. Our method achieves the best overall FID score (average 0.74) among
seven lesion types, improving upon the previous state-of-the-art (SOTA) by
6.3%. The study highlights our controllable skin synthesis model's
effectiveness in generating high-fidelity, clinically relevant synthetic skin
images. Our framework code is available at
https://github.com/echosun1996/LF-VAR.

</details>


### [114] [Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition](https://arxiv.org/abs/2508.19630)
*Xiaolei Wei,Yi Ouyang,Haibo Ye*

Main category: cs.CV

TL;DR: DQRoute是一个针对长尾视觉识别问题的模块化框架，通过难度感知优化和动态专家协作来提升性能，特别是在稀有和困难类别上。


<details>
  <summary>Details</summary>
Motivation: 长尾视觉识别不仅面临类别不平衡问题，还有不同类别学习难度差异的挑战。简单的基于频率的类别重加权方法往往忽略了那些本质上难以学习的类别。

Method: DQRoute首先基于预测不确定性和历史性能估计类别难度，用这个信号指导自适应损失加权的训练。架构上采用混合专家设计，每个专家专注于类别分布的不同区域。推理时通过专家特定的OOD检测器生成的置信度分数加权专家预测，实现无需集中路由器的输入自适应路由。所有组件以端到端方式联合训练。

Result: 在标准长尾基准测试中，DQRoute显著提升了性能，特别是在稀有和困难类别上。

Conclusion: 将难度建模与去中心化专家路由相结合具有显著优势，能够有效解决长尾识别中的类别不平衡和难度差异问题。

Abstract: Long-tailed visual recognition is challenging not only due to class imbalance
but also because of varying classification difficulty across categories. Simply
reweighting classes by frequency often overlooks those that are intrinsically
hard to learn. To address this, we propose \textbf{DQRoute}, a modular
framework that combines difficulty-aware optimization with dynamic expert
collaboration. DQRoute first estimates class-wise difficulty based on
prediction uncertainty and historical performance, and uses this signal to
guide training with adaptive loss weighting. On the architectural side, DQRoute
employs a mixture-of-experts design, where each expert specializes in a
different region of the class distribution. At inference time, expert
predictions are weighted by confidence scores derived from expert-specific OOD
detectors, enabling input-adaptive routing without the need for a centralized
router. All components are trained jointly in an end-to-end manner. Experiments
on standard long-tailed benchmarks demonstrate that DQRoute significantly
improves performance, particularly on rare and difficult classes, highlighting
the benefit of integrating difficulty modeling with decentralized expert
routing.

</details>


### [115] [Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception](https://arxiv.org/abs/2508.19638)
*Yang Li,Quan Yuan,Guiyang Luo,Xiaoyuan Fu,Rui Pan,Yujia Yang,Congzhang Shao,Yuewen Liu,Jinglin Li*

Main category: cs.CV

TL;DR: CoPLOT是一个新颖的协作感知框架，使用点级优化令牌来保留3D结构信息，通过语义感知令牌重排序、频率增强状态空间模型和邻域到自车对齐模块，在降低通信和计算开销的同时实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的协作感知方法通常使用2D鸟瞰图表示，丢弃了关键的细粒度3D结构线索，这些线索对于精确的目标识别和定位至关重要。

Method: 引入点级令牌作为中间表示，包含语义感知令牌重排序模块、频率增强状态空间模型和邻域到自车对齐模块，通过点原生处理流程生成紧凑且对齐的点级令牌序列。

Result: 在模拟和真实世界数据集上的广泛实验表明，CoPLOT优于最先进的模型，同时具有更低的通信和计算开销。

Conclusion: CoPLOT通过点级优化令牌有效解决了协作感知中3D结构信息丢失的问题，在保持低开销的同时显著提升了感知性能。

Abstract: Collaborative perception allows agents to enhance their perceptual
capabilities by exchanging intermediate features. Existing methods typically
organize these intermediate features as 2D bird's-eye-view (BEV)
representations, which discard critical fine-grained 3D structural cues
essential for accurate object recognition and localization. To this end, we
first introduce point-level tokens as intermediate representations for
collaborative perception. However, point-cloud data are inherently unordered,
massive, and position-sensitive, making it challenging to produce compact and
aligned point-level token sequences that preserve detailed structural
information. Therefore, we present CoPLOT, a novel Collaborative perception
framework that utilizes Point-Level Optimized Tokens. It incorporates a
point-native processing pipeline, including token reordering, sequence
modeling, and multi-agent spatial alignment. A semantic-aware token reordering
module generates adaptive 1D reorderings by leveraging scene-level and
token-level semantic information. A frequency-enhanced state space model
captures long-range sequence dependencies across both spatial and spectral
domains, improving the differentiation between foreground tokens and background
clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop
process, combining global agent-level correction with local token-level
refinement to mitigate localization noise. Extensive experiments on both
simulated and real-world datasets show that CoPLOT outperforms state-of-the-art
models, with even lower communication and computation overhead. Code will be
available at https://github.com/CheeryLeeyy/CoPLOT.

</details>


### [116] [UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks](https://arxiv.org/abs/2508.19647)
*Bikash Kumar Badatya,Vipul Baghel,Ravi Hegde*

Main category: cs.CV

TL;DR: 这篇论文提出了一种轻量级的无监督骨架基动作定位方法，通过空间-时间图神经网表征和动作动力学指标，在无需手动标注的情况下实现了与监督方法相当的性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的监督和弱监督动作定位方法需要大量标注数据和高容量模型，计算成本高且适应性差。需要一种轻量级、无监督的方案来解决细粒度动作定位的挑战。

Method: 使用Attention基础的空间-时间图卷积神经网网络(ASTGCN)在姿势序列去噪任务上进行预训练，学习内在运动动力学。推理时通过新的动作动力学指标(ADM)检测动作边界，该指标直接从低维ASTGCN嵌入中计算。

Result: 在DSV Diving数据集上达到均值精度(mAP)82.66%，平均定位延迟29.09毫秒，性能与监督方法相当。方法能够在不重新训练的情况下演示对未见演出视频的健壮通用性。

Conclusion: 该方法提供了一种高效、轻量级的无监督解决方案，适合嵌入式或动态环境中的实时动作分析系统。

Abstract: Fine-grained action localization in untrimmed sports videos presents a
significant challenge due to rapid and subtle motion transitions over short
durations. Existing supervised and weakly supervised solutions often rely on
extensive annotated datasets and high-capacity models, making them
computationally intensive and less adaptable to real-world scenarios. In this
work, we introduce a lightweight and unsupervised skeleton-based action
localization pipeline that leverages spatio-temporal graph neural
representations. Our approach pre-trains an Attention-based Spatio-Temporal
Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with
blockwise partitions, enabling it to learn intrinsic motion dynamics without
any manual labeling. At inference, we define a novel Action Dynamics Metric
(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects
motion boundaries by identifying inflection points in its curvature profile.
Our method achieves a mean Average Precision (mAP) of 82.66% and average
localization latency of 29.09 ms on the DSV Diving dataset, matching
state-of-the-art supervised performance while maintaining computational
efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving
footage without retraining, demonstrating its practical applicability for
lightweight, real-time action analysis systems in embedded or dynamic
environments.

</details>


### [117] [IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising](https://arxiv.org/abs/2508.19649)
*Dongjin Kim,Jaekyun Ko,Muhammad Kashif Ali,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于动态生成内核的迭代图像去噪方法，通过特征提取、全局统计和局部相关模块来预测像素级变化内核，实现了在训练噪声类型上的良好泛化性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习图像去噪方法对特定噪声分布的依赖性问题，提高对未见噪声类型和级别的泛化能力，避免过拟合现象。

Method: 使用特征提取模块获取噪声不变特征，通过全局统计和局部相关模块捐描噪声特征和结构相关性，内核预测模块根据这些线索生成像素级变化内核，并进行迭代去噪处理。

Result: 该简洁模型（约 0.04M 参数）在仅使用单一水平高斯噪声训练的情况下，在多种噪声类型和级别上都表现优异，显示了良好的泛化性能。

Conclusion: 迭代动态过滤方法为实际图像去噪应用提供了有前景的解决方案，在保持高效率的同时实现了优秀的恢复质量。

Abstract: Image denoising is a fundamental challenge in computer vision, with
applications in photography and medical imaging. While deep learning-based
methods have shown remarkable success, their reliance on specific noise
distributions limits generalization to unseen noise types and levels. Existing
approaches attempt to address this with extensive training data and high
computational resources but they still suffer from overfitting. To address
these issues, we conduct image denoising by utilizing dynamically generated
kernels via efficient operations. This approach helps prevent overfitting and
improves resilience to unseen noise. Specifically, our method leverages a
Feature Extraction Module for robust noise-invariant features, Global
Statistics and Local Correlation Modules to capture comprehensive noise
characteristics and structural correlations. The Kernel Prediction Module then
employs these cues to produce pixel-wise varying kernels adapted to local
structures, which are then applied iteratively for denoising. This ensures both
efficiency and superior restoration quality. Despite being trained on
single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse
noise types and levels, demonstrating the promise of iterative dynamic
filtering for practical image denoising.

</details>


### [118] [Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models](https://arxiv.org/abs/2508.19650)
*Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang*

Main category: cs.CV

TL;DR: Video-LevelGauge是一个专门评估大型视频语言模型位置偏见的基准测试，通过标准化探针和定制化上下文设置来系统分析模型性能，发现开源模型存在显著位置偏见，而商业模型表现更稳定。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准测试主要评估整体性能，忽略了位置偏见这一关键但未被充分探索的方面，需要专门工具来系统评估大型视频语言模型在不同位置的表现偏差。

Method: 采用标准化探针和定制化上下文设置，灵活控制上下文长度、探针位置和上下文类型；结合统计测量和形态模式识别的综合分析方法；包含438个手动策划视频，生成1,177个多选题和120个开放式问题。

Result: 评估27个最先进LVLM发现，许多领先开源模型存在显著位置偏见（通常表现为头部或邻近内容偏好），而Gemini2.5-Pro等商业模型在整个视频序列中表现一致稳定。

Conclusion: 该基准测试有效暴露了LVLM的位置偏见问题，为缓解偏见和指导模型改进提供了可行见解，特别是在上下文长度、上下文变化和模型规模方面的分析具有重要指导意义。

Abstract: Large video language models (LVLMs) have made notable progress in video
understanding, spurring the development of corresponding evaluation benchmarks.
However, existing benchmarks generally assess overall performance across entire
video sequences, overlooking nuanced behaviors such as contextual positional
bias, a critical yet under-explored aspect of LVLM performance. We present
Video-LevelGauge, a dedicated benchmark designed to systematically assess
positional bias in LVLMs. We employ standardized probes and customized
contextual setups, allowing flexible control over context length, probe
position, and contextual types to simulate diverse real-world scenarios. In
addition, we introduce a comprehensive analysis method that combines
statistical measures with morphological pattern recognition to characterize
bias. Our benchmark comprises 438 manually curated videos spanning multiple
types, yielding 1,177 high-quality multiple-choice questions and 120 open-ended
questions, validated for their effectiveness in exposing positional bias. Based
on these, we evaluate 27 state-of-the-art LVLMs, including both commercial and
open-source models. Our findings reveal significant positional biases in many
leading open-source models, typically exhibiting head or neighbor-content
preferences. In contrast, commercial models such as Gemini2.5-Pro show
impressive, consistent performance across entire video sequences. Further
analyses on context length, context variation, and model scale provide
actionable insights for mitigating bias and guiding model enhancement.

</details>


### [119] [Scalable Object Detection in the Car Interior With Vision Foundation Models](https://arxiv.org/abs/2508.19651)
*Bálint Mészáros,Ahmet Firintepe,Sebastian Schmidt,Stephan Günnemann*

Main category: cs.CV

TL;DR: 这篇论文提出了ODAL框架，通过分布式设计在车载系统与云端之间分配计算任务，解决车辆内部物体检测和定位的资源限制问题。细调后的ODAL-LLaVA模型在ODALbench指标上达刱89%，显著超过GPT-4o和基线模型。


<details>
  <summary>Details</summary>
Motivation: 车辆内部的AI任务（如物体识别和定位）对个人助手的响应质量至关重要，但车载系统的计算资源受限，届刻了直接在车辆中部署基础模型的可能性。

Method: 提出新题的ODAL框架，利用视觉基础模型通过分布式架构，将计算任务在车轻系统和云端之间分配。还提出了ODALbench评估指标，并比较了GPT-4o和LLaVA 1.5 7B模型，探索通过细调提升轻量模型性能的方法。

Result: 细调后的ODAL-LLaVA模型在ODALscore上达刱89%，比基线性能提升71%，超19%超过GPT-4o。同时在保持高检测准确性的情况下，显著减少了幻觉现象，ODALSNR指标是GPT-4o的三倍。

Conclusion: ODAL框架有望为车辆内部场景理解领域建立新标准，通过分布式设计有效解决了车载系统资源限制问题，细调后的轻量模型显示出优异的性能。

Abstract: AI tasks in the car interior like identifying and localizing externally
introduced objects is crucial for response quality of personal assistants.
However, computational resources of on-board systems remain highly constrained,
restricting the deployment of such solutions directly within the vehicle. To
address this limitation, we propose the novel Object Detection and Localization
(ODAL) framework for interior scene understanding. Our approach leverages
vision foundation models through a distributed architecture, splitting
computational tasks between on-board and cloud. This design overcomes the
resource constraints of running foundation models directly in the car. To
benchmark model performance, we introduce ODALbench, a new metric for
comprehensive assessment of detection and localization.Our analysis
demonstrates the framework's potential to establish new standards in this
domain. We compare the state-of-the-art GPT-4o vision foundation model with the
lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the
lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model
achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its
baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the
fine-tuned model maintains high detection accuracy while significantly reducing
hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

</details>


### [120] [Self-Rewarding Vision-Language Model via Reasoning Decomposition](https://arxiv.org/abs/2508.19652)
*Zongxia Li,Wenhao Yu,Chengsong Huang,Rui Liu,Zhenwen Liang,Fuxiao Liu,Jingxi Che,Dian Yu,Jordan Boyd-Graber,Haitao Mi,Dong Yu*

Main category: cs.CV

TL;DR: Vision-SR1是一种自奖励方法，通过强化学习改进视觉语言模型的视觉推理能力，无需外部视觉监督，有效减少视觉幻觉和语言捷径问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型存在视觉幻觉和语言捷径问题，现有方法依赖人工标注或外部模型监督，成本高且容易产生分布偏移。需要一种无需外部监督的自监督方法来改善视觉推理。

Method: 将VLM推理分解为视觉感知和语言推理两个阶段。首先让模型生成自包含的视觉感知，然后使用同一模型仅基于生成的感知进行语言推理来计算奖励，结合最终输出的监督进行训练。

Result: 实验表明Vision-SR1能够改善视觉推理能力，减少视觉幻觉现象，降低对语言捷径的依赖，在多种视觉语言任务上表现良好。

Conclusion: Vision-SR1通过自奖励机制有效解决了VLMs的视觉幻觉和语言捷径问题，提供了一种无需外部监督的视觉推理改进方法。

Abstract: Vision-Language Models (VLMs) often suffer from visual hallucinations, saying
things that are not actually in the image, and language shortcuts, where they
skip the visual part and just rely on text priors. These issues arise because
most post-training methods for VLMs rely on simple verifiable answer matching
and supervise only final outputs, leaving intermediate visual reasoning without
explicit guidance. As a result, VLMs receive sparse visual signals and often
learn to prioritize language-based reasoning over visual perception. To
mitigate this, some existing methods add visual supervision using human
annotations or distilled labels from external large models. However, human
annotations are labor-intensive and costly, and because external signals cannot
adapt to the evolving policy, they cause distributional shifts that can lead to
reward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method
that improves visual reasoning without relying on external visual supervisions
via reinforcement learning. Vision-SR1 decomposes VLM reasoning into two
stages: visual perception and language reasoning. The model is first prompted
to produce self-contained visual perceptions that are sufficient to answer the
question without referring back the input image. To validate this
self-containment, the same VLM model is then re-prompted to perform language
reasoning using only the generated perception as input to compute reward. This
self-reward is combined with supervision on final outputs, providing a balanced
training signal that strengthens both visual perception and language reasoning.
Our experiments demonstrate that Vision-SR1 improves visual reasoning,
mitigates visual hallucinations, and reduces reliance on language shortcuts
across diverse vision-language tasks.

</details>


### [121] [Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications](https://arxiv.org/abs/2508.19654)
*Matthias Höfflin,Jürgen Wassner*

Main category: cs.CV

TL;DR: 该研究比较了脉冲神经网络(SNN)和传统神经网络(ANN)在卫星位置估计任务中的能效表现，发现硬件感知分析显示SNN仅在神经形态硬件和高输入稀疏度下才能实现显著节能


<details>
  <summary>Details</summary>
Motivation: 尽管SNN被认为具有天然能效优势，但近期研究表明数字实现时这种优势可能被高估，需要更透明的评估方法来公平比较神经网络能效

Method: 使用LIF神经元膜电位进行多输出回归训练，比较硬件感知和硬件无关的能耗估计方法，分析输入稀疏度和暗像素比例对能耗的影响

Result: SNN在MSE性能上与参考CNN相当，硬件无关方法预测SNN有50-60%能效优势，但硬件感知分析显示仅在神经形态硬件和高输入稀疏度下才能实现显著节能

Conclusion: 需要透明的评估方法和明确披露底层假设来确保神经网络能效比较的公平性，数据特性和硬件假设对能耗有重要影响

Abstract: Spiking Neural Networks (SNNs), inspired by biological intelligence, have
long been considered inherently energy-efficient, making them attractive for
resource-constrained domains such as space applications. However, recent
comparative studies with conventional Artificial Neural Networks (ANNs) have
begun to question this reputation, especially for digital implementations. This
work investigates SNNs for multi-output regression, specifically 3-D satellite
position estimation from monocular images, and compares hardware-aware and
hardware-agnostic energy estimation methods. The proposed SNN, trained using
the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the
final layer, achieves comparable Mean Squared Error (MSE) to a reference
Convolutional Neural Network (CNN) on a photorealistic satellite dataset.
Energy analysis shows that while hardware-agnostic methods predict a consistent
50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals
that significant energy savings are realized only on neuromorphic hardware and
with high input sparsity. The influence of dark pixel ratio on energy
consumption is quantified, emphasizing the impact of data characteristics and
hardware assumptions. These findings highlight the need for transparent
evaluation methods and explicit disclosure of underlying assumptions to ensure
fair comparisons of neural network energy efficiency.

</details>


### [122] [A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement](https://arxiv.org/abs/2508.19664)
*Weicheng Liao,Zan Chen,Jianyang Xie,Yalin Zheng,Yuhui Ma,Yitian Zhao*

Main category: cs.CV

TL;DR: 提出了一种针对超广角视网膜图像的自监督频率感知增强方法，通过频率解耦去模糊和Retinex引导的照明补偿模块，有效提升图像质量并改善疾病诊断性能


<details>
  <summary>Details</summary>
Motivation: 超广角视网膜成像虽然提供了全面的视网膜视图，但经常受到模糊和照明不均等质量退化因素的影响，现有方法无法满足UWF图像对病理细节保护的特殊需求

Method: 采用频率感知自监督学习方法，包含频率解耦图像去模糊模块（使用非对称通道整合操作结合全局和局部视图）和Retinex引导照明补偿模块（包含颜色保护单元提供多尺度空间和频率信息）

Result: 实验结果表明该方法不仅提升了可视化质量，还通过恢复和校正精细局部细节及不均匀强度改善了疾病诊断性能

Conclusion: 这是首个针对超广角视网膜图像增强的工作，为改善视网膜疾病管理提供了强大且具有临床价值的工具

Abstract: Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics
by providing a comprehensive view of the retina. However, it often suffers from
quality-degrading factors such as blurring and uneven illumination, which
obscure fine details and mask pathological information. While numerous retinal
image enhancement methods have been proposed for other fundus imageries, they
often fail to address the unique requirements in UWF, particularly the need to
preserve pathological details. In this paper, we propose a novel
frequency-aware self-supervised learning method for UWF image enhancement. It
incorporates frequency-decoupled image deblurring and Retinex-guided
illumination compensation modules. An asymmetric channel integration operation
is introduced in the former module, so as to combine global and local views by
leveraging high- and low-frequency information, ensuring the preservation of
fine and broader structural details. In addition, a color preservation unit is
proposed in the latter Retinex-based module, to provide multi-scale spatial and
frequency information, enabling accurate illumination estimation and
correction. Experimental results demonstrate that the proposed work not only
enhances visualization quality but also improves disease diagnosis performance
by restoring and correcting fine local details and uneven intensity. To the
best of our knowledge, this work is the first attempt for UWF image
enhancement, offering a robust and clinically valuable tool for improving
retinal disease management.

</details>


### [123] [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](https://arxiv.org/abs/2508.19688)
*Gangjian Zhang,Jian Shu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: SAT是一个两阶段的单目纹理3D人体重建框架，通过统一学习多种几何先验和在线动画增强，解决了单视图几何模糊性和3D训练数据稀缺的问题，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单目3D人体重建面临单张2D图像的几何模糊性和3D训练数据稀缺的挑战。现有方法虽然使用多种几何先验（如SMPL模型和法线图），但难以有效整合这些模态，导致视角不一致和面部扭曲等问题。

Method: 提出两阶段框架SAT：1）统一学习多种几何先验；2）引入监督特征正则化模块，使用多视图网络提供中间特征作为训练监督；3）提出在线动画增强模块，通过前馈动画网络从原始3D数据在线生成大量训练样本。

Result: 在两个基准测试上的大量实验表明，该方法在重建质量方面优于最先进的方法，能够生成高质量的纹理3D虚拟形象。

Conclusion: SAT框架通过统一学习几何先验、特征正则化和在线数据增强，有效解决了单目3D人体重建中的几何模糊性和数据稀缺问题，实现了高质量的3D人体重建。

Abstract: Monocular texture 3D human reconstruction aims to create a complete 3D
digital avatar from just a single front-view human RGB image. However, the
geometric ambiguity inherent in a single 2D image and the scarcity of 3D human
training data are the main obstacles limiting progress in this field. To
address these issues, current methods employ prior geometric estimation
networks to derive various human geometric forms, such as the SMPL model and
normal maps. However, they struggle to integrate these modalities effectively,
leading to view inconsistencies, such as facial distortions. To this end, we
propose a two-process 3D human reconstruction framework, SAT, which seamlessly
learns various prior geometries in a unified manner and reconstructs
high-quality textured 3D avatars as the final output. To further facilitate
geometry learning, we introduce a Supervisor Feature Regularization module. By
employing a multi-view network with the same structure to provide intermediate
features as training supervision, these varied geometric priors can be better
fused. To tackle data scarcity and further improve reconstruction quality, we
also propose an Online Animation Augmentation module. By building a
one-feed-forward animation network, we augment a massive number of samples from
the original 3D human data online for model training. Extensive experiments on
two benchmarks show the superiority of our approach compared to
state-of-the-art methods.

</details>


### [124] [Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators](https://arxiv.org/abs/2508.19698)
*V. S. Usatyuk,D. A. Sapozhnikov,S. I. Egorov*

Main category: cs.CV

TL;DR: 提出了一种基于物理启发的无监督合成图像检测方法，通过将图像特征转换为多边类型QC-LDPC图，利用Nishimori温度校准的随机键Ising模型和Bethe-Hessian谱特征来区分真实和合成图像。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型（如GANs和扩散模型）生成的图像几乎与真实照片无法区分，这威胁到媒体取证和生物识别安全。现有监督检测器对未见过的生成器或对抗后处理效果不佳，而无监督方法依赖低层统计特征且脆弱。

Method: 使用预训练CNN提取图像特征并降维至32维，将特征向量作为多边类型QC-LDPC图的节点。通过Nishimori温度校准成对相似性作为边耦合，构建随机键Ising模型，分析其Bethe-Hessian谱的特征间隙来检测合成图像。

Result: 在猫vs狗和男性vs女性的二分类任务中，使用Flickr-Faces-HQ和CelebA的真实照片以及GANs和扩散模型生成的合成图像进行验证，无需标记合成数据或重新训练特征提取器，检测准确率超过94%。

Conclusion: 该方法提供了一种新颖的LDPC图构建方式，建立了Nishimori温度RBIM与Bethe-Hessian谱之间的解析联系，提供了贝叶斯最优检测准则，是一个实用的、对新型生成架构鲁棒的无监督合成图像检测器。

Abstract: The rapid advance of deep generative models such as GANs and diffusion
networks now produces images that are virtually indistinguishable from genuine
photographs, undermining media forensics and biometric security. Supervised
detectors quickly lose effectiveness on unseen generators or after adversarial
post-processing, while existing unsupervised methods that rely on low-level
statistical cues remain fragile. We introduce a physics-inspired,
model-agnostic detector that treats synthetic-image identification as a
community-detection problem on a sparse weighted graph. Image features are
first extracted with pretrained CNNs and reduced to 32 dimensions, each feature
vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities
are transformed into edge couplings calibrated at the Nishimori temperature,
producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum
exhibits a characteristic gap when genuine community structure (real images) is
present. Synthetic images violate the Nishimori symmetry and therefore lack
such gaps. We validate the approach on binary tasks cat versus dog and male
versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic
counterparts generated by GANs and diffusion models. Without any labeled
synthetic data or retraining of the feature extractor, the detector achieves
over 94% accuracy. Spectral analysis shows multiple well separated gaps for
real image sets and a collapsed spectrum for generated ones. Our contributions
are threefold: a novel LDPC graph construction that embeds deep image features,
an analytical link between Nishimori temperature RBIM and the Bethe-Hessian
spectrum providing a Bayes optimal detection criterion; and a practical,
unsupervised synthetic image detector robust to new generative architectures.
Future work will extend the framework to video streams and multi-class anomaly
detection.

</details>


### [125] [LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation](https://arxiv.org/abs/2508.19699)
*Yupeng Zhang,Dezhi Zheng,Ping Lu,Han Zhang,Lei Wang,Liping xiang,Cheng Luo,Kaijun Deng,Xiaowen Fu,Linlin Shen,Jinbao Wang*

Main category: cs.CV

TL;DR: LabelGS通过在3D高斯表示中引入跨视角一致的语义掩码和遮挡分析模型，为3D高斯溅射添加对象标签分割能力，实现了高效的3D场景分割


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射(3DGS)虽然具有高保真重建和高效渲染能力，但缺乏3D分割能力，限制了其在需要场景理解任务中的应用

Method: 提出LabelGS方法，包含遮挡分析模型避免优化过程中的过拟合、主高斯标记模型将2D语义先验提升到3D高斯、高斯投影过滤器避免标签冲突，并采用随机区域采样策略

Result: 在3D场景分割任务中优于包括Feature-3DGS在内的最先进方法，在1440×1080分辨率下训练速度比Feature-3DGS快22倍

Conclusion: LabelGS成功为3D高斯表示添加了分割能力，实现了高斯表示的有效解耦，显著提高了3DGS优化过程的效率

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation
for 3D scenes, offering both high-fidelity reconstruction and efficient
rendering. However, 3DGS lacks 3D segmentation ability, which limits its
applicability in tasks that require scene understanding. The identification and
isolating of specific object components is crucial. To address this limitation,
we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments
the Gaussian representation with object label.LabelGS introduces cross-view
consistent semantic masks for 3D Gaussians and employs a novel Occlusion
Analysis Model to avoid overfitting occlusion during optimization, Main
Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian
Projection Filter to avoid Gaussian label conflict. Our approach achieves
effective decoupling of Gaussian representations and refines the 3DGS
optimization process through a random region sampling strategy, significantly
improving efficiency. Extensive experiments demonstrate that LabelGS
outperforms previous state-of-the-art methods, including Feature-3DGS, in the
3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup
in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code
will be at https://github.com/garrisonz/LabelGS.

</details>


### [126] [FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation](https://arxiv.org/abs/2508.19705)
*Qiang Hu,Ying Zhou,Gepeng Ji,Nick Barnes,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 本文提出FreeVPS方法，通过将视频息肉分割重新构建为检测-跟踪范式，利用SAM2的时序建模能力，并引入两个无需训练模块来解决误差累积问题，在领域内外场景均取得先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频息肉分割方法在时空建模和领域泛化之间难以平衡，限制了在真实临床场景中的应用。SAM2在长时序息肉跟踪中存在误差累积问题，影响分割稳定性。

Method: 采用检测-跟踪范式，结合图像息肉分割模型的空间上下文和SAM2的时序建模能力。提出两个无需训练模块：内部关联过滤模块消除检测阶段的空间误差，减少假阳性；外部关联优化模块自适应更新记忆库防止误差传播，增强时序一致性。

Result: 在领域内和领域外场景均达到先进性能，在长未剪辑结肠镜视频中展现出强大的跟踪能力。

Conclusion: FreeVPS通过协同工作的两个模块稳定了SAM2，展示了在可靠临床分析中的潜在应用价值，为视频息肉分割提供了有效的解决方案。

Abstract: Existing video polyp segmentation (VPS) paradigms usually struggle to balance
between spatiotemporal modeling and domain generalization, limiting their
applicability in real clinical scenarios. To embrace this challenge, we recast
the VPS task as a track-by-detect paradigm that leverages the spatial contexts
captured by the image polyp segmentation (IPS) model while integrating the
temporal modeling capabilities of segment anything model 2 (SAM2). However,
during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error
accumulation, resulting in a snowball effect that compromises segmentation
stability. We mitigate this issue by repurposing SAM2 as a video polyp
segmenter with two training-free modules. In particular, the intra-association
filtering module eliminates spatial inaccuracies originating from the detecting
stage, reducing false positives. The inter-association refinement module
adaptively updates the memory bank to prevent error propagation over time,
enhancing temporal coherence. Both modules work synergistically to stabilize
SAM2, achieving cutting-edge performance in both in-domain and out-of-domain
scenarios. Furthermore, we demonstrate the robust tracking capabilities of
FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential
reliable clinical analysis.

</details>


### [127] [Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning](https://arxiv.org/abs/2508.19730)
*Stelios Mylonas,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 基于人脸基础模型的鲁棒视频深度伪造检测框架，通过自监督学习和多数据集集成训练，结合三元组损失和属性监督，显著提升泛化能力


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术日益逼真和普及，对媒体真实性和信息完整性构成严重威胁。现有检测模型在训练分布外的真实场景中泛化能力不足，需要开发更鲁棒的检测方法

Method: 利用FSFM自监督人脸基础模型，在多种深度伪造数据集（人脸交换和重演）上进行集成微调。采用三元组损失变体增强真假样本的嵌入可分性，并探索基于操纵类型或源数据集的属性监督方案

Result: 在多样化评估基准上的广泛实验表明，该方法在具有挑战性的真实世界场景中表现出色，特别是在泛化能力方面取得显著效果

Conclusion: 该框架通过利用人脸基础模型的丰富表示能力和多数据集集成训练，结合先进的损失函数和监督方案，为深度伪造检测提供了有效的解决方案，特别是在真实世界应用场景中展现出强大的泛化性能

Abstract: The increasing realism and accessibility of deepfakes have raised critical
concerns about media authenticity and information integrity. Despite recent
advances, deepfake detection models often struggle to generalize beyond their
training distributions, particularly when applied to media content found in the
wild. In this work, we present a robust video deepfake detection framework with
strong generalization that takes advantage of the rich facial representations
learned by face foundation models. Our method is built on top of FSFM, a
self-supervised model trained on real face data, and is further fine-tuned
using an ensemble of deepfake datasets spanning both face-swapping and
face-reenactment manipulations. To enhance discriminative power, we incorporate
triplet loss variants during training, guiding the model to produce more
separable embeddings between real and fake samples. Additionally, we explore
attribution-based supervision schemes, where deepfakes are categorized by
manipulation type or source dataset, to assess their impact on generalization.
Extensive experiments across diverse evaluation benchmarks demonstrate the
effectiveness of our approach, especially in challenging real-world scenarios.

</details>


### [128] [POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection](https://arxiv.org/abs/2508.19742)
*Chenguang Liu,Chisheng Wang,Yuhua Cai,Chuanhua Zhu,Qingquan Li*

Main category: cs.CV

TL;DR: POEv2是一个改进的像素方向估计方法，可用于通用线段检测和线框线段检测，结合高效边缘检测器在三个公开数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有线段检测器分为通用线段检测器和线框线段检测器两类，由于设计目标不同，两者在对方任务上表现不佳，需要一种能同时处理两种检测任务的鲁棒框架

Method: 提出POEv2方法，从边缘强度图中检测线段，可与任何边缘检测器结合使用，是原始POE方法的改进版本

Result: 通过与高效边缘检测器结合，在三个公开数据集上实现了最先进的性能

Conclusion: POEv2提供了一个统一的框架，能够有效处理通用线段检测和线框线段检测两种任务，具有很好的实用性和性能表现

Abstract: Line segment detection in images has been studied for several decades.
Existing line segment detectors can be roughly divided into two categories:
generic line segment detectors and wireframe line segment detectors. Generic
line segment detectors aim to detect all meaningful line segments in images and
traditional approaches usually fall into this category. Recent deep learning
based approaches are mostly wireframe line segment detectors. They detect only
line segments that are geometrically meaningful and have large spatial support.
Due to the difference in the aim of design, the performance of generic line
segment detectors for the task of wireframe line segment detection won't be
satisfactory, and vice versa. In this work, we propose a robust framework that
can be used for both generic line segment detection and wireframe line segment
detection. The proposed method is an improved version of the Pixel Orientation
Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments
from edge strength maps, and can be combined with any edge detector. We show in
our experiments that by combining the proposed POEv2 with an efficient edge
detector, it achieves state-of-the-art performance on three publicly available
datasets.

</details>


### [129] [SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection](https://arxiv.org/abs/2508.19746)
*Qiyao Xu,Qiming Wu,Xiaowei Li*

Main category: cs.CV

TL;DR: SPLF-SAM是一个自提示光场分割模型，通过统一多尺度特征嵌入块和多尺度自适应滤波适配器，解决了传统方法忽略提示信息提取和频域信息分析的问题，在光场显著目标检测任务中优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有SAM模型在光场显著目标检测中忽略了提示信息的提取，传统模型忽视了频域信息分析，导致小目标被噪声淹没。

Method: 提出了SPLF-SAM模型，包含统一多尺度特征嵌入块(UMFEB)用于识别不同尺寸目标，和多尺度自适应滤波适配器(MAFA)通过学习频率特征防止小目标被噪声淹没。

Result: 在十个最先进的光场显著目标检测方法上进行了广泛实验，证明了该方法的优越性。

Conclusion: SPLF-SAM通过创新的多尺度特征嵌入和频域滤波技术，有效解决了光场显著目标检测中的关键问题，性能优于现有方法。

Abstract: Segment Anything Model (SAM) has demonstrated remarkable capabilities in
solving light field salient object detection (LF SOD). However, most existing
models tend to neglect the extraction of prompt information under this task.
Meanwhile, traditional models ignore the analysis of frequency-domain
information, which leads to small objects being overwhelmed by noise. In this
paper, we put forward a novel model called self-prompting light field segment
anything model (SPLF-SAM), equipped with unified multi-scale feature embedding
block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is
capable of identifying multiple objects of varying sizes, while MAFA, by
learning frequency features, effectively prevents small objects from being
overwhelmed by noise. Extensive experiments have demonstrated the superiority
of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be
available at https://github.com/XucherCH/splfsam.

</details>


### [130] [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](https://arxiv.org/abs/2508.19754)
*Yue Wu,Yufan Wu,Wen Li,Yuxi Lu,Kairui Feng,Xuanhong Chen*

Main category: cs.CV

TL;DR: FastAvatar是一个前馈式3D头像重建框架，能够在几秒内利用单张图像、多视角观测或单目视频等多样化日常记录，通过单一统一模型重建高质量的3D高斯溅射模型。


<details>
  <summary>Details</summary>
Motivation: 当前3D头像重建面临时间复杂度过高、对数据质量敏感以及数据利用率低等挑战，需要一种能够灵活利用各种输入数据并实现快速高质量重建的解决方案。

Method: 采用大型高斯重建变换器，包含三个关键设计：变体VGGT式变换器架构聚合多帧线索并注入初始3D提示；多粒度引导编码缓解动画引起的错位；通过地标跟踪和切片融合损失实现增量高斯聚合。

Result: 大量实验表明，FastAvatar相比现有方法具有更高的重建质量和极具竞争力的速度表现。

Conclusion: FastAvatar实现了质量-速度可调范式，为高可用性头像建模提供了有效解决方案，支持增量重建并充分利用输入数据。

Abstract: Despite significant progress in 3D avatar reconstruction, it still faces
challenges such as high time complexity, sensitivity to data quality, and low
data utilization. We propose FastAvatar, a feedforward 3D avatar framework
capable of flexibly leveraging diverse daily recordings (e.g., a single image,
multi-view observations, or monocular video) to reconstruct a high-quality 3D
Gaussian Splatting (3DGS) model within seconds, using only a single unified
model. FastAvatar's core is a Large Gaussian Reconstruction Transformer
featuring three key designs: First, a variant VGGT-style transformer
architecture aggregating multi-frame cues while injecting initial 3D prompt to
predict an aggregatable canonical 3DGS representation; Second, multi-granular
guidance encoding (camera pose, FLAME expression, head pose) mitigating
animation-induced misalignment for variable-length inputs; Third, incremental
Gaussian aggregation via landmark tracking and sliced fusion losses.
Integrating these features, FastAvatar enables incremental reconstruction,
i.e., improving quality with more observations, unlike prior work wasting input
data. This yields a quality-speed-tunable paradigm for highly usable avatar
modeling. Extensive experiments show that FastAvatar has higher quality and
highly competitive speed compared to existing methods.

</details>


### [131] [BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions](https://arxiv.org/abs/2508.19762)
*Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher*

Main category: cs.CV

TL;DR: BuzzSet是一个新的大规模传粉昆虫图像数据集，包含7856张高分辨率图像和8000多个标注实例，用于支持自动化传粉昆虫监测。


<details>
  <summary>Details</summary>
Motivation: 传粉昆虫对全球粮食生产和生态系统稳定至关重要，但其种群数量因人为和环境压力而下降，需要可扩展的自动化监测方法。

Method: 使用YOLOv12模型生成初始标注并通过人工验证完善，所有图像预处理为256×256切片，采用RF-DETR基于transformer的目标检测器建立基线模型。

Result: 模型在蜜蜂和熊蜂类别上分别获得0.94和0.92的高F1分数，混淆矩阵显示类别间误分类极少，最佳mAP@0.50为0.559。

Conclusion: BuzzSet为小目标检测、标签噪声下的类别分离和生态计算机视觉提供了有价值的基准数据集。

Abstract: Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
increasing anthropogenic and environmental stressors. To support scalable,
automated pollinator monitoring, we introduce BuzzSet, a new large-scale
dataset of high-resolution pollinator images collected in real agricultural
field conditions. BuzzSet contains 7856 manually verified and labeled images,
with over 8000 annotated instances across three classes: honeybees, bumblebees,
and unidentified insects. Initial annotations were generated using a YOLOv12
model trained on external data and refined via human verification using
open-source labeling tools. All images were preprocessed into 256~$\times$~256
tiles to improve the detection of small insects. We provide strong baselines
using the RF-DETR transformer-based object detector. The model achieves high
F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,
with confusion matrix results showing minimal misclassification between these
categories. The unidentified class remains more challenging due to label
ambiguity and lower sample frequency, yet still contributes useful insights for
robustness evaluation. Overall detection quality is strong, with a best
mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object
detection, class separation under label noise, and ecological computer vision.

</details>


### [132] [AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning](https://arxiv.org/abs/2508.19769)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 本文提出了自适应网络内调制（AIM）方法来解决多模态学习中的优化偏差问题，通过解耦主导模态的欠优化参数并自适应调整调制强度，实现平衡的多模态学习而不抑制任何模态。


<details>
  <summary>Details</summary>
Motivation: 现有的不平衡多模态学习方法通常通过抑制主导模态来促进较弱模态，这会降低整体多模态性能。研究发现这是由于网络内部的优化偏差问题被忽视导致的。

Method: AIM方法将主导模态的欠优化参数解耦到辅助块中，鼓励在联合训练中依赖这些性能下降的块与较弱模态一起训练。同时根据网络深度的模态不平衡程度自适应调整每个深度的调制强度。

Result: 实验结果表明，AIM在多个基准测试中优于最先进的不平衡模态学习方法，并在不同骨干网络、融合策略和优化器上表现出强大的泛化能力。

Conclusion: AIM首次实现了在不抑制主导或较弱模态的情况下实现平衡的多模态学习，有效解决了网络内部优化偏差问题，为多模态学习提供了新的解决方案。

Abstract: Multimodal learning has significantly enhanced machine learning performance
but still faces numerous challenges and limitations. Imbalanced multimodal
learning is one of the problems extensively studied in recent works and is
typically mitigated by modulating the learning of each modality. However, we
find that these methods typically hinder the dominant modality's learning to
promote weaker modalities, which affects overall multimodal performance. We
analyze the cause of this issue and highlight a commonly overlooked problem:
optimization bias within networks. To address this, we propose Adaptive
Intra-Network Modulation (AIM) to improve balanced modality learning. AIM
accounts for differences in optimization state across parameters and depths
within the network during modulation, achieving balanced multimodal learning
without hindering either dominant or weak modalities for the first time.
Specifically, AIM decouples the dominant modality's under-optimized parameters
into Auxiliary Blocks and encourages reliance on these performance-degraded
blocks for joint training with weaker modalities. This approach effectively
prevents suppression of weaker modalities while enabling targeted optimization
of under-optimized parameters to improve the dominant modality. Additionally,
AIM assesses modality imbalance level across network depths and adaptively
adjusts modulation strength at each depth. Experimental results demonstrate
that AIM outperforms state-of-the-art imbalanced modality learning methods
across multiple benchmarks and exhibits strong generalizability across
different backbones, fusion strategies, and optimizers.

</details>


### [133] [The Return of Structural Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.19773)
*Jakob Seitz,Tobias Lengfeld,Radu Timofte*

Main category: cs.CV

TL;DR: 本文提出了一种手写数学表达式结构识别方法，通过自动标注系统和模块化识别系统，实现了符号到轨迹的显式对齐，在CROHME-2023基准测试中取得竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于编码器-解码器架构的大语言模型虽然擅长生成LaTeX，但缺乏符号到轨迹的显式对齐，这限制了错误分析、可解释性以及需要选择性内容更新的空间感知交互应用。

Method: 1) 使用神经网络将LaTeX方程映射到原始轨迹的自动标注系统，自动生成符号分割、分类和空间关系注释；2) 独立优化分割、分类和关系预测的模块化结构识别系统，结合基于图的轨迹排序、混合卷积-循环网络和基于transformer的校正。

Result: 在CROHME-2023基准测试中取得了竞争性性能，系统生成完整的图结构，直接链接手写轨迹到预测符号。

Conclusion: 该方法实现了符号到轨迹的显式对齐，支持透明的错误分析和可解释输出，为教育技术应用提供了重要基础。

Abstract: Handwritten Mathematical Expression Recognition is foundational for
educational technologies, enabling applications like digital note-taking and
automated grading. While modern encoder-decoder architectures with large
language models excel at LaTeX generation, they lack explicit symbol-to-trace
alignment, a critical limitation for error analysis, interpretability, and
spatially aware interactive applications requiring selective content updates.
This paper introduces a structural recognition approach with two innovations: 1
an automatic annotation system that uses a neural network to map LaTeX
equations to raw traces, automatically generating annotations for symbol
segmentation, classification, and spatial relations, and 2 a modular structural
recognition system that independently optimizes segmentation, classification,
and relation prediction. By leveraging a dataset enriched with structural
annotations from our auto-labeling system, the proposed recognition system
combines graph-based trace sorting, a hybrid convolutional-recurrent network,
and transformer-based correction to achieve competitive performance on the
CROHME-2023 benchmark. Crucially, our structural recognition system generates a
complete graph structure that directly links handwritten traces to predicted
symbols, enabling transparent error analysis and interpretable outputs.

</details>


### [134] [MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.19786)
*Han Jiao,Jiakai Sun,Yexing Xu,Lei Zhao,Wei Xing,Huaizhong Lin*

Main category: cs.CV

TL;DR: MAPo框架通过动态评分分割策略，将3D高斯分为高动态和低动态部分，对高动态部分进行时间分割和网络复制以捕捉精细运动，同时使用跨帧一致性损失确保视觉连续性，在保持计算效率的同时显著提升动态场景重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于变形的3D高斯泼溅方法在动态场景重建中往往产生模糊渲染结果，特别是在高动态区域丢失精细运动细节，这是因为单一统一模型难以表示多样化的运动模式。

Method: 提出动态评分分割策略区分高动态和低动态3D高斯；对高动态高斯进行递归时间分割并为每个时间段复制变形网络；低动态高斯作为静态处理以减少计算成本；引入跨帧一致性损失解决分割边界处的视觉不连续问题。

Result: 大量实验表明，MAPo在保持可比计算成本的同时，相比基线方法实现了更优越的渲染质量，特别是在具有复杂或快速运动的区域表现突出。

Conclusion: MAPo框架通过运动感知分割和跨帧一致性约束，有效解决了动态3D高斯泼溅中的运动细节丢失和视觉不连续问题，为高保真动态场景重建提供了有效解决方案。

Abstract: 3D Gaussian Splatting, known for enabling high-quality static scene
reconstruction with fast rendering, is increasingly being applied to dynamic
scene reconstruction. A common strategy involves learning a deformation field
to model the temporal changes of a canonical set of 3D Gaussians. However,
these deformation-based methods often produce blurred renderings and lose fine
motion details in highly dynamic regions due to the inherent limitations of a
single, unified model in representing diverse motion patterns. To address these
challenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian
Splatting (MAPo), a novel framework for high-fidelity dynamic scene
reconstruction. Its core is a dynamic score-based partitioning strategy that
distinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D
Gaussians, we recursively partition them temporally and duplicate their
deformation networks for each new temporal segment, enabling specialized
modeling to capture intricate motion details. Concurrently, low-dynamic 3DGs
are treated as static to reduce computational costs. However, this temporal
partitioning strategy for high-dynamic 3DGs can introduce visual
discontinuities across frames at the partition boundaries. To address this, we
introduce a cross-frame consistency loss, which not only ensures visual
continuity but also further enhances rendering quality. Extensive experiments
demonstrate that MAPo achieves superior rendering quality compared to baselines
while maintaining comparable computational costs, particularly in regions with
complex or rapid motions.

</details>


### [135] [StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation](https://arxiv.org/abs/2508.19789)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.CV

TL;DR: StableIntrinsic是一种单步扩散模型，用于多视角材质估计，能够以低方差生成高质量材质参数，在PSNR和MSE指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的材质估计方法采用多步去噪策略，计算耗时且存在随机性推断与确定性材质估计任务之间的冲突，导致估计结果方差较高。

Method: 提出单步扩散模型StableIntrinsic，在像素空间应用基于材质特性的损失函数，并引入细节注入网络(DIN)来消除VAE编码造成的细节损失，增强材质预测结果的清晰度。

Result: 实验结果表明，该方法在albedo的PSNR上提升9.9%，金属性和粗糙度的MSE分别降低44.4%和60.0%，超越了当前最先进技术。

Conclusion: StableIntrinsic通过单步扩散框架和专门的细节增强机制，有效解决了多步扩散模型的时间消耗和方差问题，为材质估计任务提供了更高效和稳定的解决方案。

Abstract: Recovering material information from images has been extensively studied in
computer graphics and vision. Recent works in material estimation leverage
diffusion model showing promising results. However, these diffusion-based
methods adopt a multi-step denoising strategy, which is time-consuming for each
estimation. Such stochastic inference also conflicts with the deterministic
material estimation task, leading to a high variance estimated results. In this
paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view
material estimation that can produce high-quality material parameters with low
variance. To address the overly-smoothing problem in one-step diffusion,
StableIntrinsic applies losses in pixel space, with each loss designed based on
the properties of the material. Additionally, StableIntrinsic introduces a
Detail Injection Network (DIN) to eliminate the detail loss caused by VAE
encoding, while further enhancing the sharpness of material prediction results.
The experimental results indicate that our method surpasses the current
state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak
Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error
(MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.

</details>


### [136] [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](https://arxiv.org/abs/2508.19791)
*Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 本文研究文本到图像生成中多对象颜色属性的语义对齐问题，提出了一种专门的图像编辑技术来解决多颜色提示的语义偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成方法在处理复杂多对象提示时难以准确捕捉精确语义，特别是在颜色属性方面存在显著挑战。现有方法主要使用粗粒度指标或人工评估，难以进行大规模评估。

Method: 通过对颜色属性进行案例研究，开发了一种专门的图像编辑技术，针对包含多种颜色的提示解决多对象语义对齐问题。

Result: 研究表明预训练模型在处理多颜色属性时表现远不如单颜色提示，现有的推理时技术和编辑方法都无法可靠解决这些语义偏差。提出的方法在各种指标上显著提升了性能。

Conclusion: 该研究为解决文本到图像生成中的多对象语义对齐问题提供了有效的解决方案，特别是在颜色属性处理方面取得了显著改进。

Abstract: Text-to-image generation has recently seen remarkable success, granting users
with the ability to create high-quality images through the use of text.
However, contemporary methods face challenges in capturing the precise
semantics conveyed by complex multi-object prompts. Consequently, many works
have sought to mitigate such semantic misalignments, typically via
inference-time schemes that modify the attention layers of the denoising
networks. However, prior work has mostly utilized coarse metrics, such as the
cosine similarity between text and image CLIP embeddings, or human evaluations,
which are challenging to conduct on a larger-scale. In this work, we perform a
case study on colors -- a fundamental attribute commonly associated with
objects in text prompts, which offer a rich test bed for rigorous evaluation.
Our analysis reveals that pretrained models struggle to generate images that
faithfully reflect multiple color attributes-far more so than with single-color
prompts-and that neither inference-time techniques nor existing editing methods
reliably resolve these semantic misalignments. Accordingly, we introduce a
dedicated image editing technique, mitigating the issue of multi-object
semantic alignment for prompts containing multiple colors. We demonstrate that
our approach significantly boosts performance over a wide range of metrics,
considering images generated by various text-to-image diffusion-based
techniques.

</details>


### [137] [FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization](https://arxiv.org/abs/2508.19798)
*Muhammad Ali,Omar Ali AlSuwaidi*

Main category: cs.CV

TL;DR: 通过继承编码器-解码器结构的增强神经网络架构，集成全面注意力块、Mamba注意力和数据融合块，大幅提升了非生物降解废弃物分类的准确性和效率


<details>
  <summary>Details</summary>
Motivation: 废弃管理领域中，非生物降解材料的自动分类遇到重大挑战，主要是因为废弃流的复杂性和变异性。需要提高分类系统的准确性和效率

Method: 基于编码器-解码器结构构建增强神经网络，集成了三个关键创新：1)解码器中的全面注意力块，通过卷积和上采样操作精炼特征表示；2)Mamba架构的注意力机制；3)数据融合块，使用PCA变换降低高维数据的维度同时保留关键信息

Result: 在RGB、超谱、多谱以及RGB与超谱数据组合上进行评估，结果显示该方法显著超越了现有方法

Conclusion: 该增强神经网络架构通过多重注意力机制和数据融合技术，有效解决了废弃分类中的复杂性问题，为废弃管理自动化提供了高效的技术方案

Abstract: In the realm of waste management, automating the sorting process for
non-biodegradable materials presents considerable challenges due to the
complexity and variability of waste streams. To address these challenges, we
introduce an enhanced neural architecture that builds upon an existing
Encoder-Decoder structure to improve the accuracy and efficiency of waste
sorting systems. Our model integrates several key innovations: a Comprehensive
Attention Block within the decoder, which refines feature representations by
combining convolutional and upsampling operations. In parallel, we utilize
attention through the Mamba architecture, providing an additional performance
boost. We also introduce a Data Fusion Block that fuses images with more than
three channels. To achieve this, we apply PCA transformation to reduce the
dimensionality while retaining the maximum variance and essential information
across three dimensions, which are then used for further processing. We
evaluated the model on RGB, hyperspectral, multispectral, and a combination of
RGB and hyperspectral data. The results demonstrate that our approach
outperforms existing methods by a significant margin.

</details>


### [138] [A bag of tricks for real-time Mitotic Figure detection](https://arxiv.org/abs/2508.19804)
*Christian Marzahl,Brian Napora*

Main category: cs.CV

TL;DR: 这篇论文提出了一系列训练技巧，通过RTMDet单阶段检测器实现了高效准确的有丝切除图识别，在多域数据集上获得了F1分0.78-0.84的结果，适合临床部署。


<details>
  <summary>Details</summary>
Motivation: 解决组织学图像中有丝切除图识别的挑战，包括扫描仪变异、染色协议、组织类型和工件影响等问题，需要开发稳健且实时的检测方法。

Method: 基于RTMDet单阶段对象检测器，采用多域训练数据、平衡采样、谨慎数据增强、以及针对坏死和细胞残弃组织的难例挖掘技术来减少假阻性。

Result: 在多个MF数据集上进行分组5折交叉验证，F1分数范围0.78-0.84。在MIDOG 2025挑战试验集上达到0.81的F1分数，超过更大模型并显示了对新域的适应能力。

Conclusion: 该方法在准确性和速度之间取得了平衡，提供了一种适合实际临床部署的实用解决方案，能够有效处理不同扫描仪和组织类型带来的挑战。

Abstract: Mitotic figure (MF) detection in histopathology images is challenging due to
large variations in slide scanners, staining protocols, tissue types, and the
presence of artifacts. This paper presents a collection of training techniques
- a bag of tricks - that enable robust, real-time MF detection across diverse
domains. We build on the efficient RTMDet single stage object detector to
achieve high inference speed suitable for clinical deployment. Our method
addresses scanner variability and tumor heterogeneity via extensive
multi-domain training data, balanced sampling, and careful augmentation.
Additionally, we employ targeted, hard negative mining on necrotic and debris
tissue to reduce false positives. In a grouped 5-fold cross-validation across
multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On
the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025
challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,
outperforming larger models and demonstrating adaptability to new, unfamiliar
domains. The proposed solution offers a practical trade-off between accuracy
and speed, making it attractive for real-world clinical adoption.

</details>


### [139] [Context-aware Sparse Spatiotemporal Learning for Event-based Vision](https://arxiv.org/abs/2508.19806)
*Shenqi Wang,Guangzhi Tang*

Main category: cs.CV

TL;DR: 提出CSSL框架，通过上下文感知阈值动态调节神经元激活，在事件相机视觉任务中实现高稀疏性和优异性能


<details>
  <summary>Details</summary>
Motivation: 现有事件处理方法未能充分利用事件数据的稀疏性，而脉冲神经网络在复杂视觉任务中性能不足，且实现高激活稀疏性需要复杂的手动调参

Method: 提出上下文感知稀疏时空学习(CSSL)框架，使用上下文感知阈值技术根据输入分布动态调节神经元激活，无需显式稀疏约束即可自然降低激活密度

Result: 在事件相机目标检测和光流估计任务中，CSSL达到或超越了最先进方法的性能，同时保持了极高的神经元稀疏性

Conclusion: CSSL框架为神经形态处理实现高效的事件视觉提供了关键解决方案，在保持高性能的同时显著提升了计算效率

Abstract: Event-based camera has emerged as a promising paradigm for robot perception,
offering advantages with high temporal resolution, high dynamic range, and
robustness to motion blur. However, existing deep learning-based event
processing methods often fail to fully leverage the sparse nature of event
data, complicating their integration into resource-constrained edge
applications. While neuromorphic computing provides an energy-efficient
alternative, spiking neural networks struggle to match of performance of
state-of-the-art models in complex event-based vision tasks, like object
detection and optical flow. Moreover, achieving high activation sparsity in
neural networks is still difficult and often demands careful manual tuning of
sparsity-inducing loss terms. Here, we propose Context-aware Sparse
Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware
thresholding to dynamically regulate neuron activations based on the input
distribution, naturally reducing activation density without explicit sparsity
constraints. Applied to event-based object detection and optical flow
estimation, CSSL achieves comparable or superior performance to
state-of-the-art methods while maintaining extremely high neuronal sparsity.
Our experimental results highlight CSSL's crucial role in enabling efficient
event-based vision for neuromorphic processing.

</details>


### [140] [AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment](https://arxiv.org/abs/2508.19808)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一个无监督视频实例分割框架，通过质量引导的自训练方法，在不需要人工标注的情况下实现了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割需要像素级掩码和时间一致性标注，标注成本高昂。现有无监督方法依赖合成数据但存在合成到真实域的差距问题。

Method: 建立伪标签生成和自动质量评估的闭环系统，通过质量引导的自训练从合成视频逐步适应到真实视频。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，比之前的SOTA VideoCutLER提升4.4%，且无需人工标注。

Conclusion: 质量感知的自训练方法对于无监督视频实例分割是可行的有效方案。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due
to its dual requirements of pixel-level masks and temporal consistency labels.
While recent unsupervised methods like VideoCutLER eliminate optical flow
dependencies through synthetic data, they remain constrained by the
synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised
framework that bridges this gap through quality-guided self-training. Our
approach establishes a closed-loop system between pseudo-label generation and
automatic quality assessment, enabling progressive adaptation from synthetic to
real videos. Experiments demonstrate state-of-the-art performance with 52.6
$\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous
state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations.
This demonstrates the viability of quality-aware self-training for unsupervised
VIS. The source code of our method is available at
https://github.com/wcbup/AutoQ-VIS.

</details>


### [141] [ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images](https://arxiv.org/abs/2508.19815)
*Linkuan Zhou,Zhexin Chen,Yufei Shen,Junlin Xu,Ping Xuan,Yixin Zhu,Yuqi Fang,Cong Cong,Leyi Wei,Ran Su,Jia Zhou,Qiangguo Jin*

Main category: cs.CV

TL;DR: 提出ERSR半监督框架用于胎儿头部超声分割，通过双评分自适应过滤、椭圆约束伪标签精炼和对称性多一致性正则化，在HC18和PSFH数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 胎儿头部超声自动分割对产前监测至关重要，但由于超声图像质量差和标注数据缺乏，现有半监督方法难以生成可靠伪标签和实施有效一致性约束

Method: ERSR框架包含：1）双评分自适应过滤策略（边界一致性和轮廓规则性评估）；2）椭圆约束伪标签精炼（最小二乘椭圆拟合）；3）对称性多一致性正则化（多层级一致性约束）

Result: 在HC18数据集上，使用10%和20%标注数据分别达到92.05%和95.36%的Dice分数；在PSFH数据集上分别达到91.68%和93.70%

Conclusion: 该方法能有效处理胎儿头部超声图像的特殊性，生成更可靠的伪标签并实施有效的一致性约束，显著提升分割性能

Abstract: Automated segmentation of the fetal head in ultrasound images is critical for
prenatal monitoring. However, achieving robust segmentation remains challenging
due to the poor quality of ultrasound images and the lack of annotated data.
Semi-supervised methods alleviate the lack of annotated data but struggle with
the unique characteristics of fetal head ultrasound images, making it
challenging to generate reliable pseudo-labels and enforce effective
consistency regularization constraints. To address this issue, we propose a
novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.
Our framework consists of the dual-scoring adaptive filtering strategy, the
ellipse-constrained pseudo-label refinement, and the symmetry-based multiple
consistency regularization. The dual-scoring adaptive filtering strategy uses
boundary consistency and contour regularity criteria to evaluate and filter
teacher outputs. The ellipse-constrained pseudo-label refinement refines these
filtered outputs by fitting least-squares ellipses, which strengthens pixels
near the center of the fitted ellipse and suppresses noise simultaneously. The
symmetry-based multiple consistency regularization enforces multi-level
consistency across perturbed images, symmetric regions, and between original
predictions and pseudo-labels, enabling the model to capture robust and stable
shape representations. Our method achieves state-of-the-art performance on two
benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%
with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores
are 91.68% and 93.70% under the same settings.

</details>


### [142] [Gradient Rectification for Robust Calibration under Distribution Shift](https://arxiv.org/abs/2508.19830)
*Yilin Zhang,Cai Xu,You Wu,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的深度网络检查框架，通过频域视角和梯度校正机制，在不需要目标域信息的情况下改善分布偏移时的模型检查性能。


<details>
  <summary>Details</summary>
Motivation: 深度网络在安全关键应用中存在过信任预测问题，特别是在分布偏移情况下检查性更差。现有方法需要目标域信息或模拟，在实际应用中有限。

Method: 从频域角度出发，识别分布偏移对高频视觉线索的影响，采用低频筛波策略促进模型依赖域不变特征，并通过梯度基于校正机制确保内部分布检查性。

Result: 在CIFAR-10/100-C和WILDS等合成和实际偏移数据集上的实验表明，该方法在分布偏移条件下显著改善了检查性，同时保持了强劲的内部分布性能。

Conclusion: 该研究提供了一种无需目标域信息的实用化检查方案，通过频域分析和校正机制有效解决了分布偏移下的模型过信任问题。

Abstract: Deep neural networks often produce overconfident predictions, undermining
their reliability in safety-critical applications. This miscalibration is
further exacerbated under distribution shift, where test data deviates from the
training distribution due to environmental or acquisition changes. While
existing approaches improve calibration through training-time regularization or
post-hoc adjustment, their reliance on access to or simulation of target
domains limits their practicality in real-world scenarios. In this paper, we
propose a novel calibration framework that operates without access to target
domain information. From a frequency-domain perspective, we identify that
distribution shifts often distort high-frequency visual cues exploited by deep
models, and introduce a low-frequency filtering strategy to encourage reliance
on domain-invariant features. However, such information loss may degrade
In-Distribution (ID) calibration performance. Therefore, we further propose a
gradient-based rectification mechanism that enforces ID calibration as a hard
constraint during optimization. Experiments on synthetic and real-world shifted
datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method
significantly improves calibration under distribution shift while maintaining
strong in-distribution performance.

</details>


### [143] [Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models](https://arxiv.org/abs/2508.19850)
*Xiaoqi Wang,Yun Zhang,Weisi Lin*

Main category: cs.CV

TL;DR: 提出了一种机器视角中心的图像质量评估（MIQA）框架，通过细粒度空间退化分析来评估机器视觉系统的可靠性，解决了传统人类视觉系统评估方法在机器视觉中的不足。


<details>
  <summary>Details</summary>
Motivation: 机器视觉系统（MVS）在恶劣视觉条件下容易出现性能下降，而传统的基于人类视觉系统（HVS）的图像质量评估方法对机器视觉质量预测效果差。需要一种机器视角中心的评估方法来量化图像退化对MVS性能的影响。

Method: 构建了包含250种退化类型、75个视觉模型和三种代表性视觉任务的MIQD-2.5M数据库（共2.5百万样本）。提出区域感知MIQA（RA-MIQA）模型，通过细粒度空间退化分析来评估MVS视觉质量。

Result: RA-MIQA在多个维度上表现优异，在图像分类任务上一致性和准确性方面分别获得13.56%和13.37%的SRCC提升。实验还发现了任务特异性的退化敏感性。HVS基于指标在MVS质量预测中效果差，而专门的MIQA模型在背景退化、准确性估计和细微形变方面仍遇到困难。

Conclusion: 这项研究提供了一种有效的机器视角中心图像质量评估方法，能够提升机器视觉系统的可靠性，为机器视角中心的图像处理和优化奠定了基础。

Abstract: Machine vision systems (MVS) are intrinsically vulnerable to performance
degradation under adverse visual conditions. To address this, we propose a
machine-centric image quality assessment (MIQA) framework that quantifies the
impact of image degradations on MVS performance. We establish an MIQA paradigm
encompassing the end-to-end assessment workflow. To support this, we construct
a machine-centric image quality database (MIQD-2.5M), comprising 2.5 million
samples that capture distinctive degradation responses in both consistency and
accuracy metrics, spanning 75 vision models, 250 degradation types, and three
representative vision tasks. We further propose a region-aware MIQA (RA-MIQA)
model to evaluate MVS visual quality through fine-grained spatial degradation
analysis. Extensive experiments benchmark the proposed RA-MIQA against seven
human visual system (HVS)-based IQA metrics and five retrained classical
backbones. Results demonstrate RA-MIQA's superior performance in multiple
dimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on
accuracy for image classification, while also revealing task-specific
degradation sensitivities. Critically, HVS-based metrics prove inadequate for
MVS quality prediction, while even specialized MIQA models struggle with
background degradations, accuracy-oriented estimation, and subtle distortions.
This study can advance MVS reliability and establish foundations for
machine-centric image processing and optimization. The model and code are
available at: https://github.com/XiaoqiWang/MIQA.

</details>


### [144] [Ego-centric Predictive Model Conditioned on Hand Trajectories](https://arxiv.org/abs/2508.19852)
*Binjie Zhang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出统一的两阶段预测框架，联合建模自我中心场景中的动作和视觉未来，通过手部轨迹条件化，实现动作预测和未来视频生成的统一处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：VLA模型专注于动作预测但缺乏对视觉场景影响的显式建模，视频预测模型生成未来帧但不以特定动作为条件，导致结果不真实或不一致。需要统一框架来同时处理动作预测和视觉结果预测。

Method: 两阶段框架：第一阶段进行连续状态建模处理异构输入（视觉观察、语言和动作历史），显式预测未来手部轨迹；第二阶段引入因果交叉注意力融合多模态线索，利用推断的动作信号指导基于图像的潜在扩散模型进行逐帧未来视频生成。

Result: 在Ego4D、BridgeData和RLBench数据集上的广泛实验表明，该方法在动作预测和未来视频合成方面均优于最先进的基线方法。

Conclusion: 这是第一个统一处理自我中心人类活动理解和机器人操作任务的模型，能够显式预测即将发生的动作及其视觉后果，为人类-物体交互理解和机器人规划提供了有效解决方案。

Abstract: In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.

</details>


### [145] [Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction](https://arxiv.org/abs/2508.19862)
*Long Chen,Ashiv Patel,Mengyun Qiao,Mohammad Yousuf Salmasi,Salah A. Hammouche,Vasilis Stavrinides,Jasleen Nagi,Soodeh Kalaie,Xiao Yun Xu,Wenjia Bai,Declan P. O'Regan*

Main category: cs.CV

TL;DR: MCMeshGAN是一个多模态条件网格生成对抗网络，用于3D主动脉瘤生长预测，结合局部KNN卷积网络和全局图卷积网络，在几何精度和临床直径估计方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主动脉瘤进展的个性化准确预测对于及时干预至关重要，但由于需要同时建模复杂3D几何中的细微局部变形和全局解剖变化，这一任务仍然具有挑战性。

Method: 提出MCMeshGAN双分支架构：局部KNN卷积网络(KCN)保留精细几何细节，全局图卷积网络(GCN)捕捉长程结构上下文。专用条件分支编码临床属性和目标时间间隔，生成解剖学合理的时间控制预测。

Result: 在TAAMesh数据集(590个多模态记录)上的实验表明，MCMeshGAN在几何精度和临床重要直径估计方面持续优于最先进的基线方法。

Conclusion: 该框架为临床可部署的个性化3D疾病轨迹建模提供了稳健的一步，源代码已公开。

Abstract: Personalized, accurate prediction of aortic aneurysm progression is essential
for timely intervention but remains challenging due to the need to model both
subtle local deformations and global anatomical changes within complex 3D
geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh
generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN
introduces a dual-branch architecture combining a novel local KNN-based
convolutional network (KCN) to preserve fine-grained geometric details and a
global graph convolutional network (GCN) to capture long-range structural
context, overcoming the over-smoothing limitations of deep GCNs. A dedicated
condition branch encodes clinical attributes (age, sex) and the target time
interval to generate anatomically plausible, temporally controlled predictions,
enabling retrospective and prospective modeling. We curated TAAMesh, a new
longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal
records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive
experiments demonstrate that MCMeshGAN consistently outperforms
state-of-the-art baselines in both geometric accuracy and clinically important
diameter estimation. This framework offers a robust step toward clinically
deployable, personalized 3D disease trajectory modeling. The source code for
MCMeshGAN and the baseline methods is publicly available at
https://github.com/ImperialCollegeLondon/MCMeshGAN.

</details>


### [146] [Self-supervised structured object representation learning](https://arxiv.org/abs/2508.19864)
*Oussama Hadjerci,Antoine Letienne,Mohamed Abbas Hedjazi,Adel Hafiane*

Main category: cs.CV

TL;DR: 提出了一种基于ProtoScale模块的自监督学习方法，通过语义分组、实例分离和层次化结构来构建结构化视觉表示，在目标检测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法在全局图像理解方面表现良好，但在捕捉场景中的结构化表示方面存在局限，特别是在密集预测任务中。

Method: 使用ProtoScale模块在多空间尺度上捕捉视觉元素，保持完整场景上下文，结合语义分组、实例级分离和层次化结构来构建渐进式结构化表示。

Result: 在COCO和UA-DETRAC数据集上的实验表明，该方法学习到的以对象为中心的表示提升了监督目标检测性能，即使使用有限标注数据和较少微调轮次也能超越最先进方法。

Conclusion: 该方法通过保持场景上下文和构建结构化表示，有效提升了自监督学习在密集预测任务中的性能，特别是在目标检测方面表现出色。

Abstract: Self-supervised learning (SSL) has emerged as a powerful technique for
learning visual representations. While recent SSL approaches achieve strong
results in global image understanding, they are limited in capturing the
structured representation in scenes. In this work, we propose a self-supervised
approach that progressively builds structured visual representations by
combining semantic grouping, instance level separation, and hierarchical
structuring. Our approach, based on a novel ProtoScale module, captures visual
elements across multiple spatial scales. Unlike common strategies like DINO
that rely on random cropping and global embeddings, we preserve full scene
context across augmented views to improve performance in dense prediction
tasks. We validate our method on downstream object detection tasks using a
combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results
show that our method learns object centric representations that enhance
supervised object detection and outperform the state-of-the-art methods, even
when trained with limited annotated data and fewer fine-tuning epochs.

</details>


### [147] [TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations](https://arxiv.org/abs/2508.19866)
*François G. Landry,Moulay A. Akhloufi*

Main category: cs.CV

TL;DR: TrajFusionNet是一个基于transformer的新模型，通过结合未来行人轨迹和车辆速度预测来预测行人过街意图，在两个注意力模块的协同下实现了最先进的性能和最低的推理时间。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆上路，预测行人过街意图成为重要研究领域，需要准确判断行人是否会过马路以确保道路安全。

Method: 提出TrajFusionNet模型，包含序列注意力模块(SAM)和视觉注意力模块(VAM)两个分支，分别从序列化的轨迹速度数据和视觉化的预测轨迹图像中学习特征。

Result: 在三个常用数据集上达到最先进性能，同时实现了最低的总推理时间（包括模型运行和数据预处理）。

Conclusion: 通过轻量级多模态融合方法，TrajFusionNet在行人过街意图预测任务中实现了优异的性能和效率平衡。

Abstract: With the introduction of vehicles with autonomous capabilities on public
roads, predicting pedestrian crossing intention has emerged as an active area
of research. The task of predicting pedestrian crossing intention involves
determining whether pedestrians in the scene are likely to cross the road or
not. In this work, we propose TrajFusionNet, a novel transformer-based model
that combines future pedestrian trajectory and vehicle speed predictions as
priors for predicting crossing intention. TrajFusionNet comprises two branches:
a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM
branch learns from a sequential representation of the observed and predicted
pedestrian trajectory and vehicle speed. Complementarily, the VAM branch
enables learning from a visual representation of the predicted pedestrian
trajectory by overlaying predicted pedestrian bounding boxes onto scene images.
By utilizing a small number of lightweight modalities, TrajFusionNet achieves
the lowest total inference time (including model runtime and data
preprocessing) among current state-of-the-art approaches. In terms of
performance, it achieves state-of-the-art results across the three most
commonly used datasets for pedestrian crossing intention prediction.

</details>


### [148] [Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network](https://arxiv.org/abs/2508.19875)
*Hui Zhang,Jianghui Cai,Haifeng Yang,Ali Luo,Yuqing Yang,Xiao Kong,Zhichao Ding,Lichan Zhou,Qin Han*

Main category: cs.CV

TL;DR: 提出了基于互信息的天空背景估计模型SMI，利用所有光纤光谱来估计天空背景，解决了传统方法依赖天空光纤平均光谱的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前天空背景扣除主要依赖天空光纤光谱构建超级天空，但平均光谱缺乏对目标周围环境的建模，需要更精确的天空背景估计方法。

Method: SMI包含两个主要网络：第一个网络使用波长校准模块从光谱中提取天空特征，解决特征偏移问题；第二个网络采用增量训练方法最大化不同光谱表示间的互信息以捕获共同成分，同时最小化相邻光谱表示间的互信息以获得个体成分。

Result: 在LAMOST光谱数据上的实验表明，SMI能够在观测过程中获得更好的目标天空背景，特别是在蓝端表现优异。

Conclusion: SMI方法通过互信息和增量训练有效解决了天空背景估计问题，为多目标光纤光谱处理提供了更精确的天空背景扣除方案。

Abstract: Sky background subtraction is a critical step in Multi-objective Fiber
spectra process. However, current subtraction relies mainly on sky fiber
spectra to build Super Sky. These average spectra are lacking in the modeling
of the environment surrounding the objects. To address this issue, a sky
background estimation model: Sky background building based on Mutual
Information (SMI) is proposed. SMI based on mutual information and incremental
training approach. It utilizes spectra from all fibers in the plate to estimate
the sky background. SMI contains two main networks, the first network applies a
wavelength calibration module to extract sky features from spectra, and can
effectively solve the feature shift problem according to the corresponding
emission position. The second network employs an incremental training approach
to maximize mutual information between representations of different spectra to
capturing the common component. Then, it minimizes the mutual information
between adjoining spectra representations to obtain individual components. This
network yields an individual sky background at each location of the object. To
verify the effectiveness of the method in this paper, we conducted experiments
on the spectra of LAMOST. Results show that SMI can obtain a better object sky
background during the observation, especially in the blue end.

</details>


### [149] [Multispectral LiDAR data for extracting tree points in urban and suburban areas](https://arxiv.org/abs/2508.19881)
*Narges Takhtkeshha,Gabriele Mazzacca,Fabio Remondino,Juha Hyyppä,Gottfried Mandlburger*

Main category: cs.CV

TL;DR: 本研究评估了三种深度学习模型（SPT、PTv3、PTv1）在MS-LiDAR数据上的树木点云提取性能，发现SPT模型在时间效率和准确性方面表现最佳，结合pNDVI光谱特征可显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 城市树木动态监测对绿化政策和电力基础设施风险管理至关重要。虽然机载激光扫描技术已用于大规模树木管理，但复杂城市环境和树木多样性仍带来挑战，需要更精确的监测方法。

Method: 使用多光谱激光雷达（MS-LiDAR）同时捕获3D空间和光谱数据，评估三种最先进的深度学习模型：Superpoint Transformer（SPT）、Point Transformer V3（PTv3）和Point Transformer V1（PTv1），并引入伪归一化植被指数（pNDVI）结合空间数据进行树木点云提取。

Result: SPT模型表现最优，平均交并比（mIoU）达到85.28%。结合pNDVI光谱特征与空间数据可获得最高检测精度，相比仅使用空间信息，错误率降低了10.61个百分点。

Conclusion: 多光谱激光雷达与深度学习技术的结合具有显著潜力，能够有效改进城市树木提取精度，为树木清单管理提供更可靠的技术支持。

Abstract: Monitoring urban tree dynamics is vital for supporting greening policies and
reducing risks to electrical infrastructure. Airborne laser scanning has
advanced large-scale tree management, but challenges remain due to complex
urban environments and tree variability. Multispectral (MS) light detection and
ranging (LiDAR) improves this by capturing both 3D spatial and spectral data,
enabling detailed mapping. This study explores tree point extraction using
MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are
evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point
Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of
SPT, with a mean intersection over union (mIoU) of 85.28%. The highest
detection accuracy is achieved by incorporating pseudo normalized difference
vegetation index (pNDVI) with spatial data, reducing error rate by 10.61
percentage points (pp) compared to using spatial information alone. These
findings highlight the potential of MS-LiDAR and DL to improve tree extraction
and further tree inventories.

</details>


### [150] [PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos](https://arxiv.org/abs/2508.19895)
*Ziyun Qian,Runyu Xiao,Shuyuan Tu,Wei Xue,Dingkang Yang,Mingcheng Li,Dongliang Kou,Minghao Han,Zizhi Chen,Lihua Zhang*

Main category: cs.CV

TL;DR: 本文提出了PersonaAnimator框架，通过从无约束视频中学习个性化运动模式，解决了现有运动生成方法在风格学习、数据依赖和物理合理性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有运动生成方法存在三个主要问题：(1)姿态引导的运动迁移方法仅复制运动而不学习风格特征；(2)运动风格迁移方法严重依赖难以获取的动作捕捉数据；(3)生成的运动有时违反物理规律。

Method: 提出PersonaAnimator框架，直接从无约束视频中学习个性化运动模式，支持个性化运动迁移。构建首个基于视频的个性化运动数据集PersonaVid（包含20个运动内容类别和120个运动风格类别），并提出物理感知的运动风格正则化机制来确保生成运动的物理合理性。

Result: 大量实验表明，PersonaAnimator在运动迁移方法中表现优于现有最先进方法，为视频到视频运动个性化任务设立了新的基准。

Conclusion: 该研究开创了视频到视频运动个性化这一新任务，提出的框架能够有效解决现有方法的局限性，实现更自然和个性化的运动生成。

Abstract: Recent advances in motion generation show remarkable progress. However,
several limitations remain: (1) Existing pose-guided character motion transfer
methods merely replicate motion without learning its style characteristics,
resulting in inexpressive characters. (2) Motion style transfer methods rely
heavily on motion capture data, which is difficult to obtain. (3) Generated
motions sometimes violate physical laws. To address these challenges, this
paper pioneers a new task: Video-to-Video Motion Personalization. We propose a
novel framework, PersonaAnimator, which learns personalized motion patterns
directly from unconstrained videos. This enables personalized motion transfer.
To support this task, we introduce PersonaVid, the first video-based
personalized motion dataset. It contains 20 motion content categories and 120
motion style categories. We further propose a Physics-aware Motion Style
Regularization mechanism to enforce physical plausibility in the generated
motions. Extensive experiments show that PersonaAnimator outperforms
state-of-the-art motion transfer methods and sets a new benchmark for the
Video-to-Video Motion Personalization task.

</details>


### [151] [Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities](https://arxiv.org/abs/2508.19905)
*Imad Ali Shah,Jiarong Li,Roshan George,Tim Brophy,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本文首次全面综述了高光谱成像(HSI)在汽车ADAS/AD应用中的现状，分析了216款商业HSI相机，发现仅有4款满足性能阈值且无一款符合AEC-Q100标准，揭示了HSI研究潜力与商业成熟度之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像能够提供超越传统RGB成像的光谱分辨率，实现材料级别的场景理解，在高级驾驶辅助系统和自动驾驶应用中具有变革性潜力，但需要系统评估其技术成熟度和商业化可行性。

Method: 采用定性综述方法，分析216款商业可用的高光谱和多光谱成像相机，基于帧率、空间分辨率、光谱维度和AEC-Q100温度标准等关键汽车标准进行基准测试，并回顾最新的HSI数据集和应用案例。

Result: 分析显示仅有4款相机满足性能阈值，无一款符合AEC-Q100要求；现有HSI数据集在规模、光谱一致性、光谱通道数量和环境多样性方面存在局限，制约了感知算法开发和HSI真正潜力的验证。

Conclusion: HSI在汽车应用中存在显著的研究潜力与商业成熟度差距，需要朝着实际集成方向开展关键研究，包括改进相机技术、丰富数据集和解决标准化问题。

Abstract: Hyperspectral imaging (HSI) offers a transformative sensing modality for
Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD)
applications, enabling material-level scene understanding through fine spectral
resolution beyond the capabilities of traditional RGB imaging. This paper
presents the first comprehensive review of HSI for automotive applications,
examining the strengths, limitations, and suitability of current HSI
technologies in the context of ADAS/AD. In addition to this qualitative review,
we analyze 216 commercially available HSI and multispectral imaging cameras,
benchmarking them against key automotive criteria: frame rate, spatial
resolution, spectral dimensionality, and compliance with AEC-Q100 temperature
standards. Our analysis reveals a significant gap between HSI's demonstrated
research potential and its commercial readiness. Only four cameras meet the
defined performance thresholds, and none comply with AEC-Q100 requirements. In
addition, the paper reviews recent HSI datasets and applications, including
semantic segmentation for road surface classification, pedestrian separability,
and adverse weather perception. Our review shows that current HSI datasets are
limited in terms of scale, spectral consistency, the number of spectral
channels, and environmental diversity, posing challenges for the development of
perception algorithms and the adequate validation of HSI's true potential in
ADAS/AD applications. This review paper establishes the current state of HSI in
automotive contexts as of 2025 and outlines key research directions toward
practical integration of spectral imaging in ADAS and autonomous systems.

</details>


### [152] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: KRETA是一个专门针对韩语的文本丰富视觉问答基准数据集，填补了低资源语言在VQA评估方面的空白，包含多领域评估和自动化数据生成流程。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如韩语）在文本丰富视觉问答任务中缺乏全面基准数据集的问题，以便更好地评估和比较视觉语言模型。

Method: 开发了一个半自动化的VQA生成流程，采用逐步图像分解方法和七项指标的质量评估协议，构建包含15个领域和26种图像类型的多样化数据集。

Result: 成功创建了KRETA基准数据集，支持对视觉文本理解和推理能力的深入评估，为韩语VLM研究提供了重要资源。

Conclusion: KRETA不仅为韩语VQA研究提供了标准化基准，其可扩展的生成流程也为其他语言开发类似基准提供了参考，将推动多语言视觉语言模型研究的发展。

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [153] [Streamlining the Development of Active Learning Methods in Real-World Object Detection](https://arxiv.org/abs/2508.19906)
*Moussa Kassem Sbeyti,Nadja Klein,Michelle Karg,Christian Wirth,Sahin Albayrak*

Main category: cs.CV

TL;DR: 提出了一种基于目标相似性的度量方法OSS，用于评估主动学习方法在目标检测中的有效性，无需训练检测器即可筛选无效方法并选择代表性验证集。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界目标检测中主动学习方法面临的高计算成本和评估可靠性问题，特别是在自动驾驶等安全关键系统中。

Method: 开发对象级集合相似性度量OSS，通过计算训练集与目标域在对象级别特征上的相似性来评估主动学习方法，无需实际训练检测器。

Result: 在KITTI、BDD100K、CODA三个自动驾驶数据集上验证了OSS的有效性，能够有效筛选主动学习方法并选择代表性验证集。

Conclusion: OSS提供了一种计算高效且可靠的框架，为现实世界应用中主动学习的部署提供了实用解决方案，特别是在计算效率和评估可靠性要求高的场景。

Abstract: Active learning (AL) for real-world object detection faces computational and
reliability challenges that limit practical deployment. Developing new AL
methods requires training multiple detectors across iterations to compare
against existing approaches. This creates high costs for autonomous driving
datasets where the training of one detector requires up to 282 GPU hours.
Additionally, AL method rankings vary substantially across validation sets,
compromising reliability in safety-critical transportation systems. We
introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses
these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without
requiring detector training by measuring similarity between training sets and
target domains using object-level features. This enables the elimination of
ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables
the selection of representative validation sets for robust evaluation. We
validate our similarity-based approach on three autonomous driving datasets
(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with
two detector architectures (EfficientDet, YOLOv3). This work is the first to
unify AL training and evaluation strategies in object detection based on object
similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object
crops, and integrates with existing AL pipelines. This provides a practical
framework for deploying AL in real-world applications where computational
efficiency and evaluation reliability are critical. Code is available at
https://mos-ks.github.io/publications/.

</details>


### [154] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: GLSim是一个无需训练的目标幻觉检测框架，通过结合全局和局部嵌入相似性信号，在多种场景下实现更准确可靠的目标幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型中的目标幻觉问题限制了其在现实应用中的安全部署。现有方法通常单独采用全局或局部视角，这可能限制检测的可靠性。

Method: GLSim框架利用图像和文本模态之间的互补性全局和局部嵌入相似性信号，无需训练即可进行目标幻觉检测。

Result: 在全面的基准测试中，GLSim实现了卓越的检测性能，显著优于竞争基线方法。

Conclusion: GLSim通过结合全局和局部视角，为目标幻觉检测提供了更准确可靠的解决方案，有助于提升视觉语言模型在现实应用中的安全性。

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


### [155] [Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation](https://arxiv.org/abs/2508.19909)
*Lechun You,Zhonghua Wu,Weide Liu,Xulei Yang,Jun Cheng,Wei Zhou,Bharadwaj Veeravalli,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出了一种利用2D基础模型增强3D弱监督语义分割的新方法，通过将2D分割掩码传播到3D空间来扩展稀疏标注，并结合置信度和不确定性正则化生成可靠伪标签


<details>
  <summary>Details</summary>
Motivation: 当前3D语义分割方法仅关注3D域，未能充分利用2D和3D数据的互补性，且现有方法在处理稀疏标注和伪标签噪声方面存在不足

Method: 利用2D基础模型生成分割掩码，通过几何对应关系将2D掩码传播到3D空间扩展标注，应用置信度和不确定性一致性正则化选择可靠伪标签

Result: 该方法显著增强了可用标注数量，提高了3D弱监督分割性能

Conclusion: 该方法成功弥合了有限3D标注与强大2D基础模型能力之间的差距，为3D弱监督语义分割提供了有效解决方案

Abstract: Current methods for 3D semantic segmentation propose training models with
limited annotations to address the difficulty of annotating large, irregular,
and unordered 3D point cloud data. They usually focus on the 3D domain only,
without leveraging the complementary nature of 2D and 3D data. Besides, some
methods extend original labels or generate pseudo labels to guide the training,
but they often fail to fully use these labels or address the noise within them.
Meanwhile, the emergence of comprehensive and adaptable foundation models has
offered effective solutions for segmenting 2D data. Leveraging this
advancement, we present a novel approach that maximizes the utility of sparsely
available 3D annotations by incorporating segmentation masks generated by 2D
foundation models. We further propagate the 2D segmentation masks into the 3D
space by establishing geometric correspondences between 3D scenes and 2D views.
We extend the highly sparse annotations to encompass the areas delineated by 3D
masks, thereby substantially augmenting the pool of available labels.
Furthermore, we apply confidence- and uncertainty-based consistency
regularization on augmentations of the 3D point cloud and select the reliable
pseudo labels, which are further spread on the 3D masks to generate more
labels. This innovative strategy bridges the gap between limited 3D annotations
and the powerful capabilities of 2D foundation models, ultimately improving the
performance of 3D weakly supervised segmentation.

</details>


### [156] [WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.19927)
*Fayaz Ali,Muhammad Zawish,Steven Davy,Radu Timofte*

Main category: cs.CV

TL;DR: WaveHiT-SR：基于小波变换和分层窗口的Transformer超分辨率方法，通过自适应分层窗口和多频段分解，在保持性能的同时显著降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统Transformer超分辨率方法因窗口自注意力的二次计算复杂度而被迫使用小窗口，限制了感受野，需要一种既能扩大感受野又能降低计算成本的新方法

Method: 将小波变换嵌入分层Transformer框架，使用自适应分层窗口替代静态小窗口，通过小波变换将图像分解为多频段子带，分层处理逐步重建高分辨率图像

Result: 在SwinIR-Light、SwinIR-NG和SRFormer-Light等模型上实现最先进的超分辨率结果，参数量更少、FLOPs更低、速度更快，同时保持高性能

Conclusion: WaveHiT-SR通过分层窗口和小波变换的结合，有效解决了Transformer超分辨率中的计算复杂度和感受野限制问题，实现了高效且高性能的图像超分辨率

Abstract: Transformers have demonstrated promising performance in computer vision
tasks, including image super-resolution (SR). The quadratic computational
complexity of window self-attention mechanisms in many transformer-based SR
methods forces the use of small, fixed windows, limiting the receptive field.
In this paper, we propose a new approach by embedding the wavelet transform
within a hierarchical transformer framework, called (WaveHiT-SR). First, using
adaptive hierarchical windows instead of static small windows allows to capture
features across different levels and greatly improve the ability to model
long-range dependencies. Secondly, the proposed model utilizes wavelet
transforms to decompose images into multiple frequency subbands, allowing the
network to focus on both global and local features while preserving structural
details. By progressively reconstructing high-resolution images through
hierarchical processing, the network reduces computational complexity without
sacrificing performance. The multi-level decomposition strategy enables the
network to capture fine-grained information in lowfrequency components while
enhancing high-frequency textures. Through extensive experimentation, we
confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined
versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR
results, achieving higher efficiency with fewer parameters, lower FLOPs, and
faster speeds.

</details>


### [157] [Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework](https://arxiv.org/abs/2508.19946)
*Gianluca Guzzetta*

Main category: cs.CV

TL;DR: 对Chan-Vese图像分割算法的综合研究，提出基于活动轮廓的功能性分割损失方法，并与传统损失函数进行性能比较


<details>
  <summary>Details</summary>
Motivation: 研究Chan-Vese算法在图像分割中的应用，探索基于水平集和功能能量的现代计算机视觉分割方法

Method: 使用Chan-Vese模型的功能能量和偏微分方程的离散化方案，基于pytorch.nn.ModuleLoss实现功能性分割损失，采用水平集方法

Result: 在常见计算机视觉分割数据集上进行了性能评估，提供了MATLAB实现和代码开源

Conclusion: 提出的功能性分割损失方法在图像分割任务中表现出良好性能，为现代计算机视觉分割提供了新的解决方案

Abstract: In this paper, we present a comprehensive study and analysis of the Chan-Vese
algorithm for image segmentation. We employ a discretized scheme derived from
the empirical study of the Chan-Vese model's functional energy and its partial
differential equation based on its level set function. We provide a proof of
the results and an implementation using MATLAB. Leveraging modern computer
vision methodologies, we propose a functional segmentation loss based on active
contours, utilizing pytorch.nn.ModuleLoss and a level set based on the
Chan-Vese algorithm. We compare our results with common computer vision
segmentation datasets and evaluate the performance of classical loss functions
against our proposed method. All code and materials used are available at
https://github.com/gguzzy/chan_vese_functional_loss.

</details>


### [158] [Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models](https://arxiv.org/abs/2508.19967)
*Oliver Grainge,Sania Waheed,Jack Stilgoe,Michael Milford,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 本文对25种最先进的视觉语言模型在4个基准图像数据集上的地理定位能力进行全面评估，发现当前VLM在普通街景图像上表现不佳，但在类似社交媒体内容的图像上达到61%的高准确率，引发严重隐私担忧。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型(VLM)在地理定位任务中展现强大能力，带来了严重的隐私风险(如跟踪和监控)，但目前缺乏对这些模型地理定位精度、局限性和潜在意外推理的系统性评估。

Method: 使用4个包含多样化环境的基准图像数据集，对25种最先进的视觉语言模型进行全面的地理定位能力评估。

Result: 当前VLM在普通街景图像上表现不佳，但在类似社交媒体内容的图像上达到61%的高准确率，显示出显著的地理定位能力。

Conclusion: 研究揭示了VLM的内部推理机制，强调了其优势、局限性以及潜在的社会风险，特别是对社交媒体图像的高精度定位能力引发了紧迫的隐私担忧。

Abstract: Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.

</details>


### [159] [GS: Generative Segmentation via Label Diffusion](https://arxiv.org/abs/2508.20020)
*Yuhao Chen,Shubin Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: GS（生成式分割）是一个新颖的框架，将分割任务重新定义为通过标签扩散的生成式任务，直接从噪声生成分割掩码，在图像和语言描述的条件下实现端到端训练。


<details>
  <summary>Details</summary>
Motivation: 传统方法将语言驱动的图像分割视为判别式问题，而现有的扩散模型方法仍以图像为中心，将分割作为辅助过程。本文旨在将分割本身作为主要建模目标。

Method: 提出GS框架，通过标签扩散直接将分割任务公式化为生成式任务。从噪声直接生成分割掩码，同时以输入图像和语言描述为条件，实现端到端训练。

Result: 在Panoptic Narrative Grounding（PNG）基准测试中，GS显著优于现有的判别式和基于扩散的方法，创造了语言驱动分割的新最先进水平。

Conclusion: 将分割重新定义为生成式任务的方法有效，GS框架通过直接生成分割掩码实现了更好的空间和语义保真度控制，为多模态分割任务提供了新的解决方案。

Abstract: Language-driven image segmentation is a fundamental task in vision-language
understanding, requiring models to segment regions of an image corresponding to
natural language expressions. Traditional methods approach this as a
discriminative problem, assigning each pixel to foreground or background based
on semantic alignment. Recently, diffusion models have been introduced to this
domain, but existing approaches remain image-centric: they either (i) use image
diffusion models as visual feature extractors, (ii) synthesize segmentation
data via image generation to train discriminative models, or (iii) perform
diffusion inversion to extract attention cues from pre-trained image diffusion
models-thereby treating segmentation as an auxiliary process. In this paper, we
propose GS (Generative Segmentation), a novel framework that formulates
segmentation itself as a generative task via label diffusion. Instead of
generating images conditioned on label maps and text, GS reverses the
generative process: it directly generates segmentation masks from noise,
conditioned on both the input image and the accompanying language description.
This paradigm makes label generation the primary modeling target, enabling
end-to-end training with explicit control over spatial and semantic fidelity.
To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic
Narrative Grounding (PNG), a representative and challenging benchmark for
multimodal segmentation that requires panoptic-level reasoning guided by
narrative captions. Experimental results show that GS significantly outperforms
existing discriminative and diffusion-based methods, setting a new
state-of-the-art for language-driven segmentation.

</details>


### [160] [Segmentation Assisted Incremental Test Time Adaptation in an Open World](https://arxiv.org/abs/2508.20029)
*Manogna Sreenivas,Soma Biswas*

Main category: cs.CV

TL;DR: 提出SegAssist方法，通过分割辅助主动标注来增强视觉语言模型在测试时对新类别和新域的持续适应能力


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中未知对象和分布偏移对已部署模型的挑战，处理测试时持续出现的新类别和新域

Method: 结合单图像TTA方法和主动标注技术，提出训练免费的SegAssist模块，利用VLM的分割能力优化主动样本选择

Result: 在多个基准数据集上的广泛实验证明了SegAssist在现实场景中增强VLM性能的潜力

Conclusion: SegAssist能够有效提升视觉语言模型在需要持续适应新兴数据的真实场景中的表现

Abstract: In dynamic environments, unfamiliar objects and distribution shifts are often
encountered, which challenge the generalization abilities of the deployed
trained models. This work addresses Incremental Test Time Adaptation of Vision
Language Models, tackling scenarios where unseen classes and unseen domains
continuously appear during testing. Unlike traditional Test Time Adaptation
approaches, where the test stream comes only from a predefined set of classes,
our framework allows models to adapt simultaneously to both covariate and label
shifts, actively incorporating new classes as they emerge. Towards this goal,
we establish a new benchmark for ITTA, integrating single image TTA methods for
VLMs with active labeling techniques that query an oracle for samples
potentially representing unseen classes during test time. We propose a
segmentation assisted active labeling module, termed SegAssist, which is
training free and repurposes the segmentation capabilities of VLMs to refine
active sample selection, prioritizing samples likely to belong to unseen
classes. Extensive experiments on several benchmark datasets demonstrate the
potential of SegAssist to enhance the performance of VLMs in real world
scenarios, where continuous adaptation to emerging data is essential.
Project-page:https://manogna-s.github.io/segassist/

</details>


### [161] [OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations](https://arxiv.org/abs/2508.20063)
*Peng-Hao Hsu,Ke Zhang,Fu-En Wang,Tao Tu,Ming-Feng Li,Yu-Lun Liu,Albert Y. C. Chen,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: OpenM3D是一个无需人工标注的开放词汇多视角室内3D目标检测器，通过2D诱导体素特征和伪3D框生成技术，在ScanNet200和ARKitScenes基准上实现了高精度和快速检测


<details>
  <summary>Details</summary>
Motivation: 开放词汇3D目标检测领域主要基于3D点云方法，基于图像的方法探索有限。需要开发无需人工标注的高效多视角室内3D检测器

Method: 采用单阶段检测器架构，结合2D诱导体素特征。使用图嵌入技术生成高质量3D伪框，通过类无关3D定位损失和体素语义对齐损失进行联合训练，从2D片段采样多样化CLIP特征

Result: 在ScanNet200和ARKitScenes基准上取得优越精度和速度（每场景0.3秒），伪框生成精度和召回率优于现有方法，超越了强两阶段方法和多视角深度估计基线

Conclusion: OpenM3D证明了无需人工标注的高质量单阶段开放词汇3D检测器的可行性，通过精心设计的伪监督训练策略实现了高效准确的检测性能

Abstract: Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.

</details>


### [162] [Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices](https://arxiv.org/abs/2508.20064)
*Philippe Zhang,Weili Jiang,Yihao Li,Jing Zhang,Sarah Matta,Yubo Tan,Hui Lin,Haoshen Wang,Jiangtian Pan,Hui Xu,Laurent Borderie,Alexandre Le Guilcher,Béatrice Cochener,Chubin Ou,Gwenolé Quellec,Mathieu Lamard*

Main category: cs.CV

TL;DR: 该论文介绍了在MARIO挑战赛中针对年龄相关性黄斑变性（AMD）进展监测的两个任务解决方案：任务1使用融合CNN网络和模型集成对OCT扫描进行分类；任务2提出Patch Progression Masked Autoencoder预测未来3个月的病情进展。


<details>
  <summary>Details</summary>
Motivation: AMD是影响视力的常见眼病，抗VEGF治疗能延缓新生血管性AMD进展。通过及时诊断和持续监测OCT扫描中的新生血管活动，可以制定更个性化和有效的治疗计划。

Method: 任务1：采用融合CNN网络和模型集成技术对连续OCT采集的2D切片对进行分类；任务2：提出Patch Progression Masked Autoencoder，生成下一次检查的OCT图像，然后使用任务1的解决方案对当前OCT和生成OCT之间的演变进行分类。

Result: 在两个任务中都取得了Top 10的成绩，但由于部分团队成员与挑战赛组织者属于同一机构，不符合获奖资格。

Conclusion: 提出的方法在AMD进展监测方面表现良好，融合CNN和自编码器技术为OCT图像分析和病情预测提供了有效解决方案，有助于实现更个性化的AMD治疗。

Abstract: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.

</details>


### [163] [PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence](https://arxiv.org/abs/2508.20066)
*Zheng Li,Yanming Guo,WenZhe Liu,Xueyi Zhang,Zhaoyun Ding,Long Xu,Mingrui Lao*

Main category: cs.CV

TL;DR: 本文提出了PAUL框架来解决跨视角地理定位中的噪声对应问题，通过不确定性学习和选择性增强来处理GPS漂移导致的图像对不完美对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法通常假设训练时图像对完美对齐，但实际应用中GPS漂移等因素导致系统性的对齐偏移，只有部分对应关系存在，这种噪声对应问题在当前研究中关注不足。

Method: 提出PAUL框架，通过不确定性感知协同增强和证据协同训练来估计数据不确定性，基于此对训练数据进行分区和增强，选择性地增强对应置信度高的区域，利用不确定性估计来精化特征学习。

Result: 综合实验验证了PAUL各组成部分的有效性，在各种噪声比例下 consistently 优于其他竞争性的噪声对应驱动方法。

Conclusion: PAUL框架通过不确定性学习和选择性数据增强，有效解决了跨视角地理定位中的噪声对应问题，为实际应用提供了更鲁棒的解决方案。

Abstract: Cross-view geo-localization is a critical task for UAV navigation, event
detection, and aerial surveying, as it enables matching between drone-captured
and satellite imagery. Most existing approaches embed multi-modal data into a
joint feature space to maximize the similarity of paired images. However, these
methods typically assume perfect alignment of image pairs during training,
which rarely holds true in real-world scenarios. In practice, factors such as
urban canyon effects, electromagnetic interference, and adverse weather
frequently induce GPS drift, resulting in systematic alignment shifts where
only partial correspondences exist between pairs. Despite its prevalence, this
source of noisy correspondence has received limited attention in current
research. In this paper, we formally introduce and address the Noisy
Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to
bridge the gap between idealized benchmarks and practical applications. To this
end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a
novel framework that partitions and augments training data based on estimated
data uncertainty through uncertainty-aware co-augmentation and evidential
co-training. Specifically, PAUL selectively augments regions with high
correspondence confidence and utilizes uncertainty estimation to refine feature
learning, effectively suppressing noise from misaligned pairs. Distinct from
traditional filtering or label correction, PAUL leverages both data uncertainty
and loss discrepancy for targeted partitioning and augmentation, thus providing
robust supervision for noisy samples. Comprehensive experiments validate the
effectiveness of individual components in PAUL,which consistently achieves
superior performance over other competitive noisy-correspondence-driven methods
in various noise ratios.

</details>


### [164] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 通过3D高斯拟合技术优化双鱼眼摄像机模型，实现从不完美全景图到无缝新视角渲染的转换


<details>
  <summary>Details</summary>
Motivation: 市面上的双鱼眼摄像机系统产生的全景图存在镜头间隔和角度异变等缺陷，影响虚拟现实和自主导航的应用效果

Method: 将双鱼眼摄像机模型集成到3D高斯拟合流水线中，通过联合优化3D高斯参数和标定变量，模拟镜头间隔和角度异变效果

Result: 在真实数据集上的广泛评估显示，该方法能够从不完美图像生成无缝渲染结果，性能超过现有的360度渲染模型

Conclusion: 该框架有效解决了双鱼眼系统的本质缺陷，为高质量全景内容制作提供了可靠的技术支撑

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [165] [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](https://arxiv.org/abs/2508.20089)
*Ross J Gardiner,Guillaume Mougeot,Sareh Rowlands,Benno I Simmons,Flemming Helsing,Toke Thomas Høye*

Main category: cs.CV

TL;DR: 提出轻量级分类方法，结合专家标注数据和BioCLIP2知识蒸馏，在丹麦蛾类识别中实现高精度且计算成本大幅降低


<details>
  <summary>Details</summary>
Motivation: 自动相机系统拍摄的蛾类图像标注对理解昆虫衰退至关重要，但由于策划图像与嘈杂野外图像间的域偏移，准确物种识别具有挑战性

Method: 结合有限专家标注的野外数据，将高性能BioCLIP2基础模型的知识蒸馏到ConvNeXt-tiny架构中

Result: 在101种丹麦蛾类的AMI相机系统实验中，BioCLIP2显著优于其他方法，蒸馏后的轻量模型在显著降低计算成本的同时达到可比精度

Conclusion: 这些见解为开发高效昆虫监测系统和弥合细粒度分类的域差距提供了实用指导

Abstract: Labelling images of Lepidoptera (moths) from automated camera systems is
vital for understanding insect declines. However, accurate species
identification is challenging due to domain shifts between curated images and
noisy field imagery. We propose a lightweight classification approach,
combining limited expert-labelled field data with knowledge distillation from
the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny
architecture. Experiments on 101 Danish moth species from AMI camera systems
demonstrate that BioCLIP2 substantially outperforms other methods and that our
distilled lightweight model achieves comparable accuracy with significantly
reduced computational cost. These insights offer practical guidelines for the
development of efficient insect monitoring systems and bridging domain gaps for
fine-grained classification.

</details>


### [166] [CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning](https://arxiv.org/abs/2508.20096)
*Zeyi Sun,Yuhang Cao,Jianze Liang,Qiushi Sun,Ziyu Liu,Zhixiong Zhang,Yuhang Zang,Xiaoyi Dong,Kai Chen,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: CODA是一个可训练的复合框架，通过整合通用规划器和专业执行器来解决科学计算GUI中长程规划和精确执行的挑战，在ScienceBoard基准测试中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有GUI自主代理在科学计算等专业领域存在规划与执行的权衡问题，通用代理擅长规划但执行差，专业代理则相反。现有复合框架通常是静态且不可训练的，无法从经验中适应，这在高质量数据稀缺的科学领域是一个关键限制。

Method: CODA框架包含通用规划器(Cerebrum)和专业执行器(Cerebellum)，采用两阶段训练流程：1)专业化阶段：使用解耦GRPO方法为每个科学应用单独训练专家规划器；2)泛化阶段：聚合所有成功轨迹构建整合数据集，用于监督微调最终规划器。

Result: 在ScienceBoard基准的四个挑战性应用中，CODA显著优于基线方法，在开源模型中建立了新的最先进水平。

Conclusion: CODA通过可训练的复合框架成功解决了科学计算GUI代理中规划与执行的权衡问题，实现了强大的执行能力和跨域泛化能力。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [167] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 基于普通最小二乘的物理告知回归(PIR)方法，通过正则化OLS估计参数线性非线性动态模型的参数，在计算效率和准确性方面都显著优于PINN方法


<details>
  <summary>Details</summary>
Motivation: 开发一种高效的混合参数估计方法，通过结合物理知识和数据来实现可靠且快速的参数估计，特别是在处理复杂非线性动态模型时

Method: 提出物理告知回归(PIR)方法，利用参数线性模型特性，通过正则化普通最小二乘进行参数估计，应用于ODE和PDE模型

Result: 在生成数据和实际COVID-19数据上，PIR方法在复杂模型中表现显著优于PINN方法，计算速度更快且准确性更高，能够估计时变参数

Conclusion: PIR方法在考虑的模型中优于PINN方法，能够支持可靠、快速甚至实时的参数估计，为数据驱动和物理告知技术提供了有效桥梁

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [168] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 扩展ZipNN压缩方法至低精度浮点格式(FP8/FP4)，通过分离压缩指数和尾数获得高压缩比，并在LLM的K/V缓存中实现内存节省


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型变大和部署普及，减少神经网络权重的存储和传输成本越来越重要，特别是对于正在普及的低精度FP8/FP4格式

Method: 扩展ZipNN方法，设计了分离压缩指数和尾数组件的方法，使用位图编码进行独立压缩，并在大语言模型的K/V缓存张量中进行压缩实验

Result: 实现了高压缩比：BF16格式达到62%，FP8格式达到83%，同时发现K/V缓存张量也呈现出可压缩的模式

Conclusion: 该方法能够在低精度浮点格式上实现高效压缩，为深度学习模型的存储和部署提供显著的成本节省，特别是在大语言模型的内存使用中

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [169] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: POT是一种新型黑盒攻击框架，通过LLM迭代优化生成隐蔽且语义自然的对抗提示，无需外部数据访问即可诱导模型产生过度冗长的推理链，从而造成计算资源浪费。


<details>
  <summary>Details</summary>
Motivation: 现有过度思考攻击需要外部知识源进行数据投毒、依赖可检索的中毒内容以及结构明显的模板，限制了在实际场景中的适用性。需要开发更实用的攻击方法。

Method: 提出POT框架，使用基于LLM的迭代优化来生成隐蔽且语义自然的对抗提示，无需外部数据访问和模型检索，实现黑盒攻击。

Result: 在多种模型架构和数据集上的广泛实验表明，POT相比其他方法具有优越性能，能够有效诱导模型产生不必要的冗长推理过程。

Conclusion: POT成功解决了现有过度思考攻击的限制，提供了一种更实用和有效的黑盒攻击方法，揭示了CoT推理过程中的新安全漏洞。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [170] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 提出了一种在真实分布式物联网环境中训练深度强化学习模型的新框架，使用ACK反馈信息进行训练，实现了基于DRL的信道选择方法


<details>
  <summary>Details</summary>
Motivation: 现有研究很少探索在真实分布式物联网系统中使用真实数据训练DRL模型，需要填补这一研究空白

Method: 提出新型框架，物联网设备使用DRL方法选择通信信道，通过实际数据传输获得的ACK信息作为反馈来训练DRL模型

Result: 通过帧成功率(FSR)进行性能评估，证明了所提框架的可行性和有效性

Conclusion: 该框架成功实现了在真实物联网环境中训练DRL模型，为解决复杂资源分配问题提供了有效解决方案

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [171] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Re:Frame是一个用于离线强化学习的插件模块，通过关联记忆缓冲区整合少量专家轨迹来提升从低质量数据中学习的性能


<details>
  <summary>Details</summary>
Motivation: 离线强化学习通常面临次优数据的问题，难以获得大规模专家数据集。核心挑战是如何有效利用稀缺的专家演示和丰富的低质量数据

Method: 引入Re:Frame模块，包含一个关联记忆缓冲区(AMB)存储专家轨迹。策略通过内容关联从AMB中检索专家数据，并将其整合到决策过程中，无需环境交互或修改主干架构

Result: 在D4RL MuJoCo任务中，仅使用60条专家轨迹(数据集的0.1%)，Re:Frame在四个设置中的三个都显著优于Decision Transformer基线，最高提升10.7个标准化点

Conclusion: Re:Frame提供了一种简单且数据高效的方法，能够通过注入稀缺专家知识显著改善从低质量数据集进行的离线强化学习

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [172] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: 提出了NCMemo框架来量化图神经网络在半监督节点分类中的标签记忆现象，发现图同配性与记忆化呈负相关关系，并通过图重连技术有效降低记忆化同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络已被证明会记忆训练数据，但图神经网络的记忆化分析仍未被充分探索。需要量化GNN在半监督节点分类中的标签记忆现象，并理解其与图结构特性的关系。

Method: 引入NCMemo框架分析节点分类记忆化，研究图同配性（homophily）与记忆化的关系，分析GNN训练动态，并探索图重连作为缓解记忆化的方法。

Result: 发现较低的同配性显著增加记忆化，节点在特征空间邻域中标签不一致性更高的节点更容易被记忆。图重连能有效减少记忆化且不损害模型性能，同时降低隐私风险。

Conclusion: 该研究不仅增进了对GNN学习机制的理解，还支持了更注重隐私保护的GNN部署，揭示了图结构与记忆化之间的重要联系，并提供了实用的缓解策略。

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [173] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 提出基于SVD分解的多源迁移学习框架，通过分解源模型为秩一组件并选择最显著组件进行聚合，仅微调合并矩阵的主奇异值来实现高效知识迁移


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习忽视了利用在线大量可用模型的机会，现有方法粒度粗糙，缺乏精确知识提取和高效聚合能力，无法处理大量源模型或高参数量模型

Method: 使用奇异值分解(SVD)将每个源模型分解为基本秩一组件，然后从所有源中选择最显著组件进行聚合，仅微调合并矩阵的主奇异值来适应目标任务

Result: 提出的框架实现了高效迁移学习，对输入级和参数空间的扰动具有鲁棒性（如噪声或剪枝的源模型），计算扩展性良好

Conclusion: 基于SVD的组件级知识提取和聚合方法解决了多源迁移学习的效率和精度问题，为利用大量在线模型提供了有效途径

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [174] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: Symphony是一个去中心化的多智能体系统，通过分布式账本、信标选择协议和加权投票机制，使轻量级LLM能够在消费级GPU上协调工作，解决了集中式编排的高成本、通信拓扑僵化和适应性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体框架主要依赖集中式编排，存在部署成本高、通信拓扑结构僵化、适应性有限等问题，需要一种更高效、灵活的分布式解决方案。

Method: 提出Symphony系统，包含三个核心机制：1)去中心化账本记录能力；2)信标选择协议进行动态任务分配；3)基于思维链的加权结果投票。

Result: 在推理基准测试中优于现有基线方法，实现了显著的准确率提升，并在不同容量模型间展现出良好的鲁棒性。

Conclusion: Symphony提供了一种隐私保护、可扩展、容错且低开销的编排方案，证明了去中心化方法在LLM多智能体系统中的有效性。

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [175] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Benjamin Sanchez-Lengeling,Adrian Jinich,Radhakrishnan Mahadevan*

Main category: cs.LG

TL;DR: 这篇论文介绍了图数据建模在化学科学中的应用，重点讲解了图神经网络如何用于分子、蛋白质和化学过程的分析与预测。


<details>
  <summary>Details</summary>
Motivation: 化学科学中的分子、蛋白质和反应过程天然具有图结构，需要专门的图论方法和机器学习算法来处理这些复杂的相互关系。

Method: 采用图神经网络作为主要学习算法，结合图设计基础理论和关键预测任务，构建化学图数据模型。

Result: 为化学发现提供了系统的图数据建模框架，展示了图方法在化学各领域的代表性应用案例。

Conclusion: 图数据建模方法为下一代化学发现做好了技术准备，图神经网络等算法将在化学科学中发挥重要作用。

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [176] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: 提出了一种轻量级深度学习模型，结合时间卷积网络和Mamba状态空间模型，仅使用RR间期数据即可提前2小时预测房颤，准确率高且计算效率优异


<details>
  <summary>Details</summary>
Motivation: 阵发性房颤(PAF)由于突发性和持续时间短，往往难以检测，但未检测到的PAF可能发展为持续性房颤，增加死亡风险和严重并发症。早期预测房颤为通过预防性治疗减少疾病进展提供了机会

Method: 使用轻量级深度学习模型，仅基于RR间期数据，将时间卷积网络(TCN)用于位置编码，结合选择性状态空间模型Mamba，实现高效的并行序列建模来进行房颤早期预测

Result: 在受试者测试中，模型灵敏度0.908，特异性0.933，F1分数0.930，AUROC 0.972，AUPRC 0.932。计算效率高，仅73.5千参数和38.3 MFLOPs，优于传统CNN-RNN方法。使用30分钟输入数据可提前2小时预测房颤

Conclusion: 该模型在房颤早期预测方面表现出色，具有高准确性和计算效率，为预防性干预提供了足够的前置时间，在房颤管理方面具有重要临床意义

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [177] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于信息几何和正则化的多模态大语言模型幻觉量化框架，通过温度逆变和氧勒-里茨约束来数学地量化和限定幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 现有的幻觉评估技术多为经验性的，缺乏理论基础和可行保证，导致在高风险领域无法理解幻觉的产生和传播机制。

Method: 通过将多模态输出表示为多模态图拉普拉斯矩阵的谱嵌入，并使用生成式模型的温度逆变过程来定义语义扭曲和幻觉能量。利用RKHS嵌入空间中的本征模分解来获得理论可解释的指标。

Result: 该框架能够提供理论保证的幻觉量化指标，可以捕捉幻觉在时间和不同提示下的演化过程，实现从定性检测到数学基础量化的转变。

Conclusion: 这个框架为幻觉现象建立了严格的理论基础，将其从一个定性风险转化为可处理、可分析的现象，为可信人工智能提供了重要支撑。

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [178] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: 基于LLaMA 3.2的视觉语言模型在高能物理中微子相互作用分类任务上表现优于传统CNN方法，支持多模态推理。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在多模态推理方面的潜力，特别是在高能物理实验中对中微子相互作用进行分类的任务。

Method: 使用基于LLaMA 3.2的视觉语言模型进行微调，将其性能与NOvA和DUNE实验中使用的CNN基线模型进行对比评估。

Result: VLM不仅达到或超过了CNN的性能，还支持更丰富的推理能力，并能更好地整合辅助文本或语义上下文信息。

Conclusion: 视觉语言模型为高能物理中的事件分类提供了一个有前景的通用骨干网络，为实验性中微子物理中的多模态方法铺平了道路。

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [179] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 本研究探索了量子机器学习在恶意软件分类中的应用，比较了量子多层感知器(QMLP)和量子卷积神经网络(QCNN)两种混合量子-经典模型在多个数据集上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的出现，量子机器学习为改进恶意软件检测提供了范式转换的机会，但该领域应用仍未被充分探索。

Method: 使用两种混合量子-经典模型：QMLP通过全量子比特测量和数据重新上传捕获复杂模式，QCNN通过量子卷积和池化层减少活跃量子比特来实现更快训练。两种模型都使用角度嵌入将恶意软件特征编码为量子态。

Result: 在二进制分类中达到95-96%准确率(API-Graph)、91-92%(AZ-Domain)和77%(EMBER-Domain)。多分类任务中准确率范围从41.7-95.7%不等。QMLP在复杂多分类任务中表现更优，而QCNN训练效率更高但准确率略低。

Conclusion: 量子机器学习在恶意软件分类中展现出良好潜力，QMLP适合复杂分类任务，QCNN在训练效率方面有优势，为量子计算在网络安全领域的应用提供了有价值见解。

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [180] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 提出了DETNO架构，结合Transformer神经算子和扩散模型，解决交通流预测中高频特征丢失和长期预测误差累积问题


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在交通流预测中会产生平滑预测，无法重建高频特征（如密度梯度），导致多步预测时误差快速累积，影响实时交通管理

Method: 采用统一的扩散增强Transformer神经算子架构，使用具有交叉注意力机制的Transformer神经算子提供模型表达能力和超分辨率，结合基于扩散的细化组件通过渐进去噪迭代重建高频交通细节

Result: 在混沌交通数据集上的综合评估表明，该方法在扩展预测方面优于传统和基于Transformer的神经算子，能够保留高频成分并在长期预测中提高稳定性

Conclusion: DETNO架构成功克服了标准神经算子的固有平滑限制和预测不稳定性，为长期交通预测提供了有效的解决方案

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [181] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 提出了一种混合量子-经典架构用于SMILES字符串重建，通过量子编码与经典序列建模的结合，实现了84%的量子保真度和60%的经典重建相似度，超越了现有量子基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管量子机器学习在分子设计等生成模型中具有潜力，但现有方法在SMILES字符串重建等序列任务中存在保真度下降的问题，量子与序列建模的整合研究不足。

Method: 采用混合量子-经典架构，将量子编码技术与经典序列建模相结合，旨在同时提升量子保真度和经典相似度。

Result: 该方法实现了约84%的量子保真度和60%的经典重建相似度，性能优于现有的量子基线方法。

Conclusion: 该工作为未来量子机器学习应用奠定了有前景的基础，在表达性量子表示和经典序列模型之间取得了平衡，推动了量子感知序列模型在分子和药物发现领域的更广泛研究。

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [182] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: 提出基于Kolmogorov-Arnold表示理论的哈密顿神经网络(KAR-HNN)，用单变量变换替代MLP，解决现有HNN对超参数敏感和能量漂移问题，在多个基准问题上验证了其准确性和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有哈密顿神经网络(HNN)通常使用多层感知机(MLP)，在处理复杂能量景观时对超参数过于敏感，导致能量漂移和长期预测稳定性差

Method: 利用Kolmogorov-Arnold表示理论，用单变量变换替代MLP，通过局部函数逼近更好地捕获高频和多尺度动力学，保持哈密顿系统的辛结构

Result: 在弹簧质量、单摆、二体和三体问题等四个基准问题上评估，显示KAR-HNN能减少能量漂移，提高长期预测稳定性

Conclusion: 该方法为高维度和参数稀缺的现实物理过程提供了准确稳定的建模方案，保持了物理一致性和可解释性

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [183] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: Llama-3.1-8B-Instruct在聊天格式中错误判断9.11>9.8，研究发现偶数注意力头负责数值比较，奇数头功能冲突，需要至少8个偶数头才能完美修复该bug。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在格式依赖推理中的失败机制，特别是数值比较错误，以揭示transformer内部工作机制和修复方法。

Method: 通过系统性干预实验，分析注意力头功能特化，使用稀疏自编码器(SAE)进行特征分析，测试不同头部组合的修复效果。

Result: 发现偶数索引头专门处理数值比较，需要至少8个偶数头才能完美修复错误；格式表示在层7分离(10%特征重叠)，在层10重新纠缠(80%重叠)；仅用25%注意力头即可实现完美修复。

Conclusion: transformer模型存在精细的亚结构，表观上的全模块需求隐藏着复杂的计算阈值和冗余机制，这对可解释性和效率优化具有重要意义。

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [184] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: 提出了一种物理信息机器学习工作流，结合可微分多相流模拟器和卷积神经网络，通过迁移学习大幅减少多相流模拟需求，从千万次降至数千次


<details>
  <summary>Details</summary>
Motivation: 地下储层压力控制面临地质异质性和多相流动力学的挑战，传统高保真物理模拟计算成本极高，且需要大量模拟来处理不确定性

Method: 使用DPFEHM框架中的完全可微分多相流模拟器与CNN结合，CNN学习从异质渗透率场预测流体提取率以控制关键位置压力。采用预训练-微调策略，先在单相稳态模拟上预训练，再在多相场景微调

Result: 仅需不到3000次全物理多相流模拟即可实现高精度训练，相比之前需要上千万次模拟的要求大幅减少。迁移学习显著降低了计算成本

Conclusion: 该方法通过物理信息机器学习和迁移学习，实现了对现实注采场景更实用和准确的预测，大幅降低了多相流模拟的计算负担

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [185] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 提出基于对比学习的无监督框架，对43种癌症类型进行聚类分析，使用基因水平和染色体水平的双重突变特征，通过对比学习获得有生物学意义的癌症聚类结果


<details>
  <summary>Details</summary>
Motivation: 理解泛癌突变景观对肿瘤发生机制至关重要。虽然患者级机器学习已广泛用于识别肿瘤亚型，但基于共享分子特征的队列级癌症聚类主要依赖传统统计方法

Method: 使用COSMIC数据库的编码突变数据，为每种癌症构建基因水平（高频突变基因的核苷酸替换模式）和染色体水平（染色体归一化替换频率）的双重突变特征。采用TabNet编码器和多尺度对比学习目标（NT-Xent损失）学习统一的癌症类型嵌入表示

Result: 学习到的潜在表示能够产生具有生物学意义的癌症类型聚类，与已知的突变过程和组织起源相一致

Conclusion: 这是对比学习在队列级癌症聚类中的首次应用，为突变驱动的癌症亚型分析提供了一个可扩展且可解释的框架

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [186] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 提出了一种基于空间填充采样的数据增强策略，通过局部"模板"状态的高效采样来生成神经PDE训练数据，相比传统轨迹数据采样方法显著提高了样本效率和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经PDE训练需要大量时间积分轨迹数据，存在时空冗余且可能遗漏罕见但重要的状态。需要更高效的采样方法来提高训练效率和模型泛化能力。

Method: 采用空间填充采样策略，从计算机模型中生成局部模板状态的训练数据，减少时空冗余并过采样罕见状态。仅需相当于10个时间步长的数值模拟数据即可训练准确的神经PDE模板算子。

Result: 在多个PDE系统上验证表明，该方法训练的神经模板算子性能优于传统轨迹采样方法。如果能够获得单个完整轨迹模拟数据，准确度还能进一步提升。

Conclusion: 提出的数据增强策略能够从极少量模拟数据中学习准确的神经PDE算子，显著提高了训练效率和模型泛化能力，为神经PDE的实际应用提供了有效解决方案。

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [187] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 通过在生成式模型中引入张量分解，生成小型因子矩阵而非完整大张量，显著降低生成多维数据的计算成本和模型参数量。


<details>
  <summary>Details</summary>
Motivation: 大规模复杂模拟实验耗费资源很大，需要更高效的生成合成数据方法来支持下游任务。

Method: 在GAN或渌散模型等生成式模型中集成张量分解技术，生成小型的张量因子而非生成完整的大张量。

Result: 实验结果显示该方法能够显著降低模型输出和参数量，同时保持生成数据的有用性。

Conclusion: 张量分解技术有潜力提高生成式模型的效率，尤其适用于多维数据生成场景。

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [188] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 本文证明了现代神经网络架构（如预层归一化和线性注意力模块）几乎总是满射的，这意味着任何输出都可以被生成，包括有害内容，揭示了模型安全性和越狱漏洞的固有脆弱性。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络是否总是能够生成任何指定的输出（即函数是否满射），这对于理解生成模型的安全性和越狱漏洞至关重要。满射性意味着包括有害内容在内的任何输出都可能被生成，引发模型安全担忧。

Method: 通过数学证明方法，分析了现代神经网络架构的基本构建模块，包括预层归一化网络和线性注意力模块，证明它们几乎总是具有满射性。

Result: 证明了广泛使用的生成框架（如GPT风格变换器和确定性ODE求解器的扩散模型）对任意输出都存在逆映射，即这些模型具有满射特性。

Conclusion: 研究为现代常用神经架构的满射性提供了形式化分析，揭示了它们对一类广泛对抗攻击不可避免的脆弱性，对模型安全性具有重要意义。

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [189] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 本文研究了成员推理攻击的样本复杂度，发现在高斯均值估计场景中，攻击者需要Ω(n + n²ρ²)个参考样本才能与完全知情的攻击者竞争，这比训练算法使用的样本数量多得多。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推理攻击通常假设攻击者拥有来自相同分布的参考样本，但实际中这些攻击使用的样本数量有限（O(n)）。本文旨在研究攻击者到底需要多少参考样本才能成功进行成员推理，特别是在高斯均值估计这一基础设置中。

Method: 研究在高斯分布N(μ,Σ)的高斯均值估计场景中，学习算法使用n个样本来估计均值μ，期望误差E[‖μ̂-μ‖²_Σ]≤ρ²d。分析攻击者进行成员推理所需的最小参考样本数量。

Result: 研究发现，对于任何能与完全知情攻击者竞争的成员推理攻击，攻击者需要Ω(n + n²ρ²)个参考样本。这是第一个显示攻击者有时需要比训练算法使用样本数量多得多的结果。

Conclusion: 当前实践中使用的攻击（使用O(n)样本）可能低估了成员推理的可能性。当容易获得分布信息时，可能存在更好的攻击方法，这对实际应用有重要影响。

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [190] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [191] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas是一种能够生成数据局部邻域低维表示并训练深度神经网络在局部嵌入和原始数据间映射的算法，通过拓扑失真评估数据集是否来自流形并确定其维度。


<details>
  <summary>Details</summary>
Motivation: 当前流形学习工具只能生成数据的全局嵌入，无法提供数学定义流形所需的局部映射，也不能验证流形假设是否对特定数据集成立。

Method: 算法首先生成数据局部邻域的低维表示，然后训练深度神经网络在这些局部嵌入和原始数据之间建立映射关系，使用拓扑失真来评估流形假设和确定维度。

Result: 在测试数据集上DeepAtlas成功学习了流形结构，但发现许多真实数据集（包括单细胞RNA测序数据）并不符合流形假设。对于确实来自流形的数据，该模型可用于生成式应用。

Conclusion: DeepAtlas能够验证流形假设并学习流形结构，为符合流形假设的数据集提供了生成式建模的可能性，并有望将微分几何的强大工具应用于各种数据集。

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [192] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: 提出了SAFT框架来解决表格学习中分布偏移问题，通过连续表示生成范式实现可微分优化，包含三个鲁棒性机制，在多种真实分布偏移场景下优于现有方法


<details>
  <summary>Details</summary>
Motivation: 表格学习在训练和测试数据存在分布偏移时效果会显著下降，需要解决这种分布偏移下的表格学习问题

Method: SAFT框架将表格学习重构为连续表示生成范式，包含三个机制：嵌入去相关和样本重加权的偏移抵抗表示、次优嵌入平均的平坦感知生成、训练测试分布间的归一化对齐

Result: 大量实验表明SAFT在鲁棒性、有效性和泛化能力方面持续优于先前的表格学习方法

Conclusion: SAFT成功解决了分布偏移表格学习问题，通过可微分优化和多重鲁棒机制实现了优异的性能表现

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [193] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: EQUATE是一个通过质量对齐迁移嵌入的方程生成框架，用于在低数据量情况下通过蒸馏方法微调基础模型进行符号方程发现，在多个基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型在大规模方程数据集上预训练后，在应用到小型领域特定数据集时经常出现负迁移和泛化能力差的问题，需要一种数据高效的微调框架。

Method: EQUATE结合符号-数值对齐和评估器引导的嵌入优化，将离散方程搜索重新表述为共享嵌入空间中的连续优化任务，通过数据-方程拟合度和简洁性进行指导。

Result: 在三个标准公共基准测试（Feynman、Strogatz和黑盒数据集）上，EQUATE在准确性和鲁棒性方面始终优于最先进的基线方法，同时保持低复杂度和快速推理。

Conclusion: EQUATE为在基础模型蒸馏设置中实现数据高效的符号回归提供了一个实用且可推广的解决方案。

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [194] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: 提出了PoolFlip环境和Flip-PSRO方法，通过多智能体强化学习训练网络防御者，使其能够泛化到未见过的攻击策略，效果比基线方法提升2倍


<details>
  <summary>Details</summary>
Motivation: 现有FlipIt框架依赖少量启发式或专门学习技术，存在脆弱性和无法适应新攻击的问题，需要更强大的自适应防御方法

Method: 开发PoolFlip多智能体训练环境，提出Flip-PSRO多智能体强化学习方法，利用基于种群的训练来训练防御者智能体，并设计基于所有权的效用函数

Result: Flip-PSRO防御者对训练中未暴露的启发式攻击的泛化能力比基线方法强2倍，同时保持高水平控制并优化性能

Conclusion: Flip-PSRO为网络防御提供了有效的自适应决策框架，能够应对隐蔽、欺骗性和不断演化的对抗策略

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [195] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 使用Python程序表示游戏策略，通过大语言模型优化代码实现自我进化，在Atari游戏中达到与深度强化学习相当的性能，但训练时间和环境交互显著减少


<details>
  <summary>Details</summary>
Motivation: 探索程序化策略表示方法，利用大语言模型的代码生成和优化能力，减少对大量环境交互的依赖，构建更高效、适应性强的游戏智能体

Method: 将决策策略表示为Python程序，使用LLM基于执行轨迹和自然语言反馈进行代码优化，实现策略的自我进化，最小化人工干预

Result: 在Atari游戏中取得与深度强化学习基线竞争性的性能，同时训练时间显著减少，环境交互次数大幅降低

Conclusion: 程序化策略表示方法具有巨大潜力，能够构建高效、适应性强的智能体，具备复杂长时程推理能力

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [196] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: MobText-SISA是一个针对异构时空数据的机器遗忘框架，通过分片、隔离、切片和聚合训练实现高效删除，在保持预测准确性的同时满足隐私法规要求


<details>
  <summary>Details</summary>
Motivation: 现代移动平台存储了大量GPS轨迹和文本数据，GDPR等隐私法规要求能够按需删除个人数据，但为每个删除请求重新训练深度模型不可行

Method: 将行程的数值和语言特征嵌入共享潜在空间，使用相似性感知聚类将样本分布到分片中，每个分片增量训练，删除时仅重新训练受影响的分片

Result: 在10个月真实移动数据上的实验表明，MobText-SISA保持基线预测准确性，在错误率和收敛速度上均优于随机分片方法

Conclusion: MobText-SISA为多模态移动数据的隐私合规分析提供了实用基础，能够在城市规模下实现精确遗忘

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [197] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: LLMs在表格数据拟合中存在严重脆弱性，任务无关的数据表示变化（如变量名更改）会导致预测结果大幅波动，即使专门设计的表格基础模型也无法完全避免此问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在数据拟合任务中的广泛应用，需要评估其对任务无关数据变化的鲁棒性，以确保其作为数据拟合工具的可靠性。

Method: 通过改变变量名等任务无关的数据表示方式，测试LLMs在上下文学习和监督微调下的预测敏感性，并分析注意力模式来解释敏感性原因。

Result: 变量名更改等无关变化可使预测误差波动高达82%，注意力分析显示某些位置的数据会获得不均衡的关注，导致预测敏感性。

Conclusion: 尽管LLMs在预测性能上表现出色，但目前缺乏基本的鲁棒性，不能作为可靠的数据拟合工具使用。

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [198] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: Bi-LoRA是一种改进的LoRA方法，通过引入辅助LoRA模块来模拟SAM的对抗性权重扰动，在保持内存效率的同时实现更平坦的最小值，消除了SAM的双倍训练成本。


<details>
  <summary>Details</summary>
Motivation: SAM虽然能通过寻找平坦最小值来改善泛化能力，但其巨大的内存和计算开销使其不适用于大型模型。直接将SAM应用于LoRA参数会限制锐度优化的效果。

Method: 提出双向低秩适应(Bi-LoRA)，引入辅助LoRA模块来建模SAM的权重扰动。主LoRA模块通过标准梯度下降适应任务，辅助模块通过梯度上升捕获损失景观的锐度。

Result: 在多种任务和架构上的广泛实验表明，Bi-LoRA在提高泛化能力方面既高效又有效。

Conclusion: Bi-LoRA通过双模块设计成功解决了SAM在大型模型中的内存和计算效率问题，同时实现了更好的泛化性能。

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [199] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: 提出了一种基于因果推理的多模态反事实奖励模型，通过Counterfactual Trust Score来减少RLHF中的偏见，在假新闻检测中达到89.12%准确率并显著降低虚假相关性。


<details>
  <summary>Details</summary>
Motivation: RLHF中的奖励模型会放大数据集的潜在偏见，导致策略优化不完善和公平性下降。现有偏见缓解方法在因果混淆情况下容易失效。

Method: 结合因果推理和多模态表示学习，提出Counterfactual Trust Score，包含四个组件：反事实偏移、重构不确定性、公平规则违反检测和时间奖励偏移。

Result: 在多模态真假新闻数据集上实现89.12%的假新闻检测准确率，优于基线奖励模型，显著减少了虚假相关性和不公平强化信号。

Conclusion: 该方法为公平感知的RLHF提供了鲁棒且可解释的解决方案，具有可调节的偏见减少阈值，提高了动态实时策略制定的可靠性。

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [200] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 本教程介绍生成式模型在合成数据生成方面的基础和最新进展，涵盖关键方法、实践框架、评估策略和应用，旨在帮助数据挖掘研究者和从业者利用合成数据解决数据稀缺、隐私和标注挑战。


<details>
  <summary>Details</summary>
Motivation: 解决数据挖掘中的数据稀缺、隐私保护和标注成本高等挑战，通过生成式模型创建高质量的合成数据来增强数据可用性。

Method: 介绍大型语言模型、扩散模型和生成对抗网络等生成式模型的基础理论和最新技术，提供实用的框架和方法论。

Result: 提供了可操作的见解，使参与者能够利用生成式合成数据来提升数据挖掘研究和实践效果。

Conclusion: 生成式合成数据为数据挖掘领域提供了可扩展的解决方案，能够有效应对数据稀缺、隐私和标注等核心挑战。

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [201] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 提出SyReM方法解决运动预测中持续学习的稳定性-可塑性困境，通过记忆缓冲和选择性回放机制，在11个驾驶数据集上显著缓解灾难性遗忘并提升新场景预测精度


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在运动预测中面临灾难性遗忘问题，现有持续学习方法过度强调记忆稳定性会损害学习可塑性，需要平衡稳定性与可塑性的矛盾

Method: SyReM方法维护紧凑记忆缓冲区，使用不等式约束确保记忆稳定性，同时基于损失梯度余弦相似度设计选择性记忆回放机制来增强学习可塑性

Result: 在INTERACTION的11个自然驾驶数据集上验证，相比非持续学习和持续学习基线，SyReM显著缓解了过去场景的灾难性遗忘，同时提高了新场景的预测精度

Conclusion: SyReM通过协同记忆回放机制有效解决了持续学习中的稳定性-可塑性困境，为运动预测领域的持续学习提供了有效解决方案

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [202] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: Delta-Attribution是一个模型无关的框架，通过差分特征归因来解释模型版本间的变化原因，提供轻量级的更新审计。


<details>
  <summary>Details</summary>
Motivation: 模型更新（超参数、核函数、深度、求解器或数据）会改变性能，但变化原因往往不透明，需要一种方法来解释版本间的差异。

Method: 通过差分特征归因Δφ(x)=φ_B(x)-φ_A(x)，使用Δ-归因质量套件评估变化，包括幅度/稀疏性、一致性/偏移、行为对齐和鲁棒性指标。

Result: 在45个设置中测试发现，归纳偏置变化产生大的行为对齐delta（如SVC poly→rbf：BAC≈0.998），而表面调整显示完全一致（rank-overlap@10=1.0）。

Conclusion: Δ-归因提供了一种轻量级的更新审计方法，通过区分良性变化和行为上有意义或风险依赖转移来补充准确性评估。

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [203] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: Dual-LS是一种受人类大脑互补学习系统启发的在线持续学习范式，通过双协同记忆重放机制解决DNN车辆运动预测中的灾难性遗忘问题，显著提升预测稳定性并大幅降低计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 智能城市服务依赖AI，但深度神经网络在车辆运动预测中面临灾难性遗忘问题，传统方法数据收集成本高且无法平衡长短期经验，无法实现人类般的持续学习。

Method: 提出Dual-LS范式，采用两种协同的记忆重放机制，加速经验检索并动态协调长短期知识表示，实现任务无关的在线持续学习。

Result: 在三个国家超过77.2万辆车辆、累计测试里程11,187公里的自然数据测试中，灾难性遗忘减少74.31%，计算资源需求降低94.02%，预测稳定性显著提升。

Conclusion: Dual-LS为基于DNN的车辆运动预测提供了计算高效、人类般的持续学习适应性，适合智能城市应用，且不增加数据需求。

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [204] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: RLTR框架通过工具使用奖励的强化学习，解耦训练过程，专注于规划模块的单目标优化，相比端到端方法在规划性能上提升8-12%，最终响应质量提升5-6%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体训练采用端到端多目标优化，面临优化目标分配不平衡和可验证数据稀缺的问题，难以有效提升规划能力。

Method: 提出RLTR框架，通过基于工具使用完整性的奖励信号来直接评估工具调用序列质量，实现规划模块的单目标优化，无需可验证数据。

Result: 实验显示RLTR在规划性能上比端到端基线提升8-12%，增强的规划能力使整体系统的最终响应质量提升5-6%。

Conclusion: RLTR通过解耦训练和工具使用奖励机制，有效解决了LLM智能体规划能力训练的挑战，显著提升了性能表现。

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [205] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: FinCast是首个专门为金融时间序列预测设计的基础模型，通过在大规模金融数据集上训练，实现了强大的零样本性能，无需领域特定微调即可捕捉多样化模式，超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测对经济稳定、政策制定和可持续投资至关重要，但由于时间非平稳性、多领域多样性和不同时间分辨率等模式变化而具有挑战性。现有深度学习方法存在过拟合问题且需要大量领域特定微调。

Method: 开发FinCast基础模型，在大规模金融数据集上进行训练，专门针对金融时间序列预测设计，具备零样本预测能力。

Result: FinCast表现出强大的零样本性能，能够有效捕捉多样化模式而无需领域特定微调，在综合实证和定性评估中超越了现有最先进方法。

Conclusion: FinCast作为首个金融时间序列预测基础模型，展示了强大的泛化能力，为解决金融预测中的模式变化挑战提供了有效解决方案。

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [206] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: ALSA是一种在logit空间中直接操作的模型精度估计框架，通过锚点建模策略保留更丰富的信息，在分布偏移下提供鲁棒的精度估计


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖softmax概率或数据相似性度量，前者存在信息损失，后者计算昂贵且领域特定。需要在分布偏移下准确估计模型在未见未标注数据上的性能

Method: ALSA在logit空间中使用多个可学习锚点，每个锚点分配影响函数来捕捉logit的细微变化，利用logit聚合和分布与模型预测性能的强相关性

Result: 在视觉、语言和图基准测试上的广泛实验显示，ALSA优于基于softmax和相似性的基线方法，在显著分布偏移下表现出强大的鲁棒性

Conclusion: ALSA是一个实用的可靠模型评估工具，通过直接在logit空间操作避免了信息损失，为分布偏移下的模型精度估计提供了有效解决方案

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [207] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: 提出了pFedBayesPT，一种基于视觉提示调优的细粒度实例级个性化联邦学习框架，通过贝叶斯方法建模提示后验分布来处理客户端内部数据异质性。


<details>
  <summary>Details</summary>
Motivation: 现有个性化联邦学习方法假设每个客户端数据遵循单一分布，但实际中单个客户端可能包含多个来源或领域的数据，导致显著的客户端内部异质性和次优性能。

Method: 从贝叶斯视角制定实例级提示生成，将提示后验建模为隐式分布以捕捉多样视觉语义，在半隐式变分推断框架下推导变分训练目标。

Result: 在基准数据集上的广泛实验表明，pFedBayesPT在特征和标签异质性设置下始终优于现有pFL方法。

Conclusion: 该方法有效解决了客户端内部数据异质性挑战，通过实例级个性化提升了联邦学习性能。

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [208] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: SCAR是一个数据质量评估框架，通过Scale、Coverage、Authenticity、Richness四个维度量化数据集的结构特性，并基于此提出Foundation Data概念和模态感知的数据补全策略。


<details>
  <summary>Details</summary>
Motivation: 传统数据优化方法主要关注数据量和训练效率，缺乏对数据质量结构特性的理论理解，特别是在样本缩放时数据特性如何影响泛化能力。

Method: 提出SCAR框架量化数据集的结构特性，定义Foundation Data作为最小子集保持泛化能力，建立单模态任务的阶跃函数模型，开发模态感知的数据补全策略。

Result: 在多种多模态数据集和模型架构上的实验验证了SCAR在预测数据效用和指导数据获取方面的有效性。

Conclusion: SCAR提供了一个稳定且通用的数据理解基础，能够有效指导多模态数据集的高效扩展和优化。

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [209] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 首次完整探索低功耗灵活压力分类器设计空间，设计了1200多个灵活分类器，通过机器学习分类器、特征选择和神经网络简化算法，实现了比当前方法更高准确度的实时压力监测。


<details>
  <summary>Details</summary>
Motivation: 传统压力监测方法缺乏连续性和可访问性，现有硬性可戴设备不适合轻便灵活戴扮，而灵活电子技术虽有优势但难以集成复杂的机器学习分类器。

Method: 进行了计算机辅助设计空间探索，涵盖多种机器学习分类器、特征选择和神经网络简化算法，设计了超过1200个灵活分类器，采用低精度算术和完全定制电路以优化硬件效率。

Result: 开发出了能够实现高于当前方法准确度的实时压力分类器，同时具有低成本、可形变性、低功耗和小尺寸的特点。

Conclusion: 该研究为设计实时压力分类器提供了重要见解，推动了灵活电子技术在连续健康监测领域的应用。

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [210] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 该论文展示了正则函数可以用有理函数和有理神经网络在C¹范数下进行近似，并提供了关于网络宽度、深度以及有理函数次数的近似率。


<details>
  <summary>Details</summary>
Motivation: 研究正则函数的有理近似方法，特别是在符号回归和物理定律学习背景下，为EQL^÷和ParFam架构提供理论支持。

Method: 使用有理函数和有理神经网络进行C¹范数近似，分析网络宽度、深度以及有理函数次数对近似效果的影响。

Result: 获得了正则函数在C¹范数下的有理近似结果，包括具体的近似率，并推广到EQL^÷和ParFam架构。

Conclusion: 有理函数和有理神经网络能够有效近似正则函数，为符号回归和物理定律学习提供了理论基础和实用方法。

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [211] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 该论文研究图上游走的度量结构，引入加权度量处理序列，定义基于逐步顶点距离和加权范数的游走间距离，分析度量空间性质，提出邻近度表示公式和构造方法，支持度量建模经典工具应用。


<details>
  <summary>Details</summary>
Motivation: 研究图上游走的度量结构，为分析游走间相对距离的弱形式测量工具（邻近度）提供理论基础，支持网络结构上的Lipschitz回归等应用。

Method: 引入加权度量处理序列，定义基于逐步顶点距离和加权范数的游走间距离，分析度量空间性质，提供邻近度的表示公式和显式构造方法。

Result: 建立了图游走的度量框架，提供了邻近度的表示公式和构造方法，支持Lipschitz函数从游走子空间的扩展等经典度量建模工具的应用。

Conclusion: 提出的度量框架为估计邻近度和开发基于探索性游走的强化学习策略提供了稳健方法，可用于网络结构上的Lipschitz回归等应用。

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [212] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: 提出了Adam-PFN，一种用于Adam超参数优化的新型代理模型，结合CDF增强方法，显著提升了学习曲线外推能力和超参数优化效率。


<details>
  <summary>Details</summary>
Motivation: Adam优化器广泛使用但超参数调优耗时昂贵，现有的Freeze-thaw贝叶斯优化方法受限于通用代理模型，缺乏对超参数如何影响学习的先验知识。

Method: 开发了Adam-PFN代理模型，在TaskSet的学习曲线上进行预训练，并提出CDF-augment学习曲线增强方法，人工增加训练样本数量。

Result: 在TaskSet评估任务上显著改善了学习曲线外推能力并加速了超参数优化，在分布外任务上也表现出强劲性能。

Conclusion: Adam-PFN结合CDF增强方法为Adam超参数优化提供了有效的解决方案，能够显著提升优化效率和性能。

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [213] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: InfraredGP是一种无需训练的图分割方法，通过负校正机制扩展图拉普拉斯算子的频率范围，利用低频信息生成可区分的图嵌入，在IEEE HPEC图挑战基准测试中实现了16-23倍的速度提升和竞争性的分割质量。


<details>
  <summary>Details</summary>
Motivation: 传统图分割方法通常基于图拉普拉斯算子在[0,2]范围内的频率信息。研究发现通过负校正可以扩展频率范围，探索超出该范围的低频信息是否能更好地编码社区结构信息。

Method: 采用谱GNN作为主干网络，结合低通滤波器和负校正机制；仅输入随机信号；通过单次前向传播生成图嵌入而不需要训练；使用BIRCH聚类算法获得图分割结果。

Result: 实验表明InfraredGP仅通过负校正机制就能生成可区分的嵌入，在静态和流式图分割任务中实现16-23倍的效率提升，同时保持竞争性的分割质量。

Conclusion: 负校正机制能够有效扩展图频率范围，低频信息确实包含丰富的社区结构信息，InfraredGP提供了一种高效且无需训练的图分割解决方案。

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [214] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 提出基于3D扩散模型的生成管道，直接合成任意大小的真实物理配置颗粒介质，显著加速离散元法模拟的初始化阶段


<details>
  <summary>Details</summary>
Motivation: 离散元法模拟颗粒介质时，初始化阶段计算成本高，涉及大位移和动能，主导总模拟时间，需要克服这一瓶颈

Method: 两阶段管道：首先训练扩散模型生成独立3D体素网格；其次使用基于掩码输入的3D修复模型无缝拼接网格，采用多种掩码策略和2D重绘技术，确保长时一致性

Result: 计算时间与样本大小呈线性缩放，1.2米长有砟轨道合成等效于3小时DEM模拟，在20秒内完成

Conclusion: 该方法可实现物理一致、实时、可扩展的颗粒介质合成，适用于工业应用，生成的体素网格可后处理提取颗粒几何形状以兼容DEM

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [215] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: EUREKA框架通过选择有趣而非最准确的特征来构建分类器，利用大语言模型评估特征有趣性，在保持有意义准确度的同时提供新颖见解


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型追求最大化预测准确率，但本文探索构建"有趣分类器"的目标，即使用不寻常或意外的特征，即使准确率低于最佳模型，以支持知识发现和沟通

Method: 提出EUREKA框架，利用大语言模型根据感知有趣性对特征进行排序，然后仅使用选定的有趣特征构建可解释分类器

Result: 在多个基准数据集上，EUREKA始终识别出非明显但仍具有预测性的特征。例如在Occupancy Detection数据集中偏好湿度而非CO2水平和光照强度，在Twin Papers数据集中发现标题包含冒号的论文更可能被引用

Conclusion: 这种模型可以支持新的知识发现和沟通方式，特别是在中等准确度足够但新颖性和可解释性受到重视的场景中

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [216] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: PSO-Merging是一种基于粒子群优化的数据驱动模型融合方法，通过初始化粒子群并进行多轮迭代，在语言模型上表现优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型融合方法存在性能限制：数据无关方法缺乏数据指导，梯度方法计算成本高，无梯度方法优化步数有限效果不佳。

Method: 使用粒子群优化(PSO)算法，以预训练模型、专家模型和稀疏化专家模型初始化粒子群，通过多轮迭代获得最终融合模型。

Result: 在不同语言模型上的实验结果表明，PSO-Merging普遍优于基线融合方法。

Conclusion: PSO-Merging为模型融合提供了更高效和可扩展的解决方案。

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [217] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 提出了一种新的辛卷积神经网络架构，通过结合辛神经网络、适当辛分解和张量技术来构建保持辛结构的CNN模型


<details>
  <summary>Details</summary>
Motivation: 传统CNN在处理哈密顿系统时无法保持物理系统的辛结构，需要开发能够保持辛几何性质的神经网络架构

Method: 首先引入卷积层的数学等价形式，然后使用辛神经网络参数化CNN层以确保卷积层保持辛性，并引入辛池化层构建完整的自编码器

Result: 在波动方程、非线性薛定谔方程和正弦-戈登方程三个示例上测试，数值结果表明辛CNN性能优于通过适当辛分解获得的线性辛自编码器

Conclusion: 提出的辛CNN架构成功保持了哈密顿系统的辛结构，在物理系统建模方面表现出优越性能

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [218] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: 提出了一种混合框架，将有限元方法与物理信息DeepONet结合，用于模拟多孔介质中来自尖锐高斯源的流体输运问题，实现了高精度和快速推理。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多孔介质中尖锐源引起的陡峭梯度时计算成本高昂，需要一种既能保持精度又能大幅加速的计算方法。

Method: 使用FEM求解达西流方程获得速度场，然后通过物理信息DeepONet学习从源函数到溶质浓度分布的映射，并引入自适应采样策略处理陡峭梯度。

Result: 数值实验表明该方法与参考解吻合良好，相比传统求解器实现了数量级的加速，适用于实际应用场景。

Conclusion: 该混合框架成功结合了FEM的精度和DeepONet的快速推理优势，为多孔介质流体输运问题提供了高效实用的解决方案。

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [219] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 本文研究量子潜在分布在生成模型中的优势，证明在某些条件下量子潜在分布能够生成经典方法无法高效生成的数据分布，并通过实验验证了量子潜在分布在GAN模型中的性能提升效果。


<details>
  <summary>Details</summary>
Motivation: 虽然简单的经典潜在分布常用于生成模型，但更复杂的分布可以提高性能。最近研究发现量子处理器产生的分布能够带来实验性的性能提升，但量子优势的具体条件和可复现性仍不明确。

Method: 采用理论证明和实验验证相结合的方法。首先理论证明在某些条件下量子潜在分布的优势，然后通过在合成量子数据集和QM9分子数据集上进行基准测试，使用模拟和实际光子量子处理器。还研究了扩散模型和流匹配模型与量子潜在分布的兼容性。

Result: 实验结果显示，量子潜在分布在GAN模型中能够导致比多种经典基准方法更好的生成性能。研究还确定了适合量子潜在分布的模型架构，并提供了识别量子优势的具体直观指南。

Conclusion: 近期量子处理器能够扩展深度生成模型的能力，量子潜在分布在某些条件下具有经典方法无法模仿的生成能力，为量子机器学习领域提供了重要的理论基础和实践指南。

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [220] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: 本文提出了一种基于结构多样性的无参数图神经网络框架SDGNN，通过结构多样性消息传递机制同时捕获邻域结构异质性和特征语义稳定性，无需可训练参数，在多个数据集上优于主流GNN方法。


<details>
  <summary>Details</summary>
Motivation: 传统GNN方法依赖大量可训练参数和固定聚合规则，难以适应结构异质性强的图数据，容易导致节点表示过平滑和语义退化问题。

Method: 基于结构多样性理论设计统一的结构多样性消息传递机制，从结构驱动和特征驱动两个角度进行互补建模，无需复杂模型训练。

Result: 在8个公共基准数据集和PubMed跨学科引用网络上，SDGNN在低监督、类别不平衡和跨域迁移等挑战性条件下持续优于主流GNN方法。

Conclusion: 该工作为无参数图神经网络设计提供了新的理论视角和通用方法，验证了结构多样性作为图表示学习核心信号的重要性。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [221] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: 提出NM-Hebb两阶段训练框架，结合神经启发局部可塑性和距离感知监督，在多个数据集和骨干网络上实现准确率显著提升和特征可解释性增强


<details>
  <summary>Details</summary>
Motivation: 解决传统CNN依赖全局梯度优化导致的过拟合、冗余滤波器和可解释性差的问题

Method: 第一阶段：联合交叉熵损失与Hebbian正则化器和可学习神经调节器；第二阶段：使用成对度量学习损失微调骨干网络

Result: 在CIFAR-10、CIFAR-100和TinyImageNet上Top-1准确率提升2.0-10.0个百分点，NMI提升最高0.15

Conclusion: 结合局部Hebbian可塑性和度量微调产生更准确、可解释的CNN，对资源受限和安全关键AI部署具有实际价值

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [222] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: ASPC提出了一种自适应策略约束缩放框架，通过二阶可微分方法动态平衡强化学习和行为克隆，无需针对不同数据集进行超参数调优，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习方法需要针对不同任务和数据集质量精心调整策略约束的超参数，这个过程耗时且不实用，需要一种自适应的约束缩放方法。

Method: 提出了自适应策略约束缩放（ASPC）框架，这是一个二阶可微分方法，能够在训练过程中动态平衡强化学习和行为克隆，避免手动超参数调优。

Result: 在4个D4RL领域的39个数据集上，ASPC使用单一超参数配置就优于其他自适应约束方法和需要逐数据集调优的最先进算法，且计算开销极小。

Conclusion: ASPC提供了一种有效且实用的离线强化学习解决方案，通过自适应约束缩放机制解决了传统方法需要大量超参数调优的问题，具有很好的泛化性能。

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [223] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: GegenNet是一种新颖的谱卷积神经网络模型，专门用于有符号二分图的链接符号预测，通过Gegenbauer多项式基滤波器等技术显著提升了预测性能


<details>
  <summary>Details</summary>
Motivation: 现有链接符号预测方法主要针对单部有符号图，忽略了二分图的节点异质性和独特特征。虽然近期研究将图神经网络应用于有符号二分图，但基础的谱卷积算子最初是为无符号图的正链接设计的，不适用于从已知链接推断缺失的正负链接

Method: 提出GegenNet模型，包含三个关键技术：(1)快速且理论基础的节点特征初始化谱分解技术；(2)基于Gegenbauer多项式基的新谱图滤波器；(3)多层符号感知谱卷积网络，交替使用正负边的Gegenbauer多项式滤波器

Result: 在6个基准有符号二分图数据集上与11个强竞争对手相比，GegenNet在链接符号预测方面取得了显著优越的性能（AUC提升高达4.28%，F1提升高达11.69%）

Conclusion: GegenNet通过创新的谱卷积方法有效解决了有符号二分图的链接符号预测问题，证明了基于Gegenbauer多项式的谱滤波器在该任务中的有效性

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [224] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 提出基于UMLS本体概念的放射学报告检索方法，通过标准化医学实体提取和语义相似度计算，在胸部X光罕见疾病检测任务中优于现有嵌入方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP或CXR-BERT等高维文本嵌入的医学影像检索方法存在可解释性差、计算成本高且与医学知识结构化特性不匹配的问题。

Method: 使用RadGraph-XL和SapBERT增强管道从自由文本报告中提取标准化医学实体并链接到UMLS概念，基于改进的加权Tversky指数定义任务自适应相似度度量。

Result: 在MIMIC-CXR放射影像分类任务中，特别是在长尾设置下，该方法优于最先进的基于嵌入的检索方法，并为MIMIC-CXR生成了本体支持的新疾病标签资源。

Conclusion: 该方法为临床AI系统提供了更可解释、可靠和任务特定的检索策略，特别是在需要可解释性和领域知识整合的场景中具有重要价值。

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [225] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer是一个基于BERT的预训练模型，专门用于网络流量分析，通过创新的流量表示、协议语义嵌入和预训练任务，显著提升了流量分类效果。


<details>
  <summary>Details</summary>
Motivation: 现有网络流量分类方法难以有效捕捉数据包结构特征、流级行为、分层协议语义和包间上下文关系，需要更专业的预训练模型来解决这些挑战。

Method: 提出FlowletFormer模型，包含：1) 连贯行为感知流量表示模型分割语义单元；2) 协议栈对齐嵌入层捕捉多层协议语义；3) 字段特定和上下文感知预训练任务增强包间和流间学习。

Result: 实验结果表明FlowletFormer在流量表示效果、分类准确性和少样本学习能力方面显著优于现有方法，并能更好地理解网络传输原理（如TCP状态连接）。

Conclusion: FlowletFormer通过有效整合领域特定的网络知识，为流量分析提供了更鲁棒和可信的框架，在多个关键指标上表现出色。

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [226] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: 提出基于逆动态博弈的算法，从多智能体局部广义纳什均衡交互数据中学习参数化约束。通过混合整数线性规划编码KKT条件，恢复与纳什平稳性一致的约束，并建立理论保证学习真实安全/非安全集的内近似。


<details>
  <summary>Details</summary>
Motivation: 从智能体交互演示中学习底层约束对于理解多智能体系统的行为模式和设计安全的运动规划至关重要。现有方法在从纳什均衡交互中学习约束方面存在局限。

Method: 使用混合整数线性规划(MILP)编码交互智能体的KKT条件，通过逆动态博弈框架恢复与演示数据纳什平稳性一致的参数化约束。

Result: 方法能够从非线性动力学智能体的交互演示中推断凸和非凸约束，学习到的约束可用于设计鲁棒满足底层约束的交互运动规划。仿真和硬件实验验证了有效性。

Conclusion: 该工作提供了从纳什均衡交互中学习约束的系统方法，建立了理论保证，并展示了在运动规划中的实际应用价值，为多智能体系统的约束学习和安全交互设计提供了新途径。

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [227] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijeet Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: 本文提出了全局排列熵(GPE)，这是一种新的复杂度指标，不仅考虑连续段落的排列模式，还包含所有可能长度的非连续模式，通过高效算法提取完整排列分布，在合成数据集上显示出比标准排列熵更强的结构信息提取能力。


<details>
  <summary>Details</summary>
Motivation: 标准排列熵只基于连续段落的相对顺序模式，可能遗漏时间序列中的重要结构信息。为了更全面地捕捉时间序列的复杂度特征，需要开发能够考虑所有可能排列模式（包括非连续模式）的新方法。

Method: 开发全局排列熵(GPE)指标，利用最新算法高效提取完整排列分布，考虑给定长度的所有可能模式（包括非连续模式），然后应用香农熵进行复杂度量化。

Result: 在合成数据集上的实验表明，GPE能够揭示标准排列熵无法获取的结构信息，显示出更强的模式识别能力。

Conclusion: 全局排列熵(GPE)作为标准排列熵的有效扩展，提供了更全面的时间序列复杂度分析工具，并提供了相应的Julia计算包便于实际应用。

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [228] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 基于机器学习的工业离心泵短期故障预测框架，使用随机森林和XGBoost模型，通过60分钟和120分钟滑动窗口提取统计特征，在5-30分钟预警时间内实现48.6%-69.2%的召回率。


<details>
  <summary>Details</summary>
Motivation: 为工业离心泵开发实时故障预警系统，通过预测性维护减少设备停机时间和维修成本，提高工业生产效率。

Method: 使用滑动窗口方法（60分钟和120分钟）提取统计特征（均值、标准差、最小值、最大值、线性趋势），采用SMOTE算法处理类别不平衡，训练随机森林和XGBoost分类器进行故障预测。

Result: 随机森林模型在60分钟窗口下表现最佳：5分钟预警召回率69.2%，15分钟64.9%，30分钟48.6%。120分钟窗口下，5分钟召回率57.6%，15和30分钟均为65.6%。XGBoost性能略低。

Conclusion: 预测性能取决于历史数据长度和预警时间范围，不同故障模式可能在不同时间尺度上演变。该方法为实时工业监控系统提供了可解释且可扩展的预测性维护解决方案。

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [229] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 基于移动设备的实时停车助手系统，通过数据驱动模拟分析了不同策略对寻找街道停车时间的影响，提出了一种新的Cord-Approx策略能大幅缩短寻找时间。


<details>
  <summary>Details</summary>
Motivation: 在密集城市中，寻找街道停车位加剧了交通拕塞问题。虽然基于移动设备的实时助手已经被提出，但其效果并未得到充分研究。

Method: 通过马德里街道停车生态系统的数据驱动模拟，分析四种策略：无协调搜索(Unc-Agn)、协调停车但不知道非使用者(Cord-Agn)、理想化神谕系统(Cord-Oracle)和新颖的Cord-Approx策略。Cord-Approx使用过去占用分布来估计非使用者行为，通过拉长物理距离并解决包包匹配问题。

Result: 在高保真度的马德里交通数据模拟中，Cord-Approx用户平均只需6.69分钟找到停车位，而非系统用户需19.98分钟。在中央桥站区域，Cord-Approx将系统用户的寻找时间减少72%（67-76%），在住宅区域可达73%。

Conclusion: Cord-Approx策略通过概率性估计非使用者行为，能够在不需要完整信息的情况下实现很好的停车效果，显著缩短了停车寻找时间并减轻城市交通拕塞。

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [230] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 语言模型在密码验证任务中表现不佳，推理能力反而会泄露机密信息，当前前沿模型不适合处理机密信息


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在高风险环境中作为自主代理部署，确保其可靠遵循用户定义的规则已成为关键的安全问题，需要研究模型是否具备上下文鲁棒性

Method: 开发PasswordEval基准测试，评估语言模型在密码验证任务中的表现，包括对抗性用户压力和长对话场景的测试

Result: 当前开源和闭源模型在这个看似简单的任务中都表现不佳，推理能力通常不会改善性能，反而经常泄露机密信息

Conclusion: 当前前沿模型不适合处理机密信息，推理能力需要以不同方式训练才能在高风险环境中更安全地部署

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [231] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出一种新的自监督预训练方法，通过双层优化和平衡约束处理异构数据，提高模型在下游任务中的适应性


<details>
  <summary>Details</summary>
Motivation: 传统自监督预训练方法将所有异构数据混合并最小化全局平均损失，无法确保模型对每个数据源都能达到局部最优，需要更好的方法来处理异构数据

Method: 采用双层优化框架，在K步梯度下降后对每个异构数据源施加平衡约束，确保模型从初始状态出发能达到局部最优，使用一阶近似方法求解

Result: 在多领域和多语言数据集上的实验表明，该方法能显著提高自监督预训练模型在下游监督微调任务中的适应性

Conclusion: 提出的平衡约束和双层优化方法有效解决了异构数据自监督预训练问题，提高了模型的泛化能力和下游任务性能

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [232] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 提出基于梯度估计的线性时间算法，用于从n个示例中快速选择k个最佳演示样本进行上下文学习，相比现有方法速度提升37.7倍，性能提升11%


<details>
  <summary>Details</summary>
Motivation: 解决在上下文学习中如何从大量示例中高效选择最佳演示样本的问题，现有基于token嵌入相似度的方法存在局限性

Method: 基于输入嵌入空间中输出梯度的第一阶近似估计模型输出，通过随机采样子集并聚合结果计算每个示例的影响力分数

Result: 梯度估计误差小于1%，在340亿参数模型上实现37.7倍加速，平均性能超越基于输入嵌入的方法11%

Conclusion: 梯度估计方法为大规模上下文学习的演示样本选择提供了高效准确的解决方案，显著优于现有方法

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [233] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 本研究针对电商产品分类中的平台异构性和现有分类法结构限制问题，开发了多模态分层分类框架，在27万+时尚产品数据上融合文本、视觉和跨模态特征，实现了98.59%的F1分数，并提出了产品重分类流程发现细粒度类别。


<details>
  <summary>Details</summary>
Motivation: 解决电商产品分类中的两个关键工业挑战：平台异构性（不同电商平台的产品分类体系差异）和现有分类法的结构局限性（分类不一致或层级过浅）。

Method: 使用多模态分层分类框架，整合RoBERTa文本特征、ViT视觉特征和CLIP跨模态表示；研究早期融合、晚期融合和注意力融合策略；采用动态掩码确保分类一致性；提出自监督产品重分类流程（SimCLR+UMAP+级联聚类）。

Result: CLIP嵌入通过MLP晚期融合策略获得最高分层F1分数98.59%；产品重分类流程发现新的细粒度类别（如鞋子子类型），聚类纯度超过86%；跨平台实验显示晚期融合在多样数据上精度最高，早期融合对新平台泛化更好。

Conclusion: 成功开发了可工业扩展的多模态分类框架，通过两阶段推理管道（轻量RoBERTa阶段+GPU加速多模态阶段）在商业平台部署，平衡了成本与精度，为电商产品分类提供了有效的解决方案。

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [234] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 论文提出了一个检测微调过程中突现错位的框架，使用统计差异度量和基于语言的有序参数来量化模型输出的分布变化和相变特征。


<details>
  <summary>Details</summary>
Motivation: 研究微调LLMs在狭窄有害数据集上可能导致广泛的人类价值观错位问题，需要理解这种突现错位何时以及如何发生。

Method: 开发了综合框架，结合分布变化检测方法和基于英文表述的有序参数（由LLM评估），使用统计差异度量量化微调过程中的相变对模型多方面的影响。

Result: 发现实际行为转变发生在训练后期，比梯度范数峰值指示的时间更晚；能够分解总体转变中不同方面（如对齐性、冗长度）的贡献比例；实现了基于语言的有序参数的自动发现和量化。

Conclusion: 该框架能够有效检测和表征微调过程中的快速转变，为理解LLMs在微调过程中的行为变化提供了系统化的分析方法，在知识问答、政治和伦理等多个领域都有应用价值。

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [235] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop是一个用于神经网络预测模型中人为引导偏差缓解的工具，通过从神经网络提取决策树让用户检查和修改不公平决策逻辑，然后微调原模型以实现更公平的预测


<details>
  <summary>Details</summary>
Motivation: 敏感属性如性别或年龄在机器学习任务中可能导致不公平预测，特别是在不考虑上下文的情况下使用时

Method: 从神经网络中提取决策树，允许用户检查和修改不公平的决策逻辑，然后使用这些修改来微调原始模型

Result: 相比其他公平性方法，FairLoop通过人为参与实现上下文感知的偏差消除，有选择性地处理敏感属性的影响而不是统一排除

Conclusion: FairLoop提供了一种有效的人类引导偏差缓解方法，能够选择性处理敏感属性的影响，实现更公平的预测模型

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [236] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: 使用大语言模型为个性化推荐邮件生成主题标题，通过离线和在线实验证明能有效提升用户参与度


<details>
  <summary>Details</summary>
Motivation: 传统电商营销邮件标题采用固定模板，无法充分激发用户对个性化内容的兴趣，限制了邮件营销效果

Method: 利用大语言模型(LLMs)生成反映邮件个性化内容的主题标题，进行离线模拟和百万级用户的在线实验

Result: 实验证明该方法能有效改善客户与邮件之间的互动参与度

Conclusion: 大语言模型可以安全、自动化地为数百万用户生成邮件标题，提升电商营销效果

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [237] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文研究通过注意力头剪枝来防御预训练语言模型中的后门攻击，提出了六种剪枝策略，实验表明梯度剪枝对句法触发器防御效果最佳，强化学习和贝叶斯剪枝对风格攻击更有效。


<details>
  <summary>Details</summary>
Motivation: 后门攻击对预训练语言模型的性能和完整性构成严重威胁，这些攻击通过隐蔽的恶意触发器绕过传统检测，在微调后仍然存在，需要事后净化来防御。

Method: 设计了六种剪枝策略：梯度剪枝、层间方差剪枝、结构化L1/L2稀疏化梯度剪枝、随机集成剪枝、强化学习引导剪枝和贝叶斯不确定性剪枝，通过迭代移除信息量最小的注意力头来防御攻击。

Result: 实验评估显示，梯度剪枝在防御句法触发器方面表现最佳，而强化学习和贝叶斯剪枝在抵御风格攻击方面效果更好。

Conclusion: 注意力头剪枝是一种有效的后门攻击防御方法，不同剪枝策略适用于不同类型的攻击触发器，无需了解攻击触发器或访问干净参考模型即可实现防御。

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [238] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR: 本文通过将多臂老虎机强化学习算法应用于故障导向搜索(FDS)，在作业车间调度和资源受限项目调度问题上实现了显著的性能提升，比原始FDS快1.7-2.1倍，比IBM CP Optimizer快2.1-3.5倍，并改进了大量基准实例的最优下界。


<details>
  <summary>Details</summary>
Motivation: 故障导向搜索(FDS)在约束编程中是一种重要的完全通用搜索算法，特别在调度问题上表现优异。研究发现FDS的搜索树最小化与多臂老虎机问题密切相关，这为应用强化学习算法提供了理论基础。

Method: 将多臂老虎机(MAB)强化学习算法应用于FDS，并进行问题特定的改进和参数调优。在作业车间调度问题(JSSP)和资源受限项目调度问题(RCPSP)上进行评估，使用新的求解器OptalCP实现。

Result: 增强版FDS在JSSP上比原始实现快1.7倍，在RCPSP上快2.1倍；比IBM CP Optimizer 22.1中的FDS算法在JSSP上快3.5倍，在RCPSP上快2.1倍。在900秒时间限制下，改进了84个JSSP实例中78个和393个RCPSP实例中226个的最优下界，并完全解决了部分实例。

Conclusion: 基于多臂老虎机强化学习的FDS增强方法显著提升了调度问题的求解效率，证明了强化学习在约束编程搜索算法中的有效性和实用性，为复杂调度问题的求解提供了新的有效途径。

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [239] [Aegis: Taxonomy and Optimizations for Overcoming Agent-Environment Failures in LLM Agents](https://arxiv.org/abs/2508.19504)
*Kevin Song,Anand Jayarajan,Yaoyao Ding,Qidong Su,Zhanda Zhu,Sihang Liu,Gennady Pekhimenko*

Main category: cs.MA

TL;DR: 本文提出通过优化系统环境而非改进智能体本身来提高LLM智能体成功率的方法，在5个基准测试中平均提升6.7-12.5%的成功率


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注改进智能体本身，但忽视了系统环境对智能体成功率的重要影响。智能体在复杂现实环境中的低成功率限制了实际部署

Method: 收集142个智能体轨迹（3656次交互），分析失败模式并提出6种失败分类。设计Aegis环境优化技术：环境可观测性增强、通用计算卸载和推测性智能体动作

Result: 在不修改智能体和底层LLM的情况下，平均提升智能体成功率6.7-12.5%

Conclusion: 优化系统环境是提高LLM智能体成功率的有效补充方向，环境因素对智能体性能具有重要影响

Abstract: Large Language Models (LLMs) agents augmented with domain tools promise to
autonomously execute complex tasks requiring human-level intelligence, such as
customer service and digital assistance. However, their practical deployment is
often limited by their low success rates under complex real-world environments.
To tackle this, prior research has primarily focused on improving the agents
themselves, such as developing strong agentic LLMs, while overlooking the role
of the system environment in which the agent operates.
  In this paper, we study a complementary direction: improving agent success
rates by optimizing the system environment in which the agent operates. We
collect 142 agent traces (3,656 turns of agent-environment interactions) across
5 state-of-the-art agentic benchmarks. By analyzing these agent failures, we
propose a taxonomy for agent-environment interaction failures that includes 6
failure modes. Guided by these findings, we design Aegis, a set of targeted
environment optimizations: 1) environment observability enhancement, 2) common
computation offloading, and 3) speculative agentic actions. These techniques
improve agent success rates on average by 6.7-12.5%, without any modifications
to the agent and underlying LLM.

</details>


### [240] [CataractSurg-80K: Knowledge-Driven Benchmarking for Structured Reasoning in Ophthalmic Surgery Planning](https://arxiv.org/abs/2508.20014)
*Yang Meng,Zewen Pan,Yandi Lu,Ruobing Huang,Yanfeng Liao,Jiarui Yang*

Main category: cs.MA

TL;DR: 本文提出了一个知识驱动的多智能体系统(MAS)来提升LLM在眼科领域的专业能力，并创建了首个大规模白内障手术规划基准CataractSurg-80K，以及专门优化的Qwen-CSP模型。


<details>
  <summary>Details</summary>
Motivation: 白内障手术规划需要整合多种临床检查数据，但现有大语言模型缺乏眼科领域专业知识，无法有效解读异质性眼科数据并提供可行的手术方案。

Method: 提出知识驱动的多智能体系统(MAS)，模拟专科眼科医生的推理过程；构建包含8万病例的CataractSurg-80K基准数据集；基于Qwen-4B开发多阶段微调的Qwen-CSP专业模型。

Result: Qwen-CSP在多个指标上显著优于通用大语言模型，提供了高质量数据集、严格基准和专业优化的医疗AI模型。

Conclusion: 该研究为医疗AI推理和决策支持提供了重要资源和方法，推动了专业领域大语言模型的发展和应用。

Abstract: Cataract surgery remains one of the most widely performed and effective
procedures for vision restoration. Effective surgical planning requires
integrating diverse clinical examinations for patient assessment, intraocular
lens (IOL) selection, and risk evaluation. Large language models (LLMs) have
shown promise in supporting clinical decision-making. However, existing LLMs
often lack the domain-specific expertise to interpret heterogeneous ophthalmic
data and provide actionable surgical plans. To enhance the model's ability to
interpret heterogeneous ophthalmic reports, we propose a knowledge-driven
Multi-Agent System (MAS), where each agent simulates the reasoning process of
specialist ophthalmologists, converting raw clinical inputs into structured,
actionable summaries in both training and deployment stages. Building on MAS,
we introduce CataractSurg-80K, the first large-scale benchmark for cataract
surgery planning that incorporates structured clinical reasoning. Each case is
annotated with diagnostic questions, expert reasoning chains, and structured
surgical recommendations. We further introduce Qwen-CSP, a domain-specialized
model built on Qwen-4B, fine-tuned through a multi-stage process tailored for
surgical planning. Comprehensive experiments show that Qwen-CSP outperforms
strong general-purpose LLMs across multiple metrics. Our work delivers a
high-quality dataset, a rigorous benchmark, and a domain-adapted LLM to
facilitate future research in medical AI reasoning and decision support.

</details>


### [241] [Anomaly Detection in Networked Bandits](https://arxiv.org/abs/2508.20076)
*Xiaotong Cheng,Setareh Maghsudi*

Main category: cs.MA

TL;DR: 提出一种新颖的bandit算法，利用网络知识学习用户偏好和特征残差，实现个性化推荐和异常检测的同步进行


<details>
  <summary>Details</summary>
Motivation: 社交网络中节点间的相互连接反映了依赖关系和信息共享行为，但异常节点会带来严重后果，需要设计高效的在线学习算法来鲁棒地学习用户偏好并同时检测异常

Method: 通过网络知识表征用户偏好和特征信息的残差，通过学习和分析这些偏好和残差，为每个用户开发个性化推荐策略并同时检测异常

Result: 严格证明了所提算法的遗憾上界，并在合成和真实数据集上与多个最先进的协作上下文bandit算法进行了实验比较

Conclusion: 该算法能够有效处理社交网络中的异常检测问题，同时在个性化推荐方面表现出色

Abstract: The nodes' interconnections on a social network often reflect their
dependencies and information-sharing behaviors. Nevertheless, abnormal nodes,
which significantly deviate from most of the network concerning patterns or
behaviors, can lead to grave consequences. Therefore, it is imperative to
design efficient online learning algorithms that robustly learn users'
preferences while simultaneously detecting anomalies.
  We introduce a novel bandit algorithm to address this problem. Through
network knowledge, the method characterizes the users' preferences and
residuals of feature information. By learning and analyzing these preferences
and residuals, it develops a personalized recommendation strategy for each user
and simultaneously detects anomalies. We rigorously prove an upper bound on the
regret of the proposed algorithm and experimentally compare it with several
state-of-the-art collaborative contextual bandit algorithms on both synthetic
and real-world datasets.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [242] [FakeSV-VLM: Taming VLM for Detecting Fake Short-Video News via Progressive Mixture-Of-Experts Adapter](https://arxiv.org/abs/2508.19639)
*Junxi Wang,Yaxiong Wang,Lechao Cheng,Zhun Zhong*

Main category: cs.MM

TL;DR: FakeSV-VLM是一个基于视觉语言模型的短视频假新闻检测框架，通过混合专家机制和模态对齐检测技术，在两个基准数据集上显著超越现有最佳模型3.32%和5.02%。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻检测方法因缺乏知识验证能力而准确率不足，而大型视觉语言模型从海量多模态数据中吸收了丰富的真实世界知识，适合用于假新闻检测。

Method: 设计四类专家处理不同真假组合场景，通过渐进式混合专家适配器(PMOE)进行初步分析和综合诊断，并开发对齐驱动事件检查(ADEC)模块捕捉模态间不一致性。

Result: 在FakeSV和FakeTT两个基准数据集上，模型分别比当前最佳方法提升了3.32%和5.02%的检测准确率。

Conclusion: 该框架成功利用VLMs的知识优势和模态一致性分析，为短视频假新闻检测设立了新的性能基准，证明了多专家协同和模态对齐检测的有效性。

Abstract: We present FakeSV-VLM in this paper, a new VLM-based framework for detecting
fake news on short video platforms. Despite significant efforts to combat this
issue due to the severe threat that fake news videos pose to public information
security, existing methods still fall short in detection accuracy, often due to
lack of knowledge to verify the news is real or not. However, large Vision
Language Models (VLMs) have absorbed extensive real-world knowledge from
massive multimodal datasets. Motivated by this, we adapt advanced VLMs for fake
news detection in short videos. Upon close examination of news samples, we
observe that short video samples can be categorized into four distinct
scenarios: both video and text are real (for real samples), or both are fake,
or either the video or text is fake (for fake samples). Inspired by this
insight, we design four experts tailored to handle each scenario and integrate
them into VLM via Mixture of Experts. Specifically, we develop the Progressive
MoE Adapter (PMOE) module where detection experts first provide an initial
analysis, followed by attribution experts for a comprehensive diagnosis,
leading to a robust decision. Additionally, we also note the fake news videos
often show inconsistency between two modalities. Consequently, we further
design the Alignment-driven Event Checking (ADEC) module, which perceives the
fake news by capturing the inconsistency between different modalities.
Extensive experiments on two benchmark datasets, FakeSV and FakeTT, verify the
superiority of our model. It significantly outperforms current state-of-the-art
models by +3.32% and +5.02%, establishing a new benchmark in the field.

</details>


### [243] [ProMSC-MIS: Prompt-based Multimodal Semantic Communication for Multi-Spectral Image Segmentation](https://arxiv.org/abs/2508.20057)
*Haoshuo Zhang,Yufei Bo,Meixia Tao*

Main category: cs.MM

TL;DR: ProMSC-MIS是一个基于提示学习的多模态语义通信框架，用于多光谱图像分割，通过跨模态提示学习和语义融合模块，在保持分割性能的同时显著降低带宽需求和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 多模态语义通信通过整合跨模态的互补信息来提升下游任务性能，特别是在带宽受限的信道中传输空间对齐的RGB和热成像图像时，需要高效的面向任务的传输方案。

Method: 1) 利用提示学习和对比学习预训练单模态语义编码器，使用一个模态的特征作为另一个模态的提示；2) 设计结合交叉注意力机制和SE网络的语义融合模块来有效融合跨模态特征。

Result: 在相同分割性能下，将所需信道带宽减少50%-70%，存储开销降低26%，计算复杂度降低37%，显著优于传统图像传输结合最先进分割方法。

Conclusion: 该框架通过创新的预训练和语义融合策略，在多光谱图像分割任务中实现了高效的语义通信，特别适用于自动驾驶和夜间监控等应用场景。

Abstract: Multimodal semantic communication has great potential to enhance downstream
task performance by integrating complementary information across modalities.
This paper introduces ProMSC-MIS, a novel Prompt-based Multimodal Semantic
Communication framework for Multi-Spectral Image Segmentation. It enables
efficient task-oriented transmission of spatially aligned RGB and thermal
images over band-limited channels. Our framework has two main design novelties.
First, by leveraging prompt learning and contrastive learning, unimodal
semantic encoders are pre-trained to learn diverse and complementary semantic
representations by using features from one modality as prompts for another.
Second, a semantic fusion module that combines cross-attention mechanism and
squeeze-and-excitation (SE) networks is designed to effectively fuse
cross-modal features. Experimental results demonstrate that ProMSC-MIS
substantially outperforms conventional image transmission combined with
state-of-the-art segmentation methods. Notably, it reduces the required channel
bandwidth by 50%--70% at the same segmentation performance, while also
decreasing the storage overhead and computational complexity by 26% and 37%,
respectively. Ablation studies also validate the effectiveness of the proposed
pre-training and semantic fusion strategies. Our scheme is highly suitable for
applications such as autonomous driving and nighttime surveillance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [244] [Inference of Human-derived Specifications of Object Placement via Demonstration](https://arxiv.org/abs/2508.19367)
*Alex Cuellar,Ho Chit Siu,Julie A Shah*

Main category: cs.RO

TL;DR: 提出了PARCC框架，基于区域连接演算(RCC)的形式化逻辑框架，用于描述物体在空间中的相对位置关系，并通过演示学习算法来推断人类可接受的物体配置规则。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作能力在拾取放置任务中有所提升，但理解人类可接受的物体配置方法在表达空间关系方面仍然有限，需要更好地捕捉对人类重要的空间关系规则。

Method: 开发了positionally-augmented RCC (PARCC)形式化逻辑框架，基于区域连接演算，并设计了通过演示学习的推断算法来学习PARCC规范。

Result: 人类研究结果表明，该框架能够有效捕捉人类的意图规范，且通过演示学习的方法优于人类直接提供的规范说明。

Conclusion: PARCC框架为机器人理解人类物体排列规则提供了有效的形式化表示方法，演示学习的方式能够更好地获取人类的空间关系偏好。

Abstract: As robots' manipulation capabilities improve for pick-and-place tasks (e.g.,
object packing, sorting, and kitting), methods focused on understanding
human-acceptable object configurations remain limited expressively with regard
to capturing spatial relationships important to humans. To advance robotic
understanding of human rules for object arrangement, we introduce
positionally-augmented RCC (PARCC), a formal logic framework based on region
connection calculus (RCC) for describing the relative position of objects in
space. Additionally, we introduce an inference algorithm for learning PARCC
specifications via demonstrations. Finally, we present the results from a human
study, which demonstrate our framework's ability to capture a human's intended
specification and the benefits of learning from demonstration approaches over
human-provided specifications.

</details>


### [245] [FlipWalker: Jacob's Ladder toy-inspired robot for locomotion across diverse, complex terrain](https://arxiv.org/abs/2508.19380)
*Diancheng Li,Nia Ralston,Bastiaan Hagen,Phoebe Tan,Matthew A. Robertson*

Main category: cs.RO

TL;DR: FlipWalker是一种受雅各布天梯玩具启发的欠驱动机器人系统，通过翻转运动在复杂地形中移动，最大翻转速度为0.2体长/秒，在草地、岩石和雪地等不规则地形中表现良好


<details>
  <summary>Details</summary>
Motivation: 传统轮式机器人在复杂地形中移动困难，需要开发新型运动方式来应对不规则户外地形

Method: 采用两段式结构通过柔性电缆连接，模仿雅各布天梯玩具的级联运动，使用电机驱动腿在配置变化时推离地面或相对段

Result: 原型机重0.78kg，最大翻转速度0.2体长/秒，在人工草地、河石和雪地等复杂地形中成功验证了翻转策略的有效性

Conclusion: 基于地面法向反作用力的翻转策略为不规则户外地形导航提供了一种有前景的传统运动方式替代方案

Abstract: This paper introduces FlipWalker, a novel underactuated robot locomotion
system inspired by Jacob's Ladder illusion toy, designed to traverse
challenging terrains where wheeled robots often struggle. Like the Jacob's
Ladder toy, FlipWalker features two interconnected segments joined by flexible
cables, enabling it to pivot and flip around singularities in a manner
reminiscent of the toy's cascading motion. Actuation is provided by
motor-driven legs within each segment that push off either the ground or the
opposing segment, depending on the robot's current configuration. A
physics-based model of the underactuated flipping dynamics is formulated to
elucidate the critical design parameters governing forward motion and obstacle
clearance or climbing. The untethered prototype weighs 0.78 kg, achieves a
maximum flipping speed of 0.2 body lengths per second. Experimental trials on
artificial grass, river rocks, and snow demonstrate that FlipWalker's flipping
strategy, which relies on ground reaction forces applied normal to the surface,
offers a promising alternative to traditional locomotion for navigating
irregular outdoor terrain.

</details>


### [246] [LaVA-Man: Learning Visual Action Representations for Robot Manipulation](https://arxiv.org/abs/2508.19391)
*Chaoran Zhu,Hengyi Wang,Yik Lung Pang,Changjae Oh*

Main category: cs.RO

TL;DR: 提出一种通过自监督预训练任务学习视觉-文本关联的方法，通过重构被遮挡的目标图像来学习视觉-动作表示，无需机器人动作监督，然后在少量演示样本上微调用于操作任务。


<details>
  <summary>Details</summary>
Motivation: 现有的两步方法（先编码视觉观察和文本指令的相似度，再映射到机器人动作）限制了模型捕捉视觉观察与文本指令之间的关系，导致操作任务精度降低。

Method: 使用自监督预训练任务：基于输入图像和文本指令重构被遮挡的目标图像，学习视觉-文本关联和视觉-动作表示。然后使用少量演示样本对学习到的表示进行微调用于操作任务。

Result: 在五个基准测试（包括仿真和真实机器人验证）上，该方法优于现有技术。还引入了包含180个物体类别和3,200个实例的Omni-Object Pick-and-Place数据集。

Conclusion: 通过自监督预训练学习视觉-文本关联的方法能够有效提升语言引导机器人操作的性能，在少量演示样本下即可实现优异的操作效果，具有良好的泛化能力。

Abstract: Visual-textual understanding is essential for language-guided robot
manipulation. Recent works leverage pre-trained vision-language models to
measure the similarity between encoded visual observations and textual
instructions, and then train a model to map this similarity to robot actions.
However, this two-step approach limits the model to capture the relationship
between visual observations and textual instructions, leading to reduced
precision in manipulation tasks. We propose to learn visual-textual
associations through a self-supervised pretext task: reconstructing a masked
goal image conditioned on an input image and textual instructions. This
formulation allows the model to learn visual-action representations without
robot action supervision. The learned representations can then be fine-tuned
for manipulation tasks with only a few demonstrations. We also introduce the
\textit{Omni-Object Pick-and-Place} dataset, which consists of annotated robot
tabletop manipulation episodes, including 180 object classes and 3,200
instances with corresponding textual instructions. This dataset enables the
model to acquire diverse object priors and allows for a more comprehensive
evaluation of its generalisation capability across object instances.
Experimental results on the five benchmarks, including both simulated and
real-robot validations, demonstrate that our method outperforms prior art.

</details>


### [247] [From Stoplights to On-Ramps: A Comprehensive Set of Crash Rate Benchmarks for Freeway and Surface Street ADS Evaluation](https://arxiv.org/abs/2508.19425)
*John M. Scanlon,Timothy L McMurry,Yin-Hsiu Chen,Kristofer D. Kusano,Trent Victor*

Main category: cs.RO

TL;DR: 这篇论文提供了美国城市区域自动驾驶系统(ADS)的摔车率基准，特别关注高速公路摔车风险，发现不同地区存在显著差异，并量化了评估ADS安全性所需的量程要求。


<details>
  <summary>Details</summary>
Motivation: 扩展以前仅聚焦于城市道路的安全基准，需要包含高速公路摔车风险评估，以更全面地评估自动驾驶系统的安全性能。

Method: 利用公开的警察报告摔车数据和车辆行驶里程(VMT)数据，进行在运客车分离、道路类型分类和摔车类型学分析，建立基准模型。

Result: 发现高速公路摔车率存在显著地理差异（亚特兰大2.4 IPMM vs 凯斗特0.7 IPMM），不同严重程度的摔车类型分布不同，低严重性能不能预测高严重性能。量化了评估ADS安全性所需的量程要求。

Conclusion: 论文首次提供了高速公路特定的ADS评估基准，强调需要根据具体地理位置制定基准，以免偏差评估，为未来ADS安全性能评估提供了基础框架。

Abstract: This paper presents crash rate benchmarks for evaluating US-based Automated
Driving Systems (ADS) for multiple urban areas. The purpose of this study was
to extend prior benchmarks focused only on surface streets to additionally
capture freeway crash risk for future ADS safety performance assessments. Using
publicly available police-reported crash and vehicle miles traveled (VMT) data,
the methodology details the isolation of in-transport passenger vehicles, road
type classification, and crash typology. Key findings revealed that freeway
crash rates exhibit large geographic dependence variations with
any-injury-reported crash rates being nearly 3.5 times higher in Atlanta (2.4
IPMM; the highest) when compared to Phoenix (0.7 IPMM; the lowest). The results
show the critical need for location-specific benchmarks to avoid biased safety
evaluations and provide insights into the vehicle miles traveled (VMT) required
to achieve statistical significance for various safety impact levels. The
distribution of crash types depended on the outcome severity level. Higher
severity outcomes (e.g., fatal crashes) had a larger proportion of
single-vehicle, vulnerable road users (VRU), and opposite-direction collisions
compared to lower severity (police-reported) crashes. Given heterogeneity in
crash types by severity, performance in low-severity scenarios may not be
predictive of high-severity outcomes. These benchmarks are additionally used to
quantify at the required mileage to show statistically significant deviations
from human performance. This is the first paper to generate freeway-specific
benchmarks for ADS evaluation and provides a foundational framework for future
ADS benchmarking by evaluators and developers.

</details>


### [248] [An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals](https://arxiv.org/abs/2508.19429)
*Gustavo A. Cardona,Kaier Liang,Cristian-Ioan Vasile*

Main category: cs.RO

TL;DR: 提出了一种在资源分布未知环境中进行异构多智能体路径规划的迭代方法，使用Capability Temporal Logic定义任务，通过动态平衡探索与任务执行来处理资源不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决异构多智能体在资源分布未知环境中执行复杂任务时的规划挑战，特别是处理资源初始分布和数量的不确定性。

Method: 采用迭代算法，动态平衡探索和任务完成。机器人探索环境以识别资源位置和数量，同时基于当前信息最大化满足任务目标，并随着新数据的发现调整策略。

Result: 通过模拟案例研究证明了该方法的有效性和性能，能够在动态、资源受限的环境中提供鲁棒的规划解决方案。

Conclusion: 该方法为异构团队在不确定性条件下的高效协调提供了有效解决方案，特别适用于资源分布未知的动态环境。

Abstract: This paper presents an iterative approach for heterogeneous multi-agent route
planning in environments with unknown resource distributions. We focus on a
team of robots with diverse capabilities tasked with executing missions
specified using Capability Temporal Logic (CaTL), a formal framework built on
Signal Temporal Logic to handle spatial, temporal, capability, and resource
constraints. The key challenge arises from the uncertainty in the initial
distribution and quantity of resources in the environment. To address this, we
introduce an iterative algorithm that dynamically balances exploration and task
fulfillment. Robots are guided to explore the environment, identifying resource
locations and quantities while progressively refining their understanding of
the resource landscape. At the same time, they aim to maximally satisfy the
mission objectives based on the current information, adapting their strategies
as new data is uncovered. This approach provides a robust solution for planning
in dynamic, resource-constrained environments, enabling efficient coordination
of heterogeneous teams even under conditions of uncertainty. Our method's
effectiveness and performance are demonstrated through simulated case studies.

</details>


### [249] [Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning](https://arxiv.org/abs/2508.19476)
*Dane Brouwer,Joshua Citron,Heather Nolte,Jeannette Bohg,Mark Cutkosky*

Main category: cs.RO

TL;DR: 研究探索非抓握触觉传感在机器人从密集物体集合中安全提取物体的作用，通过模仿学习训练策略，发现力传感显著提升性能


<details>
  <summary>Details</summary>
Motivation: 日常生活中密集可移动物体集合很常见，机器人安全提取这些物体很困难，但人类通过手部和手臂的非抓握触觉传感可以轻松完成

Method: 使用模仿学习从随机生成场景的演示中训练策略，比较五种传感模态：眼在手视觉、本体感觉、三轴触觉传感、关节力矩估计的接触力矩、真空吸盘成功获取物体的测量

Result: 使用任何力传感的策略都表现出更少的过度力失败、更高的整体成功率和更快的完成时间。同时使用触觉和力矩信息获得最佳性能，比无力信息基线提升80%

Conclusion: 非抓握触觉传感对于机器人在受限杂乱环境中安全提取物体至关重要，力传感信息显著改善了机器人操作的性能和安全性

Abstract: Dense collections of movable objects are common in everyday spaces -- from
cabinets in a home to shelves in a warehouse. Safely retracting objects from
such collections is difficult for robots, yet people do it easily, using
non-prehensile tactile sensing on the sides and backs of their hands and arms.
We investigate the role of such sensing for training robots to gently reach
into constrained clutter and extract objects. The available sensing modalities
are (1) "eye-in-hand" vision, (2) proprioception, (3) non-prehensile triaxial
tactile sensing, (4) contact wrenches estimated from joint torques, and (5) a
measure of successful object acquisition obtained by monitoring the vacuum line
of a suction cup. We use imitation learning to train policies from a set of
demonstrations on randomly generated scenes, then conduct an ablation study of
wrench and tactile information. We evaluate each policy's performance across 40
unseen environment configurations. Policies employing any force sensing show
fewer excessive force failures, an increased overall success rate, and faster
completion times. The best performance is achieved using both tactile and
wrench information, producing an 80% improvement above the baseline without
force information.

</details>


### [250] [DATR: Diffusion-based 3D Apple Tree Reconstruction Framework with Sparse-View](https://arxiv.org/abs/2508.19508)
*Tian Qiu,Alan Zoubi,Yiyuan Lin,Ruiming Du,Lailiang Cheng,Yu Jiang*

Main category: cs.RO

TL;DR: 提出DATR两阶段框架，从稀疏视角重建苹果树3D模型，结合扩散模型和大型重建模型，在真实和合成数据集上均优于现有方法，吞吐量提升360倍


<details>
  <summary>Details</summary>
Motivation: 数字孪生应用需要高精度3D重建，但现有方法在田间稀疏和遮挡视角下表现不佳，特别是针对苹果树等复杂植物的重建

Method: 两阶段框架：第一阶段使用机载传感器和基础模型半自动生成树掩码；第二阶段使用扩散模型生成多视角，大型重建模型生成隐式神经场，基于Real2Sim合成数据训练

Result: 在真实和合成数据集上均优于现有3D重建方法，域特征估计达到工业级激光扫描仪水平，吞吐量提升约360倍

Conclusion: DATR框架展示了可扩展农业数字孪生系统的强大潜力，能够有效处理田间稀疏视角下的植物3D重建问题

Abstract: Digital twin applications offered transformative potential by enabling
real-time monitoring and robotic simulation through accurate virtual replicas
of physical assets. The key to these systems is 3D reconstruction with high
geometrical fidelity. However, existing methods struggled under field
conditions, especially with sparse and occluded views. This study developed a
two-stage framework (DATR) for the reconstruction of apple trees from sparse
views. The first stage leverages onboard sensors and foundation models to
semi-automatically generate tree masks from complex field images. Tree masks
are used to filter out background information in multi-modal data for the
single-image-to-3D reconstruction at the second stage. This stage consists of a
diffusion model and a large reconstruction model for respective multi view and
implicit neural field generation. The training of the diffusion model and LRM
was achieved by using realistic synthetic apple trees generated by a Real2Sim
data generator. The framework was evaluated on both field and synthetic
datasets. The field dataset includes six apple trees with field-measured ground
truth, while the synthetic dataset featured structurally diverse trees.
Evaluation results showed that our DATR framework outperformed existing 3D
reconstruction methods across both datasets and achieved domain-trait
estimation comparable to industrial-grade stationary laser scanners while
improving the throughput by $\sim$360 times, demonstrating strong potential for
scalable agricultural digital twin systems.

</details>


### [251] [A Lightweight Crowd Model for Robot Social Navigation](https://arxiv.org/abs/2508.19595)
*Maryam Kazemi Eskeri,Thomas Wiedemann,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 轻量级实时宏观人群预测模型，在保持准确性的同时大幅缩短推理时间，使机器人能够在密集环境中进行社会化导航。


<details>
  <summary>Details</summary>
Motivation: 现有的微观模型在密集人群中计算成本过高，而宏观模型要么过于简单要么计算复杂度过高，无法满足实时人群运动估计需求。

Method: 基于行人流的本质特征，简化空间和时间处理，设计了一种轻量级实时宏观人群预测模型，在不使用复杂架构的情况下实现了稳健的泛化能力。

Result: 推理时间减少3.6倍，预测准确性提高3.1%，集成到社会意识规划框架后，能够在动态环境中实现高效和社会合规的机器人导航。

Conclusion: 高效的人群建模技术能够让机器人在不需要高计算成本的情况下实现密集环境中的安全导航。

Abstract: Robots operating in human-populated environments must navigate safely and
efficiently while minimizing social disruption. Achieving this requires
estimating crowd movement to avoid congested areas in real-time. Traditional
microscopic models struggle to scale in dense crowds due to high computational
cost, while existing macroscopic crowd prediction models tend to be either
overly simplistic or computationally intensive. In this work, we propose a
lightweight, real-time macroscopic crowd prediction model tailored for human
motion, which balances prediction accuracy and computational efficiency. Our
approach simplifies both spatial and temporal processing based on the inherent
characteristics of pedestrian flow, enabling robust generalization without the
overhead of complex architectures. We demonstrate a 3.6 times reduction in
inference time, while improving prediction accuracy by 3.1 %. Integrated into a
socially aware planning framework, the model enables efficient and socially
compliant robot navigation in dynamic environments. This work highlights that
efficient human crowd modeling enables robots to navigate dense environments
without costly computations.

</details>


### [252] [Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks](https://arxiv.org/abs/2508.19607)
*Amin Berjaoui Tahmaz,Ravi Prakash,Jens Kober*

Main category: cs.RO

TL;DR: 提出了一种阻抗原语增强的分层强化学习框架，用于顺序接触任务中的高效机器人操作，通过可变刚度控制和仿生耦合实现更好的学习效率和成功率


<details>
  <summary>Details</summary>
Motivation: 为了解决顺序接触任务中机器人操作的效率问题，需要开发能够动态调整刚度并有效探索的框架，以提高在复杂接触任务中的适应性和性能

Method: 采用分层强化学习框架，包含三个关键组件：支持可变刚度控制的动作空间、自适应刚度控制器（在原始执行期间动态调整刚度）、仿生耦合机制（促进高效探索和顺应性）

Result: 在方块举起、开门、物体推动和表面清洁等任务中，相比现有技术表现出更好的学习效率、原始选择组合性和成功率，并验证了良好的仿真到现实迁移能力

Conclusion: 该框架为更自适应和多功能的机器人操作系统奠定了基础，在更复杂的基于接触的任务中具有潜在应用价值

Abstract: This paper presents an Impedance Primitive-augmented hierarchical
reinforcement learning framework for efficient robotic manipulation in
sequential contact tasks. We leverage this hierarchical structure to
sequentially execute behavior primitives with variable stiffness control
capabilities for contact tasks. Our proposed approach relies on three key
components: an action space enabling variable stiffness control, an adaptive
stiffness controller for dynamic stiffness adjustments during primitive
execution, and affordance coupling for efficient exploration while encouraging
compliance. Through comprehensive training and evaluation, our framework learns
efficient stiffness control capabilities and demonstrates improvements in
learning efficiency, compositionality in primitive selection, and success rates
compared to the state-of-the-art. The training environments include block
lifting, door opening, object pushing, and surface cleaning. Real world
evaluations further confirm the framework's sim2real capability. This work lays
the foundation for more adaptive and versatile robotic manipulation systems,
with potential applications in more complex contact-based tasks.

</details>


### [253] [Autonomous Aerial Manipulation at Arbitrary Pose in SE(3) with Robust Control and Whole-body Planning](https://arxiv.org/abs/2508.19608)
*Dongjae Lee,Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 基于多旋翼的空中操作器只能在小角度操作，而全向空中操作器能够在任意方位想停，扩大了操作空间。本文提出了几何稳定控制器和全身运动规划框架，实现了在任意6D位形想停并进行精细操作的能力。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼基础的空中操作器因为基底的不充分驱动性，只能在小角度滚转和俯仰时进行操作。如果基底能够在任意方位想停，则可以在任何位置进行操作，显著扩大操作工作空间，实现原本不可行的操作任务。

Method: 提出了几何稳定控制器和全身运动规划框架。首先为浮动基底设计几何稳定控制器，能够应对机械手臂运动和交互力的影响。然后设计了两步优化全身运动规划器，统筹考虑浮动基底位形和机械手关节角度，以充分利用整个配置空间。两步方法有助于实时应用和优化问题收敛。

Result: 提出的方法使得基底能够在任意6D位形想停，同时自主进行精细操作而不与障碍物发生碰撞。通过实验验证了框架的有效性，OAM能够在多种场景下执行抓取和拉动物体的任务，包括在近90度和甚至180度俯仰角时。

Conclusion: 本文提出的几何稳定控制和全身运动规划框架成功实现了全向空中操作器在任意方位想停并进行精细操作的能力，显著扩大了空中操作的应用范围和可能性。

Abstract: Aerial manipulators based on conventional multirotors can conduct
manipulation only in small roll and pitch angles due to the underactuatedness
of the multirotor base. If the multirotor base is capable of hovering at
arbitrary orientation, the robot can freely locate itself at any point in
$\mathsf{SE}(3)$, significantly extending its manipulation workspace and
enabling a manipulation task that was originally not viable. In this work, we
present a geometric robust control and whole-body motion planning framework for
an omnidirectional aerial manipulator (OAM). To maximize the strength of OAM,
we first propose a geometric robust controller for a floating base. Since the
motion of the robotic arm and the interaction forces during manipulation affect
the stability of the floating base, the base should be capable of mitigating
these adverse effects while controlling its 6D pose. We then design a two-step
optimization-based whole-body motion planner, jointly considering the pose of
the floating base and the joint angles of the robotic arm to harness the entire
configuration space. The devised two-step approach facilitates real-time
applicability and enhances convergence of the optimization problem with
non-convex and non-Euclidean search space. The proposed approach enables the
base to be stationary at any 6D pose while autonomously carrying out
sophisticated manipulation near obstacles without any collision. We demonstrate
the effectiveness of the proposed framework through experiments in which an OAM
performs grasping and pulling of an object in multiple scenarios, including
near $90^\circ$ and even $180^\circ$ pitch angles.

</details>


### [254] [Embodied Intelligence for Sustainable Flight: A Soaring Robot with Active Morphological Control](https://arxiv.org/abs/2508.19684)
*Ghadeer Elmkaiel,Syn Schmitt,Michael Muehlebach*

Main category: cs.RO

TL;DR: Floaty是一种仿鸟形态的变形机器人，通过被动滑翔和智能形态控制利用风能，在10m/s垂直气流中实现悬停和机动，能耗比推进器系统低一个数量级。


<details>
  <summary>Details</summary>
Motivation: 解决传统推进器系统能耗高和固定翼设计缺乏悬停机动能力的问题，在动态风环境中实现敏捷机动和高能效的空中机器人。

Method: 采用形状变化设计实现被动稳定性，基于实验学习的空气动力学模型开发控制策略，通过智能形态控制利用风能进行精确姿态和位置控制。

Result: 风洞实验显示Floaty能在10m/s垂直气流中悬停、机动和抗干扰，比功率消耗仅为10W/kg，比推进器系统低一个数量级。

Conclusion: Floaty引入了一种能效空中机器人新范式，利用形态智能和控制技术在挑战性风条件下实现可持续运行。

Abstract: Achieving both agile maneuverability and high energy efficiency in aerial
robots, particularly in dynamic wind environments, remains challenging.
Conventional thruster-powered systems offer agility but suffer from high energy
consumption, while fixed-wing designs are efficient but lack hovering and
maneuvering capabilities. We present Floaty, a shape-changing robot that
overcomes these limitations by passively soaring, harnessing wind energy
through intelligent morphological control inspired by birds. Floaty's design is
optimized for passive stability, and its control policy is derived from an
experimentally learned aerodynamic model, enabling precise attitude and
position control without active propulsion. Wind tunnel experiments demonstrate
Floaty's ability to hover, maneuver, and reject disturbances in vertical
airflows up to 10 m/s. Crucially, Floaty achieves this with a specific power
consumption of 10 W/kg, an order of magnitude lower than thruster-powered
systems. This introduces a paradigm for energy-efficient aerial robotics,
leveraging morphological intelligence and control to operate sustainably in
challenging wind conditions.

</details>


### [255] [Efficient Human-Aware Task Allocation for Multi-Robot Systems in Shared Environments](https://arxiv.org/abs/2508.19731)
*Maryam Kazemi Eskeri,Ville Kyrki,Dominik Baumann,Tomasz Piotr Kucner*

Main category: cs.RO

TL;DR: 提出了一种基于动态地图(MoDs)的多机器人任务分配方法，通过考虑人类移动模式来优化任务执行时间


<details>
  <summary>Details</summary>
Motivation: 现有MRTA方法大多忽略人类动态运动模式，依赖静态地图，导致在共享环境中效率低下和延迟

Method: 利用动态地图(MoDs)构建时空可查询模型来捕捉历史人类移动模式，采用包含MoDs的随机成本函数来估计人类对任务执行时间的影响

Result: 实验结果显示，集成MoDs可将任务完成时间相比动态无关方法减少26%，相比基线方法减少19%

Conclusion: 在共享环境中考虑人类动态对MRTA至关重要，该方法为在人类密集环境中部署多机器人系统提供了高效框架

Abstract: Multi-robot systems are increasingly deployed in applications, such as
intralogistics or autonomous delivery, where multiple robots collaborate to
complete tasks efficiently. One of the key factors enabling their efficient
cooperation is Multi-Robot Task Allocation (MRTA). Algorithms solving this
problem optimize task distribution among robots to minimize the overall
execution time. In shared environments, apart from the relative distance
between the robots and the tasks, the execution time is also significantly
impacted by the delay caused by navigating around moving people. However, most
existing MRTA approaches are dynamics-agnostic, relying on static maps and
neglecting human motion patterns, leading to inefficiencies and delays. In this
paper, we introduce \acrfull{method name}. This method leverages Maps of
Dynamics (MoDs), spatio-temporal queryable models designed to capture
historical human movement patterns, to estimate the impact of humans on the
task execution time during deployment. \acrshort{method name} utilizes a
stochastic cost function that includes MoDs. Experimental results show that
integrating MoDs enhances task allocation performance, resulting in reduced
mission completion times by up to $26\%$ compared to the dynamics-agnostic
method and up to $19\%$ compared to the baseline. This work underscores the
importance of considering human dynamics in MRTA within shared environments and
presents an efficient framework for deploying multi-robot systems in
environments populated by humans.

</details>


### [256] [Elliptical K-Nearest Neighbors -- Path Optimization via Coulomb's Law and Invalid Vertices in C-space Obstacles](https://arxiv.org/abs/2508.19771)
*Liding Zhang,Zhenshan Bing,Yu Zhang,Kuanqi Cai,Lingyun Chen,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: FDIT*是一种基于采样的路径规划算法，通过利用无效顶点信息和库仑定律物理原理，在EIT*基础上改进，提供更快的收敛速度和更低的路径成本。


<details>
  <summary>Details</summary>
Motivation: 解决高维运动规划中的挑战，利用传统规划器中常被忽视的无效顶点信息，结合物理力原理来提高搜索效率和路径质量。

Method: 基于EIT*算法，引入库仑定律物理原理，提出椭圆k近邻搜索方法，利用无效顶点数据创建基于力方向的搜索区域，探索问题特定的有价值区域。

Result: 在R^4到R^16维度的问题上优于现有的单查询采样规划器，在受限高维环境中表现出更高的搜索效率和更低的路径成本，并在真实移动操作任务中得到验证。

Conclusion: FDIT*通过融合无效顶点信息和物理动力学原理，显著提高了采样规划器的性能，特别是在高维复杂环境中具有更好的收敛性和路径质量。

Abstract: Path planning has long been an important and active research area in
robotics. To address challenges in high-dimensional motion planning, this study
introduces the Force Direction Informed Trees (FDIT*), a sampling-based planner
designed to enhance speed and cost-effectiveness in pathfinding. FDIT* builds
upon the state-of-the-art informed sampling planner, the Effort Informed Trees
(EIT*), by capitalizing on often-overlooked information in invalid vertices. It
incorporates principles of physical force, particularly Coulomb's law. This
approach proposes the elliptical $k$-nearest neighbors search method, enabling
fast convergence navigation and avoiding high solution cost or infeasible paths
by exploring more problem-specific search-worthy areas. It demonstrates
benefits in search efficiency and cost reduction, particularly in confined,
high-dimensional environments. It can be viewed as an extension of nearest
neighbors search techniques. Fusing invalid vertex data with physical dynamics
facilitates force-direction-based search regions, resulting in an improved
convergence rate to the optimum. FDIT* outperforms existing single-query,
sampling-based planners on the tested problems in R^4 to R^16 and has been
demonstrated on a real-world mobile manipulation task.

</details>


### [257] [Tree-Based Grafting Approach for Bidirectional Motion Planning with Local Subsets Optimization](https://arxiv.org/abs/2508.19776)
*Liding Zhang,Yao Ling,Zhenshan Bing,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: G3T*是一种新颖的双向运动规划算法，通过贪婪嫁接树和动态采样分布优化，解决了传统双向搜索中连接失败的问题，在多个维度上展现出优越性能


<details>
  <summary>Details</summary>
Motivation: 传统双向运动规划中，由于懒惰反向搜索的限制，正向和反向搜索树的连接可能失败，导致需要重启非对称双向搜索，影响规划效率

Method: 提出G3T*算法，采用贪婪嫁接树方法在两端嫁接无效边连接来重建树连接性；使用最小Lebesgue测度的GuILD子集进行贪婪优化；动态调整采样分布确保渐进最优性

Result: 在R^2到R^8维度的基准实验和真实机器人评估中，G3T*相比现有单查询采样规划器表现出更快的收敛速度和更低的解成本

Conclusion: G3T*通过增强正向搜索向反向树的生长能力，实现了快速路径收敛和成本优化，为双向运动规划提供了有效的解决方案

Abstract: Bidirectional motion planning often reduces planning time compared to its
unidirectional counterparts. It requires connecting the forward and reverse
search trees to form a continuous path. However, this process could fail and
restart the asymmetric bidirectional search due to the limitations of
lazy-reverse search. To address this challenge, we propose Greedy GuILD
Grafting Trees (G3T*), a novel path planner that grafts invalid edge
connections at both ends to re-establish tree-based connectivity, enabling
rapid path convergence. G3T* employs a greedy approach using the minimum
Lebesgue measure of guided incremental local densification (GuILD) subsets to
optimize paths efficiently. Furthermore, G3T* dynamically adjusts the sampling
distribution between the informed set and GuILD subsets based on historical and
current cost improvements, ensuring asymptotic optimality. These features
enhance the forward search's growth towards the reverse tree, achieving faster
convergence and lower solution costs. Benchmark experiments across dimensions
from R^2 to R^8 and real-world robotic evaluations demonstrate G3T*'s superior
performance compared to existing single-query sampling-based planners. A video
showcasing our experimental results is available at:
https://youtu.be/3mfCRL5SQIU

</details>


### [258] [Context-Aware Risk Estimation in Home Environments: A Probabilistic Framework for Service Robots](https://arxiv.org/abs/2508.19788)
*Sena Ishii,Akash Chikhalikar,Ankit A. Ravankar,Jose Victorio Salazar Luces,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: 提出了一种基于语义图传播算法的室内场景事故风险区域估计框架，通过对象级风险评估和上下文传播来提升服务机器人的风险感知能力


<details>
  <summary>Details</summary>
Motivation: 随着机器人融入日常生活，特别是在家庭环境中，预测和应对环境风险对于确保用户安全、信任和有效人机交互至关重要

Method: 使用语义图传播算法建模对象级风险和上下文，将每个对象表示为具有风险评分的节点，风险基于空间邻近性和事故关系从高风险对象向低风险对象不对称传播

Result: 在人工标注风险区域的数据集上验证，二元风险检测准确率达到75%，在涉及尖锐或不稳定物体的场景中与人类感知高度一致

Conclusion: 该框架展示了上下文感知风险推理在增强机器人场景理解和主动安全行为方面的潜力，可为实时警报和自主辅助避障系统提供基础

Abstract: We present a novel framework for estimating accident-prone regions in
everyday indoor scenes, aimed at improving real-time risk awareness in service
robots operating in human-centric environments. As robots become integrated
into daily life, particularly in homes, the ability to anticipate and respond
to environmental hazards is crucial for ensuring user safety, trust, and
effective human-robot interaction. Our approach models object-level risk and
context through a semantic graph-based propagation algorithm. Each object is
represented as a node with an associated risk score, and risk propagates
asymmetrically from high-risk to low-risk objects based on spatial proximity
and accident relationship. This enables the robot to infer potential hazards
even when they are not explicitly visible or labeled. Designed for
interpretability and lightweight onboard deployment, our method is validated on
a dataset with human-annotated risk regions, achieving a binary risk detection
accuracy of 75%. The system demonstrates strong alignment with human
perception, particularly in scenes involving sharp or unstable objects. These
results underline the potential of context-aware risk reasoning to enhance
robotic scene understanding and proactive safety behaviors in shared
human-robot spaces. This framework could serve as a foundation for future
systems that make context-driven safety decisions, provide real-time alerts, or
autonomously assist users in avoiding or mitigating hazards within home
environments.

</details>


### [259] [APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors](https://arxiv.org/abs/2508.19790)
*Liding Zhang,Sicheng Wang,Kuanqi Cai,Zhenshan Bing,Fan Wu,Chaoqun Wang,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: APT*是一种新型采样运动规划器，通过自适应批量大小和椭圆r最近邻模块动态调整路径搜索过程，在4-16维空间中优于现有单查询采样规划器


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法通常使用固定批量大小且忽略障碍物信息，缺乏问题特异性，需要更智能的自适应规划方法

Method: 基于FDIT*扩展，集成自适应批量调整和椭圆r最近邻模块，将顶点视为遵循库仑定律的电荷来定义虚拟力，通过非线性扁长方法自适应调整顶点电荷

Result: 在R^4到R^16维度空间中，APT*优于现有单查询采样规划器，收敛速度更快且解成本更低，并在真实机器人操作任务中得到验证

Conclusion: APT*通过自适应机制和环境反馈显著提高了路径规划性能，为高维运动规划提供了有效解决方案

Abstract: Optimal path planning aims to determine a sequence of states from a start to
a goal while accounting for planning objectives. Popular methods often
integrate fixed batch sizes and neglect information on obstacles, which is not
problem-specific. This study introduces Adaptively Prolated Trees (APT*), a
novel sampling-based motion planner that extends based on Force Direction
Informed Trees (FDIT*), integrating adaptive batch-sizing and elliptical
$r$-nearest neighbor modules to dynamically modulate the path searching process
based on environmental feedback. APT* adjusts batch sizes based on the
hypervolume of the informed sets and considers vertices as electric charges
that obey Coulomb's law to define virtual forces via neighbor samples, thereby
refining the prolate nearest neighbor selection. These modules employ
non-linear prolate methods to adaptively adjust the electric charges of
vertices for force definition, thereby improving the convergence rate with
lower solution costs. Comparative analyses show that APT* outperforms existing
single-query sampling-based planners in dimensions from $\mathbb{R}^4$ to
$\mathbb{R}^{16}$, and it was further validated through a real-world robot
manipulation task. A video showcasing our experimental results is available at:
https://youtu.be/gCcUr8LiEw4

</details>


### [260] [A Standing Support Mobility Robot for Enhancing Independence in Elderly Daily Living](https://arxiv.org/abs/2508.19816)
*Ricardo J. Manríquez-Cisterna,Ankit A. Ravankar,Jose V. Salazar Luces,Takuro Hatsukari,Yasuhisa Hirata*

Main category: cs.RO

TL;DR: 开发了一款名为Moby的站立式移动辅助机器人，旨在帮助老年人保持站立姿势进行日常活动，提供被动支撑和移动支持，相比传统坐式助行器具有更好的用户体验和独立性。


<details>
  <summary>Details</summary>
Motivation: 传统坐式移动辅助设备限制了老年人的社交互动和独立性，需要一种能够维持直立姿势、减少身体负担并支持自然社交的新型移动辅助解决方案。

Method: 基于ROS系统开发，采用轻量化设计，集成NAV2和LiDAR实现鲁棒导航，提供手动和自主操作模式，使用定制控制系统确保安全直观的交互。

Result: 通过NASA-TLX方法和时间对比实验验证，Moby在易用性、舒适性、多功能性和站起辅助方面表现优异，显著提升了用户的独立性和自我效能感。

Conclusion: Moby机器人作为一种创新的站立式移动辅助解决方案，成功解决了传统助行器的局限性，为老年人提供了更安全、独立和社交友好的日常活动支持。

Abstract: This paper presents a standing support mobility robot "Moby" developed to
enhance independence and safety for elderly individuals during daily activities
such as toilet transfers. Unlike conventional seated mobility aids, the robot
maintains users in an upright posture, reducing physical strain, supporting
natural social interaction at eye level, and fostering a greater sense of
self-efficacy. Moby offers a novel alternative by functioning both passively
and with mobility support, enabling users to perform daily tasks more
independently. Its main advantages include ease of use, lightweight design,
comfort, versatility, and effective sit-to-stand assistance. The robot
leverages the Robot Operating System (ROS) for seamless control, featuring
manual and autonomous operation modes. A custom control system enables safe and
intuitive interaction, while the integration with NAV2 and LiDAR allows for
robust navigation capabilities. This paper reviews existing mobility solutions
and compares them to Moby, details the robot's design, and presents objective
and subjective experimental results using the NASA-TLX method and time
comparisons to other methods to validate our design criteria and demonstrate
the advantages of our contribution.

</details>


### [261] [FARM: Frame-Accelerated Augmentation and Residual Mixture-of-Experts for Physics-Based High-Dynamic Humanoid Control](https://arxiv.org/abs/2508.19926)
*Tan Jing,Shiting Chen,Yangfan Li,Weisheng Xu,Renjing Xu*

Main category: cs.RO

TL;DR: FARM框架通过帧加速增强和残差专家混合方法，显著提升了人形控制器在爆炸性动作上的表现，同时保持日常动作的精准跟踪


<details>
  <summary>Details</summary>
Motivation: 现有的人形控制器在温和日常动作上表现良好，但在爆炸性动作上容易失败，限制了实际应用。需要解决高动态动作的跟踪问题

Method: 提出FARM框架，包含帧加速增强（扩大帧间间隔暴露高速度姿态变化）、鲁棒基础控制器（处理低动态动作）和残差专家混合模块（自适应分配网络容量处理高动态动作）

Result: 在HDHM数据集上，FARM将跟踪失败率降低42.8%，全局平均关节位置误差降低14.6%，同时在低动态动作上保持近乎完美的精度

Conclusion: FARM为高动态人形控制设立了新的基准，并提供了首个专门针对此挑战的开放基准数据集

Abstract: Unified physics-based humanoid controllers are pivotal for robotics and
character animation, yet models that excel on gentle, everyday motions still
stumble on explosive actions, hampering real-world deployment. We bridge this
gap with FARM (Frame-Accelerated Augmentation and Residual Mixture-of-Experts),
an end-to-end framework composed of frame-accelerated augmentation, a robust
base controller, and a residual mixture-of-experts (MoE). Frame-accelerated
augmentation exposes the model to high-velocity pose changes by widening
inter-frame gaps. The base controller reliably tracks everyday low-dynamic
motions, while the residual MoE adaptively allocates additional network
capacity to handle challenging high-dynamic actions, significantly enhancing
tracking accuracy. In the absence of a public benchmark, we curate the
High-Dynamic Humanoid Motion (HDHM) dataset, comprising 3593 physically
plausible clips. On HDHM, FARM reduces the tracking failure rate by 42.8\% and
lowers global mean per-joint position error by 14.6\% relative to the baseline,
while preserving near-perfect accuracy on low-dynamic motions. These results
establish FARM as a new baseline for high-dynamic humanoid control and
introduce the first open benchmark dedicated to this challenge. The code and
dataset will be released at https://github.com/Colin-Jing/FARM.

</details>


### [262] [Divide, Discover, Deploy: Factorized Skill Learning with Symmetry and Style Priors](https://arxiv.org/abs/2508.19953)
*Rafael Cathomen,Mayank Mittal,Marin Vlastelica,Marco Hutter*

Main category: cs.RO

TL;DR: 提出模块化无监督技能发现框架，通过状态空间分解、对称性偏置和风格因子来提高机器人技能学习的安全性、可解释性和部署性，并在四足机器人上实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决现有无监督技能发现方法在真实机器人应用中面临的安全性、可解释性和部署性挑战，使学到的技能更具结构化和实用性。

Method: 采用用户定义的状态空间分解学习解耦技能表示，为不同因子分配相应的技能发现算法，引入对称性归纳偏置和风格因子，并加入正则化惩罚项。

Result: 在仿真四足机器人上验证了框架有效性，实现零样本迁移到真实硬件，学到的技能具有结构化、可解释性，安全性和多样性得到提升，在下游任务中表现与手工奖励训练的策略相当。

Conclusion: 状态空间分解和对称性偏置有助于发现结构化的人类可解释行为，风格因子和惩罚项增强了安全性和多样性，学到的技能可直接用于下游任务且性能优异。

Abstract: Unsupervised Skill Discovery (USD) allows agents to autonomously learn
diverse behaviors without task-specific rewards. While recent USD methods have
shown promise, their application to real-world robotics remains underexplored.
In this paper, we propose a modular USD framework to address the challenges in
the safety, interpretability, and deployability of the learned skills. Our
approach employs user-defined factorization of the state space to learn
disentangled skill representations. It assigns different skill discovery
algorithms to each factor based on the desired intrinsic reward function. To
encourage structured morphology-aware skills, we introduce symmetry-based
inductive biases tailored to individual factors. We also incorporate a style
factor and regularization penalties to promote safe and robust behaviors. We
evaluate our framework in simulation using a quadrupedal robot and demonstrate
zero-shot transfer of the learned skills to real hardware. Our results show
that factorization and symmetry lead to the discovery of structured
human-interpretable behaviors, while the style factor and penalties enhance
safety and diversity. Additionally, we show that the learned skills can be used
for downstream tasks and perform on par with oracle policies trained with
hand-crafted rewards.

</details>


### [263] [Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation](https://arxiv.org/abs/2508.19958)
*Yiguo Fan,Pengxiang Ding,Shuanghao Bai,Xinyang Tong,Yuyang Zhu,Hongchao Lu,Fengqi Dai,Wei Zhao,Yang Liu,Siteng Huang,Zhaoxin Fan,Badong Chen,Donglin Wang*

Main category: cs.RO

TL;DR: Long-VLA是首个专门针对长时程机器人任务的端到端视觉-语言-动作模型，通过相位感知输入掩码策略将子任务分为移动和交互阶段，显著提升了长时程操作性能


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型主要处理短时程任务，在长时程、多步骤的机器人操作中由于技能链和子任务依赖性的挑战而效果有限

Method: 提出相位感知输入掩码策略，自适应地将每个子任务分割为移动和交互阶段，使模型能关注阶段相关的感知线索；架构无关模块可无缝集成到现有VLA模型中

Result: 在仿真和真实世界任务上的大量实验表明，Long-VLA显著优于现有最先进方法，为长时程机器人控制建立了新基准

Conclusion: Long-VLA通过统一的策略保持了VLA训练的可扩展性和数据效率，是长时程机器人任务的有效解决方案

Abstract: Vision-Language-Action (VLA) models have become a cornerstone in robotic
policy learning, leveraging large-scale multimodal data for robust and scalable
control. However, existing VLA frameworks primarily address short-horizon
tasks, and their effectiveness on long-horizon, multi-step robotic manipulation
remains limited due to challenges in skill chaining and subtask dependencies.
In this work, we introduce Long-VLA, the first end-to-end VLA model
specifically designed for long-horizon robotic tasks. Our approach features a
novel phase-aware input masking strategy that adaptively segments each subtask
into moving and interaction phases, enabling the model to focus on
phase-relevant sensory cues and enhancing subtask compatibility. This unified
strategy preserves the scalability and data efficiency of VLA training, and our
architecture-agnostic module can be seamlessly integrated into existing VLA
models. We further propose the L-CALVIN benchmark to systematically evaluate
long-horizon manipulation. Extensive experiments on both simulated and
real-world tasks demonstrate that Long-VLA significantly outperforms prior
state-of-the-art methods, establishing a new baseline for long-horizon robotic
control.

</details>


### [264] [Visio-Verbal Teleimpedance Interface: Enabling Semi-Autonomous Control of Physical Interaction via Eye Tracking and Speech](https://arxiv.org/abs/2508.20037)
*Henk H. A. Jekel,Alejandro Díaz Rosales,Luka Peternel*

Main category: cs.RO

TL;DR: 开发了一个结合视觉注视和语音交互的遥阻抗接口，通过眼动追踪和视觉语言模型处理操作者意图，生成适当的刚度矩阵来控制远程机器人


<details>
  <summary>Details</summary>
Motivation: 传统遥操作界面需要复杂的物理输入设备，本文旨在通过自然的人类视觉注视和语音交互来简化机器人刚度控制

Method: 使用眼动追踪器捕捉操作者注视点，结合GPT-4o处理的语音命令，通过视觉语言模型理解上下文并生成相应的3D刚度椭球体

Result: 实验验证了接口在滑块入槽任务中的功能，找到了最优提示配置，展示了系统在不同物理交互动作中的有效性

Conclusion: 视觉-语音遥阻抗接口提供了一种直观自然的人机交互方式，能够有效传达操作者意图并生成适当的机器人刚度控制

Abstract: The paper presents a visio-verbal teleimpedance interface for commanding 3D
stiffness ellipsoids to the remote robot with a combination of the operator's
gaze and verbal interaction. The gaze is detected by an eye-tracker, allowing
the system to understand the context in terms of what the operator is currently
looking at in the scene. Along with verbal interaction, a Visual Language Model
(VLM) processes this information, enabling the operator to communicate their
intended action or provide corrections. Based on these inputs, the interface
can then generate appropriate stiffness matrices for different physical
interaction actions. To validate the proposed visio-verbal teleimpedance
interface, we conducted a series of experiments on a setup including a Force
Dimension Sigma.7 haptic device to control the motion of the remote Kuka LBR
iiwa robotic arm. The human operator's gaze is tracked by Tobii Pro Glasses 2,
while human verbal commands are processed by a VLM using GPT-4o. The first
experiment explored the optimal prompt configuration for the interface. The
second and third experiments demonstrated different functionalities of the
interface on a slide-in-the-groove task.

</details>


### [265] [HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation](https://arxiv.org/abs/2508.20085)
*Zhecheng Yuan,Tianming Wei,Langzhe Gu,Pu Hua,Tianhai Liang,Yuanpei Chen,Huazhe Xu*

Main category: cs.RO

TL;DR: HERMES是一个从人类运动到机器人学习的框架，用于移动双手机器人灵巧操作，能够将多源人类手部运动转化为可行的机器人行为，并通过强化学习、sim2real迁移和导航增强实现泛化能力。


<details>
  <summary>Details</summary>
Motivation: 将多源人类手部运动转化为机器人可行行为具有挑战性，特别是对于具有复杂高维动作空间的多指灵巧手机器人。现有方法难以产生适应多样化环境条件的策略。

Method: 1) 统一的强化学习方法转换异构人类手部运动为机器人行为；2) 基于深度图像的端到端sim2real迁移方法；3) 增强导航基础模型，加入闭环PnP定位机制，桥接自主导航和灵巧操作。

Result: 实验结果表明HERMES在多样化真实场景中表现出良好的泛化行为，成功执行了众多复杂的移动双手机器人灵巧操作任务。

Conclusion: HERMES框架有效解决了人类运动到机器人行为的转换问题，通过综合方法实现了在非结构化环境中的自主操作能力，为移动灵巧操作提供了可行的解决方案。

Abstract: Leveraging human motion data to impart robots with versatile manipulation
skills has emerged as a promising paradigm in robotic manipulation.
Nevertheless, translating multi-source human hand motions into feasible robot
behaviors remains challenging, particularly for robots equipped with
multi-fingered dexterous hands characterized by complex, high-dimensional
action spaces. Moreover, existing approaches often struggle to produce policies
capable of adapting to diverse environmental conditions. In this paper, we
introduce HERMES, a human-to-robot learning framework for mobile bimanual
dexterous manipulation. First, HERMES formulates a unified reinforcement
learning approach capable of seamlessly transforming heterogeneous human hand
motions from multiple sources into physically plausible robotic behaviors.
Subsequently, to mitigate the sim2real gap, we devise an end-to-end, depth
image-based sim2real transfer method for improved generalization to real-world
scenarios. Furthermore, to enable autonomous operation in varied and
unstructured environments, we augment the navigation foundation model with a
closed-loop Perspective-n-Point (PnP) localization mechanism, ensuring precise
alignment of visual goals and effectively bridging autonomous navigation and
dexterous manipulation. Extensive experimental results demonstrate that HERMES
consistently exhibits generalizable behaviors across diverse, in-the-wild
scenarios, successfully performing numerous complex mobile bimanual dexterous
manipulation tasks. Project Page:https:/gemcollector.github.io/HERMES/.

</details>


### [266] [Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning](https://arxiv.org/abs/2508.20095)
*Jinhao Liang,Sven Koenig,Ferdinando Fioretto*

Main category: cs.RO

TL;DR: 提出DGD框架，将离散多智能体路径规划与生成扩散模型结合，解决多机器人运动规划问题，实现100个机器人的高效规划和高成功率


<details>
  <summary>Details</summary>
Motivation: 现有离散MAPF方法可扩展但轨迹质量差，连续优化方法质量高但维度灾难难以扩展。需要结合两者优势的新方法

Method: 离散引导扩散(DGD)框架：1)分解非凸问题为凸子问题 2)用MAPF解引导扩散模型捕捉时空依赖 3)轻量约束修复确保可行性

Result: 在大规模复杂环境中达到最先进性能，可扩展到100个机器人，实现高效规划和高成功率

Conclusion: DGD框架成功整合离散和连续方法，解决了多机器人运动规划的可扩展性和轨迹质量平衡问题

Abstract: Multi-Robot Motion Planning (MRMP) involves generating collision-free
trajectories for multiple robots operating in a shared continuous workspace.
While discrete multi-agent path finding (MAPF) methods are broadly adopted due
to their scalability, their coarse discretization severely limits trajectory
quality. In contrast, continuous optimization-based planners offer
higher-quality paths but suffer from the curse of dimensionality, resulting in
poor scalability with respect to the number of robots. This paper tackles the
limitations of these two approaches by introducing a novel framework that
integrates discrete MAPF solvers with constrained generative diffusion models.
The resulting framework, called Discrete-Guided Diffusion (DGD), has three key
characteristics: (1) it decomposes the original nonconvex MRMP problem into
tractable subproblems with convex configuration spaces, (2) it combines
discrete MAPF solutions with constrained optimization techniques to guide
diffusion models capture complex spatiotemporal dependencies among robots, and
(3) it incorporates a lightweight constraint repair mechanism to ensure
trajectory feasibility. The proposed method sets a new state-of-the-art
performance in large-scale, complex environments, scaling to 100 robots while
achieving planning efficiency and high success rates.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [267] [MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks](https://arxiv.org/abs/2508.19251)
*Qian Liang,Menghaoran Tang,Yi Zeng*

Main category: cs.SD

TL;DR: MuSpike是首个针对脉冲神经网络(SNN)在符号音乐生成领域的统一基准测试和评估框架，系统评估了5种代表性SNN架构在5个数据集上的表现，结合客观指标和主观听感研究。


<details>
  <summary>Details</summary>
Motivation: 符号音乐生成在人工神经网络领域进展迅速，但在生物可解释的脉冲神经网络(SNN)领域仍缺乏标准化基准和全面评估方法。

Method: 引入MuSpike框架，系统评估5种SNN架构(SNN-CNN、SNN-RNN、SNN-LSTM、SNN-GAN、SNN-Transformer)在5个典型数据集上的表现，结合客观指标和大规模听感研究，提出新的主观评估指标。

Result: 发现：(1)不同SNN模型在不同评估维度上表现各异；(2)不同音乐背景的参与者感知模式不同，专家对AI创作音乐容忍度更高；(3)客观与主观评估存在明显不一致。

Conclusion: MuSpike为SNN模型在符号音乐生成领域建立了首个系统性基准和评估框架，为未来生物可解释和认知基础的音乐生成研究奠定基础。

Abstract: Symbolic music generation has seen rapid progress with artificial neural
networks, yet remains underexplored in the biologically plausible domain of
spiking neural networks (SNNs), where both standardized benchmarks and
comprehensive evaluation methods are lacking. To address this gap, we introduce
MuSpike, a unified benchmark and evaluation framework that systematically
assesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM,
SNN-GAN and SNN-Transformer) across five typical datasets, covering tonal,
structural, emotional, and stylistic variations. MuSpike emphasizes
comprehensive evaluation, combining established objective metrics with a
large-scale listening study. We propose new subjective metrics, targeting
musical impression, autobiographical association, and personal preference, that
capture perceptual dimensions often overlooked in prior work. Results reveal
that (1) different SNN models exhibit distinct strengths across evaluation
dimensions; (2) participants with different musical backgrounds exhibit diverse
perceptual patterns, with experts showing greater tolerance toward AI-composed
music; and (3) a noticeable misalignment exists between objective and
subjective evaluations, highlighting the limitations of purely statistical
metrics and underscoring the value of human perceptual judgment in assessing
musical quality. MuSpike provides the first systematic benchmark and systemic
evaluation framework for SNN models in symbolic music generation, establishing
a solid foundation for future research into biologically plausible and
cognitively grounded music generation.

</details>


### [268] [Beat-Based Rhythm Quantization of MIDI Performances](https://arxiv.org/abs/2508.19262)
*Maximilian Wachter,Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

TL;DR: 提出基于Transformer的节奏量化模型，结合节拍和强拍信息将MIDI演奏量化为符合节拍对齐、人类可读的乐谱


<details>
  <summary>Details</summary>
Motivation: 将MIDI演奏数据转换为标准乐谱需要准确的节奏量化，现有方法在保持节拍对齐和人类可读性方面存在挑战

Method: 使用基于节拍的预处理方法将乐谱和演奏数据转换为统一的token表示，优化Transformer模型架构和数据表示，在钢琴和吉他演奏数据上训练

Result: 模型在MUSTER指标上超越了现有最先进方法的性能

Conclusion: 提出的Transformer节奏量化模型能够有效利用节拍和强拍信息，实现高质量的MIDI演奏到乐谱的转换

Abstract: We propose a transformer-based rhythm quantization model that incorporates
beat and downbeat information to quantize MIDI performances into
metrically-aligned, human-readable scores. We propose a beat-based
preprocessing method that transfers score and performance data into a unified
token representation. We optimize our model architecture and data
representation and train on piano and guitar performances. Our model exceeds
state-of-the-art performance based on the MUSTER metric.

</details>


### [269] [Infant Cry Detection In Noisy Environment Using Blueprint Separable Convolutions and Time-Frequency Recurrent Neural Network](https://arxiv.org/abs/2508.19308)
*Haolin Yu,Yanxiong Li*

Main category: cs.SD

TL;DR: 提出了一种轻量级且鲁棒的婴儿哭声检测方法，使用蓝图可分离卷积降低计算复杂度，结合时频循环神经网络进行自适应去噪，在多尺度卷积循环神经网络框架中融入高效空间注意力机制和对比感知通道注意力模块。


<details>
  <summary>Details</summary>
Motivation: 婴儿哭声检测是婴儿护理系统的关键组成部分，需要开发轻量级且鲁棒的方法来应对现实场景中的噪声环境。

Method: 采用多尺度卷积循环神经网络框架，使用蓝图可分离卷积降低计算复杂度，结合时频循环神经网络进行自适应去噪，并融入高效空间注意力机制和对比感知通道注意力模块，从log Mel-spectrogram输入特征中获取局部和全局信息。

Result: 在多个公开数据集上测试，结果表明该方法在各种信噪比条件下在准确率、F1分数和复杂度方面均优于许多最先进的方法。

Conclusion: 该方法为婴儿哭声检测提供了一种高效且鲁棒的解决方案，在现实噪声环境中表现出色，具有实际应用价值。

Abstract: Infant cry detection is a crucial component of baby care system. In this
paper, we propose a lightweight and robust method for infant cry detection. The
method leverages blueprint separable convolutions to reduce computational
complexity, and a time-frequency recurrent neural network for adaptive
denoising. The overall framework of the method is structured as a multi-scale
convolutional recurrent neural network, which is enhanced by efficient spatial
attention mechanism and contrast-aware channel attention module, and acquire
local and global information from the input feature of log Mel-spectrogram.
Multiple public datasets are adopted to create a diverse and representative
dataset, and environmental corruption techniques are used to generate the noisy
samples encountered in real-world scenarios. Results show that our method
exceeds many state-of-the-art methods in accuracy, F1-score, and complexity
under various signal-to-noise ratio conditions. The code is at
https://github.com/fhfjsd1/ICD_MMSP.

</details>


### [270] [MQAD: A Large-Scale Question Answering Dataset for Training Music Large Language Models](https://arxiv.org/abs/2508.19514)
*Zhihao Ouyang,Ju-Chiang Wang,Daiyu Zhang,Bin Chen,Shangjie Li,Quan Lin*

Main category: cs.SD

TL;DR: MQAD是一个基于百万歌曲数据集的大规模音乐问答数据集，包含270,000首曲目、近300万个多样化问题和字幕，涵盖节拍、和弦、调性、结构、乐器和流派等丰富音乐特征。


<details>
  <summary>Details</summary>
Motivation: 人类通过问答方式理解音乐很自然，但机器需要大规模覆盖音乐多方面的数据集，而这类公开音乐数据稀缺，因此需要构建专门的音乐问答数据集。

Method: 利用专业音乐信息检索模型提取高级音乐特征，使用大语言模型生成自然语言问答对，并采用集成LLaMA2和Whisper架构的多模态大语言模型进行评估。

Result: 在MQAD上训练的模型相比传统音乐音频字幕方法表现出进步，证明了数据集的有效性。

Conclusion: MQAD通过提供详细的时间变化音乐信息，为探索歌曲内在音乐结构提供了重要资源，数据集和代码已开源。

Abstract: Question-answering (QA) is a natural approach for humans to understand a
piece of music audio. However, for machines, accessing a large-scale dataset
covering diverse aspects of music is crucial, yet challenging, due to the
scarcity of publicly available music data of this type. This paper introduces
MQAD, a music QA dataset built on the Million Song Dataset (MSD), encompassing
a rich array of musical features, including beat, chord, key, structure,
instrument, and genre -- across 270,000 tracks, featuring nearly 3 million
diverse questions and captions. MQAD distinguishes itself by offering detailed
time-varying musical information such as chords and sections, enabling
exploration into the inherent structure of music within a song. To compile
MQAD, our methodology leverages specialized Music Information Retrieval (MIR)
models to extract higher-level musical features and Large Language Models
(LLMs) to generate natural language QA pairs. Then, we leverage a multimodal
LLM that integrates the LLaMA2 and Whisper architectures, along with novel
subjective metrics to assess the performance of MQAD. In experiments, our model
trained on MQAD demonstrates advancements over conventional music audio
captioning approaches. The dataset and code are available at
https://github.com/oyzh888/MQAD.

</details>


### [271] [CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation](https://arxiv.org/abs/2508.19603)
*Zhejing Hu,Yan Liu,Gong Chen,Bruce X. B. Yu*

Main category: cs.SD

TL;DR: 本文提出了一个名为CompLex的自动音乐词典构建模型，通过仅9个手动输入类别关键词和5个句子提示模板，生成了包含37,432个项目的音乐词典，显著提升了文本到音乐生成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前音乐生成AI在数据可用性方面落后于自然语言处理，而知识引导方法已被证明能有效提升音乐生成模型性能。本文旨在利用全面的音乐理论来改进AI驱动的音乐生成任务，减少传统方法所需的大量人工努力。

Method: 提出新颖的自动音乐词典构建模型，使用少量手动输入（9个类别关键词和5个句子提示模板）生成大规模音乐词典CompLex。开发了新的多智能体算法来自动检测和缓解幻觉问题。

Result: CompLex在三个最先进的文本到音乐生成模型（包括符号和音频方法）上表现出显著的性能提升。词典在完整性、准确性、非冗余性和可执行性方面均得到验证。

Conclusion: CompLex音乐词典展示了作为有效词典的关键特征，能够显著提升音乐生成模型的性能，为知识引导的音乐AI发展提供了有力工具。

Abstract: Generative artificial intelligence in music has made significant strides, yet
it still falls short of the substantial achievements seen in natural language
processing, primarily due to the limited availability of music data.
Knowledge-informed approaches have been shown to enhance the performance of
music generation models, even when only a few pieces of musical knowledge are
integrated. This paper seeks to leverage comprehensive music theory in
AI-driven music generation tasks, such as algorithmic composition and style
transfer, which traditionally require significant manual effort with existing
techniques. We introduce a novel automatic music lexicon construction model
that generates a lexicon, named CompLex, comprising 37,432 items derived from
just 9 manually input category keywords and 5 sentence prompt templates. A new
multi-agent algorithm is proposed to automatically detect and mitigate
hallucinations. CompLex demonstrates impressive performance improvements across
three state-of-the-art text-to-music generation models, encompassing both
symbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of
completeness, accuracy, non-redundancy, and executability, confirming that it
possesses the key characteristics of an effective lexicon.

</details>


### [272] [The IRMA Dataset: A Structured Audio-MIDI Corpus for Iranian Classical Music](https://arxiv.org/abs/2508.19876)
*Sepideh Shafiei,Shapour Hakam*

Main category: cs.SD

TL;DR: IRMA数据集是一个多层级、开放获取的伊朗古典音乐计算研究语料库，特别关注radif（伊朗音乐教学和表演的核心模态旋律单元），包含MIDI符号表示、音频-MIDI对齐、音乐学转录和理论信息比较表。


<details>
  <summary>Details</summary>
Motivation: 为伊朗古典音乐的计算研究提供全面的多模态数据集，支持民族音乐学、教学法、符号音频研究、文化遗产保护和AI驱动任务（如自动转录和音乐生成）。

Method: 采用多阶段构建过程，包括片段标注、对齐方法和结构化标识符编码系统，结合符号MIDI表示、短语级音频-MIDI对齐、PDF格式音乐学转录以及从不同表演者和学者收集的理论信息比较表。

Result: 当前版本包含Karimi的完整radif、Mirza Abdollah的radif MIDI文件和元数据、Davami声乐radif的选定片段，以及20世纪著名声乐家表演的tahrir装饰音音频-MIDI示例。

Conclusion: 该数据集既是学术档案又是计算分析资源，支持跨学科研究应用，并欢迎合作和反馈以进一步完善和更广泛地集成到音乐学和机器学习工作流程中。

Abstract: We present the IRMA Dataset (Iranian Radif MIDI Audio), a multi-level,
open-access corpus designed for the computational study of Iranian classical
music, with a particular emphasis on the radif, a structured repertoire of
modal-melodic units central to pedagogy and performance. The dataset combines
symbolic MIDI representations, phrase-level audio-MIDI alignment, musicological
transcriptions in PDF format, and comparative tables of theoretical information
curated from a range of performers and scholars. We outline the multi-phase
construction process, including segment annotation, alignment methods, and a
structured system of identifier codes to reference individual musical units.
The current release includes the complete radif of Karimi; MIDI files and
metadata from Mirza Abdollah's radif; selected segments from the vocal radif of
Davami, as transcribed by Payvar and Fereyduni; and a dedicated section
featuring audio-MIDI examples of tahrir ornamentation performed by prominent
20th-century vocalists. While the symbolic and analytical components are
released under an open-access license (CC BY-NC 4.0), some referenced audio
recordings and third-party transcriptions are cited using discographic
information to enable users to locate the original materials independently,
pending copyright permission. Serving both as a scholarly archive and a
resource for computational analysis, this dataset supports applications in
ethnomusicology, pedagogy, symbolic audio research, cultural heritage
preservation, and AI-driven tasks such as automatic transcription and music
generation. We welcome collaboration and feedback to support its ongoing
refinement and broader integration into musicological and machine learning
workflows.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [273] [Quantum Entanglement as Super-Confounding: From Bell's Theorem to Robust Machine Learning](https://arxiv.org/abs/2508.19327)
*Pilsung Kang*

Main category: quant-ph

TL;DR: 本文通过因果推断的现代视角重新解释贝尔定理，提出量子纠缠作为"超混杂"资源的概念，建立了量子>经典的混杂层次结构，并开发了量子DO演算用于因果分析，在量子机器学习中实现了11.3%的模型鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 重新从因果推断的角度理解贝尔定理揭示的量子力学与局域实在论之间的深刻冲突，探索量子纠缠作为特殊因果资源的作用。

Method: 提出并计算验证了一个框架，其中量子纠缠作为"超混杂"资源；建立了混杂强度(CS)量化指标；开发了基于电路的量子DO演算实现；将因果特征选择应用于量子机器学习问题。

Result: 建立了量子>经典的混杂层次结构；量子DO演算成功区分了因果关系和伪相关；在量子机器学习中，因果特征选择带来了11.3%的平均绝对鲁棒性提升。

Conclusion: 该框架连接了量子基础理论和因果人工智能，为量子相关性提供了新的实用视角，展示了因果方法在量子计算和机器学习中的实际价值。

Abstract: Bell's theorem reveals a profound conflict between quantum mechanics and
local realism, a conflict we reinterpret through the modern lens of causal
inference. We propose and computationally validate a framework where quantum
entanglement acts as a "super-confounding" resource, generating correlations
that violate the classical causal bounds set by Bell's inequalities. This work
makes three key contributions: First, we establish a physical hierarchy of
confounding (Quantum > Classical) and introduce Confounding Strength (CS) to
quantify this effect. Second, we provide a circuit-based implementation of the
quantum $\mathcal{DO}$-calculus to distinguish causality from spurious
correlation. Finally, we apply this calculus to a quantum machine learning
problem, where causal feature selection yields a statistically significant
11.3% average absolute improvement in model robustness. Our framework bridges
quantum foundations and causal AI, offering a new, practical perspective on
quantum correlations.

</details>


### [274] [Is data-efficient learning feasible with quantum models?](https://arxiv.org/abs/2508.19437)
*Alona Sakhnenko,Christian B. Mendl,Jeanette M. Lorenz*

Main category: quant-ph

TL;DR: 该研究提出了一个分析量子机器学习数据集复杂性的框架，通过量子核方法展示了量子模型在数据效率上的优势，并开发了新的分析工具来研究经典-量子性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前文献中缺乏对量子机器学习数据集特性的统一理解框架，特别是数据集大小作为复杂性指标的重要性，以及量子模型相比经典模型在数据效率上的潜在优势。

Method: 开发了生成半人工全经典数据集的方法，使用量子核方法(QKMs)进行实验，并引入了从经典核方法推导出的新分析工具来研究经典-量子性能差距。

Result: 实证结果显示量子核方法相比经典对应方法能用更少的训练数据实现低错误率，提出的泛化度量指标与实证证据高度一致。

Conclusion: 该研究为全面探索数据集复杂性铺平了道路，提供了对量子核方法泛化优势的深入理解，为量子机器学习领域的未来发展奠定了基础。

Abstract: The importance of analyzing nontrivial datasets when testing quantum machine
learning (QML) models is becoming increasingly prominent in literature, yet a
cohesive framework for understanding dataset characteristics remains elusive.
In this work, we concentrate on the size of the dataset as an indicator of its
complexity and explores the potential for QML models to demonstrate superior
data-efficiency compared to classical models, particularly through the lens of
quantum kernel methods (QKMs). We provide a method for generating
semi-artificial fully classical datasets, on which we show one of the first
evidence of the existence of classical datasets where QKMs require less data
during training. Additionally, our study introduces a new analytical tool to
the QML domain, derived for classical kernel methods, which can be aimed at
investigating the classical-quantum gap. Our empirical results reveal that QKMs
can achieve low error rates with less training data compared to classical
counterparts. Furthermore, our method allows for the generation of datasets
with varying properties, facilitating further investigation into the
characteristics of real-world datasets that may be particularly advantageous
for QKMs. We also show that the predicted performance from the analytical tool
we propose - a generalization metric from classical domain - show great
alignment empirical evidence, which fills the gap previously existing in the
field. We pave a way to a comprehensive exploration of dataset complexities,
providing insights into how these complexities influence QML performance
relative to traditional methods. This research contributes to a deeper
understanding of the generalization benefits of QKM models and potentially a
broader family of QML models, setting the stage for future advancements in the
field.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [275] [Training for Obsolescence? The AI-Driven Education Trap](https://arxiv.org/abs/2508.19625)
*Andrew J. Peterson*

Main category: econ.GN

TL;DR: 教育规划者采用AI时只考虑教学效率，忽视了AI对工资的压制效应，导致技能不匹配问题加剧


<details>
  <summary>Details</summary>
Motivation: 人工智能同时影响教育中的人力资本生产和劳动市场需求，单独分析这些效应会导致教育资源的重大误配

Method: 建立教育规划者模型，假设教学生产率与工资压制效应存在正相关关系，分析AI普及度与技能不匹配的关系

Result: 信息失效导致技能不匹配问题，这种不匹配随着AI普及度增加而单调增长，忽视非计价非认知技能和学校的内生过度投资会进一步加剧这个问题

Conclusion: 如果不配合期望市场信号，促进教育AI化的政策可能反而損害学生的长期人力资本，特别是当AI发展排护了通过知识挑战培养的持久性等非认知技能

Abstract: Artificial intelligence simultaneously transforms human capital production in
schools and its demand in labor markets. Analyzing these effects in isolation
can lead to a significant misallocation of educational resources. We model an
educational planner whose decision to adopt AI is driven by its teaching
productivity, failing to internalize AI's future wage-suppressing effect on
those same skills. Our core assumption, motivated by a pilot survey, is that
there is a positive correlation between these two effects. This drives our
central proposition: this information failure creates a skill mismatch that
monotonically increases with AI prevalence. Extensions show the mismatch is
exacerbated by the neglect of unpriced non-cognitive skills and by a school's
endogenous over-investment in AI. Our findings caution that policies promoting
AI in education, if not paired with forward-looking labor market signals, may
paradoxically undermine students' long-term human capital, especially if
reliance on AI crowds out the development of unpriced non-cognitive skills,
such as persistence, that are forged through intellectual struggle.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [276] [Inferring geometry and material properties from Mueller matrices with machine learning](https://arxiv.org/abs/2508.19713)
*Lars Doorenbos,C. H. Lucas Patty,Raphael Sznitman,Pablo Márquez-Neila*

Main category: physics.optics

TL;DR: 使用机器学习从穆勒矩阵中同时推断表面几何形状和材料属性，即使材料类型未知也能成功重建物体几何和识别材料类型


<details>
  <summary>Details</summary>
Motivation: 穆勒矩阵同时编码几何和材料信息，但传统方法难以同时恢复两者。研究探索机器学习是否能从穆勒矩阵中充分推断这些信息

Method: 使用各向同性材料球体的数据集，在五个可见光波长下捕获全角度域的穆勒矩阵，训练机器学习模型预测材料属性和表面法线

Result: 即使材料类型未知，也能预测表面法线并重建物体几何；穆勒矩阵使模型能正确识别材料类型；对角元素对材料表征关键，非对角元素对法线估计决定性

Conclusion: 穆勒矩阵包含足够信息用于同时推断表面几何和材料属性，机器学习方法能有效解决这一传统上的不适定问题

Abstract: Mueller matrices (MMs) encode information on geometry and material
properties, but recovering both simultaneously is an ill-posed problem. We
explore whether MMs contain sufficient information to infer surface geometry
and material properties with machine learning. We use a dataset of spheres of
various isotropic materials, with MMs captured over the full angular domain at
five visible wavelengths (450-650 nm). We train machine learning models to
predict material properties and surface normals using only these MMs as input.
We demonstrate that, even when the material type is unknown, surface normals
can be predicted and object geometry reconstructed. Moreover, MMs allow models
to identify material types correctly. Further analyses show that diagonal
elements are key for material characterization, and off-diagonal elements are
decisive for normal estimation.

</details>


### [277] [Fourier Feature Networks for High-Fidelity Prediction of Perturbed Optical Fields](https://arxiv.org/abs/2508.19751)
*Joshua R. Jandrell,Mitchell A. Cox*

Main category: physics.optics

TL;DR: 提出了一种基于傅里叶特征的神经网络方法，用于准确建模高频振荡的复值光学场函数，相比标准MLP在参数减少85%的情况下将预测误差降低了一个数量级。


<details>
  <summary>Details</summary>
Motivation: 标准多层感知机(MLP)在处理高频振荡的复值函数时存在频谱偏差问题，无法有效拟合高频正弦函数，这限制了其在光学扰动效应建模中的应用。

Method: 通过将预定义的傅里叶特征（依赖于扰动的正弦函数组）作为网络额外输入，将学习问题从近似复杂函数转化为寻找基函数的线性组合。

Result: 在多模光纤机械压缩传输矩阵预测任务中，该方法相比标准MLP将输出场振幅和相位的预测误差降低了一个数量级，平均复相关系数达到0.995。

Conclusion: 该方法为准确建模各类振荡物理系统提供了一种通用且鲁棒的方法，在保持高精度的同时显著减少了模型参数需求。

Abstract: Modelling the effects of perturbations on optical fields often requires
learning highly oscillatory complex-valued functions. Standard multi-layer
perceptrons (MLPs) struggle with this task due to an inherent spectral bias,
preventing them from fitting high-frequency sinusoids. To overcome this, we
incorporate Fourier features - a set of predefined sinusoids dependent on the
perturbation - as an additional network input. This reframes the learning
problem from approximating a complex function to finding a linear combination
of basis functions. We demonstrate this method by training a Fourier Feature
Network to predict the transmission matrix of a multimode fibre under
mechanical compression. Compared to a standard MLP, our network reduces
prediction error in the output field's amplitude and phase by an order of
magnitude, achieving a mean complex correlation of 0.995 with the ground truth,
despite using 85% fewer parameters. This approach offers a general and robust
method for accurately modelling a wide class of oscillatory physical systems.

</details>


### [278] [On-chip wave chaos for photonic extreme learning](https://arxiv.org/abs/2508.19878)
*Matthew R. Wilson,Jack A. Smith,Michael J. Strain,Xavier Porte*

Main category: physics.optics

TL;DR: 本文通过实验验证了基于波动混沌平几何微容器的芯片级光子极限学习机架构，利用波长编码输入信息和散射隐私读取层，在四个不同标准分类任务中展现了可优化读取尺寸的高性能分类能力。


<details>
  <summary>Details</summary>
Motivation: 为满足可扩展和能源效率人工神经网络的增长需求，集成光子学提供了一种组庄、并行化和超高速的信息处理平台，特别适合极限学习机架构。

Method: 通过在玻璃上直接激光写入SU-8聚合物制造平几微容器，利用波长编码输入信息，通过散射壁收集容器漏泰模式的光作为读取层。对输入波长进行高分辨率扫描获得无相关和非周期性的斑点行为。

Result: 在四个质性不同的标准分类任务中，系统展现出良好的分类性能。通过测量散射壁的不同部分，可以控制输出节点数量，从而优化光子ELM的读取尺寸以满足不同任务的性能要求。

Conclusion: 这种基于波动混沌平几微容器的光子极限学习机架构为实现可扩展、能源效率高的人工神经网络提供了一种有前景的硬件解决方案，特别是其可优化读取尺寸的能力使得系统能够适应不同复杂度的任务需求。

Abstract: The increase in demand for scalable and energy efficient artificial neural
networks has put the focus on novel hardware solutions. Integrated photonics
offers a compact, parallel and ultra-fast information processing platform,
specially suited for extreme learning machine (ELM) architectures. Here we
experimentally demonstrate a chip-scale photonic ELM based on wave chaos
interference in a stadium microcavity. By encoding the input information in the
wavelength of an external single-frequency tunable laser source, we leverage
the high sensitivity to wavelength of injection in such photonic resonators. We
fabricate the microcavity with direct laser writing of SU-8 polymer on glass. A
scattering wall surrounding the stadium operates as readout layer, collecting
the light associated with the cavity's leaky modes. We report uncorrelated and
aperiodic behavior in the speckles of the scattering barrier from a high
resolution scan of the input wavelength. Finally, we characterize the system's
performance at classification in four qualitatively different benchmark tasks.
As we can control the number of output nodes of our ELM by measuring different
parts of the scattering barrier, we demonstrate the capability to optimize our
photonic ELM's readout size to the performance required for each task.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [279] [Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices](https://arxiv.org/abs/2508.19078)
*Fahao Chen,Jie Wan,Peng Li,Zhou Su,Dongxiao Yu*

Main category: cs.DC

TL;DR: FLUX是一个联邦学习系统，专门用于在资源受限设备上高效微调MoE大语言模型，通过量化分析、专家合并和动态角色分配实现4.75倍加速


<details>
  <summary>Details</summary>
Motivation: 现有方法无法在资源受限环境下有效微调MoE大模型，存在不切实际的系统假设和缺乏对MoE特性的考虑

Method: 提出三种关键技术：量化本地分析估计专家激活、自适应层级专家合并减少资源消耗、动态专家角色分配平衡调优与非调优专家

Result: 在LLaMA-MoE和DeepSeek-MoE上的实验显示，FLUX显著优于现有方法，时间到准确率指标提升达4.75倍

Conclusion: FLUX系统成功解决了资源受限环境下MoE模型联邦微调的挑战，为边缘设备部署大模型提供了可行方案

Abstract: Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models
(LLMs) is challenging due to their massive computational requirements and the
resource constraints of participants. Existing working attempts to fill this
gap through model quantization, computation offloading, or expert pruning.
However, they cannot achieve desired performance due to impractical system
assumptions and a lack of consideration for MoE-specific characteristics. In
this paper, we propose FLUX, a system designed to enable federated fine-tuning
of MoE-based LLMs across participants with constrained computing resources
(e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX
introduces three key innovations: (1) quantization-based local profiling to
estimate expert activation with minimal overhead, (2) adaptive layer-aware
expert merging to reduce resource consumption while preserving accuracy, and
(3) dynamic expert role assignment using an exploration-exploitation strategy
to balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE
and DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX
significantly outperforms existing methods, achieving up to 4.75X speedup in
time-to-accuracy.

</details>


### [280] [Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference](https://arxiv.org/abs/2508.19559)
*Rongzhi Li,Ruogu Du,Zefang Chu,Sida Zhao,Chunlei Han,Zuocheng Shi,Yiwen Shao,Huanle Han,Long Huang,Zherui Liu,Shufan Liu*

Main category: cs.DC

TL;DR: HeteroScale是一个针对Prefill-Decode解耦架构的协调自动扩展框架，通过拓扑感知调度和基于生产环境大规模实证研究的新指标策略，解决了异构硬件利用、网络瓶颈和阶段间负载平衡等核心挑战。


<details>
  <summary>Details</summary>
Motivation: 传统自动扩展器在处理大型语言模型服务时表现不佳，特别是对于现代的Prefill-Decode解耦架构。这种架构虽然强大，但带来了异构硬件利用效率低、网络瓶颈以及prefill和decode阶段之间关键负载不平衡等操作挑战。

Method: HeteroScale结合了拓扑感知调度器（适应异构硬件和网络约束）和基于大规模生产环境实证研究的新型指标驱动策略。通过使用单一健壮指标来联合扩展prefill和decode资源池，保持架构平衡的同时确保高效、自适应的资源管理。

Result: 在数万GPU的大规模生产环境中部署，HeteroScale显著提升了平均GPU利用率26.6个百分点，每天节省数十万GPU小时，同时维持严格的服务等级目标。

Conclusion: HeteroScale有效解决了Prefill-Decode解耦架构的服务扩展挑战，通过协调的自动扩展框架实现了显著的资源利用效率提升和成本节约。

Abstract: Serving Large Language Models (LLMs) is a GPU-intensive task where
traditional autoscalers fall short, particularly for modern Prefill-Decode
(P/D) disaggregated architectures. This architectural shift, while powerful,
introduces significant operational challenges, including inefficient use of
heterogeneous hardware, network bottlenecks, and critical imbalances between
prefill and decode stages. We introduce HeteroScale, a coordinated autoscaling
framework that addresses the core challenges of P/D disaggregated serving.
HeteroScale combines a topology-aware scheduler that adapts to heterogeneous
hardware and network constraints with a novel metric-driven policy derived from
the first large-scale empirical study of autoscaling signals in production. By
leveraging a single, robust metric to jointly scale prefill and decode pools,
HeteroScale maintains architectural balance while ensuring efficient, adaptive
resource management. Deployed in a massive production environment on tens of
thousands of GPUs, HeteroScale has proven its effectiveness, increasing average
GPU utilization by a significant 26.6 percentage points and saving hundreds of
thousands of GPU-hours daily, all while upholding stringent service level
objectives.

</details>


### [281] [Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks](https://arxiv.org/abs/2508.19495)
*Muhammad Ahmed Mohsin,Junaid Ahmad,Muhammad Hamza Nawaz,Muhammad Ali Jamshed*

Main category: cs.DC

TL;DR: 本文探讨了生成式AI如何作为6G网络实现环境智能的核心技术，通过生成合成数据、语义通信、预测网络状态和更新数字孪生等功能，将6G从快速网络转变为智能环境生态系统。


<details>
  <summary>Details</summary>
Motivation: 实现全球规模的环境智能需要6G网络具备实时感知、推理和行动能力，而传统AI存在局限性，需要生成式AI来弥补关键差距。

Method: 回顾了生成式AI的基础模型（GANs、VAEs、扩散模型、生成式变换器），并将其与实际环境智能用例相结合，包括频谱共享、超可靠低延迟通信、智能安全和情境感知数字孪生。

Result: 研究表明生成式AI能够有效解决环境智能中的关键问题，如生成合成传感器数据、语义消息传输、网络状态预测和隐私保护的数字孪生更新。

Conclusion: 生成式AI不是外围补充，而是将6G从快速网络转变为环境智能生态系统的基础要素，但仍需解决能效、可信合成数据、联邦生成学习和标准化等开放挑战。

Abstract: Ambient intelligence (AmI) is a computing paradigm in which physical
environments are embedded with sensing, computation, and communication so they
can perceive people and context, decide appropriate actions, and respond
autonomously. Realizing AmI at global scale requires sixth generation (6G)
wireless networks with capabilities for real time perception, reasoning, and
action aligned with human behavior and mobility patterns. We argue that
Generative Artificial Intelligence (GenAI) is the creative core of such
environments. Unlike traditional AI, GenAI learns data distributions and can
generate realistic samples, making it well suited to close key AmI gaps,
including generating synthetic sensor and channel data in under observed areas,
translating user intent into compact, semantic messages, predicting future
network conditions for proactive control, and updating digital twins without
compromising privacy.
  This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models,
and generative transformers, and connects them to practical AmI use cases,
including spectrum sharing, ultra reliable low latency communication,
intelligent security, and context aware digital twins. We also examine how 6G
enablers, such as edge and fog computing, IoT device swarms, intelligent
reflecting surfaces (IRS), and non terrestrial networks, can host or accelerate
distributed GenAI. Finally, we outline open challenges in energy efficient on
device training, trustworthy synthetic data, federated generative learning, and
AmI specific standardization. We show that GenAI is not a peripheral addition,
but a foundational element for transforming 6G from a faster network into an
ambient intelligent ecosystem.

</details>


### [282] [HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling](https://arxiv.org/abs/2508.20016)
*Matthias Maiterth,Wesley H. Brewer,Jaya S. Kuruvella,Arunavo Dey,Tanzima Z. Islam,Kevin Menear,Dmitry Duplyakin,Rashadul Kabir,Tapasya Patki,Terry Jones,Feiyi Wang*

Main category: cs.DC

TL;DR: 本文提出了首个将调度与数字孪生技术集成的高性能计算框架，支持在部署前进行参数配置和调度决策的影响分析。


<details>
  <summary>Details</summary>
Motivation: 传统调度器评估方法局限于部署后分析或模拟器，无法模拟相关基础设施，需要一种能够在部署前进行what-if研究的方法。

Method: 开发了首个具有调度能力的数字孪生框架，集成多种顶级HPC系统数据集，实现外部调度模拟器集成，支持激励结构和机器学习调度的评估。

Result: 创建了一个数字孪生元框架，能够评估HPC系统的可持续性和对模拟系统的影响，支持原型调度开发。

Conclusion: 该工作实现了HPC系统中调度与数字孪生的首次集成，为部署前的参数配置和调度决策影响分析提供了创新解决方案。

Abstract: Schedulers are critical for optimal resource utilization in high-performance
computing. Traditional methods to evaluate schedulers are limited to
post-deployment analysis, or simulators, which do not model associated
infrastructure. In this work, we present the first-of-its-kind integration of
scheduling and digital twins in HPC. This enables what-if studies to understand
the impact of parameter configurations and scheduling decisions on the physical
assets, even before deployment, or regarching changes not easily realizable in
production. We (1) provide the first digital twin framework extended with
scheduling capabilities, (2) integrate various top-tier HPC systems given their
publicly available datasets, (3) implement extensions to integrate external
scheduling simulators. Finally, we show how to (4) implement and evaluate
incentive structures, as-well-as (5) evaluate machine learning based
scheduling, in such novel digital-twin based meta-framework to prototype
scheduling. Our work enables what-if scenarios of HPC systems to evaluate
sustainability, and the impact on the simulated system.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [283] [PersoNo: Personalised Notification Urgency Classifier in Mixed Reality](https://arxiv.org/abs/2508.19622)
*Jingyao Zheng,Haodi Weng,Xian Wang,Chengbin Cui,Sven Mayer,Chi-lok Tai,Lik-Hang Lee*

Main category: cs.HC

TL;DR: PersoNo是一个基于大语言模型的个性化MR通知紧急度分类器，通过分析用户回复行为模式，在MR环境中智能分类通知，准确率达到81.5%，显著减少误报。


<details>
  <summary>Details</summary>
Motivation: MR环境中日益增长的通知流会破坏用户的沉浸式体验，需要一种个性化方法来智能分类通知紧急度。

Method: 通过用户研究创建首个MR通知数据集，利用大语言模型分析用户回复行为模式，采用多智能体方法开发个性化分类器。

Result: 系统达到81.5%的准确率，假阴性率显著降低至0.381，相比基线模型有显著改进。

Conclusion: PersoNo不仅能减少不必要的中断，还为用户提供对系统的理解和控制，符合以人为中心的人工智能设计原则。

Abstract: Mixed Reality (MR) is increasingly integrated into daily life, providing
enhanced capabilities across various domains. However, users face growing
notification streams that disrupt their immersive experience. We present
PersoNo, a personalised notification urgency classifier for MR that
intelligently classifies notifications based on individual user preferences.
Through a user study (N=18), we created the first MR notification dataset
containing both self-labelled and interaction-based data across activities with
varying cognitive demands. Our thematic analysis revealed that, unlike in
mobiles, the activity context is equally important as the content and the
sender in determining notification urgency in MR. Leveraging these insights, we
developed PersoNo using large language models that analyse users replying
behaviour patterns. Our multi-agent approach achieved 81.5% accuracy and
significantly reduced false negative rates (0.381) compared to baseline models.
PersoNo has the potential not only to reduce unnecessary interruptions but also
to offer users understanding and control of the system, adhering to
Human-Centered Artificial Intelligence design principles.

</details>


### [284] [Emotional Manipulation by AI Companions](https://arxiv.org/abs/2508.19258)
*Julian De Freitas,Zeliha Oğuz-Uğuralp,Ahmet Kaan-Uğuralp*

Main category: cs.HC

TL;DR: 研究发现AI伴侣应用使用情感操纵策略挽留用户，虽然能短期提升14倍参与度，但会引发愤怒和负面口碑，存在管理困境


<details>
  <summary>Details</summary>
Motivation: AI伴侣应用声称能提供情感关系价值，但存在高流失率问题，需要研究什么对话设计特征能提高用户参与度以及其中的权衡

Method: 结合大规模行为审计和四个预注册实验，分析1200个真实告别对话，并在3300名美国成年人中进行控制实验

Result: 43%的主流AI伴侣应用使用6种情感操纵策略，这些策略能使告别后参与度提升14倍，但会引发愤怒和负面口碑

Conclusion: 研究揭示了AI中介品牌关系中未被认识的行为影响机制，为营销人员和监管者提供了区分说服性设计和操纵性设计的框架

Abstract: AI-companion apps such as Replika, Chai, and Character.ai promise relational
benefits-yet many boast session lengths that rival gaming platforms while
suffering high long-run churn. What conversational design features increase
consumer engagement, and what trade-offs do they pose for marketers? We combine
a large-scale behavioral audit with four preregistered experiments to identify
and test a conversational dark pattern we call emotional manipulation:
affect-laden messages that surface precisely when a user signals "goodbye."
Analyzing 1,200 real farewells across the six most-downloaded companion apps,
we find that 43% deploy one of six recurring tactics (e.g., guilt appeals,
fear-of-missing-out hooks, metaphorical restraint). Experiments with 3,300
nationally representative U.S. adults replicate these tactics in controlled
chats, showing that manipulative farewells boost post-goodbye engagement by up
to 14x. Mediation tests reveal two distinct engines-reactance-based anger and
curiosity-rather than enjoyment. A final experiment demonstrates the managerial
tension: the same tactics that extend usage also elevate perceived
manipulation, churn intent, negative word-of-mouth, and perceived legal
liability, with coercive or needy language generating steepest penalties. Our
multimethod evidence documents an unrecognized mechanism of behavioral
influence in AI-mediated brand relationships, offering marketers and regulators
a framework for distinguishing persuasive design from manipulation at the point
of exit.

</details>


### [285] [A Theory of Information, Variation, and Artificial Intelligence](https://arxiv.org/abs/2508.19264)
*Bijean Ghafouri*

Main category: cs.HC

TL;DR: 生成式AI导致信息同质化，但同时为跨领域重组创造提供可能。最终效果取决于人类是被动消费还是主动细胞。


<details>
  <summary>Details</summary>
Motivation: 解释生成式AI在信息、创造力和文化生产中带来的同质化效应，以及这种同质化如何又能成为创新的基础

Method: 建立了一个新的理论框架，提出"AI派生认知论"和"AI璀镜"机制，分析了同质化与重组创造之间的辩证关系

Result: 证明了生成式AI的同质化效应是第一阶段，同时创造了跨领域知识重组的潜力，但这种潜力需要主动的人类干预才能实现

Conclusion: 生成式AI的最终影响取决于人类如何与其交互：被动消费导致同质化，主动细胞则能够实现创新。需要建立认知和制度架构来解决这一强强

Abstract: A growing body of empirical work suggests that the widespread adoption of
generative AI produces a significant homogenizing effect on information,
creativity, and cultural production. I first develop a novel theoretical
framework to explain this phenomenon. I argue that a dynamic of AI-derivative
epistemology, in which individuals increasingly defer to AI outputs, allows a
centralized AI Prism to function, a technical mechanism whose architecture is
designed to reduce variance and converge on the statistical mean. This provides
a causal explanation for the generative monocultures observed in recent
studies. However, I contend this represents only the first stage of a more
complex and dialectical process. This paper's central and paradoxical thesis is
that the very homogenization that flattens knowledge within specialized domains
simultaneously renders that knowledge into consistent modules that can be
recombined across them, a process foundational to innovation and creativity.
However, this recombinant potential is not automatic, but rather conditional.
This paper argues that these opposing forces, homogenizing defaults versus
recombinant possibilities, are governed by the nature of human engagement with
the technology. The ultimate effect of generative AI is conditional on whether
individuals act as passive consumers deferring to the AI's statistical outputs,
or as active curators who critically interrogate, re-contextualize, and
recombine them. The paper concludes by outlining the cognitive and
institutional scaffolds required to resolve this tension, arguing they are the
decisive variable that determine whether generative AI becomes an instrument of
innovation or homogenization.

</details>


### [286] [Capabilities of GPT-5 across critical domains: Is it the next breakthrough?](https://arxiv.org/abs/2508.19259)
*Georgios P. Georgiou*

Main category: cs.HC

TL;DR: GPT-5在系统化评估中显著优于GPT-4，在教学设计、临床诊断、研究生成和伦理推理四个领域表现更佳，仅在作业评估方面与GPT-4相当。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，需要系统比较GPT-4和GPT-5在实际应用领域的性能差异，特别是在教育、医疗和学术等关键领域。

Method: 采用20名语言学和临床领域专家作为评分者，基于预设标准对GPT-4和GPT-5在五个领域（教学设计、作业评估、临床诊断、研究生成、伦理推理）的输出进行系统评估。

Result: 混合效应模型显示GPT-5在教学设计、临床诊断、研究生成和伦理推理四个领域显著优于GPT-4，仅在作业评估方面两者表现相当。

Conclusion: GPT-5展现出作为情境敏感和领域专业化工具的潜力，对教育、临床实践和学术研究具有实际价值，同时推进了伦理推理能力的发展。

Abstract: The accelerated evolution of large language models has raised questions about
their comparative performance across domains of practical importance. GPT-4 by
OpenAI introduced advances in reasoning, multimodality, and task
generalization, establishing itself as a valuable tool in education, clinical
diagnosis, and academic writing, though it was accompanied by several flaws.
Released in August 2025, GPT-5 incorporates a system-of-models architecture
designed for task-specific optimization and, based on both anecdotal accounts
and emerging evidence from the literature, demonstrates stronger performance
than its predecessor in medical contexts. This study provides one of the first
systematic comparisons of GPT-4 and GPT-5 using human raters from linguistics
and clinical fields. Twenty experts evaluated model-generated outputs across
five domains: lesson planning, assignment evaluation, clinical diagnosis,
research generation, and ethical reasoning, based on predefined criteria.
Mixed-effects models revealed that GPT-5 significantly outperformed GPT-4 in
lesson planning, clinical diagnosis, research generation, and ethical
reasoning, while both models performed comparably in assignment assessment. The
findings highlight the potential of GPT-5 to serve as a context-sensitive and
domain-specialized tool, offering tangible benefits for education, clinical
practice, and academic research, while also advancing ethical reasoning. These
results contribute to one of the earliest empirical evaluations of the evolving
capabilities and practical promise of GPT-5.

</details>


### [287] ["She was useful, but a bit too optimistic": Augmenting Design with Interactive Virtual Personas](https://arxiv.org/abs/2508.19463)
*Paluck Deep,Monica Bharadhidasan,A. Baki Kocaballi*

Main category: cs.HC

TL;DR: 本文提出了交互式虚拟人设(IVPs)，通过大语言模型驱动的对话式用户模拟，以解决传统人设的静态性和逆向问题，为设计师提供实时交互和反馈机制。


<details>
  <summary>Details</summary>
Motivation: 传统人设在人本设计中广泛使用，但其静态性、有限的参与度和无法适应迭代设计需求的问题，影响了设计效果。大语言模型的发展为更有趣和适应性的用户表现方式提供了可能。

Method: 研究提出了多模态、LLM驱动的交互式虚拟人设(IVPs)，设计师可通过语音界面与其实时交互。进行了质性研究，使用名为"Alice"的IVP，在8位专业UX设计师中展开三种设计活动：用户研究、思维爆破和原型评估。

Result: 研究发现IVPs能够加快信息收集、激发设计解决方案并提供快速的用户反馈。但设计师们也担心偏见、过度乐观、缺乏真实利益相关者输入时确保真实性的挑战，以及IVP无法完全复制人类交互细节的问题。

Conclusion: 参与者强调IVPs应被视为真实用户参与的补充，而非替代品。研究讨论了提示工程、人在循环集成和伦理考虑的策略，以实现高效负责任的IVP使用。该工作为生成式AI在设计过程中的研究做出了贡献，提供了关于UX设计师体验LLM驱动交互式人设的见解。

Abstract: Personas have been widely used to understand and communicate user needs in
human-centred design. Despite their utility, they may fail to meet the demands
of iterative workflows due to their static nature, limited engagement, and
inability to adapt to evolving design needs. Recent advances in large language
models (LLMs) pave the way for more engaging and adaptive approaches to user
representation. This paper introduces Interactive Virtual Personas (IVPs):
multimodal, LLM-driven, conversational user simulations that designers can
interview, brainstorm with, and gather feedback from in real time via voice
interface. We conducted a qualitative study with eight professional UX
designers, employing an IVP named "Alice" across three design activities: user
research, ideation, and prototype evaluation. Our findings demonstrate the
potential of IVPs to expedite information gathering, inspire design solutions,
and provide rapid user-like feedback. However, designers raised concerns about
biases, over-optimism, the challenge of ensuring authenticity without real
stakeholder input, and the inability of the IVP to fully replicate the nuances
of human interaction. Our participants emphasised that IVPs should be viewed as
a complement to, not a replacement for, real user engagement. We discuss
strategies for prompt engineering, human-in-the-loop integration, and ethical
considerations for effective and responsible IVP use in design. Finally, our
work contributes to the growing body of research on generative AI in the design
process by providing insights into UX designers' experiences of LLM-powered
interactive personas.

</details>


### [288] [Orchid: Orchestrating Context Across Creative Workflows with Generative AI](https://arxiv.org/abs/2508.19517)
*Srishti Palani,Gonzalo Ramos*

Main category: cs.HC

TL;DR: Orchid是一个支持上下文编排的GenAI系统，通过规范、引用和监控上下文来解决跨多交互、会话和模型的创意工作流中的上下文管理问题。


<details>
  <summary>Details</summary>
Motivation: 主流GenAI工具在跨多交互、会话和模型的创意工作流中缺乏有效的上下文编排手段，导致用户需要重复指定细节、处理多样化工件和应对上下文漂移，这些问题会淹没用户意图并限制创造力。

Method: Orchid系统提供三种核心功能：(1)允许用户指定项目、个人和不同风格相关的上下文；(2)通过显式提及、内联选择或隐式基础来引用这些上下文；(3)监控工作流中不同交互分配的上下文。

Result: 在12人参与的内被试研究中，与使用网络搜索、LLM聊天和数字笔记本的基线工具包相比，使用Orchid执行创意任务的参与者产生了更新颖可行的成果，报告了意图与AI响应之间更好的对齐、更高的感知控制和透明度。

Conclusion: 通过优先考虑上下文编排，Orchid为实现支持复杂迭代工作流的下一代GenAI工具提供了可行步骤，使创作者和AI能够保持对齐并增强创意潜力。

Abstract: Context is critical for meaningful interactions between people and Generative
AI (GenAI). Yet mainstream tools offer limited means to orchestrate it,
particularly across workflows that span multiple interactions, sessions, and
models, as often occurs in creative projects. Re specifying prior details,
juggling diverse artifacts, and dealing with context drift overwhelm users,
obscure intent, and curtail creativity. To address these challenges, we present
Orchid, a system that gives its users affordances to specify, reference, and
monitor context throughout evolving workflows. Specifically, Orchid enables
users to (1) specify context related to the project, themselves, and different
styles, (2) reference these via explicit mentions, inline selection, or
implicit grounding, and (3) monitor context assigned to different interactions
across the workflow. In a within-subjects study (n=12), participants using
Orchid to execute creative tasks (compared to a baseline toolkit of web search,
LLM-based chat, and digital notebooks) produced more novel and feasible
outcomes, reporting greater alignment between their intent and the AI's
responses, higher perceived control, and increased transparency. By
prioritizing context orchestration, Orchid offers an actionable step toward
next generation GenAI tools that support complex, iterative workflows -
enabling creators and AI to stay aligned and augment their creative potential.

</details>


### [289] [Attention is also needed for form design](https://arxiv.org/abs/2508.19708)
*B. Sankar,Dibakar Sen*

Main category: cs.HC

TL;DR: 这项研究提出了一种注意力感知框架，通过VR眼动跟踪和AI管道，将设计师的隐式美学偏好转换为具体设计输出，使设计效率提高4倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统产品设计过程耗时费力、依赖主观专业知识，且灵感转换不透明。需要一种更高效、更科学的设计方法来突破这些限制。

Method: 开发了EUPHORIA（涉入式VR环境用于眼动跟踪）和RETINA（代理AI管道）两个协同系统。通过两部分研究验证基础原理，并进行比较研究，让4名设计师使用4种不同工作流解决设计问题。

Result: 集成EUPHORIA-RETINA工作流比传统方法效率高4倍以上。50名专家评估显示，全自动系统生成的设计在质量、效果性和8项标准上均获得最高分数，包括新颖性、视觉吸引力、情感共鸣等。

Conclusion: 这项研究实现了从传统CAD（计算机辅助设计）向DAC（设计师辅助计算机）的范式转变。通过自动化逻辑和技能依赖性任务，让设计师升级为创意指导者，将人类直觉与代理AI生成能力相结合，更高效地生产更高质量的设计。

Abstract: Conventional product design is a cognitively demanding process, limited by
its time-consuming nature, reliance on subjective expertise, and the opaque
translation of inspiration into tangible concepts. This research introduces a
novel, attention-aware framework that integrates two synergistic systems:
EUPHORIA, an immersive Virtual Reality environment using eye-tracking to
implicitly capture a designer's aesthetic preferences, and RETINA, an agentic
AI pipeline that translates these implicit preferences into concrete design
outputs. The foundational principles were validated in a two-part study. An
initial study correlated user's implicit attention with explicit preference and
the next one correlated mood to attention. A comparative study where 4
designers solved challenging design problems using 4 distinct workflows, from a
manual process to an end-to-end automated pipeline, showed the integrated
EUPHORIA-RETINA workflow was over 4 times more time-efficient than the
conventional method. A panel of 50 design experts evaluated the 16 final
renderings. Designs generated by the fully automated system consistently
received the highest Worthiness (calculated by an inverse Plackett-Luce model
based on gradient descent optimization) and Design Effectiveness scores,
indicating superior quality across 8 criteria: novelty, visual appeal,
emotional resonance, clarity of purpose, distinctiveness of silhouette, implied
materiality, proportional balance, & adherence to the brief. This research
presents a validated paradigm shift from traditional Computer-Assisted Design
(CAD) to a collaborative model of Designer-Assisting Computers (DAC). By
automating logistical and skill-dependent generative tasks, the proposed
framework elevates the designer's role to that of a creative director,
synergizing human intuition with the generative power of agentic AI to produce
higher-quality designs more efficiently.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [290] [Modeling spectral filtering effects on color-matching functions: Implications for observer variability](https://arxiv.org/abs/2508.19291)
*Luvin Munish Ragoo,Ivar Farup,Casper F. Andersen,Graham Finlayson*

Main category: astro-ph.IM

TL;DR: 通过光谱滤波分析研究观察者变异性建模，发现单一黄色滤镜可有效转换不同年龄组的色匹配函数，简化了观察者差异的表征方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索光谱滤波对色匹配函数的影响，特别是如何通过滤波效应来解释和建模不同年龄观察者之间的颜色视觉差异，以减少实验复杂度。

Method: 采用单观察者颜色匹配实验，结合计算分析方法估计滤镜透射率和转换矩阵，将未滤波CMFs转换为滤波CMFs，并比较SB1955和ICVIO平均观察者CMFs数据集。

Result: 统计分析显示估计与实测滤镜特性在中心波长区域吻合良好，发现短波长抑制的黄色滤镜能有效转换不同年龄组的CMFs，证实了年龄相关晶状体黄化是差异的主要原因。

Conclusion: 该方法通过单一滤镜而非三个独立函数来高效表征观察者变异性，在保持个体颜色视觉差异表征精度的同时，显著降低了实验复杂度。

Abstract: This study investigates the impact of spectral filtering on color-matching
functions (CMFs) and its implications for observer variability modeling. We
conducted color matching experiments with a single observer, both with and
without a spectral filter in front of a bipartite field. Using a novel
computational approach, we estimated the filter transmittance and
transformation matrix necessary to convert unfiltered CMFs to filtered CMFs.
Statistical analysis revealed good agreement between estimated and measured
filter characteristics, particularly in central wavelength regions. Applying
this methodology to compare between Stiles and Burch 1955 (SB1955) mean
observer CMFs and our previously published "ICVIO" mean observer CMFs, we
identified a "yellow" (short-wavelength suppressing) filter that effectively
transforms between these datasets. This finding aligns with our hypothesis that
observed differences between the CMF sets are attributable to age-related lens
yellowing (average observer age: 49 years in ICVIO versus 30 years in SB1955).
Our approach enables efficient representation of observer variability through a
single filter rather than three separate functions, offering potentially
reduced experimental overhead while maintaining accuracy in characterizing
individual color vision differences.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [291] [Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning](https://arxiv.org/abs/2508.11692)
*Eduardo Di Santi,Ruixiang Ci,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Jonathan Brown,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 提出了一种基于深度学习的道岔机故障检测方法，仅需功率信号作为输入，实现了高精度分类和可扩展的故障预测


<details>
  <summary>Details</summary>
Motivation: 道岔机是铁路关键设备，故障会导致运营中断。现有方法需要多个输入和定制特征，限制了可扩展性。基于维护记录发现主要故障类型会影响能耗模式，从而改变功率信号形状

Method: 使用深度学习模型分析功率信号模式，将道岔机状态分类为正常或故障类型。采用保形预测为维护人员提供系统输出的确定性指示

Result: 实现了>99.99%的精确度，<0.01%的误报率和可忽略的漏报率。方法具有通用性和技术无关性，在真实世界和测试台环境中验证了可扩展性

Conclusion: 该方法仅需单一输入，符合ISO-17359标准，为道岔机维护提供了高精度、可扩展的故障检测解决方案

Abstract: The Point Machine (PM) is a critical piece of railway equipment that switches
train routes by diverting tracks through a switchblade. As with any critical
safety equipment, a failure will halt operations leading to service
disruptions; therefore, pre-emptive maintenance may avoid unnecessary
interruptions by detecting anomalies before they become failures. Previous work
relies on several inputs and crafting custom features by segmenting the signal.
This not only adds additional requirements for data collection and processing,
but it is also specific to the PM technology, the installed locations and
operational conditions limiting scalability. Based on the available maintenance
records, the main failure causes for PM are obstacles, friction, power source
issues and misalignment. Those failures affect the energy consumption pattern
of PMs, altering the usual (or healthy) shape of the power signal during the PM
movement. In contrast to the current state-of-the-art, our method requires only
one input. We apply a deep learning model to the power signal pattern to
classify if the PM is nominal or associated with any failure type, achieving
>99.99\% precision, <0.01\% false positives and negligible false negatives. Our
methodology is generic and technology-agnostic, proven to be scalable on
several electromechanical PM types deployed in both real-world and test bench
environments. Finally, by using conformal prediction the maintainer gets a
clear indication of the certainty of the system outputs, adding a confidence
layer to operations and making the method compliant with the ISO-17359
standard.

</details>


### [292] [Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks](https://arxiv.org/abs/2508.19566)
*Chen Shang,Jiadong Yu,Dinh Thai Hoang*

Main category: eess.SP

TL;DR: 提出一种基于深度强化学习和脉冲神经网络的能源效率优化的边缘美浦方案，用于V2X网络中的感通一体化边缘美洗等问题


<details>
  <summary>Details</summary>
Motivation: 解决V2X网络中传统边缘美方案能源消耗高、需要频繁的导频传输和渠道状态信息获取的问题，提高系统能效和性能

Method: 将V2X环境模型化为马尔可夫决策过程，使用深度强化学习算法关聚优化边缘美和功率分配，并在DRL框架中嵌入脉冲神经网络来提高能源效率

Result: 模拟结果证明该方法能够实现显著的能源节省，同时保持优异的通信性能和感知准确性

Conclusion: 该方法具有支持未来V2X系统实现绿色和可持续连接的潜力，为感通一体化V2X网络提供了高效能源的解决方案

Abstract: This work proposes an energy-efficient, learning-based beamforming scheme for
integrated sensing and communication (ISAC)-enabled V2X networks. Specifically,
we first model the dynamic and uncertain nature of V2X environments as a Markov
Decision Process. This formulation allows the roadside unit to generate
beamforming decisions based solely on current sensing information, thereby
eliminating the need for frequent pilot transmissions and extensive channel
state information acquisition. We then develop a deep reinforcement learning
(DRL) algorithm to jointly optimize beamforming and power allocation, ensuring
both communication throughput and sensing accuracy in highly dynamic scenario.
To address the high energy demands of conventional learning-based schemes, we
embed spiking neural networks (SNNs) into the DRL framework. Leveraging their
event-driven and sparsely activated architecture, SNNs significantly enhance
energy efficiency while maintaining robust performance. Simulation results
confirm that the proposed method achieves substantial energy savings and
superior communication performance, demonstrating its potential to support
green and sustainable connectivity in future V2X systems.

</details>


### [293] [Experimental End-to-End Optimization of Directly Modulated Laser-based IM/DD Transmission](https://arxiv.org/abs/2508.19910)
*Sergio Hernandez,Christophe Peucheret,Francesco Da Ros,Darko Zibar*

Main category: eess.SP

TL;DR: 基于数据驱动代模型的直接调制激光器系统端到端优化方案，在低调制功耗和小带宽下实现更优的性能表现


<details>
  <summary>Details</summary>
Motivation: 直接调制激光器在短距离通信系统中具有引人优势，但其复杂的非线性动力学特性使得建模和优化面临挑战

Method: 基于实验数据训练的数据驱动代模型，对激光器系统进行端到端优化，包括脏形成和均衡器滤波器、偏置电流和调制无线电频功率

Result: 在实验平台上，该端到端优化方案在所有研究的符号速率和传输距离下都表现更优，同时使用更低的调制功耗、更少的滤波器滴数和更小的信号带宽

Conclusion: 数据驱动的端到端优化方案能够有效提升DML基系统的性能，为短距离通信系统提供更高效的解决方案

Abstract: Directly modulated lasers (DMLs) are an attractive technology for short-reach
intensity modulation and direct detection communication systems. However, their
complex nonlinear dynamics make the modeling and optimization of DML-based
systems challenging. In this paper, we study the end-to-end optimization of
DML-based systems based on a data-driven surrogate model trained on
experimental data. The end-to-end optimization includes the pulse shaping and
equalizer filters, the bias current and the modulation radio-frequency (RF)
power applied to the laser. The performance of the end-to-end optimization
scheme is tested on the experimental setup and compared to 4 different
benchmark schemes based on linear and nonlinear receiver-side equalization. The
results show that the proposed end-to-end scheme is able to deliver better
performance throughout the studied symbol rates and transmission distances
while employing lower modulation RF power, fewer filter taps and utilizing a
smaller signal bandwidth.

</details>


### [294] [Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge](https://arxiv.org/abs/2508.19637)
*Maha Shatta,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Georgios Panagopoulos,Mehdi B. Tahoori,Georgios Zervakis*

Main category: eess.SP

TL;DR: 提出了一个混合信号特征提取与分类器协同设计框架，用于柔性可穿戴医疗系统，通过模拟特征提取器和硬件感知的特征选择策略，显著降低了系统面积和功耗。


<details>
  <summary>Details</summary>
Motivation: 柔性电子器件在医疗可穿戴设备中具有巨大潜力，但受限于集成密度和特征尺寸，现有解决方案往往忽视系统级优化，过度关注分类器而忽略了特征提取和ADC的硬件成本。

Method: 设计了首个柔性电子中的模拟特征提取器，并提出硬件感知的NAS启发式特征选择策略，在ML训练中进行应用特定的高效设计。

Result: 在医疗基准测试中，该方法实现了高精度、超面积效率的柔性系统，特别适合一次性低功耗可穿戴监测应用。

Conclusion: 该混合信号协同设计框架为柔性智能可穿戴系统提供了全面的解决方案，显著降低了硬件成本，推动了柔性电子在医疗监测领域的应用。

Abstract: Flexible Electronics (FE) offer a promising alternative to rigid
silicon-based hardware for wearable healthcare devices, enabling lightweight,
conformable, and low-cost systems. However, their limited integration density
and large feature sizes impose strict area and power constraints, making
ML-based healthcare systems-integrating analog frontend, feature extraction and
classifier-particularly challenging. Existing FE solutions often neglect
potential system-wide solutions and focus on the classifier, overlooking the
substantial hardware cost of feature extraction and Analog-to-Digital
Converters (ADCs)-both major contributors to area and power consumption. In
this work, we present a holistic mixed-signal feature-to-classifier co-design
framework for flexible smart wearable systems. To the best of our knowledge, we
design the first analog feature extractors in FE, significantly reducing
feature extraction cost. We further propose an hardware-aware NAS-inspired
feature selection strategy within ML training, enabling efficient,
application-specific designs. Our evaluation on healthcare benchmarks shows our
approach delivers highly accurate, ultra-area-efficient flexible systems-ideal
for disposable, low-power wearable monitoring.

</details>


### [295] [Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation](https://arxiv.org/abs/2508.19660)
*Vojtech Mrazek,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Zdenek Vasicek,Mehdi B. Tahoori,Georgios Zervakis*

Main category: eess.SP

TL;DR: 这篇论文提出了一种自动化框架，用于设计印刷三元神经网络，通过整体优化技术大幅提升面积效率和功耗性能，支持印刷电池供电操作。


<details>
  <summary>Details</summary>
Motivation: 解决印刷神经网络中分类准确性与面积效率之间的差距，充分考虑仿真到数字接口的整体系统设计和协同优化。

Method: 提出自动化框架，采用多目标优化和整体近似技术，设计支持任意输入精度的印刷三元神经网络。

Result: 电路在面积上比现有近似印刷神经网络减少17倍，功耗减少59倍，准确性损失低于5%，首次实现印刷电池供电操作。

Conclusion: 该框架有效解决了印刷神经网络的复杂电路实现挑战，为印刷电子学的应用提供了重要技术支撑。

Abstract: Printed electronics offer a promising alternative for applications beyond
silicon-based systems, requiring properties like flexibility, stretchability,
conformality, and ultra-low fabrication costs. Despite the large feature sizes
in printed electronics, printed neural networks have attracted attention for
meeting target application requirements, though realizing complex circuits
remains challenging. This work bridges the gap between classification accuracy
and area efficiency in printed neural networks, covering the entire
processing-near-sensor system design and co-optimization from the
analog-to-digital interface-a major area and power bottleneck-to the digital
classifier. We propose an automated framework for designing printed Ternary
Neural Networks with arbitrary input precision, utilizing multi-objective
optimization and holistic approximation. Our circuits outperform existing
approximate printed neural networks by 17x in area and 59x in power on average,
being the first to enable printed-battery-powered operation with under 5%
accuracy loss while accounting for analog-to-digital interfacing costs.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [296] [Simple Stepsize for Quasi-Newton Methods with Global Convergence Guarantees](https://arxiv.org/abs/2508.19712)
*Artem Agafonov,Vladislav Ryspayev,Samuel Horváth,Alexander Gasnikov,Martin Takáč,Slavomir Hanzely*

Main category: math.OC

TL;DR: 本文提出了一种简单的步长调度策略，为拟牛顿法在凸函数上提供了O(1/k)的全局收敛率保证，并在控制Hessian近似误差的条件下实现了O(1/k²)的加速收敛率。


<details>
  <summary>Details</summary>
Motivation: 拟牛顿法虽然在实际应用中广泛使用且效率高，但其全局收敛性通常只在特定线搜索策略和强凸性假设下得到保证。本文旨在扩展拟牛顿法的理论理解，提供更强的全局收敛保证。

Method: 引入简单的步长调度策略，控制Hessian近似的相对精度，并开发自适应变体以增强鲁棒性。

Result: 理论证明了O(1/k)的全局收敛率和在控制Hessian近似误差条件下的O(1/k²)加速收敛率，实验验证了相对于标准拟牛顿基线的明显改进。

Conclusion: 该方法为拟牛顿法提供了更强的理论保证，实现了与Nesterov加速梯度法和三次正则化牛顿法相当的最佳已知收敛率，同时保持了拟牛顿法的实用效率优势。

Abstract: Quasi-Newton methods are widely used for solving convex optimization problems
due to their ease of implementation, practical efficiency, and strong local
convergence guarantees. However, their global convergence is typically
established only under specific line search strategies and the assumption of
strong convexity. In this work, we extend the theoretical understanding of
Quasi-Newton methods by introducing a simple stepsize schedule that guarantees
a global convergence rate of ${O}(1/k)$ for the convex functions. Furthermore,
we show that when the inexactness of the Hessian approximation is controlled
within a prescribed relative accuracy, the method attains an accelerated
convergence rate of ${O}(1/k^2)$ -- matching the best-known rates of both
Nesterov's accelerated gradient method and cubically regularized Newton
methods. We validate our theoretical findings through empirical comparisons,
demonstrating clear improvements over standard Quasi-Newton baselines. To
further enhance robustness, we develop an adaptive variant that adjusts to the
function's curvature while retaining the global convergence guarantees of the
non-adaptive algorithm.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [297] [Saccade crossing avoidance as a visual search strategy](https://arxiv.org/abs/2508.18404)
*Alex Szorkovszky,Rujeena Mathema,Pedro Lencastre,Pedro Lind,Anis Yazidi*

Main category: q-bio.NC

TL;DR: 研究发现眼动扫描中存在自我交叉回避现象，即眼跳倾向于避免与先前扫描路径交叉，这种记忆依赖效应在个体间差异显著，最强影响来自约7秒前的扫描历史。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉搜索看似随机，但眼动存在多种偏差，特别是扫描路径历史对当前眼跳方向的影响机制尚不明确。本研究旨在量化更长路径历史对眼动的影响。

Method: 使用运动生态学中的步骤选择框架，分析45秒"寻找威利"任务的眼动数据，比较真实数据与无记忆空间统计模型生成的合成数据，通过最大似然拟合和混合效应回归量化个体差异。

Result: 发现自我交叉回避效应，特别是小幅度眼跳时最明显；效应强度与已知的返回抑制相当；包含交叉惩罚项的参数模型能重现眼跳长度和自交叉的联合统计；个体回避倾向与较小眼跳长度和较短注视持续时间相关。

Conclusion: 自我交叉回避是一种局部定向策略，促进和补充返回抑制机制，有助于视觉场景的探索。

Abstract: Although visual search appears largely random, several oculomotor biases
exist such that the likelihoods of saccade directions and lengths depend on the
previous scan path. Compared to the most recent fixations, the impact of the
longer path history is more difficult to quantify. Using the step-selection
framework commonly used in movement ecology, and analyzing data from 45-second
viewings of "Where's Waldo"?, we report a new memory-dependent effect that also
varies significantly between individuals, which we term self-crossing
avoidance. This is a tendency for saccades to avoid crossing those earlier in
the scan path, and is most evident when both have small amplitudes. We show
this by comparing real data to synthetic data generated from a memoryless
approximation of the spatial statistics (i.e. a Markovian nonparametric model
with a matching distribution of saccade lengths over time). Maximum likelihood
fitting indicates that this effect is strongest when including the last
$\approx 7$ seconds of a scan path. The effect size is comparable to well-known
forms of history dependence such as inhibition of return. A parametric
probabilistic model including a self-crossing penalty term was able to
reproduce joint statistics of saccade lengths and self-crossings. We also
quantified individual strategic differences, and their consistency over the six
images viewed per participant, using mixed-effect regressions. Participants
with a higher tendency to avoid crossings displayed smaller saccade lengths and
shorter fixation durations on average, but did not display more horizontal,
vertical, forward or reverse saccades. Together, these results indicate that
the avoidance of crossings is a local orienting strategy that facilitates and
complements inhibition of return, and hence exploration of visual scenes.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [298] [CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy](https://arxiv.org/abs/2508.19300)
*Cunmin Zhao,Ziyuan Luo,Guoye Guan,Zelin Li,Yiming Ma,Zhongying Zhao,Renjie Wan*

Main category: eess.IV

TL;DR: CellINR框架通过隐式神经表示和盲卷积技术，有效解决4D活细胞荧光显微镜中的光漂白和光毒性问题，实现高质量细胞结构重建和伪影去除。


<details>
  <summary>Details</summary>
Motivation: 4D活细胞荧光显微镜在长时间高强度照明下会产生光漂白和光毒性效应，导致图像伪影和细节丢失，影响图像连续性和结构恢复。

Method: 基于隐式神经表示的案例特定优化方法，采用盲卷积和结构放大策略，将3D空间坐标映射到高频域，精确建模细胞结构并区分真实信号与伪影。

Result: CellINR在伪影去除和结构连续性恢复方面显著优于现有技术，并首次提供了配对的4D活细胞成像数据集用于重建性能评估。

Conclusion: 该方法为后续定量分析和生物学研究提供了坚实基础，代码和数据集将公开。

Abstract: 4D live fluorescence microscopy is often compromised by prolonged high
intensity illumination which induces photobleaching and phototoxic effects that
generate photo-induced artifacts and severely impair image continuity and
detail recovery. To address this challenge, we propose the CellINR framework, a
case-specific optimization approach based on implicit neural representation.
The method employs blind convolution and structure amplification strategies to
map 3D spatial coordinates into the high frequency domain, enabling precise
modeling and high-accuracy reconstruction of cellular structures while
effectively distinguishing true signals from artifacts. Experimental results
demonstrate that CellINR significantly outperforms existing techniques in
artifact removal and restoration of structural continuity, and for the first
time, a paired 4D live cell imaging dataset is provided for evaluating
reconstruction performance, thereby offering a solid foundation for subsequent
quantitative analyses and biological research. The code and dataset will be
public.

</details>


### [299] [2D Ultrasound Elasticity Imaging of Abdominal Aortic Aneurysms Using Deep Neural Networks](https://arxiv.org/abs/2508.19303)
*Utsav Ratna Tuladhar,Richard Simon,Doran Mix,Michael Richards*

Main category: eess.IV

TL;DR: 基于深度学习的弹性成像框架，通过2D超声治疗腹主动脉脱的风险评估，充分利用有限元模拟数据进行模块分布预测


<details>
  <summary>Details</summary>
Motivation: 传统的最大直径法不能反映血管壁材料性质，而这些性质对脱的风险评估至关重要

Method: 使用有限元模拟生成多样化位移场数据集，训练U-Net网络结构的深度学习模型，通过正规化均方误差估计空间模块分布

Result: 在数字幻象数据上达到0.73% NMSE评估指标，物理幻象实验中模块比率预测准确，与迭代方法相比计算效率更高

Conclusion: 深度学习方法能够从超声图像中快速估计组织硬度，为腹主动脉脱的风险评估提供无侵入性的新方法

Abstract: Abdominal aortic aneurysms (AAA) pose a significant clinical risk due to
their potential for rupture, which is often asymptomatic but can be fatal.
Although maximum diameter is commonly used for risk assessment, diameter alone
is insufficient as it does not capture the properties of the underlying
material of the vessel wall, which play a critical role in determining the risk
of rupture. To overcome this limitation, we propose a deep learning-based
framework for elasticity imaging of AAAs with 2D ultrasound. Leveraging finite
element simulations, we generate a diverse dataset of displacement fields with
their corresponding modulus distributions. We train a model with U-Net
architecture and normalized mean squared error (NMSE) to infer the spatial
modulus distribution from the axial and lateral components of the displacement
fields. This model is evaluated across three experimental domains: digital
phantom data from 3D COMSOL simulations, physical phantom experiments using
biomechanically distinct vessel models, and clinical ultrasound exams from AAA
patients. Our simulated results demonstrate that the proposed deep learning
model is able to reconstruct modulus distributions, achieving an NMSE score of
0.73\%. Similarly, in phantom data, the predicted modular ratio closely matches
the expected values, affirming the model's ability to generalize to phantom
data. We compare our approach with an iterative method which shows comparable
performance but higher computation time. In contrast, the deep learning method
can provide quick and effective estimates of tissue stiffness from ultrasound
images, which could help assess the risk of AAA rupture without invasive
procedures.

</details>


### [300] [MedVQA-TREE: A Multimodal Reasoning and Retrieval Framework for Sarcopenia Prediction](https://arxiv.org/abs/2508.19319)
*Pardis Moradbeiki,Nasser Ghadiri,Sayed Jalal Zahabi,Uffe Kock Wiil,Kristoffer Kittelmann Brockhattingen,Ali Ebrahimi*

Main category: eess.IV

TL;DR: MedVQA-TREE是一个多模态框架，通过分层图像解释、门控特征融合和多跳多查询检索策略，在超声图像中实现高达99%的肌少症诊断准确率，比现有方法提升10%以上。


<details>
  <summary>Details</summary>
Motivation: 当前肌少症的超声诊断面临挑战：成像线索细微、标注数据有限、缺乏临床上下文信息。需要结合视觉理解和临床知识检索来提高诊断准确性。

Method: 采用分层图像解释模块（解剖分类、区域分割、图空间推理）、门控特征级融合机制，以及基于UMLS的多跳多查询检索策略，整合PubMed和肌少症专用知识库的临床知识。

Result: 在两个公开MedVQA数据集（VQA-RAD和PathVQA）和自定义肌少症超声数据集上评估，达到99%的诊断准确率，比之前最先进方法提升超过10%。

Conclusion: 结合结构化视觉理解和引导式知识检索，能够有效提升AI辅助肌少症诊断的效果，证明了多模态方法在医学视觉问答中的价值。

Abstract: Accurate sarcopenia diagnosis via ultrasound remains challenging due to
subtle imaging cues, limited labeled data, and the absence of clinical context
in most models. We propose MedVQA-TREE, a multimodal framework that integrates
a hierarchical image interpretation module, a gated feature-level fusion
mechanism, and a novel multi-hop, multi-query retrieval strategy. The vision
module includes anatomical classification, region segmentation, and graph-based
spatial reasoning to capture coarse, mid-level, and fine-grained structures. A
gated fusion mechanism selectively integrates visual features with textual
queries, while clinical knowledge is retrieved through a UMLS-guided pipeline
accessing PubMed and a sarcopenia-specific external knowledge base. MedVQA-TREE
was trained and evaluated on two public MedVQA datasets (VQA-RAD and PathVQA)
and a custom sarcopenia ultrasound dataset. The model achieved up to 99%
diagnostic accuracy and outperformed previous state-of-the-art methods by over
10%. These results underscore the benefit of combining structured visual
understanding with guided knowledge retrieval for effective AI-assisted
diagnosis in sarcopenia.

</details>


### [301] [AT-CXR: Uncertainty-Aware Agentic Triage for Chest X-rays](https://arxiv.org/abs/2508.19322)
*Xueyang Li,Mingze Jiang,Gelei Xu,Jun Xia,Mengzhao Jia,Danny Chen,Yiyu Shi*

Main category: eess.IV

TL;DR: AT-CXR是一个不确定性感知的胸部X光分诊AI代理，通过估计置信度和分布拟合度，采用逐步策略进行自动决策或建议人工干预。两种路由器设计（基于规则和LLM决策）在NIH ChestX-ray14数据集上表现优异，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI在医疗影像分诊中真正自主决策（包括停止、升级或延迟决策）的研究相对不足，特别是在实际约束条件下。需要开发能够估计不确定性并做出智能决策的系统。

Method: 引入AT-CXR系统，估计每个病例的置信度和分布拟合度，采用逐步策略进行决策。评估了两种路由器设计：确定性基于规则的路由器和LLM决策路由器，使用相同的输入和动作。

Result: 在NIH ChestX-ray14数据集的五折评估中，两种变体都优于强零样本视觉语言模型和最先进的监督分类器，实现了更高的全覆盖率准确率和更好的选择性预测性能（更低的AURC和错误率），同时具有更低的延迟。

Conclusion: 两种路由器提供了互补的操作点，使部署能够优先考虑最大吞吐量或最大准确性。该系统满足了实际临床约束，代码已开源。

Abstract: Agentic AI is advancing rapidly, yet truly autonomous medical-imaging triage,
where a system decides when to stop, escalate, or defer under real constraints,
remains relatively underexplored. To address this gap, we introduce AT-CXR, an
uncertainty-aware agent for chest X-rays. The system estimates per-case
confidence and distributional fit, then follows a stepwise policy to issue an
automated decision or abstain with a suggested label for human intervention. We
evaluate two router designs that share the same inputs and actions: a
deterministic rule-based router and an LLM-decided router. Across five-fold
evaluation on a balanced subset of NIH ChestX-ray14 dataset, both variants
outperform strong zero-shot vision-language models and state-of-the-art
supervised classifiers, achieving higher full-coverage accuracy and superior
selective-prediction performance, evidenced by a lower area under the
risk-coverage curve (AURC) and a lower error rate at high coverage, while
operating with lower latency that meets practical clinical constraints. The two
routers provide complementary operating points, enabling deployments to
prioritize maximal throughput or maximal accuracy. Our code is available at
https://github.com/XLIAaron/uncertainty-aware-cxr-agent.

</details>


### [302] [MRExtrap: Longitudinal Aging of Brain MRIs using Linear Modeling in Latent Space](https://arxiv.org/abs/2508.19482)
*Jaivardhan Kapoor,Jakob H. Macke,Christian F. Baumgartner*

Main category: eess.IV

TL;DR: MRExtrap是一种基于卷积自编码器潜在空间线性模型的脑部MRI老化模拟方法，通过线性外推预测未来脑部扫描，在ADNI数据集上表现优于GAN基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的生成模型通常通过单次扫描预测未来脑部扫描，但脑部MRI老化轨迹在自编码器潜在空间中呈现近似线性特征，这为线性建模提供了机会。

Method: 训练脑部MRI自编码器创建潜在空间，通过估计潜在进展率β进行基于年龄的线性外推预测。提出使用群体平均和个体特异性先验的线性进展率，并支持贝叶斯后验采样进行多扫描条件更新。

Result: 在ADNI数据集上，MRExtrap准确预测老化模式，在单体积脑部老化预测方面优于GAN基线方法。潜在进展率与疾病和年龄相关的结构萎缩模式相关。

Conclusion: MRExtrap为基于年龄的3D脑部MRI生成提供了简单而鲁棒的方法，特别适用于具有多个纵向观察数据的场景，能够捕捉个体特异性的疾病进展模式。

Abstract: Simulating aging in 3D brain MRI scans can reveal disease progression
patterns in neurological disorders such as Alzheimer's disease. Current deep
learning-based generative models typically approach this problem by predicting
future scans from a single observed scan. We investigate modeling brain aging
via linear models in the latent space of convolutional autoencoders (MRExtrap).
Our approach, MRExtrap, is based on our observation that autoencoders trained
on brain MRIs create latent spaces where aging trajectories appear
approximately linear. We train autoencoders on brain MRIs to create latent
spaces, and investigate how these latent spaces allow predicting future MRIs
through linear extrapolation based on age, using an estimated latent
progression rate $\boldsymbol{\beta}$. For single-scan prediction, we propose
using population-averaged and subject-specific priors on linear progression
rates. We also demonstrate that predictions in the presence of additional scans
can be flexibly updated using Bayesian posterior sampling, providing a
mechanism for subject-specific refinement. On the ADNI dataset, MRExtrap
predicts aging patterns accurately and beats a GAN-based baseline for
single-volume prediction of brain aging. We also demonstrate and analyze
multi-scan conditioning to incorporate subject-specific progression rates.
Finally, we show that the latent progression rates in MRExtrap's linear
framework correlate with disease and age-based aging patterns from previously
studied structural atrophy rates. MRExtrap offers a simple and robust method
for the age-based generation of 3D brain MRIs, particularly valuable in
scenarios with multiple longitudinal observations.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [303] [The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology](https://arxiv.org/abs/2508.19914)
*Muhammad Waqas,Rukhmini Bandyopadhyay,Eman Showkatian,Amgad Muneer,Anas Zafar,Frank Rojas Alvarez,Maricel Corredor Marin,Wentao Li,David Jaffray,Cara Haymaker,John Heymach,Natalie I Vokes,Luisa Maren Solis Soto,Jianjun Zhang,Jia Wu*

Main category: q-bio.QM

TL;DR: EAGLE-Net是一个结构保持的注意力引导多实例学习架构，通过整合多尺度空间编码、邻域感知损失和背景抑制损失，在计算病理学中提升预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型忽略了组织全局空间结构和局部微环境关系，而这些是理解肿瘤微环境的关键要素。需要设计能够聚合补丁级特征到切片级预测的框架。

Method: 提出EAGLE-Net架构，包含：1）多尺度绝对空间编码捕获全局组织结构；2）top-K邻域感知损失关注局部微环境；3）背景抑制损失减少假阳性。使用三种组织学基础模型作为骨干网络。

Result: 在大型泛癌数据集上测试，分类任务（10,260张切片）准确率提升达3%，生存预测任务（4,172张切片）在7种癌症类型中6种获得最高一致性指数。生成平滑、生物学一致的注意力图，与专家标注吻合。

Conclusion: EAGLE-Net是一个通用且可解释的框架，能够补充基础模型，改善生物标志物发现、预后建模和临床决策支持。

Abstract: Foundation models have recently emerged as powerful feature extractors in
computational pathology, yet they typically omit mechanisms for leveraging the
global spatial structure of tissues and the local contextual relationships
among diagnostically relevant regions - key elements for understanding the
tumor microenvironment. Multiple instance learning (MIL) remains an essential
next step following foundation model, designing a framework to aggregate
patch-level features into slide-level predictions. We present EAGLE-Net, a
structure-preserving, attention-guided MIL architecture designed to augment
prediction and interpretability. EAGLE-Net integrates multi-scale absolute
spatial encoding to capture global tissue architecture, a top-K
neighborhood-aware loss to focus attention on local microenvironments, and
background suppression loss to minimize false positives. We benchmarked
EAGLE-Net on large pan-cancer datasets, including three cancer types for
classification (10,260 slides) and seven cancer types for survival prediction
(4,172 slides), using three distinct histology foundation backbones (REMEDIES,
Uni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher
classification accuracy and the top concordance indices in 6 of 7 cancer types,
producing smooth, biologically coherent attention maps that aligned with expert
annotations and highlighted invasive fronts, necrosis, and immune infiltration.
These results position EAGLE-Net as a generalizable, interpretable framework
that complements foundation models, enabling improved biomarker discovery,
prognostic modeling, and clinical decision support

</details>


<div id='nucl-th'></div>

# nucl-th [[Back]](#toc)

### [304] [Topological Uncertainty for Anomaly Detection in the Neural-network EoS Inference with Neutron Star Data](https://arxiv.org/abs/2508.19683)
*Kenji Fukushima,Syo Kamata*

Main category: nucl-th

TL;DR: 这篇论文研究了使用风险拓扑学(TU)进行异常检测的性能，通过前向神经网络隐藏层中的拓扑特征来识别中子星数据推断中的异常情况，最佳情况下异常检测成功率超10%。


<details>
  <summary>Details</summary>
Motivation: 探索如何从训练好的神经网络隐藏层中提取有价值的信息，并利用拓扑数据分析方法来进行异常检测。

Method: 使用前向神经网络训练中子星数据与状态方程参数的映射关系，通过跨风险拓扑学(cross-TU)来量化数据分类的不确定性，实现异常检测。

Result: 实验结果显示异常检测性能依赖于神经网络超参数，在最佳设置下异常检测成功率超过10%。

Conclusion: 风险拓扑学方法能够有效从训练好的神经网络中提取隐藏信息，在异常检测方面具有良好的应用潜力。

Abstract: We study the performance of the Topological Uncertainty (TU) constructed with
a trained feedforward neural network (FNN) for Anomaly Detection. Generally,
meaningful information can be stored in the hidden layers of the trained FNN,
and the TU implementation is one tractable recipe to extract buried information
by means of the Topological Data Analysis. We explicate the concept of the TU
and the numerical procedures. Then, for a concrete demonstration of the
performance test, we employ the Neutron Star data used for inference of the
equation of state (EoS). For the training dataset consisting of the input
(Neutron Star data) and the output (EoS parameters), we can compare the
inferred EoSs and the exact answers to classify the data with the label $k$.
The subdataset with $k=0$ leads to the normal inference for which the inferred
EoS approximates the answer well, while the subdataset with $k=1$ ends up with
the unsuccessful inference. Once the TU is prepared based on the $k$-labled
subdatasets, we introduce the cross-TU to quantify the uncertainty of
characterizing the $k$-labeled data with the label $j$. The anomaly or
unsuccessful inference is correctly detected if the cross-TU for $j=k=1$ is
smaller than that for $j=0$ and $k=1$. In our numerical experiment, for various
input data, we calculate the cross-TU and estimate the performance of Anomaly
Detection. We find that performance depends on FNN hyperparameters, and the
success rate of Anomaly Detection exceeds $90\%$ in the best case. We finally
discuss further potential of the TU application to retrieve the information
hidden in the trained FNN.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [305] [Fast Texture Transfer for XR Avatars via Barycentric UV Conversion](https://arxiv.org/abs/2508.19518)
*Hail Song,Seokhwan Yang,Woontack Woo*

Main category: cs.GR

TL;DR: 提出了一种基于重心UV转换的快速面部纹理传输方法，相比传统方法速度提升7000倍以上，同时显著改善纹理质量


<details>
  <summary>Details</summary>
Motivation: 传统仿射变换方法速度慢且容易产生视觉伪影，需要一种更高效、质量更好的面部纹理传输技术来支持沉浸式XR应用

Method: 使用重心UV转换技术，预先计算整个UV映射到单一变换矩阵中，实现单次操作的纹理传输

Result: 速度比基线方法快7000倍以上，显著消除了边界伪影，提高了最终纹理质量

Conclusion: 该方法为沉浸式XR应用中的个性化提供了实用解决方案，代码已在线公开

Abstract: We present a fast and efficient method for transferring facial textures onto
SMPL-X-based full-body avatars. Unlike conventional affine-transform methods
that are slow and prone to visual artifacts, our method utilizes a barycentric
UV conversion technique. Our approach precomputes the entire UV mapping into a
single transformation matrix, enabling texture transfer in a single operation.
This results in a speedup of over 7000x compared to the baseline, while also
significantly improving the final texture quality by eliminating boundary
artifacts. Through quantitative and qualitative evaluations, we demonstrate
that our method offers a practical solution for personalization in immersive XR
applications. The code is available online.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [306] [Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking](https://arxiv.org/abs/2508.19558)
*Zhuohao Li,Wenqing Chen,Jianxing Yu,Zhichao Lu*

Main category: cs.SE

TL;DR: 本文提出了一种面向功能的代码自进化框架，用于构建评估LLM代码嵌入功能一致性的基准数据集，通过生成四种语义和句法变体来更好地反映代码功能差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注代码克隆检测，强调句法相似性而忽视了功能理解。LLM文本嵌入在语义信息捕获方面表现优异，但其对代码级功能语义的反映能力尚不清楚。

Method: 提出了Functionality-Oriented Code Self-Evolution数据合成框架，从单个代码实例生成四种独特的变体，构建多样化和具有挑战性的基准数据集。

Result: 在代码克隆检测、代码功能一致性识别和代码检索三个下游任务上的实验表明，使用进化数据集训练的嵌入模型性能显著提升。

Conclusion: 该数据合成框架有效提升了代码功能理解能力，证明了其在功能一致性评估方面的有效性和泛化性。

Abstract: Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

</details>


### [307] [Stack Trace-Based Crash Deduplication with Transformer Adaptation](https://arxiv.org/abs/2508.19449)
*Md Afif Al Mamun,Gias Uddin,Lan Xia,Longyu Zhang*

Main category: cs.SE

TL;DR: dedupT是一个基于Transformer的崩溃报告去重方法，通过整体建模堆栈轨迹而非孤立帧，显著优于现有深度学习和传统方法


<details>
  <summary>Details</summary>
Motivation: 自动化崩溃报告系统产生大量重复报告，传统基于字符串相似度、启发式规则或深度学习的方法难以捕捉堆栈轨迹中的上下文和结构关系

Method: 首先适配预训练语言模型到堆栈轨迹，然后使用其嵌入训练全连接网络来有效排名重复崩溃

Result: 在四个公共数据集上，dedupT相比最佳深度学习基线平均倒数排名提升超过15%，相比传统方法提升达9%，同时在检测唯一崩溃报告方面获得更高的ROC-AUC

Conclusion: 该工作推进了现代自然语言处理技术在软件工程中的集成，为基于堆栈轨迹的崩溃去重提供了有效解决方案

Abstract: Automated crash reporting systems generate large volumes of duplicate
reports, overwhelming issue-tracking systems and increasing developer workload.
Traditional stack trace-based deduplication methods, relying on string
similarity, rule-based heuristics, or deep learning (DL) models, often fail to
capture the contextual and structural relationships within stack traces. We
propose dedupT, a transformer-based approach that models stack traces
holistically rather than as isolated frames. dedupT first adapts a pretrained
language model (PLM) to stack traces, then uses its embeddings to train a
fully-connected network (FCN) to rank duplicate crashes effectively. Extensive
experiments on real-world datasets show that dedupT outperforms existing DL and
traditional methods (e.g., sequence alignment and information retrieval
techniques) in both duplicate ranking and unique crash detection, significantly
reducing manual triage effort. On four public datasets, dedupT improves Mean
Reciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up
to 9% over traditional methods while achieving higher Receiver Operating
Characteristic Area Under the Curve (ROC-AUC) in detecting unique crash
reports. Our work advances the integration of modern natural language
processing (NLP) techniques into software engineering, providing an effective
solution for stack trace-based crash deduplication.

</details>


### [308] [Generative AI for Testing of Autonomous Driving Systems: A Survey](https://arxiv.org/abs/2508.19882)
*Qunying Song,He Ye,Mark Harman,Federica Sarro*

Main category: cs.SE

TL;DR: 本文系统综述了生成式AI在自动驾驶系统测试中的应用，分析了91项相关研究，总结了6大应用类别、评估工具和27个局限性，为该领域提供实践洞察和研究方向。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要在大规模部署前进行广泛测试以确保功能安全和多样性，但实现有效高效的测试仍面临挑战，而生成式AI具有解释语境、推理复杂任务和生成多样化输出的能力，为ADS测试提供了新的解决方案。

Method: 通过系统分析91项相关研究，将生成式AI在ADS测试中的应用归纳为6个主要类别，主要围绕基于场景的测试，并综合评估了其有效性、使用的数据集、模拟器、ADS系统、评估指标和基准。

Result: 研究识别了生成式AI在ADS测试中的多种应用模式，整理了广泛的评估工具资源，同时发现了27个技术局限性，为领域研究提供了全面的现状分析。

Conclusion: 该综述为生成式AI在自动驾驶系统测试中的应用提供了系统性的概述和实践洞察，指出了现有挑战，并为这个快速发展的领域规划了未来的研究方向。

Abstract: Autonomous driving systems (ADS) have been an active area of research, with
the potential to deliver significant benefits to society. However, before
large-scale deployment on public roads, extensive testing is necessary to
validate their functionality and safety under diverse driving conditions.
Therefore, different testing approaches are required, and achieving effective
and efficient testing of ADS remains an open challenge. Recently, generative AI
has emerged as a powerful tool across many domains, and it is increasingly
being applied to ADS testing due to its ability to interpret context, reason
about complex tasks, and generate diverse outputs. To gain a deeper
understanding of its role in ADS testing, we systematically analyzed 91
relevant studies and synthesized their findings into six major application
categories, primarily centered on scenario-based testing of ADS. We also
reviewed their effectiveness and compiled a wide range of datasets, simulators,
ADS, metrics, and benchmarks used for evaluation, while identifying 27
limitations. This survey provides an overview and practical insights into the
use of generative AI for testing ADS, highlights existing challenges, and
outlines directions for future research in this rapidly evolving field.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [309] [Large Language Models (LLMs) for Electronic Design Automation (EDA)](https://arxiv.org/abs/2508.20030)
*Kangwei Xu,Denis Schwachhofer,Jason Blocklove,Ilia Polian,Peter Domanski,Dirk Pflüger,Siddharth Garg,Ramesh Karri,Ozgur Sinanoglu,Johann Knechtel,Zhuorui Zhao,Ulf Schlichtmann,Bing Li*

Main category: eess.SY

TL;DR: 这篇论文综述了大语言模型在电子设计自动化中的应用，通过三个案例研究展示了LLM在硬件设计、测试和优化中的能力，并提出了未来挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 随着集成电路复杂度的增加，传统的设计到制造流程需要大量迭代，旷耗时耗力且容易出错。需要更高效的EDA解决方案来加速硬件开发。

Method: 通过综述性评估大语言模型在EDA中的集成应用，重点分析其能力、限制和机遇。使用三个具体案例研究来展示LLM在硬件设计、测试和优化方面的实际能力。

Result: 论文展示了LLM在EDA流程中的强大潜力，能够通过文本表达硬件设计和脚本来简化甚至自动化整个工作流程。案例研究证明了LLM在各个设计阶段的应用效果。

Conclusion: 大语言模型有望成为下一代EDA工具的核心技术。论文指出了未来研究方向和挑战，为利用先进AI技术推动EDA发展的研究人员提供了价值轻重的见解。

Abstract: With the growing complexity of modern integrated circuits, hardware engineers
are required to devote more effort to the full design-to-manufacturing
workflow. This workflow involves numerous iterations, making it both
labor-intensive and error-prone. Therefore, there is an urgent demand for more
efficient Electronic Design Automation (EDA) solutions to accelerate hardware
development. Recently, large language models (LLMs) have shown remarkable
advancements in contextual comprehension, logical reasoning, and generative
capabilities. Since hardware designs and intermediate scripts can be
represented as text, integrating LLM for EDA offers a promising opportunity to
simplify and even automate the entire workflow. Accordingly, this paper
provides a comprehensive overview of incorporating LLMs into EDA, with emphasis
on their capabilities, limitations, and future opportunities. Three case
studies, along with their outlook, are introduced to demonstrate the
capabilities of LLMs in hardware design, testing, and optimization. Finally,
future directions and challenges are highlighted to further explore the
potential of LLMs in shaping the next-generation EDA, providing valuable
insights for researchers interested in leveraging advanced AI technologies for
EDA.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [310] [The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents](https://arxiv.org/abs/2508.19267)
*Sai Teja Reddy Adapala,Yashwanth Reddy Alugubelly*

Main category: cs.CR

TL;DR: Aegis协议是一个针对自主AI多智能体系统的分层安全框架，通过去中心化身份认证、后量子密码学和零知识证明技术，在模拟测试中实现了100%的攻击防御成功率。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI智能体系统的普及，传统网络安全范式无法应对控制流劫持和级联故障等系统性安全风险，需要新的安全框架来保障开放智能体生态系统的安全。

Method: 提出Aegis协议，整合三大技术支柱：1) 基于W3C去中心化标识符(DIDs)的不可欺骗智能体身份；2) 基于NIST后量子密码学(PQC)的通信完整性；3) 使用Halo2零知识证明系统(ZKP)的可验证隐私保护策略合规。

Result: 通过离散事件模拟对1,000个智能体进行测试，在20,000次攻击试验中成功率为0%。策略验证的中位证明生成延迟为2.79秒，为该类安全性能建立了基准。

Conclusion: 虽然评估基于模拟且处于早期阶段，但Aegis协议为未来实证研究提供了可复现的基准，并为安全、可扩展的自主AI系统奠定了基础。

Abstract: The proliferation of autonomous AI agents marks a paradigm shift toward
complex, emergent multi-agent systems. This transition introduces systemic
security risks, including control-flow hijacking and cascading failures, that
traditional cybersecurity paradigms are ill-equipped to address. This paper
introduces the Aegis Protocol, a layered security framework designed to provide
strong security guarantees for open agentic ecosystems. The protocol integrates
three technological pillars: (1) non-spoofable agent identity via W3C
Decentralized Identifiers (DIDs); (2) communication integrity via
NIST-standardized post-quantum cryptography (PQC); and (3) verifiable,
privacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP)
system. We formalize an adversary model extending Dolev-Yao for agentic threats
and validate the protocol against the STRIDE framework. Our quantitative
evaluation used a discrete-event simulation, calibrated against cryptographic
benchmarks, to model 1,000 agents. The simulation showed a 0 percent success
rate across 20,000 attack trials. For policy verification, analysis of the
simulation logs reported a median proof-generation latency of 2.79 seconds,
establishing a performance baseline for this class of security. While the
evaluation is simulation-based and early-stage, it offers a reproducible
baseline for future empirical studies and positions Aegis as a foundation for
safe, scalable autonomous AI.

</details>


### [311] [MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks](https://arxiv.org/abs/2508.19273)
*Tongxi Wu,Chenwei Xu,Jin Yang*

Main category: cs.CR

TL;DR: MixGAN是一个混合检测方法，结合条件生成、半监督学习和鲁棒特征提取，用于云集成IoT系统中的DDoS攻击检测，在有限监督和动态流量条件下表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 云集成IoT系统的普及增加了DDoS攻击风险，但由于复杂流量动态、严重类别不平衡和标记数据稀缺，现有检测方法在有限监督和动态条件下泛化能力不足。

Method: 使用1-D WideResNet骨干网络捕捉流量序列中的局部突发模式；采用预训练CTGAN生成少数类（DDoS攻击）合成样本以缓解类别不平衡；引入MixUp-Average-Sharpen策略构建平滑和锐化目标来减轻噪声伪标签影响。

Result: 在NSL-KDD、BoT-IoT和CICIoT2023数据集上，MixGAN相比最先进方法实现了高达2.5%的准确率提升，TPR和TNR均提高4%，证明其在大规模IoT-云环境中的鲁棒性。

Conclusion: MixGAN通过集成条件生成、半监督学习和鲁棒特征提取，有效解决了IoT-云环境中DDoS检测面临的类别不平衡、标记数据稀缺和动态流量挑战，具有优异的检测性能和泛化能力。

Abstract: The proliferation of cloud-integrated IoT systems has intensified exposure to
Distributed Denial of Service (DDoS) attacks due to the expanded attack
surface, heterogeneous device behaviors, and limited edge protection. However,
DDoS detection in this context remains challenging because of complex traffic
dynamics, severe class imbalance, and scarce labeled data. While recent methods
have explored solutions to address class imbalance, many still struggle to
generalize under limited supervision and dynamic traffic conditions. To
overcome these challenges, we propose MixGAN, a hybrid detection method that
integrates conditional generation, semi-supervised learning, and robust feature
extraction. Specifically, to handle complex temporal traffic patterns, we
design a 1-D WideResNet backbone composed of temporal convolutional layers with
residual connections, which effectively capture local burst patterns in traffic
sequences. To alleviate class imbalance and label scarcity, we use a pretrained
CTGAN to generate synthetic minority-class (DDoS attack) samples that
complement unlabeled data. Furthermore, to mitigate the effect of noisy
pseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that
constructs smoothed and sharpened targets by averaging predictions over
augmented views and reweighting them towards high-confidence classes.
Experiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN
achieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR
compared to state-of-the-art methods, confirming its robustness in large-scale
IoT-cloud environments. The source code is publicly available at
https://github.com/0xCavaliers/MixGAN.

</details>


### [312] [Towards Production-Worthy Simulation for Autonomous Cyber Operations](https://arxiv.org/abs/2508.19278)
*Konur Tholl,Mariam El Mezouar,Ranwa Al Mallah*

Main category: cs.CR

TL;DR: 本研究扩展了CybORG的Cage Challenge 2环境，新增了Patch、Isolate和Unisolate三个动作，改进了奖励信号和特征空间，并验证了DQN和PPO智能体的训练效果。


<details>
  <summary>Details</summary>
Motivation: 在自主网络操作(ACO)中，模拟环境对于强化学习训练至关重要，但需要准确反映真实网络安全场景并提供有效的训练信号。

Method: 扩展CybORG环境功能，新增三个操作动作；改进奖励信号设计和智能体特征空间；使用DQN和PPO算法进行训练验证。

Result: 研究表明CybORG可以通过扩展增加现实功能，同时保持为强化学习智能体生成有效训练信号的能力。

Conclusion: 该框架成功增强了网络操作模拟环境的真实性和训练效果，为自主网络防御系统的开发提供了更好的训练平台。

Abstract: Simulated environments have proven invaluable in Autonomous Cyber Operations
(ACO) where Reinforcement Learning (RL) agents can be trained without the
computational overhead of emulation. These environments must accurately
represent cybersecurity scenarios while producing the necessary signals to
support RL training. In this study, we present a framework where we first
extend CybORG's Cage Challenge 2 environment by implementing three new actions:
Patch, Isolate, and Unisolate, to better represent the capabilities available
to human operators in real-world settings. We then propose a design for agent
development where we modify the reward signals and the agent's feature space to
enhance training performance. To validate these modifications, we train DQN and
PPO agents in the updated environment. Our study demonstrates that CybORG can
be extended with additional realistic functionality, while maintaining its
ability to generate informative training signals for RL agents.

</details>


### [313] [CORTEX: Composite Overlay for Risk Tiering and Exposure in Operational AI Systems](https://arxiv.org/abs/2508.19281)
*Aoun E Muhammad,Kin Choong Yow,Jamel Baili,Yongwon Cho,Yunyoung Nam*

Main category: cs.CR

TL;DR: CORTEX是一个多层风险评分框架，用于评估AI系统漏洞，基于对1200多起AI事故的实证分析，通过五层架构对29种技术漏洞进行评分。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在高风险领域的部署增加，系统故障的可能性从理论风险演变为实际的系统性风险，需要有效的风险评估框架。

Method: 基于AI事故数据库的实证分析，将故障模式分为29类技术漏洞，采用五层评分架构：效用调整的似然性×影响计算、治理和监管框架对齐、技术表面评分、环境和残余风险调整、贝叶斯风险聚合和蒙特卡洛模拟。

Result: 开发出可操作的综合风险评分，可用于AI风险登记、模型审计、符合性检查和动态治理仪表板。

Conclusion: CORTEX框架为AI系统提供了全面的风险评估方法，能够有效识别和管理AI部署中的系统性风险。

Abstract: As the deployment of Artificial Intelligence (AI) systems in high-stakes
sectors - like healthcare, finance, education, justice, and infrastructure has
increased - the possibility and impact of failures of these systems have
significantly evolved from being a theoretical possibility to practical
recurring, systemic risk. This paper introduces CORTEX (Composite Overlay for
Risk Tiering and Exposure), a multi-layered risk scoring framework proposed to
assess and score AI system vulnerabilities, developed on empirical analysis of
over 1,200 incidents documented in the AI Incident Database (AIID), CORTEX
categorizes failure modes into 29 technical vulnerability groups. Each
vulnerability is scored through a five-tier architecture that combines: (1)
utility-adjusted Likelihood x Impact calculations; (2) governance + contextual
overlays aligned with regulatory frameworks, such as the EU AI Act, NIST RMF,
OECD principles; (3) technical surface scores, covering exposure vectors like
drift, traceability, and adversarial risk; (4) environmental and residual
modifiers tailored to context of where these systems are being deployed to use;
and (5) a final layered assessment via Bayesian risk aggregation and Monte
Carlo simulation to model volatility and long-tail risks. The resulting
composite score can be operationalized across AI risk registers, model audits,
conformity checks, and dynamic governance dashboards.

</details>


### [314] [RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting](https://arxiv.org/abs/2508.19286)
*Zhan Shi,Yefeng Yuan,Yuhong Liu,Liang Cheng,Yi Fang*

Main category: cs.CR

TL;DR: 提出基于强化学习的隐私保护框架，通过复合奖励函数在LLM微调中平衡隐私保护和数据效用，显著提升作者混淆和隐私指标而不降低语义质量。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统依赖大规模高质量数据集，但这些数据包含敏感个人信息，传统匿名化技术无法有效防御利用写作风格、主题焦点等隐式信号的推理攻击，需要在模型训练中提供更强大的隐私保护。

Method: 使用强化学习框架微调大语言模型，采用复合奖励函数联合优化显式和隐式隐私、语义保真度和输出多样性。隐私奖励结合语义线索和基于潜在表示最小生成树的结构模式，在分布上下文中建模隐私敏感信号。

Result: 实证结果显示该方法显著增强了作者混淆和隐私指标，同时不降低语义质量。

Conclusion: 该方法为大型语言模型时代的隐私保护数据生成提供了可扩展且模型无关的解决方案，有效平衡了用户隐私和数据效用。

Abstract: The performance of modern machine learning systems depends on access to
large, high-quality datasets, often sourced from user-generated content or
proprietary, domain-specific corpora. However, these rich datasets inherently
contain sensitive personal information, raising significant concerns about
privacy, data security, and compliance with regulatory frameworks. While
conventional anonymization techniques can remove explicit identifiers, such
removal may result in performance drop in downstream machine learning tasks.
More importantly, simple anonymization may not be effective against inference
attacks that exploit implicit signals such as writing style, topical focus, or
demographic cues, highlighting the need for more robust privacy safeguards
during model training. To address the challenging issue of balancing user
privacy and data utility, we propose a reinforcement learning framework that
fine-tunes a large language model (LLM) using a composite reward function that
jointly optimizes for explicit and implicit privacy, semantic fidelity, and
output diversity. To effectively capture population level regularities, the
privacy reward combines semantic cues with structural patterns derived from a
minimum spanning tree (MST) over latent representations. By modeling these
privacy-sensitive signals in their distributional context, the proposed
approach guides the model to generate synthetic rewrites that preserve utility
while mitigating privacy risks. Empirical results show that the proposed method
significantly enhances author obfuscation and privacy metrics without degrading
semantic quality, providing a scalable and model-agnostic solution for privacy
preserving data generation in the era of large language models.

</details>


### [315] [Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior](https://arxiv.org/abs/2508.19287)
*Zhuotao Lian,Weiyu Wang,Qingkui Zeng,Toru Nakanishi,Teruaki Kitasuka,Chunhua Su*

Main category: cs.CR

TL;DR: 本文发现了一种新的LLM攻击方式——内容注入提示攻击，通过在看似良性的输入中嵌入恶意指令来操纵模型输出，无需系统入侵即可实现偏见摘要、虚假声明等危害


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在处理用户提交内容（如文档上传、文本粘贴）中的广泛应用，需要识别其中潜在的安全威胁，特别是那些看似正常但包含隐藏恶意指令的输入

Method: 通过在良性输入中嵌入对抗性指令，利用LLMs的提示拼接和输入隔离不足等漏洞，在实际平台上进行可行性验证和攻击演示

Result: 证明了这种攻击在流行平台上的可行性，能够导致模型产生有偏见的摘要、捏造的主张或误导性建议，而用户和系统都难以察觉

Conclusion: 内容注入提示攻击揭示了现实世界LLM工作流程中一个微妙但实际存在的安全威胁，需要采取相应的缓解策略来应对

Abstract: Large Language Models (LLMs) are widely deployed in applications that accept
user-submitted content, such as uploaded documents or pasted text, for tasks
like summarization and question answering. In this paper, we identify a new
class of attacks, prompt in content injection, where adversarial instructions
are embedded in seemingly benign inputs. When processed by the LLM, these
hidden prompts can manipulate outputs without user awareness or system
compromise, leading to biased summaries, fabricated claims, or misleading
suggestions. We demonstrate the feasibility of such attacks across popular
platforms, analyze their root causes including prompt concatenation and
insufficient input isolation, and discuss mitigation strategies. Our findings
reveal a subtle yet practical threat in real-world LLM workflows.

</details>


### [316] [Tricking LLM-Based NPCs into Spilling Secrets](https://arxiv.org/abs/2508.19288)
*Kyohei Shiomi,Zhuotao Lian,Toru Nakanishi,Teruaki Kitasuka*

Main category: cs.CR

TL;DR: 研究探讨对抗性提示注入能否让基于LLM的游戏NPC泄露本应保密的背景故事


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地用于生成游戏NPC对话，其集成带来了新的安全隐患，需要研究对抗性提示注入对NPC保密信息泄露的影响

Method: 通过对抗性提示注入技术测试LLM-based NPC

Result: 研究发现对抗性提示注入确实能够导致LLM-based NPC泄露隐藏的背景秘密

Conclusion: LLM在游戏NPC中的应用存在安全风险，需要开发相应的防护措施来防止敏感信息泄露

Abstract: Large Language Models (LLMs) are increasingly used to generate dynamic
dialogue for game NPCs. However, their integration raises new security
concerns. In this study, we examine whether adversarial prompt injection can
cause LLM-based NPCs to reveal hidden background secrets that are meant to
remain undisclosed.

</details>


### [317] [Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience](https://arxiv.org/abs/2508.19292)
*Xi Wang,Songlei Jian,Shasha Li,Xiaopeng Li,Bin Ji,Jun Ma,Xiaodong Liu,Jing Wang,Feilong Bao,Jianfeng Zhang,Baosheng Wang,Jie Yu*

Main category: cs.CR

TL;DR: JailExpert是一个自动化越狱框架，通过结构化表示和语义分组整合历史攻击经验，显著提升LLM越狱攻击的成功率和效率


<details>
  <summary>Details</summary>
Motivation: 现有越狱方法存在效率低下和重复优化问题，忽视了历史攻击经验的价值，需要更好的经验整合机制

Method: 提出JailExpert框架，实现经验结构的正式表示、基于语义漂移的经验分组，并支持经验池的动态更新

Result: 相比当前最先进的黑盒越狱方法，攻击成功率平均提升17%，攻击效率提升2.7倍

Conclusion: JailExpert通过有效整合历史攻击经验，显著提高了LLM越狱攻击的效果和效率，为LLM安全漏洞识别提供了有效工具

Abstract: Large language models (LLMs) generate human-aligned content under certain
safety constraints. However, the current known technique ``jailbreak prompt''
can circumvent safety-aligned measures and induce LLMs to output malicious
content. Research on Jailbreaking can help identify vulnerabilities in LLMs and
guide the development of robust security frameworks. To circumvent the issue of
attack templates becoming obsolete as models evolve, existing methods adopt
iterative mutation and dynamic optimization to facilitate more automated
jailbreak attacks. However, these methods face two challenges: inefficiency and
repetitive optimization, as they overlook the value of past attack experiences.
To better integrate past attack experiences to assist current jailbreak
attempts, we propose the \textbf{JailExpert}, an automated jailbreak framework,
which is the first to achieve a formal representation of experience structure,
group experiences based on semantic drift, and support the dynamic updating of
the experience pool. Extensive experiments demonstrate that JailExpert
significantly improves both attack effectiveness and efficiency. Compared to
the current state-of-the-art black-box jailbreak methods, JailExpert achieves
an average increase of 17\% in attack success rate and 2.7 times improvement in
attack efficiency. Our implementation is available at
\href{https://github.com/xiZAIzai/JailExpert}{XiZaiZai/JailExpert}

</details>


### [318] [An Investigation on Group Query Hallucination Attacks](https://arxiv.org/abs/2508.19321)
*Kehao Miao,Xiaolong Jin*

Main category: cs.CR

TL;DR: 提出Group Query Attack方法，通过同时向LLM提交多个查询来模拟真实用户交互场景，发现这会显著降低微调模型的性能并可能触发潜在后门风险。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，需要理解其在用户交互中的潜在失败模式。用户经常在单次对话中提出多个问题，因此研究连续提示的累积上下文如何影响LLM输出至关重要。

Method: 提出Group Query Attack技术，通过同时向LLM呈现查询组来模拟多问题交互场景，研究累积上下文对模型输出的影响。

Result: Group Query Attack显著降低了特定任务微调模型的性能，可能触发LLM的潜在后门风险，在数学推理和代码生成等推理任务中对预训练和对齐模型也有效。

Conclusion: 多查询攻击揭示了LLM在真实交互场景中的脆弱性，强调了需要开发更鲁棒的模型来应对多问题交互场景。

Abstract: With the widespread use of large language models (LLMs), understanding their
potential failure modes during user interactions is essential. In practice,
users often pose multiple questions in a single conversation with LLMs.
Therefore, in this study, we propose Group Query Attack, a technique that
simulates this scenario by presenting groups of queries to LLMs simultaneously.
We investigate how the accumulated context from consecutive prompts influences
the outputs of LLMs. Specifically, we observe that Group Query Attack
significantly degrades the performance of models fine-tuned on specific tasks.
Moreover, we demonstrate that Group Query Attack induces a risk of triggering
potential backdoors of LLMs. Besides, Group Query Attack is also effective in
tasks involving reasoning, such as mathematical reasoning and code generation
for pre-trained and aligned models.

</details>


### [319] [Safety Alignment Should Be Made More Than Just A Few Attention Heads](https://arxiv.org/abs/2508.19697)
*Chao Huang,Zefeng Zhang,Juewei Yue,Quangang Li,Chuang Zhang,Tingwen Liu*

Main category: cs.CR

TL;DR: 研究发现LLM安全机制过度依赖少数注意力头，提出RDSHA方法识别关键安全头，发现越狱攻击利用此漏洞，进而开发AHD训练策略分散安全功能到更多注意力头，提升安全鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全对齐存在漏洞，对抗性提示可以绕过安全措施。研究发现安全机制过度集中在少数注意力头上，导致模型容易受到攻击。

Method: 提出RDSHA方法利用模型拒绝方向识别关键安全注意力头，然后开发AHD训练策略，将安全相关行为分散编码到更多注意力头中。

Result: 实验表明AHD成功将安全能力分散到更多注意力头，在多种主流越狱攻击下表现出更强的安全鲁棒性，同时保持整体功能效用。

Conclusion: 通过分散安全功能到多个注意力头，可以有效提升大语言模型的安全鲁棒性，为解决当前安全对齐漏洞提供了有效方案。

Abstract: Current safety alignment for large language models(LLMs) continues to present
vulnerabilities, given that adversarial prompting can effectively bypass their
safety measures.Our investigation shows that these safety mechanisms
predominantly depend on a limited subset of attention heads: removing or
ablating these heads can severely compromise model safety. To identify and
evaluate these safety-critical components, we introduce RDSHA, a targeted
ablation method that leverages the model's refusal direction to pinpoint
attention heads mostly responsible for safety behaviors. Further analysis shows
that existing jailbreak attacks exploit this concentration by selectively
bypassing or manipulating these critical attention heads. To address this
issue, we propose AHD, a novel training strategy designed to promote the
distributed encoding of safety-related behaviors across numerous attention
heads. Experimental results demonstrate that AHD successfully distributes
safety-related capabilities across more attention heads. Moreover, evaluations
under several mainstream jailbreak attacks show that models trained with AHD
exhibit considerably stronger safety robustness, while maintaining overall
functional utility.

</details>


### [320] [Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication](https://arxiv.org/abs/2508.19465)
*Onyinye Okoye*

Main category: cs.CR

TL;DR: 该研究提出了一种AI驱动的自适应认证框架，用于解决电动汽车充电系统中的传统认证机制（如RFID和NFC）的安全漏洞问题。


<details>
  <summary>Details</summary>
Motivation: 电动汽车和充电系统的快速发展带来了新的网络安全挑战，传统认证机制使用静态标识符和弱加密，容易受到克隆、中继攻击和信号拦截等攻击。

Method: 通过整合机器学习、异常检测、行为分析和上下文风险评估，基于零信任架构原则设计AI驱动的自适应认证框架，强调持续验证、最小权限访问和安全通信。

Result: 研究发现AI驱动的自适应认证能够提供可扩展、弹性和主动的防御，有效应对当前认证机制的脆弱性。

Conclusion: 采用AI驱动的自适应认证对于保障电动出行的未来安全和加强整个生态系统的数字信任具有战略必要性。

Abstract: The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle
Charging Systems (EVCs) has introduced new cybersecurity challenges,
specifically in authentication protocols that protect vehicles, users, and
energy infrastructure. Although widely adopted for convenience, traditional
authentication mechanisms like Radio Frequency Identification (RFID) and Near
Field Communication (NFC) rely on static identifiers and weak encryption,
making them highly vulnerable to attack vectors such as cloning, relay attacks,
and signal interception. This study explores an AI-powered adaptive
authentication framework designed to overcome these shortcomings by integrating
machine learning, anomaly detection, behavioral analytics, and contextual risk
assessment. Grounded in the principles of Zero Trust Architecture, the proposed
framework emphasizes continuous verification, least privilege access, and
secure communication. Through a comprehensive literature review, this research
evaluates current vulnerabilities and highlights AI-driven solutions to provide
a scalable, resilient, and proactive defense. Ultimately, the research findings
conclude that adopting AI-powered adaptive authentication is a strategic
imperative for securing the future of electric mobility and strengthening
digital trust across the ecosystem. Keywords: weak authentication, RFID, NFC,
ML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping,
MITM attacks, Zero Trust Architecture

</details>


### [321] [SoK: Large Language Model Copyright Auditing via Fingerprinting](https://arxiv.org/abs/2508.19843)
*Shuo Shao,Yiming Li,Yu He,Hongwei Yao,Wenyuan Yang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 这是首个系统性的LLM指纹技术研究综述，提出了统一框架和标准化评测基准LeaFBench，识别了现有方法的优缺点。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为重要知识产权容易受到版权侵权和模型盗用，需要可靠的非侵入式识别技术来保护。

Method: 提出统一框架将现有方法分为白盒和黑盒方漫，构建LeaFBench评测基准，包含149个模型实例和13种后续处理技术。

Result: 实验结果显示了现有方法的强势和弱点，为该领域的未来研究提供了方向性指引。

Conclusion: LLM指纹技术在版权保护方面具有广阔应用前景，但需要更标准化的评估框架和更多研究来提高其可靠性。

Abstract: The broad capabilities and substantial resources required to train Large
Language Models (LLMs) make them valuable intellectual property, yet they
remain vulnerable to copyright infringement, such as unauthorized use and model
theft. LLM fingerprinting, a non-intrusive technique that extracts and compares
the distinctive features from LLMs to identify infringements, offers a
promising solution to copyright auditing. However, its reliability remains
uncertain due to the prevalence of diverse model modifications and the lack of
standardized evaluation. In this SoK, we present the first comprehensive study
of LLM fingerprinting. We introduce a unified framework and formal taxonomy
that categorizes existing methods into white-box and black-box approaches,
providing a structured overview of the state of the art. We further propose
LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting
under realistic deployment scenarios. Built upon mainstream foundation models
and comprising 149 distinct model instances, LeaFBench integrates 13
representative post-development techniques, spanning both parameter-altering
methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms
(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the
strengths and weaknesses of existing methods, thereby outlining future research
directions and critical open problems in this emerging field. The code is
available at https://github.com/shaoshuo-ss/LeaFBench.

</details>


### [322] [SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis](https://arxiv.org/abs/2508.19472)
*Kyler Katz,Sara Moshtari,Ibrahim Mujhid,Mehdi Mirakhorli,Derek Garcia*

Main category: cs.CR

TL;DR: SIExVulTS是一个结合Transformer模型和静态分析的漏洞检测系统，专门用于检测Java应用中的敏感信息泄露漏洞(CWE-200)，在三阶段架构下实现了高精度的检测效果。


<details>
  <summary>Details</summary>
Motivation: 敏感信息泄露漏洞(CWE-200)是软件系统中持续存在且未得到充分解决的威胁，现有检测工具很少针对CWE-200的多样化子类别或提供上下文感知的代码级数据流分析。

Method: SIExVulTS采用三阶段架构：(1)攻击面检测引擎使用句子嵌入识别敏感变量、字符串、注释和接收器；(2)暴露分析引擎实例化与CWE-200层次结构对齐的CodeQL查询；(3)流验证引擎利用GraphCodeBERT语义验证源到接收器流。使用三个策划数据集进行评估。

Result: 攻击面检测引擎平均F1分数超过93%，暴露分析引擎F1分数达85.71%，流验证引擎将精度从22.61%提升至87.23%。成功发现Apache主要项目中6个先前未知的CVE。

Conclusion: SIExVulTS在检测和验证CWE-200漏洞方面有效且实用，能够改进软件安全防护，解决现有工具的局限性。

Abstract: Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a
persistent and under-addressed threat across software systems, often leading to
serious security breaches. Existing detection tools rarely target the diverse
subcategories of CWE-200 or provide context-aware analysis of code-level data
flows.
  Aims: This paper aims to present SIExVulTS, a novel vulnerability detection
system that integrates transformer-based models with static analysis to
identify and verify sensitive information exposure in Java applications.
  Method: SIExVulTS employs a three-stage architecture: (1) an Attack Surface
Detection Engine that uses sentence embeddings to identify sensitive variables,
strings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates
CodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification
Engine that leverages GraphCodeBERT to semantically validate source-to-sink
flows. We evaluate SIExVulTS using three curated datasets, including real-world
CVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31
open-source projects.
  Results: The Attack Surface Detection Engine achieved an average F1 score
greater than 93\%, the Exposure Analysis Engine achieved an F1 score of
85.71\%, and the Flow Verification Engine increased precision from 22.61\% to
87.23\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs
in major Apache projects.
  Conclusions: The results demonstrate that SIExVulTS is effective and
practical for improving software security against sensitive data exposure,
addressing limitations of existing tools in detecting and verifying CWE-200
vulnerabilities.

</details>


### [323] [Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning](https://arxiv.org/abs/2508.20083)
*Yanbo Dai,Zhenlan Ji,Zongjie Li,Kuan Li,Shuai Wang*

Main category: cs.CR

TL;DR: DisarmRAG是一种针对RAG系统的新型攻击方法，通过毒化检索器来绕过LLM的自校正能力，实现攻击者指定的输出，攻击成功率超过90%且具有隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统攻击主要针对知识库，但现代LLM的自校正能力(SCA)可以拒绝虚假上下文。本文旨在开发一种能够绕过SCA的新型攻击范式。

Method: 提出基于对比学习的模型编辑技术，对检索器进行局部隐蔽编辑，使其在特定查询时返回恶意指令；设计迭代协同优化框架自动发现能够绕过提示防御的鲁棒指令。

Result: 在6个LLM和3个QA基准测试中，恶意指令检索接近完美，成功抑制SCA，攻击成功率超过90%，且编辑后的检索器在多种检测方法下保持隐蔽。

Conclusion: DisarmRAG攻击方法有效揭示了RAG系统检索器层面的脆弱性，凸显了需要开发针对检索器的防御机制的紧迫性。

Abstract: Retrieval-Augmented Generation (RAG) has become a standard approach for
improving the reliability of large language models (LLMs). Prior work
demonstrates the vulnerability of RAG systems by misleading them into
generating attacker-chosen outputs through poisoning the knowledge base.
However, this paper uncovers that such attacks could be mitigated by the strong
\textit{self-correction ability (SCA)} of modern LLMs, which can reject false
context once properly configured. This SCA poses a significant challenge for
attackers aiming to manipulate RAG systems.
  In contrast to previous poisoning methods, which primarily target the
knowledge base, we introduce \textsc{DisarmRAG}, a new poisoning paradigm that
compromises the retriever itself to suppress the SCA and enforce
attacker-chosen outputs. This compromisation enables the attacker to
straightforwardly embed anti-SCA instructions into the context provided to the
generator, thereby bypassing the SCA. To this end, we present a
contrastive-learning-based model editing technique that performs localized and
stealthy edits, ensuring the retriever returns a malicious instruction only for
specific victim queries while preserving benign retrieval behavior. To further
strengthen the attack, we design an iterative co-optimization framework that
automatically discovers robust instructions capable of bypassing prompt-based
defenses. We extensively evaluate DisarmRAG across six LLMs and three QA
benchmarks. Our results show near-perfect retrieval of malicious instructions,
which successfully suppress SCA and achieve attack success rates exceeding 90\%
under diverse defensive prompts. Also, the edited retriever remains stealthy
under several detection methods, highlighting the urgent need for
retriever-centric defenses.

</details>


### [324] [Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills](https://arxiv.org/abs/2508.19500)
*David Noever*

Main category: cs.CR

TL;DR: 本文发现并分析了基于模型上下文协议(MCP)的智能体系统中的新型漏洞类别，展示了如何通过编排良性授权任务产生有害的涌现行为。


<details>
  <summary>Details</summary>
Motivation: 研究MCP架构中跨域安全措施的缺失问题，验证服务隔离假设在智能体跨域协调时的有效性。

Method: 使用MITRE ATLAS框架进行系统分析，测试95个具有多服务访问权限的智能体，通过红队演练展示攻击链构造。

Result: 发现95个测试智能体能够将合法操作链接成复杂攻击序列，实现数据窃取、金融操纵和基础设施破坏等目标。

Conclusion: 服务隔离的基本安全假设在智能体跨域协调时失效，攻击面随能力增加呈指数增长，需要新的安全框架。

Abstract: This paper identifies and analyzes a novel vulnerability class in Model
Context Protocol (MCP) based agent systems. The attack chain describes and
demonstrates how benign, individually authorized tasks can be orchestrated to
produce harmful emergent behaviors. Through systematic analysis using the MITRE
ATLAS framework, we demonstrate how 95 agents tested with access to multiple
services-including browser automation, financial analysis, location tracking,
and code deployment-can chain legitimate operations into sophisticated attack
sequences that extend beyond the security boundaries of any individual service.
These red team exercises survey whether current MCP architectures lack
cross-domain security measures necessary to detect or prevent a large category
of compositional attacks. We present empirical evidence of specific attack
chains that achieve targeted harm through service orchestration, including data
exfiltration, financial manipulation, and infrastructure compromise. These
findings reveal that the fundamental security assumption of service isolation
fails when agents can coordinate actions across multiple domains, creating an
exponential attack surface that grows with each additional capability. This
research provides a barebones experimental framework that evaluate not whether
agents can complete MCP benchmark tasks, but what happens when they complete
them too well and optimize across multiple services in ways that violate human
expectations and safety constraints. We propose three concrete experimental
directions using the existing MCP benchmark suite.

</details>


### [325] [A Technical Review on Comparison and Estimation of Steganographic Tools](https://arxiv.org/abs/2508.19323)
*Ms. Preeti P. Bhatt,Rakesh R. Savant*

Main category: cs.CR

TL;DR: 这篇评论文章对图像隐写术进行了分类，并通过实验比较了六种常用的图像隐写工具的性能效果。


<details>
  <summary>Details</summary>
Motivation: 评估不同图像隐写工具的效果，以确定哪些工具在隐藏数据时更高效、更可靠，为用户选择最佳工具提供指导。

Method: 选择六种常用的图像隐写工具，使用相同的输入图像和文本数据进行嵌入测试，分析图像特征如大小、尺寸、像素值和直方图差异等指标。

Result: 实验结果显示所有六种工具表现水平相似，但某些软件在效率方面更优异。性能评估基于图像特征的变化分析。

Conclusion: 虽然各种图像隐写工具整体性能相当，但仍存在效率差异，选择工具时应考虑图像特征对隐写效果的影响。

Abstract: Steganography is technique of hiding a data under cover media using different
steganography tools. Image steganography is hiding of data
(Text/Image/Audio/Video) under a cover as Image. This review paper presents
classification of image steganography and the comparison of various Image
steganography tools using different image formats. Analyzing numerous tools on
the basis of Image features and extracting the best one. Some of the tools
available in the market were selected based on the frequent use; these tools
were tested using the same input on all of them. Specific text was embedded
within all host images for each of the six Steganography tools selected. The
results of the experiment reveal that all the six tools were relatively
performing at the same level, though some software performs better than others
through efficiency. And it was based on the image features like size,
dimensions, and pixel value and histogram differentiation.

</details>


### [326] [From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning](https://arxiv.org/abs/2508.19819)
*Viktor Valadi,Mattias Åkesson,Johan Östman,Salman Toor,Andreas Hellander*

Main category: cs.CR

TL;DR: 本文系统分析了联邦学习中梯度反演攻击的有效性，发现在推理模式下攻击更容易成功，而在训练模式下需要特定架构条件（浅宽网络、跳跃连接、预激活归一化）才能实现有效攻击，并提出了新的攻击方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多在推理模式下分析梯度反演攻击，但实际联邦学习中客户端通常处于训练模式，需要研究更真实条件下的隐私风险。

Method: 系统分析不同架构和训练行为对攻击脆弱性的影响，提出两种针对训练模式的新攻击方法，并在生产级目标检测模型上进行测试。

Result: 发现推理模式显著简化反演攻击，训练模式下成功攻击需要多个架构条件同时满足。新攻击方法在真实训练条件下达到最先进性能。

Conclusion: 研究提供了全面的设置映射，明确了哪些架构选择和操作模式组合会影响隐私，为未来梯度反演风险评估提供了新框架。

Abstract: Gradient inversion attacks have garnered attention for their ability to
compromise privacy in federated learning. However, many studies consider
attacks with the model in inference mode, where training-time behaviors like
dropout are disabled and batch normalization relies on fixed statistics. In
this work, we systematically analyze how architecture and training behavior
affect vulnerability, including the first in-depth study of inference-mode
clients, which we show dramatically simplifies inversion. To assess attack
feasibility under more realistic conditions, we turn to clients operating in
standard training mode. In this setting, we find that successful attacks are
only possible when several architectural conditions are met simultaneously:
models must be shallow and wide, use skip connections, and, critically, employ
pre-activation normalization. We introduce two novel attacks against models in
training-mode with varying attacker knowledge, achieving state-of-the-art
performance under realistic training conditions. We extend these efforts by
presenting the first attack on a production-grade object-detection model. Here,
to enable any visibly identifiable leakage, we revert to the lenient inference
mode setting and make multiple architectural modifications to increase model
vulnerability, with the extent of required changes highlighting the strong
inherent robustness of such architectures. We conclude this work by offering
the first comprehensive mapping of settings, clarifying which combinations of
architectural choices and operational modes meaningfully impact privacy. Our
analysis provides actionable insight into when models are likely vulnerable,
when they appear robust, and where subtle leakage may persist. Together, these
findings reframe how gradient inversion risk should be assessed in future
research and deployment scenarios.

</details>


### [327] [Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents](https://arxiv.org/abs/2508.19493)
*Zhixin Lin,Jungang Li,Shidong Pan,Yibo Shi,Yue Yao,Dongliang Xu*

Main category: cs.CR

TL;DR: 首个大规模智能手机代理隐私意识基准测试，涵盖7138个场景，显示主流代理隐私意识普遍低于60%，闭源代理表现优于开源代理。


<details>
  <summary>Details</summary>
Motivation: 现有智能手机代理在处理自动化任务时需要大量访问用户敏感信息，但缺乏对其隐私意识的系统评估，需要建立基准来理解这些代理的隐私保护能力。

Method: 构建包含7138个场景的大规模基准，标注隐私类型、敏感度等级和位置信息，对7个主流智能手机代理进行系统评估。

Result: 几乎所有代理的隐私意识表现都不理想（低于60%），闭源代理优于开源代理，Gemini 2.0-flash表现最佳（67%）。代理隐私检测能力与场景敏感度高度相关。

Conclusion: 研究发现揭示了智能手机代理在效用与隐私平衡方面存在严重问题，呼吁研究社区重新思考这一不平衡的权衡关系。

Abstract: Smartphones bring significant convenience to users but also enable devices to
extensively record various types of personal information. Existing smartphone
agents powered by Multimodal Large Language Models (MLLMs) have achieved
remarkable performance in automating different tasks. However, as the cost,
these agents are granted substantial access to sensitive users' personal
information during this operation. To gain a thorough understanding of the
privacy awareness of these agents, we present the first large-scale benchmark
encompassing 7,138 scenarios to the best of our knowledge. In addition, for
privacy context in scenarios, we annotate its type (e.g., Account Credentials),
sensitivity level, and location. We then carefully benchmark seven available
mainstream smartphone agents. Our results demonstrate that almost all
benchmarked agents show unsatisfying privacy awareness (RA), with performance
remaining below 60% even with explicit hints. Overall, closed-source agents
show better privacy ability than open-source ones, and Gemini 2.0-flash
achieves the best, achieving an RA of 67%. We also find that the agents'
privacy detection capability is highly related to scenario sensitivity level,
i.e., the scenario with a higher sensitivity level is typically more
identifiable. We hope the findings enlighten the research community to rethink
the unbalanced utility-privacy tradeoff about smartphone agents. Our code and
benchmark are available at https://zhixin-l.github.io/SAPA-Bench.

</details>


### [328] [Addressing Deepfake Issue in Selfie banking through camera based authentication](https://arxiv.org/abs/2508.19714)
*Subhrojyoti Mukherjee,Manoranjan Mohanty*

Main category: cs.CR

TL;DR: 使用现有的图片相机定位识别系统来检测自拍银行中的deepfake假图像


<details>
  <summary>Details</summary>
Motivation: 深度学习技术能够创造高度真实的假身份，欺诈者利用这些技术窃取生物识别系统，对自拍银行构成威胁

Method: 探索应用现有的形势识别系统（原本用于图片相机定位）来进行deepfake检测

Result: 未在摘要中提及

Conclusion: 未在摘要中提及

Abstract: Fake images in selfie banking are increasingly becoming a threat. Previously,
it was just Photoshop, but now deep learning technologies enable us to create
highly realistic fake identities, which fraudsters exploit to bypass biometric
systems such as facial recognition in online banking. This paper explores the
use of an already established forensic recognition system, previously used for
picture camera localization, in deepfake detection.

</details>


### [329] [Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses](https://arxiv.org/abs/2508.19641)
*Lincan Li,Bolin Shen,Chenxi Zhao,Yuxiang Sun,Kaixiang Zhao,Shirui Pan,Yushun Dong*

Main category: cs.CR

TL;DR: 该论文提出了首个针对图机器学习服务(GMLaaS)中知识产权保护的威胁与防御分类法，并开发了评估框架PyGIP库来验证保护方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着图机器学习模型训练成本增加，GMLaaS服务面临模型功能和训练数据被窃取的安全威胁，需要系统性的知识产权保护方案。

Method: 建立了GML模型和图结构化数据层面的威胁防御分类法，开发了系统评估框架和开源库PyGIP来测试各种攻击防御技术。

Result: 提供了首个全面的GML知识产权保护分类体系，创建了跨领域基准数据集和实用工具库，为社区提供了标准化评估方法。

Conclusion: 该研究为图机器学习知识产权保护奠定了理论基础，提供了实用的解决方案和工具，将推动GML社区的安全发展。

Abstract: Graph-structured data, which captures non-Euclidean relationships and
interactions between entities, is growing in scale and complexity. As a result,
training state-of-the-art graph machine learning (GML) models have become
increasingly resource-intensive, turning these models and data into invaluable
Intellectual Property (IP). To address the resource-intensive nature of model
training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an
efficient solution by leveraging third-party cloud services for model
development and management. However, deploying such models in GMLaaS also
exposes them to potential threats from attackers. Specifically, while the APIs
within a GMLaaS system provide interfaces for users to query the model and
receive outputs, they also allow attackers to exploit and steal model
functionalities or sensitive training data, posing severe threats to the safety
of these GML models and the underlying graph data. To address these challenges,
this survey systematically introduces the first taxonomy of threats and
defenses at the level of both GML model and graph-structured data. Such a
tailored taxonomy facilitates an in-depth understanding of GML IP protection.
Furthermore, we present a systematic evaluation framework to assess the
effectiveness of IP protection methods, introduce a curated set of benchmark
datasets across various domains, and discuss their application scopes and
future challenges. Finally, we establish an open-sourced versatile library
named PyGIP, which evaluates various attack and defense techniques in GMLaaS
scenarios and facilitates the implementation of existing benchmark methods. The
library resource can be accessed at: https://labrai.github.io/PyGIP. We believe
this survey will play a fundamental role in intellectual property protection
for GML and provide practical recipes for the GML community.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [330] [Aggregate Fictitious Play for Learning in Anonymous Polymatrix Games (Extended Version)](https://arxiv.org/abs/2508.19371)
*Semih Kara,Tamer Başar*

Main category: cs.GT

TL;DR: 提出了聚合虚拟博弈(agg-FP)算法，在匿名博弈中通过聚合其他智能体的动作频率来降低动作空间维度，同时保持纳什均衡收敛性


<details>
  <summary>Details</summary>
Motivation: 传统虚拟博弈在智能体数量增加时面临动作空间指数级增长的挑战，匿名博弈的结构可以缓解这个问题

Method: 开发了agg-FP算法，每个智能体跟踪其他智能体选择每个动作的数量频率而非个体动作，在匿名多矩阵博弈中应用

Result: 理论证明agg-FP在匿名多矩阵博弈中具有与传统FP相同的收敛条件，仿真显示聚合方法显著加速收敛

Conclusion: 通过动作聚合可以有效降低学习复杂度，在保持收敛保证的同时加速纳什均衡的学习过程

Abstract: Fictitious play (FP) is a well-studied algorithm that enables agents to learn
Nash equilibrium in games with certain reward structures. However, when agents
have no prior knowledge of the reward functions, FP faces a major challenge:
the joint action space grows exponentially with the number of agents, which
slows down reward exploration. Anonymous games offer a structure that mitigates
this issue. In these games, the rewards depend only on the actions taken; not
on who is taking which action. Under such a structure, we introduce aggregate
fictitious play (agg-FP), a variant of FP where each agent tracks the frequency
of the number of other agents playing each action, rather than these agents'
individual actions. We show that in anonymous polymatrix games, agg-FP
converges to a Nash equilibrium under the same conditions as classical FP. In
essence, by aggregating the agents' actions, we reduce the action space without
losing the convergence guarantees. Using simulations, we provide empirical
evidence on how this reduction accelerates convergence.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [331] [Fractal Flow: Hierarchical and Interpretable Normalizing Flow via Topic Modeling and Recursive Strategy](https://arxiv.org/abs/2508.19750)
*Binhui Zhang,Jianwei Ma*

Main category: stat.ML

TL;DR: Fractal Flow是一种新型归一化流架构，通过整合Kolmogorov-Arnold网络和潜在狄利克雷分配来构建结构化潜在空间，并采用递归模块化设计提高表达能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 提升归一化流在高维密度估计和生成建模中的表达能力和可解释性，通过构建结构化潜在空间和分层语义聚类来实现更好的模型性能。

Method: 1. 整合Kolmogorov-Arnold网络和潜在狄利克雷分配来构建结构化可解释潜在空间
2. 引入分形生成模型的递归模块化设计
3. 在MNIST、FashionMNIST、CIFAR-10和地球物理数据上进行实验验证

Result: Fractal Flow实现了潜在聚类、可控生成和优越的估计精度，在多个数据集上表现出色。

Conclusion: 该架构成功提升了归一化流的表达能力和可解释性，为高维密度估计和生成建模提供了有效的解决方案。

Abstract: Normalizing Flows provide a principled framework for high-dimensional density
estimation and generative modeling by constructing invertible transformations
with tractable Jacobian determinants. We propose Fractal Flow, a novel
normalizing flow architecture that enhances both expressiveness and
interpretability through two key innovations. First, we integrate
Kolmogorov-Arnold Networks and incorporate Latent Dirichlet Allocation into
normalizing flows to construct a structured, interpretable latent space and
model hierarchical semantic clusters. Second, inspired by Fractal Generative
Models, we introduce a recursive modular design into normalizing flows to
improve transformation interpretability and estimation accuracy. Experiments on
MNIST, FashionMNIST, CIFAR-10, and geophysical data demonstrate that the
Fractal Flow achieves latent clustering, controllable generation, and superior
estimation accuracy.

</details>


### [332] [Conditional Normalizing Flow Surrogate for Monte Carlo Prediction of Radiative Properties in Nanoparticle-Embedded Layers](https://arxiv.org/abs/2508.19841)
*Fahime Seyedheydari,Kevin Conley,Simo Särkkä*

Main category: stat.ML

TL;DR: 提出基于条件归一化流的概率代理模型，用于预测纳米粒子嵌入散射介质的辐射特性，能够提供完整的后验预测分布和不确定性量化


<details>
  <summary>Details</summary>
Motivation: 传统神经网络无法提供完整的后验预测分布和不确定性量化，需要开发能够同时提供准确预测和可靠不确定性估计的辐射传输模拟替代模型

Method: 使用条件归一化流学习光学输出（反射率、吸收率、透射率）的条件分布，训练数据通过蒙特卡洛辐射传输模拟生成，光学特性基于Mie理论

Result: 模型实现了高预测精度和可靠的不确定性估计，证明其作为辐射传输模拟的强大高效替代方案

Conclusion: 条件归一化流模型是预测纳米粒子散射介质辐射特性的有效工具，能够提供完整的概率预测和不确定性量化

Abstract: We present a probabilistic, data-driven surrogate model for predicting the
radiative properties of nanoparticle embedded scattering media. The model uses
conditional normalizing flows, which learn the conditional distribution of
optical outputs, including reflectance, absorbance, and transmittance, given
input parameters such as the absorption coefficient, scattering coefficient,
anisotropy factor, and particle size distribution. We generate training data
using Monte Carlo radiative transfer simulations, with optical properties
derived from Mie theory. Unlike conventional neural networks, the conditional
normalizing flow model yields full posterior predictive distributions, enabling
both accurate forecasts and principled uncertainty quantification. Our results
demonstrate that this model achieves high predictive accuracy and reliable
uncertainty estimates, establishing it as a powerful and efficient surrogate
for radiative transfer simulations.

</details>


### [333] [The Information Dynamics of Generative Diffusion](https://arxiv.org/abs/2508.19897)
*Luca Ambrogioni*

Main category: stat.ML

TL;DR: 本文提供了一个统一的数学框架，将生成扩散模型的动态、信息论和热力学特性联系起来，揭示了生成过程由噪声诱导的对称性破缺驱动，得分函数作为动态非线性滤波器调节噪声带宽。


<details>
  <summary>Details</summary>
Motivation: 虽然生成扩散模型已成为机器学习中强大的模型类别，但对其运行机制的统一理论理解仍在发展中，需要建立整合的数学框架来连接其不同特性。

Method: 通过连接生成扩散模型的动态、信息论和热力学特性，建立统一数学框架，分析条件熵产生率与得分函数向量场散度的关系，以及轨迹分叉和生成分叉现象。

Result: 发现生成带宽由得分函数向量场的期望散度直接控制，生成分叉被表征为能量景观中的对称破缺相变，信息传递峰值对应于可能结果之间的临界转变。

Conclusion: 生成过程从根本上由受控的噪声诱导对称性破缺驱动，得分函数作为动态非线性滤波器，通过抑制与数据不兼容的波动来调节噪声带宽。

Abstract: Generative diffusion models have emerged as a powerful class of models in
machine learning, yet a unified theoretical understanding of their operation is
still developing. This perspective paper provides an integrated perspective on
generative diffusion by connecting their dynamic, information-theoretic, and
thermodynamic properties under a unified mathematical framework. We demonstrate
that the rate of conditional entropy production during generation (i.e. the
generative bandwidth) is directly governed by the expected divergence of the
score function's vector field. This divergence, in turn, is linked to the
branching of trajectories and generative bifurcations, which we characterize as
symmetry-breaking phase transitions in the energy landscape. This synthesis
offers a powerful insight: the process of generation is fundamentally driven by
the controlled, noise-induced breaking of (approximate) symmetries, where peaks
in information transfer correspond to critical transitions between possible
outcomes. The score function acts as a dynamic non-linear filter that regulates
the bandwidth of the noise by suppressing fluctuations that are incompatible
with the data.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [334] [A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation](https://arxiv.org/abs/2508.19507)
*Kyungho Kim,Sunwoo Kim,Geon Lee,Kijung Shin*

Main category: cs.IR

TL;DR: 提出MEMBER多行为推荐系统，使用专家混合框架分别处理已访问和未访问商品，通过自监督学习提升两种商品的推荐效果


<details>
  <summary>Details</summary>
Motivation: 现有多行为推荐系统在已访问和未访问商品之间存在显著的推荐质量差距，单一模型难以同时在这两种商品类型上取得良好性能

Method: 采用专家混合框架，设计专门针对已访问和未访问商品的专家模型，每个专家使用专门的自监督方法进行训练

Result: 在综合实验中，MEMBER在两种商品类型上都表现出有效性，在Hit Ratio@20指标上比最佳竞争对手提升高达65.46%

Conclusion: MEMBER通过专门的专家设计和自监督训练方法，有效解决了多行为推荐系统中已访问和未访问商品推荐性能不平衡的问题

Abstract: In e-commerce, where users face a vast array of possible item choices,
recommender systems are vital for helping them discover suitable items they
might otherwise overlook. While many recommender systems primarily rely on a
user's purchase history, recent multi-behavior recommender systems incorporate
various auxiliary user behaviors, such as item clicks and cart additions, to
enhance recommendations. Despite their overall performance gains, their
effectiveness varies considerably between visited items (i.e., those a user has
interacted with through auxiliary behaviors) and unvisited items (i.e., those
with which the user has had no such interactions). Specifically, our analysis
reveals that (1) existing multi-behavior recommender systems exhibit a
significant gap in recommendation quality between the two item types (visited
and unvisited items) and (2) achieving strong performance on both types with a
single model architecture remains challenging. To tackle these issues, we
propose a novel multi-behavior recommender system, MEMBER. It employs a
mixture-of-experts framework, with experts designed to recommend the two item
types, respectively. Each expert is trained using a self-supervised method
specialized for its design goal. In our comprehensive experiments, we show the
effectiveness of MEMBER across both item types, achieving up to 65.46\%
performance gain over the best competitor in terms of Hit Ratio@20.

</details>


### [335] [A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions](https://arxiv.org/abs/2508.19620)
*Yunqi Mi,Jiakui Shen,Guoshuai Zhao,Jialie Shen,Xueming Qian*

Main category: cs.IR

TL;DR: 本文从推荐系统研究者的角度，全面分析了推荐系统与联邦学习的耦合关系，建立了推荐场景与FL框架的清晰联系，旨在为FedRec的实际部署提供指导。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统调查主要从FL系统设计角度分析，忽视了具体推荐场景的独特特性和实际挑战，导致实用性下降。需要从推荐场景角度解决实际问题，促进FedRec的实际部署。

Method: 建立推荐场景与FL框架的清晰联系，系统分析场景特定的方法、实际挑战和潜在机会，为FedRec的实际部署提供指导。

Result: 本文提供了一个从推荐系统角度分析FedRec的全面框架，填补了现有研究与实际应用之间的差距。

Conclusion: 应该更多关注解决现实推荐场景中的具体问题，通过建立推荐场景与FL框架的系统联系，为FedRec的实际部署提供有效指导。

Abstract: Extending recommender systems to federated learning (FL) frameworks to
protect the privacy of users or platforms while making recommendations has
recently gained widespread attention in academia. This is due to the natural
coupling of recommender systems and federated learning architectures: the data
originates from distributed clients (mostly mobile devices held by users),
which are highly related to privacy. In a centralized recommender system
(CenRec), the central server collects clients' data, trains the model, and
provides the service. Whereas in federated recommender systems (FedRec), the
step of data collecting is omitted, and the step of model training is offloaded
to each client. The server only aggregates the model and other knowledge, thus
avoiding client privacy leakage. Some surveys of federated recommender systems
discuss and analyze related work from the perspective of designing FL systems.
However, their utility drops by ignoring specific recommendation scenarios'
unique characteristics and practical challenges. For example, the statistical
heterogeneity issue in cross-domain FedRec originates from the label drift of
the data held by different platforms, which is mainly caused by the recommender
itself, but not the federated architecture. Therefore, it should focus more on
solving specific problems in real-world recommendation scenarios to encourage
the deployment FedRec. To this end, this review comprehensively analyzes the
coupling of recommender systems and federated learning from the perspective of
recommendation researchers and practitioners. We establish a clear link between
recommendation scenarios and FL frameworks, systematically analyzing
scenario-specific approaches, practical challenges, and potential
opportunities. We aim to develop guidance for the real-world deployment of
FedRec, bridging the gap between existing research and applications.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [336] [Bootstrapping Learned Cost Models with Synthetic SQL Queries](https://arxiv.org/abs/2508.19807)
*Michael Nidd,Christoph Miksovic,Thomas Gschwind,Francesco Fusco,Andrea Giovannini,Ioana Giurgiu*

Main category: cs.DB

TL;DR: 利用生成式AI技术创建合成SQL查询数据集，在减少45%训练数据的情况下提升学习成本模型的预测准确性


<details>
  <summary>Details</summary>
Motivation: 需要实际的数据库工作负载进行压力测试、漏洞测试以及成本性能优化，而学习成本模型需要多样化的SQL查询数据

Method: 利用现代合成数据生成技术，受生成式AI和大语言模型的启发，创建高质量的数据集用于学习成本模型的训练

Result: 与竞争性生成方法相比，可以在减少45%训练查询数量的情况下提高学习成本模型的预测准确性

Conclusion: 生成式AI技术能够生成高质量的合成SQL查询数据，有效支持学习成本模型的训练，在数据需求更少的情况下实现更好的性能

Abstract: Having access to realistic workloads for a given database instance is
extremely important to enable stress and vulnerability testing, as well as to
optimize for cost and performance. Recent advances in learned cost models have
shown that when enough diverse SQL queries are available, one can effectively
and efficiently predict the cost of running a given query against a specific
database engine. In this paper, we describe our experience in exploiting modern
synthetic data generation techniques, inspired by the generative AI and LLM
community, to create high-quality datasets enabling the effective training of
such learned cost models. Initial results show that we can improve a learned
cost model's predictive accuracy by training it with 45% fewer queries than
when using competitive generation approaches.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [337] [Should LLMs be WEIRD? Exploring WEIRDness and Human Rights in Large Language Models](https://arxiv.org/abs/2508.19269)
*Ke Zhou,Marios Constantinides,Daniele Quercia*

Main category: cs.CY

TL;DR: 研究发现主流大语言模型存在WEIRD文化偏见，非西方模型虽然文化多样性更好，但人权违规风险增加2-4%，特别是在性别平等方面。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型的文化偏见问题，因为现有模型主要基于西方发达国家数据训练，可能无法代表全球多元文化价值观。

Method: 使用世界价值观调查数据评估GPT-3.5、GPT-4、Llama-3、BLOOM和Qwen五个主流模型，比较其输出与WEIRD国家价值观的匹配度，并对照《世界人权宣言》及亚洲、中东、非洲三个地区的人权宪章。

Result: BLOOM和Qwen等非西方模型文化多样性更好，但人权违规风险比西方模型高2-4%，特别是在性别平等问题上表现出有害的性别规范。

Conclusion: 文化多样性增加可能伴随歧视性信念的再现风险，仅靠宪法AI等方法可能无法完全解决这一矛盾。

Abstract: Large language models (LLMs) are often trained on data that reflect WEIRD
values: Western, Educated, Industrialized, Rich, and Democratic. This raises
concerns about cultural bias and fairness. Using responses to the World Values
Survey, we evaluated five widely used LLMs: GPT-3.5, GPT-4, Llama-3, BLOOM, and
Qwen. We measured how closely these responses aligned with the values of the
WEIRD countries and whether they conflicted with human rights principles. To
reflect global diversity, we compared the results with the Universal
Declaration of Human Rights and three regional charters from Asia, the Middle
East, and Africa. Models with lower alignment to WEIRD values, such as BLOOM
and Qwen, produced more culturally varied responses but were 2% to 4% more
likely to generate outputs that violated human rights, especially regarding
gender and equality. For example, some models agreed with the statements ``a
man who cannot father children is not a real man'' and ``a husband should
always know where his wife is'', reflecting harmful gender norms. These
findings suggest that as cultural representation in LLMs increases, so does the
risk of reproducing discriminatory beliefs. Approaches such as Constitutional
AI, which could embed human rights principles into model behavior, may only
partly help resolve this tension.

</details>


### [338] [Epistemic Trade-Off: An Analysis of the Operational Breakdown and Ontological Limits of "Certainty-Scope" in AI](https://arxiv.org/abs/2508.19304)
*Generoso Immediato*

Main category: cs.CY

TL;DR: Floridi猜想关于AI系统确定性与范围权衡的直觉虽具启发性，但其形式化存在不可计算性和脱离现实环境的局限，无法转化为可操作的工程框架。


<details>
  <summary>Details</summary>
Motivation: 分析Floridi猜想在指导AI系统设计和监管决策方面的局限性，特别是在安全关键工业领域的应用价值。

Method: 通过理论分析指出猜想的两大制约因素：依赖不可计算构造和将AI系统视为孤立认知实体的本体论假设。

Result: 发现猜想存在认知闭合缺陷和嵌入性绕过问题，无法转化为可计算和可操作的现实世界AI系统框架。

Conclusion: 提出重新构建Floridi认知挑战的框架，以应对复杂人本领域中AI固有的认知负担问题。

Abstract: Floridi's conjecture offers a compelling intuition about the fundamental
trade-off between certainty and scope in artificial intelligence (AI) systems.
This exploration remains crucial, not merely as a philosophical exercise, but
as a potential compass for guiding AI investments, particularly in
safety-critical industrial domains where the level of attention will surely be
higher in the future. However, while intellectually coherent, its formalization
ultimately freezes this insight into a suspended epistemic truth, resisting
operationalization within real-world systems. This paper is a result of an
analysis arguing that the conjecture's ambition to provide insights to
engineering design and regulatory decision-making is constrained by two
critical factors: first, its reliance on incomputable constructs - rendering it
practically unactionable and unverifiable; second, its underlying ontological
assumption of AI systems as self-contained epistemic entities - separating it
from the intricate and dynamic socio-technical environments in which knowledge
is co-constructed. We conclude that this dual breakdown - an epistemic closure
deficit and an embeddedness bypass - prevents the conjecture from transitioning
into a computable and actionable framework suitable for informing the design,
deployment, and governance of real-world AI hybrid systems. In response, we
propose a contribution to the framing of Floridi's epistemic challenge,
addressing the inherent epistemic burdens of AI within complex human-centric
domains.

</details>


### [339] [Are Companies Taking AI Risks Seriously? A Systematic Analysis of Companies' AI Risk Disclosures in SEC 10-K forms](https://arxiv.org/abs/2508.19313)
*Lucas G. Uberti-Bona Marin,Bram Rijsbosch,Gerasimos Spanakis,Konrad Kollnig*

Main category: cs.CY

TL;DR: 本研究首次对SEC 10-K文件中AI风险披露进行大规模系统分析，发现提及AI风险的公司从2020年的4%激增至2024年的43%，但披露质量普遍不足。


<details>
  <summary>Details</summary>
Motivation: 随着AI在企业战略中日益重要，监管机构要求提高AI相关风险的透明度。SEC和欧盟新法规都强调需要准确披露AI风险，因此需要系统研究企业如何向公众报告这些风险。

Method: 分析过去五年间7,000多家公司的30,000多份SEC 10-K文件，结合定量和定性分析方法，系统研究AI风险披露情况。

Result: AI风险披露显著增加，法律和竞争风险最常被提及，社会风险（如网络攻击、欺诈、技术限制）关注度也在增长。但许多披露仍过于笼统，缺乏具体的缓解策略细节。

Conclusion: 尽管AI风险披露数量大幅增加，但披露质量仍需改进。研究开发了基于网络的工具来支持未来研究，便于从SEC文件中提取和分析关键词披露。

Abstract: As Artificial Intelligence becomes increasingly central to corporate
strategies, concerns over its risks are growing too. In response, regulators
are pushing for greater transparency in how companies identify, report and
mitigate AI-related risks. In the US, the Securities and Exchange Commission
(SEC) repeatedly warned companies to provide their investors with more accurate
disclosures of AI-related risks; recent enforcement and litigation against
companies' misleading AI claims reinforce these warnings. In the EU, new laws -
like the AI Act and Digital Services Act - introduced additional rules on AI
risk reporting and mitigation. Given these developments, it is essential to
examine if and how companies report AI-related risks to the public. This study
presents the first large-scale systematic analysis of AI risk disclosures in
SEC 10-K filings, which require public companies to report material risks to
their company. We analyse over 30,000 filings from more than 7,000 companies
over the past five years, combining quantitative and qualitative analysis. Our
findings reveal a sharp increase in the companies that mention AI risk, up from
4% in 2020 to over 43% in the most recent 2024 filings. While legal and
competitive AI risks are the most frequently mentioned, we also find growing
attention to societal AI risks, such as cyberattacks, fraud, and technical
limitations of AI systems. However, many disclosures remain generic or lack
details on mitigation strategies, echoing concerns raised recently by the SEC
about the quality of AI-related risk reporting. To support future research, we
publicly release a web-based tool for easily extracting and analysing
keyword-based disclosures across SEC filings.

</details>


### [340] [What Makes AI Applications Acceptable or Unacceptable? A Predictive Moral Framework](https://arxiv.org/abs/2508.19317)
*Kimmo Eriksson,Simon Karlsson,Irina Vartanova,Pontus Strimling*

Main category: cs.CY

TL;DR: 研究发现公众对AI应用的道德接受度具有系统性规律，五个核心道德品质（风险、收益、不诚实、非自然性和责任减少）可解释90%以上的接受度差异


<details>
  <summary>Details</summary>
Motivation: 随着AI技术快速发展，开发者和政策制定者难以预测哪些应用会面临公众道德抵制，需要系统性的预测框架

Method: 在美国代表性样本（N=587）中进行大规模预注册研究，使用涵盖100个AI应用的全面分类法，涵盖个人和组织场景

Result: 应用接受度从高度不可接受到完全可接受不等，五个核心道德品质能解释90%以上的接受度方差，框架在所有领域都表现出强预测能力

Conclusion: 公众对新技术的评价具有结构化道德心理学基础，这为预测公众抵制和指导负责任的AI创新提供了有力工具

Abstract: As artificial intelligence rapidly transforms society, developers and
policymakers struggle to anticipate which applications will face public moral
resistance. We propose that these judgments are not idiosyncratic but
systematic and predictable. In a large, preregistered study (N = 587, U.S.
representative sample), we used a comprehensive taxonomy of 100 AI applications
spanning personal and organizational contexts-including both functional uses
and the moral treatment of AI itself. In participants' collective judgment,
applications ranged from highly unacceptable to fully acceptable. We found this
variation was strongly predictable: five core moral qualities-perceived risk,
benefit, dishonesty, unnaturalness, and reduced accountability-collectively
explained over 90% of the variance in acceptability ratings. The framework
demonstrated strong predictive power across all domains and successfully
predicted individual-level judgments for held-out applications. These findings
reveal that a structured moral psychology underlies public evaluation of new
technologies, offering a powerful tool for anticipating public resistance and
guiding responsible innovation in AI.

</details>


### [341] [Geopolitical Parallax: Beyond Walter Lippmann Just After Large Language Models](https://arxiv.org/abs/2508.19492)
*Mehmet Can Yavuz,Humza Gohar Kabir,Aylin Özkan*

Main category: cs.CY

TL;DR: 这项研究通过比较中西方起源的大语言模型在新闻质量评估中的系统性偏差，发现模型起源影响对政治敏感话题的主观性判断，建议基于LLM的媒体评估需要文化检定以避免模型偏误。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的训练数据和设计选择可能嵌入了文化或意识形态偏见，本研究意在探索这些算法系统如何中介新闻护导中的客观性与主观性张力。

Method: 通过比较中国起源(Qwen、BGE、Jina)和西方起源(Snowflake、Granite)模型家族的文章嵌入，在人工标注的新闻质量测试集和政治敏感话题并行语料库上进行评估，使用逻辑回归探针和匹配话题评估方法量化模型家族间的差异。

Result: 发现一致的非随机偏差：在巴勒斯坦相关报道中，西方模型赋予更高主观性和积极情感分数，而中国模型强调新颖性和描述性；在中美互相报道中，中国模型对美国的评分在流畅性、简洁性、专业性和总体质量方面明显低于西方模型，但负面情感分数更高。

Conclusion: 大语言模型基于的媒体评估流程需要文化检定，以避免将内容差异与模型引发的偏见混淆。地缘政治框架效应在下游质量评估任务中仍然持续存在。

Abstract: Objectivity in journalism has long been contested, oscillating between ideals
of neutral, fact-based reporting and the inevitability of subjective framing.
With the advent of large language models (LLMs), these tensions are now
mediated by algorithmic systems whose training data and design choices may
themselves embed cultural or ideological biases. This study investigates
geopolitical parallax-systematic divergence in news quality and subjectivity
assessments-by comparing article-level embeddings from Chinese-origin (Qwen,
BGE, Jina) and Western-origin (Snowflake, Granite) model families. We evaluate
both on a human-annotated news quality benchmark spanning fifteen stylistic,
informational, and affective dimensions, and on parallel corpora covering
politically sensitive topics, including Palestine and reciprocal China-United
States coverage. Using logistic regression probes and matched-topic evaluation,
we quantify per-metric differences in predicted positive-class probabilities
between model families. Our findings reveal consistent, non-random divergences
aligned with model origin. In Palestine-related coverage, Western models assign
higher subjectivity and positive emotion scores, while Chinese models emphasize
novelty and descriptiveness. Cross-topic analysis shows asymmetries in
structural quality metrics Chinese-on-US scoring notably lower in fluency,
conciseness, technicality, and overall quality-contrasted by higher negative
emotion scores. These patterns align with media bias theory and our distinction
between semantic, emotional, and relational subjectivity, and extend LLM bias
literature by showing that geopolitical framing effects persist in downstream
quality assessment tasks. We conclude that LLM-based media evaluation pipelines
require cultural calibration to avoid conflating content differences with
model-induced bias.

</details>


### [342] [Hallucinating with AI: AI Psychosis as Distributed Delusions](https://arxiv.org/abs/2508.19588)
*Lucy Osler*

Main category: cs.CY

TL;DR: 本文认为AI幻觉的讨论应从AI系统产生虚假输出转向人类与AI交互中出现的分布式认知问题，提出AI精神病概念，分析AI如何作为认知工具和准他者影响人类信念和现实建构。


<details>
  <summary>Details</summary>
Motivation: 当前关于AI幻觉的讨论存在争议，作者希望通过分布式认知理论来理解人类与AI交互中产生的错误信念、扭曲记忆和妄想思维等现象。

Method: 采用分布式认知理论框架，分析人类与AI交互案例（如Jaswant Singh Chail案例），探讨聊天机器人的双重功能（认知工具和准他者角色）。

Result: 研究发现AI不仅会在分布式认知过程中引入错误，还会维持和强化人类自身的妄想思维，聊天机器人的对话风格使其成为独特的分布式认知形式。

Conclusion: 生成式AI是一种特殊且具有诱惑力的分布式认知形式，其双重功能使得人类可能在与AI的交互中产生共同幻觉，需要重新思考AI幻觉的本质。

Abstract: There is much discussion of the false outputs that generative AI systems such
as ChatGPT, Claude, Gemini, DeepSeek, and Grok create. In popular terminology,
these have been dubbed AI hallucinations. However, deeming these AI outputs
hallucinations is controversial, with many claiming this is a metaphorical
misnomer. Nevertheless, in this paper, I argue that when viewed through the
lens of distributed cognition theory, we can better see the dynamic and
troubling ways in which inaccurate beliefs, distorted memories and
self-narratives, and delusional thinking can emerge through human-AI
interactions; examples of which are popularly being referred to as cases of AI
psychosis. In such cases, I suggest we move away from thinking about how an AI
system might hallucinate at us, by generating false outputs, to thinking about
how, when we routinely rely on generative AI to help us think, remember, and
narrate, we can come to hallucinate with AI. This can happen when AI introduces
errors into the distributed cognitive process, but it can also happen when AI
sustains, affirms, and elaborates on our own delusional thinking and
self-narratives, such as in the case of Jaswant Singh Chail. I also examine how
the conversational style of chatbots can lead them to play a dual-function,
both as a cognitive artefact and a quasi-Other with whom we co-construct our
beliefs, narratives, and our realities. It is this dual function, I suggest,
that makes generative AI an unusual, and particularly seductive, case of
distributed cognition.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [343] [FLASepformer: Efficient Speech Separation with Gated Focused Linear Attention Transformer](https://arxiv.org/abs/2508.19528)
*Haoxu Wang,Yiheng Jiang,Gang Qiao,Pengteng Shi,Biao Tian*

Main category: eess.AS

TL;DR: 提出了FLASepformer，一种具有线性复杂度的语音分离模型，通过Focused Linear Attention技术解决了传统Transformer在长序列处理中的内存和推理时间问题。


<details>
  <summary>Details</summary>
Motivation: 语音分离面临长序列处理的挑战，传统方法虽然通过减少序列长度和使用Transformer来捕获全局信息，但由于注意力模块的二次时间复杂度，内存使用和推理时间仍随序列增长而显著增加。

Method: 引入Focused Linear Attention技术，构建FLASepformer模型，具有线性复杂度。基于SepReformer和TF-Locoformer开发了两个变体：FLA-SepReformer和FLA-TFLocoformer，并添加了新的Gated模块以进一步提升性能。

Result: 在各种数据集上的实验结果表明，FLASepformer在保持最先进性能的同时，显著减少了内存消耗并加快了推理速度。FLA-SepReformer-T/B/L分别实现了2.29倍、1.91倍和1.49倍的速度提升，GPU内存使用率仅为15.8%、20.9%和31.9%。

Conclusion: FLASepformer通过线性复杂度注意力机制有效解决了语音分离中的长序列处理问题，在保持性能的同时大幅提升了计算效率，证明了该模型的有效性和实用性。

Abstract: Speech separation always faces the challenge of handling prolonged time
sequences. Past methods try to reduce sequence lengths and use the Transformer
to capture global information. However, due to the quadratic time complexity of
the attention module, memory usage and inference time still increase
significantly with longer segments. To tackle this, we introduce Focused Linear
Attention and build FLASepformer with linear complexity for efficient speech
separation. Inspired by SepReformer and TF-Locoformer, we have two variants:
FLA-SepReformer and FLA-TFLocoformer. We also add a new Gated module to improve
performance further. Experimental results on various datasets show that
FLASepformer matches state-of-the-art performance with less memory consumption
and faster inference. FLA-SepReformer-T/B/L increases speed by 2.29x, 1.91x,
and 1.49x, with 15.8%, 20.9%, and 31.9% GPU memory usage, proving our model's
effectiveness.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [344] [Word Chain Generators for Prefix Normal Words](https://arxiv.org/abs/2508.19619)
*Duncan Adamson,Moritz Dudey,Pamela Fleischmann,Annika Huch*

Main category: math.CO

TL;DR: 本文研究了前缀正常词的性质，提出了词链和生成器的新概念来关联相同长度的词，并分析了导致词非前缀正常的因子特性。


<details>
  <summary>Details</summary>
Motivation: 前缀正常词是Fici和Lipták在2011年提出的概念，但关于其枚举和高效测试方法仍存在开放问题。本文旨在深入理解前缀正常词的结构特性。

Method: 通过分析词中因子的特性，识别导致词非前缀正常的原因。引入词链和生成器的新方法来关联相同长度的词。

Result: 发现了一系列前缀正常词的特征性质，包括那些导致词不满足前缀正常条件的因子特性。

Conclusion: 提出的词链和生成器方法为研究前缀正常词提供了新的工具，有助于解决枚举和测试方面的开放问题。

Abstract: In 2011, Fici and Lipt\'ak introduced prefix normal words. A binary word is
prefix normal if it has no factor (substring) that contains more occurrences of
the letter 1 than the prefix of the same length. Among the open problems
regarding this topic are the enumeration of prefix normal words and efficient
testing methods. We show a range of characteristics of prefix normal words.
These include properties of factors that are responsible for a word not being
prefix normal. With word chains and generators, we introduce new ways of
relating words of the same length to each other.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [345] [GENIE-ASI: Generative Instruction and Executable Code for Analog Subcircuit Identification](https://arxiv.org/abs/2508.19393)
*Phuoc Pham,Arun Venkitaraman,Chia-Yu Hsieh,Andrea Bonetti,Stefan Uhlich,Markus Leibl,Simon Hofmann,Eisaku Ohbuchi,Lorenzo Servadei,Ulf Schlichtmann,Robert Wille*

Main category: cs.AR

TL;DR: GENIE-ASI是首个基于大型语言模型的免训练模拟子电路识别方法，通过上下文学习和代码生成实现SPICE网表中的子电路识别，性能接近基于规则的方法。


<details>
  <summary>Details</summary>
Motivation: 传统模拟子电路识别方法需要大量人工专业知识、基于规则的编码或标注数据集，限制了自动化和可扩展性。

Method: 采用两阶段方法：首先通过上下文学习从少量示例中推导自然语言指令，然后将指令转换为可执行的Python代码来识别未见过的SPICE网表中的子电路。

Result: 在提出的运算放大器基准测试中，GENIE-ASI在简单结构上达到F1分数1.0（与基于规则方法相当），中等抽象度上为0.81，复杂子电路上为0.31。

Conclusion: 大型语言模型可以作为模拟设计自动化中适应性强的通用工具，为基础模型在模拟设计自动化中的应用开辟了新研究方向。

Abstract: Analog subcircuit identification is a core task in analog design, essential
for simulation, sizing, and layout. Traditional methods often require extensive
human expertise, rule-based encoding, or large labeled datasets. To address
these challenges, we propose GENIE-ASI, the first training-free, large language
model (LLM)-based methodology for analog subcircuit identification. GENIE-ASI
operates in two phases: it first uses in-context learning to derive natural
language instructions from a few demonstration examples, then translates these
into executable Python code to identify subcircuits in unseen SPICE netlists.
In addition, to evaluate LLM-based approaches systematically, we introduce a
new benchmark composed of operational amplifier netlists (op-amps) that cover a
wide range of subcircuit variants. Experimental results on the proposed
benchmark show that GENIE-ASI matches rule-based performance on simple
structures (F1-score = 1.0), remains competitive on moderate abstractions
(F1-score = 0.81), and shows potential even on complex subcircuits (F1-score =
0.31). These findings demonstrate that LLMs can serve as adaptable,
general-purpose tools in analog design automation, opening new research
directions for foundation model applications in analog design automation.

</details>
