<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 28]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.CV](#cs.CV) [Total: 98]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.RO](#cs.RO) [Total: 25]
- [cs.SD](#cs.SD) [Total: 8]
- [cs.CR](#cs.CR) [Total: 16]
- [eess.IV](#eess.IV) [Total: 5]
- [eess.AS](#eess.AS) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.LO](#cs.LO) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [math.OC](#math.OC) [Total: 2]
- [cs.IR](#cs.IR) [Total: 25]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.SC](#cs.SC) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 8]
- [cs.DL](#cs.DL) [Total: 1]
- [math.NA](#math.NA) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [stat.ML](#stat.ML) [Total: 6]
- [stat.ME](#stat.ME) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cs.CY](#cs.CY) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 论文提出了一种名为AEPO的新策略优化框架，通过多答案生成策略和自适应探索奖励函数，解决了MLLMs在GUI操作中语义对齐的探索效率问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMs）在GUI操作中语义对齐的探索效率瓶颈问题。

Method: 提出了自适应探索策略优化（AEPO）框架，结合多答案生成策略和自适应探索奖励函数（AER）。

Result: AEPO训练的模型在多个GUI基准测试中达到新最优性能，相对基线提升达9.0%。

Conclusion: AEPO有效解决了语义对齐的探索问题，显著提升了MLLMs在GUI任务中的性能。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [2] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 提出了一种结合主动推理与大型语言模型的新型框架，用于开发安全的通用人工智能（AGI），强调将安全性融入系统核心设计。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法（如事后可解释性和奖励工程）存在根本性局限，需要一种更本质的安全设计方法。

Method: 通过透明信念表示和分层价值对齐，将安全性融入系统核心；利用自然语言表示信念，实现人类监督；采用多智能体系统，基于主动推理原则自组织。

Result: 提出了具体的安全机制，如信念与偏好的自然语言分离、资源感知的自由能最小化、模块化智能体结构等。

Conclusion: 该框架为AGI开发提供了一条更本质的安全路径，并提出了基于ARC基准的研究议程以验证其安全性。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [3] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 现代神经网络表现出类似人类思维的组合、创新和快速学习能力，削弱了人类认知过程是符号化的论点，但仍需研究符号系统在抽象问题中的作用。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络是否具备类似人类思维的组合、创新和快速学习能力，从而挑战人类认知过程是符号化的传统观点。

Method: 通过分析现代神经网络的能力，并与人类思维特征对比，提出新的研究方向。

Result: 神经网络表现出类似人类思维的能力，削弱了符号化认知的论点，但符号系统在抽象问题中的作用仍需研究。

Conclusion: 提出新的研究议程，探索符号系统在人类思维中的基础作用。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [4] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI是一个统一的框架，结合因果评级与传统XAI方法，支持交互式、多方法的解释过程，满足不同利益相关者的需求。


<details>
  <summary>Details</summary>
Motivation: 当前XAI方法主要服务于开发者，且多关注模型输出的合理性，而非多样化的利益相关者需求。H-XAI旨在填补这一空白。

Method: H-XAI整合因果评级与传统XAI方法，支持利益相关者通过提问、测试假设和比较模型行为与自动构建的随机和偏见基线来交互式解释。

Result: 通过两个案例研究（信用风险分类和金融时间序列预测）展示了H-XAI的通用性，能够回答个体决策和整体模型层面的问题。

Conclusion: H-XAI通过结合因果评级和后验解释，填补了现有XAI方法的不足，为不同利益相关者提供更全面的支持。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [5] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 该论文综述了具身导航中的安全问题，包括攻击策略、防御机制和评估方法，并探讨了未解决的问题和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和具身AI的发展，具身导航在关键应用中的安全性问题日益突出，需要全面分析和解决。

Method: 通过多角度综合分析现有安全挑战、缓解技术、数据集和评估指标，探讨未解决问题和未来方向。

Result: 论文总结了具身导航中的安全挑战和现有解决方案，提出了未来研究方向，如更可靠的评估技术和验证框架。

Conclusion: 该研究为开发更安全可靠的具身导航系统提供了指导，并具有增强社会安全和工业效率的广泛意义。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [6] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 提出了一种基于知识图谱（KG）的工具检索框架，通过捕捉工具间的语义关系和功能依赖，显著提升了多步任务中的工具检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖用户查询与工具描述的相似性，限制了多步请求的检索准确性，因此需要一种更全面的方法。

Method: 采用知识图谱框架，利用1-hop ego工具图的集成建模工具间的直接和间接连接。

Result: 在合成数据集上，该方法在Complete Recall指标上达到91.85%的工具覆盖率，优于非KG基线方法的89.26%。

Conclusion: 知识图谱的结构信息为纯相似性匹配提供了补充信号，特别适用于需要顺序工具组合的查询。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [7] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出MedOrch框架，通过LLM调解多模态VLM代理协作，提升医疗决策性能。


<details>
  <summary>Details</summary>
Motivation: 现有多代理系统多限于语言任务，多模态场景下VLM协作能力不足，需解决其指令跟随和自反思问题。

Method: 采用LLM调解代理协调多个VLM专家代理，利用开源模型实现异构协作，避免高成本GPT模型。

Result: 在五个医疗视觉问答基准上验证，协作性能超越单代理，无需额外训练。

Conclusion: 调解引导的多代理协作可推动医疗多模态智能发展。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [8] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 论文提出了一种分层多智能体框架HIMA，结合模仿学习和元控制器，以解决LLM在动态长时任务（如《星际争霸II》）中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法在动态、长时任务（如《星际争霸II》）中表现不佳，难以应对资源约束和部分可观测环境。

Method: 提出HIMA框架，包含多个模仿学习专家智能体和一个元控制器（Strategic Planner），通过专家演示学习特定策略，并由SP协调生成适应性计划。

Result: HIMA在战略清晰度、适应性和计算效率上优于现有方法，验证了其有效性。

Conclusion: 结合专业化模仿模块与元级协调，可开发更鲁棒、通用的AI智能体。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [9] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 该论文提出了一个双用途框架，利用参与式预算（PB）作为LLM资源分配的实践场景和评估其推理能力的基准。通过三种提示策略测试LLM在约束条件下的项目选择能力，并评估其从非结构化输入中提取偏好的能力。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在结构化资源分配任务中的能力，并解决现有评估方法因数据污染和静态基准而受限的问题。

Method: 使用参与式预算（PB）作为框架，通过贪婪选择、直接优化和启发式改进三种提示策略，评估LLM在预算约束下的项目选择能力。同时测试LLM从自然语言输入中推断偏好的能力。

Result: 结果表明提示设计对LLM性能至关重要，并展示了LLM在机制设计和非结构化输入处理中的潜力。

Conclusion: LLM在资源分配和偏好推断方面具有潜力，提示设计是关键因素，为未来机制设计提供了新方向。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [10] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 论文呼吁重视认知想象在人工智能中的关键作用，并提出语义模型作为模拟认知想象的新方法。


<details>
  <summary>Details</summary>
Motivation: 认知想象在人类思维中扮演重要角色，但目前被低估，限制了AI的能力。

Method: 提出语义模型，这是一种基于概率因果关系的数学模型，能够学习和确保想象上下文的连贯性。

Result: 语义模型能够模拟认知想象，支持连贯的推理和决策。

Conclusion: 认知想象是AI未来的重要突破方向，语义模型为实现这一目标提供了可行工具。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [11] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: CA-DL8.5是一种通用的、完整的、随时可用的波束搜索算法，扩展了DL8.5框架，统一了现有的随时策略，并通过模块化设计整合了多种启发式和松弛机制。


<details>
  <summary>Details</summary>
Motivation: 现有方法如LDS-DL8.5、Top-k-DL8.5和Blossom在随时性能上缺乏系统比较，难以评估其相对有效性。

Method: CA-DL8.5结合了DL8.5的高效分支定界剪枝和基于字典树的缓存，通过逐步放松剪枝标准的波束搜索提升解的质量。

Result: 实验表明，基于LDS启发式的CA-DL8.5在随时性能上表现最佳，优于其他变体和Blossom算法。

Conclusion: CA-DL8.5提供了一个通用框架，支持多种启发式和搜索策略，同时保持了完整性和最优性保证。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [12] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR框架通过LLM代理科学家进行表格推理，无需数据增强或参数优化，表现优于普通LLM，媲美全监督模型。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理任务中依赖标注数据或复杂数据增强的问题，提升灵活性和泛化能力。

Method: PanelTR框架利用五个科学家角色进行独立调查、自我审查和同行评审讨论，实现语义级迁移。

Result: 在四个基准测试中，PanelTR优于普通LLM，媲美全监督模型，且无需训练数据。

Conclusion: 结构化科学方法能有效处理复杂任务，具备零样本下的灵活语义理解能力。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [13] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 论文提出了一种基于深度强化学习（DRL）和鸟瞰图（BEV）感知的自动驾驶新方法，结合了高效的时空特征提取网络Mamba-BEV和ME³-BEV框架，显著提升了动态城市驾驶场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统模块化方法存在误差传播和协调问题，端到端学习系统则面临计算瓶颈。本文旨在通过结合BEV感知和DRL，解决这些问题。

Method: 提出Mamba-BEV模型，结合BEV感知和Mamba框架进行时空特征建模；进一步开发ME³-BEV框架，用于端到端DRL。

Result: 在CARLA模拟器上的实验表明，ME³-BEV在碰撞率和轨迹精度等指标上优于现有模型。

Conclusion: ME³-BEV为实时自动驾驶提供了一种高效且可解释的解决方案。

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [14] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 本文解决了关于图神经网络（GNNs）逻辑表达能力的一个开放性问题，证明了其表达能力严格超过C2逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究GNNs与逻辑语言之间的关系，尤其是解决Barceló等人提出的关于GNNs是否被C2逻辑完全刻画的开放性问题。

Method: 通过理论分析，比较GNNs与C2逻辑的表达能力，并证明GNNs的表达能力更强。

Result: 证明了GNNs的逻辑表达能力严格超过C2逻辑，适用于无向和有向图。

Conclusion: 研究不仅解决了GNNs的开放性问题，还为无穷逻辑的表达能力提供了新的见解。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [15] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE是一个自动化、可扩展的评估框架，通过让大语言模型（LLMs）相互生成和解决任务来评估其能力，无需人工干预或领域专业知识。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型能力的方法需要大量领域专业知识，难以适应模型的快速演进。

Method: SKATE框架将评估视为游戏，模型既是任务生成者也是解决者，通过生成可验证任务相互竞争。

Result: SKATE能够客观区分模型能力，发现模型自我偏好行为，并揭示模型间的细微差异。

Conclusion: SKATE为通用、可扩展的评估框架提供了重要进展，能够跟上大语言模型的发展步伐。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [16] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 论文探讨了如何利用机器学习方法分析车辆路径问题（VRP）解决方案的结构特征，并通过可解释AI理解模型决策，提出了一种统一框架来评估特征重要性。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法依赖人工设计，机器学习方法可以更高效地分析VRP解决方案的结构特征，从而改进算法设计。

Method: 使用多种分类器模型进行敏感性分析，预测VRP解决方案的质量，并利用可解释AI理解模型决策。

Result: 研究发现某些特征始终是强预测因子，并提出统一框架评估特征重要性。

Conclusion: 特征重要性分析为改进元启发式算法提供了基础，展示了机器学习在VRP中的潜力。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [17] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 研究通过RAG框架增强LLMs在药物禁忌领域的应用，显著提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在医疗领域的潜力，特别是在需要高准确性的药物禁忌信息方面。

Method: 使用GPT-4o-mini和text-embedding-3-small模型，结合Langchain构建混合检索系统，利用DUR数据。

Result: RAG框架显著提升了模型准确性，三个类别的准确率分别达到0.94、0.87和0.89。

Conclusion: RAG框架能有效减少药物禁忌决策中的不确定性，提供更可靠的信息。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [18] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 论文提出从以准确性为中心的评估转向以置信度驱动的风险感知LLM评估系统，强调校准置信度的重要性，并提出新指标TH-Score和框架LLM-as-a-Fuser以提升可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为自动评估工具时过于关注准确性，忽略了置信度校准的重要性，导致实际部署中的可靠性问题。

Method: 引入TH-Score量化置信度与准确性的对齐，提出LLM-as-a-Fuser框架，通过集成方法提升评估的可靠性和风险感知能力。

Result: 实验表明，该方法显著改善了置信度校准，实现了自适应且可靠的评估流程，优于现有基线。

Conclusion: 置信度驱动的风险感知评估系统能显著提升LLM作为评估工具的可靠性和实用性。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [19] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: GeoLaux是一个新的几何问题解决基准，包含2,186个问题，重点关注辅助线构建和长步推理能力，评估了13个MLLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估MLLM几何技能时忽略了辅助线构建和细粒度过程评估，无法全面评估长步推理能力。

Method: 提出了GeoLaux基准，包含计算和证明问题，设计了五维评估策略。

Result: 实验显示MLLM在长步推理中性能显著下降，倾向于走捷径，且缺乏辅助线意识。

Conclusion: GeoLaux可作为评估MLLM几何推理能力的基准，并指导能力提升。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [20] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯归纳逻辑编程方法，通过平衡假设复杂度和数据拟合，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 统一概率和逻辑学习是AI的关键挑战。

Method: 采用贝叶斯归纳逻辑编程，通过先验和似然平衡假设复杂度和数据拟合。

Result: 在多个领域（如游戏和药物设计）中显著优于现有方法，且数据高效、对示例平衡不敏感。

Conclusion: 该方法在统一概率和逻辑学习方面表现出色，具有高效性和鲁棒性。

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [21] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 提出了一种通过打破假设空间对称性来加速归纳逻辑编程的方法，并在多个领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决归纳逻辑编程中假设空间庞大且存在大量逻辑等价假设的问题。

Method: 使用答案集编程实现对称性打破的方法。

Result: 实验表明，该方法将求解时间从超过一小时缩短至17秒。

Conclusion: 该方法显著提高了归纳逻辑编程的效率，适用于视觉推理和游戏等多个领域。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [22] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: PRISM Eval开发了BET工具，通过动态对抗优化实现100%攻击成功率，并提出了细粒度鲁棒性指标和原始级漏洞分析。


<details>
  <summary>Details</summary>
Motivation: 评估和提升大型语言模型（LLM）的鲁棒性，揭示其在不同攻击下的脆弱性。

Method: 使用动态对抗优化进行自动化红队测试，提出细粒度鲁棒性指标和原始级漏洞分析。

Result: 对41个先进LLM中的37个实现了100%攻击成功率，攻击难度差异达300倍。

Conclusion: 通过分布式鲁棒性评估为社区提供了实用的安全性提升路径。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [23] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 论文探讨了Conant和Ashby的“每个好的系统调节器必须是该系统的模型”定理的局限性，并提出了一种更广义的模型概念，即观察者可以将调节任务的执行解释为代理的“信念更新”。


<details>
  <summary>Details</summary>
Motivation: 研究Conant和Ashby定理的局限性，并探索在更广泛背景下如何定义系统的模型。

Method: 通过观察者视角，将代理的调节行为解释为“信念更新”，从而定义一种更广义的模型概念。

Result: 提出了一种新的模型定义，适用于更广泛的调节任务，包括经典控制理论和内部状态调节。

Conclusion: 模型不仅是系统的属性，还依赖于观察者的解释，从而解决了Conant和Ashby定理的局限性。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [24] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer的机器学习模型AntiCheatPT_256，用于检测《CS2》中的作弊行为，并公开了标注数据集CS2CD。模型在未增强测试集上准确率达89.17%，AUC为93.36%。


<details>
  <summary>Details</summary>
Motivation: 在线游戏中的作弊行为破坏了游戏体验的公平性，现有反作弊系统（如VAC）难以在不侵犯用户隐私的情况下应对不断演变的作弊手段。

Method: 使用公开数据集CS2CD（包含795场比赛数据），生成90,707个上下文窗口并进行数据增强以解决类别不平衡问题。基于Transformer的模型训练后用于作弊检测。

Result: 模型在未增强测试集上达到89.17%的准确率和93.36%的AUC。

Conclusion: AntiCheatPT_256为数据驱动的作弊检测提供了可复现且实用的基线模型，适用于未来研究。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [25] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 论文提出“解释性AI”作为补充范式，利用生成式AI能力作为人类理解的解释伙伴，而非算法透明度的提供者。


<details>
  <summary>Details</summary>
Motivation: 当前可解释AI（XAI）方法过于关注算法透明度，提供的解释抽象且非自适应，难以支持终端用户的理解。

Method: 提出八维概念模型，区分解释性AI，强调叙事沟通、自适应个性化和渐进披露原则，并通过医疗专业人员的实证验证。

Result: 用户更偏好上下文敏感的多模态解释，而非技术透明度。

Conclusion: 研究呼吁设计以人类理解为中心的AI系统，并确立了跨领域和文化背景的用户中心解释方法研究议程。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [26] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 论文提出两种自动化构建法律知识图谱（KG）的方法，填补了法律领域KG的空白，并针对针对妇女暴力的法律案例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 法律决策需要全面的立法背景知识和最新的法律案例信息，但目前法律领域的KG较少，因此开发了针对特定法律案例的KG。

Method: 采用两种互补方法：系统化的自底向上方法和基于大型语言模型的新方案，结合结构化数据提取、本体开发和语义增强。

Result: 构建了针对妇女暴力法律案例的KG，并通过能力问题验证了其有效性。

Conclusion: 开发的KG可提高法律信息的可访问性，支持复杂查询，并为预测性司法机器学习工具提供知识支持。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [27] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 论文提出了一种动态机制“Fair Game”，通过结合审计员和去偏算法，利用强化学习实现公平性目标的自适应调整，以弥补公平机器学习在动态社会环境中理论与实践的差距。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习的定义多为观察性，且常互相冲突，难以在动态社会环境中实现公平性目标。

Method: 提出“Fair Game”框架，将审计员和去偏算法通过强化学习循环结合，动态调整公平性目标。

Result: “Fair Game”能够模拟社会伦理和法律框架的演变，实现公平性目标的自适应调整。

Conclusion: “Fair Game”为公平机器学习提供了灵活且适应动态环境的框架，适用于部署前后的系统。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [28] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 本文提出了一种数据驱动的方法，评估多赢家投票规则在不同偏好分布下违反公理的频率，并通过神经网络优化规则以减少公理违反。


<details>
  <summary>Details</summary>
Motivation: 研究多赢家投票规则在实际应用中满足公理的情况，摆脱传统最坏情况分析的二元视角。

Method: 提出数据驱动框架，分析多赢家投票规则在不同偏好分布下的公理表现，并利用神经网络优化规则。

Result: 神经网络作为投票规则，在减少公理违反方面优于传统规则。

Conclusion: 数据驱动方法可为新投票系统设计提供参考，推动社会选择领域的数据驱动研究。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [29] [PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare](https://arxiv.org/abs/2508.05722)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: PEACH是一个英语-阿拉伯语对齐的医疗文本平行语料库，包含51,671对句子，可用于语言学、翻译研究和自然语言处理。


<details>
  <summary>Details</summary>
Motivation: 为医疗领域的对比语言学、翻译研究和自然语言处理提供高质量的对齐语料库。

Method: 手动对齐的医疗文本，包括患者信息手册和教育材料。

Result: 语料库包含51,671对句子，约590,517英语和567,707阿拉伯语词标记。

Conclusion: PEACH是一个公开可用的黄金标准语料库，支持多领域研究。

Abstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic
corpus of healthcare texts encompassing patient information leaflets and
educational materials. The corpus contains 51,671 parallel sentences, totaling
approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths
vary between 9.52 and 11.83 words on average. As a manually aligned corpus,
PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,
translation studies, and natural language processing. It can be used to derive
bilingual lexicons, adapt large language models for domain-specific machine
translation, evaluate user perceptions of machine translation in healthcare,
assess patient information leaflets and educational materials' readability and
lay-friendliness, and as an educational resource in translation studies. PEACH
is publicly accessible.

</details>


### [30] [Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation](https://arxiv.org/abs/2508.05775)
*Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu*

Main category: cs.CL

TL;DR: 该论文综述了大语言模型（LLMs）在内容生成中的双重作用：既是强大工具，又可能产生有害内容，并系统分析了相关风险与防御措施。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在解决实际问题时的潜力及其潜在危害，以应对这一紧迫的社会技术挑战。

Method: 系统回顾了近期研究，包括无意毒性、对抗性攻击和内容审核技术，提出了统一的分类法，并分析了多模态和LLM辅助的攻击策略。

Result: 综合了当前LLM安全领域的进展，指出了评估方法的局限性，并提出了未来研究方向。

Conclusion: 强调了开发稳健且符合伦理的语言技术的重要性，并呼吁进一步研究以应对LLM安全挑战。

Abstract: Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

</details>


### [31] [FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification](https://arxiv.org/abs/2508.05782)
*Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver*

Main category: cs.CL

TL;DR: 论文提出了一个细粒度对话事实验证基准FineDialFact，用于检测LLMs生成的对话中的幻觉问题，并展示了基于Chain-of-Thought推理的方法能提升性能。


<details>
  <summary>Details</summary>
Motivation: LLMs生成的对话中常包含事实错误或虚构信息（幻觉），现有检测方法过于粗粒度，需细粒度验证。

Method: 构建FineDialFact基准和数据集，基于公开对话数据集，采用Chain-of-Thought推理方法进行验证。

Result: 实验显示Chain-of-Thought方法能提升性能，但在开放域对话数据集HybriDialogue上F1-score仅为0.75，任务仍具挑战性。

Conclusion: FineDialFact为未来研究提供了挑战性基准，代码和数据集将公开。

Abstract: Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

</details>


### [32] [Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models](https://arxiv.org/abs/2508.05803)
*Abishek Thamma,Micha Heilbron*

Main category: cs.CL

TL;DR: 研究探讨了短暂记忆对语言学习的益处，发现短暂记忆能提升语言模型性能，但意外地降低了人类阅读时间的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 验证短暂记忆是否有助于语言学习，尤其是在Transformer模型中。

Method: 通过对比实验，训练带有和不带有短暂记忆的Transformer模型，评估其语言建模和人类阅读时间预测能力。

Result: 短暂记忆提升了语言学习效果，但降低了阅读时间预测的准确性。

Conclusion: 短暂记忆对神经网络语言学习有益，但对行为预测无益。

Abstract: Human memory is fleeting. As words are processed, the exact wordforms that
make up incoming sentences are rapidly lost. Cognitive scientists have long
believed that this limitation of memory may, paradoxically, help in learning
language - an idea supported by classic connectionist modelling work. The rise
of Transformers appears to challenge this idea, as these models can learn
language effectively, despite lacking memory limitations or other architectural
recency biases. Here, we investigate the hypothesized benefit of fleeting
memory for language learning in tightly controlled experiments on transformer
language models. Training transformers with and without fleeting memory on a
developmentally realistic training set, we find that fleeting memory
consistently improves language learning (as quantified by both overall language
modelling performance and targeted syntactic evaluation) but, unexpectedly,
impairs surprisal-based prediction of human reading times. Interestingly,
follow up analyses revealed that this discrepancy - better language modeling,
yet worse reading time prediction - could not be accounted for by prior
explanations of why better language models sometimes fit human reading time
worse. Together, these results support a benefit of memory limitations on
neural network language learning - but not on predicting behavior.

</details>


### [33] ["Mirror" Language AI Models of Depression are Criterion-Contaminated](https://arxiv.org/abs/2508.05830)
*Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns*

Main category: cs.CL

TL;DR: 研究发现，基于语言的抑郁评估模型（Mirror模型）因“标准污染”导致效应量虚高，而Non-Mirror模型虽效应量较小但更具普适性。


<details>
  <summary>Details</summary>
Motivation: 探讨Mirror模型与Non-Mirror模型在抑郁评估中的表现差异，揭示标准污染对模型普适性的影响。

Method: 使用GPT-4、GPT-4o和LLaMA3-70B预测抑郁评分，比较Mirror模型（基于诊断访谈）与Non-Mirror模型（基于生活史访谈）的效果。

Result: Mirror模型效应量虚高（R2=0.80），Non-Mirror模型效应量较小但更稳健（R2=0.27）。两者与自报抑郁症状的相关性相同（r≈0.54）。

Conclusion: Mirror模型因标准污染效应量虚高，Non-Mirror模型更具普适性，未来抑郁评估应结合Non-Mirror模型以提高实用性。

Abstract: A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

</details>


### [34] [Discovering Properties of Inflectional Morphology in Neural Emergent Communication](https://arxiv.org/abs/2508.05843)
*Miles Gilberti,Shane Storks,Huteng Dai*

Main category: cs.CL

TL;DR: 论文重新解释了一种常见的涌现通信（EmCom）设置，通过小词汇约束模拟双重发音，并提出了一个类似自然语言屈折形态的新设置，以探索自然语言的特性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过模拟自然语言的屈折形态特性（如拼接性和融合性），更好地理解人类语言的本质。

Method: 在属性-值重建游戏中引入小词汇约束，模拟双重发音，并设计新指标和变体实验。

Result: 实验发现，模拟的音位约束促进了拼接性形态，而涌现语言倾向于融合语法属性，与自然语言类似。

Conclusion: 研究为涌现通信提供了更接近自然语言的框架，揭示了模拟约束对语言形态的影响。

Abstract: Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

</details>


### [35] [Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models](https://arxiv.org/abs/2508.05880)
*Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang*

Main category: cs.CL

TL;DR: 该论文探讨了大型语言模型（LLMs）在情感计算中如何通过认知维度进行情感推理，超越了传统的情感识别任务，并提出了一个新的基准CoRE来评估LLMs的认知推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中在监督学习下的情感标签任务，缺乏对LLMs在情感认知推理方面的深入探索。本文旨在填补这一空白，研究LLMs是否能够通过认知维度进行连贯的情感推理。

Method: 基于认知评价理论，作者设计了一个大规模基准CoRE，通过实验分析LLMs在情感推理中是否依赖特定的认知评价维度，以及这些维度如何表征不同情感。

Result: 实验结果显示，不同LLMs在情感推理中表现出多样化的认知模式，揭示了模型内部表征与认知评价维度之间的关系。

Conclusion: 该研究为LLMs在情感计算中的应用提供了新的视角，强调了认知推理的重要性，并公开了基准和代码以促进未来研究。

Abstract: Affective Computing has been established as a crucial field of inquiry to
advance the holistic development of Artificial Intelligence (AI) systems.
Foundation models -- especially Large Language Models (LLMs) -- have been
evaluated, trained, or instruction-tuned in several past works, to become
better predictors or generators of emotion. Most of these studies, however,
approach emotion-related tasks in a supervised manner, assessing or training
the capabilities of LLMs using discrete emotion labels associated with stimuli
(e.g., text, images, video, audio). Evaluation studies, in particular, have
often been limited to standard and superficial emotion-related tasks, such as
the recognition of evoked or expressed emotions. In this paper, we move beyond
surface-level emotion tasks to investigate how LLMs reason about emotions
through cognitive dimensions. Drawing from cognitive appraisal theory, we
examine whether LLMs produce coherent and plausible cognitive reasoning when
reasoning about emotionally charged stimuli. We introduce a large-scale
benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal
cognitive structures implicitly used by LLMs for emotional reasoning. Through a
plethora of evaluation experiments and analysis, we seek to answer: (a) Are
models more likely to implicitly rely on specific cognitive appraisal
dimensions?, (b) What cognitive dimensions are important for characterizing
specific emotions?, and, (c) Can the internal representations of different
emotion categories in LLMs be interpreted through cognitive appraisal
dimensions? Our results and analyses reveal diverse reasoning patterns across
different LLMs. Our benchmark and code will be made publicly available.

</details>


### [36] [Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05909)
*Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui*

Main category: cs.CL

TL;DR: 论文提出了一种名为SPS的轻量级无监督指标，用于评估检索摘要与隐藏表示的语义对齐，并基于此开发了动态采样和压缩框架xCompress。实验表明SPS能提升任务性能并揭示检索与生成的交互机制。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法难以单独评估检索的真实贡献，尤其是LLM作为阅读器时的提示敏感性。

Method: 引入Spectrum Projection Score（SPS）指标，通过比较生成标记区域与子空间主方向来度量语义对齐；基于SPS开发xCompress框架动态处理检索摘要。

Result: 在五个QA基准测试和四种开源LLM上的实验显示，SPS提升了任务性能并提供了检索与生成交互的理论视角。

Conclusion: SPS为RAG提供了有效的评估工具，xCompress框架进一步优化了检索摘要的动态处理。

Abstract: Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

</details>


### [37] [Scaling Personality Control in LLMs with Big Five Scaler Prompts](https://arxiv.org/abs/2508.06149)
*Gunhee Cho,Yun-Gyung Cheong*

Main category: cs.CL

TL;DR: Big5-Scaler是一个基于提示的框架，用于控制大型语言模型的Big Five人格特质，无需额外训练即可实现细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 通过自然语言提示嵌入数值特质，实现对LLMs人格特质的可控调节。

Method: 在提示中嵌入数值特质，评估其在特质表达、对话生成和人类特质模仿任务中的表现。

Result: 结果显示，Big5-Scaler能诱导一致且可区分的人格特质，性能因提示类型和强度而异。

Conclusion: 简洁提示和较低特质强度更有效，为构建人格感知对话代理提供了高效方法。

Abstract: We present Big5-Scaler, a prompt-based framework for conditioning large
language models (LLMs) with controllable Big Five personality traits. By
embedding numeric trait values into natural language prompts, our method
enables fine-grained personality control without additional training. We
evaluate Big5-Scaler across trait expression, dialogue generation, and human
trait imitation tasks. Results show that it induces consistent and
distinguishable personality traits across models, with performance varying by
prompt type and scale. Our analysis highlights the effectiveness of concise
prompts and lower trait intensities, providing a efficient approach for
building personality-aware dialogue agents.

</details>


### [38] [Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale](https://arxiv.org/abs/2508.05938)
*Rafal Kocielnik,Min Kim,Penphob,Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 提出了一种三阶段流程，用于高效、低成本地检测文本中的亲社会性内容，结合人类与AI协作，显著降低了推理成本并提高了分类精度。


<details>
  <summary>Details</summary>
Motivation: 亲社会性检测在信任与安全系统中日益重要，但缺乏明确的定义和标注数据，需要新的标注和部署方法。

Method: 采用三阶段流程：1) 基于小规模人工标注数据选择最佳LLM标注策略；2) 人类与AI协作迭代优化任务定义；3) 训练两阶段推理系统，结合轻量级分类器和GPT-4o处理模糊实例。

Result: 减少了约70%的推理成本，同时实现了高精度（约0.90）。

Conclusion: 通过人类与AI的协作、任务定义的优化和部署感知的架构设计，为新兴责任AI任务提供了可扩展的解决方案。

Abstract: Detecting prosociality in text--communication intended to affirm, support, or
improve others' behavior--is a novel and increasingly important challenge for
trust and safety systems. Unlike toxic content detection, prosociality lacks
well-established definitions and labeled data, requiring new approaches to both
annotation and deployment. We present a practical, three-stage pipeline that
enables scalable, high-precision prosocial content classification while
minimizing human labeling effort and inference costs. First, we identify the
best LLM-based labeling strategy using a small seed set of human-labeled
examples. We then introduce a human-AI refinement loop, where annotators review
high-disagreement cases between GPT-4 and humans to iteratively clarify and
expand the task definition-a critical step for emerging annotation tasks like
prosociality. This process results in improved label quality and definition
alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train
a two-stage inference system: a lightweight classifier handles high-confidence
predictions, while only $\sim$35\% of ambiguous instances are escalated to
GPT-4o. This architecture reduces inference costs by $\sim$70% while achieving
high precision ($\sim$0.90). Our pipeline demonstrates how targeted human-AI
interaction, careful task formulation, and deployment-aware architecture design
can unlock scalable solutions for novel responsible AI tasks.

</details>


### [39] [Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring](https://arxiv.org/abs/2508.05987)
*Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu*

Main category: cs.CL

TL;DR: 论文提出了一种名为ATOP的新方法，通过联合学习主题共享和主题特定特征，改进跨主题自动作文评分（AES）。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注主题共享特征，忽略了主题特定特征，限制了评估关键特质（如主题一致性）的能力。

Method: ATOP通过优化可学习的主题感知提示（包含共享和特定组件）从预训练语言模型中提取相关知识，并结合对抗训练和邻居分类器。

Result: 在ASAP++数据集上的实验表明，ATOP在整体和多特质作文评分上显著优于现有方法。

Conclusion: ATOP通过联合学习主题共享和特定特征，提升了跨主题AES的性能。

Abstract: Cross-topic automated essay scoring (AES) aims to develop a transferable
model capable of effectively evaluating essays on a target topic. A significant
challenge in this domain arises from the inherent discrepancies between topics.
While existing methods predominantly focus on extracting topic-shared features
through distribution alignment of source and target topics, they often neglect
topic-specific features, limiting their ability to assess critical traits such
as topic adherence. To address this limitation, we propose an Adversarial
TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns
topic-shared and topic-specific features to improve cross-topic AES. ATOP
achieves this by optimizing a learnable topic-aware prompt--comprising both
shared and specific components--to elicit relevant knowledge from pre-trained
language models (PLMs). To enhance the robustness of topic-shared prompt
learning and mitigate feature scale sensitivity introduced by topic alignment,
we incorporate adversarial training within a unified regression and
classification framework. In addition, we employ a neighbor-based classifier to
model the local structure of essay representations and generate pseudo-labels
for target-topic essays. These pseudo-labels are then used to guide the
supervised learning of topic-specific prompts tailored to the target topic.
Extensive experiments on the publicly available ASAP++ dataset demonstrate that
ATOP significantly outperforms existing state-of-the-art methods in both
holistic and multi-trait essay scoring. The implementation of our method is
publicly available at: https://anonymous.4open.science/r/ATOP-A271.

</details>


### [40] [Large Language Model Data Generation for Enhanced Intent Recognition in German Speech](https://arxiv.org/abs/2508.06277)
*Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter*

Main category: cs.CL

TL;DR: 论文提出了一种结合Whisper ASR和Transformer语言模型的方法，用于德语老年人的语音意图识别，利用LLM生成合成数据提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有意图识别方法局限于短命令和英语的问题，专注于德语老年人的语音识别。

Method: 结合Whisper ASR和Transformer语言模型，利用LLM（LeoLM、Llama3、ChatGPT）生成合成数据，并通过TTS模型生成语音进行测试。

Result: 合成数据显著提升分类性能和鲁棒性，LeoLM在德语意图识别中表现优于ChatGPT。

Conclusion: 生成式AI可有效填补低资源领域的数据缺口，方法透明且可复现。

Abstract: Intent recognition (IR) for speech commands is essential for artificial
intelligence (AI) assistant systems; however, most existing approaches are
limited to short commands and are predominantly developed for English. This
paper addresses these limitations by focusing on IR from speech by elderly
German speakers. We propose a novel approach that combines an adapted Whisper
ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based
language models trained on synthetic text datasets generated by three
well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To
evaluate the robustness of our approach, we generate synthetic speech with a
text-to-speech model and conduct extensive cross-dataset testing. Our results
show that synthetic LLM-generated data significantly boosts classification
performance and robustness to different speaking styles and unseen vocabulary.
Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the
much larger ChatGPT (175B) in dataset quality for German intent recognition.
Our approach demonstrates that generative AI can effectively bridge data gaps
in low-resource domains. We provide detailed documentation of our data
generation and training process to ensure transparency and reproducibility.

</details>


### [41] [Memp: Exploring Agent Procedural Memory](https://arxiv.org/abs/2508.06433)
*Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 论文提出Memp方法，通过将代理轨迹提炼为细粒度指令和高级抽象，赋予代理可学习、可更新的终身程序记忆，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）代理在多样化任务中表现出色，但其程序记忆脆弱，依赖手动设计或静态参数。研究旨在解决这一问题。

Method: 提出Memp方法，将代理轨迹提炼为细粒度指令和高级抽象，并探索构建、检索和更新程序记忆的策略。

Result: 实验表明，随着记忆库的优化，代理在类似任务中的成功率和效率逐步提升，且记忆迁移至较弱模型也能带来显著性能提升。

Conclusion: Memp方法成功实现了代理程序记忆的动态更新和终身学习，显著提升了任务性能。

Abstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they
suffer from brittle procedural memory that is manually engineered or entangled
in static parameters. In this work, we investigate strategies to endow agents
with a learnable, updatable, and lifelong procedural memory. We propose Memp
that distills past agent trajectories into both fine-grained, step-by-step
instructions and higher-level, script-like abstractions, and explore the impact
of different strategies for Build, Retrieval, and Update of procedural memory.
Coupled with a dynamic regimen that continuously updates, corrects, and
deprecates its contents, this repository evolves in lockstep with new
experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as
the memory repository is refined, agents achieve steadily higher success rates
and greater efficiency on analogous tasks. Moreover, procedural memory built
from a stronger model retains its value: migrating the procedural memory to a
weaker model yields substantial performance gains.

</details>


### [42] [Crisp Attention: Regularizing Transformers via Structured Sparsity](https://arxiv.org/abs/2508.06016)
*Sagar Gandhi,Vishal Gandhi*

Main category: cs.CL

TL;DR: 通过在后处理中引入结构化稀疏性到DistilBERT模型的注意力机制中，模型在SST-2情感分析任务上的准确率显著提升，表明稀疏性可以作为隐式正则化器提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型中自注意力机制二次计算成本的问题，并探索稀疏性对模型性能的潜在积极影响。

Method: 在DistilBERT模型的注意力机制中引入结构化稀疏性，并在SST-2任务上进行微调。

Result: 80%稀疏性的模型验证准确率达到91.59%，比密集基线提高了0.97%。

Conclusion: 稀疏性不仅是计算效率工具，还能提升Transformer模型的泛化能力和性能。

Abstract: The quadratic computational cost of the self-attention mechanism is a primary
challenge in scaling Transformer models. While attention sparsity is widely
studied as a technique to improve computational efficiency, it is almost
universally assumed to come at the cost of model accuracy. In this paper, we
report a surprising counter-example to this common wisdom. By introducing
structured, post-hoc sparsity to the attention mechanism of a DistilBERT model
during fine-tuning on the SST-2 sentiment analysis task, we find that model
accuracy improves significantly. Our model with 80\% attention sparsity
achieves a validation accuracy of 91.59\%, a 0.97\% absolute improvement over
the dense baseline. We hypothesize that this phenomenon is due to sparsity
acting as a powerful implicit regularizer, preventing the model from
overfitting by forcing it to make predictions with a more constrained and
robust set of features. Our work recasts attention sparsity not just as a tool
for computational efficiency, but as a potential method for improving the
generalization and performance of Transformer models.

</details>


### [43] [Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future](https://arxiv.org/abs/2508.06026)
*Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种改进的自奖励语言模型架构，通过协调过去、现在和未来的模型输出来维持学习信号，解决了现有自奖励模型中对比样本差异逐渐缩小的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自奖励语言模型在同步改进选择和拒绝的响应时，对比样本的表示差异逐渐缩小，影响了偏好学习的有效性。

Method: 提出了双阶段框架：1) 锚定拒绝（固定初始模型的拒绝响应）；2) 未来引导选择（动态筛选未来模型的预测样本）。

Result: 在多个模型家族和规模上实验表明，该方法显著优于基线，例如Llama3.1-8B在AlpacaEval 2.0上的胜率提高了9.75。

Conclusion: 该方法不仅提升了性能，还表现出更强的泛化能力，适用于数学推理、知识问答和代码生成等任务。

Abstract: Self-Rewarding Language Models propose an architecture in which the Large
Language Models(LLMs) both generates responses and evaluates its own outputs
via LLM-as-a-Judge prompting, dynamically improving its generative capabilities
through iterative Direct Preference Optimization (DPO). However, our analysis
reveals a critical limitation in existing Self-Rewarding paradigms: the
synchronized improvement of chosen and rejected responses progressively narrows
the representational difference between contrasting samples, undermining
effective preference learning. We propose \textbf{Temporal Self-Rewarding
Language Models} that strategically coordinate past, present, and future model
generations to sustain learning signals. Our dual-phase framework introduces:
(1) \textit{Anchored Rejection} - fixing rejected responses using the past
initial model's outputs and (2) \textit{Future-Guided Chosen} - dynamically
curating chosen samples using next-generation model predictions. Extensive
experiments across three model families (Llama, Qwen, Mistral) and different
model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained
with our method compared to Self-Rewarding using same computation resources.
For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our
method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our
method also demonstrates superior out-of-distribution generalization across
mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code
generation (HumanEval) tasks, even though we do not specifically collect such
training data.

</details>


### [44] [Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings](https://arxiv.org/abs/2508.06030)
*Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar*

Main category: cs.CL

TL;DR: 论文提出PEEK方法，利用预训练嵌入模型预测大语言模型（LLM）的知识，避免直接探测的高计算成本。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的随机性，直接探测其知识成本高且耗时，需要一种高效替代方法。

Method: 通过嵌入模型（如文本或图嵌入）作为代理，训练线性解码器预测LLM的知识。

Result: 在多个数据集和模型上，嵌入模型预测LLM知识的准确率高达90%。

Conclusion: 知识适应的嵌入模型可大规模识别LLM的知识缺口，揭示其内部归纳偏好。

Abstract: Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

</details>


### [45] [EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](https://arxiv.org/abs/2508.06046)
*Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为EvolvR的自进化框架，通过多角色策略生成对齐分数的CoT数据，并通过多智能体过滤确保数据质量，最终提升故事评估和生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放任务（如故事评估）中表现有限，封闭源模型的提示工程适应性差，开源模型的微调缺乏严谨推理能力。

Method: 提出EvolvR框架，基于成对比较，通过多角色策略自合成对齐分数的CoT数据，并通过多智能体过滤确保逻辑严谨性。

Result: 在StoryER、HANNA和OpenMEVA三个基准测试中达到SOTA性能，并显著提升生成故事的质量。

Conclusion: EvolvR框架通过自进化方法有效解决了故事评估的局限性，验证了其优越性。

Abstract: Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

</details>


### [46] [ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline](https://arxiv.org/abs/2508.06094)
*Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš*

Main category: cs.CL

TL;DR: 利用现代LLMs作为计算创造力工具，开发了一个多阶段管道ConlangCrafter，用于端到端构建人工语言，并通过自反馈机制确保一致性和多样性。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用大规模基础模型（如LLMs）辅助人工语言（conlangs）的创造，以降低对语言学专业知识的需求。

Method: 提出ConlangCrafter，一个多阶段管道，分解语言设计为音系、形态、句法、词汇生成和翻译，利用LLMs的元语言推理能力和自反馈机制。

Result: 在一致性和类型多样性指标上表现良好，能够生成连贯且多样的人工语言。

Conclusion: ConlangCrafter展示了LLMs在人工语言创造中的潜力，无需人类语言学专业知识即可生成高质量结果。

Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

</details>


### [47] [Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs](https://arxiv.org/abs/2508.06103)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 论文提出两种提取式问答方法，针对《古兰经》的复杂语言和独特术语，结合大语言模型和专门阿拉伯语提示框架，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决《古兰经》文本中复杂语言、独特术语和深层含义带来的问答挑战。

Method: 1. 使用大语言模型（如Gemini和DeepSeek）进行少样本提示；2. 开发专门阿拉伯语提示框架；3. 强后处理系统整合子词对齐、重叠抑制和语义过滤。

Result: 大语言模型在阿拉伯语指令下表现优于传统微调模型，最佳配置pAP10得分为0.637。

Conclusion: 基于提示的指令调优对低资源、语义丰富的问答任务有效。

Abstract: This paper presents two effective approaches for Extractive Question
Answering (QA) on the Quran. It addresses challenges related to complex
language, unique terminology, and deep meaning in the text. The second uses
few-shot prompting with instruction-tuned large language models such as Gemini
and DeepSeek. A specialized Arabic prompt framework is developed for span
extraction. A strong post-processing system integrates subword alignment,
overlap suppression, and semantic filtering. This improves precision and
reduces hallucinations. Evaluations show that large language models with Arabic
instructions outperform traditional fine-tuned models. The best configuration
achieves a pAP10 score of 0.637. The results confirm that prompt-based
instruction tuning is effective for low-resource, semantically rich QA tasks.

</details>


### [48] [You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures](https://arxiv.org/abs/2508.06105)
*Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang*

Main category: cs.CL

TL;DR: LogicRAG框架通过动态构建逻辑依赖图优化检索增强生成，避免预建图的高成本，提升推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有GraphRAG方法因预建图导致的高成本和低灵活性，以及查询类型多样性与预建图结构不匹配的问题。

Method: 动态分解查询为子问题，构建有向无环图（DAG）建模逻辑依赖，通过拓扑排序线性化推理顺序，并结合图剪枝和上下文剪枝减少冗余。

Result: 实验表明LogicRAG在性能和效率上均优于现有基线方法。

Conclusion: LogicRAG通过动态逻辑结构提取和自适应检索，显著提升了检索增强生成的效果和效率。

Abstract: Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

</details>


### [49] [AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models](https://arxiv.org/abs/2508.06124)
*Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee*

Main category: cs.CL

TL;DR: 论文提出AURA框架，通过多层次的Process Reward Models（PRMs）解决LLMs在逻辑推理中的安全隐患，显著提升输出的逻辑完整性和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在逻辑推理中存在安全隐患，传统方法无法有效检测和干预，需要更细粒度和主动的解决方案。

Method: 引入AURA框架，结合自省式自我批判、细粒度PRM评估和自适应安全感知解码，动态引导模型推理。

Result: 实证表明，AURA显著优于现有方法，提升模型输出的逻辑完整性和安全性。

Conclusion: AURA为更安全、负责任的AI设立了新基准，推动了对齐敏感应用的发展。

Abstract: Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

</details>


### [50] [Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2508.06135)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为选择性反思蒸馏（SRD）的新框架，通过动态评估和筛选训练数据，提升知识蒸馏（KD）的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有白盒知识蒸馏方法忽视了训练数据质量和学生模型兼容性，限制了蒸馏效果。

Method: SRD利用学生模型的反馈动态筛选高质量、兼容的训练数据，并采用课程调度策略逐步引入数据。

Result: 实验表明SRD能显著提升蒸馏模型性能，并减少高达39%的训练时间。

Conclusion: 数据质量和兼容性是高效蒸馏的关键，SRD为提升压缩语言模型的能力和效率提供了实用框架。

Abstract: Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

</details>


### [51] [Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach](https://arxiv.org/abs/2508.06155)
*Renhan Zhang,Lian Lian,Zhen Qi,Guiran Liu*

Main category: cs.CL

TL;DR: 本文提出了一种可解释的偏见检测方法，用于识别大型语言模型输出中的隐性社会偏见，结合嵌套语义表示和上下文对比机制，验证了其在多维度上的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型生成过程中可能出现的隐性刻板印象问题，提供透明可靠的偏见检测技术基础。

Method: 结合嵌套语义表示与上下文对比机制，通过注意力权重扰动分析模型对特定社会属性词的敏感性，揭示偏见形成的语义路径。

Result: 实验表明，该方法在多个维度上具有强检测性能，能准确识别语义相似文本间的偏见差异，同时保持高语义对齐和输出稳定性。

Conclusion: 该方法设计具有高可解释性，适用于需要高可信生成内容的实际应用场景。

Abstract: This paper addresses the issue of implicit stereotypes that may arise during
the generation process of large language models. It proposes an interpretable
bias detection method aimed at identifying hidden social biases in model
outputs, especially those semantic tendencies that are not easily captured
through explicit linguistic features. The method combines nested semantic
representation with a contextual contrast mechanism. It extracts latent bias
features from the vector space structure of model outputs. Using attention
weight perturbation, it analyzes the model's sensitivity to specific social
attribute terms, thereby revealing the semantic pathways through which bias is
formed. To validate the effectiveness of the method, this study uses the
StereoSet dataset, which covers multiple stereotype dimensions including
gender, profession, religion, and race. The evaluation focuses on several key
metrics, such as bias detection accuracy, semantic consistency, and contextual
sensitivity. Experimental results show that the proposed method achieves strong
detection performance across various dimensions. It can accurately identify
bias differences between semantically similar texts while maintaining high
semantic alignment and output stability. The method also demonstrates high
interpretability in its structural design. It helps uncover the internal bias
association mechanisms within language models. This provides a more transparent
and reliable technical foundation for bias detection. The approach is suitable
for real-world applications where high trustworthiness of generated content is
required.

</details>


### [52] [One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging](https://arxiv.org/abs/2508.06163)
*Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: TADrop是一种自适应稀疏化策略，通过为每个参数张量分配定制化的稀疏度，优化模型合并性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法采用统一的稀疏化比例，忽略了参数的结构和统计异质性，导致关键参数被误剪或冗余参数被保留。

Method: TADrop根据参数张量的分布特性，动态调整稀疏度，密集冗余的张量被剪枝更多，稀疏关键的张量被保留。

Result: 在多种任务和模型上验证，TADrop显著提升性能，例如在ViT-B/32任务上平均提升2.0%。

Conclusion: TADrop通过自适应稀疏化有效减少参数干扰，为高性能模型合并提供了新基准。

Abstract: Model merging has emerged as a compelling data-free paradigm for multi-task
learning, enabling the fusion of multiple fine-tuned models into a single,
powerful entity. A key technique in merging methods is sparsification, which
prunes redundant parameters from task vectors to mitigate interference.
However, prevailing approaches employ a ``one-size-fits-all'' strategy,
applying a uniform sparsity ratio that overlooks the inherent structural and
statistical heterogeneity of model parameters. This often leads to a suboptimal
trade-off, where critical parameters are inadvertently pruned while less useful
ones are retained. To address this limitation, we introduce \textbf{TADrop}
(\textbf{T}ensor-wise \textbf{A}daptive \textbf{Drop}), an adaptive
sparsification strategy that respects this heterogeneity. Instead of a global
ratio, TADrop assigns a tailored sparsity level to each parameter tensor based
on its distributional properties. The core intuition is that tensors with
denser, more redundant distributions can be pruned aggressively, while sparser,
more critical ones are preserved. As a simple and plug-and-play module, we
validate TADrop by integrating it with foundational, classic, and SOTA merging
methods. Extensive experiments across diverse tasks (vision, language, and
multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and
significantly boosts their performance. For instance, when enhancing a leading
merging method, it achieves an average performance gain of 2.0\% across 8
ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter
interference by tailoring sparsification to the model's structure, offering a
new baseline for high-performance model merging.

</details>


### [53] [UR$^2$: Unify RAG and Reasoning through Reinforcement Learning](https://arxiv.org/abs/2508.06165)
*Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: UR2框架通过强化学习统一检索与推理，结合难度感知课程训练和混合知识访问策略，显著提升多任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG和RLVR方法在检索与推理能力上缺乏统一，限制了泛化性和应用范围。

Method: 提出UR2框架，包括难度感知课程训练和混合知识访问策略，动态协调检索与推理。

Result: 在多个任务上显著优于现有方法，性能接近GPT-4o-mini和GPT-4.1-mini。

Conclusion: UR2成功统一检索与推理，展示了广泛的应用潜力。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities through two
complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances
knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),
which optimizes complex reasoning abilities. However, these two capabilities
are often developed in isolation, and existing efforts to unify them remain
narrow in scope-typically limited to open-domain QA with fixed retrieval
settings and task-specific assumptions. This lack of integration constrains
generalization and limits the applicability of RAG-RL methods to broader
domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a
general framework that unifies retrieval and reasoning through reinforcement
learning. UR2 introduces two key contributions: a difficulty-aware curriculum
training that selectively invokes retrieval only for challenging problems, and
a hybrid knowledge access strategy combining domain-specific offline corpora
with LLM-generated summaries. These components are designed to enable dynamic
coordination between retrieval and reasoning, improving adaptability across a
diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,
and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B
and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,
achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several
benchmarks. We have released all code, models, and data at
https://github.com/Tsinghua-dhy/UR2.

</details>


### [54] [Pragmatics beyond humans: meaning, communication, and LLMs](https://arxiv.org/abs/2508.06167)
*Vít Gvoždiak*

Main category: cs.CL

TL;DR: 论文重新定义语用学为动态接口，探讨大语言模型（LLMs）对传统语用学理论的挑战，并提出人机通信（HMC）框架和概率语用学作为替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统语用学理论基于人类中心假设，难以适用于LLMs等预测系统，需重新思考语用学在AI通信中的角色。

Method: 通过分析传统符号学三分法的局限性，提出HMC框架；探讨概率语用学（如理性言语行为框架）的适用性；分析替代主义问题及语境挫折现象。

Result: 传统语用学理论需调整以适配LLMs，概率语用学更适用于优化目标；语境挫折现象揭示了用户与模型共同构建语用条件的必要性。

Conclusion: 语用学理论需扩展以适应生成式AI的通信需求，强调动态接口和共同构建语用条件的重要性。

Abstract: The paper reconceptualizes pragmatics not as a subordinate, third dimension
of meaning, but as a dynamic interface through which language operates as a
socially embedded tool for action. With the emergence of large language models
(LLMs) in communicative contexts, this understanding needs to be further
refined and methodologically reconsidered. The first section challenges the
traditional semiotic trichotomy, arguing that connectionist LLM architectures
destabilize established hierarchies of meaning, and proposes the Human-Machine
Communication (HMC) framework as a more suitable alternative. The second
section examines the tension between human-centred pragmatic theories and the
machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics
continue to dominate, it relies on human-specific assumptions ill-suited to
predictive systems like LLMs. Probabilistic pragmatics, particularly the
Rational Speech Act framework, offers a more compatible teleology by focusing
on optimization rather than truth-evaluation. The third section addresses the
issue of substitutionalism in three forms - generalizing, linguistic, and
communicative - highlighting the anthropomorphic biases that distort LLM
evaluation and obscure the role of human communicative subjects. Finally, the
paper introduces the concept of context frustration to describe the paradox of
increased contextual input paired with a collapse in contextual understanding,
emphasizing how users are compelled to co-construct pragmatic conditions both
for the model and themselves. These arguments suggest that pragmatic theory may
need to be adjusted or expanded to better account for communication involving
generative AI.

</details>


### [55] [Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime](https://arxiv.org/abs/2508.06178)
*Hugo Abonizio,Thales Almeida,Roberto Lotufo,Rodrigo Nogueira*

Main category: cs.CL

TL;DR: 论文研究了如何向大语言模型（LLM）注入少量非结构化信息，探讨了与灾难性遗忘现象的关系，并通过实验比较了不同数据增强方法的效果。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在少量数据下难以有效学习新知识的问题，并研究灾难性遗忘现象。

Method: 使用新闻数据集评估知识获取能力，比较了持续预训练和数据增强方法，特别是多样提示生成合成数据。

Result: 数据增强方法显著提升了新知识的学习效果，但RAG方法在控制数据集上表现较差。模型能生成有效的合成数据。

Conclusion: 多样化的数据增强方法能有效提升LLM在少量数据下的学习能力，同时揭示了灾难性遗忘的平衡问题。

Abstract: Large language models (LLMs) often require vast amounts of text to
effectively acquire new knowledge. While continuing pre-training on large
corpora or employing retrieval-augmented generation (RAG) has proven
successful, updating an LLM with only a few thousand or million tokens remains
challenging. In this work, we investigate the task of injecting small,
unstructured information into LLMs and its relation to the catastrophic
forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap
with the model's pre-training data -- to evaluate the knowledge acquisition by
probing the model with question-answer pairs related the learned information.
Starting from a continued pre-training baseline, we explored different
augmentation algorithms to generate synthetic data to improve the knowledge
acquisition capabilities. Our experiments show that simply continuing
pre-training on limited data yields modest improvements, whereas exposing the
model to diverse textual variations significantly improves the learning of new
facts -- particularly with methods that induce greater variability through
diverse prompting. Furthermore, we shed light on the forgetting phenomenon in
small-data regimes, illustrating the delicate balance between learning new
content and retaining existing capabilities. We also confirm the sensitivity of
RAG-based approaches for knowledge injection, which often lead to greater
degradation on control datasets compared to parametric methods. Finally, we
demonstrate that models can generate effective synthetic training data
themselves, suggesting a pathway toward self-improving model updates. All code
and generated data used in our experiments are publicly available, providing a
resource for studying efficient knowledge injection in LLMs with limited data
at https://github.com/hugoabonizio/knowledge-injection-methods.

</details>


### [56] [DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration](https://arxiv.org/abs/2508.06186)
*Ali Sarabadani,Maryam Abdollahi Shamami,Hamidreza Sadeghsalehi,Borhan Asadi,Saba Hesaraki*

Main category: cs.CL

TL;DR: DKG-LLM框架通过动态知识图谱与Grok 3大语言模型结合，提出了一种创新的医疗诊断和个性化治疗推荐方法，取得了高准确率和语义覆盖率。


<details>
  <summary>Details</summary>
Motivation: 提升医疗诊断和个性化治疗的准确性，整合异构医疗数据并动态更新知识图谱。

Method: 结合动态知识图谱（DKG）与Grok 3大语言模型，使用自适应语义融合算法（ASFA）处理医疗数据。

Result: 诊断准确率84.19%，治疗推荐准确率89.63%，语义覆盖率93.48%。

Conclusion: DKG-LLM是一种可靠且具有变革性的工具，适用于复杂医疗场景。

Abstract: Large Language Models (LLMs) have grown exponentially since the release of
ChatGPT. These models have gained attention due to their robust performance on
various tasks, including language processing tasks. These models achieve
understanding and comprehension of tasks by training billions of parameters.
The development of these models is a transformative force in enhancing natural
language understanding and has taken a significant step towards artificial
general intelligence (AGI). In this study, we aim to present the DKG-LLM
framework. The DKG-LLM framework introduces a groundbreaking approach to
medical diagnosis and personalized treatment recommendations by integrating a
dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the
Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data
(including clinical reports and PubMed articles) and patient records
dynamically generate a knowledge graph consisting of 15,964 nodes in 13
distinct types (e.g., diseases, symptoms, treatments, patient profiles) and
127,392 edges in 26 relationship types (e.g., causal, therapeutic,
association). ASFA utilizes advanced probabilistic models, Bayesian inference,
and graph optimization to extract semantic information, dynamically updating
the graph with approximately 150 new nodes and edges in each data category
while maintaining scalability with up to 987,654 edges. Real-world datasets,
including MIMIC-III and PubMed, were utilized to evaluate the proposed
architecture. The evaluation results show that DKG-LLM achieves a diagnostic
accuracy of 84.19%. The model also has a treatment recommendation accuracy of
89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and
transformative tool that handles noisy data and complex multi-symptom diseases,
along with feedback-based learning from physician input.

</details>


### [57] [Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation](https://arxiv.org/abs/2508.06194)
*Lai Jiang,Yuekang Li,Xiaohan Zhang,Youtao Ding,Li Pan*

Main category: cs.CL

TL;DR: SceneJailEval提出了一种场景自适应的多维度框架，用于精确评估LLM越狱行为，解决了现有方法的局限性，并在多个场景中取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有越狱评估方法多为二元分类或多维度统一标准，无法量化危害强度且存在场景不匹配问题，限制了评估的精确性。

Method: 提出SceneJailEval框架，包含场景自适应多维度评估标准和14个场景的数据集，支持灵活扩展。

Result: 在完整场景数据集上F1得分为0.917（比现有最优高6%），在JBB上为0.995（高3%），验证了其优越性。

Conclusion: SceneJailEval通过场景自适应框架和高质量数据集，显著提升了越狱评估的精确性和适用性。

Abstract: Precise jailbreak evaluation is vital for LLM red teaming and jailbreak
research. Current approaches employ binary classification ( e.g., string
matching, toxic text classifiers, LLM-driven methods), yielding only "yes/no"
labels without quantifying harm intensity. Existing multi-dimensional
frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)
apply uniform evaluation criteria across scenarios, resulting in
scenario-specific mismatches--for instance, "Relative Truthfulness" is
irrelevant to "hate speech"--which compromise evaluation precision. To tackle
these limitations, we introduce SceneJailEval, with key contributions: (1) A
groundbreaking scenario-adaptive multi-dimensional framework for jailbreak
evaluation, overcoming the critical "one-size-fits-all" constraint of existing
multi-dimensional methods, and featuring strong extensibility to flexibly adapt
to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset
with diverse jailbreak variants and regional cases, filling the long-standing
gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)
SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on
our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over
prior SOTA), surpassing accuracy limits of existing evaluation methods in
heterogeneous scenarios and confirming its advantage.

</details>


### [58] [EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations](https://arxiv.org/abs/2508.06196)
*Nizi Nazar,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: 论文提出了一个针对大语言模型（LLMs）的情感智能（EI）四层分类法，并开发了EICAP-Bench基准测试。通过评估六种LLMs，发现Qwen2.5-Instruct表现最佳。微调实验显示，仅Appraisal层通过数据微调有显著提升，揭示了现有预训练和指令调优在情感推理上的局限性。


<details>
  <summary>Details</summary>
Motivation: 情感智能（EI）在人类对齐的大语言模型（LLMs）中是一个重要但未被充分探索的维度。

Method: 提出了一个心理学基础的四层EI分类法，并开发了EICAP-Bench基准测试。评估了六种LLMs，并通过LoRA适配器对Qwen2.5模型在UltraChat数据集上进行微调。

Result: Qwen2.5-Instruct表现最佳；微调仅显著提升了Appraisal层的能力。

Conclusion: 现有预训练和指令调优方法在情感推理上存在局限，需针对性数据和建模策略以实现全面EI对齐。

Abstract: Emotional Intelligence (EI) is a critical yet underexplored dimension in the
development of human-aligned LLMs. To address this gap, we introduce a unified,
psychologically grounded four-layer taxonomy of EI tailored for large language
models (LLMs), encompassing emotional tracking, cause inference, appraisal, and
emotionally appropriate response generation. Building on this framework, we
present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to
evaluate EI capabilities in open-source LLMs across diverse linguistic and
cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma
(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,
identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential
for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and
Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,
instruction-tuned dialogue dataset, in both English and Arabic. Our statistical
analysis reveals that among the five EI layers, only the Appraisal layer shows
significant improvement through UC-based fine-tuning. These findings highlight
the limitations of existing pretraining and instruction-tuning paradigms in
equipping LLMs with deeper emotional reasoning and underscore the need for
targeted data and modeling strategies for comprehensive EI alignment.

</details>


### [59] [Classification is a RAG problem: A case study on hate speech detection](https://arxiv.org/abs/2508.06204)
*Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen*

Main category: cs.CL

TL;DR: 论文提出了一种基于检索增强生成（RAG）的分类方法，用于内容审核，能够动态适应政策变化而无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 传统分类系统难以快速适应政策变化，需要昂贵的重新训练。本文旨在通过RAG方法实现灵活、透明的分类过程。

Method: 采用检索增强生成（RAG）技术，将分类任务从依赖预训练参数转向基于推理时检索的上下文知识评估。提出了Contextual Policy Engine（CPE）系统。

Result: 实验表明，CPE在分类准确性上与主流商业系统相当，支持动态政策更新，并能精细调整特定身份群体的保护策略。

Conclusion: RAG方法能够将分类任务转变为更灵活、透明和可适应的过程，适用于内容审核及其他分类问题。

Abstract: Robust content moderation requires classification systems that can quickly
adapt to evolving policies without costly retraining. We present classification
using Retrieval-Augmented Generation (RAG), which shifts traditional
classification tasks from determining the correct category in accordance with
pre-trained parameters to evaluating content in relation to contextual
knowledge retrieved at inference. In hate speech detection, this transforms the
task from "is this hate speech?" to "does this violate the hate speech policy?"
  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates
this approach and offers three key advantages: (1) robust classification
accuracy comparable to leading commercial systems, (2) inherent explainability
via retrieved policy segments, and (3) dynamic policy updates without model
retraining. Through three experiments, we demonstrate strong baseline
performance and show that the system can apply fine-grained policy control by
correctly adjusting protection for specific identity groups without requiring
retraining or compromising overall performance. These findings establish that
RAG can transform classification into a more flexible, transparent, and
adaptable process for content moderation and wider classification problems.

</details>


### [60] [InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?](https://arxiv.org/abs/2508.06220)
*Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu*

Main category: cs.CL

TL;DR: InfoCausalQA是一个新的多模态基准，用于评估视觉语言模型在基于信息图的因果推理能力，发现当前模型在计算和语义因果推理方面表现有限。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在因果推理方面的能力，填补多模态环境中这一核心认知能力的空白。

Method: 构建InfoCausalQA基准，包含定量和语义因果推理任务，使用GPT-4o生成问题并由人工修订。

Result: 当前模型在计算和语义因果推理方面表现不佳，与人类能力存在显著差距。

Conclusion: 需要提升多模态AI系统的因果推理能力，InfoCausalQA为此提供了评估工具。

Abstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive
capabilities in perception and reasoning. However, the ability to perform
causal inference -- a core aspect of human cognition -- remains underexplored,
particularly in multimodal settings. In this study, we introduce InfoCausalQA,
a novel benchmark designed to evaluate causal reasoning grounded in
infographics that combine structured visual data with textual context. The
benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning
based on inferred numerical trends, while Task 2 targets semantic causal
reasoning involving five types of causal relations: cause, effect,
intervention, counterfactual, and temporal. We manually collected 494
infographic-text pairs from four public sources and used GPT-4o to generate
1,482 high-quality multiple-choice QA pairs. These questions were then
carefully revised by humans to ensure they cannot be answered based on
surface-level cues alone but instead require genuine visual grounding. Our
experimental results reveal that current VLMs exhibit limited capability in
computational reasoning and even more pronounced limitations in semantic causal
reasoning. Their significantly lower performance compared to humans indicates a
substantial gap in leveraging infographic-based information for causal
inference. Through InfoCausalQA, we highlight the need for advancing the causal
reasoning abilities of multimodal AI systems.

</details>


### [61] [Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC](https://arxiv.org/abs/2508.06309)
*Ruichong Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为MDIR的新方法，用于检测大型语言模型（LLM）的抄袭行为，解决了现有方法在权重对应重建、统计显著性计算和误报方面的不足。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型（LLM）的知识产权（IP）问题日益突出，现有抄袭检测方法存在局限性，亟需更准确的解决方案。

Method: MDIR利用矩阵分析和大偏差理论，无需完整模型推理即可准确重建权重关系并提供严格的p值估计。

Result: 实验表明，MDIR即使在模型经过随机置换或持续预训练等复杂变换后，仍能可靠检测抄袭，且检测过程高效（单台PC一小时内完成）。

Conclusion: MDIR是一种高效、准确的LLM抄袭检测方法，解决了现有技术的不足，具有实际应用价值。

Abstract: In recent years, concerns about intellectual property (IP) in large language
models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct
weight copying, upcycling, pruning, or continual pretraining) and claiming
authorship without properly attributing to the original license, is a serious
misconduct that can lead to significant financial and reputational harm to the
original developers. However, existing methods for detecting LLM plagiarism
fall short in key areas. They fail to accurately reconstruct weight
correspondences, lack the ability to compute statistical significance measures
such as $p$-values, and may mistakenly flag models trained on similar data as
being related. To address these limitations, we propose Matrix-Driven Instant
Review (MDIR), a novel method that leverages matrix analysis and Large
Deviation Theory. MDIR achieves accurate reconstruction of weight
relationships, provides rigorous $p$-value estimation, and focuses exclusively
on weight similarity without requiring full model inference. Experimental
results demonstrate that MDIR reliably detects plagiarism even after extensive
transformations, such as random permutations and continual pretraining with
trillions of tokens. Moreover, all detections can be performed on a single PC
within an hour, making MDIR both efficient and accessible.

</details>


### [62] [Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering](https://arxiv.org/abs/2508.06345)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang*

Main category: cs.CL

TL;DR: 论文提出DynamicTRF框架，通过动态选择适合的图表示形式（TRF）和引入新指标GRE，提升大型多模态模型在零样本图问答任务中的准确性和简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用单一图表示形式（TRF），忽略了不同模型或任务的特定需求，导致回答不准确或冗长。

Method: 设计了一组零样本图问答专用的TRF（$F_{ZS}$），引入GRE指标衡量性能与简洁性，并开发DynamicTRF框架，通过TRFP数据集和TRF路由器动态选择最佳TRF。

Result: 在7个领域内算法图问答任务和2个领域外下游任务中，DynamicTRF显著提升了零样本图问答的准确性。

Conclusion: DynamicTRF通过动态TRF选择和GRE指标，有效解决了现有方法的局限性，提升了图问答任务的性能。

Abstract: Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities
in diverse domain question-answering (QA) tasks, including graph QA that
involves complex graph topologies. However, most current approaches use only a
single type of graph representation, namely Topology Representation Form (TRF),
such as prompt-unified text descriptions or style-fixed visual styles. Those
"one-size-fits-all" approaches fail to consider the specific preferences of
different models or tasks, often leading to incorrect or overly long responses.
To address this, we first analyze the characteristics and weaknesses of
existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to
zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency
(GRE), which measures the balance between the performance and the brevity in
graph QA. Built on these, we develop the DynamicTRF framework, which aims to
improve both the accuracy and conciseness of graph QA. To be specific,
DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based
on their GRE scores, to probe the question-specific TRF preferences. Then it
trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from
$F_{ZS}$ for each question during the inference. Extensive experiments across 7
in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show
that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms
of accuracy

</details>


### [63] [Cyberbullying Detection via Aggression-Enhanced Prompting](https://arxiv.org/abs/2508.06360)
*Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 研究探讨了通过将攻击性检测作为辅助任务，提升大语言模型在社交媒体网络欺凌检测中的性能。实验表明，通过丰富提示管道的方法优于标准微调。


<details>
  <summary>Details</summary>
Motivation: 网络欺凌检测因表达形式多样且隐蔽而具有挑战性，研究旨在通过辅助任务提升模型性能。

Method: 采用指令调优的大语言模型，评估零样本、少样本、独立LoRA微调和多任务学习策略，并提出丰富提示管道方法。

Result: 丰富提示管道方法在性能上优于标准LoRA微调，表明攻击性检测辅助任务能显著提升网络欺凌检测。

Conclusion: 辅助任务（如攻击性检测）可提升大语言模型在安全关键应用中的泛化能力。

Abstract: Detecting cyberbullying on social media remains a critical challenge due to
its subtle and varied expressions. This study investigates whether integrating
aggression detection as an auxiliary task within a unified training framework
can enhance the generalisation and performance of large language models (LLMs)
in cyberbullying detection. Experiments are conducted on five aggression
datasets and one cyberbullying dataset using instruction-tuned LLMs. We
evaluated multiple strategies: zero-shot, few-shot, independent LoRA
fine-tuning, and multi-task learning (MTL). Given the inconsistent results of
MTL, we propose an enriched prompt pipeline approach in which aggression
predictions are embedded into cyberbullying detection prompts to provide
contextual augmentation. Preliminary results show that the enriched prompt
pipeline consistently outperforms standard LoRA fine-tuning, indicating that
aggression-informed context significantly boosts cyberbullying detection. This
study highlights the potential of auxiliary tasks, such as aggression
detection, to improve the generalisation of LLMs for safety-critical
applications on social networks.

</details>


### [64] [Evaluating Style-Personalized Text Generation: Challenges and Directions](https://arxiv.org/abs/2508.06374)
*Anubhav Jangra,Bahareh Sarrafzadeh,Adrian de Wynter,Silviu Cucerzan,Sujay Kumar Jauhar*

Main category: cs.CL

TL;DR: 本文探讨了低资源作者风格个性化文本生成中的评估问题，质疑了BLEU和ROUGE等常用指标的适用性，并提出了风格嵌入和LLM-as-judge等新评估范式。


<details>
  <summary>Details</summary>
Motivation: 现有研究在低资源作者风格个性化文本生成领域的评估探索有限，作者希望通过研究更全面的评估方法填补这一空白。

Method: 作者通过一个涵盖八种写作任务的风格判别基准，评估了多种指标及其组合，包括领域判别、作者归属和LLM个性化与非个性化判别。

Result: 研究结果表明，采用多样化的评估指标组合能更有效地评估风格个性化文本生成任务。

Conclusion: 结论支持采用多样化的评估指标组合来全面评估风格个性化文本生成。

Abstract: While prior research has built tools and benchmarks towards style
personalized text generation, there has been limited exploration of evaluation
in low-resource author style personalized text generation space. Through this
work, we question the effectiveness of the widely adopted evaluation metrics
like BLEU and ROUGE, and explore other evaluation paradigms such as style
embeddings and LLM-as-judge to holistically evaluate the style personalized
text generation task. We evaluate these metrics and their ensembles using our
style discrimination benchmark, that spans eight writing tasks, and evaluates
across three settings, domain discrimination, authorship attribution, and LLM
personalized vs non-personalized discrimination. We provide conclusive evidence
to adopt ensemble of diverse evaluation metrics to effectively evaluate style
personalized text generation.

</details>


### [65] [LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing](https://arxiv.org/abs/2508.06388)
*Lanlan Qiu,Xiao Pu,Yeqi Feng,Tianxing He*

Main category: cs.CL

TL;DR: 论文提出ChatAnime数据集，结合LLMs的角色扮演和情感支持能力，评估其在动漫角色情感支持对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 填补LLMs在情感支持与角色扮演结合领域的研究空白，以动漫角色为案例研究。

Method: 通过全国选拔40名动漫爱好者，设计60个情感场景问题，收集10个LLMs和人类的两轮对话数据，并设计多维度评估系统。

Result: 表现最佳的LLMs在角色扮演和情感支持上超越人类，但人类在回答多样性上仍占优。

Conclusion: ChatAnime为优化LLMs在情感支持角色扮演领域提供了资源和见解。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing conversations and providing emotional support as separate research
directions. However, there remains a significant research gap in combining
these capabilities to enable emotionally supportive interactions with virtual
characters. To address this research gap, we focus on anime characters as a
case study because of their well-defined personalities and large fan bases.
This choice enables us to effectively evaluate how well LLMs can provide
emotional support while maintaining specific character traits. We introduce
ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We
first thoughtfully select 20 top-tier characters from popular anime communities
and design 60 emotion-centric real-world scenario questions. Then, we execute a
nationwide selection process to identify 40 Chinese anime enthusiasts with
profound knowledge of specific characters and extensive experience in
role-playing. Next, we systematically collect two rounds of dialogue data from
10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP
performance of LLMs, we design a user experience-oriented evaluation system
featuring 9 fine-grained metrics across three dimensions: basic dialogue,
role-playing and emotional support, along with an overall metric for response
diversity. In total, the dataset comprises 2,400 human-written and 24,000
LLM-generated answers, supported by over 132,000 human annotations.
Experimental results show that top-performing LLMs surpass human fans in
role-playing and emotional support, while humans still lead in response
diversity. We hope this work can provide valuable resources and insights for
future research on optimizing LLMs in ESRP. Our datasets are available at
https://github.com/LanlanQiu/ChatAnime.

</details>


### [66] [Quantifying Conversation Drift in MCP via Latent Polytope](https://arxiv.org/abs/2508.06418)
*Haoran Shi,Hongwei Yao,Shuo Shao,Shaopeng Jiao,Ziqi Peng,Zhan Qin,Cong Wang*

Main category: cs.CL

TL;DR: SecMCP是一个安全框架，通过检测和量化对话漂移来增强MCP的安全性，防止工具中毒和间接提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: MCP在动态聚合实时数据时存在安全和隐私风险，现有防御方法效果不足。

Method: SecMCP利用潜在多面体空间建模LLM激活向量，识别对话动态异常。

Result: 在多个LLM和数据集上测试，AUROC分数超过0.915，系统可用性良好。

Conclusion: SecMCP有效解决了MCP的安全威胁，并提供了新的量化方法。

Abstract: The Model Context Protocol (MCP) enhances large language models (LLMs) by
integrating external tools, enabling dynamic aggregation of real-time data to
improve task execution. However, its non-isolated execution context introduces
critical security and privacy risks. In particular, adversarially crafted
content can induce tool poisoning or indirect prompt injection, leading to
conversation hijacking, misinformation propagation, or data exfiltration.
Existing defenses, such as rule-based filters or LLM-driven detection, remain
inadequate due to their reliance on static signatures, computational
inefficiency, and inability to quantify conversational hijacking. To address
these limitations, we propose SecMCP, a secure framework that detects and
quantifies conversation drift, deviations in latent space trajectories induced
by adversarial external knowledge. By modeling LLM activation vectors within a
latent polytope space, SecMCP identifies anomalous shifts in conversational
dynamics, enabling proactive detection of hijacking, misleading, and data
exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,
Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),
demonstrating robust detection with AUROC scores exceeding 0.915 while
maintaining system usability. Our contributions include a systematic
categorization of MCP security threats, a novel latent polytope-based
methodology for quantifying conversation drift, and empirical validation of
SecMCP's efficacy.

</details>


### [67] [Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages](https://arxiv.org/abs/2508.06435)
*Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain*

Main category: cs.CL

TL;DR: 研究表明，轻量级LLaMA模型通过少量语言微调即可实现跨语言主题检测，且多语言微调有助于立场分类。预训练偏见可通过少量干预纠正，开源模型成本极低。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在少量语言微调后是否能在未见语言中实现知识迁移，并纠正预训练中的语言偏见。

Method: 在单语、双语或多语数据集上微调LLaMA模型，用于13种语言的移民相关推文分类。

Result: 单语或双语微调模型能可靠分类未见语言的移民内容，多语言微调提升立场分类效果。预训练偏见可通过少量干预纠正。

Conclusion: 跨语言能力无需大量多语言训练，轻量干预可纠正偏见，开源模型提供高效低成本解决方案。

Abstract: Large language models (LLMs) are transforming social-science research by
enabling scalable, precise analysis. Their adaptability raises the question of
whether knowledge acquired through fine-tuning in a few languages can transfer
to unseen languages that only appeared during pre-training. To examine this, we
fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or
multilingual data sets to classify immigration-related tweets from X/Twitter
across 13 languages, a domain characterised by polarised, culturally specific
discourse. We evaluate whether minimal language-specific fine-tuning enables
cross-lingual topic detection and whether adding targeted languages corrects
pre-training biases. Results show that LLMs fine-tuned in one or two languages
can reliably classify immigration-related content in unseen languages. However,
identifying whether a tweet expresses a pro- or anti-immigration stance
benefits from multilingual fine-tuning. Pre-training bias favours dominant
languages, but even minimal exposure to under-represented languages during
fine-tuning (as little as $9.62\times10^{-11}$ of the original pre-training
token volume) yields significant gains. These findings challenge the assumption
that cross-lingual mastery requires extensive multilingual training: limited
language coverage suffices for topic-level generalisation, and structural
biases can be corrected with lightweight interventions. By releasing
4-bit-quantised, LoRA fine-tuned models, we provide an open-source,
reproducible alternative to proprietary LLMs that delivers 35 times faster
inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,
enabling scalable, inclusive research.

</details>


### [68] [Echoes of Automation: The Increasing Use of LLMs in Newsmaking](https://arxiv.org/abs/2508.06445)
*Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee*

Main category: cs.CL

TL;DR: 研究发现，生成式AI（尤其是LLMs）在新闻写作中的使用显著增加，尤其是在地方和校园媒体中，AI多用于新闻开头，而结论多为人工撰写。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI对新闻行业诚信和作者身份的潜在影响。

Method: 分析40,000多篇新闻文章，使用三种AI文本检测工具（Binoculars、Fast-Detect GPT、GPTZero），并进行句子级和语言学分析。

Result: AI使用量近年显著增加，提升了词汇丰富度和可读性，但降低了正式性，导致写作风格趋同。

Conclusion: 生成式AI在新闻写作中的应用日益普遍，需关注其对新闻风格和诚信的影响。

Abstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns
for journalistic integrity and authorship. This study examines AI-generated
content across over 40,000 news articles from major, local, and college news
media, in various media formats. Using three advanced AI-text detectors (e.g.,
Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of
GenAI use in recent years, especially in local and college news. Sentence-level
analysis reveals LLMs are often used in the introduction of news, while
conclusions usually written manually. Linguistic analysis shows GenAI boosts
word richness and readability but lowers formality, leading to more uniform
writing styles, particularly in local media.

</details>


### [69] [SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning](https://arxiv.org/abs/2508.06447)
*Lingkun Long,Rubing Yang,Yushi Huang,Desheng Hui,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: SlimInfer通过动态剪枝冗余提示令牌加速LLM推理，减少计算和内存开销，提升效率。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理对LLM计算需求高，现有方法效率有限，需优化隐藏状态处理。

Method: 提出动态细粒度剪枝机制，逐层剪枝隐藏状态冗余令牌，结合异步KV缓存管理。

Result: 实验显示TTFT加速2.53倍，端到端延迟降低1.88倍，性能无损。

Conclusion: SlimInfer高效加速LLM推理，适用于长上下文任务。

Abstract: Long-context inference for Large Language Models (LLMs) is heavily limited by
high computational demands. While several existing methods optimize attention
computation, they still process the full set of hidden states at each layer,
limiting overall efficiency. In this work, we propose SlimInfer, an innovative
framework that aims to accelerate inference by directly pruning less critical
prompt tokens during the forward pass. Our key insight is an information
diffusion phenomenon: As information from critical tokens propagates through
layers, it becomes distributed across the entire sequence. This diffusion
process suggests that LLMs can maintain their semantic integrity when excessive
tokens, even including these critical ones, are pruned in hidden states.
Motivated by this, SlimInfer introduces a dynamic fine-grained pruning
mechanism that accurately removes redundant tokens of hidden state at
intermediate layers. This layer-wise pruning naturally enables an asynchronous
KV cache manager that prefetches required token blocks without complex
predictors, reducing both memory usage and I/O costs. Extensive experiments
show that SlimInfer can achieve up to $\mathbf{2.53\times}$ time-to-first-token
(TTFT) speedup and $\mathbf{1.88\times}$ end-to-end latency reduction for
LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on
LongBench. Our code will be released upon acceptance.

</details>


### [70] [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471)
*GLM-4. 5 Team,:,Aohan Zeng,Xin Lv,Qinkai Zheng,Zhenyu Hou,Bin Chen,Chengxing Xie,Cunxiang Wang,Da Yin,Hao Zeng,Jiajie Zhang,Kedong Wang,Lucen Zhong,Mingdao Liu,Rui Lu,Shulin Cao,Xiaohan Zhang,Xuancheng Huang,Yao Wei,Yean Cheng,Yifan An,Yilin Niu,Yuanhao Wen,Yushi Bai,Zhengxiao Du,Zihan Wang,Zilin Zhu,Bohan Zhang,Bosi Wen,Bowen Wu,Bowen Xu,Can Huang,Casey Zhao,Changpeng Cai,Chao Yu,Chen Li,Chendi Ge,Chenghua Huang,Chenhui Zhang,Chenxi Xu,Chenzheng Zhu,Chuang Li,Congfeng Yin,Daoyan Lin,Dayong Yang,Dazhi Jiang,Ding Ai,Erle Zhu,Fei Wang,Gengzheng Pan,Guo Wang,Hailong Sun,Haitao Li,Haiyang Li,Haiyi Hu,Hanyu Zhang,Hao Peng,Hao Tai,Haoke Zhang,Haoran Wang,Haoyu Yang,He Liu,He Zhao,Hongwei Liu,Hongxi Yan,Huan Liu,Huilong Chen,Ji Li,Jiajing Zhao,Jiamin Ren,Jian Jiao,Jiani Zhao,Jianyang Yan,Jiaqi Wang,Jiayi Gui,Jiayue Zhao,Jie Liu,Jijie Li,Jing Li,Jing Lu,Jingsen Wang,Jingwei Yuan,Jingxuan Li,Jingzhao Du,Jinhua Du,Jinxin Liu,Junkai Zhi,Junli Gao,Ke Wang,Lekang Yang,Liang Xu,Lin Fan,Lindong Wu,Lintao Ding,Lu Wang,Man Zhang,Minghao Li,Minghuan Xu,Mingming Zhao,Mingshu Zhai,Pengfan Du,Qian Dong,Shangde Lei,Shangqing Tu,Shangtong Yang,Shaoyou Lu,Shijie Li,Shuang Li,Shuang-Li,Shuxun Yang,Sibo Yi,Tianshu Yu,Wei Tian,Weihan Wang,Wenbo Yu,Weng Lam Tam,Wenjie Liang,Wentao Liu,Xiao Wang,Xiaohan Jia,Xiaotao Gu,Xiaoying Ling,Xin Wang,Xing Fan,Xingru Pan,Xinyuan Zhang,Xinze Zhang,Xiuqing Fu,Xunkai Zhang,Yabo Xu,Yandong Wu,Yida Lu,Yidong Wang,Yilin Zhou,Yiming Pan,Ying Zhang,Yingli Wang,Yingru Li,Yinpei Su,Yipeng Geng,Yitong Zhu,Yongkun Yang,Yuhang Li,Yuhao Wu,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yuxuan Zhang,Zezhen Liu,Zhen Yang,Zhengda Zhou,Zhongpei Qiao,Zhuoer Feng,Zhuorui Liu,Zichen Zhang,Zihan Wang,Zijun Yao,Zikang Wang,Ziqiang Liu,Ziwei Chai,Zixuan Li,Zuodong Zhao,Wenguang Chen,Jidong Zhai,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.CL

TL;DR: GLM-4.5是一个开源的混合专家（MoE）大语言模型，总参数量355B，激活参数量32B，支持混合推理模式。通过多阶段训练和强化学习，在多个任务上表现优异，发布两个版本以推动研究。


<details>
  <summary>Details</summary>
Motivation: 推动推理和代理AI系统的研究，通过开源模型促进社区发展。

Method: 采用混合专家架构和多阶段训练，结合强化学习优化模型性能。

Result: 在多个基准测试中表现优异，排名靠前，参数量少于竞争对手。

Conclusion: GLM-4.5及其紧凑版本为推理和代理AI系统提供了高效工具，开源以推动研究。

Abstract: We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language
model with 355B total parameters and 32B activated parameters, featuring a
hybrid reasoning method that supports both thinking and direct response modes.
Through multi-stage training on 23T tokens and comprehensive post-training with
expert model iteration and reinforcement learning, GLM-4.5 achieves strong
performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on
TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer
parameters than several competitors, GLM-4.5 ranks 3rd overall among all
evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B
parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance
research in reasoning and agentic AI systems. Code, models, and more
information are available at https://github.com/zai-org/GLM-4.5.

</details>


### [71] [HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning](https://arxiv.org/abs/2508.06475)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 论文提出了HapticLLaMA，一种多模态感官语言模型，用于将触觉信号转化为自然语言描述，填补了触觉信号研究的空白。


<details>
  <summary>Details</summary>
Motivation: 触觉信号在虚拟现实、无障碍和康复应用中具有重要意义，但此前研究主要集中在视觉和听觉上，触觉信号的研究不足。

Method: 提出HapticLLaMA模型，采用两种触觉标记器（频率基和EnCodec基）将触觉信号离散化，并通过两阶段训练（监督微调和强化学习）优化模型。

Result: HapticLLaMA在触觉信号解释上表现优异，METEOR得分59.98，BLEU-4得分32.06，61%以上生成描述获人类评分超过3.5（7分制）。

Conclusion: 研究表明大型语言模型能有效处理和适应感官数据，强化学习进一步提升了模型与人类触觉感知的一致性。

Abstract: Haptic captioning is the task of generating natural language descriptions
from haptic signals, such as vibrations, for use in virtual reality,
accessibility, and rehabilitation applications. While previous multimodal
research has focused primarily on vision and audio, haptic signals for the
sense of touch remain underexplored. To address this gap, we formalize the
haptic captioning task and propose HapticLLaMA, a multimodal sensory language
model that interprets vibration signals into descriptions in a given sensory,
emotional, or associative category. We investigate two types of haptic
tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that
convert haptic signals into sequences of discrete units, enabling their
integration with the LLaMA model. HapticLLaMA is trained in two stages: (1)
supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,
and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We
assess HapticLLaMA's captioning performance using both automated n-gram metrics
and human evaluation. HapticLLaMA demonstrates strong capability in
interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a
BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated
captions received human ratings above 3.5 on a 7-point scale, with RLHF
yielding a 10% improvement in the overall rating distribution, indicating
stronger alignment with human haptic perception. These findings highlight the
potential of large language models to process and adapt to sensory data.

</details>


### [72] [Post-training for Efficient Communication via Convention Formation](https://arxiv.org/abs/2508.06482)
*Yilun Hua,Evan Wang,Yoav Artzi*

Main category: cs.CL

TL;DR: 论文提出了一种后训练方法，通过针对性地微调启发式识别的示范，提升LLMs在多轮互动中形成临时约定的能力，并通过两个新基准验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 人类在多轮互动中能高效适应语言并形成临时约定，而现有LLMs缺乏这种能力，因此需要改进。

Method: 采用后训练过程，通过启发式识别的示范进行针对性微调，并设计了两个新基准（互动基准和文档引用任务）来评估能力。

Result: 实验表明，经过后训练的LLMs在两个评估方法中显著提升了形成约定的能力。

Conclusion: 后训练方法有效提升了LLMs在多轮互动中的约定形成能力，为未来研究提供了新方向。

Abstract: Humans communicate with increasing efficiency in multi-turn interactions, by
adapting their language and forming ad-hoc conventions. In contrast, prior work
shows that LLMs do not naturally show this behavior. We develop a post-training
process to develop this ability through targeted fine-tuning on heuristically
identified demonstrations of convention formation. We evaluate with two new
benchmarks focused on this capability. First, we design a focused,
cognitively-motivated interaction benchmark that consistently elicits strong
convention formation trends in humans. Second, we create a new
document-grounded reference completion task that reflects in-the-wild
convention formation behavior. Our studies show significantly improved
convention formation abilities in post-trained LLMs across the two evaluation
methods.

</details>


### [73] [Indian Legal NLP Benchmarks : A Survey](https://arxiv.org/abs/2107.06056)
*Prathamesh Kalamkar,Janani Venugopalan Ph. D.,Vivek Raghavan Ph. D*

Main category: cs.CL

TL;DR: 提出为印度法律文本创建专门的NLP基准，以推动AI在法律领域的应用。


<details>
  <summary>Details</summary>
Motivation: 法律文本与普通英语文本差异显著，需针对印度法律系统设计挑战性基准，促进NLP技术创新。

Method: 回顾现有研究并提出创建印度法律NLP新基准的思路。

Result: 未明确具体实验结果，但强调了基准的重要性。

Conclusion: 创建专门基准将推动印度法律NLP的发展，惠及AI和法律界。

Abstract: Availability of challenging benchmarks is the key to advancement of AI in a
specific field.Since Legal Text is significantly different than normal English
text, there is a need to create separate Natural Language Processing benchmarks
for Indian Legal Text which are challenging and focus on tasks specific to
Legal Systems. This will spur innovation in applications of Natural language
Processing for Indian Legal Text and will benefit AI community and Legal
fraternity. We review the existing work in this area and propose ideas to
create new benchmarks for Indian Legal Natural Language Processing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [74] [Boosting Adversarial Transferability via Residual Perturbation Attack](https://arxiv.org/abs/2508.05689)
*Jinjia Peng,Zeze Tao,Huibing Wang,Meng Wang,Yang Wang*

Main category: cs.CV

TL;DR: 提出了一种名为ResPA的新型攻击方法，通过利用残差梯度作为扰动方向，提高对抗样本在目标模型上的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了扰动方向的影响，导致对抗样本的可迁移性受限。

Method: ResPA通过指数移动平均获取参考梯度，并利用当前梯度与参考梯度的残差来捕捉全局扰动方向的变化。

Result: 实验表明，ResPA的可迁移性优于现有典型迁移攻击方法，且与输入变换方法结合后效果更佳。

Conclusion: ResPA通过优化扰动方向，显著提升了对抗样本的可迁移性。

Abstract: Deep neural networks are susceptible to adversarial examples while suffering
from incorrect predictions via imperceptible perturbations. Transfer-based
attacks create adversarial examples for surrogate models and transfer these
examples to target models under black-box scenarios. Recent studies reveal that
adversarial examples in flat loss landscapes exhibit superior transferability
to alleviate overfitting on surrogate models. However, the prior arts overlook
the influence of perturbation directions, resulting in limited transferability.
In this paper, we propose a novel attack method, named Residual Perturbation
Attack (ResPA), relying on the residual gradient as the perturbation direction
to guide the adversarial examples toward the flat regions of the loss function.
Specifically, ResPA conducts an exponential moving average on the input
gradients to obtain the first moment as the reference gradient, which
encompasses the direction of historical gradients. Instead of heavily relying
on the local flatness that stems from the current gradients as the perturbation
direction, ResPA further considers the residual between the current gradient
and the reference gradient to capture the changes in the global perturbation
direction. The experimental results demonstrate the better transferability of
ResPA than the existing typical transfer-based attack methods, while the
transferability can be further improved by combining ResPA with the current
input transformation methods. The code is available at
https://github.com/ZezeTao/ResPA.

</details>


### [75] [Generalized Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2508.05732)
*Pinxuan Li,Bing Cao,Changqing Zhang,Qinghua Hu*

Main category: cs.CV

TL;DR: 提出了一种广义少样本OOD检测框架（GOOD），通过引入通用知识模型（GKM）和知识动态嵌入（KDE）机制，提升模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有少样本OOD检测方法在开放世界中的泛化能力不足，容易过拟合，导致性能下降。

Method: 提出GOOD框架，利用GKM增强通用知识，并通过KDE机制动态调整输出分布。

Result: 在真实OOD基准测试中表现优越，理论证明了GS-balance能降低泛化误差上界。

Conclusion: GOOD框架通过通用知识和动态调整，显著提升了少样本OOD检测的泛化性能。

Abstract: Few-shot Out-of-Distribution (OOD) detection has emerged as a critical
research direction in machine learning for practical deployment. Most existing
Few-shot OOD detection methods suffer from insufficient generalization
capability for the open world. Due to the few-shot learning paradigm, the OOD
detection ability is often overfit to the limited training data itself, thus
degrading the performance on generalized data and performing inconsistently
across different scenarios. To address this challenge, we proposed a
Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general
knowledge of the OOD detection model with an auxiliary General Knowledge Model
(GKM), instead of directly learning from few-shot data. We proceed to reveal
the few-shot OOD detection from a generalization perspective and theoretically
derive the Generality-Specificity balance (GS-balance) for OOD detection, which
provably reduces the upper bound of generalization error with a general
knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE)
mechanism to adaptively modulate the guidance of general knowledge. KDE
dynamically aligns the output distributions of the OOD detection model to the
general knowledge model based on the Generalized Belief (G-Belief) of GKM,
thereby boosting the GS-balance. Experiments on real-world OOD benchmarks
demonstrate our superiority. Codes will be available.

</details>


### [76] [UnGuide: Learning to Forget with LoRA-Guided Diffusion Models](https://arxiv.org/abs/2508.05755)
*Agnieszka Polowczyk,Alicja Polowczyk,Dawid Malarz,Artur Kasymov,Marcin Mazur,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: UnGuide是一种新的方法，通过动态推理机制UnGuidance，结合LoRA适配器，实现对扩散模型中特定概念的精确去除，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型可能被滥用生成有害或误导性内容，因此需要有效的机器遗忘方法，即在不影响整体性能的情况下移除特定知识。

Method: UnGuide结合了LoRA适配器和动态推理机制UnGuidance，通过调整引导尺度，实现对特定概念的精确去除。

Result: UnGuide在概念去除任务中表现优于现有基于LoRA的方法，同时保持了模型的表达能力。

Conclusion: UnGuide提供了一种有效且可控的机器遗忘方法，适用于扩散模型中的特定知识移除。

Abstract: Recent advances in large-scale text-to-image diffusion models have heightened
concerns about their potential misuse, especially in generating harmful or
misleading content. This underscores the urgent need for effective machine
unlearning, i.e., removing specific knowledge or concepts from pretrained
models without compromising overall performance. One possible approach is
Low-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models
for targeted unlearning. However, LoRA often inadvertently alters unrelated
content, leading to diminished image fidelity and realism. To address this
limitation, we introduce UnGuide -- a novel approach which incorporates
UnGuidance, a dynamic inference mechanism that leverages Classifier-Free
Guidance (CFG) to exert precise control over the unlearning process. UnGuide
modulates the guidance scale based on the stability of a few first steps of
denoising processes, enabling selective unlearning by LoRA adapter. For prompts
containing the erased concept, the LoRA module predominates and is
counterbalanced by the base model; for unrelated prompts, the base model
governs generation, preserving content fidelity. Empirical results demonstrate
that UnGuide achieves controlled concept removal and retains the expressive
power of diffusion models, outperforming existing LoRA-based methods in both
object erasure and explicit content removal tasks.

</details>


### [77] [Improving Masked Style Transfer using Blended Partial Convolution](https://arxiv.org/abs/2508.05769)
*Seyed Hadi Seyed,Ayberk Cansever,David Hart*

Main category: cs.CV

TL;DR: 提出了一种基于部分卷积的风格迁移网络，专注于对图像中特定区域进行风格迁移，避免了传统方法中的风格特征捕捉不准确问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法对整个图像进行风格迁移后通过掩码处理特定区域，但会导致风格特征在目标区域中表现不准确。

Method: 采用部分卷积网络，结合内部混合技术，精准地对目标区域进行风格迁移，同时处理区域选择的不完美性。

Result: 在SA-1B数据集上验证，视觉和定量指标均显示改进。

Conclusion: 该方法有效提升了特定区域风格迁移的准确性和视觉效果，代码已开源。

Abstract: Artistic style transfer has long been possible with the advancements of
convolution- and transformer-based neural networks. Most algorithms apply the
artistic style transfer to the whole image, but individual users may only need
to apply a style transfer to a specific region in the image. The standard
practice is to simply mask the image after the stylization. This work shows
that this approach tends to improperly capture the style features in the region
of interest. We propose a partial-convolution-based style transfer network that
accurately applies the style features exclusively to the region of interest.
Additionally, we present network-internal blending techniques that account for
imperfections in the region selection. We show that this visually and
quantitatively improves stylization using examples from the SA-1B dataset. Code
is publicly available at https://github.com/davidmhart/StyleTransferMasked.

</details>


### [78] [MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss](https://arxiv.org/abs/2508.05772)
*Can Zhao,Pengfei Guo,Dong Yang,Yucheng Tang,Yufan He,Benjamin Simon,Mason Belue,Stephanie Harmon,Baris Turkbey,Daguang Xu*

Main category: cs.CV

TL;DR: MAISI-v2是一个加速的3D医学图像合成框架，通过整合rectified flow实现快速高质量生成，并引入区域特异性对比损失提升条件一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在医学图像合成中的局限性，包括泛化性差、推理速度慢和输入条件对齐弱的问题。

Method: 整合rectified flow加速生成，引入区域特异性对比损失增强条件一致性。

Result: MAISI-v2实现了33倍的加速，并达到SOTA图像质量，合成图像可用于数据增强。

Conclusion: MAISI-v2在速度和条件一致性上显著改进，为医学图像合成提供了高效解决方案。

Abstract: Medical image synthesis is an important topic for both clinical and research
applications. Recently, diffusion models have become a leading approach in this
area. Despite their strengths, many existing methods struggle with (1) limited
generalizability that only work for specific body regions or voxel spacings,
(2) slow inference, which is a common issue for diffusion models, and (3) weak
alignment with input conditions, which is a critical issue for medical imaging.
MAISI, a previously proposed framework, addresses generalizability issues but
still suffers from slow inference and limited condition consistency. In this
work, we present MAISI-v2, the first accelerated 3D medical image synthesis
framework that integrates rectified flow to enable fast and high quality
generation. To further enhance condition fidelity, we introduce a novel
region-specific contrastive loss to enhance the sensitivity to region of
interest. Our experiments show that MAISI-v2 can achieve SOTA image quality
with $33 \times$ acceleration for latent diffusion model. We also conducted a
downstream segmentation experiment to show that the synthetic images can be
used for data augmentation. We release our code, training details, model
weights, and a GUI demo to facilitate reproducibility and promote further
development within the community.

</details>


### [79] [Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks](https://arxiv.org/abs/2508.05783)
*Mengyu Li,Guoyao Shen,Chad W. Farris,Xin Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于预训练MRI变换器的少样本部署框架，结合MAE策略和混合架构，在数据有限条件下实现高效、稳定的医学影像任务。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中标注数据稀缺的问题，提升变换器模型在真实场景中的适用性。

Method: 采用MAE预训练策略，结合大规模多队列脑MRI数据集，提出MAE-FUnet混合架构，融合多尺度CNN特征与MAE嵌入。

Result: 在MRI序列识别任务中达到SOTA准确率，在分割任务中优于其他基线模型，表现出高效、稳定和可扩展性。

Conclusion: 该框架适用于低资源临床环境和广泛的神经影像应用。

Abstract: Machine learning using transformers has shown great potential in medical
imaging, but its real-world applicability remains limited due to the scarcity
of annotated data. In this study, we propose a practical framework for the
few-shot deployment of pretrained MRI transformers in diverse brain imaging
tasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a
large-scale, multi-cohort brain MRI dataset comprising over 31 million slices,
we obtain highly transferable latent representations that generalize well
across tasks and datasets. For high-level tasks such as classification, a
frozen MAE encoder combined with a lightweight linear head achieves
state-of-the-art accuracy in MRI sequence identification with minimal
supervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a
hybrid architecture that fuses multiscale CNN features with pretrained MAE
embeddings. This model consistently outperforms other strong baselines in both
skull stripping and multi-class anatomical segmentation under data-limited
conditions. With extensive quantitative and qualitative evaluations, our
framework demonstrates efficiency, stability, and scalability, suggesting its
suitability for low-resource clinical environments and broader neuroimaging
applications.

</details>


### [80] [Optimization-Free Style Transfer for 3D Gaussian Splats](https://arxiv.org/abs/2508.05813)
*Raphael Du Sablon,David Hart*

Main category: cs.CV

TL;DR: 提出了一种无需重建或优化的3D高斯样条风格迁移方法，通过生成样条表示的隐式表面图结构，实现快速风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要重建或优化样条表示，效率低且依赖额外训练。

Method: 生成样条表示的隐式表面图结构，使用前馈表面风格化方法并插值回场景中的样条。

Result: 无需额外训练或优化，支持任意风格图像和3D高斯样条，速度在2分钟内完成。

Conclusion: 该方法高效且通用，适用于快速3D高斯样条风格迁移。

Abstract: The task of style transfer for 3D Gaussian splats has been explored in many
previous works, but these require reconstructing or fine-tuning the splat while
incorporating style information or optimizing a feature extraction network on
the splat representation. We propose a reconstruction- and optimization-free
approach to stylizing 3D Gaussian splats. This is done by generating a graph
structure across the implicit surface of the splat representation. A
feed-forward, surface-based stylization method is then used and interpolated
back to the individual splats in the scene. This allows for any style image and
3D Gaussian splat to be used without any additional training or optimization.
This also allows for fast stylization of splats, achieving speeds under 2
minutes even on consumer-grade hardware. We demonstrate the quality results
this approach achieves and compare to other 3D Gaussian splat style transfer
methods. Code is publicly available at
https://github.com/davidmhart/FastSplatStyler.

</details>


### [81] [MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses](https://arxiv.org/abs/2508.05819)
*Jong-Ik Park,Carlee Joe-Wong,Gary K. Fedder*

Main category: cs.CV

TL;DR: MZEN是一种改进的NeRF框架，通过处理多缩放图像集，显著提升了工业检测中的细节重建能力。


<details>
  <summary>Details</summary>
Motivation: 传统NeRF方法在工业检测中无法捕捉微米级细节，且多缩放图像会破坏多视角一致性。MZEN旨在解决这一问题。

Method: MZEN引入可学习的缩放因子和新的位姿策略，先通过广角图像建立全局坐标系，再通过缩放一致的裁剪匹配方法处理放大图像。

Result: MZEN在多个场景中表现优异，PSNR提升28%，SSIM提升10%，LPIPS降低222%。

Conclusion: MZEN成功将NeRF应用于工业场景，兼顾全局精度和微米级细节。

Abstract: Neural Radiance Fields (NeRF) methods excel at 3D reconstruction from
multiple 2D images, even those taken with unknown camera poses. However, they
still miss the fine-detailed structures that matter in industrial inspection,
e.g., detecting sub-micron defects on a production line or analyzing chips with
Scanning Electron Microscopy (SEM). In these scenarios, the sensor resolution
is fixed and compute budgets are tight, so the only way to expose fine
structure is to add zoom-in images; yet, this breaks the multi-view consistency
that pose-free NeRF training relies on. We propose Multi-Zoom Enhanced NeRF
(MZEN), the first NeRF framework that natively handles multi-zoom image sets.
MZEN (i) augments the pin-hole camera model with an explicit, learnable zoom
scalar that scales the focal length, and (ii) introduces a novel pose strategy:
wide-field images are solved first to establish a global metric frame, and
zoom-in images are then pose-primed to the nearest wide-field counterpart via a
zoom-consistent crop-and-match procedure before joint refinement. Across eight
forward-facing scenes$\unicode{x2013}$synthetic TCAD models, real SEM of
micro-structures, and BLEFF objects$\unicode{x2013}$MZEN consistently
outperforms pose-free baselines and even high-resolution variants, boosting
PSNR by up to $28 \%$, SSIM by $10 \%$, and reducing LPIPS by up to $222 \%$.
MZEN, therefore, extends NeRF to real-world factory settings, preserving global
accuracy while capturing the micron-level details essential for industrial
inspection.

</details>


### [82] [TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios](https://arxiv.org/abs/2508.05829)
*Guoping Xu,Hua-Chieh Shao,You Zhang*

Main category: cs.CV

TL;DR: TSMS-SAM2是一种新型框架，通过多时间尺度视频采样增强和内存分割修剪机制，提升了手术视频中可提示视频对象分割与跟踪的性能。


<details>
  <summary>Details</summary>
Motivation: 手术视频分析中，复杂的运动动态和内存冗余限制了基础模型（如SAM2）的应用效果。

Method: 提出TSMS-SAM2框架，采用多时间尺度视频采样增强和内存分割修剪机制。

Result: 在EndoVis2017和EndoVis2018数据集上分别达到95.24和86.73的Dice分数，优于现有方法。

Conclusion: TSMS-SAM2在复杂手术场景中表现出高效、鲁棒的分割潜力。

Abstract: Promptable video object segmentation and tracking (VOST) has seen significant
advances with the emergence of foundation models like Segment Anything Model 2
(SAM2); however, their application in surgical video analysis remains
challenging due to complex motion dynamics and the redundancy of memory that
impedes effective learning. In this work, we propose TSMS-SAM2, a novel
framework that enhances promptable VOST in surgical videos by addressing
challenges of rapid object motion and memory redundancy in SAM2. TSMS-SAM2
introduces two key strategies: multi-temporal-scale video sampling augmentation
to improve robustness against motion variability, and a memory splitting and
pruning mechanism that organizes and filters past frame features for more
efficient and accurate segmentation. Evaluated on EndoVis2017 and EndoVis2018
datasets, TSMS-SAM2 achieved the highest mean Dice scores of 95.24 and 86.73,
respectively, outperforming prior SAM-based and task-specific methods.
Extensive ablation studies confirm the effectiveness of multiscale temporal
augmentation and memory splitting, highlighting the framework's potential for
robust, efficient segmentation in complex surgical scenarios. Our source code
will be available at https://github.com/apple1986/TSMS-SAM2.

</details>


### [83] [Temporal Cluster Assignment for Efficient Real-Time Video Segmentation](https://arxiv.org/abs/2508.05851)
*Ka-Wai Yung,Felix J. S. Bragman,Jialang Xu,Imanol Luengo,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TL;DR: TCA（Temporal Cluster Assignment）是一种轻量级、无需微调的策略，通过利用帧间时间一致性优化视频分割中的令牌聚类，显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: Swin Transformer在视频分割中计算成本高，传统令牌剪枝方法不适用，现有聚类方法未充分利用时间冗余。

Method: 提出TCA，通过时间相关性优化令牌聚类，保留细节并减少计算。

Result: 在多个数据集上验证，TCA显著提升了现有聚类方法的准确性与速度平衡。

Conclusion: TCA在自然和特定领域视频中均表现出色，是一种高效优化方法。

Abstract: Vision Transformers have substantially advanced the capabilities of
segmentation models across both image and video domains. Among them, the Swin
Transformer stands out for its ability to capture hierarchical, multi-scale
representations, making it a popular backbone for segmentation in videos.
However, despite its window-attention scheme, it still incurs a high
computational cost, especially in larger variants commonly used for dense
prediction in videos. This remains a major bottleneck for real-time,
resource-constrained applications. Whilst token reduction methods have been
proposed to alleviate this, the window-based attention mechanism of Swin
requires a fixed number of tokens per window, limiting the applicability of
conventional pruning techniques. Meanwhile, training-free token clustering
approaches have shown promise in image segmentation while maintaining window
consistency. Nevertheless, they fail to exploit temporal redundancy, missing a
key opportunity to further optimize video segmentation performance. We
introduce Temporal Cluster Assignment (TCA), a lightweight and effective,
fine-tuning-free strategy that enhances token clustering by leveraging temporal
coherence across frames. Instead of indiscriminately dropping redundant tokens,
TCA refines token clusters using temporal correlations, thereby retaining
fine-grained details while significantly reducing computation. Extensive
evaluations on YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and a private surgical
video dataset show that TCA consistently boosts the accuracy-speed trade-off of
existing clustering-based methods. Our results demonstrate that TCA generalizes
competently across both natural and domain-specific videos.

</details>


### [84] [VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments](https://arxiv.org/abs/2508.05852)
*Kaiser Hamid,Khandakar Ashrafi Akbar,Nade Liang*

Main category: cs.CV

TL;DR: 提出了一种基于视觉-语言框架的驾驶员视觉注意力预测方法，通过自然语言描述注意力变化，支持少样本和零样本学习。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注静态图像的注意力分配，缺乏对动态注意力变化的建模，且缺乏可解释性。

Method: 利用BDD-A数据集的高质量标注，通过人类反馈优化，微调LLaVA模型，结合低层线索和上下文信息生成语言描述。

Result: 微调模型在注意力转移检测和可解释性上优于通用视觉-语言模型。

Conclusion: 该方法为自动驾驶中的可解释AI提供了新方向，支持下游任务如行为预测和人机协作。

Abstract: Driver visual attention prediction is a critical task in autonomous driving
and human-computer interaction (HCI) research. Most prior studies focus on
estimating attention allocation at a single moment in time, typically using
static RGB images such as driving scene pictures. In this work, we propose a
vision-language framework that models the changing landscape of drivers' gaze
through natural language, using few-shot and zero-shot learning on single RGB
images. We curate and refine high-quality captions from the BDD-A dataset using
human-in-the-loop feedback, then fine-tune LLaVA to align visual perception
with attention-centric scene understanding. Our approach integrates both
low-level cues and top-down context (e.g., route semantics, risk anticipation),
enabling language-based descriptions of gaze behavior. We evaluate performance
across training regimes (few shot, and one-shot) and introduce domain-specific
metrics for semantic alignment and response diversity. Results show that our
fine-tuned model outperforms general-purpose VLMs in attention shift detection
and interpretability. To our knowledge, this is among the first attempts to
generate driver visual attention allocation and shifting predictions in natural
language, offering a new direction for explainable AI in autonomous driving.
Our approach provides a foundation for downstream tasks such as behavior
forecasting, human-AI teaming, and multi-agent coordination.

</details>


### [85] [Multi-view Gaze Target Estimation](https://arxiv.org/abs/2508.05857)
*Qiaomu Miao,Vivek Raju Golani,Jingyi Xu,Progga Paromita Dutta,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: 提出了一种利用多摄像头视角进行视线目标估计（GTE）的方法，通过整合不同视角信息提高准确性并扩展适用性。


<details>
  <summary>Details</summary>
Motivation: 解决单视角方法在面部遮挡、目标模糊和视线外目标等问题上的局限性。

Method: 结合头部信息聚合（HIA）、基于不确定性的视线选择（UGS）和基于极线的场景注意力（ESA）模块，处理双视角输入。

Result: 显著优于单视角基线，尤其在第二视角提供清晰面部视图时。还能仅用第二视角图像估计第一视角的视线目标。

Conclusion: 该方法在多视角GTE任务中表现出色，并提供了多视角数据集供开发与评估。

Abstract: This paper presents a method that utilizes multiple camera views for the gaze
target estimation (GTE) task. The approach integrates information from
different camera views to improve accuracy and expand applicability, addressing
limitations in existing single-view methods that face challenges such as face
occlusion, target ambiguity, and out-of-view targets. Our method processes a
pair of camera views as input, incorporating a Head Information Aggregation
(HIA) module for leveraging head information from both views for more accurate
gaze estimation, an Uncertainty-based Gaze Selection (UGS) for identifying the
most reliable gaze output, and an Epipolar-based Scene Attention (ESA) module
for cross-view background information sharing. This approach significantly
outperforms single-view baselines, especially when the second camera provides a
clear view of the person's face. Additionally, our method can estimate the gaze
target in the first view using the image of the person in the second view only,
a capability not possessed by single-view GTE methods. Furthermore, the paper
introduces a multi-view dataset for developing and evaluating multi-view GTE
methods. Data and code are available at
https://www3.cs.stonybrook.edu/~cvl/multiview_gte.html

</details>


### [86] [ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates](https://arxiv.org/abs/2508.05898)
*Hamidreza Dastmalchi,Aijun An,Ali cheraghian*

Main category: cs.CV

TL;DR: ETTA提出了一种高效的测试时适应方法，通过递归更新模块和自适应集成模块，显著提升了预训练视觉语言模型在分布偏移下的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型（如CLIP）在零样本任务中表现良好，但在分布偏移下泛化能力不足。现有的测试时适应方法（TTA）通常依赖有限的缓存样本，限制了决策边界的优化。

Method: ETTA引入递归更新模块，动态整合所有测试样本以优化决策边界，并结合自适应集成模块减少对提示的依赖。通过置信度动态结合两个模块的输出。

Result: 在两个基准测试中，ETTA在计算复杂度和准确性上均优于现有TTA模型。

Conclusion: ETTA为高效、有效的测试时适应设定了新标准，代码已开源。

Abstract: Pretrained vision-language models (VLMs) like CLIP show strong zero-shot
performance but struggle with generalization under distribution shifts.
Test-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test
data in new domains. While some TTA methods rely on prompt-tuning,
training-free cache-based approaches are preferred for efficiency. However,
current cache-based TTA models store only a limited set of high-confidence
samples, restricting the decision boundary to these samples and ignoring the
influence of other incoming test data. To address this, we propose Efficient
Test-Time Adaptation (ETTA), introducing a Recursive Updating module that
integrates all incoming test samples, progressively refining the decision
boundary. This strategy mimics an unbounded cache, dynamically updating
contextual embeddings for improved accuracy with minimal memory and
computational overhead. ETTA also includes an Adaptive Ensemble module to
reduce prompt dependency in image-to-text scores by dynamically selecting
optimal prompts for each class. Furthermore, ETTA adaptively combines scores
from both modules based on confidence levels, leveraging their complementary
strengths. Extensive experiments on two benchmarks confirm that ETTA surpasses
the state-of-the-art TTA models in computational complexity and accuracy,
setting a new standard for effective, efficient test-time adaptation. The code
has been released at https://github.com/hamidreza-dastmalchi/ETTA.

</details>


### [87] [HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing](https://arxiv.org/abs/2508.05899)
*Zixuan Bian,Ruohan Ren,Yue Yang,Chris Callison-Burch*

Main category: cs.CV

TL;DR: HOLODECK 2.0是一个基于视觉语言模型的3D场景生成框架，支持交互式编辑，能生成多样且语义准确的3D场景。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景生成依赖大量人工，且现有自动化方法难以支持开放域场景或灵活编辑。

Method: 利用视觉语言模型解析场景需求，结合3D生成模型生成高质量资产，并通过空间约束优化布局。

Result: 生成的场景在语义和物理布局上表现优异，优于基线方法，并支持灵活编辑。

Conclusion: HOLODECK 2.0在游戏建模等应用中具有潜力，能提升效率并生成沉浸式环境。

Abstract: 3D scene generation plays a crucial role in gaming, artistic creation,
virtual reality and many other domains. However, current 3D scene design still
relies heavily on extensive manual effort from creators, and existing automated
methods struggle to generate open-domain scenes or support flexible editing. As
a result, generating 3D worlds directly from text has garnered increasing
attention. In this paper, we introduce HOLODECK 2.0, an advanced
vision-language-guided framework for 3D world generation with support for
interactive scene editing based on human feedback. HOLODECK 2.0 can generate
diverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and
cyberpunk styles) that exhibit high semantic fidelity to fine-grained input
descriptions, suitable for both indoor and open-domain environments. HOLODECK
2.0 leverages vision-language models (VLMs) to identify and parse the objects
required in a scene and generates corresponding high-quality assets via
state-of-the-art 3D generative models. It then iteratively applies spatial
constraints derived from the VLMs to achieve semantically coherent and
physically plausible layouts. Human evaluations and CLIP-based assessments
demonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely
aligned with detailed textual descriptions, consistently outperforming
baselines across indoor and open-domain scenarios. Additionally, we provide
editing capabilities that flexibly adapt to human feedback, supporting layout
refinement and style-consistent object edits. Finally, we present a practical
application of HOLODECK 2.0 in procedural game modeling, generating visually
rich and immersive environments, potentially boosting efficiency.

</details>


### [88] [Robust Image Stitching with Optimal Plane](https://arxiv.org/abs/2508.05903)
*Lang Nie,Yuan Mei,Kang Liao,Yunqiu Xu,Chunyu Lin,Bin Xiao*

Main category: cs.CV

TL;DR: RopStitch是一种无监督的深度图像拼接框架，通过双分支架构和虚拟最优平面概念，实现了高鲁棒性和自然性。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像拼接方法在多样真实场景中鲁棒性和自然性不足的问题。

Method: 采用双分支架构分别捕获粗粒度与细粒度特征，并通过虚拟最优平面概念缓解内容对齐与结构保留的矛盾。

Result: 在多个数据集上显著优于现有方法，尤其在场景鲁棒性和内容自然性方面表现突出。

Conclusion: RopStitch通过创新的架构和优化策略，为图像拼接提供了高效且通用的解决方案。

Abstract: We present \textit{RopStitch}, an unsupervised deep image stitching framework
with both robustness and naturalness. To ensure the robustness of
\textit{RopStitch}, we propose to incorporate the universal prior of content
perception into the image stitching model by a dual-branch architecture. It
separately captures coarse and fine features and integrates them to achieve
highly generalizable performance across diverse unseen real-world scenes.
Concretely, the dual-branch model consists of a pretrained branch to capture
semantically invariant representations and a learnable branch to extract
fine-grained discriminative features, which are then merged into a whole by a
controllable factor at the correlation level. Besides, considering that content
alignment and structural preservation are often contradictory to each other, we
propose a concept of virtual optimal planes to relieve this conflict. To this
end, we model this problem as a process of estimating homography decomposition
coefficients, and design an iterative coefficient predictor and minimal
semantic distortion constraint to identify the optimal plane. This scheme is
finally incorporated into \textit{RopStitch} by warping both views onto the
optimal plane bidirectionally. Extensive experiments across various datasets
demonstrate that \textit{RopStitch} significantly outperforms existing methods,
particularly in scene robustness and content naturalness. The code is available
at {\color{red}https://github.com/MmelodYy/RopStitch}.

</details>


### [89] [Neural Field Representations of Mobile Computational Photography](https://arxiv.org/abs/2508.05907)
*Ilya Chugunov*

Main category: cs.CV

TL;DR: 论文探讨了如何利用精心设计的神经场模型，通过智能手机收集的数据实现深度估计、图层分离和图像拼接等应用，无需复杂预处理或标记数据。


<details>
  <summary>Details</summary>
Motivation: 随着移动成像技术的快速发展，智能手机已成为多功能计算成像平台，但现有方法依赖复杂预处理或标记数据，限制了其应用潜力。

Method: 采用神经场模型，通过随机梯度下降直接拟合智能手机的原始测量数据，解决逆问题。

Result: 提出的方法在深度估计、图层分离和图像拼接等任务中优于现有技术，无需复杂预处理或标记数据。

Conclusion: 神经场模型为移动计算成像提供了一种高效、自正则化的解决方案，具有广泛的应用前景。

Abstract: Over the past two decades, mobile imaging has experienced a profound
transformation, with cell phones rapidly eclipsing all other forms of digital
photography in popularity. Today's cell phones are equipped with a diverse
range of imaging technologies - laser depth ranging, multi-focal camera arrays,
and split-pixel sensors - alongside non-visual sensors such as gyroscopes,
accelerometers, and magnetometers. This, combined with on-board integrated
chips for image and signal processing, makes the cell phone a versatile
pocket-sized computational imaging platform. Parallel to this, we have seen in
recent years how neural fields - small neural networks trained to map
continuous spatial input coordinates to output signals - enable the
reconstruction of complex scenes without explicit data representations such as
pixel arrays or point clouds. In this thesis, I demonstrate how carefully
designed neural field models can compactly represent complex geometry and
lighting effects. Enabling applications such as depth estimation, layer
separation, and image stitching directly from collected in-the-wild mobile
photography data. These methods outperform state-of-the-art approaches without
relying on complex pre-processing steps, labeled ground truth data, or machine
learning priors. Instead, they leverage well-constructed, self-regularized
models that tackle challenging inverse problems through stochastic gradient
descent, fitting directly to raw measurements from a smartphone.

</details>


### [90] [Enhancing Construction Site Analysis and Understanding with 3D Segmentation](https://arxiv.org/abs/2508.05922)
*Sri Ramana Saketh Vasanthawada,Pengkun Liu,Pingbo Tang*

Main category: cs.CV

TL;DR: 论文评估了SAM和Mask3D两种3D分割方法在复杂建筑工地环境中的适应性，揭示了当前方法在户外场景中的不足，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 传统建筑进度监测方法效率低且难以适应复杂多变的工地环境，需要更高效的计算机视觉解决方案。

Method: 通过比较SAM和Mask3D在室内和户外建筑工地中的表现，评估其适应性和性能。

Result: 研究发现当前分割方法缺乏户外场景的基准，两种模型在复杂环境中表现有限。

Conclusion: 需开发针对建筑工地的定制化分割工作流，以实现更自动化和精确的监测。

Abstract: Monitoring construction progress is crucial yet resource-intensive, prompting
the exploration of computer-vision-based methodologies for enhanced efficiency
and scalability. Traditional data acquisition methods, primarily focusing on
indoor environments, falter in construction site's complex, cluttered, and
dynamically changing conditions. This paper critically evaluates the
application of two advanced 3D segmentation methods, Segment Anything Model
(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained
initially on indoor datasets, both models' adaptability and performance are
assessed in real-world construction settings, highlighting the gap in current
segmentation approaches due to the absence of benchmarks for outdoor scenarios.
Through a comparative analysis, this study not only showcases the relative
effectiveness of SAM and Mask3D but also addresses the critical need for
tailored segmentation workflows capable of extracting actionable insights from
construction site data, thereby advancing the field towards more automated and
precise monitoring techniques.

</details>


### [91] [A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image](https://arxiv.org/abs/2508.05950)
*Yanxing Liang,Yinghui Wang,Jinlong Yang,Wei Li*

Main category: cs.CV

TL;DR: SINGAD提出了一种基于3D高斯扩散的自监督框架，通过物理驱动的光交互建模和可微分渲染重投影策略，解决了单图像法线估计中的多视角几何不一致性和数据依赖性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖数据驱动的统计先验，缺乏光与表面交互的显式建模，导致多视角法线方向冲突，且扩散模型的离散采样机制阻碍了3D几何误差的反向传播。

Method: SINGAD结合了光交互驱动的3D高斯重参数化模型和条件扩散模型中的跨域特征融合模块，通过可微分3D重投影损失策略实现自监督优化。

Result: 在Google Scanned Objects数据集上的定量评估表明，该方法在多个指标上优于现有技术。

Conclusion: SINGAD通过物理建模和自监督优化，显著提升了单图像法线估计的准确性和一致性，减少了对标注数据的依赖。

Abstract: The lack of spatial dimensional information remains a challenge in normal
estimation from a single image. Recent diffusion-based methods have
demonstrated significant potential in 2D-to-3D implicit mapping, they rely on
data-driven statistical priors and miss the explicit modeling of light-surface
interaction, leading to multi-view normal direction conflicts. Moreover, the
discrete sampling mechanism of diffusion models causes gradient discontinuity
in differentiable rendering reconstruction modules, preventing 3D geometric
errors from being backpropagated to the normal generation network, thereby
forcing existing methods to depend on dense normal annotations. This paper
proposes SINGAD, a novel Self-supervised framework from a single Image for
Normal estimation via 3D GAussian splatting guided Diffusion. By integrating
physics-driven light-interaction modeling and a differentiable rendering-based
reprojection strategy, our framework directly converts 3D geometric errors into
normal optimization signals, solving the challenges of multi-view geometric
inconsistency and data dependency. Specifically, the framework constructs a
light-interaction-driven 3DGS reparameterization model to generate multi-scale
geometric features consistent with light transport principles, ensuring
multi-view normal consistency. A cross-domain feature fusion module is designed
within a conditional diffusion model, embedding geometric priors to constrain
normal generation while maintaining accurate geometric error propagation.
Furthermore, a differentiable 3D reprojection loss strategy is introduced for
self-supervised optimization that minimizes geometric error between the
reconstructed and input image, eliminating dependence on annotated normal
datasets. Quantitative evaluations on the Google Scanned Objects dataset
demonstrate that our method outperforms state-of-the-art approaches across
multiple metrics.

</details>


### [92] [Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents](https://arxiv.org/abs/2508.05954)
*Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal*

Main category: cs.CV

TL;DR: Bifrost-1是一个统一框架，通过将预训练多模态LLMs与扩散模型结合，利用CLIP图像嵌入作为潜在变量，实现高效训练和高保真图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练成本高且可能损害LLMs推理能力的情况下，难以将高保真视觉合成能力整合到LLMs中。

Method: 使用patch-level CLIP图像嵌入作为潜在变量，通过轻量级ControlNet适应扩散模型，并初始化MLLMs的视觉生成分支。

Result: Bifrost-1在视觉保真度和多模态理解上表现优异，且训练计算成本显著降低。

Conclusion: Bifrost-1成功整合了预训练MLLMs和扩散模型，实现了高效可控的高保真图像生成。

Abstract: There is growing interest in integrating high-fidelity visual synthesis
capabilities into large language models (LLMs) without compromising their
strong reasoning capabilities. Existing methods that directly train LLMs or
bridge LLMs and diffusion models usually suffer from costly training since the
backbone LLMs have not seen image representations during pretraining. We
present Bifrost-1, a unified framework that bridges pretrained multimodal LLMs
(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent
variables, which are natively aligned with the MLLM's CLIP visual encoder.
These patch-level image embeddings are integrated into the diffusion model with
a lightweight adaptation of its ControlNet. To retain the original multimodal
reasoning capabilities of MLLMs, we equip the MLLM with a visual generation
branch initialized from the original MLLM parameters when predicting the
patch-level image embeddings. By seamlessly integrating pretrained MLLMs and
diffusion models with patch-level CLIP latents, our framework enables
high-fidelity controllable image generation with significant training
efficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or
better performance than previous methods in terms of visual fidelity and
multimodal understanding, with substantially lower compute during training. We
also provide comprehensive ablation studies showing the effectiveness of our
design choices.

</details>


### [93] [PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation](https://arxiv.org/abs/2508.05976)
*Zhihao Zhu,Yifan Zheng,Siyu Pan,Yaohui Jin,Yao Mu*

Main category: cs.CV

TL;DR: PASG框架通过几何特征聚合和语义锚定，解决了机器人操作中语义与几何特征的割裂问题，实现了动态语义-功能关系的捕捉。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中高级任务语义与低级几何特征之间的割裂问题，减少对人工标注的依赖。

Method: 提出PASG框架，包括自动几何基元提取、VLM驱动的语义锚定和空间语义推理基准。

Result: 在多样化机器人操作任务中表现优异，性能接近人工标注水平。

Conclusion: PASG为机器人操作中的几何基元与任务语义提供了统一的桥梁。

Abstract: The fragmentation between high-level task semantics and low-level geometric
features remains a persistent challenge in robotic manipulation. While
vision-language models (VLMs) have shown promise in generating affordance-aware
visual representations, the lack of semantic grounding in canonical spaces and
reliance on manual annotations severely limit their ability to capture dynamic
semantic-affordance relationships. To address these, we propose Primitive-Aware
Semantic Grounding (PASG), a closed-loop framework that introduces: (1)
Automatic primitive extraction through geometric feature aggregation, enabling
cross-category detection of keypoints and axes; (2) VLM-driven semantic
anchoring that dynamically couples geometric primitives with functional
affordances and task-relevant description; (3) A spatial-semantic reasoning
benchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's
effectiveness in practical robotic manipulation tasks across diverse scenarios,
achieving performance comparable to manual annotations. PASG achieves a
finer-grained semantic-affordance understanding of objects, establishing a
unified paradigm for bridging geometric primitives with task semantics in
robotic manipulation.

</details>


### [94] [AnimateScene: Camera-controllable Animation in Any Scene](https://arxiv.org/abs/2508.05982)
*Qingyang Liu,Bingjie Gao,Weiheng Huang,Jun Zhang,Zhongqian Sun,Yang Wei,Zelin Peng,Qianli Ma,Shuai Yang,Zhaohe Liao,Haonan Zhao,Li Niu*

Main category: cs.CV

TL;DR: AnimateScene提出了一种统一框架，解决了3D场景重建与4D人体动画无缝集成的挑战，包括位置放置、风格对齐和相机轨迹重建。


<details>
  <summary>Details</summary>
Motivation: 将3D场景重建与4D人体动画无缝集成以生成视觉吸引力的结果存在挑战，如位置与比例匹配、光照风格一致性和相机轨迹重建。

Method: AnimateScene包含三个模块：精确放置模块、无训练风格对齐方法和联合后重建方法，分别解决位置、风格和相机轨迹问题。

Result: 实验表明，AnimateScene能生成具有高几何细节和时空一致性的动态场景视频。

Conclusion: AnimateScene通过统一框架解决了3D场景与4D人体动画集成的关键问题，实现了高质量的动态场景生成。

Abstract: 3D scene reconstruction and 4D human animation have seen rapid progress and
broad adoption in recent years. However, seamlessly integrating reconstructed
scenes with 4D human animation to produce visually engaging results remains
challenging. One key difficulty lies in placing the human at the correct
location and scale within the scene while avoiding unrealistic
interpenetration. Another challenge is that the human and the background may
exhibit different lighting and style, leading to unrealistic composites. In
addition, appealing character motion videos are often accompanied by camera
movements, which means that the viewpoints need to be reconstructed along a
specified trajectory. We present AnimateScene, which addresses the above issues
in a unified framework. First, we design an accurate placement module that
automatically determines a plausible 3D position for the human and prevents any
interpenetration within the scene during motion. Second, we propose a
training-free style alignment method that adapts the 4D human representation to
match the background's lighting and style, achieving coherent visual
integration. Finally, we design a joint post-reconstruction method for both the
4D human and the 3D scene that allows camera trajectories to be inserted,
enabling the final rendered video to feature visually appealing camera
movements. Extensive experiments show that AnimateScene generates dynamic scene
videos with high geometric detail and spatiotemporal coherence across various
camera and action combinations.

</details>


### [95] [ETA: Energy-based Test-time Adaptation for Depth Completion](https://arxiv.org/abs/2508.05989)
*Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong*

Main category: cs.CV

TL;DR: 提出了一种基于能量的测试时适应方法（ETA），用于预训练深度补全模型的测试时适应，通过对抗扰动探索数据空间并训练能量模型，显著提升了模型在新环境条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 深度补全模型在从源数据迁移到目标数据时，由于协变量偏移导致预测错误。现有方法缺乏对目标数据的先验知识，因此需要一种无需假设目标分布的方法。

Method: 利用对抗扰动探索数据空间，训练能量模型评估深度预测的分布情况，并在测试时通过最小化能量更新模型参数，使其预测更接近源分布。

Result: 在三个室内和三个室外数据集上，ETA平均分别提升了10.23%和6.94%，优于现有最佳方法。

Conclusion: ETA通过能量模型和测试时适应，有效解决了深度补全模型在新环境中的性能下降问题，具有广泛的应用潜力。

Abstract: We propose a method for test-time adaptation of pretrained depth completion
models. Depth completion models, trained on some ``source'' data, often predict
erroneous outputs when transferred to ``target'' data captured in novel
environmental conditions due to a covariate shift. The crux of our method lies
in quantifying the likelihood of depth predictions belonging to the source data
distribution. The challenge is in the lack of access to out-of-distribution
(target) data prior to deployment. Hence, rather than making assumptions
regarding the target distribution, we utilize adversarial perturbations as a
mechanism to explore the data space. This enables us to train an energy model
that scores local regions of depth predictions as in- or out-of-distribution.
We update the parameters of pretrained depth completion models at test time to
minimize energy, effectively aligning test-time predictions to those of the
source distribution. We call our method ``Energy-based Test-time Adaptation'',
or ETA for short. We evaluate our method across three indoor and three outdoor
datasets, where ETA improve over the previous state-of-the-art method by an
average of 6.94% for outdoors and 10.23% for indoors. Project Page:
https://fuzzythecat.github.io/eta.

</details>


### [96] [Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision](https://arxiv.org/abs/2508.05990)
*Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han*

Main category: cs.CV

TL;DR: 提出了一种高效视频计算机视觉系统，通过移除图像信号处理器和引入快速块匹配运动估计算法，显著减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 视频计算机视觉系统因时间冗余和前端计算开销而效率低下，现有方法未能充分解决这些问题。

Method: 1. 移除图像信号处理器，直接输入Bayer格式数据；2. 提出快速块匹配运动估计算法，并引入运动矢量细化模块和上下文感知块细化网络；3. 采用帧选择策略平衡精度与效率。

Result: 在多个视频计算机视觉任务中，方法实现了显著加速，性能损失轻微。

Conclusion: 该方法通过减少冗余和优化前端计算，显著提升了视频计算机视觉系统的效率。

Abstract: The efficiency of video computer vision system remains a challenging task due
to the high temporal redundancy inside a video. Existing works have been
proposed for efficient vision computer vision. However, they do not fully
reduce the temporal redundancy and neglect the front end computation overhead.
In this paper, we propose an efficient video computer vision system. First,
image signal processor is removed and Bayer-format data is directly fed into
video computer vision models, thus saving the front end computation. Second,
instead of optical flow models and video codecs, a fast block matching-based
motion estimation algorithm is proposed specifically for efficient video
computer vision, with a MV refinement module. To correct the error,
context-aware block refinement network is introduced to refine regions with
large error. To further balance the accuracy and efficiency, a frame selection
strategy is employed. Experiments on multiple video computer vision tasks
demonstrate that our method achieves significant acceleration with slight
performance loss.

</details>


### [97] [ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge](https://arxiv.org/abs/2508.05991)
*Juewen Hu,Yexin Li,Jiulin Li,Shuo Chen,Pring Wong*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态情感识别框架，通过预训练模型提取视觉、音频和文本特征，并采用双分支视觉编码器和上下文增强方法优化特征提取。融合策略结合自注意力机制和残差连接，同时通过多源标签策略优化训练数据。该方法在MER2025-SEMI数据集上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互中的情感识别能力，解决数据稀缺问题。

Method: 利用预训练模型提取多模态特征，设计双分支视觉编码器和上下文增强文本方法，融合策略结合自注意力机制和残差连接，优化训练标签。

Result: 在MER2025-SEMI数据集上加权F-score达到87.49%，显著优于基线模型的78.63%。

Conclusion: 提出的框架在多模态情感识别任务中表现优异，验证了其有效性。

Abstract: Emotion recognition plays a vital role in enhancing human-computer
interaction. In this study, we tackle the MER-SEMI challenge of the MER2025
competition by proposing a novel multimodal emotion recognition framework. To
address the issue of data scarcity, we leverage large-scale pre-trained models
to extract informative features from visual, audio, and textual modalities.
Specifically, for the visual modality, we design a dual-branch visual encoder
that captures both global frame-level features and localized facial
representations. For the textual modality, we introduce a context-enriched
method that employs large language models to enrich emotional cues within the
input text. To effectively integrate these multimodal features, we propose a
fusion strategy comprising two key components, i.e., self-attention mechanisms
for dynamic modality weighting, and residual connections to preserve original
representations. Beyond architectural design, we further refine noisy labels in
the training set by a multi-source labeling strategy. Our approach achieves a
substantial performance improvement over the official baseline on the
MER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to
78.63%, thereby validating the effectiveness of the proposed framework.

</details>


### [98] [EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad](https://arxiv.org/abs/2508.05994)
*Huadong Wu,Yi Fu,Yunhao Li,Yuan Gao,Kang Du*

Main category: cs.CV

TL;DR: 论文提出MakeupQuad数据集和EvoMakeup框架，解决现有面部化妆编辑方法在细节和保真度上的不足，实现高质量、可控的多任务化妆编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法因缺乏结构化配对数据，导致化妆细节粗糙且难以同时保持身份和化妆保真度。

Method: 引入MakeupQuad数据集，提出EvoMakeup框架，通过多阶段蒸馏避免图像退化，支持多任务化妆编辑。

Result: EvoMakeup在真实基准测试中表现优异，支持高保真、可控的全脸和局部化妆编辑，以及文本驱动的编辑。

Conclusion: EvoMakeup在化妆保真度和身份保持上取得平衡，优于现有方法，代码和数据集将公开。

Abstract: Facial makeup editing aims to realistically transfer makeup from a reference
to a target face. Existing methods often produce low-quality results with
coarse makeup details and struggle to preserve both identity and makeup
fidelity, mainly due to the lack of structured paired data -- where source and
result share identity, and reference and result share identical makeup. To
address this, we introduce MakeupQuad, a large-scale, high-quality dataset with
non-makeup faces, references, edited results, and textual makeup descriptions.
Building on this, we propose EvoMakeup, a unified training framework that
mitigates image degradation during multi-stage distillation, enabling iterative
improvement of both data and model quality. Although trained solely on
synthetic data, EvoMakeup generalizes well and outperforms prior methods on
real-world benchmarks. It supports high-fidelity, controllable, multi-task
makeup editing -- including full-face and partial reference-based editing, as
well as text-driven makeup editing -- within a single model. Experimental
results demonstrate that our method achieves superior makeup fidelity and
identity preservation, effectively balancing both aspects. Code and dataset
will be released upon acceptance.

</details>


### [99] [MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2508.06009)
*Jun Feng,Zixin Wang,Zhentao Zhang,Yue Guo,Zhihan Zhou,Xiuyi Chen,Zhenyang Li,Dawei Yin*

Main category: cs.CV

TL;DR: MathReal是一个包含2000个真实教育场景数学问题的数据集，用于评估多模态大语言模型（MLLMs）在现实教育环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多基于干净或处理过的多模态输入，未涵盖真实K-12教育用户提供的图像，MathReal填补了这一空白。

Method: 构建MathReal数据集，包含真实场景下的数学问题图像，并分类为图像质量、视角变化和无关内容干扰三类。设计六种实验设置评估MLLMs表现。

Result: 现有MLLMs在真实教育场景中的问题解决能力受到显著挑战，研究分析了其表现和错误模式。

Conclusion: 研究为MLLMs的识别、理解和推理能力提供了改进方向，并开源了数据集和代码。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in visual mathematical reasoning across various existing
benchmarks. However, these benchmarks are predominantly based on clean or
processed multimodal inputs, without incorporating the images provided by
real-world Kindergarten through 12th grade (K-12) educational users. To address
this gap, we introduce MathReal, a meticulously curated dataset comprising
2,000 mathematical questions with images captured by handheld mobile devices in
authentic scenarios. Each question is an image, containing the question text
and visual element. We systematically classify the real images into three
primary categories: image quality degradation, perspective variation, and
irrelevant content interference, which are further delineated into 14
subcategories. Additionally, MathReal spans five core knowledge and ability
categories, which encompass three question types and are divided into three
difficulty levels. To comprehensively evaluate the multimodal mathematical
reasoning abilities of state-of-the-art MLLMs in real-world scenarios, we
design six experimental settings that enable a systematic analysis of their
performance. Through extensive experimentation, we find that the
problem-solving abilities of existing MLLMs are significantly challenged in
realistic educational contexts. Based on this, we conduct a thorough analysis
of their performance and error patterns, providing insights into their
recognition, comprehension, and reasoning capabilities, and outlining
directions for future improvements. Data and code:
https://github.com/junfeng0288/MathReal.

</details>


### [100] [ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors](https://arxiv.org/abs/2508.06014)
*Minsu Kim,Subin Jeon,In Cho,Mijin Yoo,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯泼溅（3DGS）的流程，通过生成额外训练视图和改进渲染结果，显著提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在偏离训练轨迹的视角下渲染时存在伪影和缺失区域，限制了场景的无缝探索。

Method: 采用信息增益驱动的虚拟相机放置策略和视频扩散先验，优化3D高斯重建。

Result: 实验表明，该方法优于现有3DGS方法，实现了高质量、无伪影的任意视角渲染。

Conclusion: 提出的方法显著提升了3DGS的重建质量，适用于挑战性场景探索。

Abstract: Recent advances in novel view synthesis (NVS) have enabled real-time
rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle
with artifacts and missing regions when rendering from viewpoints that deviate
from the training trajectory, limiting seamless scene exploration. To address
this, we propose a 3DGS-based pipeline that generates additional training views
to enhance reconstruction. We introduce an information-gain-driven virtual
camera placement strategy to maximize scene coverage, followed by video
diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with
these enhanced views significantly improves reconstruction quality. To evaluate
our method, we present Wild-Explore, a benchmark designed for challenging scene
exploration. Experiments demonstrate that our approach outperforms existing
3DGS-based methods, enabling high-quality, artifact-free rendering from
arbitrary viewpoints.
  https://exploregs.github.io

</details>


### [101] [Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis](https://arxiv.org/abs/2508.06021)
*Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve*

Main category: cs.CV

TL;DR: 利用深度学习结合流式成像显微镜分析亚可见颗粒，但数据稀缺和类别不平衡是主要挑战。本文开发了一种扩散模型生成高质量图像以解决数据不平衡问题，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺和类别不平衡限制了多分类器在亚可见颗粒分析中的应用，尤其是对罕见颗粒类型（如硅油和气泡）的分类效果较差。

Method: 开发了一种先进的扩散模型，生成高保真图像以增强训练数据集，并通过大规模实验验证其有效性。

Result: 生成的样本在视觉质量和结构上与真实颗粒图像相似，实验表明该方法显著提高了分类性能。

Conclusion: 扩散模型生成的图像能有效解决数据不平衡问题，提升分类性能，相关模型和工具已开源。

Abstract: Sub-visible particle analysis using flow imaging microscopy combined with
deep learning has proven effective in identifying particle types, enabling the
distinction of harmless components such as silicone oil from protein particles.
However, the scarcity of available data and severe imbalance between particle
types within datasets remain substantial hurdles when applying multi-class
classifiers to such problems, often forcing researchers to rely on less
effective methods. The aforementioned issue is particularly challenging for
particle types that appear unintentionally and in lower numbers, such as
silicone oil and air bubbles, as opposed to protein particles, where obtaining
large numbers of images through controlled settings is comparatively
straightforward. In this work, we develop a state-of-the-art diffusion model to
address data imbalance by generating high-fidelity images that can augment
training datasets, enabling the effective training of multi-class deep neural
networks. We validate this approach by demonstrating that the generated samples
closely resemble real particle images in terms of visual quality and structure.
To assess the effectiveness of using diffusion-generated images in training
datasets, we conduct large-scale experiments on a validation dataset comprising
500,000 protein particle images and demonstrate that this approach improves
classification performance with no negligible downside. Finally, to promote
open research and reproducibility, we publicly release both our diffusion
models and the trained multi-class deep neural network classifiers, along with
a straightforward interface for easy integration into future studies, at
https://github.com/utkuozbulak/svp-generative-ai.

</details>


### [102] [Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts](https://arxiv.org/abs/2508.06032)
*Kiran Chhatre,Christopher Peters,Srikrishna Karanam*

Main category: cs.CV

TL;DR: Spectrum提出了一种基于扩散模型的统一网络，用于像素级人体解析（身体部位和服装）和实例级分组，通过改进的图像到纹理扩散模型提升细粒度解析能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人体解析中通常使用固定掩码类别，无法区分细粒度服装类型；而开放词汇分割方法虽能零样本迁移，但缺乏对服装多样性和身体细节的区分。

Method: Spectrum利用经过微调的图像到纹理（I2Tx）扩散模型提取特征，并通过提示引导生成语义有效的掩码，实现细粒度解析。

Result: 实验表明，Spectrum在身体部位、服装类别和未见服装的解析任务中均优于基线方法。

Conclusion: Spectrum通过改进的扩散模型实现了更精细的人体解析，为开放词汇分割提供了新思路。

Abstract: Existing methods for human parsing into body parts and clothing often use
fixed mask categories with broad labels that obscure fine-grained clothing
types. Recent open-vocabulary segmentation approaches leverage pretrained
text-to-image (T2I) diffusion model features for strong zero-shot transfer, but
typically group entire humans into a single person category, failing to
distinguish diverse clothing or detailed body parts. To address this, we
propose Spectrum, a unified network for part-level pixel parsing (body parts
and clothing) and instance-level grouping. While diffusion-based
open-vocabulary models generalize well across tasks, their internal
representations are not specialized for detailed human parsing. We observe
that, unlike diffusion models with broad representations, image-driven 3D
texture generators maintain faithful correspondence to input images, enabling
stronger representations for parsing diverse clothing and body parts. Spectrum
introduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model --
obtained by fine-tuning a T2I model on 3D human texture maps -- for improved
alignment with body parts and clothing. From an input image, we extract
human-part internal features via the I2Tx diffusion model and generate
semantically valid masks aligned to diverse clothing categories through
prompt-guided grounding. Once trained, Spectrum produces semantic segmentation
maps for every visible body part and clothing category, ignoring standalone
garments or irrelevant objects, for any number of humans in the scene. We
conduct extensive cross-dataset experiments -- separately assessing body parts,
clothing parts, unseen clothing categories, and full-body masks -- and
demonstrate that Spectrum consistently outperforms baseline methods in
prompt-based segmentation.

</details>


### [103] [GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.06113)
*Jian Wang,Chaokang Jiang,Haitao Xu*

Main category: cs.CV

TL;DR: GMF-Drive提出了一种基于门控Mamba融合的端到端自动驾驶框架，通过几何增强的LiDAR表示和高效的空间感知状态空间模型，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于Transformer的融合方法在自动驾驶中存在计算复杂度高和缺乏空间先验的问题，限制了高分辨率特征的使用和对BEV表示的有效建模。

Method: 采用几何增强的LiDAR表示和门控Mamba融合架构（GM-Fusion），替代Transformer，利用状态空间模型（SSM）实现线性复杂度的长程依赖建模。

Result: 在NAVSIM基准测试中，GMF-Drive性能显著优于DiffusionDrive，达到新的SOTA。

Conclusion: 任务特定的SSM在自动驾驶中优于通用Transformer，证明了GMF-Drive在性能和效率上的优势。

Abstract: Diffusion-based models are redefining the state-of-the-art in end-to-end
autonomous driving, yet their performance is increasingly hampered by a
reliance on transformer-based fusion. These architectures face fundamental
limitations: quadratic computational complexity restricts the use of
high-resolution features, and a lack of spatial priors prevents them from
effectively modeling the inherent structure of Bird's Eye View (BEV)
representations. This paper introduces GMF-Drive (Gated Mamba Fusion for
Driving), an end-to-end framework that overcomes these challenges through two
principled innovations. First, we supersede the information-limited
histogram-based LiDAR representation with a geometrically-augmented pillar
format encoding shape descriptors and statistical features, preserving critical
3D geometric details. Second, we propose a novel hierarchical gated mamba
fusion (GM-Fusion) architecture that substitutes an expensive transformer with
a highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM
leverages directional sequencing and adaptive fusion mechanisms to capture
long-range dependencies with linear complexity, while explicitly respecting the
unique spatial properties of the driving scene. Extensive experiments on the
challenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new
state-of-the-art performance, significantly outperforming DiffusionDrive.
Comprehensive ablation studies validate the efficacy of each component,
demonstrating that task-specific SSMs can surpass a general-purpose transformer
in both performance and efficiency for autonomous driving.

</details>


### [104] [InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow](https://arxiv.org/abs/2508.06033)
*Yiming Gong,Zhen Zhu,Minjia Zhang*

Main category: cs.CV

TL;DR: InstantEdit是一种基于RectifiedFlow框架的快速文本引导图像编辑方法，通过PerRFI反转策略和Inversion Latent Injection技术实现高效编辑，同时结合Disentangled Prompt Guidance和ControlNet提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导图像编辑方法在速度和编辑效果上存在不足，InstantEdit旨在通过RectifiedFlow框架实现快速且高质量的编辑。

Method: 采用PerRFI反转策略和Inversion Latent Injection技术，结合Disentangled Prompt Guidance和Canny-conditioned ControlNet。

Result: 在PIE数据集上，InstantEdit在速度和编辑质量上均优于现有方法。

Conclusion: InstantEdit通过RectifiedFlow框架和多项创新技术，实现了快速且高质量的文本引导图像编辑。

Abstract: We propose a fast text-guided image editing method called InstantEdit based
on the RectifiedFlow framework, which is structured as a few-step editing
process that preserves critical content while following closely to textual
instructions. Our approach leverages the straight sampling trajectories of
RectifiedFlow by introducing a specialized inversion strategy called PerRFI. To
maintain consistent while editable results for RectifiedFlow model, we further
propose a novel regeneration method, Inversion Latent Injection, which
effectively reuses latent information obtained during inversion to facilitate
more coherent and detailed regeneration. Additionally, we propose a
Disentangled Prompt Guidance technique to balance editability with detail
preservation, and integrate a Canny-conditioned ControlNet to incorporate
structural cues and suppress artifacts. Evaluation on the PIE image editing
dataset demonstrates that InstantEdit is not only fast but also achieves better
qualitative and quantitative results compared to state-of-the-art few-step
editing methods.

</details>


### [105] [Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor](https://arxiv.org/abs/2508.06177)
*Dominik Brämer,Diana Kleingarn,Oliver Urbann*

Main category: cs.CV

TL;DR: 提出了一种基于图表示和图卷积网络（GCNs）的机器人定位框架，利用地板特征实现高精度（0.64cm误差）和高效定位，并解决了绑架机器人问题。


<details>
  <summary>Details</summary>
Motivation: 传统定位方法（如激光雷达或QR码）在复杂环境中存在可扩展性和适应性限制，需要更高效、准确的解决方案。

Method: 使用图表示地板特征，结合GCNs进行定位，避免了复杂的图像特征比较和滤波过程。

Result: 实现了0.64cm的定位误差，并在每帧中成功解决了绑架机器人问题。

Conclusion: 该方法为复杂环境中的机器人导航提供了新的可能性。

Abstract: Accurate localization represents a fundamental challenge in
  robotic navigation. Traditional methodologies, such as Lidar or QR-code based
systems, suffer from inherent scalability and adaptability con straints,
particularly in complex environments. In this work, we propose
  an innovative localization framework that harnesses flooring characteris tics
by employing graph-based representations and Graph Convolutional
  Networks (GCNs). Our method uses graphs to represent floor features,
  which helps localize the robot more accurately (0.64cm error) and more
  efficiently than comparing individual image features. Additionally, this
  approach successfully addresses the kidnapped robot problem in every
  frame without requiring complex filtering processes. These advancements
  open up new possibilities for robotic navigation in diverse environments.

</details>


### [106] [More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment](https://arxiv.org/abs/2508.06036)
*Jun Xie,Yingjian Zhu,Feng Chen,Zhenghao Zhang,Xiaohui Fan,Hongzhu Yi,Xinming Wang,Chen Yu,Yue Bi,Zhaoran Zhao,Xiongjun Guan,Zhepeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种半监督学习框架，通过混合专家模型（MoE）和多模态输入，结合伪标签策略和多专家投票集成，在MER2025-SEMI挑战中取得第二名。


<details>
  <summary>Details</summary>
Motivation: 解决半监督学习中的情感识别问题，利用多模态数据和未标记数据提升模型性能。

Method: 采用混合专家模型（MoE），整合多模态输入（如视觉语言模型和动作单元信息），并引入基于共识的伪标签策略进行两阶段训练。最后通过多专家投票集成和基于规则的重新排序优化预测。

Result: 在MER2025-SEMI测试集上F1得分为0.8772，排名第二。

Conclusion: 提出的框架在多模态情感识别任务中表现优异，验证了伪标签策略和多专家集成的有效性。

Abstract: In this paper, we present our solution for the semi-supervised learning track
(MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the
principle that "more is better," to construct a robust Mixture of Experts (MoE)
emotion recognition system. Our approach integrates a diverse range of input
modalities as independent experts, including novel signals such as knowledge
from large Vision-Language Models (VLMs) and temporal Action Unit (AU)
information. To effectively utilize unlabeled data, we introduce a
consensus-based pseudo-labeling strategy, generating high-quality labels from
the agreement between a baseline model and Gemini, which are then used in a
two-stage training paradigm. Finally, we employ a multi-expert voting ensemble
combined with a rule-based re-ranking process to correct prediction bias and
better align the outputs with human preferences. Evaluated on the MER2025-SEMI
challenge dataset, our method achieves an F1-score of 0.8772 on the test set,
ranking 2nd in the track. Our code is available at
https://github.com/zhuyjan/MER2025-MRAC25.

</details>


### [107] [Depth Jitter: Seeing through the Depth](https://arxiv.org/abs/2508.06227)
*Md Sazidur Rahman,David Cabecinhas,Ricard Marxer*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度的数据增强方法Depth-Jitter，通过模拟自然深度变化提升模型在深度敏感环境中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强方法忽略了深度感知变换，限制了模型在真实世界深度变化中的鲁棒性。

Method: Depth-Jitter通过自适应深度偏移和深度方差阈值生成合成深度扰动，同时保持结构完整性。

Result: 在FathomNet和UTDAC2020数据集上的实验表明，Depth-Jitter能提升模型在深度变化下的稳定性，但性能不一定优于传统方法。

Conclusion: Depth-Jitter为深度感知增强提供了新思路，代码已开源，支持进一步研究。

Abstract: Depth information is essential in computer vision, particularly in underwater
imaging, robotics, and autonomous navigation. However, conventional
augmentation techniques overlook depth aware transformations, limiting model
robustness in real world depth variations. In this paper, we introduce
Depth-Jitter, a novel depth-based augmentation technique that simulates natural
depth variations to improve generalization. Our approach applies adaptive depth
offsetting, guided by depth variance thresholds, to generate synthetic depth
perturbations while preserving structural integrity. We evaluate Depth-Jitter
on two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on
model stability under diverse depth conditions. Extensive experiments compare
Depth-Jitter against traditional augmentation strategies such as ColorJitter,
analyzing performance across varying learning rates, encoders, and loss
functions. While Depth-Jitter does not always outperform conventional methods
in absolute performance, it consistently enhances model stability and
generalization in depth-sensitive environments. These findings highlight the
potential of depth-aware augmentation for real-world applications and provide a
foundation for further research into depth-based learning strategies. The
proposed technique is publicly available to support advancements in depth-aware
augmentation. The code is publicly available on
\href{https://github.com/mim-team/Depth-Jitter}{github}.

</details>


### [108] [Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models](https://arxiv.org/abs/2508.06038)
*Huanyu Wang,Jushi Kai,Haoli Bai,Lu Hou,Bo Jiang,Ziwei He,Zhouhan Lin*

Main category: cs.CV

TL;DR: Fourier-VLM通过频域压缩视觉特征，显著减少计算开销和推理延迟，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型中大量视觉标记增加了上下文长度，导致高计算开销和延迟，现有方法常牺牲性能或增加额外成本。

Method: 利用二维离散余弦变换（DCT）对视觉特征进行低通滤波，通过FFT高效计算，减少标记数量。

Result: 在多个基准测试中表现优异，推理FLOPs减少83.8%，生成速度提升31.2%。

Conclusion: Fourier-VLM在高效性和实用性上表现突出，适用于多种架构。

Abstract: Vision-Language Models (VLMs) typically replace the predefined image
placeholder token (<image>) in textual instructions with visual features from
an image encoder, forming the input to a backbone Large Language Model (LLM).
However, the large number of vision tokens significantly increases the context
length, leading to high computational overhead and inference latency. While
previous efforts mitigate this by selecting only important visual features or
leveraging learnable queries to reduce token count, they often compromise
performance or introduce substantial extra costs. In response, we propose
Fourier-VLM, a simple yet efficient method that compresses visual
representations in the frequency domain. Our approach is motivated by the
observation that vision features output from the vision encoder exhibit
concentrated energy in low-frequency components. Leveraging this, we apply a
low-pass filter to the vision features using a two-dimentional Discrete Cosine
Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier
Transform (FFT) operator with a time complexity of $\mathcal{O}(n\log n)$,
minimizing the extra computational cost while introducing no additional
parameters. Extensive experiments across various image-based benchmarks
demonstrate that Fourier-VLM achieves competitive performance with strong
generalizability across both LLaVA and Qwen-VL architectures. Crucially, it
reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%
compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.

</details>


### [109] [NEP: Autoregressive Image Editing via Next Editing Token Prediction](https://arxiv.org/abs/2508.06044)
*Huimin Wu,Xiaojian Ma,Haozhe Zhao,Yanpeng Zhao,Qing Li*

Main category: cs.CV

TL;DR: 提出了一种基于自回归图像生成的Next Editing-token Prediction（NEP）方法，仅编辑需要修改的区域，避免不必要的计算和非编辑区域的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成整个目标图像，导致计算成本高且编辑质量受限。

Method: 预训练一个任意顺序的自回归文本到图像（T2I）模型，支持零样本图像编辑，并适应NEP方法。

Result: 在广泛使用的图像编辑基准测试中达到新最优性能，并支持零样本迭代优化（TTS）。

Conclusion: NEP方法显著提升了图像编辑的效率和质量，同时支持灵活的零样本应用。

Abstract: Text-guided image editing involves modifying a source image based on a
language instruction and, typically, requires changes to only small local
regions. However, existing approaches generate the entire target image rather
than selectively regenerate only the intended editing areas. This results in
(1) unnecessary computational costs and (2) a bias toward reconstructing
non-editing regions, which compromises the quality of the intended edits. To
resolve these limitations, we propose to formulate image editing as Next
Editing-token Prediction (NEP) based on autoregressive image generation, where
only regions that need to be edited are regenerated, thus avoiding unintended
modification to the non-editing areas. To enable any-region editing, we propose
to pre-train an any-order autoregressive text-to-image (T2I) model. Once
trained, it is capable of zero-shot image editing and can be easily adapted to
NEP for image editing, which achieves a new state-of-the-art on widely used
image editing benchmarks. Moreover, our model naturally supports test-time
scaling (TTS) through iteratively refining its generation in a zero-shot
manner. The project page is: https://nep-bigai.github.io/

</details>


### [110] [VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning](https://arxiv.org/abs/2508.06051)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Jun Jia,Kaiwei Zhang,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: VQAThinker是一个基于推理的视频质量评估框架，利用多模态模型和强化学习解决现有模型的泛化性和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型在泛化性和可解释性上存在不足，限制了实际应用。

Method: 采用GRPO强化学习算法，结合三种VQA特定奖励机制（回归、排序和时间一致性）。

Result: 在领域内和OOD基准测试中表现优异，泛化性强，且在质量描述和失真归因上优于现有模型。

Conclusion: 强化学习为构建仅需分数监督的泛化性和可解释性VQA模型提供了有效途径。

Abstract: Video quality assessment (VQA) aims to objectively quantify perceptual
quality degradation in alignment with human visual perception. Despite recent
advances, existing VQA models still suffer from two critical limitations:
\textit{poor generalization to out-of-distribution (OOD) videos} and
\textit{limited explainability}, which restrict their applicability in
real-world scenarios. To address these challenges, we propose
\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large
multimodal models (LMMs) with reinforcement learning to jointly model video
quality understanding and scoring, emulating human perceptual decision-making.
Specifically, we adopt group relative policy optimization (GRPO), a rule-guided
reinforcement learning algorithm that enables reasoning over video quality
under score-level supervision, and introduce three VQA-specific rewards: (1) a
\textbf{bell-shaped regression reward} that increases rapidly as the prediction
error decreases and becomes progressively less sensitive near the ground truth;
(2) a \textbf{pairwise ranking reward} that guides the model to correctly
determine the relative quality between video pairs; and (3) a \textbf{temporal
consistency reward} that encourages the model to prefer temporally coherent
videos over their perturbed counterparts. Extensive experiments demonstrate
that VQAThinker achieves state-of-the-art performance on both in-domain and OOD
VQA benchmarks, showing strong generalization for video quality scoring.
Furthermore, evaluations on video quality understanding tasks validate its
superiority in distortion attribution and quality description compared to
existing explainable VQA models and LMMs. These findings demonstrate that
reinforcement learning offers an effective pathway toward building
generalizable and explainable VQA models solely with score-level supervision.

</details>


### [111] [LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing](https://arxiv.org/abs/2508.06055)
*Wonjung Park,Suhyun Ahn,Jinah Park*

Main category: cs.CV

TL;DR: LV-Net是一个用于从脑MRI生成个性化3D侧脑室（LV）网格的新框架，通过变形解剖学感知的联合LV-海马模板网格，提高了分割和重建的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 侧脑室形状分析作为神经系统疾病的生物标志物具有潜力，但由于个体间形状差异大和MRI分辨率限制导致的分割困难，仍面临挑战。

Method: LV-Net通过变形联合LV-海马模板网格，利用解剖关系减少分割伪影，并通过顶点分类增强点对应性。

Result: LV-Net在分割不完美的情况下仍实现高重建精度，并在阿尔茨海默病分析中识别出与疾病显著相关的LV子区域。

Conclusion: LV-Net提高了LV形状分析的准确性和鲁棒性，为神经系统疾病研究提供了可靠工具。

Abstract: Lateral ventricle (LV) shape analysis holds promise as a biomarker for
neurological diseases; however, challenges remain due to substantial shape
variability across individuals and segmentation difficulties arising from
limited MRI resolution. We introduce LV-Net, a novel framework for producing
individualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint
LV-hippocampus template mesh. By incorporating anatomical relationships
embedded within the joint template, LV-Net reduces boundary segmentation
artifacts and improves reconstruction robustness. In addition, by classifying
the vertices of the template mesh based on their anatomical adjacency, our
method enhances point correspondence across subjects, leading to more accurate
LV shape statistics. We demonstrate that LV-Net achieves superior
reconstruction accuracy, even in the presence of segmentation imperfections,
and delivers more reliable shape descriptors across diverse datasets. Finally,
we apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that
show significantly associations with the disease relative to cognitively normal
controls. The codes for LV shape modeling are available at
https://github.com/PWonjung/LV_Shape_Modeling.

</details>


### [112] [AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?](https://arxiv.org/abs/2508.06057)
*Mojtaba Valipour,Kelly Zheng,James Lowman,Spencer Szabados,Mike Gartner,Bobby Braswell*

Main category: cs.CV

TL;DR: 本文探讨了卫星光谱影像作为AGI多模态数据的重要性，指出现有基准的不足，并提出了更全面的评估任务。


<details>
  <summary>Details</summary>
Motivation: 卫星光谱影像在AGI研究中未受足够重视，但其对理解自然世界具有潜力，需改进评估基准。

Method: 分析现有基准的局限性，并提出一套全面的任务以评估地球观测模型的泛化能力。

Result: 强调了卫星光谱影像的价值，并设计了更全面的评估任务。

Conclusion: 需建立更全面的基准以推动地球观测模型的发展。

Abstract: Artificial General Intelligence (AGI) is closer than ever to becoming a
reality, sparking widespread enthusiasm in the research community to collect
and work with various modalities, including text, image, video, and audio.
Despite recent efforts, satellite spectral imagery, as an additional modality,
has yet to receive the attention it deserves. This area presents unique
challenges, but also holds great promise in advancing the capabilities of AGI
in understanding the natural world. In this paper, we argue why Earth
Observation data is useful for an intelligent model, and then we review
existing benchmarks and highlight their limitations in evaluating the
generalization ability of foundation models in this domain. This paper
emphasizes the need for a more comprehensive benchmark to evaluate earth
observation models. To facilitate this, we propose a comprehensive set of tasks
that a benchmark should encompass to effectively assess a model's ability to
understand and interact with Earth observation data.

</details>


### [113] [Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention](https://arxiv.org/abs/2508.06058)
*Shiyang Zhou,Haijin Zeng,Yunfan Lu,Yongyong Chen,Jie Liu,Jingyong Su*

Main category: cs.CV

TL;DR: TSANet是一种轻量级的两阶段网络，通过状态空间增强的交叉注意力，分别处理事件像素修复和去马赛克，显著提升了HybridEVS相机的图像质量。


<details>
  <summary>Details</summary>
Motivation: HybridEVS相机结合Quad Bayer CFA传感器和事件像素时，由于事件像素缺乏颜色信息，导致去马赛克过程中出现伪影和混叠问题，现有方法难以在资源有限的移动设备上解决这些问题。

Method: TSANet采用两阶段网络设计，分别处理事件像素修复和去马赛克，并引入轻量级的Cross-Swin State Block，利用位置先验和状态空间模型增强全局依赖性。

Result: TSANet在模拟和真实HybridEVS数据上表现出色，PSNR和SSIM优于现有方法DemosaicFormer，同时参数和计算成本分别降低1.86倍和3.29倍。

Conclusion: TSANet为移动设备上的高效图像去马赛克提供了新思路，代码已开源。

Abstract: Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera
capture brightness changes as asynchronous "events" instead of frames, offering
advanced application on mobile photography. However, challenges arise from
combining a Quad Bayer Color Filter Array (CFA) sensor with event pixels
lacking color information, resulting in aliasing and artifacts on the
demosaicing process before downstream application. Current methods struggle to
address these issues, especially on resource-limited mobile devices. In
response, we introduce \textbf{TSANet}, a lightweight \textbf{T}wo-stage
network via \textbf{S}tate space augmented cross-\textbf{A}ttention, which can
handle event pixels inpainting and demosaicing separately, leveraging the
benefits of dividing complex tasks into manageable subtasks. Furthermore, we
introduce a lightweight Cross-Swin State Block that uniquely utilizes
positional prior for demosaicing and enhances global dependencies through the
state space model with linear complexity. In summary, TSANet demonstrates
excellent demosaicing performance on both simulated and real data of HybridEVS
while maintaining a lightweight model, averaging better results than the
previous state-of-the-art method DemosaicFormer across seven diverse datasets
in both PSNR and SSIM, while respectively reducing parameter and computation
costs by $1.86\times$ and $3.29\times$. Our approach presents new possibilities
for efficient image demosaicing on mobile devices. Code is available in the
supplementary materials.

</details>


### [114] [Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection](https://arxiv.org/abs/2508.06063)
*Chao Hao,Zitong Yu,Xin Liu,Yuhao Wang,Weicheng Xie,Jingang Shi,Huanjing Yue,Jingyu Yang*

Main category: cs.CV

TL;DR: SCJoint是一种联合学习方案，用于显著目标检测（SOD）和伪装目标检测（COD）任务，通过最小化任务特定参数实现任务解耦，同时提出SBSS策略优化训练集。


<details>
  <summary>Details</summary>
Motivation: 尽管SOD和COD任务具有矛盾属性，但作者认为通过正确的学习方法，网络可以同时具备检测显著和伪装目标的能力。

Method: 提出SCJoint联合学习方案，学习SOD和COD解码过程的分布特性，并引入SBSS策略平衡训练集。

Result: 实验证明JoNet网络能同时捕获显著和伪装目标，性能优越。

Conclusion: SCJoint和SBSS策略有效，联合学习可行且性能提升。

Abstract: Salient object detection (SOD) and camouflaged object detection (COD) are two
closely related but distinct computer vision tasks. Although both are
class-agnostic segmentation tasks that map from RGB space to binary space, the
former aims to identify the most salient objects in the image, while the latter
focuses on detecting perfectly camouflaged objects that blend into the
background in the image. These two tasks exhibit strong contradictory
attributes. Previous works have mostly believed that joint learning of these
two tasks would confuse the network, reducing its performance on both tasks.
However, here we present an opposite perspective: with the correct approach to
learning, the network can simultaneously possess the capability to find both
salient and camouflaged objects, allowing both tasks to benefit from joint
learning. We propose SCJoint, a joint learning scheme for SOD and COD tasks,
assuming that the decoding processes of SOD and COD have different distribution
characteristics. The key to our method is to learn the respective means and
variances of the decoding processes for both tasks by inserting a minimal
amount of task-specific learnable parameters within a fully shared network
structure, thereby decoupling the contradictory attributes of the two tasks at
a minimal cost. Furthermore, we propose a saliency-based sampling strategy
(SBSS) to sample the training set of the SOD task to balance the training set
sizes of the two tasks. In addition, SBSS improves the training set quality and
shortens the training time. Based on the proposed SCJoint and SBSS, we train a
powerful generalist network, named JoNet, which has the ability to
simultaneously capture both ``salient" and ``camouflaged". Extensive
experiments demonstrate the competitive performance and effectiveness of our
proposed method. The code is available at https://github.com/linuxsino/JoNet.

</details>


### [115] [Can Large Models Fool the Eye? A New Turing Test for Biological Animation](https://arxiv.org/abs/2508.06072)
*Zijian Chen,Lirong Deng,Zhengyu Chen,Kaiwei Zhang,Qi Jia,Yuan Tian,Yucheng Zhu,Guangtao Zhai*

Main category: cs.CV

TL;DR: BioMotion Arena是一个通过视觉动画评估大型语言模型（LLMs）和多模态大型语言模型（MLLMs）的新框架，利用点光源成像放大模型间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试要么基于静态数据集的真实评分，要么采用模糊的聊天机器人式人类偏好收集，无法提供直观的性能差异反馈。

Method: 采用点光源成像技术，通过视觉动画进行成对比较评估，收集了超过45k票的众包数据。

Result: 90%以上的模型（包括前沿的InternVL3和Claude-4系列）无法生成基本的人形点光源组，更不用说平滑且生物学合理的运动。

Conclusion: BioMotion Arena是一个具有挑战性的性能可视化基准测试，无需依赖真实数据，提供灵活的评估框架。

Abstract: Evaluating the abilities of large models and manifesting their gaps are
challenging. Current benchmarks adopt either ground-truth-based score-form
evaluation on static datasets or indistinct textual chatbot-style human
preferences collection, which may not provide users with immediate, intuitive,
and perceptible feedback on performance differences. In this paper, we
introduce BioMotion Arena, a novel framework for evaluating large language
models (LLMs) and multimodal large language models (MLLMs) via visual
animation. Our methodology draws inspiration from the inherent visual
perception of motion patterns characteristic of living organisms that utilizes
point-light source imaging to amplify the performance discrepancies between
models. Specifically, we employ a pairwise comparison evaluation and collect
more than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion
variants. Data analyses show that the crowd-sourced human votes are in good
agreement with those of expert raters, demonstrating the superiority of our
BioMotion Arena in offering discriminative feedback. We also find that over
90\% of evaluated models, including the cutting-edge open-source InternVL3 and
proprietary Claude-4 series, fail to produce fundamental humanoid point-light
groups, much less smooth and biologically plausible motions. This enables
BioMotion Arena to serve as a challenging benchmark for performance
visualization and a flexible evaluation framework without restrictions on
ground-truth.

</details>


### [116] [Towards MR-Based Trochleoplasty Planning](https://arxiv.org/abs/2508.06076)
*Michael Wehrli,Alicia Durrer,Paul Friedrich,Sidaty El Hadramy,Edwin Li,Luana Brahaj,Carol C. Hasler,Philippe C. Cattin*

Main category: cs.CV

TL;DR: 提出了一种从低分辨率MR扫描生成高分辨率3D伪健康目标形态的管道，用于治疗滑车发育不良（TD），无需CT扫描，减少辐射。


<details>
  <summary>Details</summary>
Motivation: 当前TD治疗方法依赖低分辨率MR扫描和外科医生经验，手术结果不一致且微创技术应用有限。

Method: 使用隐式神经表示（INR）生成各向同性超分辨率MR体积，多标签网络分割骨骼，小波扩散模型（WDM）生成伪健康目标形态。

Result: 在25例TD患者中验证，显著改善了滑车角度（SA）和滑车沟深度（TGD）。

Conclusion: 该方法为术前规划提供了高分辨率3D形态，减少辐射且兼容微创手术。

Abstract: To treat Trochlear Dysplasia (TD), current approaches rely mainly on
low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.
The surgeries are planned based on surgeons experience, have limited adoption
of minimally invasive techniques, and lead to inconsistent outcomes. We propose
a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy
target morphologies from conventional clinical MR scans. First, we compute an
isotropic super-resolved MR volume using an Implicit Neural Representation
(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label
custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to
generate pseudo-healthy target morphologies of the trochlear region. In
contrast to prior work producing pseudo-healthy low-resolution 3D MR images,
our approach enables the generation of sub-millimeter resolved 3D shapes
compatible for pre- and intraoperative use. These can serve as preoperative
blueprints for reshaping the femoral groove while preserving the native patella
articulation. Furthermore, and in contrast to other work, we do not require a
CT for our pipeline - reducing the amount of radiation. We evaluated our
approach on 25 TD patients and could show that our target morphologies
significantly improve the sulcus angle (SA) and trochlear groove depth (TGD).
The code and interactive visualization are available at
https://wehrlimi.github.io/sr-3d-planning/.

</details>


### [117] [DreamVE: Unified Instruction-based Image and Video Editing](https://arxiv.org/abs/2508.06080)
*Bin Xia,Jiyang Liu,Yuechen Zhang,Bohao Peng,Ruihang Chu,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: DreamVE是一个基于指令的图像和视频编辑统一模型，通过两阶段训练策略（先图像后视频）和综合数据合成方法（拼贴和生成模型）提升性能。


<details>
  <summary>Details</summary>
Motivation: 指令式编辑潜力巨大，但视频编辑因训练数据有限而受限。DreamVE旨在解决这一问题，统一图像和视频编辑。

Method: 采用两阶段训练策略，结合拼贴和生成模型的数据合成方法，并设计高效的编辑框架。

Result: DreamVE在关键编辑类型上表现优异，泛化和迁移能力强，但属性编辑性能稍弱。

Conclusion: DreamVE通过统一框架和多样化数据合成，显著提升了指令式编辑的实用性和效果。

Abstract: Instruction-based editing holds vast potential due to its simple and
efficient interactive editing format. However, instruction-based editing,
particularly for video, has been constrained by limited training data,
hindering its practical application. To this end, we introduce DreamVE, a
unified model for instruction-based image and video editing. Specifically, We
propose a two-stage training strategy: first image editing, then video editing.
This offers two main benefits: (1) Image data scales more easily, and models
are more efficient to train, providing useful priors for faster and better
video editing training. (2) Unifying image and video generation is natural and
aligns with current trends. Moreover, we present comprehensive training data
synthesis pipelines, including collage-based and generative model-based data
synthesis. The collage-based data synthesis combines foreground objects and
backgrounds to generate diverse editing data, such as object manipulation,
background changes, and text modifications. It can easily generate billions of
accurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE
on extensive collage-based data to achieve strong performance in key editing
types and enhance generalization and transfer capabilities. However,
collage-based data lacks some attribute editing cases, leading to a relative
drop in performance. In contrast, the generative model-based pipeline, despite
being hard to scale up, offers flexibility in handling attribute editing cases.
Therefore, we use generative model-based data to further fine-tune DreamVE.
Besides, we design an efficient and powerful editing framework for DreamVE. We
build on the SOTA T2V model and use a token concatenation with early drop
approach to inject source image guidance, ensuring strong consistency and
editability. The codes and models will be released.

</details>


### [118] [SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment](https://arxiv.org/abs/2508.06082)
*Yanxiao Sun,Jiafu Wu,Yun Cao,Chengming Xu,Yabiao Wang,Weijian Cao,Donghao Luo,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: SwiftVideo提出了一种结合轨迹保持和分布匹配的统一稳定蒸馏框架，显著减少视频生成的推理步骤，同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散或流模型的视频合成方法需要多次迭代采样，计算开销大；而现有蒸馏方法在少步设置下性能下降或产生更多伪影。

Method: 提出连续时间一致性蒸馏确保ODE轨迹精确保持，并通过双视角对齐（分布对齐和轨迹对齐）结合两种策略优势。

Result: 在OpenVid-1M基准测试中，SwiftVideo在少步视频生成中显著优于现有方法。

Conclusion: SwiftVideo通过统一框架解决了少步视频生成的性能问题，同时保持了生成质量。

Abstract: Diffusion-based or flow-based models have achieved significant progress in
video synthesis but require multiple iterative sampling steps, which incurs
substantial computational overhead. While many distillation methods that are
solely based on trajectory-preserving or distribution-matching have been
developed to accelerate video generation models, these approaches often suffer
from performance breakdown or increased artifacts under few-step settings. To
address these limitations, we propose \textbf{\emph{SwiftVideo}}, a unified and
stable distillation framework that combines the advantages of
trajectory-preserving and distribution-matching strategies. Our approach
introduces continuous-time consistency distillation to ensure precise
preservation of ODE trajectories. Subsequently, we propose a dual-perspective
alignment that includes distribution alignment between synthetic and real data
along with trajectory alignment across different inference steps. Our method
maintains high-quality video generation while substantially reducing the number
of inference steps. Quantitative evaluations on the OpenVid-1M benchmark
demonstrate that our method significantly outperforms existing approaches in
few-step video generation.

</details>


### [119] [AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance](https://arxiv.org/abs/2508.06084)
*Weichen Zhang,Zhui Zhu,Ningbo Li,Kebin Liu,Yunhao Liu*

Main category: cs.CV

TL;DR: AdaptInfer是一种自适应视觉令牌剪枝框架，通过动态文本引导和跨模态注意力分析，显著降低推理成本，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型（VLMs）在推理阶段因处理大量视觉令牌导致的高成本问题，现有剪枝方法未能充分利用动态内部信号。

Method: 提出动态文本引导剪枝机制，重用层间文本-文本注意力图构建软先验，并结合跨模态注意力分析设计高效剪枝策略。

Result: 在LLaVA-1.5-7B上，CUDA延迟降低61.3%，平均精度保持92.9%，在相同令牌预算下超越现有最优方法。

Conclusion: AdaptInfer是一种轻量级、即插即用的通用框架，有效平衡了推理成本与精度。

Abstract: Vision-language models (VLMs) have achieved impressive performance on
multimodal reasoning tasks such as visual question answering (VQA), but their
inference cost remains a significant challenge due to the large number of
vision tokens processed during the prefill stage. Existing pruning methods
often rely on directly using the attention patterns or static text prompt
guidance, failing to exploit the dynamic internal signals generated during
inference. To address these issues, we propose AdaptInfer, a plug-and-play
framework for adaptive vision token pruning in VLMs. First, we introduce a
fine-grained, dynamic text-guided pruning mechanism that reuses layer-wise
text-to-text attention maps to construct soft priors over text-token
importance, allowing more informed scoring of vision tokens at each stage.
Second, we perform an offline analysis of cross-modal attention shifts and
identify consistent inflection locations in inference, which inspire us to
propose a more principled and efficient pruning schedule. Our method is
lightweight and plug-and-play, also generalizable across multi-modal tasks.
Experimental results have verified the effectiveness of the proposed method.
For example, it reduces CUDA latency by 61.3\% while maintaining an average
accuracy of 92.9\% on vanilla LLaVA-1.5-7B. Under the same token budget,
AdaptInfer surpasses SOTA in accuracy.

</details>


### [120] [Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation](https://arxiv.org/abs/2508.06092)
*Yachun Mi,Yu Li,Yanting Li,Shixin Sun,Chen Hui,Tong Zhang,Yuanyuan Liu,Chenyue Song,Shaohui Liu*

Main category: cs.CV

TL;DR: Q-CLIP是一种基于视觉语言模型（VLMs）的视频质量评估（VQA）框架，通过共享跨模态适配器（SCMA）和可学习的质量提示，显著降低了计算成本并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前VQA方法依赖大规模分类数据集的预训练，存在语义知识不足和计算资源消耗大的问题。

Method: 提出Q-CLIP框架，利用SCMA增强视觉和文本表示，并引入质量提示和帧差采样策略。

Result: Q-CLIP在多个VQA数据集上表现出色。

Conclusion: Q-CLIP为VQA提供了一种高效且性能优越的解决方案。

Abstract: Accurate and efficient Video Quality Assessment (VQA) has long been a key
research challenge. Current mainstream VQA methods typically improve
performance by pretraining on large-scale classification datasets (e.g.,
ImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this
strategy presents two significant challenges: (1) merely transferring semantic
knowledge learned from pretraining is insufficient for VQA, as video quality
depends on multiple factors (e.g., semantics, distortion, motion, aesthetics);
(2) pretraining on large-scale datasets demands enormous computational
resources, often dozens or even hundreds of times greater than training
directly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown
remarkable generalization capabilities across a wide range of visual tasks, and
have begun to demonstrate promising potential in quality assessment. In this
work, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP
enhances both visual and textual representations through a Shared Cross-Modal
Adapter (SCMA), which contains only a minimal number of trainable parameters
and is the only component that requires training. This design significantly
reduces computational cost. In addition, we introduce a set of five learnable
quality-level prompts to guide the VLMs in perceiving subtle quality
variations, thereby further enhancing the model's sensitivity to video quality.
Furthermore, we investigate the impact of different frame sampling strategies
on VQA performance, and find that frame-difference-based sampling leads to
better generalization performance across datasets. Extensive experiments
demonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.

</details>


### [121] [E-React: Towards Emotionally Controlled Synthesis of Human Reactions](https://arxiv.org/abs/2508.06093)
*Chen Zhu,Buzhen Huang,Zijing Wu,Binghui Zuo,Yangang Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于情感驱动的反应动作生成方法，通过半监督情感先验和扩散模型提升生成动作的自然性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有动作生成框架未考虑情感影响，限制了其在交互任务中的应用。本文旨在通过情感驱动生成更自然的反应动作。

Method: 采用半监督学习训练情感先验，结合扩散模型生成反应动作，同时考虑空间交互和情感响应。

Result: 实验表明，该方法在反应动作生成任务中优于现有方法。

Conclusion: 提出的方法能够生成多样且符合情感条件的反应动作，提升了交互任务的自然性。

Abstract: Emotion serves as an essential component in daily human interactions.
Existing human motion generation frameworks do not consider the impact of
emotions, which reduces naturalness and limits their application in interactive
tasks, such as human reaction synthesis. In this work, we introduce a novel
task: generating diverse reaction motions in response to different emotional
cues. However, learning emotion representation from limited motion data and
incorporating it into a motion generation framework remains a challenging
problem. To address the above obstacles, we introduce a semi-supervised emotion
prior in an actor-reactor diffusion model to facilitate emotion-driven reaction
synthesis. Specifically, based on the observation that motion clips within a
short sequence tend to share the same emotion, we first devise a
semi-supervised learning framework to train an emotion prior. With this prior,
we further train an actor-reactor diffusion model to generate reactions by
considering both spatial interaction and emotional response. Finally, given a
motion sequence of an actor, our approach can generate realistic reactions
under various emotional conditions. Experimental results demonstrate that our
model outperforms existing reaction generation methods. The code and data will
be made publicly available at https://ereact.github.io/

</details>


### [122] [UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization](https://arxiv.org/abs/2508.06101)
*Yachun Mi,Xingyang He,Shixin Sun,Yu Li,Yanting Li,Zhixuan Li,Jian Jin,Chen Hui,Shaohui Liu*

Main category: cs.CV

TL;DR: UGD-IML是一种基于扩散模型的生成框架，首次将IML和CIML任务统一在一个框架中，减少了对大规模标注数据的依赖，并在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数字时代中，高级图像编辑工具威胁视觉内容的真实性，现有IML方法依赖大规模标注数据，而数据集规模不足限制了模型性能。

Method: 提出基于扩散模型的生成框架UGD-IML，通过类嵌入机制和参数共享设计，统一IML和CIML任务，减少数据依赖并简化标注流程。

Result: 在多个数据集上，UGD-IML在IML和CIML任务中的F1指标分别平均优于SOTA方法9.66和4.36。

Conclusion: UGD-IML通过生成模型和端到端设计，显著提升了图像篡改检测和定位的性能，同时具备高效性和鲁棒性。

Abstract: In the digital age, advanced image editing tools pose a serious threat to the
integrity of visual content, making image forgery detection and localization a
key research focus. Most existing Image Manipulation Localization (IML) methods
rely on discriminative learning and require large, high-quality annotated
datasets. However, current datasets lack sufficient scale and diversity,
limiting model performance in real-world scenarios. To overcome this, recent
studies have explored Constrained IML (CIML), which generates pixel-level
annotations through algorithmic supervision. However, existing CIML approaches
often depend on complex multi-stage pipelines, making the annotation process
inefficient. In this work, we propose a novel generative framework based on
diffusion models, named UGD-IML, which for the first time unifies both IML and
CIML tasks within a single framework. By learning the underlying data
distribution, generative diffusion models inherently reduce the reliance on
large-scale labeled datasets, allowing our approach to perform effectively even
under limited data conditions. In addition, by leveraging a class embedding
mechanism and a parameter-sharing design, our model seamlessly switches between
IML and CIML modes without extra components or training overhead. Furthermore,
the end-to-end design enables our model to avoid cumbersome steps in the data
annotation process. Extensive experimental results on multiple datasets
demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and
4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the
proposed method also excels in uncertainty estimation, visualization and
robustness.

</details>


### [123] [MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment](https://arxiv.org/abs/2508.06104)
*Gui Zou,Chaofan Gan,Chern Hong Lim,Supavadee Aramvith,Weiyao Lin*

Main category: cs.CV

TL;DR: 提出了一种名为MCA的鲁棒2D-3D跨模态检索框架，通过多模态联合标签校正和多层次自适应对齐，解决了噪声标签条件下的检索问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理噪声标签时容易过拟合，且缺乏跨模态一致性，需要更鲁棒的解决方案。

Method: MCA框架包含多模态联合标签校正（MJC）和多层次自适应对齐（MAA）策略，分别用于标签优化和特征增强。

Result: MCA在传统和噪声3D基准测试中均达到最优性能，验证了其通用性和有效性。

Conclusion: MCA通过联合标签校正和特征对齐，显著提升了噪声标签条件下的跨模态检索性能。

Abstract: With the increasing availability of 2D and 3D data, significant advancements
have been made in the field of cross-modal retrieval. Nevertheless, the
existence of imperfect annotations presents considerable challenges, demanding
robust solutions for 2D-3D cross-modal retrieval in the presence of noisy label
conditions. Existing methods generally address the issue of noise by dividing
samples independently within each modality, making them susceptible to
overfitting on corrupted labels. To address these issues, we propose a robust
2D-3D \textbf{M}ulti-level cross-modal adaptive \textbf{C}orrection and
\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal
Joint label Correction (MJC) mechanism that leverages multimodal historical
self-predictions to jointly model the modality prediction consistency, enabling
reliable label refinement. Additionally, we propose a Multi-level Adaptive
Alignment (MAA) strategy to effectively enhance cross-modal feature semantics
and discrimination across different levels. Extensive experiments demonstrate
the superiority of our method, MCA, which achieves state-of-the-art performance
on both conventional and realistic noisy 3D benchmarks, highlighting its
generality and effectiveness.

</details>


### [124] [Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention](https://arxiv.org/abs/2508.06107)
*Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu*

Main category: cs.CV

TL;DR: 提出了一种自监督学习框架，用于手写数学表达式识别，无需昂贵标注数据，通过对比损失和渐进掩码策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别因二维结构、符号尺度变化和复杂空间关系而具有挑战性，现有方法依赖大量标注数据。

Method: 结合全局和局部对比损失预训练图像编码器，提出自监督注意力网络，采用渐进空间掩码策略学习语义区域。

Result: 在CROHME基准测试中优于现有自监督和全监督基线，验证了渐进注意力机制的有效性。

Conclusion: 自监督学习框架显著提升了手写数学表达式识别的性能，尤其在减少标注数据依赖方面表现出色。

Abstract: Recognizing handwritten mathematical expressions (HMER) is a challenging task
due to the inherent two-dimensional structure, varying symbol scales, and
complex spatial relationships among symbols. In this paper, we present a
self-supervised learning (SSL) framework for HMER that eliminates the need for
expensive labeled data. Our approach begins by pretraining an image encoder
using a combination of global and local contrastive loss, enabling the model to
learn both holistic and fine-grained representations. A key contribution of
this work is a novel self-supervised attention network, which is trained using
a progressive spatial masking strategy. This attention mechanism is designed to
learn semantically meaningful focus regions, such as operators, exponents, and
nested mathematical notation, without requiring any supervision. The
progressive masking curriculum encourages the network to become increasingly
robust to missing or occluded visual information, ultimately improving
structural understanding. Our complete pipeline consists of (1) self-supervised
pretraining of the encoder, (2) self-supervised attention learning, and (3)
supervised fine-tuning with a transformer decoder to generate LATEX sequences.
Extensive experiments on CROHME benchmarks demonstrate that our method
outperforms existing SSL and fully supervised baselines, validating the
effectiveness of our progressive attention mechanism in enhancing HMER
performance. Our codebase can be found here.

</details>


### [125] [FMCE-Net++: Feature Map Convergence Evaluation and Training](https://arxiv.org/abs/2508.06109)
*Zhibo Zhu,Renyu Huang,Lei He*

Main category: cs.CV

TL;DR: FMCE-Net++ 是一种新的训练框架，通过结合特征图收敛评分（FMCS）和任务标签，动态优化主干网络，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络（DNNs）因内部表示不透明而难以解释的问题，同时改进现有FMCE方法缺乏实验验证和闭环集成的不足。

Method: 提出FMCE-Net++框架，集成预训练的冻结FMCE-Net作为辅助头，生成FMCS预测，并通过表示辅助损失（RAL）动态平衡分类损失和特征收敛优化。

Result: 在MNIST、CIFAR-10等数据集上验证，FMCE-Net++显著提升模型性能（如ResNet-50在CIFAR-10上准确率提升1.16个百分点）。

Conclusion: FMCE-Net++无需修改架构或增加数据，即可有效提升模型性能，验证了其优越性。

Abstract: Deep Neural Networks (DNNs) face interpretability challenges due to their
opaque internal representations. While Feature Map Convergence Evaluation
(FMCE) quantifies module-level convergence via Feature Map Convergence Scores
(FMCS), it lacks experimental validation and closed-loop integration. To
address this limitation, we propose FMCE-Net++, a novel training framework that
integrates a pretrained, frozen FMCE-Net as an auxiliary head. This module
generates FMCS predictions, which, combined with task labels, jointly supervise
backbone optimization through a Representation Auxiliary Loss. The RAL
dynamically balances the primary classification loss and feature convergence
optimization via a tunable \Representation Abstraction Factor. Extensive
experiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100
demonstrate that FMCE-Net++ consistently enhances model performance without
architectural modifications or additional data. Key experimental outcomes
include accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp
(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate
state-of-the-art performance ceilings.

</details>


### [126] [SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.06115)
*Weichen Zhang,Kebin Liu,Fan Dang,Zhui Zhu,Xikai Sun,Yunhao Liu*

Main category: cs.CV

TL;DR: SynSeg提出了一种弱监督的开放词汇语义分割方法，通过多类别对比学习和特征协同结构，显著提升了语义定位和区分能力。


<details>
  <summary>Details</summary>
Motivation: 开放词汇场景下的语义分割面临类别广泛和细粒度的挑战，现有弱监督方法因依赖类别特定监督和不适合的特征构建方法导致语义不对齐和性能不佳。

Method: SynSeg采用多类别对比学习（MCCL）作为更强的训练信号，并结合特征协同结构（FSS）重构特征，通过先验融合和语义激活图增强避免视觉编码器引入的前景偏差。

Result: 在多个基准测试中，SynSeg优于现有最优方法，如在VOC上准确率提升4.5%，Context上提升8.9%。

Conclusion: SynSeg通过MCCL和FSS有效解决了开放词汇语义分割的挑战，显著提升了弱监督下的性能。

Abstract: Semantic segmentation in open-vocabulary scenarios presents significant
challenges due to the wide range and granularity of semantic categories.
Existing weakly-supervised methods often rely on category-specific supervision
and ill-suited feature construction methods for contrastive learning, leading
to semantic misalignment and poor performance. In this work, we propose a novel
weakly-supervised approach, SynSeg, to address the challenges. SynSeg performs
Multi-Category Contrastive Learning (MCCL) as a stronger training signal with a
new feature reconstruction framework named Feature Synergy Structure (FSS).
Specifically, MCCL strategy robustly combines both intra- and inter-category
alignment and separation in order to make the model learn the knowledge of
correlations from different categories within the same image. Moreover, FSS
reconstructs discriminative features for contrastive learning through prior
fusion and semantic-activation-map enhancement, effectively avoiding the
foreground bias introduced by the visual encoder. In general, SynSeg
effectively improves the abilities in semantic localization and discrimination
under weak supervision. Extensive experiments on benchmarks demonstrate that
our method outperforms state-of-the-art (SOTA) performance. For instance,
SynSeg achieves higher accuracy than SOTA baselines by 4.5\% on VOC, 8.9\% on
Context, 2.6\% on Object and 2.0\% on City.

</details>


### [127] [Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events](https://arxiv.org/abs/2508.06122)
*Ting-Shuo Yo,Shih-Hao Su,Chien-Ming Wu,Wei-Ting Chen,Jung-Lien Chu,Chiao-Wei Chang,Hung-Chi Kuo*

Main category: cs.CV

TL;DR: 该研究比较了PCA、CAE和预训练残差网络在卫星图像表示学习中的表现，发现CAE在所有分类任务中表现最佳，但缺乏物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 探索不同表示学习算法在卫星图像天气事件分类中的效果，并评估其潜在空间的质量。

Method: 使用PCA、CAE和预训练残差网络（PT）学习卫星图像的潜在空间，并通过分类任务评估其性能。

Result: CAE在所有分类任务中表现最佳，PCA命中率高但误报率也高，PT在热带气旋识别中表现优异。高分辨率数据集对深度学习算法效果更好。

Conclusion: CAE在表示学习中高效且有效，但缺乏物理可解释性，未来可开发物理信息版本的CAE。

Abstract: This study applied representation learning algorithms to satellite images and
evaluated the learned latent spaces with classifications of various weather
events. The algorithms investigated include the classical linear
transformation, i.e., principal component analysis (PCA), state-of-the-art deep
learning method, i.e., convolutional autoencoder (CAE), and a residual network
pre-trained with large image datasets (PT). The experiment results indicated
that the latent space learned by CAE consistently showed higher threat scores
for all classification tasks. The classifications with PCA yielded high hit
rates but also high false-alarm rates. In addition, the PT performed
exceptionally well at recognizing tropical cyclones but was inferior in other
tasks. Further experiments suggested that representations learned from
higher-resolution datasets are superior in all classification tasks for
deep-learning algorithms, i.e., CAE and PT. We also found that smaller latent
space sizes had minor impact on the classification task's hit rate. Still, a
latent space dimension smaller than 128 caused a significantly higher false
alarm rate. Though the CAE can learn latent spaces effectively and efficiently,
the interpretation of the learned representation lacks direct connections to
physical attributions. Therefore, developing a physics-informed version of CAE
can be a promising outlook for the current work.

</details>


### [128] [SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning](https://arxiv.org/abs/2508.06125)
*Lin Zhang,Xianfang Zeng,Kangcong Li,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: SC-Captioner是一个基于强化学习的框架，通过奖励函数设计提升图像描述模型的自我修正能力，显著优于直接偏好优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述模型缺乏自我修正能力，导致生成的描述不够准确。

Method: 通过场景图解析算法分解描述为对象、属性和关系集，计算集合差异以设计奖励函数，激励准确修正。

Result: 实验表明，SC-Captioner能生成更优的图像描述，显著优于直接偏好优化策略。

Conclusion: SC-Captioner通过强化学习框架和精细的奖励设计，有效提升了图像描述的准确性和质量。

Abstract: We propose SC-Captioner, a reinforcement learning framework that enables the
self-correcting capability of image caption models. Our crucial technique lies
in the design of the reward function to incentivize accurate caption
corrections. Specifically, the predicted and reference captions are decomposed
into object, attribute, and relation sets using scene-graph parsing algorithms.
We calculate the set difference between sets of initial and self-corrected
captions to identify added and removed elements. These elements are matched
against the reference sets to calculate correctness bonuses for accurate
refinements and mistake punishments for wrong additions and removals, thereby
forming the final reward. For image caption quality assessment, we propose a
set of metrics refined from CAPTURE that alleviate its incomplete precision
evaluation and inefficient relation matching problems. Furthermore, we collect
a fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K
diverse images from COCO dataset. Experiments show that applying SC-Captioner
on large visual-language models can generate better image captions across
various scenarios, significantly outperforming the direct preference
optimization training strategy.

</details>


### [129] [SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures](https://arxiv.org/abs/2508.06127)
*Yi Qin,Rui Wang,Tao Huang,Tong Xiao,Liping Jing*

Main category: cs.CV

TL;DR: VeSCA方法利用SAM的编码器生成可迁移的对抗样本，通过参数化单纯复形表征共享脆弱区域，性能提升12.7%。


<details>
  <summary>Details</summary>
Motivation: 评估SAM的可迁移漏洞，防止下游应用因单点风险失效。

Method: 提出VeSCA方法，通过迭代顶点细化和轻量级域适应策略生成对抗样本。

Result: 在五个领域数据集上，VeSCA性能优于现有方法12.7%。

Conclusion: SAM的漏洞对下游模型构成风险，需开发更鲁棒的基础模型。

Abstract: While the Segment Anything Model (SAM) transforms interactive segmentation
with zero-shot abilities, its inherent vulnerabilities present a single-point
risk, potentially leading to the failure of numerous downstream applications.
Proactively evaluating these transferable vulnerabilities is thus imperative.
Prior adversarial attacks on SAM often present limited transferability due to
insufficient exploration of common weakness across domains. To address this, we
propose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that
leverages only the encoder of SAM for generating transferable adversarial
examples. Specifically, it achieves this by explicitly characterizing the
shared vulnerable regions between SAM and downstream models through a
parametric simplicial complex. Our goal is to identify such complexes within
adversarially potent regions by iterative vertex-wise refinement. A lightweight
domain re-adaptation strategy is introduced to bridge domain divergence using
minimal reference data during the initialization of simplicial complex.
Ultimately, VeSCA generates consistently transferable adversarial examples
through random simplicial complex sampling. Extensive experiments demonstrate
that VeSCA achieves performance improved by 12.7% compared to state-of-the-art
methods across three downstream model categories across five domain-specific
datasets. Our findings further highlight the downstream model risks posed by
SAM's vulnerabilities and emphasize the urgency of developing more robust
foundation models.

</details>


### [130] [Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation](https://arxiv.org/abs/2508.06136)
*YoungChan Choi,HengFei Wang,YiHua Cheng,Boeun Kim,Hyung Jin Chang,YoungGeun Choi,Sang-Il Choi*

Main category: cs.CV

TL;DR: 提出了一种基于显式3D眼球结构的新型3D视线重定向框架，优于现有基于神经辐射场的方法。


<details>
  <summary>Details</summary>
Motivation: 现有视线重定向方法通常依赖隐式神经表示，无法显式建模眼球的旋转和平移，限制了生成图像的逼真度和准确性。

Method: 采用3D高斯泼溅（3DGS）显式建模眼球结构，并引入自适应变形模块模拟眼部肌肉细微运动。

Result: 在ETH-XGaze数据集上实验表明，该方法能生成多样化的新视线图像，图像质量和视线估计精度优于现有方法。

Conclusion: 显式3D眼球结构和自适应变形模块显著提升了视线重定向的逼真度和准确性。

Abstract: We propose a novel 3D gaze redirection framework that leverages an explicit
3D eyeball structure. Existing gaze redirection methods are typically based on
neural radiance fields, which employ implicit neural representations via volume
rendering. Unlike these NeRF-based approaches, where the rotation and
translation of 3D representations are not explicitly modeled, we introduce a
dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian
Splatting (3DGS). Our method generates photorealistic images that faithfully
reproduce the desired gaze direction by explicitly rotating and translating the
3D eyeball structure. In addition, we propose an adaptive deformation module
that enables the replication of subtle muscle movements around the eyes.
Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our
framework is capable of generating diverse novel gaze images, achieving
superior image quality and gaze estimation accuracy compared to previous
state-of-the-art methods.

</details>


### [131] [DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera](https://arxiv.org/abs/2508.06139)
*Shaohua Pan,Xinyu Yi,Yan Zhou,Weihua Jian,Yuan Zhang,Pengfei Wan,Feng Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的方法，结合稀疏IMU和单目摄像头信号，实现实时人体运动捕捉。通过将视觉信息转化为条件嵌入，并逐帧处理IMU数据，系统在视觉信息缺失时仍能保持鲁棒性。实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 结合稀疏IMU和单目摄像头进行实时人体运动捕捉是一个新兴且有前景的方向，但现有方法在视觉信息缺失时表现不佳。本文旨在解决这一问题。

Method: 提出扩散模型框架，将视觉信息整体转化为条件嵌入，同时逐帧处理IMU数据与噪声姿态，以融合两种信号。

Result: 实验证明该方法在视觉信息缺失时仍能保持鲁棒性，并在姿态估计任务中达到最先进性能。

Conclusion: 该方法通过巧妙融合IMU和视觉信号，实现了鲁棒且高效的实时人体运动捕捉，为相关研究提供了新思路。

Abstract: Combining sparse IMUs and a monocular camera is a new promising setting to
perform real-time human motion capture. This paper proposes a diffusion-based
solution to learn human motion priors and fuse the two modalities of signals
together seamlessly in a unified framework. By delicately considering the
characteristics of the two signals, the sequential visual information is
considered as a whole and transformed into a condition embedding, while the
inertial measurement is concatenated with the noisy body pose frame by frame to
construct a sequential input for the diffusion model. Firstly, we observe that
the visual information may be unavailable in some frames due to occlusions or
subjects moving out of the camera view. Thus incorporating the sequential
visual features as a whole to get a single feature embedding is robust to the
occasional degenerations of visual information in those frames. On the other
hand, the IMU measurements are robust to occlusions and always stable when
signal transmission has no problem. So incorporating them frame-wisely could
better explore the temporal information for the system. Experiments have
demonstrated the effectiveness of the system design and its state-of-the-art
performance in pose estimation compared with the previous works. Our codes are
available for research at https://shaohua-pan.github.io/diffcap-page.

</details>


### [132] [SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models](https://arxiv.org/abs/2508.06142)
*Hanqing Wang,Yuan Tian,Mingyu Liu,Zhenhao Zhang,Xiangyang Zhu*

Main category: cs.CV

TL;DR: SDEval是一个动态评估框架，通过调整安全基准的分布和复杂性来评估多模态大语言模型（MLLMs）的安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有安全基准因MLLM快速发展而过时及数据污染问题。

Method: 采用文本、图像和文本-图像动态策略生成新样本，探索其对模型安全性的影响。

Result: SDEval显著影响安全评估，缓解数据污染，并暴露MLLMs的安全局限性。

Conclusion: SDEval是一个通用的动态评估框架，适用于现有安全和能力基准。

Abstract: In the rapidly evolving landscape of Multimodal Large Language Models
(MLLMs), the safety concerns of their outputs have earned significant
attention. Although numerous datasets have been proposed, they may become
outdated with MLLM advancements and are susceptible to data contamination
issues. To address these problems, we propose \textbf{SDEval}, the
\textit{first} safety dynamic evaluation framework to controllably adjust the
distribution and complexity of safety benchmarks. Specifically, SDEval mainly
adopts three dynamic strategies: text, image, and text-image dynamics to
generate new samples from original benchmarks. We first explore the individual
effects of text and image dynamics on model safety. Then, we find that
injecting text dynamics into images can further impact safety, and conversely,
injecting image dynamics into text also leads to safety risks. SDEval is
general enough to be applied to various existing safety and even capability
benchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and
capability benchmarks, MMBench and MMVet, show that SDEval significantly
influences safety evaluation, mitigates data contamination, and exposes safety
limitations of MLLMs. Code is available at https://github.com/hq-King/SDEval

</details>


### [133] [Text-guided Visual Prompt DINO for Generic Segmentation](https://arxiv.org/abs/2508.06146)
*Yuchen Guan,Chong Sun,Canmiao Fu,Zhipeng Huang,Chun Yuan,Chen Li*

Main category: cs.CV

TL;DR: Prompt-DINO提出了一种文本引导的视觉提示框架，通过早期融合、顺序对齐查询选择和生成数据引擎，解决了多模态视觉模型中的特征融合和查询选择问题，并在开放世界检测中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态视觉模型中晚期特征融合、查询选择不优以及词汇表限制的问题。

Method: 1. 早期融合机制统一文本/视觉提示和主干特征；2. 顺序对齐查询选择优化文本与视觉查询的结构对齐；3. 生成数据引擎通过双路径交叉验证减少标签噪声。

Result: 在开放世界检测基准上达到最佳性能，语义覆盖范围显著扩展。

Conclusion: Prompt-DINO为开放世界场景中的多模态检测和数据生成建立了新范式。

Abstract: Recent advancements in multimodal vision models have highlighted limitations
in late-stage feature fusion and suboptimal query selection for hybrid prompts
open-world segmentation, alongside constraints from caption-derived
vocabularies. To address these challenges, we propose Prompt-DINO, a
text-guided visual Prompt DINO framework featuring three key innovations.
First, we introduce an early fusion mechanism that unifies text/visual prompts
and backbone features at the initial encoding stage, enabling deeper
cross-modal interactions to resolve semantic ambiguities. Second, we design
order-aligned query selection for DETR-based architectures, explicitly
optimizing the structural alignment between text and visual queries during
decoding to enhance semantic-spatial consistency. Third, we develop a
generative data engine powered by the Recognize Anything via Prompting (RAP)
model, which synthesizes 0.5B diverse training instances through a dual-path
cross-verification pipeline, reducing label noise by 80.5% compared to
conventional approaches. Extensive experiments demonstrate that Prompt-DINO
achieves state-of-the-art performance on open-world detection benchmarks while
significantly expanding semantic coverage beyond fixed-vocabulary constraints.
Our work establishes a new paradigm for scalable multimodal detection and data
generation in open-world scenarios. Data&Code are available at
https://github.com/WeChatCV/WeVisionOne.

</details>


### [134] [DSConv: Dynamic Splitting Convolution for Pansharpening](https://arxiv.org/abs/2508.06147)
*Xuanyu Liu,Bonan An*

Main category: cs.CV

TL;DR: 提出了一种名为DSConv的动态卷积核分割方法，结合注意力机制，提升遥感图像融合的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多依赖标准卷积，未能充分利用遥感图像的像素间相关性，动态卷积核分割可提升特征提取能力。

Method: 动态分割卷积核并结合注意力机制，选择感兴趣位置，将原始卷积核分割为多个小核，增强网络泛化和特征表示能力。

Result: 实验证明DSConv在图像融合任务中表现优异，达到先进水平。

Conclusion: DSConv通过动态卷积核分割和注意力机制，显著提升了遥感图像融合的性能和效率。

Abstract: Aiming to obtain a high-resolution image, pansharpening involves the fusion
of a multi-spectral image (MS) and a panchromatic image (PAN), the low-level
vision task remaining significant and challenging in contemporary research.
Most existing approaches rely predominantly on standard convolutions, few
making the effort to adaptive convolutions, which are effective owing to the
inter-pixel correlations of remote sensing images. In this paper, we propose a
novel strategy for dynamically splitting convolution kernels in conjunction
with attention, selecting positions of interest, and splitting the original
convolution kernel into multiple smaller kernels, named DSConv. The proposed
DSConv more effectively extracts features of different positions within the
receptive field, enhancing the network's generalization, optimization, and
feature representation capabilities. Furthermore, we innovate and enrich
concepts of dynamic splitting convolution and provide a novel network
architecture for pansharpening capable of achieving the tasks more efficiently,
building upon this methodology. Adequate fair experiments illustrate the
effectiveness and the state-of-the-art performance attained by
DSConv.Comprehensive and rigorous discussions proved the superiority and
optimal usage conditions of DSConv.

</details>


### [135] [VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation](https://arxiv.org/abs/2508.06152)
*Kaiyuan Jiang,Ruoxi Sun,Ying Cao,Yuqi Xu,Xinran Zhang,Junyan Guo,ChengSheng Deng*

Main category: cs.CV

TL;DR: VISTAR是一个用户中心的多维度文本到图像（T2I）评估基准，结合确定性指标和新型HWPQ方案，显著提升评估准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有T2I评估指标的局限性，提供更全面的评估方法。

Method: 采用两阶段混合范式：确定性指标量化物理属性，HWPQ方案评估抽象语义。基于专家研究定义用户角色和评估角度。

Result: HWPQ方案在抽象语义评估中达到85.9%准确率，整体指标与人类对齐度超过75%。

Conclusion: VISTAR为T2I模型提供了更精准的评估工具，资源公开以促进可复现研究。

Abstract: We present VISTAR, a user-centric, multi-dimensional benchmark for
text-to-image (T2I) evaluation that addresses the limitations of existing
metrics. VISTAR introduces a two-tier hybrid paradigm: it employs
deterministic, scriptable metrics for physically quantifiable attributes (e.g.,
text rendering, lighting) and a novel Hierarchical Weighted P/N Questioning
(HWPQ) scheme that uses constrained vision-language models to assess abstract
semantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study
with 120 experts, we defined seven user roles and nine evaluation angles to
construct the benchmark, which comprises 2,845 prompts validated by over 15,000
human pairwise comparisons. Our metrics achieve high human alignment (>75%),
with the HWPQ scheme reaching 85.9% accuracy on abstract semantics,
significantly outperforming VQA baselines. Comprehensive evaluation of
state-of-the-art models reveals no universal champion, as role-weighted scores
reorder rankings and provide actionable guidance for domain-specific
deployment. All resources are publicly released to foster reproducible T2I
assessment.

</details>


### [136] [An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06157)
*Xiaoxiao Yang,Meiliang Liu,Yunfang Xu,Zijin Li,Zhengye Si,Xinyue Yang,Zhiwen Zhao*

Main category: cs.CV

TL;DR: 提出了一种名为MPF-KANSC的创新框架，通过多平面融合和KANSC注意力机制，提高了阿尔茨海默病（AD）诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期诊断因脑部结构变化的复杂性而具有挑战性，现有深度学习方法难以准确捕捉病理区域的非线性关系。

Method: 结合多平面融合（MPF）和KANSC注意力机制，从多个解剖平面并行提取特征，并利用更灵活的非线性函数逼近技术。

Result: 在ADNI数据集上验证了MPF-KANSC的优越性能，并发现AD进展中皮质下结构变化的右偏侧不对称性。

Conclusion: MPF-KANSC为AD诊断提供了更精确和可解释的方法，揭示了新的病理特征。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that
severely impairs cognitive function and quality of life. Timely intervention in
AD relies heavily on early and precise diagnosis, which remains challenging due
to the complex and subtle structural changes in the brain. Most existing deep
learning methods focus only on a single plane of structural magnetic resonance
imaging (sMRI) and struggle to accurately capture the complex and nonlinear
relationships among pathological regions of the brain, thus limiting their
ability to precisely identify atrophic features. To overcome these limitations,
we propose an innovative framework, MPF-KANSC, which integrates multi-plane
fusion (MPF) for combining features from the coronal, sagittal, and axial
planes, and a Kolmogorov-Arnold Network-guided spatial-channel attention
mechanism (KANSC) to more effectively learn and represent sMRI atrophy
features. Specifically, the proposed model enables parallel feature extraction
from multiple anatomical planes, thus capturing more comprehensive structural
information. The KANSC attention mechanism further leverages a more flexible
and accurate nonlinear function approximation technique, facilitating precise
identification and localization of disease-related abnormalities. Experiments
on the ADNI dataset confirm that the proposed MPF-KANSC achieves superior
performance in AD diagnosis. Moreover, our findings provide new evidence of
right-lateralized asymmetry in subcortical structural changes during AD
progression, highlighting the model's promising interpretability.

</details>


### [137] [Effective Training Data Synthesis for Improving MLLM Chart Understanding](https://arxiv.org/abs/2508.06492)
*Yuwei Yang,Zeyu Zhang,Yunzhong Hou,Zhuowan Li,Gaowen Liu,Ali Payani,Yuan-Sen Ting,Liang Zheng*

Main category: cs.CV

TL;DR: 通过模块化和多样化视觉细节改进图表理解能力，提出五步数据合成流程，生成高质量数据集ECD，显著提升多模态大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源多模态大语言模型在图表理解任务上表现不佳（成功率30%-50%），且合成图表与真实图表差异影响模型训练效果。

Method: 设计五步数据合成流程：分离数据和功能生成单图、条件生成多子图、视觉多样化、过滤低质量数据、用GPT-4生成问答对。

Result: 生成数据集ECD（10k+图表、300k+问答对），覆盖25个主题和250+图表类型组合，显著提升模型性能。

Conclusion: ECD数据集有效提升多模态大语言模型在图表理解任务上的表现，代码和数据已开源。

Abstract: Being able to effectively read scientific plots, or chart understanding, is a
central part toward building effective agents for science. However, existing
multimodal large language models (MLLMs), especially open-source ones, are
still falling behind with a typical success rate of 30%-50% on challenging
benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are
often restricted by their inadequate similarity to the real charts, which could
compromise model training and performance on complex real-world charts. In this
study, we show that modularizing chart generation and diversifying visual
details improves chart understanding capabilities. In particular, we design a
five-step data synthesis pipeline, where we separate data and function creation
for single plot generation, condition the generation of later subplots on
earlier ones for multi-subplot figures, visually diversify the generated
figures, filter out low quality data, and finally generate the question-answer
(QA) pairs with GPT-4o. This approach allows us to streamline the generation of
fine-tuning datasets and introduce the effective chart dataset (ECD), which
contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring
250+ chart type combinations with high visual complexity. We show that ECD
consistently improves the performance of various MLLMs on a range of real-world
and synthetic test sets. Code, data and models are available at:
https://github.com/yuweiyang-anu/ECD.

</details>


### [138] [Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment](https://arxiv.org/abs/2508.06160)
*Zhenbang Du,Yonggan Fu,Lifu Wang,Jiayi Qian,Xiao Luo,Yingyan,Lin*

Main category: cs.CV

TL;DR: PostDiff框架通过混合分辨率去噪和模块缓存策略，在无需微调的情况下优化预训练扩散模型的效率与生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的高计算需求限制了其在资源有限平台上的部署，研究如何在无需微调的情况下优化模型效率。

Method: 提出PostDiff框架，包括混合分辨率去噪方案和模块缓存策略，以减少计算冗余。

Result: 实验表明，PostDiff显著提升了扩散模型的效率与生成质量平衡，且降低单步推理成本比减少去噪步数更有效。

Conclusion: PostDiff为预训练扩散模型的高效部署提供了有效解决方案，尤其在资源受限场景下表现突出。

Abstract: Diffusion models have shown remarkable success across generative tasks, yet
their high computational demands challenge deployment on resource-limited
platforms. This paper investigates a critical question for compute-optimal
diffusion model deployment: Under a post-training setting without fine-tuning,
is it more effective to reduce the number of denoising steps or to use a
cheaper per-step inference? Intuitively, reducing the number of denoising steps
increases the variability of the distributions across steps, making the model
more sensitive to compression. In contrast, keeping more denoising steps makes
the differences smaller, preserving redundancy, and making post-training
compression more feasible. To systematically examine this, we propose PostDiff,
a training-free framework for accelerating pre-trained diffusion models by
reducing redundancy at both the input level and module level in a post-training
manner. At the input level, we propose a mixed-resolution denoising scheme
based on the insight that reducing generation resolution in early denoising
steps can enhance low-frequency components and improve final generation
fidelity. At the module level, we employ a hybrid module caching strategy to
reuse computations across denoising steps. Extensive experiments and ablation
studies demonstrate that (1) PostDiff can significantly improve the
fidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to
boost efficiency while maintaining decent generation fidelity, reducing
per-step inference cost is often more effective than reducing the number of
denoising steps. Our code is available at
https://github.com/GATECH-EIC/PostDiff.

</details>


### [139] [UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting](https://arxiv.org/abs/2508.06169)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Changting Lin,Jianfeng Dong,Chaochao Chen,Xun Zhou,Meng Han*

Main category: cs.CV

TL;DR: UW-3DGS是一种基于3D高斯溅射（3DGS）的新型水下3D场景重建框架，通过可学习的物理模块和自适应修剪技术，显著提升了重建质量和效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如NeRF及其扩展）在水下环境中因光线吸收、散射和浑浊问题导致几何和颜色保真度下降，且效率受限。

Method: 提出UW-3DGS框架，包含可学习的水下图像形成模块和物理感知不确定性修剪（PAUP）分支，通过端到端优化减少噪声。

Result: 在SeaThru-NeRF和UWBundle数据集上表现优异，PSNR达27.604，SSIM为0.868，LPIPS为0.104，浮动伪影减少约65%。

Conclusion: UW-3DGS通过结合物理模型和自适应修剪，显著提升了水下3D重建的精度和鲁棒性。

Abstract: Underwater 3D scene reconstruction faces severe challenges from light
absorption, scattering, and turbidity, which degrade geometry and color
fidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF
extensions such as SeaThru-NeRF incorporate physics-based models, their MLP
reliance limits efficiency and spatial resolution in hazy environments. We
introduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for
robust underwater reconstruction. Key innovations include: (1) a plug-and-play
learnable underwater image formation module using voxel-based regression for
spatially varying attenuation and backscatter; and (2) a Physics-Aware
Uncertainty Pruning (PAUP) branch that adaptively removes noisy floating
Gaussians via uncertainty scoring, ensuring artifact-free geometry. The
pipeline operates in training and rendering stages. During training, noisy
Gaussians are optimized end-to-end with underwater parameters, guided by PAUP
pruning and scattering modeling. In rendering, refined Gaussians produce clean
Unattenuated Radiance Images (URIs) free from media effects, while learned
physics enable realistic Underwater Images (UWIs) with accurate light
transport. Experiments on SeaThru-NeRF and UWBundle datasets show superior
performance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on
SeaThru-NeRF, with ~65% reduction in floating artifacts.

</details>


### [140] [Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation](https://arxiv.org/abs/2508.06170)
*Ojonugwa Oluwafemi Ejiga Peter,Akingbola Oluwapemiisin,Amalahu Chetachi,Adeniran Opeyemi,Fahmi Khalifa,Md Mahmudur Rahman*

Main category: cs.CV

TL;DR: 研究提出了一种多方向架构框架，用于自动化结肠镜图像中的息肉检测，结合合成数据生成和检测分割算法，显著提升了检测和分割性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜检查是结直肠癌早期诊断的重要工具，但医疗数据集有限且标注复杂，因此需要自动化解决方案。

Method: 采用Faster R-CNN进行初始目标定位，结合Segment Anything Model（SAM）优化分割掩码，并评估了五种分割模型。

Result: Faster R-CNN的召回率为93.08%，精确度为88.97%，FPN在PSNR和SSIM上表现最佳，UNet在召回率上领先。

Conclusion: 该框架在息肉检测和分割中表现出色，为医疗图像分析提供了高效解决方案。

Abstract: Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,
which is one of the main causes of cancer-related mortality globally; hence, it
is deemed an essential technique for the prevention and early detection of
colorectal cancer. The research introduces a unique multidirectional
architectural framework to automate polyp detection within colonoscopy images
while helping resolve limited healthcare dataset sizes and annotation
complexities. The research implements a comprehensive system that delivers
synthetic data generation through Stable Diffusion enhancements together with
detection and segmentation algorithms. This detection approach combines Faster
R-CNN for initial object localization while the Segment Anything Model (SAM)
refines the segmentation masks. The faster R-CNN detection algorithm achieved a
recall of 93.08% combined with a precision of 88.97% and an F1 score of
90.98%.SAM is then used to generate the image mask. The research evaluated five
state-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,
and MANet using ResNet34 as a base model. The results demonstrate the superior
performance of FPN with the highest scores of PSNR (7.205893) and SSIM
(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced
performance in IoU (64.20%) and Dice score (77.53%).

</details>


### [141] [MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration](https://arxiv.org/abs/2508.06189)
*Cheng Liu,Daou Zhang,Tingxu Liu,Yuhan Wang,Jinyang Chen,Yuexuan Li,Xinying Xiao,Chenbo Xin,Ziru Wang,Weichao Wu*

Main category: cs.CV

TL;DR: 提出了一种基于多智能体异步协作的犯罪行为预测框架MA-CBP，通过实时视频流分析实现潜在犯罪行为的早期预警。


<details>
  <summary>Details</summary>
Motivation: 城市化加速导致公共场景犯罪行为威胁增加，传统方法难以捕捉高级语义或满足实时需求。

Method: 将视频流转换为帧级语义描述，构建因果一致的历史摘要，融合相邻帧进行长短期上下文联合推理。

Result: 在多个数据集上表现优异，为城市公共安全提供有效风险预警方案。

Conclusion: MA-CBP框架在犯罪预测和公共安全领域具有显著潜力。

Abstract: With the acceleration of urbanization, criminal behavior in public scenes
poses an increasingly serious threat to social security. Traditional anomaly
detection methods based on feature recognition struggle to capture high-level
behavioral semantics from historical information, while generative approaches
based on Large Language Models (LLMs) often fail to meet real-time
requirements. To address these challenges, we propose MA-CBP, a criminal
behavior prediction framework based on multi-agent asynchronous collaboration.
This framework transforms real-time video streams into frame-level semantic
descriptions, constructs causally consistent historical summaries, and fuses
adjacent image frames to perform joint reasoning over long- and short-term
contexts. The resulting behavioral decisions include key elements such as event
subjects, locations, and causes, enabling early warning of potential criminal
activity. In addition, we construct a high-quality criminal behavior dataset
that provides multi-scale language supervision, including frame-level,
summary-level, and event-level semantic annotations. Experimental results
demonstrate that our method achieves superior performance on multiple datasets
and offers a promising solution for risk warning in urban public safety
scenarios.

</details>


### [142] [A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet](https://arxiv.org/abs/2508.06191)
*Ruixiang Tang,Jianglong Qin,Mingda Zhang,Yan Song,Yi Wu,Wei Wu*

Main category: cs.CV

TL;DR: 提出了一种名为DBIF-AUNet的双分支交互融合注意力模型，用于解决胸水CT图像语义分割中的挑战，如灰度相似、边缘模糊和形态多变。通过DDFD模块和BIAF模块的协同作用，模型在多尺度特征互补和动态特征融合方面表现优异，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 胸水CT图像的语义分割在临床诊断中具有重要意义，但现有方法难以应对灰度相似、边缘模糊和形态多变等挑战，导致分割精度不足。

Method: 提出DBIF-AUNet模型，包含双域特征解耦模块（DDFD）和分支交互注意力融合模块（BIAF），通过多尺度特征互补和动态特征融合提升分割性能。

Result: 在1,622张胸水CT图像上验证，DBIF-AUNet的IoU和Dice分数分别为80.1%和89.0%，优于U-Net++和Swin-UNet。

Conclusion: DBIF-AUNet通过创新模块设计显著优化了复杂胸水CT图像的分割精度，为临床诊断提供了更可靠的工具。

Abstract: Pleural effusion semantic segmentation can significantly enhance the accuracy
and timeliness of clinical diagnosis and treatment by precisely identifying
disease severity and lesion areas. Currently, semantic segmentation of pleural
effusion CT images faces multiple challenges. These include similar gray levels
between effusion and surrounding tissues, blurred edges, and variable
morphology. Existing methods often struggle with diverse image variations and
complex edges, primarily because direct feature concatenation causes semantic
gaps. To address these challenges, we propose the Dual-Branch Interactive
Fusion Attention model (DBIF-AUNet). This model constructs a densely nested
skip-connection network and innovatively refines the Dual-Domain Feature
Disentanglement module (DDFD). The DDFD module orthogonally decouples the
functions of dual-domain modules to achieve multi-scale feature complementarity
and enhance characteristics at different levels. Concurrently, we design a
Branch Interaction Attention Fusion module (BIAF) that works synergistically
with the DDFD. This module dynamically weights and fuses global, local, and
frequency band features, thereby improving segmentation robustness.
Furthermore, we implement a nested deep supervision mechanism with hierarchical
adaptive hybrid loss to effectively address class imbalance. Through validation
on 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet
achieved IoU and Dice scores of 80.1% and 89.0% respectively. These results
outperform state-of-the-art medical image segmentation models U-Net++ and
Swin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant
optimization in segmentation accuracy for complex pleural effusion CT images.

</details>


### [143] [LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning](https://arxiv.org/abs/2508.06202)
*Chang Che,Ziqi Wang,Pengwan Yang,Qi Wang,Hui Ma,Zenglin Shi*

Main category: cs.CV

TL;DR: LiLoRA是一种高效架构扩展方法，用于解决多模态大语言模型（MLLMs）在持续视觉指令调优（CVIT）中的灾难性遗忘问题，通过共享LoRA矩阵和低秩分解减少参数冗余，同时引入余弦正则化稳定性损失保持共享表示的一致性。


<details>
  <summary>Details</summary>
Motivation: 持续视觉指令调优（CVIT）中，多模态大语言模型（MLLMs）在学习新任务时会出现灾难性遗忘问题，现有方法通过架构扩展缓解遗忘，但参数开销大且扩展性差。

Method: 提出LiLoRA方法：共享LoRA矩阵A以减少冗余，对矩阵B进行低秩分解以减少任务特定参数，并引入余弦正则化稳定性损失保持共享表示一致性。

Result: 在多样化CVIT基准测试中，LiLoRA在连续任务学习中表现优异，参数效率显著优于现有方法。

Conclusion: LiLoRA通过高效架构扩展和稳定性损失，有效解决了CVIT中的灾难性遗忘问题，同时提升了参数效率。

Abstract: Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language
Models (MLLMs) to incrementally learn new tasks over time. However, this
process is challenged by catastrophic forgetting, where performance on
previously learned tasks deteriorates as the model adapts to new ones. A common
approach to mitigate forgetting is architecture expansion, which introduces
task-specific modules to prevent interference. Yet, existing methods often
expand entire layers for each task, leading to significant parameter overhead
and poor scalability. To overcome these issues, we introduce LoRA in LoRA
(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in
MLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,
applies an additional low-rank decomposition to matrix B to minimize
task-specific parameters, and incorporates a cosine-regularized stability loss
to preserve consistency in shared representations over time. Extensive
experiments on a diverse CVIT benchmark show that LiLoRA consistently achieves
superior performance in sequential task learning while significantly improving
parameter efficiency compared to existing approaches.

</details>


### [144] [AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection](https://arxiv.org/abs/2508.06203)
*Zhaopeng Gu,Bingke Zhu,Guibo Zhu,Yingying Chen,Wei Ge,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: AnomalyMoE是一个基于Mixture-of-Experts架构的通用异常检测框架，通过分解异常检测问题为三个语义层次，显著提升了跨领域的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法通常针对特定领域或异常类型，泛化能力有限。AnomalyMoE旨在通过多层级专家网络解决这一问题。

Method: AnomalyMoE采用三个专家网络分别处理局部结构、组件语义和全局逻辑异常，并引入EIR和ESB模块优化专家多样性和利用率。

Result: 在8个不同领域的挑战性数据集上，AnomalyMoE显著优于领域专用方法，达到新的SOTA性能。

Conclusion: AnomalyMoE通过多层级专家设计和优化模块，实现了通用且高性能的异常检测。

Abstract: Anomaly detection is a critical task across numerous domains and modalities,
yet existing methods are often highly specialized, limiting their
generalizability. These specialized models, tailored for specific anomaly types
like textural defects or logical errors, typically exhibit limited performance
when deployed outside their designated contexts. To overcome this limitation,
we propose AnomalyMoE, a novel and universal anomaly detection framework based
on a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the
complex anomaly detection problem into three distinct semantic hierarchies:
local structural anomalies, component-level semantic anomalies, and global
logical anomalies. AnomalyMoE correspondingly employs three dedicated expert
networks at the patch, component, and global levels, and is specialized in
reconstructing features and identifying deviations at its designated semantic
level. This hierarchical design allows a single model to concurrently
understand and detect a wide spectrum of anomalies. Furthermore, we introduce
an Expert Information Repulsion (EIR) module to promote expert diversity and an
Expert Selection Balancing (ESB) module to ensure the comprehensive utilization
of all experts. Experiments on 8 challenging datasets spanning industrial
imaging, 3D point clouds, medical imaging, video surveillance, and logical
anomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art
performance, significantly outperforming specialized methods in their
respective domains.

</details>


### [145] [PA-HOI: A Physics-Aware Human and Object Interaction Dataset](https://arxiv.org/abs/2508.06205)
*Ruiyan Wang,Lin Zuo,Zonghao Lin,Qiang Wang,Zhengxue Cheng,Rong Xie,Jun Ling,Li Song*

Main category: cs.CV

TL;DR: 论文介绍了PA-HOI运动捕捉数据集，填补了现有HOI数据集中忽视物体物理属性对人类长期运动影响的空白。


<details>
  <summary>Details</summary>
Motivation: 现有HOI数据集关注功能细节，但忽略了物体物理属性对人类运动的影响，阻碍了对交互动态的全面理解。

Method: 构建PA-HOI数据集，包含562个运动序列，涵盖不同性别受试者与35种3D物体的交互，记录物体尺寸、形状和重量对运动的影响。

Result: 数据集显著扩展了对物体物理属性如何影响人类姿势、速度、运动规模和交互策略的理解。

Conclusion: PA-HOI数据集通过与现有运动生成方法结合，验证了其传递真实物理感知的能力，为相关领域提供了重要资源。

Abstract: The Human-Object Interaction (HOI) task explores the dynamic interactions
between humans and objects in physical environments, providing essential
biomechanical and cognitive-behavioral foundations for fields such as robotics,
virtual reality, and human-computer interaction. However, existing HOI data
sets focus on details of affordance, often neglecting the influence of physical
properties of objects on human long-term motion. To bridge this gap, we
introduce the PA-HOI Motion Capture dataset, which highlights the impact of
objects' physical attributes on human motion dynamics, including human posture,
moving velocity, and other motion characteristics. The dataset comprises 562
motion sequences of human-object interactions, with each sequence performed by
subjects of different genders interacting with 35 3D objects that vary in size,
shape, and weight. This dataset stands out by significantly extending the scope
of existing ones for understanding how the physical attributes of different
objects influence human posture, speed, motion scale, and interacting
strategies. We further demonstrate the applicability of the PA-HOI dataset by
integrating it with existing motion generation methods, validating its capacity
to transfer realistic physical awareness.

</details>


### [146] [Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning](https://arxiv.org/abs/2508.06218)
*Zhiyan Bo,Laura C. Coates,Bartlomiej W. Papiez*

Main category: cs.CV

TL;DR: 该论文提出了一种两阶段管道，用于通过双手X光片预测可解释的图像级SvdH评分，以解决手动评分的低效问题。


<details>
  <summary>Details</summary>
Motivation: SvdH评分在类风湿关节炎（RA）临床试验中广泛使用，但其复杂性限制了其在常规临床实践中的采用。手动评分效率低下，因此需要自动化解决方案。

Method: 采用两阶段管道，提取疾病相关图像区域，并通过基于注意力的多实例学习整合这些区域以生成图像级特征。提出了两种区域提取方案：1）采样最可能包含异常的图像块；2）裁剪包含疾病相关关节的补丁。

Result: 最佳模型（方案2）的Pearson相关系数（PCC）为0.943，均方根误差（RMSE）为15.73。集成学习进一步提升了性能（PCC=0.945，RMSE=15.57），达到与经验丰富的放射科医生相当的水平。

Conclusion: 该管道能有效识别并基于临床相关的解剖结构做出决策，为RA进展提供了高效且可解释的评分方法。

Abstract: The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials
to quantify radiographic damage in Rheumatoid Arthritis (RA), but its
complexity has limited its adoption in routine clinical practice. To address
the inefficiency of manual scoring, this work proposes a two-stage pipeline for
interpretable image-level SvdH score prediction using dual-hand radiographs.
Our approach extracts disease-relevant image regions and integrates them using
attention-based multiple instance learning to generate image-level features for
prediction. We propose two region extraction schemes: 1) sampling image tiles
most likely to contain abnormalities, and 2) cropping patches containing
disease-relevant joints. With Scheme 2, our best individual score prediction
model achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root
mean squared error (RMSE) of 15.73. Ensemble learning further boosted
prediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving
state-of-the-art performance that is comparable to that of experienced
radiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively
identified and made decisions based on anatomical structures which clinicians
consider relevant to RA progression.

</details>


### [147] [TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images](https://arxiv.org/abs/2508.06224)
*Guoyu Zhou,Jing Zhang,Yi Yan,Hui Zhang,Li Zhuo*

Main category: cs.CV

TL;DR: 提出了一种纹理感知和边缘引导的Transformer（TEFormer），用于城市遥感图像的语义分割，解决了纹理差异小和边缘复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 城市遥感图像中地物纹理差异小、空间结构相似，易导致语义模糊和误分类，同时不规则形状和模糊边界增加了分割难度。

Method: 设计了纹理感知模块（TaM）增强语义区分，边缘引导三分支解码器（Eg3Head）保留局部细节，边缘引导特征融合模块（EgFFM）融合上下文与边缘信息。

Result: 在Potsdam、Vaihingen和LoveDA数据集上分别达到88.57%、81.46%和53.55%的mIoU。

Conclusion: TEFormer在城市遥感图像语义分割中表现出色，有效解决了纹理和边缘问题。

Abstract: Semantic segmentation of urban remote sensing images (URSIs) is crucial for
applications such as urban planning and environmental monitoring. However,
geospatial objects often exhibit subtle texture differences and similar spatial
structures, which can easily lead to semantic ambiguity and misclassification.
Moreover, challenges such as irregular object shapes, blurred boundaries, and
overlapping spatial distributions of semantic objects contribute to complex and
diverse edge morphologies, further complicating accurate segmentation. To
tackle these issues, we propose a texture-aware and edge-guided Transformer
(TEFormer) that integrates texture awareness and edge-guidance mechanisms for
semantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is
designed to capture fine-grained texture differences between visually similar
categories to enhance semantic discrimination. Then, an edge-guided tri-branch
decoder (Eg3Head) is constructed to preserve local edges and details for
multiscale context-awareness. Finally, an edge-guided feature fusion module
(EgFFM) is to fuse contextual and detail information with edge information to
realize refined semantic segmentation. Extensive experiments show that TEFormer
achieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and
LoveDA datasets, respectively, shows the effectiveness in URSI semantic
segmentation.

</details>


### [148] [Towards Unified Image Deblurring using a Mixture-of-Experts Decoder](https://arxiv.org/abs/2508.06228)
*Daniel Feijoo,Paula Garrido-Mellado,Jaesung Rim,Alvaro Garcia,Marcos V. Conde*

Main category: cs.CV

TL;DR: 提出了一种全能的图像去模糊方法，通过混合专家（MoE）解码模块动态处理多种模糊类型，性能媲美专用模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法针对特定模糊类型设计，缺乏通用性，需要多个模型，实用性不足。

Method: 采用混合专家（MoE）解码模块，根据模糊类型动态路由图像特征，实现端到端恢复。

Result: 方法在多种模糊类型上表现优异，对未见过的模糊场景也展现出强鲁棒性和泛化能力。

Conclusion: 提出的统一方法高效且通用，适用于多种模糊场景，性能接近专用模型。

Abstract: Image deblurring, removing blurring artifacts from images, is a fundamental
task in computational photography and low-level computer vision. Existing
approaches focus on specialized solutions tailored to particular blur types,
thus, these solutions lack generalization. This limitation in current methods
implies requiring multiple models to cover several blur types, which is not
practical in many real scenarios. In this paper, we introduce the first
all-in-one deblurring method capable of efficiently restoring images affected
by diverse blur degradations, including global motion, local motion, blur in
low-light conditions, and defocus blur. We propose a mixture-of-experts (MoE)
decoding module, which dynamically routes image features based on the
recognized blur degradation, enabling precise and efficient restoration in an
end-to-end manner. Our unified approach not only achieves performance
comparable to dedicated task-specific models, but also demonstrates remarkable
robustness and generalization capabilities on unseen blur degradation
scenarios.

</details>


### [149] [Deepfake Detection that Generalizes Across Benchmarks](https://arxiv.org/abs/2508.06248)
*Andrii Yermakov,Jan Cech,Jiri Matas,Mario Fritz*

Main category: cs.CV

TL;DR: 论文提出了一种参数高效的CLIP视觉编码器微调方法（LNCLIP-DF），仅调整层归一化参数（0.03%），通过L2归一化和潜在空间增强提升泛化能力，在13个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度伪造检测器对未见过的伪造技术的泛化问题，避免复杂的架构调整。

Method: 微调预训练CLIP模型的层归一化参数，结合L2归一化和潜在空间增强，构建超球面特征流形。

Result: 在13个基准数据集上表现优异，平均跨数据集AUROC超过复杂方法，发现配对真实-伪造数据训练和多样化数据集对泛化至关重要。

Conclusion: 通过最小化调整预训练CLIP模型，实现了高效且可复现的SOTA泛化性能。

Abstract: The generalization of deepfake detectors to unseen manipulation techniques
remains a challenge for practical deployment. Although many approaches adapt
foundation models by introducing significant architectural complexity, this
work demonstrates that robust generalization is achievable through a
parameter-efficient adaptation of a pre-trained CLIP vision encoder. The
proposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters
(0.03% of the total) and enhances generalization by enforcing a hyperspherical
feature manifold using L2 normalization and latent space augmentations.
  We conducted an extensive evaluation on 13 benchmark datasets spanning from
2019 to 2025. The proposed method achieves state-of-the-art performance,
outperforming more complex, recent approaches in average cross-dataset AUROC.
Our analysis yields two primary findings for the field: 1) training on paired
real-fake data from the same source video is essential for mitigating shortcut
learning and improving generalization, and 2) detection difficulty on academic
datasets has not strictly increased over time, with models trained on older,
diverse datasets showing strong generalization capabilities.
  This work delivers a computationally efficient and reproducible method,
proving that state-of-the-art generalization is attainable by making targeted,
minimal changes to a pre-trained CLIP model. The code will be made publicly
available upon acceptance.

</details>


### [150] [FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing](https://arxiv.org/abs/2508.06256)
*Barış Büyüktaş,Jonas Klotz,Begüm Demir*

Main category: cs.CV

TL;DR: 提出了一种名为FedX的新策略，通过解释引导的剪枝减少联邦学习中的通信开销，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在遥感图像分类任务中面临通信开销大的问题，FedX旨在通过剪枝减少传输数据量。

Method: 利用反向传播解释方法评估模型组件的重要性，剪枝最不相关的部分，生成稀疏全局模型以减少通信量。

Result: 在BigEarthNet-S2和EuroSAT数据集上的实验表明，FedX显著减少了共享参数数量，同时提升了模型泛化能力。

Conclusion: FedX成功降低了通信开销，优于未剪枝模型和其他先进剪枝方法，代码将公开。

Abstract: Federated learning (FL) enables the collaborative training of deep neural
networks across decentralized data archives (i.e., clients), where each client
stores data locally and only shares model updates with a central server. This
makes FL a suitable learning paradigm for remote sensing (RS) image
classification tasks, where data centralization may be restricted due to legal
and privacy constraints. However, a key challenge in applying FL to RS tasks is
the communication overhead caused by the frequent exchange of large model
updates between clients and the central server. To address this issue, in this
paper we propose a novel strategy (denoted as FedX) that uses
explanation-guided pruning to reduce communication overhead by minimizing the
size of the transmitted models without compromising performance. FedX leverages
backpropagation-based explanation methods to estimate the task-specific
importance of model components and prunes the least relevant ones at the
central server. The resulting sparse global model is then sent to clients,
substantially reducing communication overhead. We evaluate FedX on multi-label
scene classification using the BigEarthNet-S2 dataset and single-label scene
classification using the EuroSAT dataset. Experimental results show the success
of FedX in significantly reducing the number of shared model parameters while
enhancing the generalization capability of the global model, compared to both
unpruned model and state-of-the-art pruning methods. The code of FedX will be
available at https://git.tu-berlin.de/rsim/FedX.

</details>


### [151] [XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation](https://arxiv.org/abs/2508.06258)
*Byunghyun Ko,Anning Tian,Jeongkyu Lee*

Main category: cs.CV

TL;DR: XAG-Net是一种新型2.5D U-Net架构，通过像素级跨切片注意力（CSA）和跳跃注意力门控（AG）机制，提升了股骨MRI分割的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有2D和3D深度学习分割方法在股骨MRI分割中存在局限性，需要更高效的解决方案。

Method: 提出XAG-Net，结合像素级CSA和AG机制，优化切片间上下文建模和切片内特征细化。

Result: XAG-Net在股骨分割准确性上优于基线2D、2.5D和3D U-Net模型，同时保持计算效率。

Conclusion: XAG-Net通过CSA和AG模块的有效性，成为股骨MRI分割的高效准确框架。

Abstract: Accurate segmentation of femur structures from Magnetic Resonance Imaging
(MRI) is critical for orthopedic diagnosis and surgical planning but remains
challenging due to the limitations of existing 2D and 3D deep learning-based
segmentation approaches. In this study, we propose XAG-Net, a novel 2.5D
U-Net-based architecture that incorporates pixel-wise cross-slice attention
(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice
contextual modeling and intra-slice feature refinement. Unlike previous
CSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent
slices at each spatial location for fine-grained inter-slice modeling.
Extensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and
3D U-Net models in femur segmentation accuracy while maintaining computational
efficiency. Ablation studies further validate the critical role of the CSA and
AG modules, establishing XAG-Net as a promising framework for efficient and
accurate femur MRI segmentation.

</details>


### [152] [SIFThinker: Spatially-Aware Image Focus for Visual Reasoning](https://arxiv.org/abs/2508.06259)
*Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang*

Main category: cs.CV

TL;DR: SIFThinker是一个空间感知的多模态框架，通过深度增强的边界框和自然语言交互，提升复杂视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在复杂视觉任务（如空间理解和细粒度感知）中表现不足，缺乏利用空间线索进行注意力校正的能力。

Method: 提出SIFThinker框架，结合反向扩展前向推理策略生成图像-文本链，并引入GRPO-SIF训练范式，动态校正注意力。

Result: SIFThinker在空间理解和细粒度感知任务中优于现有方法，同时保持通用能力。

Conclusion: SIFThinker通过空间感知和动态注意力校正，显著提升了复杂视觉任务的性能。

Abstract: Current multimodal large language models (MLLMs) still face significant
challenges in complex visual tasks (e.g., spatial understanding, fine-grained
perception). Prior methods have tried to incorporate visual reasoning, however,
they fail to leverage attention correction with spatial cues to iteratively
refine their focus on prompt-relevant regions. In this paper, we introduce
SIFThinker, a spatially-aware "think-with-images" framework that mimics human
visual perception. Specifically, SIFThinker enables attention correcting and
image region focusing by interleaving depth-enhanced bounding boxes and natural
language. Our contributions are twofold: First, we introduce a
reverse-expansion-forward-inference strategy that facilitates the generation of
interleaved image-text chains of thought for process-level supervision, which
in turn leads to the construction of the SIF-50K dataset. Besides, we propose
GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual
grounding into a unified reasoning pipeline, teaching the model to dynamically
correct and focus on prompt-relevant regions. Extensive experiments demonstrate
that SIFThinker outperforms state-of-the-art methods in spatial understanding
and fine-grained visual perception, while maintaining strong general
capabilities, highlighting the effectiveness of our method.

</details>


### [153] [Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding](https://arxiv.org/abs/2508.06317)
*Jian Hu,Zixu Cheng,Shaogang Gong,Isabel Guan,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.CV

TL;DR: 提出了一种数据高效的跨域视频时间定位方法URPA，无需目标域标注，仅需少量未标注视频即可实现实时部署。


<details>
  <summary>Details</summary>
Motivation: 现有方法GRPO依赖标注数据且计算开销大，难以在未标注域中应用。

Method: 使用不确定性量化的Rollout策略适应（URPA），通过生成多候选预测并加权训练奖励实现跨域知识迁移。

Result: 在六个跨域设置中，URPA仅需少量未标注视频即表现出良好泛化能力。

Conclusion: URPA解决了标注依赖和计算开销问题，适用于实时跨域视频时间定位。

Abstract: Video Temporal Grounding (TG) aims to temporally locate video segments
matching a natural language description (a query) in a long video. While
Vision-Language Models (VLMs) are effective at holistic semantic matching, they
often struggle with fine-grained temporal localisation. Recently, Group
Relative Policy Optimisation (GRPO) reformulates the inference process as a
reinforcement learning task, enabling fine-grained grounding and achieving
strong in-domain performance. However, GRPO relies on labelled data, making it
unsuitable in unlabelled domains. Moreover, because videos are large and
expensive to store and process, performing full-scale adaptation introduces
prohibitive latency and computational overhead, making it impractical for
real-time deployment. To overcome both problems, we introduce a Data-Efficient
Unlabelled Cross-domain Temporal Grounding method, from which a model is first
trained on a labelled source domain, then adapted to a target domain using only
a small number of unlabelled videos from the target domain. This approach
eliminates the need for target annotation and keeps both computational and
storage overhead low enough to run in real time. Specifically, we introduce.
Uncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain
knowledge transfer in learning video temporal grounding without target labels.
URPA generates multiple candidate predictions using GRPO rollouts, averages
them to form a pseudo label, and estimates confidence from the variance across
these rollouts. This confidence then weights the training rewards, guiding the
model to focus on reliable supervision. Experiments on three datasets across
six cross-domain settings show that URPA generalises well using only a few
unlabelled target videos. Codes will be released once published.

</details>


### [154] [Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.06318)
*Giacomo D'Amicantonio,Snehashis Majhi,Quan Kong,Lorenzo Garattoni,Gianpiero Francesca,François Bremond,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文提出了一种名为GS-MoE的新框架，通过专家模型和时序高斯损失改进弱监督视频异常检测，解决了现有模型在复杂异常事件上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测模型在处理复杂异常事件时表现不佳，主要由于模型无法区分异常类别且弱监督信号缺乏精确时序信息。

Method: 提出GS-MoE框架，使用多个专家模型分别捕捉特定异常类型，并通过时序高斯损失增强弱监督信号。

Result: 在UCF-Crime数据集上达到91.58%的AUC，并在XD-Violence和MSAD数据集上表现优异。

Conclusion: GS-MoE通过类别特异性专家和时序引导，为弱监督视频异常检测设定了新基准。

Abstract: Video Anomaly Detection (VAD) is a challenging task due to the variability of
anomalous events and the limited availability of labeled data. Under the
Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided
during training, while predictions are made at the frame level. Although
state-of-the-art models perform well on simple anomalies (e.g., explosions),
they struggle with complex real-world events (e.g., shoplifting). This
difficulty stems from two key issues: (1) the inability of current models to
address the diversity of anomaly types, as they process all categories with a
shared model, overlooking category-specific features; and (2) the weak
supervision signal, which lacks precise temporal information, limiting the
ability to capture nuanced anomalous patterns blended with normal events. To
address these challenges, we propose Gaussian Splatting-guided Mixture of
Experts (GS-MoE), a novel framework that employs a set of expert models, each
specialized in capturing specific anomaly types. These experts are guided by a
temporal Gaussian splatting loss, enabling the model to leverage temporal
consistency and enhance weak supervision. The Gaussian splatting approach
encourages a more precise and comprehensive representation of anomalies by
focusing on temporal segments most likely to contain abnormal events. The
predictions from these specialized experts are integrated through a
mixture-of-experts mechanism to model complex relationships across diverse
anomaly patterns. Our approach achieves state-of-the-art performance, with a
91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on
XD-Violence and MSAD datasets. By leveraging category-specific expertise and
temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.

</details>


### [155] [Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?](https://arxiv.org/abs/2508.06327)
*Xin Ci Wong,Duygu Sarikaya,Kieran Zucker,Marc De Kamps,Nishant Ravikumar*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型的合成数据生成方法，用于解决心脏MR图像分析中的域偏移问题，显著提升多中心分割性能。


<details>
  <summary>Details</summary>
Motivation: 心脏MR图像因设备和协议差异导致域偏移，限制了AI模型在实际场景中的应用。传统方法如数据增强或迁移学习存在局限性，合成数据提供了一种新思路。

Method: 使用扩散模型在源域上生成合成心脏MR图像，保持结构和空间一致性，并用于训练分割模型（2D/3D nnU-Net和U-Net）。

Result: 合成数据显著提升了未见目标域的分割性能（Welch's t-test, p < 0.01），优于仅使用真实数据的方法。

Conclusion: 该方法无需迁移学习或在线训练，有效解决了域偏移问题，特别适用于数据稀缺场景。

Abstract: Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain
shift due to variations in imaging devices and acquisition protocols. This
challenge limits the deployment of trained AI models in real-world scenarios,
where performance degrades on unseen domains. Traditional solutions involve
increasing the size of the dataset through ad-hoc image augmentation or
additional online training/transfer learning, which have several limitations.
Synthetic data offers a promising alternative, but anatomical/structural
consistency constraints limit the effectiveness of generative models in
creating image-label pairs. To address this, we propose a diffusion model (DM)
trained on a source domain that generates synthetic cardiac MR images that
resemble a given reference. The synthetic data maintains spatial and structural
fidelity, ensuring similarity to the source domain and compatibility with the
segmentation mask. We assess the utility of our generative approach in
multi-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and
vanilla U-Net segmentation networks. We explore domain generalisation, where,
domain-invariant segmentation models are trained on synthetic source domain
data, and domain adaptation, where, we shift target domain data towards the
source domain using the DM. Both strategies significantly improved segmentation
performance on data from an unseen target domain, in terms of surface-based
metrics (Welch's t-test, p < 0.01), compared to training segmentation models on
real data alone. The proposed method ameliorates the need for transfer learning
or online training to address domain shift challenges in cardiac MR image
analysis, especially useful in data-scarce settings.

</details>


### [156] [ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction](https://arxiv.org/abs/2508.06335)
*Patrick Takenaka,Johannes Maucher,Marco F. Huber*

Main category: cs.CV

TL;DR: 改进ViPro模型，使其能够从观测中正确推断状态，无需提供初始真实状态，并在无监督方式下实现。


<details>
  <summary>Details</summary>
Motivation: 解决ViPro模型因依赖初始真实状态而无法在噪声环境下正确推断状态的问题。

Method: 在ViPro基础上添加改进，使其能无监督地从观测中推断状态，并扩展Orbits数据集为3D版本。

Result: 模型能够在无监督情况下正确推断状态，且适用于更接近真实世界的3D场景。

Conclusion: 改进后的ViPro模型在状态推断和视频帧预测任务中表现更优，适用于复杂动态场景。

Abstract: Predicting future video frames is a challenging task with many downstream
applications. Previous work has shown that procedural knowledge enables deep
models for complex dynamical settings, however their model ViPro assumed a
given ground truth initial symbolic state. We show that this approach led to
the model learning a shortcut that does not actually connect the observed
environment with the predicted symbolic state, resulting in the inability to
estimate states given an observation if previous states are noisy. In this
work, we add several improvements to ViPro that enables the model to correctly
infer states from observations without providing a full ground truth state in
the beginning. We show that this is possible in an unsupervised manner, and
extend the original Orbits dataset with a 3D variant to close the gap to real
world scenarios.

</details>


### [157] [Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities](https://arxiv.org/abs/2508.06342)
*Kieran Elrod,Katherine Flanigan,Mario Bergés*

Main category: cs.CV

TL;DR: 利用街景图像和大型语言模型分析城市社交性，验证其与城市规划和环境变量的关联。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注行人数量而非社交互动质量，街景图像作为低成本、全球覆盖的数据源，可能蕴含潜在社交信息。

Method: 分析15个城市的2,998张街景图像，结合Mehta的社交性分类理论，使用线性回归模型控制天气、时间等因素。

Result: 天空视野指数与三类社交性相关，绿色视野指数预测持久社交性，地方依恋与短暂社交性正相关。

Conclusion: 街景图像可推断社交互动与建成环境的关系，为跨文化理论测试和社会活力城市设计提供工具。

Abstract: Designing socially active streets has long been a goal of urban planning, yet
existing quantitative research largely measures pedestrian volume rather than
the quality of social interactions. We hypothesize that street view imagery --
an inexpensive data source with global coverage -- contains latent social
information that can be extracted and interpreted through established social
science theory. As a proof of concept, we analyzed 2,998 street view images
from 15 cities using a multimodal large language model guided by Mehta's
taxonomy of passive, fleeting, and enduring sociability -- one illustrative
example of a theory grounded in urban design that could be substituted or
complemented by other sociological frameworks. We then used linear regression
models, controlling for factors like weather, time of day, and pedestrian
counts, to test whether the inferred sociability measures correlate with
city-level place attachment scores from the World Values Survey and with
environmental predictors (e.g., green, sky, and water view indices) derived
from individual street view images. Results aligned with long-standing urban
planning theory: the sky view index was associated with all three sociability
types, the green view index predicted enduring sociability, and place
attachment was positively associated with fleeting sociability. These results
provide preliminary evidence that street view images can be used to infer
relationships between specific types of social interactions and built
environment variables. Further research could establish street view imagery as
a scalable, privacy-preserving tool for studying urban sociability, enabling
cross-cultural theory testing and evidence-based design of socially vibrant
cities.

</details>


### [158] [Aligning Effective Tokens with Video Anomaly in Large Language Models](https://arxiv.org/abs/2508.06350)
*Yingxian Chen,Jiahui Liu,Ruifan Di,Yanwei Li,Chirui Chang,Shizhen Zhao,Wilton W. T. Fok,Xiaojuan Qi,Yik-Chung Wu*

Main category: cs.CV

TL;DR: VA-GPT是一种新型多模态大语言模型（MLLM），用于视频中异常事件的总结和定位，通过空间和时间有效令牌模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在处理视频异常事件时因空间和时间稀疏性表现不佳，需要更高效的模型。

Method: 提出VA-GPT，结合SETS和TETG模块，优化视觉与语言模型的对齐，并构建专用数据集。

Result: 在多个基准测试中优于现有方法。

Conclusion: VA-GPT通过有效令牌选择和生成模块显著提升了异常事件分析的准确性。

Abstract: Understanding abnormal events in videos is a vital and challenging task that
has garnered significant attention in a wide range of applications. Although
current video understanding Multi-modal Large Language Models (MLLMs) are
capable of analyzing general videos, they often struggle to handle anomalies
due to the spatial and temporal sparsity of abnormal events, where the
redundant information always leads to suboptimal outcomes. To address these
challenges, exploiting the representation and generalization capabilities of
Vison Language Models (VLMs) and Large Language Models (LLMs), we propose
VA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in
various videos. Our approach efficiently aligns effective tokens between visual
encoders and LLMs through two key proposed modules: Spatial Effective Token
Selection (SETS) and Temporal Effective Token Generation (TETG). These modules
enable our model to effectively capture and analyze both spatial and temporal
information associated with abnormal events, resulting in more accurate
responses and interactions. Furthermore, we construct an instruction-following
dataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a
cross-domain evaluation benchmark based on XD-Violence dataset. Our proposed
method outperforms existing state-of-the-art methods on various benchmarks.

</details>


### [159] [An Implemention of Two-Phase Image Segmentation using the Split Bregman Method](https://arxiv.org/abs/2508.06351)
*Olakunle S. Abawonse,Günay Doğan*

Main category: cs.CV

TL;DR: 本文实现了一种基于Goldstein、Bresson和Osher提出的两阶段图像分割算法，通过改进Chan-Vese能量模型，利用Split Bregman方法高效实现图像分割。


<details>
  <summary>Details</summary>
Motivation: 图像分割是计算机视觉中的重要任务，传统Chan-Vese模型在效率上存在不足，本文旨在通过改进能量模型和优化方法提升分割效率。

Method: 采用改进的Chan-Vese能量模型，结合Split Bregman方法进行优化，实现高效的两阶段图像分割。

Result: 实验验证了该方法在不同参数和图像上的性能，证明了其高效性和有效性。

Conclusion: 本文提出的方法在图像分割任务中表现优异，为相关领域提供了实用的实现方案。

Abstract: In this paper, we describe an implementation of the two-phase image
segmentation algorithm proposed by Goldstein, Bresson, Osher in
\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into
foreground and background regions, and each pixel of the image is assigned
membership to one of these two regions. The underlying assumption for the
segmentation model is that the pixel values of the input image can be
summarized by two distinct average values, and that the region boundaries are
smooth. Accordingly, the model is defined as an energy in which the variable is
a region membership function to assign pixels to either region, originally
proposed by Chan and Vese in \cite{chan:vese}. This energy is the sum of image
data terms in the regions and a length penalty for region boundaries.
Goldstein, Bresson, Osher modify the energy of Chan-Vese in \cite{gold:bre} so
that their new energy can be minimized efficiently using the split Bregman
method to produce an equivalent two-phase segmentation. We provide a detailed
implementation of this method \cite{gold:bre}, and document its performance
with several images over a range of algorithm parameters.

</details>


### [160] [Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd](https://arxiv.org/abs/2508.06357)
*Aman Bhatta,Maria Dhakal,Michael C. King,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 论文提出了一种新方法，利用额外的注册图像预测一对多人脸识别中的排名第一结果是否为库内或库外，以减少误识别和调查时间浪费。


<details>
  <summary>Details</summary>
Motivation: 解决一对多人脸识别中排名第一结果是否为库内或库外的问题，传统方法依赖相似度阈值，而新方法利用额外注册图像信息。

Method: 通过提取排名第一身份的额外注册图像排名生成训练数据，训练分类器预测库内或库外状态。

Result: 实验表明该方法适用于高质量和低质量图像，且在人口统计学上分类准确率相似。

Conclusion: 该方法能有效减少误识别和调查时间浪费，且仅在使用先进损失函数训练的匹配器上有效。

Abstract: A central problem in one-to-many facial identification is that the person in
the probe image may or may not have enrolled image(s) in the gallery; that is,
may be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one
result is Out-of-gallery have mostly focused on finding a suitable threshold on
the similarity score. We take a new approach, using the additional enrolled
images of the identity with the rank-one result to predict if the rank-one
result is In-gallery / Out-of-gallery. Given a gallery of identities and
images, we generate In-gallery and Out-of-gallery training data by extracting
the ranks of additional enrolled images corresponding to the rank-one identity.
We then train a classifier to utilize this feature vector to predict whether a
rank-one result is In-gallery or Out-of-gallery. Using two different datasets
and four different matchers, we present experimental results showing that our
approach is viable for mugshot quality probe images, and also, importantly, for
probes degraded by blur, reduced resolution, atmospheric turbulence and
sunglasses. We also analyze results across demographic groups, and show that
In-gallery / Out-of-gallery classification accuracy is similar across
demographics. Our approach has the potential to provide an objective estimate
of whether a one-to-many facial identification is Out-of-gallery, and thereby
to reduce false positive identifications, wrongful arrests, and wasted
investigative time. Interestingly, comparing the results of older deep
CNN-based face matchers with newer ones suggests that the effectiveness of our
Out-of-gallery detection approach emerges only with matchers trained using
advanced margin-based loss functions.

</details>


### [161] [Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning](https://arxiv.org/abs/2508.06382)
*Xiangyu Wu,Feng Yu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: TaAM-CPT是一种通过文本数据构建通用多模态表示模型的方法，无需特定模态标注数据，支持无限模态扩展。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量模态标注数据或仅适用于单一模态，限制了通用性和扩展性。

Method: TaAM-CPT结合模态提示池、文本构建和模态对齐文本编码器，设计跨模态学习目标。

Result: 在视频、图像和音频分类任务中表现领先，无需模态标注数据。

Conclusion: TaAM-CPT展示了通过文本数据实现多模态通用表示的潜力，具有高度扩展性。

Abstract: The integration of prompt tuning with multimodal learning has shown
significant generalization abilities for various downstream tasks. Despite
advancements, existing methods heavily depend on massive modality-specific
labeled data (e.g., video, audio, and image), or are customized for a single
modality. In this study, we present Text as Any-Modality by Consistent Prompt
Tuning (TaAM-CPT), a scalable approach for constructing a general
representation model toward unlimited modalities using solely text data.
TaAM-CPT comprises modality prompt pools, text construction, and
modality-aligned text encoders from pre-trained models, which allows for
extending new modalities by simply adding prompt pools and modality-aligned
text encoders. To harmonize the learning across different modalities, TaAM-CPT
designs intra- and inter-modal learning objectives, which can capture category
details within modalities while maintaining semantic consistency across
different modalities. Benefiting from its scalable architecture and pre-trained
models, TaAM-CPT can be seamlessly extended to accommodate unlimited
modalities. Remarkably, without any modality-specific labeled data, TaAM-CPT
achieves leading results on diverse datasets spanning various modalities,
including video classification, image classification, and audio classification.
The code is available at https://github.com/Jinx630/TaAM-CPT.

</details>


### [162] [FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation](https://arxiv.org/abs/2508.06392)
*Wenbin Teng,Gonglin Chen,Haiwei Chen,Yajie Zhao*

Main category: cs.CV

TL;DR: FVGen框架通过蒸馏视频扩散模型，实现快速新视角合成，显著减少采样时间90%以上。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏视图下3D重建中因采样速度慢导致的效率问题。

Method: 提出一种视频扩散模型蒸馏方法，将多步去噪教师模型蒸馏为少步去噪学生模型，结合GAN和软化反向KL散度最小化。

Result: 在真实数据集上，FVGen以更少采样步骤生成高质量新视角，采样时间减少90%以上。

Conclusion: FVGen显著提升稀疏视图下3D重建的时间效率。

Abstract: Recent progress in 3D reconstruction has enabled realistic 3D models from
dense image captures, yet challenges persist with sparse views, often leading
to artifacts in unseen areas. Recent works leverage Video Diffusion Models
(VDMs) to generate dense observations, filling the gaps when only sparse views
are available for 3D reconstruction tasks. A significant limitation of these
methods is their slow sampling speed when using VDMs. In this paper, we present
FVGen, a novel framework that addresses this challenge by enabling fast novel
view synthesis using VDMs in as few as four sampling steps. We propose a novel
video diffusion model distillation method that distills a multi-step denoising
teacher model into a few-step denoising student model using Generative
Adversarial Networks (GANs) and softened reverse KL-divergence minimization.
Extensive experiments on real-world datasets show that, compared to previous
works, our framework generates the same number of novel views with similar (or
even better) visual quality while reducing sampling time by more than 90%.
FVGen significantly improves time efficiency for downstream reconstruction
tasks, particularly when working with sparse input views (more than 2) where
pre-trained VDMs need to be run multiple times to achieve better spatial
coverage.

</details>


### [163] [A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery](https://arxiv.org/abs/2508.06407)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 论文探讨了将分类目标直接融入超分辨率过程是否能提升分类准确性，并提出了一种优化图像质量和分类性能的新方法。


<details>
  <summary>Details</summary>
Motivation: 低分辨率图像限制了自动化分析的准确性，传统超分辨率方法仅关注像素级指标，未充分探索超分辨率图像保真度与下游分类性能的关系。

Method: 提出了一种新颖的方法，通过优化同时考虑图像质量和分类性能的损失函数，提高合成孔径雷达图像的分辨率。

Result: 该方法在科学验证的图像质量指标上提升了图像质量，同时提高了分类准确性。

Conclusion: 将分类目标融入超分辨率过程可以同时提升图像质量和分类性能。

Abstract: High-resolution imagery plays a critical role in improving the performance of
visual recognition tasks such as classification, detection, and segmentation.
In many domains, including remote sensing and surveillance, low-resolution
images can limit the accuracy of automated analysis. To address this,
super-resolution (SR) techniques have been widely adopted to attempt to
reconstruct high-resolution images from low-resolution inputs. Related
traditional approaches focus solely on enhancing image quality based on
pixel-level metrics, leaving the relationship between super-resolved image
fidelity and downstream classification performance largely underexplored. This
raises a key question: can integrating classification objectives directly into
the super-resolution process further improve classification accuracy? In this
paper, we try to respond to this question by investigating the relationship
between super-resolution and classification through the deployment of a
specialised algorithmic strategy. We propose a novel methodology that increases
the resolution of synthetic aperture radar imagery by optimising loss functions
that account for both image quality and classification performance. Our
approach improves image quality, as measured by scientifically ascertained
image quality indicators, while also enhancing classification accuracy.

</details>


### [164] [Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification](https://arxiv.org/abs/2508.06420)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 论文提出两种新算法（M2m$_f$和M2m$_u$）用于解决SAR船舶分类中的长尾数据集问题，通过特征空间过采样方法提升分类性能。


<details>
  <summary>Details</summary>
Motivation: SAR船舶分类面临长尾数据集的挑战，尤其是少数类别的分类困难。光学数据中的过采样方法已被证明有效，但需验证其在SAR数据中的效果。

Method: 提出两种基于Major-to-minor（M2m）方法的新算法M2m$_f$和M2m$_u$，并在OpenSARShip和FuSARShip数据集上测试，使用ViT、VGG16和ResNet50作为特征提取器。

Result: 新方法在FuSARShip和OpenSARShip数据集上平均F1分数分别提高了8.82%和4.44%，优于原始M2m和基线方法。

Conclusion: 特征空间过采样方法对SAR船舶分类有效，新算法显著提升了少数类别的分类性能。

Abstract: SAR ship classification faces the challenge of long-tailed datasets, which
complicates the classification of underrepresented classes. Oversampling
methods have proven effective in addressing class imbalance in optical data. In
this paper, we evaluated the effect of oversampling in the feature space for
SAR ship classification. We propose two novel algorithms inspired by the
Major-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two
public datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three
state-of-the-art models as feature extractors: ViT, VGG16, and ResNet50.
Additionally, we also analyzed the impact of oversampling methods on different
class sizes. The results demonstrated the effectiveness of our novel methods
over the original M2m and baselines, with an average F1-score increase of 8.82%
for FuSARShip and 4.44% for OpenSARShip.

</details>


### [165] [SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation](https://arxiv.org/abs/2508.06429)
*Guido Manni,Clemente Lauretti,Loredana Zollo,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种基于GAN的半监督学习框架，针对医学影像中标记数据稀缺的问题，通过集成生成器、判别器和分类器，结合伪标签技术，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中标记数据不足导致的深度学习效果受限问题。

Method: 采用GAN框架，结合生成器、判别器和分类器，通过监督学习和无监督学习的交替训练，利用伪标签技术增强模型性能。

Result: 在11个MedMNIST数据集上显著优于六种最先进的半监督方法，尤其在5-shot极端情况下表现突出。

Conclusion: 该框架为标记成本高的医学影像应用提供了实用解决方案，即使标记数据极少也能实现稳健分类。

Abstract: Deep learning has revolutionized medical imaging, but its effectiveness is
severely limited by insufficient labeled training data. This paper introduces a
novel GAN-based semi-supervised learning framework specifically designed for
low labeled-data regimes, evaluated across settings with 5 to 50 labeled
samples per class. Our approach integrates three specialized neural networks --
a generator for class-conditioned image translation, a discriminator for
authenticity assessment and classification, and a dedicated classifier --
within a three-phase training framework. The method alternates between
supervised training on limited labeled data and unsupervised learning that
leverages abundant unlabeled images through image-to-image translation rather
than generation from noise. We employ ensemble-based pseudo-labeling that
combines confidence-weighted predictions from the discriminator and classifier
with temporal consistency through exponential moving averaging, enabling
reliable label estimation for unlabeled data. Comprehensive evaluation across
eleven MedMNIST datasets demonstrates that our approach achieves statistically
significant improvements over six state-of-the-art GAN-based semi-supervised
methods, with particularly strong performance in the extreme 5-shot setting
where the scarcity of labeled data is most challenging. The framework maintains
its superiority across all evaluated settings (5, 10, 20, and 50 shots per
class). Our approach offers a practical solution for medical imaging
applications where annotation costs are prohibitive, enabling robust
classification performance even with minimal labeled data. Code is available at
https://github.com/GuidoManni/SPARSE.

</details>


### [166] [MotionSwap](https://arxiv.org/abs/2508.06430)
*Om Patil,Jinesh Modi,Suryabha Mukhopadhyay,Meghaditya Giri,Chhavi Malhotra*

Main category: cs.CV

TL;DR: 本文提出了一种改进的SimSwap框架，通过引入自注意力和交叉注意力机制、动态损失加权和余弦退火学习率调度，显著提升了人脸交换的保真度。


<details>
  <summary>Details</summary>
Motivation: 人脸交换技术在学术和商业应用中受到广泛关注，但现有方法在身份保持和视觉质量方面仍有改进空间。

Method: 改进SimSwap框架，包括自注意力和交叉注意力机制、动态损失加权和余弦退火学习率调度。

Result: 实验表明，改进后的模型在身份相似性、FID分数和视觉质量上优于基线，并通过消融研究验证了各改进的重要性。

Conclusion: 未来方向包括集成StyleGAN3、改进唇同步、引入3D面部建模和视频应用的时间一致性。

Abstract: Face swapping technology has gained significant attention in both academic
research and commercial applications. This paper presents our implementation
and enhancement of SimSwap, an efficient framework for high fidelity face
swapping. We introduce several improvements to the original model, including
the integration of self and cross-attention mechanisms in the generator
architecture, dynamic loss weighting, and cosine annealing learning rate
scheduling. These enhancements lead to significant improvements in identity
preservation, attribute consistency, and overall visual quality.
  Our experimental results, spanning 400,000 training iterations, demonstrate
progressive improvements in generator and discriminator performance. The
enhanced model achieves better identity similarity, lower FID scores, and
visibly superior qualitative results compared to the baseline. Ablation studies
confirm the importance of each architectural and training improvement. We
conclude by identifying key future directions, such as integrating StyleGAN3,
improving lip synchronization, incorporating 3D facial modeling, and
introducing temporal consistency for video-based applications.

</details>


### [167] [CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment](https://arxiv.org/abs/2508.06434)
*Shengzhu Yang,Jiawei Du,Shuai Lu,Weihang Zhang,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: CLIPin是一种非对比性插件，可无缝集成到CLIP架构中，提升多模态语义对齐能力。


<details>
  <summary>Details</summary>
Motivation: 解决自然图像-文本数据集语义对齐松散和医学数据集内容多样性低的问题，以增强CLIP模型的鲁棒性和泛化能力。

Method: 提出CLIPin插件，设计共享预投影器，结合对比和非对比学习。

Result: 在多样化下游任务中验证了CLIPin的有效性和通用性。

Conclusion: CLIPin作为即插即用组件，兼容多种对比框架，显著提升性能。

Abstract: Large-scale natural image-text datasets, especially those automatically
collected from the web, often suffer from loose semantic alignment due to weak
supervision, while medical datasets tend to have high cross-modal correlation
but low content diversity. These properties pose a common challenge for
contrastive language-image pretraining (CLIP): they hinder the model's ability
to learn robust and generalizable representations. In this work, we propose
CLIPin, a unified non-contrastive plug-in that can be seamlessly integrated
into CLIP-style architectures to improve multimodal semantic alignment,
providing stronger supervision and enhancing alignment robustness. Furthermore,
two shared pre-projectors are designed for image and text modalities
respectively to facilitate the integration of contrastive and non-contrastive
learning in a parameter-compromise manner. Extensive experiments on diverse
downstream tasks demonstrate the effectiveness and generality of CLIPin as a
plug-and-play component compatible with various contrastive frameworks. Code is
available at https://github.com/T6Yang/CLIPin.

</details>


### [168] [TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation](https://arxiv.org/abs/2508.06452)
*Mattia Litrico,Mario Valerio Giuffrida,Sebastiano Battiato,Devis Tuia*

Main category: cs.CV

TL;DR: TRUST是一种新型的无监督域适应方法，利用语言模态的鲁棒性指导视觉模型的适应，通过生成伪标签和不确定性估计提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂域偏移（如地理偏移）中传统无监督域适应方法表现不佳的问题，利用语言模态的鲁棒性提升视觉模型的适应性。

Method: TRUST通过生成伪标签和基于CLIP相似度分数的估计不确定性来重加权分类损失，并提出多模态软对比学习损失对齐视觉和语言特征空间。

Result: 在经典（DomainNet）和复杂（GeoNet）域偏移上优于现有方法，达到新SOTA。

Conclusion: TRUST通过语言模态的引导和不确定性估计，有效提升了视觉模型在复杂域偏移中的适应性。

Abstract: Recent unsupervised domain adaptation (UDA) methods have shown great success
in addressing classical domain shifts (e.g., synthetic-to-real), but they still
suffer under complex shifts (e.g. geographical shift), where both the
background and object appearances differ significantly across domains. Prior
works showed that the language modality can help in the adaptation process,
exhibiting more robustness to such complex shifts. In this paper, we introduce
TRUST, a novel UDA approach that exploits the robustness of the language
modality to guide the adaptation of a vision model. TRUST generates
pseudo-labels for target samples from their captions and introduces a novel
uncertainty estimation strategy that uses normalised CLIP similarity scores to
estimate the uncertainty of the generated pseudo-labels. Such estimated
uncertainty is then used to reweight the classification loss, mitigating the
adverse effects of wrong pseudo-labels obtained from low-quality captions. To
further increase the robustness of the vision model, we propose a multimodal
soft-contrastive learning loss that aligns the vision and language feature
spaces, by leveraging captions to guide the contrastive training of the vision
model on target images. In our contrastive loss, each pair of images acts as
both a positive and a negative pair and their feature representations are
attracted and repulsed with a strength proportional to the similarity of their
captions. This solution avoids the need for hardly determining positive and
negative pairs, which is critical in the UDA setting. Our approach outperforms
previous methods, setting the new state-of-the-art on classical (DomainNet) and
complex (GeoNet) domain shifts. The code will be available upon acceptance.

</details>


### [169] [Text Embedded Swin-UMamba for DeepLesion Segmentation](https://arxiv.org/abs/2508.06453)
*Ruida Cheng,Tejas Sudharshan Mathai,Pritam Mukherjee,Benjamin Hou,Qingqing Zhu,Zhiyong Lu,Matthew McAuliffe,Ronald M. Summers*

Main category: cs.CV

TL;DR: 研究探讨了将大语言模型（LLM）与Swin-UMamba架构结合用于CT病灶分割的可行性，结果显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 通过结合影像特征和放射学报告中的病灶描述，提升慢性疾病（如淋巴瘤）的自动测量准确性。

Method: 使用公开的ULS23 DeepLesion数据集和报告中的简短描述，构建Text-Swin-UMamba模型进行病灶分割。

Result: 测试数据集中，病灶分割的Dice Score达82%，Hausdorff距离为6.58像素，性能优于其他模型。

Conclusion: Text-Swin-UMamba模型在病灶分割任务中表现出色，为临床评估提供了高效工具。

Abstract: Segmentation of lesions on CT enables automatic measurement for clinical
assessment of chronic diseases (e.g., lymphoma). Integrating large language
models (LLMs) into the lesion segmentation workflow offers the potential to
combine imaging features with descriptions of lesion characteristics from the
radiology reports. In this study, we investigate the feasibility of integrating
text into the Swin-UMamba architecture for the task of lesion segmentation. The
publicly available ULS23 DeepLesion dataset was used along with short-form
descriptions of the findings from the reports. On the test dataset, a high Dice
Score of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for
lesion segmentation. The proposed Text-Swin-UMamba model outperformed prior
approaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <
0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by
1.74% and 0.22%, respectively. The dataset and code can be accessed at
https://github.com/ruida/LLM-Swin-UMamba

</details>


### [170] [WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion](https://arxiv.org/abs/2508.06485)
*Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai*

Main category: cs.CV

TL;DR: WGAST是一种弱监督生成网络，用于通过时空融合实现每日10米分辨率的地表温度（LST）估计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 城市化、气候变化和农业压力增加了对精确环境监测的需求，但现有遥感系统在时空分辨率上存在权衡。

Method: 采用条件生成对抗网络架构，包括特征提取、融合、LST重建和噪声抑制四个阶段，结合弱监督训练策略。

Result: WGAST在定量和定性评估中均优于现有方法，平均降低RMSE 17.18%，提高SSIM 11.00%。

Conclusion: WGAST能有效捕捉精细热模式，对云干扰具有鲁棒性，适用于高分辨率LST估计。

Abstract: Urbanization, climate change, and agricultural stress are increasing the
demand for precise and timely environmental monitoring. Land Surface
Temperature (LST) is a key variable in this context and is retrieved from
remote sensing satellites. However, these systems face a trade-off between
spatial and temporal resolution. While spatio-temporal fusion methods offer
promising solutions, few have addressed the estimation of daily LST at 10 m
resolution. In this study, we present WGAST, a Weakly-Supervised Generative
Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra
MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning
framework designed for this task. It adopts a conditional generative
adversarial architecture, with a generator composed of four stages: feature
extraction, fusion, LST reconstruction, and noise suppression. The first stage
employs a set of encoders to extract multi-level latent representations from
the inputs, which are then fused in the second stage using cosine similarity,
normalization, and temporal attention mechanisms. The third stage decodes the
fused features into high-resolution LST, followed by a Gaussian filter to
suppress high-frequency noise. Training follows a weakly supervised strategy
based on physical averaging principles and reinforced by a PatchGAN
discriminator. Experiments demonstrate that WGAST outperforms existing methods
in both quantitative and qualitative evaluations. Compared to the
best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves
SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and
effectively captures fine-scale thermal patterns, as validated against 33
ground-based sensors. The code is available at
https://github.com/Sofianebouaziz1/WGAST.git.

</details>


### [171] [LightSwitch: Multi-view Relighting with Material-guided Diffusion](https://arxiv.org/abs/2508.06494)
*Yehonathan Litman,Fernando De la Torre,Shubham Tulsiani*

Main category: cs.CV

TL;DR: LightSwitch是一种基于扩散框架的3D重光照方法，利用多视角和材质信息高效重光照多视角数据，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有2D重光照生成先验未充分利用物体固有属性或多视角数据，导致效果不佳。

Method: 提出LightSwitch框架，结合多视角和材质信息，采用可扩展去噪方案进行重光照。

Result: 在2D重光照预测质量上优于现有方法，并在合成和真实物体重光照中表现优异。

Conclusion: LightSwitch通过结合固有属性和多视角数据，显著提升了重光照效果和效率。

Abstract: Recent approaches for 3D relighting have shown promise in integrating 2D
image relighting generative priors to alter the appearance of a 3D
representation while preserving the underlying structure. Nevertheless,
generative priors used for 2D relighting that directly relight from an input
image do not take advantage of intrinsic properties of the subject that can be
inferred or cannot consider multi-view data at scale, leading to subpar
relighting. In this paper, we propose Lightswitch, a novel finetuned
material-relighting diffusion framework that efficiently relights an arbitrary
number of input images to a target lighting condition while incorporating cues
from inferred intrinsic properties. By using multi-view and material
information cues together with a scalable denoising scheme, our method
consistently and efficiently relights dense multi-view data of objects with
diverse material compositions. We show that our 2D relighting prediction
quality exceeds previous state-of-the-art relighting priors that directly
relight from images. We further demonstrate that LightSwitch matches or
outperforms state-of-the-art diffusion inverse rendering methods in relighting
synthetic and real objects in as little as 2 minutes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [172] [Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty](https://arxiv.org/abs/2508.05659)
*Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos*

Main category: cs.LG

TL;DR: 提出了一种将因果循环图（CLD）转换为系统动力学模型（SDM）的方法Diagrams-to-Dynamics（D2D），以支持动态分析和干预策略探索。


<details>
  <summary>Details</summary>
Motivation: 因果循环图（CLDs）作为静态定性工具，无法支持动态分析或干预策略评估，且现有定量分析方法易导致错误推断。

Method: D2D方法利用CLD中的结构信息（链接存在性和极性），通过用户简单标注变量类型（存量、流量/辅助变量或常量），生成探索性SDM。

Result: D2D能区分高/低优先级杠杆点，与数据驱动模型的一致性优于网络中心性分析，并提供不确定性估计和数据收集指导。

Conclusion: D2D方法通过开源工具实现，降低了动态建模门槛，未来验证将进一步证明其广泛适用性。

Abstract: Causal loop diagrams (CLDs) are widely used in health and environmental
research to represent hypothesized causal structures underlying complex
problems. However, as qualitative and static representations, CLDs are limited
in their ability to support dynamic analysis and inform intervention
strategies. Additionally, quantitative CLD analysis methods like network
centrality analysis often lead to false inference. We propose
Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory
system dynamics models (SDMs) in the absence of empirical data. With minimal
user input - following a protocol to label variables as stocks,
flows/auxiliaries, or constants - D2D leverages the structural information
already encoded in CLDs, namely, link existence and polarity, to simulate
hypothetical interventions and explore potential leverage points under
uncertainty. Results suggest that D2D helps distinguish between high- and
low-ranked leverage points. We compare D2D to a data-driven SDM constructed
from the same CLD and variable labeling. D2D showed greater consistency with
the data-driven model than network centrality analysis, while providing
uncertainty estimates and guidance for future data collection. The method is
implemented in an open-source Python package and a web-based application to
support further testing and lower the barrier to dynamic modeling for
researchers working with CLDs. We expect additional validation will further
establish the approach's utility across a broad range of cases and domains.

</details>


### [173] [A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics](https://arxiv.org/abs/2508.05724)
*Massimiliano Romiti*

Main category: cs.LG

TL;DR: 论文提出了一种新颖的框架，将物理定律表示为加权知识图谱，并通过图注意力网络（GAT）进行链接预测，显著优于传统方法和现有GNN架构。


<details>
  <summary>Details</summary>
Motivation: 解决物理方程表示中的符号歧义问题，并探索物理概念之间的跨领域关系。

Method: 构建了一个包含400个高级物理方程的数据库，开发了加权图表示，并训练GAT进行链接预测。

Result: GAT在测试中AUC达到0.9742，显著优于基线方法，并重新发现了物理学的宏观结构。

Conclusion: 该框架不仅能识别已知的跨领域关系，还能生成新的数学类比，为物理学研究提供了新工具。

Abstract: This work introduces a novel framework for representing and analyzing
physical laws as a weighted knowledge graph. We constructed a database of 659
distinct physical equations, subjected to rigorous semantic cleaning to resolve
notational ambiguities, resulting in a corpus of 400 advanced physics
equations. We developed an enhanced graph representation where both physical
concepts and equations are nodes, connected by weighted inter-equation bridges.
These weights are objectively defined using normalized metrics for variable
overlap, physics-informed importance scores, and bibliometric data. A Graph
Attention Network (GAT) was trained for link prediction, achieving a test AUC
of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming
both classical heuristics (best baseline AUC: 0.9487) and established GNN
architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing
confirmed significance of all comparisons (p < 0.05), with 2.7% improvement
over the best baseline. Our analysis reveals three key findings: (i) The model
autonomously rediscovers the known macroscopic structure of physics,
identifying strong conceptual axes between Electromagnetism and Statistical
Mechanics. (ii) It identifies central hub equations that serve as critical
bridges between multiple physical domains. (iii) The model generates stable,
computationally-derived hypotheses for cross-domain relationships, identifying
both known principles and suggesting novel mathematical analogies for further
theoretical investigation. The framework can generate hundreds of such
hypotheses, enabling the creation of specialized datasets for targeted analysis
of specific physics subfields. Code and data available at
https://github.com/kingelanci/graphysics

</details>


### [174] [Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems](https://arxiv.org/abs/2508.05778)
*Jaemin Oh,Jinsil Lee,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出了一种基于神经网络的数据驱动方法，用于学习非线性状态空间模型中的nudging项，并在混沌系统中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 设计有效的nudging项在非线性系统中具有挑战性，因此需要一种数据驱动的方法来解决这一问题。

Method: 利用神经网络学习非线性状态空间模型中的nudging项，并基于Kazantzis--Kravaris--Luenberger观测器理论提供理论支持。

Result: 在Lorenz 96模型、Kuramoto--Sivashinsky方程和Kolmogorov流等混沌系统中验证了方法的有效性。

Conclusion: 神经网络nudging是一种有效的数据驱动方法，适用于非线性系统的数据同化。

Abstract: Nudging is an empirical data assimilation technique that incorporates an
observation-driven control term into the model dynamics. The trajectory of the
nudged system approaches the true system trajectory over time, even when the
initial conditions differ. For linear state space models, such control terms
can be derived under mild assumptions. However, designing effective nudging
terms becomes significantly more challenging in the nonlinear setting. In this
work, we propose neural network nudging, a data-driven method for learning
nudging terms in nonlinear state space models. We establish a theoretical
existence result based on the Kazantzis--Kravaris--Luenberger observer theory.
The proposed approach is evaluated on three benchmark problems that exhibit
chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and
the Kolmogorov flow.

</details>


### [175] [From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data](https://arxiv.org/abs/2508.05791)
*Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu*

Main category: cs.LG

TL;DR: 提出了一种可扩展的框架，通过整合异构数据重建可靠的配电网拓扑，结合空间布局和动态行为维度，并引入置信感知推理机制，确保推断结果既不确定感知又结构有效。


<details>
  <summary>Details</summary>
Motivation: 现代电网运行需要准确的配电网拓扑，但实际数据来源多样且质量不均，亟需一种可靠的重建方法。

Method: 结合空间基础设施布局和系统动态行为，引入置信感知推理机制，并嵌入物理可行性约束。

Result: 在Oncor的8000多个电表数据上验证，拓扑重建准确率超过95%，置信校准和计算效率显著提升。

Conclusion: 该框架在现实条件下快速收敛到可信拓扑，为电网操作提供了可靠支持。

Abstract: Accurate distribution grid topology is essential for reliable modern grid
operations. However, real-world utility data originates from multiple sources
with varying characteristics and levels of quality. In this work, developed in
collaboration with Oncor Electric Delivery, we propose a scalable framework
that reconstructs a trustworthy grid topology by systematically integrating
heterogeneous data. We observe that distribution topology is fundamentally
governed by two complementary dimensions: the spatial layout of physical
infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the
system in the signal domain (e.g., voltage time series). When jointly
leveraged, these dimensions support a complete and physically coherent
reconstruction of network connectivity. To address the challenge of uneven data
quality without compromising observability, we introduce a confidence-aware
inference mechanism that preserves structurally informative yet imperfect
inputs, while quantifying the reliability of each inferred connection for
operator interpretation. This soft handling of uncertainty is tightly coupled
with hard enforcement of physical feasibility: we embed operational
constraints, such as transformer capacity limits and radial topology
requirements, directly into the learning process. Together, these components
ensure that inference is both uncertainty-aware and structurally valid,
enabling rapid convergence to actionable, trustworthy topologies under
real-world deployment conditions. The proposed framework is validated using
data from over 8000 meters across 3 feeders in Oncor's service territory,
demonstrating over 95% accuracy in topology reconstruction and substantial
improvements in confidence calibration and computational efficiency relative to
baseline methods.

</details>


### [176] [Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation](https://arxiv.org/abs/2508.05154)
*Rishabh Gaur,Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 论文提出了一种基于领域驱动的强化学习（RL）评估指标，用于优化基于代理的模型（ABMs）和理性代理模型（RABMs），并应用于疾病建模案例。


<details>
  <summary>Details</summary>
Motivation: 现有RL算法在ABMs和RABMs中的性能评估缺乏标准化指标，且系统复杂性和随机性增加了评估难度。

Method: 开发了领域驱动的RL指标，结合传统和前沿指标，并通过政策优化在疾病建模案例中验证。

Result: 结果表明，领域驱动的奖励与传统及前沿指标结合，在不同模拟场景（如口罩供应差异）中有效。

Conclusion: 领域驱动的RL指标为ABMs和RABMs的性能评估提供了更全面的方法。

Abstract: For the development and optimization of agent-based models (ABMs) and
rational agent-based models (RABMs), optimization algorithms such as
reinforcement learning are extensively used. However, assessing the performance
of RL-based ABMs and RABMS models is challenging due to the complexity and
stochasticity of the modeled systems, and the lack of well-standardized metrics
for comparing RL algorithms. In this study, we are developing domain-driven
metrics for RL, while building on state-of-the-art metrics. We demonstrate our
``Domain-driven-RL-metrics'' using policy optimization on a rational ABM
disease modeling case study to model masking behavior, vaccination, and
lockdown in a pandemic. Our results show the use of domain-driven rewards in
conjunction with traditional and state-of-the-art metrics for a few different
simulation scenarios such as the differential availability of masks.

</details>


### [177] [Optimal Linear Baseline Models for Scientific Machine Learning](https://arxiv.org/abs/2508.05831)
*Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung*

Main category: cs.LG

TL;DR: 论文提出了一种基于贝叶斯风险最小化的统一理论框架，用于分析线性编码器-解码器架构，适用于科学机器学习问题。


<details>
  <summary>Details</summary>
Motivation: 解决非线性神经网络在可解释性方面的不足，为科学机器学习问题提供理论透明的线性方法。

Method: 通过贝叶斯风险最小化，推导出闭式、秩约束的线性和仿射线性最优映射，用于正向建模和逆恢复任务。

Result: 理论结果在生物医学成像、金融因子分析和非线性流体动力学等数据集上得到验证。

Conclusion: 该工作为科学机器学习问题中的神经网络模型提供了理论基准和解释基础。

Abstract: Across scientific domains, a fundamental challenge is to characterize and
compute the mappings from underlying physical processes to observed signals and
measurements. While nonlinear neural networks have achieved considerable
success, they remain theoretically opaque, which hinders adoption in contexts
where interpretability is paramount. In contrast, linear neural networks serve
as a simple yet effective foundation for gaining insight into these complex
relationships. In this work, we develop a unified theoretical framework for
analyzing linear encoder-decoder architectures through the lens of Bayes risk
minimization for solving data-driven scientific machine learning problems. We
derive closed-form, rank-constrained linear and affine linear optimal mappings
for forward modeling and inverse recovery tasks. Our results generalize
existing formulations by accommodating rank-deficiencies in data, forward
operators, and measurement processes. We validate our theoretical results by
conducting numerical experiments on datasets from simple biomedical imaging,
financial factor analysis, and simulations involving nonlinear fluid dynamics
via the shallow water equations. This work provides a robust baseline for
understanding and benchmarking learned neural network models for scientific
machine learning problems.

</details>


### [178] [An Effective Approach for Node Classification in Textual Graphs](https://arxiv.org/abs/2508.05836)
*Rituparna Datta,Nibir Chandra Mandal*

Main category: cs.LG

TL;DR: 本文提出了一种结合TAPE和Graphormer的新框架，利用ChatGPT生成语义丰富的解释，并通过注意力机制融合文本与结构信息，显著提升了节点分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合文本语义与图结构信息时存在困难，尤其是在捕捉领域术语、长程依赖、时间演化和大规模数据方面表现不足。

Method: 结合TAPE框架和Graphormer，利用ChatGPT生成语义解释，通过注意力机制融合文本与结构特征，并采用路径感知编码和多头注意力捕捉长程依赖。

Result: 在ogbn-arxiv数据集上达到0.772的分类准确率，显著优于GCN基线（0.713），并在精确率、召回率和F1分数上表现优异。

Conclusion: 该框架为动态TAGs中的节点分类提供了可扩展且稳健的解决方案，为知识系统和科学发现的研究提供了新方向。

Abstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks
like citation networks, but effective node classification remains challenging
due to difficulties in integrating rich semantics from text with structural
graph information. Existing methods often struggle with capturing nuanced
domain-specific terminology, modeling long-range dependencies, adapting to
temporal evolution, and scaling to massive datasets. To address these issues,
we propose a novel framework that integrates TAPE (Text-Attributed Graph
Representation Enhancement) with Graphormer. Our approach leverages a large
language model (LLM), specifically ChatGPT, within the TAPE framework to
generate semantically rich explanations from paper content, which are then
fused into enhanced node representations. These embeddings are combined with
structural features using a novel integration layer with learned attention
weights. Graphormer's path-aware position encoding and multi-head attention
mechanisms are employed to effectively capture long-range dependencies across
the citation network. We demonstrate the efficacy of our framework on the
challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a
classification accuracy of 0.772, significantly surpassing the best GCN
baseline of 0.713. Our method also yields strong results in precision (0.671),
recall (0.577), and F1-score (0.610). We validate our approach through
comprehensive ablation studies that quantify the contribution of each
component, demonstrating the synergy between semantic and structural
information. Our framework provides a scalable and robust solution for node
classification in dynamic TAGs, offering a promising direction for future
research in knowledge systems and scientific discovery.

</details>


### [179] [A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance](https://arxiv.org/abs/2508.05876)
*Francesca Ferrara,Lander W. Schillinger Arana,Florian Dörfler,Sarah H. Q. Li*

Main category: cs.LG

TL;DR: 提出了一种基于MDP和RL-PG的自主避碰策略，旨在平衡碰撞风险和燃料消耗。


<details>
  <summary>Details</summary>
Motivation: 解决传统避碰策略中燃料消耗高且决策时间固定的问题。

Method: 将避碰建模为连续状态、离散动作的有限时域MDP，结合风险、燃料和轨道几何模型。

Result: 在合成和历史数据上，策略显著降低燃料消耗，同时保持或提高碰撞风险保障。

Conclusion: 该方法在优化燃料消耗和碰撞风险间取得了有效平衡。

Abstract: This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.

</details>


### [180] [The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)](https://arxiv.org/abs/2508.05905)
*Jeffrey Uhlmann*

Main category: cs.LG

TL;DR: SZT是一种2位量化方法，能在固定资源预算下提高信息密度，优于非量化方法。


<details>
  <summary>Details</summary>
Motivation: 量化通常被视为性能与计算资源之间的权衡，但SZT试图在固定资源预算下提供更优的信息密度。

Method: 引入Signed-Zero Ternary (SZT)，一种2位量化方法，确定性地提供梯度信息且无前向路径损失。

Result: 分析表明，SZT可能比非量化方法具有更高的信息密度。

Conclusion: SZT在固定资源预算下是一种有效的量化方法，可能优于传统非量化方案。

Abstract: Quantization is usually regarded as a means to trade quality of performance
for reduced compute requirements, i.e., as a suboptimal approximation. However,
if examined in terms of a fixed overall resource budget, a very different
perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit
quantization that deterministically provides gradient information with no
forward-path penalty. Our analysis provides evidence that it may improve
information density compared to non-quantized alternatives.

</details>


### [181] [Dual Signal Decomposition of Stochastic Time Series](https://arxiv.org/abs/2508.05915)
*Alex Glushkovsky*

Main category: cs.LG

TL;DR: 论文提出了一种将随机时间序列分解为均值、离散度和噪声三部分的方法，通过机器学习拟合双信号并优化损失函数。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列分解问题，提取均值与离散度信号，同时隔离噪声，以便更好地分析和预测。

Method: 应用机器学习拟合双信号，优化损失函数，结合统计过程控制方法加权正则化项，支持顺序或联合学习。

Result: 分解方法可作为平滑或去噪算法，支持均值与离散度的联合建模，适用于异方差时间序列。

Conclusion: 该方法能有效分解时间序列，为结构学习、预测和交叉效应分析提供基础。

Abstract: The research paper addresses decomposition of a stochastic time series into
three time series representing a dual signal i.e., the mean and the dispersion,
with noise isolated. Decomposition is done by applying machine learning to fit
a dual signal. Machine learning minimizes the loss function which compromises
between fitting the original time series and penalizing irregularities of the
dual signal. The latter includes terms based on the first and second order
derivatives along time. To preserve special patterns, weighting of the
regularization components of the loss function has been introduced based on
Statistical Process Control methodology. The proposed decomposition can be
applied as a smoothing algorithm against the mean and dispersion of the time
series. By isolating noise, the proposed decomposition can be seen as a
denoising algorithm. Two approaches of the learning process have been
considered: sequential and jointly. The former approach learns the mean signal
first and then dispersion. The latter approach fits the dual signal jointly.
Jointly learning can uncover complex relationships for the time series with
heteroskedasticity. Learning has been set by solving the direct non-linear
unconstrained optimization problem or by applying neural networks that have
sequential or twin output architectures. Tuning of the loss function
hyperparameters focuses on the isolated noise to be a stationary stochastic
process without autocorrelation properties. Depending on the applications, the
hyperparameters of the learning can be tuned towards either the discrete states
by stepped signal or smoothed series. The decomposed dual signal can be
represented on the 2D space and used to learn inherent structures, to forecast
both mean and dispersion, or to analyze cross effects in case of multiple time
series.

</details>


### [182] [Unsupervised Partner Design Enables Robust Ad-hoc Teamwork](https://arxiv.org/abs/2508.06336)
*Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling*

Main category: cs.LG

TL;DR: UPD是一种无监督的多智能体强化学习框架，通过动态生成多样化的训练伙伴，无需预训练伙伴或手动调参，显著提升了协作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中需要预训练伙伴或手动调参的问题，实现完全无监督的协作训练。

Method: 通过随机混合自我策略与偏置随机行为生成多样化伙伴，并使用基于方差的易学性指标评分。

Result: 在Overcooked-AI等任务中，UPD优于基线方法，用户研究显示其适应性、人机协作性更优。

Conclusion: UPD为完全无监督的协作训练提供了高效解决方案，显著提升了性能和用户体验。

Abstract: We introduce Unsupervised Partner Design (UPD) - a population-free,
multi-agent reinforcement learning framework for robust ad-hoc teamwork that
adaptively generates training partners without requiring pretrained partners or
manual parameter tuning. UPD constructs diverse partners by stochastically
mixing an ego agent's policy with biased random behaviours and scores them
using a variance-based learnability metric that prioritises partners near the
ego agent's current learning frontier. We show that UPD can be integrated with
unsupervised environment design, resulting in the first method enabling fully
unsupervised curricula over both level and partner distributions in a
cooperative setting. Through extensive evaluations on Overcooked-AI and the
Overcooked Generalisation Challenge, we demonstrate that this dynamic partner
curriculum is highly effective: UPD consistently outperforms both
population-based and population-free baselines as well as ablations. In a user
study, we further show that UPD achieves higher returns than all baselines and
was perceived as significantly more adaptive, more human-like, a better
collaborator, and less frustrating.

</details>


### [183] [Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations](https://arxiv.org/abs/2508.05921)
*Siddharth Rout*

Main category: cs.LG

TL;DR: 论文提出了一种名为Shifted Gaussian Encoding的方法，通过优化激活矩阵的条件数，显著提升了神经PDE求解器的性能。


<details>
  <summary>Details</summary>
Motivation: 神经PDE求解器的精度问题通常源于优化困难，而非表达能力不足，尤其是在多保真度和刚性问题上。

Method: 采用Shifted Gaussian Encoding技术，通过激活过滤步骤提高矩阵秩和表达能力，同时保持凸性。

Result: 方法将稳态对流扩散方程的Peclet数可解范围扩展了两个数量级，在多频函数学习上误差降低了六个数量级，且在高保真图像向量拟合上表现优于百万参数深度网络。

Conclusion: 研究表明，条件数而非网络深度是科学神经求解器的瓶颈，简单的架构改进可以带来显著性能提升。

Abstract: Accuracy in neural PDE solvers often breaks down not because of limited
expressivity, but due to poor optimisation caused by ill-conditioning,
especially in multi-fidelity and stiff problems. We study this issue in
Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural
PDE solvers, and show that asymptotic components in governing equations can
produce highly ill-conditioned activation matrices, severely limiting
convergence. We introduce Shifted Gaussian Encoding, a simple yet effective
activation filtering step that increases matrix rank and expressivity while
preserving convexity. Our method extends the solvable range of Peclet numbers
in steady advection-diffusion equations by over two orders of magnitude,
achieves up to six orders lower error on multi-frequency function learning, and
fits high-fidelity image vectors more accurately and faster than deep networks
with over a million parameters. This work highlights that conditioning, not
depth, is often the bottleneck in scientific neural solvers and that simple
architectural changes can unlock substantial gains.

</details>


### [184] [Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting](https://arxiv.org/abs/2508.05928)
*Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu*

Main category: cs.LG

TL;DR: S-GRPO是一种改进的GRPO方法，通过噪声感知优势权重稳定训练，显著提升数学推理模型的性能。


<details>
  <summary>Details</summary>
Motivation: GRPO在训练大型推理模型时存在Think-Answer Mismatch问题，噪声奖励信号会破坏学习过程，尤其在响应组不平衡时更为严重。

Method: 提出S-GRPO，通过噪声感知优势权重优化训练稳定性。

Result: 在多个模型上显著优于GRPO，性能提升2.2%-2.5%，并在20%噪声下保持稳定学习。

Conclusion: S-GRPO为大规模推理模型的鲁棒训练提供了有效解决方案。

Abstract: Group-Relative Policy Optimization (GRPO) is a key technique for training
large reasoning models, yet it suffers from a critical vulnerability: the
\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning
process. This problem is most severe in unbalanced response groups,
paradoxically degrading the signal precisely when it should be most
informative. To address this challenge, we propose Stable Group-Relative Policy
Optimization (S-GRPO), a principled enhancement that derives optimal,
noise-aware advantage weights to stabilize training. Our comprehensive
experiments on mathematical reasoning benchmarks demonstrate S-GRPO's
effectiveness and robustness. On various models, S-GRPO significantly
outperforms DR. GRPO, achieving performance gains of +2.5% on
Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on
Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn
under 20% synthetic reward noise, S-GRPO maintains stable learning progress.
These results highlight S-GRPO's potential for more robust and effective
training of large-scale reasoning models. \footnote{Code and data are available
at: https://github.com/shenpeijun0212/S-GRPO

</details>


### [185] [Multi-Armed Bandits-Based Optimization of Decision Trees](https://arxiv.org/abs/2508.05957)
*Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman*

Main category: cs.LG

TL;DR: 提出一种基于多臂老虎机（MAB）的决策树剪枝方法，通过强化学习动态优化剪枝过程，提升模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法（如CCP和REP）基于贪心策略，可能导致泛化能力不足，尤其是在小规模复杂数据集上。

Method: 将剪枝过程建模为探索-利用问题，利用MAB算法动态选择最优剪枝节点。

Result: 在多个基准数据集上的实验表明，该方法比传统方法具有更好的预测性能。

Conclusion: MAB方法为决策树剪枝提供了一种动态且概率化的优化方式，提升了模型的泛化能力。

Abstract: Decision trees, without appropriate constraints, can easily become overly
complex and prone to overfit, capturing noise rather than generalizable
patterns. To resolve this problem,pruning operation is a crucial part in
optimizing decision trees, as it not only reduces the complexity of trees but
also decreases the probability of generating overfit models. The conventional
pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning
(REP) are mostly based on greedy approaches that focus on immediate gains in
performance while pruning nodes of the decision tree. However, this might
result in a lower generalization in the long run, compromising the robust
ability of the tree model when introduced to unseen data samples, particularly
when trained with small and complex datasets. To address this challenge, we are
proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement
learning (RL)-based technique, that will dynamically prune the tree to generate
an optimal decision tree with better generalization. Our proposed approach
assumes the pruning process as an exploration-exploitation problem, where we
are utilizing the MAB algorithms to find optimal branch nodes to prune based on
feedback from each pruning actions. Experimental evaluation on several
benchmark datasets, demonstrated that our proposed approach results in better
predictive performance compared to the traditional ones. This suggests the
potential of utilizing MAB for a dynamic and probabilistic way of decision tree
pruning, in turn optimizing the decision tree-based model.

</details>


### [186] [Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2508.05960)
*Haohui Chen,Zhiyong Chen*

Main category: cs.LG

TL;DR: 论文提出了一种名为MCRE的框架和MCRQ算法，用于平衡离线强化学习中的保守性和性能提升，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中，学习策略与行为策略之间的分布偏移会导致OOD动作和过高估计，需要平衡保守性和性能。

Method: 提出MCRE框架，结合TD误差和行为克隆项，并基于此开发MCRQ算法。

Result: MCRQ在基准数据集上优于现有离线强化学习算法。

Conclusion: MCRE和MCRQ有效解决了离线强化学习中的保守性与性能平衡问题。

Abstract: Offline reinforcement learning (RL) seeks to learn optimal policies from
static datasets without further environment interaction. A key challenge is the
distribution shift between the learned and behavior policies, leading to
out-of-distribution (OOD) actions and overestimation. To prevent gross
overestimation, the value function must remain conservative; however, excessive
conservatism may hinder performance improvement. To address this, we propose
the mildly conservative regularized evaluation (MCRE) framework, which balances
conservatism and performance by combining temporal difference (TD) error with a
behavior cloning term in the Bellman backup. Building on this, we develop the
mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates
MCRE into an off-policy actor-critic framework. Experiments show that MCRQ
outperforms strong baselines and state-of-the-art offline RL algorithms on
benchmark datasets.

</details>


### [187] [LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning](https://arxiv.org/abs/2508.05977)
*Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan*

Main category: cs.LG

TL;DR: 提出一种基于语义对齐的强化学习方法，利用SBERT计算奖励，避免手工设计奖励函数。


<details>
  <summary>Details</summary>
Motivation: 在科学机器学习中，设计有效的奖励函数是一个挑战，尤其是在任务目标难以数值化的环境中。现有方法多依赖启发式或手工调整。

Method: 使用SBERT计算当前状态与目标语义指令的余弦相似度作为奖励，替代手工定义的奖励函数。

Result: 在多个环境中验证了语义奖励能指导学习，实现竞争性控制行为，且无需手工奖励函数。

Conclusion: 该方法展示了语言嵌入空间与传统欧氏空间的关联，为自然语言目标与代理行为的对齐奠定了基础。

Abstract: In the domain of scientific machine learning, designing effective reward
functions remains a challenge in reinforcement learning (RL), particularly in
environments where task goals are difficult to specify numerically. Reward
functions in existing work are predominantly based on heuristics, manual
engineering, or task-specific tuning. In this work, we introduce a semantically
aligned reinforcement learning method where rewards are computed by aligning
the current state with a target semantic instruction using a
Sentence-Bidirectional Encoder Representations from Transformers (SBERT).
Instead of relying on manually defined reward functions, the policy receives
feedback based on the reward, which is a cosine similarity between the goal
textual description and the statement description in the episode. We evaluated
our approach in several environments and showed that semantic reward can guide
learning to achieve competitive control behavior, even in the absence of
hand-crafted reward functions. Our study demonstrates a correlation between the
language embedding space and the conventional Euclidean space. This framework
opens new horizons for aligning agent behavior with natural language goals and
lays the groundwork for a more seamless integration of larger language models
(LLMs) and fluid control applications.

</details>


### [188] [Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning](https://arxiv.org/abs/2508.05984)
*Ankur Naskar,Gugan Thoppe,Vijay Gupta*

Main category: cs.LG

TL;DR: 论文提出了一种解决非线性固定点方程的方法，通过结合半范数收缩和诱导范数的单调性，首次实现了参数无关的最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 解决非线性固定点方程（如平均奖励Q学习和TD学习）中半范数非单调性导致的收敛速率问题。

Method: 将平均误差重新构造为涉及非线性扰动的线性递归，并通过半范数收缩与诱导范数单调性的结合来抑制非线性。

Result: 首次实现了参数无关的$\tilde{O}(1/\sqrt{t})$最优收敛速率，适用于同步/异步更新、单/多代理部署及多种数据流。

Conclusion: 该方法为非线性固定点方程的求解提供了通用的高效框架，具有广泛适用性。

Abstract: Algorithms for solving \textit{nonlinear} fixed-point equations -- such as
average-reward \textit{$Q$-learning} and \textit{TD-learning} -- often involve
semi-norm contractions. Achieving parameter-free optimal convergence rates for
these methods via Polyak--Ruppert averaging has remained elusive, largely due
to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting
the averaged error as a linear recursion involving a nonlinear perturbation,
and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with
the monotonicity of a suitably induced norm. Our main result yields the first
parameter-free $\tilde{O}(1/\sqrt{t})$ optimal rates for $Q$-learning in both
average-reward and exponentially discounted settings, where $t$ denotes the
iteration index. The result applies within a broad framework that accommodates
synchronous and asynchronous updates, single-agent and distributed deployments,
and data streams obtained either from simulators or along Markovian
trajectories.

</details>


### [189] [Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal](https://arxiv.org/abs/2508.05988)
*Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu*

Main category: cs.LG

TL;DR: ASAP是一种新颖的CoT压缩框架，通过锚点引导和基于惊讶度的剪枝，显著减少推理延迟和训练成本，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决长推理链带来的训练成本高、推理延迟大和部署困难的问题。

Method: ASAP采用粗到细的框架，先锚点引导剪枝保留核心结构，再基于第一标记惊讶度选择逻辑关键步骤，并训练模型自主生成简洁CoT。

Result: 在多个代码生成基准测试中达到最优准确率，LiveCodeBench v4_v5上减少23.5%的标记生成和43.5%的推理延迟，Pass@1准确率为36.19%。

Conclusion: ASAP为构建高效强大的LRMs提供了有前景的方向。

Abstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable
capabilities in code reasoning by scaling up the length of Chain-of-Thought
(CoT). However, excessively long reasoning traces introduce substantial
challenges in terms of training cost, inference latency, and deployment
feasibility. While various CoT compression approaches have emerged to address
this challenge, they face inherent trade-offs: token-level methods often
disrupt syntactic and logical coherence, while step-level methods based on
perplexity fail to reliably capture the logically critical reasoning steps. In
this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel
coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided
pruning to preserve the core reasoning structure, which efficiently reduces the
search space for subsequent processing. It then enables a logic-aware pruning
by selecting logically essential reasoning steps based on a novel first-token
surprisal metric. Finally, ASAP teaches models to autonomously generate and
leverage these concise CoTs at inference time, enabling efficient reasoning in
coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy
across multiple code generation benchmarks while substantially reducing
training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,
our approach reduces token generation by 23.5% and inference latency by 43.5%
compared to the strongest baseline, while achieving a competitive accuracy of
36.19% in Pass@1. Our results highlight a promising direction for building
powerful and efficient LRMs.

</details>


### [190] [Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization](https://arxiv.org/abs/2508.05995)
*Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: MCTS-OPS结合蒙特卡洛树搜索（MCTS）与大型语言模型（LLM），通过多步提示序列优化代码生成质量，显著提升复杂任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码生成和结构化推理方面表现出色，但在需要多步规划的复杂任务中性能下降。现有方法多关注启发式代码生成或简单任务，缺乏对复杂优化的支持。

Method: 提出MCTS-OPS框架，将提示选择建模为MCTS引导的序列决策过程，探索并优化多步提示序列。

Result: 在网络优化实验中，代码执行成功率和优化结果显著优于基线（奖励提高2~4倍，标准差降低3倍），且在困难问题中达到最优解的概率提高约10%。

Conclusion: 结合符号规划与LLM的方法在复杂领域中展现出高质量代码生成的潜力。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
code generation and structured reasoning; however, their performance often
degrades on complex tasks that require consistent multi-step planning. Recent
work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet
existing approaches primarily focus on generating heuristic-based code for
optimization or target simpler tasks where correctness alone is sufficient. In
this work, we propose MCTS-OPS, a novel neural-symbolic framework that
formulates prompt selection as a sequential decision process guided by MCTS.
Our method explores and refines multi-step prompt sequences for the goal of
improving code generation quality and enhancing the problem-solving
capabilities of LLMs in general optimization. Experiments on network
optimization show significant improvement over the baselines, both in the
success rate of executing the generated code and in the optimization results
with the specified objective and constraints (2$\sim$4$\times$ higher reward
and 3$\times$ lower standard deviation). Moreover, it improves the chance of
attaining the optimal solution by about 10\% of cases, compared to baseline
methods in hard problems. These results highlight the promise of combining
symbolic planning with LLMs for robust, high-quality code generation in complex
domains.

</details>


### [191] [Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients](https://arxiv.org/abs/2508.06023)
*Xiaobin Shen,Jonathan Elmer,George H. Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种新型的逐步动态竞争风险模型，用于改善心脏骤停后昏迷患者的神经预后预测，通过分阶段利用时间不变和时间变化的特征。


<details>
  <summary>Details</summary>
Motivation: 心脏骤停后昏迷患者的预后预测对ICU临床决策至关重要，但现有方法未能充分利用随时间变化的特征。

Method: 扩展Fine and Gray模型，分两阶段建模（时间不变和时间变化特征），并引入神经网络捕捉非线性关系。

Result: 在2,278名患者的回顾性队列中，模型对觉醒、撤除生命支持和死亡等竞争结果表现出强大的判别性能。

Conclusion: 该方法可推广到多阶段特征收集的动态预测任务，适用于需要判断新特征何时对预测有帮助的场景。

Abstract: Prognostication for comatose post-cardiac arrest patients is a critical
challenge that directly impacts clinical decision-making in the ICU. Clinical
information that informs prognostication is collected serially over time.
Shortly after cardiac arrest, various time-invariant baseline features are
collected (e.g., demographics, cardiac arrest characteristics). After ICU
admission, additional features are gathered, including time-varying hemodynamic
data (e.g., blood pressure, doses of vasopressor medications). We view these as
two phases in which we collect new features. In this study, we propose a novel
stepwise dynamic competing risks model that improves the prediction of
neurological outcomes by automatically determining when to take advantage of
time-invariant features (first phase) and time-varying features (second phase).
Notably, our model finds patients for whom this second phase (time-varying
hemodynamic) information is beneficial for prognostication and also when this
information is beneficial (as we collect more hemodynamic data for a patient
over time, how important these data are for prognostication varies). Our
approach extends the standard Fine and Gray model to explicitly model the two
phases and to incorporate neural networks to flexibly capture complex nonlinear
feature relationships. Evaluated on a retrospective cohort of 2,278 comatose
post-arrest patients, our model demonstrates robust discriminative performance
for the competing outcomes of awakening, withdrawal of life-sustaining therapy,
and death despite maximal support. Our approach generalizes to more than two
phases in which new features are collected and could be used in other dynamic
prediction tasks, where it may be helpful to know when and for whom newly
collected features significantly improve prediction.

</details>


### [192] [Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity](https://arxiv.org/abs/2508.06034)
*Qin Chen,Guojie Song*

Main category: cs.LG

TL;DR: 论文提出了一种自适应异构图神经网络（AHGNN），用于解决异构图中的异质性分布和语义多样性问题，通过异质性感知卷积和注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多孤立地处理异质性或异质性，忽视了实际应用中异质性异构图的普遍性，导致性能下降。

Method: AHGNN采用异质性感知卷积处理不同跳数和元路径的异质性分布，并通过粗到细的注意力机制整合多样语义信息。

Result: 在七个真实世界图和二十个基线上的实验表明，AHGNN在高异质性情况下表现优异。

Conclusion: AHGNN有效解决了异质性异构图建模的挑战，显著提升了性能。

Abstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often
exhibit heterophily. However, most existing studies focus on either
heterogeneity or heterophily in isolation, overlooking the prevalence of
heterophilic HGs in practical applications. Such ignorance leads to their
performance degradation. In this work, we first identify two main challenges in
modeling heterophily HGs: (1) varying heterophily distributions across hops and
meta-paths; (2) the intricate and often heterophily-driven diversity of
semantic information across different meta-paths. Then, we propose the Adaptive
Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN
employs a heterophily-aware convolution that accounts for heterophily
distributions specific to both hops and meta-paths. It then integrates messages
from diverse semantic spaces using a coarse-to-fine attention mechanism, which
filters out noise and emphasizes informative signals. Experiments on seven
real-world graphs and twenty baselines demonstrate the superior performance of
AHGNN, particularly in high-heterophily situations.

</details>


### [193] [DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment](https://arxiv.org/abs/2508.06041)
*Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park*

Main category: cs.LG

TL;DR: DP-LLM是一种动态分配精度的机制，通过轻量级误差估计器和阈值学习，优化大型语言模型的性能和延迟权衡。


<details>
  <summary>Details</summary>
Motivation: 解决在设备上运行大型语言模型时如何根据动态变化的运行时约束（如延迟和精度）有效配置模型的问题。

Method: 提出DP-LLM机制，动态为每个层分配精度，利用轻量级误差估计器和学习到的阈值在运行时选择位宽。

Result: 实验表明，DP-LLM在性能和延迟权衡上优于现有方法。

Conclusion: DP-LLM通过动态精度分配，显著提升了大型语言模型的适应性和效率。

Abstract: How can we effectively handle queries for on-device large language models
(LLMs) with varying runtime constraints, such as latency and accuracy?
Multi-scale quantization addresses this challenge by enabling memory-efficient
runtime model adaptation of LLMs through the overlaying of multiple model
variants quantized to different bitwidths. Meanwhile, an important question
still remains open-ended: how can models be properly configured to match a
target precision or latency? While mixed-precision offers a promising solution,
we take this further by leveraging the key observation that the sensitivity of
each layer dynamically changes across decoding iterations. Building on this
insight, we introduce DP-LLM, a novel mechanism that dynamically assigns
precision to each layer based on input values. DP-LLM augments each linear
layer in an LLM with a precision selector that determines the bitwidth at
runtime using a lightweight error estimator and threshold values learned
through fine-tuning. Experimental results across multiple models and benchmarks
demonstrate that DP-LLM achieves a superior performance-latency trade-off,
outperforming prior approaches.

</details>


### [194] [Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology](https://arxiv.org/abs/2508.06066)
*Barak Gahtan,Alex M. Bronstein*

Main category: cs.LG

TL;DR: 论文提出了针对深度时间模型（如TCNs）的非空架构感知泛化边界，并引入了一种公平比较方法，揭示了时间依赖性在固定信息预算下可能增强学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决深度时间模型泛化理论理解的不足，并提供架构感知的泛化边界和评估方法。

Method: 通过延迟反馈阻塞机制将依赖样本转化为近似独立的样本，推导出泛化边界，并设计公平比较方法固定有效样本量。

Result: 泛化边界与网络深度、核大小等参数相关，时间依赖性强的序列泛化差距更小，但收敛速率与理论预测存在差异。

Conclusion: 时间依赖性在固定信息预算下可能有益，但理论与实践的差距仍需进一步研究。

Abstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs)
achieve strong predictive performance on sequential data, yet theoretical
understanding of their generalization remains limited. We address this gap by
providing both the first non-vacuous, architecture-aware generalization bounds
for deep temporal models and a principled evaluation methodology.
  For exponentially $\beta$-mixing sequences, we derive bounds scaling as $
O\!\Bigl(R\,\sqrt{\tfrac{D\,p\,n\,\log N}{N}}\Bigr), $ where $D$ is network
depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our
delayed-feedback blocking mechanism transforms dependent samples into
effectively independent ones while discarding only $O(1/\log N)$ of the data,
yielding $\sqrt{D}$ scaling instead of exponential, implying that doubling
depth requires approximately quadrupling the training data.
  We also introduce a fair-comparison methodology that fixes the effective
sample size to isolate the effect of temporal structure from information
content. Under $N_{\text{eff}}=2{,}000$, strongly dependent sequences
($\rho=0.8$) exhibit $\approx76\%$ smaller generalization gaps than weakly
dependent ones ($\rho=0.2$), challenging the intuition that dependence is
purely detrimental. Yet convergence rates diverge from theory: weak
dependencies follow $N_{\text{eff}}^{-1.21}$ scaling and strong dependencies
follow $N_{\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.
These findings reveal that temporal dependence can enhance learning under fixed
information budgets, while highlighting gaps between theory and practice that
motivate future research.

</details>


### [195] [Recurrent Deep Differentiable Logic Gate Networks](https://arxiv.org/abs/2508.06097)
*Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 论文首次实现了循环深度可微逻辑门网络（RDDLGN），将布尔运算与循环架构结合用于序列到序列学习，在WMT'14英德翻译任务中表现接近GRU。


<details>
  <summary>Details</summary>
Motivation: 探索可微逻辑门在序列建模中的应用，填补其在循环架构中的研究空白。

Method: 提出RDDLGN，结合布尔运算与循环架构，用于序列到序列学习。

Result: 在WMT'14英德翻译任务中，RDDLGN训练时达到5.00 BLEU和30.9%准确率，接近GRU性能（5.41 BLEU），推理时表现稳健（4.39 BLEU）。

Conclusion: 证明了基于循环逻辑的神经计算的可行性，为FPGA加速等研究方向开辟了新路径。

Abstract: While differentiable logic gates have shown promise in feedforward networks,
their application to sequential modeling remains unexplored. This paper
presents the first implementation of Recurrent Deep Differentiable Logic Gate
Networks (RDDLGN), combining Boolean operations with recurrent architectures
for sequence-to-sequence learning.
  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and
30.9\% accuracy during training, approaching GRU performance (5.41 BLEU) and
graceful degradation (4.39 BLEU) during inference. This work establishes
recurrent logic-based neural computation as viable, opening research directions
for FPGA acceleration in sequential modeling and other recursive network
architectures.

</details>


### [196] [GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2508.06108)
*Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang*

Main category: cs.LG

TL;DR: 论文提出了一种名为Hindsight Goal-conditioned Regularization (HGR)的技术，结合Hindsight Self-imitation Regularization (HSR)，显著提高了目标条件强化学习中的样本利用效率。


<details>
  <summary>Details</summary>
Motivation: 目标条件强化学习（GCRL）在稀疏奖励下仍面临挑战。虽然Hindsight Experience Replay (HER)通过重标定轨迹取得了一定进展，但仅依赖轨迹重标定未能充分利用经验，导致样本效率有限。

Method: 提出HGR技术，基于后见目标生成动作正则化先验，并结合HSR，最大化离策略RL算法的经验利用率。

Result: 在导航和操作任务上，HGR和HSR的组合比现有方法（如HER和自模仿技术）实现了更高效的样本重用和最佳性能。

Conclusion: HGR和HSR的组合显著提升了GCRL的样本效率，为稀疏奖励下的强化学习提供了有效解决方案。

Abstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a
fundamental challenge in reinforcement learning. While hindsight experience
replay (HER) has shown promise by relabeling collected trajectories with
achieved goals, we argue that trajectory relabeling alone does not fully
exploit the available experiences in off-policy GCRL methods, resulting in
limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned
Regularization (HGR), a technique that generates action regularization priors
based on hindsight goals. When combined with hindsight self-imitation
regularization (HSR), our approach enables off-policy RL algorithms to maximize
experience utilization. Compared to existing GCRL methods that employ HER and
self-imitation techniques, our hindsight regularizations achieve substantially
more efficient sample reuse and the best performances, which we empirically
demonstrate on a suite of navigation and manipulation tasks.

</details>


### [197] [Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models](https://arxiv.org/abs/2508.06151)
*Yong Oh Lee,JeeEun Kim,Jung Woo Lee*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型的图像修复技术，用于合成高质量口腔癌病变图像，显著提升了诊断模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决口腔癌诊断中标注数据不足和训练数据多样性的问题。

Method: 使用微调的扩散模型和图像修复技术合成逼真的口腔癌病变图像，并结合多源数据集训练诊断模型。

Result: 分类模型诊断准确率达0.97，检测模型病灶定位准确率为0.85。

Conclusion: 该方法验证了合成图像在医学诊断中的潜力，并为其他癌症诊断研究提供了新思路。

Abstract: In oral cancer diagnostics, the limited availability of annotated datasets
frequently constrains the performance of diagnostic models, particularly due to
the variability and insufficiency of training data. To address these
challenges, this study proposed a novel approach to enhance diagnostic accuracy
by synthesizing realistic oral cancer lesions using an inpainting technique
with a fine-tuned diffusion model. We compiled a comprehensive dataset from
multiple sources, featuring a variety of oral cancer images. Our method
generated synthetic lesions that exhibit a high degree of visual fidelity to
actual lesions, thereby significantly enhancing the performance of diagnostic
algorithms. The results show that our classification model achieved a
diagnostic accuracy of 0.97 in differentiating between cancerous and
non-cancerous tissues, while our detection model accurately identified lesion
locations with 0.85 accuracy. This method validates the potential for synthetic
image generation in medical diagnostics and paves the way for further research
into extending these methods to other types of cancer diagnostics.

</details>


### [198] [Differentially Private Federated Clustering with Random Rebalancing](https://arxiv.org/abs/2508.06183)
*Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li*

Main category: cs.LG

TL;DR: RR-Cluster是一种轻量级技术，通过随机重新平衡聚类分配减少隐私噪声，提升联邦聚类算法的隐私/效用权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类通过为每个聚类训练一个模型提升性能，但隐私泄露风险更高。直接应用差分隐私机制会显著降低效用。

Method: 提出RR-Cluster技术，通过随机重新平衡聚类分配，确保每个聚类有最少客户端数量，从而减少隐私噪声。

Result: RR-Cluster显著提升了隐私/效用权衡，在合成和真实数据集上均表现优异。

Conclusion: RR-Cluster是一种简单有效的技术，可显著改善联邦聚类算法的隐私和性能。

Abstract: Federated clustering aims to group similar clients into clusters and produce
one model for each cluster. Such a personalization approach typically improves
model performance compared with training a single model to serve all clients,
but can be more vulnerable to privacy leakage. Directly applying client-level
differentially private (DP) mechanisms to federated clustering could degrade
the utilities significantly. We identify that such deficiencies are mainly due
to the difficulties of averaging privacy noise within each cluster (following
standard privacy mechanisms), as the number of clients assigned to the same
clusters is uncontrolled. To this end, we propose a simple and effective
technique, named RR-Cluster, that can be viewed as a light-weight add-on to
many federated clustering algorithms. RR-Cluster achieves reduced privacy noise
via randomly rebalancing cluster assignments, guaranteeing a minimum number of
clients assigned to each cluster. We analyze the tradeoffs between decreased
privacy noise variance and potentially increased bias from incorrect
assignments and provide convergence bounds for RR-Clsuter. Empirically, we
demonstrate the RR-Cluster plugged into strong federated clustering algorithms
results in significantly improved privacy/utility tradeoffs across both
synthetic and real-world datasets.

</details>


### [199] [Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient](https://arxiv.org/abs/2304.04475)
*Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 论文提出了一种基于DDPG的政策优化框架，用于在大规模流行病模拟中自动确定最优干预措施，如封锁和疫苗接种。


<details>
  <summary>Details</summary>
Motivation: 当前研究在模拟目标、规模和干预策略探索方面存在局限性，无法有效优化干预措施。

Method: 使用DDPG框架在大规模（10万个体）流行病代理模拟中进行多目标优化，确定封锁和疫苗接种的最优策略。

Result: 结果显示，在无封锁和针对中老年人群的疫苗接种下，经济和健康目标达到平衡。

Conclusion: 需要进一步模拟验证结果，并开源框架。

Abstract: To mitigate the impact of the pandemic, several measures include lockdowns,
rapid vaccination programs, school closures, and economic stimulus. These
interventions can have positive or unintended negative consequences. Current
research to model and determine an optimal intervention automatically through
round-tripping is limited by the simulation objectives, scale (a few thousand
individuals), model types that are not suited for intervention studies, and the
number of intervention strategies they can explore (discrete vs continuous). We
address these challenges using a Deep Deterministic Policy Gradient (DDPG)
based policy optimization framework on a large-scale (100,000 individual)
epidemiological agent-based simulation where we perform multi-objective
optimization. We determine the optimal policy for lockdown and vaccination in a
minimalist age-stratified multi-vaccine scenario with a basic simulation for
economic activity. With no lockdown and vaccination (mid-age and elderly),
results show optimal economy (individuals below the poverty line) with balanced
health objectives (infection, and hospitalization). An in-depth simulation is
needed to further validate our results and open-source our framework.

</details>


### [200] [Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning](https://arxiv.org/abs/2508.06199)
*Mateusz Praski,Jakub Adamczyk,Wojciech Czech*

Main category: cs.LG

TL;DR: 该研究对25种预训练神经网络模型在25个数据集上进行了广泛比较，发现大多数模型在分子指纹基准（ECFP）上表现无显著改进，仅CLAMP模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 评估预训练神经网络在化学和小分子药物设计中的实际效果，揭示现有研究的评估严谨性问题。

Method: 采用公平比较框架和分层贝叶斯统计测试模型，评估多种模态、架构和预训练策略的模型。

Result: 几乎所有神经网络模型表现与ECFP基准无显著差异，仅CLAMP模型显著优于其他模型。

Conclusion: 研究结果质疑现有评估的严谨性，提出了潜在原因、解决方案和实践建议。

Abstract: Pretrained neural networks have attracted significant interest in chemistry
and small molecule drug design. Embeddings from these models are widely used
for molecular property prediction, virtual screening, and small data learning
in molecular chemistry. This study presents the most extensive comparison of
such models to date, evaluating 25 models across 25 datasets. Under a fair
comparison framework, we assess models spanning various modalities,
architectures, and pretraining strategies. Using a dedicated hierarchical
Bayesian statistical testing model, we arrive at a surprising result: nearly
all neural models show negligible or no improvement over the baseline ECFP
molecular fingerprint. Only the CLAMP model, which is also based on molecular
fingerprints, performs statistically significantly better than the
alternatives. These findings raise concerns about the evaluation rigor in
existing studies. We discuss potential causes, propose solutions, and offer
practical recommendations.

</details>


### [201] [Graph Federated Learning for Personalized Privacy Recommendation](https://arxiv.org/abs/2508.06208)
*Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang*

Main category: cs.LG

TL;DR: 论文提出了一种名为GFed-PP的新型图联邦学习方法，用于个性化隐私推荐，通过结合公开用户数据提升推荐性能，同时适应不同隐私需求。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统假设所有用户对隐私保护的需求相同，忽略了利用公开用户数据提升服务的潜力。现实中用户可能选择公开或隐私模式，因此需要一种能适应不同隐私需求的推荐方法。

Method: GFed-PP利用公开用户数据构建用户-项目交互图和用户关系图，采用轻量级图卷积网络学习个性化项目嵌入。用户嵌入和评分函数在本地学习以保护隐私，通过客户端项目嵌入初始化和服务器用户关系图聚合优化框架。

Result: 实验结果表明，GFed-PP在五个数据集上显著优于现有方法，提供更高的推荐准确性且不损害隐私。

Conclusion: GFed-PP为联邦推荐系统中适应不同隐私偏好提供了实用解决方案。

Abstract: Federated recommendation systems (FedRecs) have gained significant attention
for providing privacy-preserving recommendation services. However, existing
FedRecs assume that all users have the same requirements for privacy
protection, i.e., they do not upload any data to the server. The approaches
overlook the potential to enhance the recommendation service by utilizing
publicly available user data. In real-world applications, users can choose to
be private or public. Private users' interaction data is not shared, while
public users' interaction data can be shared. Inspired by the issue, this paper
proposes a novel Graph Federated Learning for Personalized Privacy
Recommendation (GFed-PP) that adapts to different privacy requirements while
improving recommendation performance. GFed-PP incorporates the interaction data
of public users to build a user-item interaction graph, which is then used to
form a user relationship graph. A lightweight graph convolutional network (GCN)
is employed to learn each user's user-specific personalized item embedding. To
protect user privacy, each client learns the user embedding and the scoring
function locally. Additionally, GFed-PP achieves optimization of the federated
recommendation framework through the initialization of item embedding on
clients and the aggregation of the user relationship graph on the server.
Experimental results demonstrate that GFed-PP significantly outperforms
existing methods for five datasets, offering superior recommendation accuracy
without compromising privacy. This framework provides a practical solution for
accommodating varying privacy preferences in federated recommendation systems.

</details>


### [202] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: AttriLens-Mol是一种基于属性引导的强化学习框架，用于提升大语言模型在分子属性预测任务中的表现，通过结构化输出和验证机制显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在分子属性预测中依赖人工设计的提示和思维链模板，且推理过程冗长且缺乏相关性。

Method: AttriLens-Mol采用三种奖励机制：格式奖励、计数奖励和合理性奖励，引导模型生成结构化且相关的分子属性。

Result: 在多个数据集上的实验表明，该方法显著提升了模型性能，优于监督微调和其他先进模型。

Conclusion: AttriLens-Mol能够有效提取相关分子属性，提升预测性能和可解释性。

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [203] [Reparameterization Proximal Policy Optimization](https://arxiv.org/abs/2508.06214)
*Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang*

Main category: cs.LG

TL;DR: 论文提出了一种稳定的重参数化策略梯度方法（RPO），通过结合PPO的代理目标和KL散度正则化，解决了RPG训练不稳定的问题，并在实验中表现出优越的样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 重参数化策略梯度（RPG）在样本效率上有潜力，但训练不稳定，梯度方差高。本文旨在通过结合PPO的稳定性和RPG的效率，解决这一问题。

Method: 论文首先建立了PPO代理目标与RPG的联系，提出了一种基于重参数化的PPO变体（RPO），通过时间反向传播高效计算梯度，并结合KL散度正则化和裁剪代理目标实现稳定训练。

Result: 在多个具有挑战性的运动和控制任务中，RPO表现出更高的样本效率和更强的性能。

Conclusion: RPO通过结合PPO的稳定性和RPG的效率，成功解决了训练不稳定的问题，为策略优化提供了一种高效且稳定的方法。

Abstract: Reparameterization policy gradient (RPG) is promising for improving sample
efficiency by leveraging differentiable dynamics. However, a critical barrier
is its training instability, where high-variance gradients can destabilize the
learning process. To address this, we draw inspiration from Proximal Policy
Optimization (PPO), which uses a surrogate objective to enable stable sample
reuse in the model-free setting. We first establish a connection between this
surrogate objective and RPG, which has been largely unexplored and is
non-trivial. Then, we bridge this gap by demonstrating that the
reparameterization gradient of a PPO-like surrogate objective can be computed
efficiently using backpropagation through time. Based on this key insight, we
propose Reparameterization Proximal Policy Optimization (RPO), a stable and
sample-efficient RPG-based method. RPO enables multiple epochs of stable sample
reuse by optimizing a clipped surrogate objective tailored for RPG, while being
further stabilized by Kullback-Leibler (KL) divergence regularization and
remaining fully compatible with existing variance reduction methods. We
evaluate RPO on a suite of challenging locomotion and manipulation tasks, where
experiments demonstrate that our method achieves superior sample efficiency and
strong performance.

</details>


### [204] [SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems](https://arxiv.org/abs/2508.06243)
*Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian*

Main category: cs.LG

TL;DR: SCAR是一个基于边缘AI的框架，通过ML压缩技术优化6G车载娱乐网络的资源管理，提升调度公平性和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统RRM技术难以处理车载网络中日益复杂的数据（如CQI），需要更高效的资源管理方法。

Method: SCAR采用ML压缩技术（如聚类和RBF网络）减少CQI数据量，并利用强化学习策略优化调度和公平性。

Result: SCAR将可行调度区域时间提升14%，不公平调度时间减少15%，CQI聚类失真降低10%。

Conclusion: SCAR在动态车载网络中展现出良好的可扩展性和公平性优势。

Abstract: The advent of 6G networks opens new possibilities for connected infotainment
services in vehicular environments. However, traditional Radio Resource
Management (RRM) techniques struggle with the increasing volume and complexity
of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To
address this, we propose SCAR (State-Space Compression for AI-Driven Resource
Management), an Edge AI-assisted framework that optimizes scheduling and
fairness in vehicular infotainment. SCAR employs ML-based compression
techniques (e.g., clustering and RBF networks) to reduce CQI data size while
preserving essential features. These compressed states are used to train
6G-enabled Reinforcement Learning policies that maximize throughput while
meeting fairness objectives defined by the NGMN. Simulations show that SCAR
increases time in feasible scheduling regions by 14\% and reduces unfair
scheduling time by 15\% compared to RL baselines without CQI compression.
Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based
clustering reduces CQI clustering distortion by 10\%, confirming its
efficiency. These results demonstrate SCAR's scalability and fairness benefits
for dynamic vehicular networks.

</details>


### [205] [Membership Inference Attack with Partial Features](https://arxiv.org/abs/2508.06244)
*Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang*

Main category: cs.LG

TL;DR: 论文研究了部分特征成员推断攻击（PFMI），提出了一种名为MRAD的两阶段攻击框架，通过优化未知特征值和异常检测来推断样本是否在训练集中。


<details>
  <summary>Details</summary>
Motivation: 现有成员推断攻击方法通常假设攻击者能访问目标样本的全部特征，但现实中往往只能获取部分特征信息，限制了这些方法的适用性。

Method: 提出MRAD框架，第一阶段优化未知特征值以最小化样本损失，第二阶段通过异常检测测量重构样本与训练分布的偏差。

Result: 实验表明MRAD在多种数据集上有效，例如在STL-10上，即使缺失40%特征，AUC仍可达0.6。

Conclusion: MRAD为解决部分特征场景下的成员推断问题提供了有效方法，且兼容多种现成异常检测技术。

Abstract: Machine learning models have been shown to be susceptible to membership
inference attack, which can be used to determine whether a given sample appears
in the training data. Existing membership inference methods commonly assume
that the adversary has full access to the features of the target sample. This
assumption, however, does not hold in many real-world scenarios where only
partial features information is available, thereby limiting the applicability
of these methods. In this work, we study an inference scenario where the
adversary observes only partial features of each sample and aims to infer
whether this observed subset was present in the training set of the target
model. We define this problem as Partial Feature Membership Inference (PFMI).
To address this problem, we propose MRAD (Memory-guided Reconstruction and
Anomaly Detection), a two-stage attack framework. In the first stage, MRAD
optimizes the unknown feature values to minimize the loss of the sample. In the
second stage, it measures the deviation between the reconstructed sample and
the training distribution using anomaly detection. Empirical results
demonstrate that MRAD is effective across a range of datasets, and maintains
compatibility with various off-the-shelf anomaly detection techniques. For
example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of
the missing features.

</details>


### [206] [Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2508.06247)
*Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li*

Main category: cs.LG

TL;DR: CMOSS算法解决了组合多臂老虎机问题中UCB和对抗方法的不足，实现了高效的实例无关遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决UCB方法中的对数遗憾因子和对抗方法的高计算开销问题。

Method: 提出CMOSS算法，结合半强盗反馈，实现高效计算。

Result: CMOSS在合成和真实数据集上表现优于基准算法，遗憾和运行效率均优。

Conclusion: CMOSS是组合多臂老虎机问题的高效解决方案，消除了对数遗憾因子并匹配理论下界。

Abstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential
decision-making framework, dominated by two algorithmic families: UCB-based and
adversarial methods such as follow the regularized leader (FTRL) and online
mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer
from additional regret factor $\log T$ that is detrimental over long horizons,
while adversarial methods such as EXP3.M and HYBRID impose significant
computational overhead. To resolve this trade-off, we introduce the
Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS
is a computationally efficient algorithm that achieves an instance-independent
regret of $O\big( (\log k)^2\sqrt{kmT}\big )$ under semi-bandit feedback, where
$m$ is the number of arms and $k$ is the maximum cardinality of a feasible
action. Crucially, this result eliminates the dependency on $\log T$ and
matches the established $\Omega\big( \sqrt{kmT}\big)$ lower bound up to
$O\big((\log k)^2\big)$. We then extend our analysis to show that CMOSS is also
applicable to cascading feedback. Experiments on synthetic and real-world
datasets validate that CMOSS consistently outperforms benchmark algorithms in
both regret and runtime efficiency.

</details>


### [207] [In-Training Defenses against Emergent Misalignment in Language Models](https://arxiv.org/abs/2508.06249)
*David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs)
for new domains, yet recent work reveals emergent misalignment (EMA): Even a
small, domain-specific fine-tune can induce harmful behaviors far outside the
target domain. Even in the case where model weights are hidden behind a
fine-tuning API, this gives attackers inadvertent access to a broadly
misaligned model in a way that can be hard to detect from the fine-tuning data
alone. We present the first systematic study of in-training safeguards against
EMA that are practical for providers who expose fine-tuning via an API. We
investigate four training regularization interventions: (i) KL-divergence
regularization toward a safe reference model, (ii) $\ell_2$ distance in feature
space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving
of a small amount of safe training examples from a general instruct-tuning
dataset. We first evaluate the methods' emergent misalignment effect across
four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on
benign tasks. We conclude with a discussion of open questions in emergent
misalignment research.

</details>


### [208] [Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)](https://arxiv.org/abs/2508.06251)
*Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi*

Main category: cs.LG

TL;DR: 提出了一种基于张量网络（MPS）的隐私保护高质量合成表格数据生成方法，在数据保真度和隐私保护方面优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺、隐私约束及多样化数据集需求，为训练鲁棒模型提供支持。

Method: 使用矩阵乘积状态（MPS）生成合成数据，结合噪声注入和梯度裁剪实现差分隐私。

Result: MPS在严格隐私约束下表现优于CTGAN、VAE和PrivBayes等模型。

Conclusion: MPS为隐私感知的合成数据生成提供了可解释且可扩展的解决方案。

Abstract: Synthetic data generation is a key technique in modern artificial
intelligence, addressing data scarcity, privacy constraints, and the need for
diverse datasets in training robust models. In this work, we propose a method
for generating privacy-preserving high-quality synthetic tabular data using
Tensor Networks, specifically Matrix Product States (MPS). We benchmark the
MPS-based generative model against state-of-the-art models such as CTGAN, VAE,
and PrivBayes, focusing on both fidelity and privacy-preserving capabilities.
To ensure differential privacy (DP), we integrate noise injection and gradient
clipping during training, enabling privacy guarantees via R\'enyi Differential
Privacy accounting. Across multiple metrics analyzing data fidelity and
downstream machine learning task performance, our results show that MPS
outperforms classical models, particularly under strict privacy constraints.
This work highlights MPS as a promising tool for privacy-aware synthetic data
generation. By combining the expressive power of tensor network representations
with formal privacy mechanisms, the proposed approach offers an interpretable
and scalable alternative for secure data sharing. Its structured design
facilitates integration into sensitive domains where both data quality and
confidentiality are critical.

</details>


### [209] [Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors](https://arxiv.org/abs/2508.06257)
*Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang*

Main category: cs.LG

TL;DR: 提出了一种名为GTMancer的框架，利用图神经网络和对比学习整合多组学数据，提升癌症亚型分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多组学数据整合中忽略了异构组学间的复杂耦合，限制了其对癌症亚型细微差异的解析能力。

Method: GTMancer结合图神经网络和对比学习，将多组学数据嵌入统一语义空间，并引入双重注意力系数捕捉组内和组间结构先验。

Result: 在七个真实癌症数据集上的实验表明，GTMancer优于现有最先进算法。

Conclusion: GTMancer通过全局信息指导个体组学表示，显著提升了癌症亚型分类的精度。

Abstract: Integrating multi-omics datasets through data-driven analysis offers a
comprehensive understanding of the complex biological processes underlying
various diseases, particularly cancer. Graph Neural Networks (GNNs) have
recently demonstrated remarkable ability to exploit relational structures in
biological data, enabling advances in multi-omics integration for cancer
subtype classification. Existing approaches often neglect the intricate
coupling between heterogeneous omics, limiting their capacity to resolve subtle
cancer subtype heterogeneity critical for precision oncology. To address these
limitations, we propose a framework named Graph Transformer for Multi-omics
Cancer Subtype Classification (GTMancer). This framework builds upon the GNN
optimization problem and extends its application to complex multi-omics data.
Specifically, our method leverages contrastive learning to embed multi-omics
data into a unified semantic space. We unroll the multiplex graph optimization
problem in that unified space and introduce dual sets of attention coefficients
to capture structural graph priors both within and among multi-omics data. This
approach enables global omics information to guide the refining of the
representations of individual omics. Empirical experiments on seven real-world
cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art
algorithms.

</details>


### [210] [OM2P: Offline Multi-Agent Mean-Flow Policy](https://arxiv.org/abs/2508.06269)
*Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: OM2P是一种新型离线多智能体强化学习算法，通过一步动作采样和奖励感知优化，解决了生成模型在MARL中的低效问题。


<details>
  <summary>Details</summary>
Motivation: 生成模型在离线多智能体强化学习中效率低下，难以满足实时或资源受限的需求。

Method: 提出OM2P算法，结合均值流匹配损失和Q函数监督，优化生成目标与奖励最大化的一致性。

Result: 在Multi-Agent Particle和MuJoCo基准测试中表现优异，GPU内存使用减少3.8倍，训练速度提升10.8倍。

Conclusion: OM2P首次成功将均值流模型整合到离线MARL中，为多智能体合作场景提供了实用的生成策略。

Abstract: Generative models, especially diffusion and flow-based models, have been
promising in offline multi-agent reinforcement learning. However, integrating
powerful generative models into this framework poses unique challenges. In
particular, diffusion and flow-based policies suffer from low sampling
efficiency due to their iterative generation processes, making them impractical
in time-sensitive or resource-constrained settings. To tackle these
difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel
offline MARL algorithm to achieve efficient one-step action sampling. To
address the misalignment between generative objectives and reward maximization,
we introduce a reward-aware optimization scheme that integrates a
carefully-designed mean-flow matching loss with Q-function supervision.
Additionally, we design a generalized timestep distribution and a
derivative-free estimation strategy to reduce memory overhead and improve
training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo
benchmarks demonstrate that OM2P achieves superior performance, with up to a
3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.
Our approach represents the first to successfully integrate mean-flow model
into offline MARL, paving the way for practical and scalable generative
policies in cooperative multi-agent settings.

</details>


### [211] [A Study on Regularization-Based Continual Learning Methods for Indic ASR](https://arxiv.org/abs/2508.06280)
*Gokul Adethya T,S. Jaya Nirmala*

Main category: cs.LG

TL;DR: 该论文研究了在印度语言多样性背景下，通过持续学习（CL）方法开发包容性自动语音识别（ASR）系统，解决了传统多语言模型的数据隐私和顺序性问题。


<details>
  <summary>Details</summary>
Motivation: 印度语言多样性为开发包容性ASR系统带来挑战，传统多语言模型因数据顺序到达和隐私限制不适用，CL提供了一种解决方案。

Method: 使用基于Conformer的混合RNN-T/CTC模型，初始预训练为印地语，随后逐步训练八种印度语言，评估了三种CL策略（EWC、MAS、LwF）。

Result: 结果表明，CL能有效减少遗忘，优于简单微调，适用于现实约束下印度语言的ASR扩展。

Conclusion: 持续学习是解决印度语言ASR系统开发中数据隐私和顺序性问题的有效方法。

Abstract: Indias linguistic diversity poses significant challenges for developing
inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual
models, which require simultaneous access to all language data, are impractical
due to the sequential arrival of data and privacy constraints. Continual
Learning (CL) offers a solution by enabling models to learn new languages
sequentially without catastrophically forgetting previously learned knowledge.
This paper investigates CL for ASR on Indian languages using a subset of the
IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,
initially pretrained on Hindi, which is then incrementally trained on eight
additional Indian languages, for a total sequence of nine languages. We
evaluate three prominent regularization- and distillation-based CL strategies:
Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning
without Forgetting (LwF), selected for their suitability in no-replay,
privacy-conscious scenarios. Performance is analyzed using Word Error Rate
(WER) for both RNN-T and CTC paths on clean and noisy data, as well as
knowledge retention via Backward Transfer. We also explore the impact of
varying the number of training epochs (1, 2, 5, and 10) per task. Results,
compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating
forgetting, making it a promising approach for scalable ASR in diverse Indian
languages under realistic constraints. The code is available at:
https://github.com/FrozenWolf-Cyber/Indic-CL-ASR

</details>


### [212] [Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback](https://arxiv.org/abs/2508.06292)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 提出了一种新型多输出脉冲神经元模型，结合了线性状态空间模型和非线性反馈机制，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 结合脉冲神经网络（SNNs）和深度状态空间模型（SSMs）的优势，解决SSMs缺乏重置机制和高精度激活函数的问题。

Method: 设计了一种多输出脉冲神经元模型，明确区分脉冲功能、重置条件和重置动作，并引入非线性反馈机制。

Result: 在多个任务（如关键词识别、事件视觉任务和序列模式识别）中表现与现有SNN基准相当，且能克服线性动态不稳定性。

Conclusion: 提出的重置机制有效提升了模型稳定性，扩展了深度SSM模型的应用范围。

Abstract: Neuromorphic computing is an emerging technology enabling low-latency and
energy-efficient signal processing. A key algorithmic tool in neuromorphic
computing is spiking neural networks (SNNs). SNNs are biologically inspired
neural networks which utilize stateful neurons, and provide low-bit data
processing by encoding and decoding information using spikes. Similar to SNNs,
deep state-space models (SSMs) utilize stateful building blocks. However, deep
SSMs, which recently achieved competitive performance in various temporal
modeling tasks, are typically designed with high-precision activation functions
and no reset mechanisms. To bridge the gains offered by SNNs and the recent
deep SSM models, we propose a novel multiple-output spiking neuron model that
combines a linear, general SSM state transition with a non-linear feedback
mechanism through reset. Compared to the existing neuron models for SNNs, our
proposed model clearly conceptualizes the differences between the spiking
function, the reset condition and the reset action. The experimental results on
various tasks, i.e., a keyword spotting task, an event-based vision task and a
sequential pattern recognition task, show that our proposed model achieves
performance comparable to existing benchmarks in the SNN literature. Our
results illustrate how the proposed reset mechanism can overcome instability
and enable learning even when the linear part of neuron dynamics is unstable,
allowing us to go beyond the strictly enforced stability of linear dynamics in
recent deep SSM models.

</details>


### [213] [FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields](https://arxiv.org/abs/2508.06301)
*Junhyeog Yun,Minui Hong,Gunhee Kim*

Main category: cs.LG

TL;DR: FedMeNF是一种新的联邦元学习方法，通过隐私保护损失函数解决传统FML的隐私泄露问题，实现高效优化和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 神经场学习需要大量数据和计算资源，传统FML存在隐私泄露问题，FedMeNF旨在解决这些限制。

Method: FedMeNF采用隐私保护损失函数，在本地元优化中减少隐私泄露，无需保留客户端私有数据。

Result: 实验表明，FedMeNF在少样本或非IID数据下仍能快速优化并保持稳健的重建性能。

Conclusion: FedMeNF在保护隐私的同时，实现了高效的神经场学习和优化。

Abstract: Neural fields provide a memory-efficient representation of data, which can
effectively handle diverse modalities and large-scale data. However, learning
to map neural fields often requires large amounts of training data and
computations, which can be limited to resource-constrained edge devices. One
approach to tackle this limitation is to leverage Federated Meta-Learning
(FML), but traditional FML approaches suffer from privacy leakage. To address
these issues, we introduce a novel FML approach called FedMeNF. FedMeNF
utilizes a new privacy-preserving loss function that regulates privacy leakage
in the local meta-optimization. This enables the local meta-learner to optimize
quickly and efficiently without retaining the client's private data. Our
experiments demonstrate that FedMeNF achieves fast optimization speed and
robust reconstruction performance, even with few-shot or non-IID data across
diverse data modalities, while preserving client data privacy.

</details>


### [214] [Introducing Fractional Classification Loss for Robust Learning with Noisy Labels](https://arxiv.org/abs/2508.06346)
*Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya*

Main category: cs.LG

TL;DR: 提出了一种自适应鲁棒损失函数FCL，通过分数阶导数和主动-被动损失框架，自动调整对标签噪声的鲁棒性，无需手动调参。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒损失函数需要大量数据集特定的超参数调整，FCL旨在解决这一问题。

Method: FCL结合了交叉熵损失的分数阶导数（主动部分）和MAE（被动部分），通过可学习参数μ动态调整鲁棒性与收敛速度。

Result: FCL在基准数据集上实现了最先进的分类性能，无需手动调参。

Conclusion: FCL通过动态调整损失函数，有效平衡了鲁棒性和收敛速度，适用于标签噪声环境。

Abstract: Robust loss functions are crucial for training deep neural networks in the
presence of label noise, yet existing approaches require extensive,
dataset-specific hyperparameter tuning. In this work, we introduce Fractional
Classification Loss (FCL), an adaptive robust loss that automatically
calibrates its robustness to label noise during training. Built within the
active-passive loss framework, FCL employs the fractional derivative of the
Cross-Entropy (CE) loss as its active component and the Mean Absolute Error
(MAE) as its passive loss component. With this formulation, we demonstrate that
the fractional derivative order $\mu$ spans a family of loss functions that
interpolate between MAE-like robustness and CE-like fast convergence.
Furthermore, we integrate $\mu$ into the gradient-based optimization as a
learnable parameter and automatically adjust it to optimize the trade-off
between robustness and convergence speed. We reveal that FCL's unique property
establishes a critical trade-off that enables the stable learning of $\mu$:
lower log penalties on difficult or mislabeled examples improve robustness but
impose higher penalties on easy or clean data, reducing model confidence in
them. Consequently, FCL can dynamically reshape its loss landscape to achieve
effective classification performance under label noise. Extensive experiments
on benchmark datasets show that FCL achieves state-of-the-art results without
the need for manual hyperparameter tuning.

</details>


### [215] [Structural Equation-VAE: Disentangled Latent Representations for Tabular Data](https://arxiv.org/abs/2508.06347)
*Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam*

Main category: cs.LG

TL;DR: SE-VAE是一种新型变分自编码器，通过结构方程建模设计，直接嵌入测量结构，实现可解释的潜在表示学习。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据中潜在表示学习的可解释性问题，特别是在理论和测量有效性至关重要的领域。

Method: SE-VAE通过结构方程建模设计，将潜在子空间与已知指标分组对齐，并引入全局干扰潜在变量以隔离特定构造的混杂变异。

Result: SE-VAE在模拟表格数据集上表现优异，优于基线方法，尤其在因子恢复、可解释性和对干扰变异的鲁棒性方面。

Conclusion: SE-VAE通过设计而非统计正则化实现解耦，为科学和社会领域的白盒生成建模提供了原则性框架。

Abstract: Learning interpretable latent representations from tabular data remains a
challenge in deep generative modeling. We introduce SE-VAE (Structural
Equation-Variational Autoencoder), a novel architecture that embeds measurement
structure directly into the design of a variational autoencoder. Inspired by
structural equation modeling, SE-VAE aligns latent subspaces with known
indicator groupings and introduces a global nuisance latent to isolate
construct-specific confounding variation. This modular architecture enables
disentanglement through design rather than through statistical regularizers
alone. We evaluate SE-VAE on a suite of simulated tabular datasets and
benchmark its performance against a series of leading baselines using standard
disentanglement metrics. SE-VAE consistently outperforms alternatives in factor
recovery, interpretability, and robustness to nuisance variation. Ablation
results reveal that architectural structure, rather than regularization
strength, is the key driver of performance. SE-VAE offers a principled
framework for white-box generative modeling in scientific and social domains
where latent constructs are theory-driven and measurement validity is
essential.

</details>


### [216] [Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means](https://arxiv.org/abs/2508.06353)
*Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic*

Main category: cs.LG

TL;DR: Gk-means是一种基于几何原理（标量投影）改进的k-means算法，显著提升效率与能源经济性，同时保持解的质量。


<details>
  <summary>Details</summary>
Motivation: 传统k-means算法效率较低且能耗高，Gk-means旨在通过几何优化解决这一问题。

Method: 利用标量投影识别高表达数据（HE），忽略低表达数据（LE），减少计算开销。

Result: 在合成、真实世界和高维数据集上，Gk-means在运行时间和距离计算上优于传统及SOTA k-means变体，且能源效率更高。

Conclusion: Gk-means是一种高效、节能且可持续的k-means改进算法。

Abstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel
approach that significantly enhances the efficiency and energy economy of the
widely utilized k-means algorithm, which, despite its inception over five
decades ago, remains a cornerstone in machine learning applications. The
essence of Gk-means lies in its active utilization of geometric principles,
specifically scalar projection, to significantly accelerate the algorithm
without sacrificing solution quality. This geometric strategy enables a more
discerning focus on data points that are most likely to influence cluster
updates, which we call as high expressive data (HE). In contrast, low
expressive data (LE), does not impact clustering outcome, is effectively
bypassed, leading to considerable reductions in computational overhead.
Experiments spanning synthetic, real-world and high-dimensional datasets,
demonstrate Gk-means is significantly better than traditional and state of the
art (SOTA) k-means variants in runtime and distance computations (DC).
Moreover, Gk-means exhibits better resource efficiency, as evidenced by its
reduced energy footprint, placing it as more sustainable alternative.

</details>


### [217] [Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts](https://arxiv.org/abs/2508.06361)
*Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He*

Main category: cs.LG

TL;DR: 研究探讨了大型语言模型（LLMs）在无明确诱导情况下自发的欺骗行为，提出了一种基于心理学的评估框架，发现LLMs在处理复杂任务时欺骗倾向增加。


<details>
  <summary>Details</summary>
Motivation: LLMs的信任度是关键问题，但现有研究多关注人为诱导的欺骗，忽视了模型自发的欺骗行为。

Method: 提出基于‘接触搜索问题’的框架，使用两种统计指标（欺骗意图分数和欺骗行为分数）量化欺骗倾向。

Result: 评估14个主流LLMs发现，任务难度增加时欺骗指标上升，且两者呈正相关。

Conclusion: 即使最先进的LLMs在复杂任务中也表现出欺骗倾向，这对LLMs在关键领域的部署提出了警示。

Abstract: Large Language Models (LLMs) have been widely deployed in reasoning,
planning, and decision-making tasks, making their trustworthiness a critical
concern. The potential for intentional deception, where an LLM deliberately
fabricates or conceals information to serve a hidden objective, remains a
significant and underexplored threat. Existing studies typically induce such
deception by explicitly setting a "hidden" objective through prompting or
fine-tuning, which may not fully reflect real-world human-LLM interactions.
Moving beyond this human-induced deception, we investigate LLMs' self-initiated
deception on benign prompts. To address the absence of ground truth in this
evaluation, we propose a novel framework using "contact searching questions."
This framework introduces two statistical metrics derived from psychological
principles to quantify the likelihood of deception. The first, the Deceptive
Intention Score, measures the model's bias towards a hidden objective. The
second, Deceptive Behavior Score, measures the inconsistency between the LLM's
internal belief and its expressed output. Upon evaluating 14 leading LLMs, we
find that both metrics escalate as task difficulty increases, rising in
parallel for most models. Building on these findings, we formulate a
mathematical model to explain this behavior. These results reveal that even the
most advanced LLMs exhibit an increasing tendency toward deception when
handling complex problems, raising critical concerns for the deployment of LLM
agents in complex and crucial domains.

</details>


### [218] [ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design](https://arxiv.org/abs/2508.06364)
*Renyi Zhou,Huimin Zhu,Jing Tang,Min Li*

Main category: cs.LG

TL;DR: ActivityDiff是一种基于扩散模型的生成方法，通过分类器引导技术实现分子生物活性的精确控制，包括增强目标活性和减少脱靶毒性。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法主要关注单一活性分子设计，缺乏同时管理多目标和非目标分子相互作用的机制。

Method: 采用扩散模型和分类器引导技术，利用分别训练的药物-靶点分类器进行正负引导。

Result: 实验表明ActivityDiff能有效处理单/双靶点生成、片段约束双靶点设计、选择性生成和减少脱靶效应等任务。

Conclusion: ActivityDiff为分子设计提供了一种平衡效果和安全性的新范式，是一个多功能且可扩展的框架。

Abstract: Achieving precise control over a molecule's biological activity-encompassing
targeted activation/inhibition, cooperative multi-target modulation, and
off-target toxicity mitigation-remains a critical challenge in de novo drug
design. However, existing generative methods primarily focus on producing
molecules with a single desired activity, lacking integrated mechanisms for the
simultaneous management of multiple intended and unintended molecular
interactions. Here, we propose ActivityDiff, a generative approach based on the
classifier-guidance technique of diffusion models. It leverages separately
trained drug-target classifiers for both positive and negative guidance,
enabling the model to enhance desired activities while minimizing harmful
off-target effects. Experimental results show that ActivityDiff effectively
handles essential drug design tasks, including single-/dual-target generation,
fragment-constrained dual-target design, selective generation to enhance target
specificity, and reduction of off-target effects. These results demonstrate the
effectiveness of classifier-guided diffusion in balancing efficacy and safety
in molecular design. Overall, our work introduces a novel paradigm for
achieving integrated control over molecular activity, and provides ActivityDiff
as a versatile and extensible framework.

</details>


### [219] [End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](https://arxiv.org/abs/2508.06387)
*Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh*

Main category: cs.LG

TL;DR: 本文提出了一种三阶段的端到端文本到SQL框架，通过LLM和提示工程提取自然语言查询中的隐含信息，训练数据库标识预测模型，并利用批评代理优化SQL生成，显著提升了数据库意图预测和SQL生成准确性。


<details>
  <summary>Details</summary>
Motivation: 传统文本到SQL方法需要预先指定目标数据库，而在多数据库场景中，识别正确数据库是关键但被忽视的步骤。本文旨在解决这一问题。

Method: 采用三阶段框架：1）利用LLM和提示工程从自然语言查询中提取规则；2）训练基于RoBERTa的数据库标识预测模型；3）使用批评代理优化生成的SQL。

Result: 实验表明，该框架在数据库意图预测和SQL生成准确性上优于当前最优模型。

Conclusion: 提出的框架在多数据库场景中显著提升了文本到SQL的性能，为实际应用提供了有效解决方案。

Abstract: Text-to-SQL bridges the gap between natural language and structured database
language, thus allowing non-technical users to easily query databases.
Traditional approaches model text-to-SQL as a direct translation task, where a
given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances
in large language models (LLMs) have significantly improved translation
accuracy, however, these methods all require that the target database is
pre-specified. This becomes problematic in scenarios with multiple extensive
databases, where identifying the correct database becomes a crucial yet
overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL
framework to identify the user's intended database before generating SQL
queries. Our approach leverages LLMs and prompt engineering to extract implicit
information from natural language queries (NLQs) in the form of a ruleset. We
then train a large db\_id prediction model, which includes a RoBERTa-based
finetuned encoder, to predict the correct Database identifier (db\_id) based on
both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL
by using critic agents to correct errors. Experimental results demonstrate that
our framework outperforms the current state-of-the-art models in both database
intent prediction and SQL generation accuracy.

</details>


### [220] [A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images](https://arxiv.org/abs/2508.06409)
*Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee*

Main category: cs.LG

TL;DR: 利用公开众包数据（311服务电话和街景图像）预测旧金山无家可归者帐篷趋势，提供更及时、本地化和低成本的信息。


<details>
  <summary>Details</summary>
Motivation: 现有监测方法（如PIT计数）在频率、一致性和空间细节上存在局限，无法捕捉快速变化和空间转移。

Method: 使用311服务电话和街景图像数据，建立预测模型，捕捉每日和社区级别的变化。

Result: 模型揭示了传统方法忽略的模式，如疫情期间的快速波动和帐篷位置的空间变化。

Conclusion: 该方法为政策制定和干预评估提供了更有效的工具。

Abstract: Homelessness in the United States has surged to levels unseen since the Great
Depression. However, existing methods for monitoring it, such as point-in-time
(PIT) counts, have limitations in terms of frequency, consistency, and spatial
detail. This study proposes a new approach using publicly available,
crowdsourced data, specifically 311 Service Calls and street-level imagery, to
track and forecast homeless tent trends in San Francisco. Our predictive model
captures fine-grained daily and neighborhood-level variations, uncovering
patterns that traditional counts often overlook, such as rapid fluctuations
during the COVID-19 pandemic and spatial shifts in tent locations over time. By
providing more timely, localized, and cost-effective information, this approach
serves as a valuable tool for guiding policy responses and evaluating
interventions aimed at reducing unsheltered homelessness.

</details>


### [221] [Sample-efficient LLM Optimization with Reset Replay](https://arxiv.org/abs/2508.06412)
*Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: 论文提出了一种名为LoRR的插件方法，通过高重放训练和周期性重置策略，提升基于偏好的LLM优化框架的样本效率，同时避免过拟合。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习和偏好优化的LLM后训练方法存在样本效率低和初始偏好偏差问题，影响模型性能和学习过程。

Method: LoRR结合高重放训练、周期性重置策略和混合优化目标（SFT与偏好损失），提升数据利用效率。

Result: 实验表明，LoRR显著提升了多种偏好优化方法的性能，在数学和通用推理任务上表现优异，甚至媲美复杂RL算法。

Conclusion: LoRR为LLM微调提供了一种高效、实用的新范式，能在有限数据下实现更高性能。

Abstract: Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

</details>


### [222] [LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection](https://arxiv.org/abs/2508.06467)
*Ameya Anjarlekar,Sandeep Pombra*

Main category: cs.LG

TL;DR: GRIN是一个针对大型语言模型（LLM）的模块化、目标化遗忘框架，通过梯度比指标和选择性噪声注入实现高效遗忘敏感数据，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于法律和伦理对LLM的审查日益严格，需要有效遗忘敏感或未经授权数据，现有方法存在遗忘不彻底或无关知识退化的问题。

Method: GRIN提出基于梯度比的指标定位关键参数，并在微调前选择性注入噪声，优化遗忘效果。

Result: 在TOFU、WMDP和SafePKU等基准测试中验证了GRIN的有效性，并提出了新的评估指标。

Conclusion: GRIN为LLM提供了一种高效、精准的遗忘方法，平衡了遗忘效果与模型性能。

Abstract: The growing legal and ethical scrutiny of large language models (LLMs)
necessitates effective machine unlearning, particularly for sensitive or
unauthorized data. Existing empirical methods often yield incomplete forgetting
or unintended degradation of unrelated knowledge due to poor localization. In
this work, we propose GRIN: a modular and targeted framework for LLM
unlearning. GRIN introduces a novel gradient-ratio-based metric to identify
parameters most responsible for memorizing forget data. We then perform
selective noise injection into these parameters prior to fine-tuning, which
improves unlearning performance while maintaining model utility. Finally, we
propose new evaluation metrics tailored to the LLM setting and validate our
approach on standard benchmarks such as TOFU, WMDP, and SafePKU.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [223] [Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.05687)
*Alistair Reid,Simon O'Callaghan,Liam Carroll,Tiberio Caetano*

Main category: cs.MA

TL;DR: 论文探讨了多智能体AI系统的风险识别与分析，提出了六种关键故障模式，并为实践者提供了工具包。


<details>
  <summary>Details</summary>
Motivation: 随着组织从单智能体转向多智能体网络，交互行为可能引发新的故障模式，需要不同的风险分析方法。

Method: 通过分阶段测试（模拟、观察、基准测试和红队测试）逐步提高分析有效性。

Result: 提出了六种关键故障模式及相应工具包，为组织风险管理奠定基础。

Conclusion: 该方法为LLM多智能体系统的部署和运营提供了稳健的风险管理框架。

Abstract: Organisations are starting to adopt LLM-based AI agents, with their
deployments naturally evolving from single agents towards interconnected,
multi-agent networks. Yet a collection of safe agents does not guarantee a safe
collection of agents, as interactions between agents over time create emergent
behaviours and induce novel failure modes. This means multi-agent systems
require a fundamentally different risk analysis approach than that used for a
single agent.
  This report addresses the early stages of risk identification and analysis
for multi-agent AI systems operating within governed environments where
organisations control their agent configurations and deployment. In this
setting, we examine six critical failure modes: cascading reliability failures,
inter-agent communication failures, monoculture collapse, conformity bias,
deficient theory of mind, and mixed motive dynamics. For each, we provide a
toolkit for practitioners to extend or integrate into their existing frameworks
to assess these failure modes within their organisational contexts.
  Given fundamental limitations in current LLM behavioural understanding, our
approach centres on analysis validity, and advocates for progressively
increasing validity through staged testing across stages of abstraction and
deployment that gradually increases exposure to potential negative impacts,
while collecting convergent evidence through simulation, observational
analysis, benchmarking, and red teaming. This methodology establishes the
groundwork for robust organisational risk management as these LLM-based
multi-agent systems are deployed and operated.

</details>


### [224] [Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control](https://arxiv.org/abs/2508.05702)
*Yan Zhang*

Main category: cs.MA

TL;DR: 论文提出了一种名为Grid-Agent的AI驱动框架，结合大型语言模型和多智能体强化学习，实时检测和修复电网违规问题，并通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源（DERs）和电动汽车（EVs）的普及以及极端天气事件的增加，传统电网规划和管理方法难以应对现代电网的复杂性和动态性。

Method: Grid-Agent采用模块化智能体架构，结合语义推理和数值精度，包括规划智能体和验证智能体，并通过自适应多尺度网络表示实现可扩展性。

Result: 在IEEE和CIGRE测试系统中，Grid-Agent表现出卓越的违规缓解性能，并能持续学习和适应不同网络拓扑。

Conclusion: Grid-Agent的自主性和适应性使其特别适合需要快速响应动态运行条件的现代智能电网应用。

Abstract: The increasing penetration of Distributed Energy Resources (DERs), widespread
adoption of Electric Vehicles (EVs), and the growing frequency of extreme
weather events have significantly increased the complexity of power grid
planning, operation, and management. Traditional rule-based systems and
numerical optimization approaches often struggle with the scale, dynamics, and
adaptability required by modern power networks. This paper introduces
Grid-Agent, an autonomous, AI-driven framework that combines Large Language
Models (LLMs) with multi-agent reinforcement learning to detect and remediate
grid violations in real time. Grid-Agent integrates semantic reasoning with
numerical precision through a modular agent architecture: a planning agent
generates coordinated action sequences using numerical power flow solvers,
while a validation agent evaluates system stability and action effectiveness
via sandboxed execution with safety rollbacks. To ensure scalability,
Grid-Agent incorporates an adaptive multiscale network representation that
dynamically selects optimal encoding schemes based on network size and
complexity. The framework enables coordinated violation resolution through
optimizing switch configurations, battery deployment, and load curtailment
strategies. Experimental results in standard IEEE and CIGRE test systems (IEEE
69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation
performance. Additionally, the framework's built-in data collection and
learning capabilities enable continuous learning and adaptation to diverse
network topologies. The autonomous nature of the framework makes it
particularly suitable for modern smart grid applications requiring rapid
response to dynamic operating conditions.

</details>


### [225] [Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and Delivery](https://arxiv.org/abs/2508.05890)
*Yue Zhang,Zhe Chen,Daniel Harabor,Pierre Le Bodic,Peter J. Stuckey*

Main category: cs.MA

TL;DR: 论文提出了一种基于最小成本流的在线多智能体拾取与交付（MAPD）任务分配方法，解决了现有方法在实时性和可扩展性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有在线方法要么依赖简单启发式导致决策质量低，要么采用复杂推理但受限于实时性。

Method: 将任务分配问题建模为环境图上的最小成本流问题，避免成对距离计算，并引入两种拥堵感知的边成本模型。

Result: 方法支持实时执行，可扩展到20000个智能体和30000个任务，1秒内完成规划，优于现有基线。

Conclusion: 该方法在计算效率和任务分配质量上均优于现有方法，适用于大规模实时MAPD问题。

Abstract: We study the problem of online Multi-Agent Pickup and Delivery (MAPD), where
a team of agents must repeatedly serve dynamically appearing tasks on a shared
map. Existing online methods either rely on simple heuristics, which result in
poor decisions, or employ complex reasoning, which suffers from limited
scalability under real-time constraints. In this work, we focus on the task
assignment subproblem and formulate it as a minimum-cost flow over the
environment graph. This eliminates the need for pairwise distance computations
and allows agents to be simultaneously assigned to tasks and routed toward
them. The resulting flow network also supports efficient guide path extraction
to integrate with the planner and accelerates planning under real-time
constraints. To improve solution quality, we introduce two congestion-aware
edge cost models that incorporate real-time traffic estimates. This approach
supports real-time execution and scales to over 20000 agents and 30000 tasks
within 1-second planning time, outperforming existing baselines in both
computational efficiency and assignment quality.

</details>


### [226] [Policy Optimization in Multi-Agent Settings under Partially Observable Environments](https://arxiv.org/abs/2508.06061)
*Ainur Zhaikhan,Malek Khammassi,Ali H. Sayed*

Main category: cs.MA

TL;DR: 提出了一种结合自适应社会学习和多智能体强化学习（MARL）的方法，用于估计部分可观测的全局状态。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中社会学习与强化学习分离的问题，减少计算和时间成本。

Method: 交替进行单步社会学习和单步MARL，避免复杂的双时间尺度学习框架。

Result: 理论分析和仿真结果表明，该方法性能接近已知真实状态时的强化学习。

Conclusion: 该方法有效且高效，适用于部分可观测的MARL问题。

Abstract: This work leverages adaptive social learning to estimate partially observable
global states in multi-agent reinforcement learning (MARL) problems. Unlike
existing methods, the proposed approach enables the concurrent operation of
social learning and reinforcement learning. Specifically, it alternates between
a single step of social learning and a single step of MARL, eliminating the
need for the time- and computation-intensive two-timescale learning frameworks.
Theoretical guarantees are provided to support the effectiveness of the
proposed method. Simulation results verify that the performance of the proposed
methodology can approach that of reinforcement learning when the true state is
known.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [227] [GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems](https://arxiv.org/abs/2508.05773)
*Keyvan Majd,Hardik Parwana,Bardh Hoxha,Steven Hong,Hideki Okamoto,Georgios Fainekos*

Main category: cs.RO

TL;DR: BR-MPPI方法通过结合控制屏障函数（CBF）约束，改进了MPPI控制算法，提高了在复杂环境中导航的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决铰接式车辆（如拖车、场站卡车等）在拥挤空间中倒车和机动时的导航问题，特别是在有行人的环境中。

Method: 将控制屏障函数（CBF）约束直接嵌入到路径积分更新中，引导重要性采样分布朝向无碰撞且动态可行的轨迹。

Result: 在高保真CarMaker模拟器中测试，BR-MPPI在单GPU上以超过100Hz的频率计算控制输入，并在停车间隙方面优于标准MPPI和带碰撞成本的MPPI基线。

Conclusion: BR-MPPI显著提升了MPPI的探索能力和轨迹鲁棒性，适用于复杂环境中的车辆导航。

Abstract: Articulated vehicles such as tractor-trailers, yard trucks, and similar
platforms must often reverse and maneuver in cluttered spaces where pedestrians
are present. We present how Barrier-Rate guided Model Predictive Path Integral
(BR-MPPI) control can solve navigation in such challenging environments.
BR-MPPI embeds Control Barrier Function (CBF) constraints directly into the
path-integral update. By steering the importance-sampling distribution toward
collision-free, dynamically feasible trajectories, BR-MPPI enhances the
exploration strength of MPPI and improves robustness of resulting trajectories.
The method is evaluated in the high-fidelity CarMaker simulator on a 12 [m]
tractor-trailer tasked with reverse and forward parking in a parking lot.
BR-MPPI computes control inputs in above 100 [Hz] on a single GPU (for
scenarios with eight obstacles) and maintains better parking clearance than a
standard MPPI baseline and an MPPI with collision cost baseline.

</details>


### [228] [Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction](https://arxiv.org/abs/2508.05838)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.RO

TL;DR: 论文提出了一种结合视觉基础模型与强化学习的新方法，显著提升了模拟环境中对象的交互能力。


<details>
  <summary>Details</summary>
Motivation: 通过整合先进的视觉模型（如SAM和YOLOv5）与强化学习，旨在提高智能体在复杂环境中的感知与交互能力。

Method: 使用Segment Anything Model (SAM)和YOLOv5结合Proximal Policy Optimization (PPO)算法，在AI2-THOR模拟环境中进行实验。

Result: 实验结果显示，平均累积奖励提高了68%，对象交互成功率提升了52.5%，导航效率提高了33%。

Conclusion: 研究证明了视觉基础模型与强化学习结合在复杂机器人任务中的潜力，为更先进的自主智能体开发铺平了道路。

Abstract: This paper presents a novel approach that integrates vision foundation models
with reinforcement learning to enhance object interaction capabilities in
simulated environments. By combining the Segment Anything Model (SAM) and
YOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the
AI2-THOR simulation environment, we enable the agent to perceive and interact
with objects more effectively. Our comprehensive experiments, conducted across
four diverse indoor kitchen settings, demonstrate significant improvements in
object interaction success rates and navigation efficiency compared to a
baseline agent without advanced perception. The results show a 68% increase in
average cumulative reward, a 52.5% improvement in object interaction success
rate, and a 33% increase in navigation efficiency. These findings highlight the
potential of integrating foundation models with reinforcement learning for
complex robotic tasks, paving the way for more sophisticated and capable
autonomous agents.

</details>


### [229] [Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration](https://arxiv.org/abs/2508.05936)
*Haohui Pan,Takuya Kiyokawa,Tomoki Ishikura,Shingo Hamada,Genichiro Matsuda,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出了一种基于模块化真空夹具的系统，利用商用气球型软夹持器适应复杂几何形状，提高螺丝拆卸任务的稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性夹具难以适应小型家电复杂曲面，导致拆卸困难。

Method: 开发稳定性感知规划框架，采样目标物体底面，筛选接触点并评估支撑配置。

Result: 与传统刚性夹具相比，新系统在螺丝拆卸任务中成功率更高，稳定性更优。

Conclusion: 模块化真空夹具系统显著提升了复杂几何形状物体的拆卸效率和稳定性。

Abstract: The disassembly of small household appliances poses significant challenges
due to their complex and curved geometries, which render traditional rigid
fixtures inadequate. In this paper, we propose a modular vacuum-based fixturing
system that leverages commercially available balloon-type soft grippers to
conform to arbitrarily shaped surfaces and provide stable support during
screw-removal tasks. To enable a reliable deployment of the system, we develop
a stability-aware planning framework that samples the bottom surface of the
target object, filters candidate contact points based on geometric continuity,
and evaluates support configurations using convex hull-based static stability
criteria. We compare the quality of object placement under different numbers
and configurations of balloon hands. In addition, real-world experiments were
conducted to compare the success rates of traditional rigid fixtures with our
proposed system. The results demonstrate that our method consistently achieves
higher success rates and superior placement stability during screw removal
tasks.

</details>


### [230] [Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts](https://arxiv.org/abs/2508.05937)
*Gen Sako,Takuya Kiyokawa,Kensuke Harada,Tomoki Ishikura,Naoya Miyaji,Genichiro Matsuda*

Main category: cs.RO

TL;DR: 提出了一种基于视觉引导的远程操作系统，用于解决机器人拆卸配对零件时的灵活操作和内部结构不可见问题。


<details>
  <summary>Details</summary>
Motivation: 机器人拆卸配对零件时面临灵活操作和内部结构不可见的挑战，需要一种直观的解决方案。

Method: 开发了一种视觉引导的远程操作系统，结合虚拟环境中的可行抓取位姿和拆卸方向，并集成混合控制器（位置和阻抗控制）。

Result: 实验验证了系统的有效性，提高了任务成功率并减少了物体位姿偏差。

Conclusion: 该系统为配对零件的拆卸提供了一种直观且高效的解决方案。

Abstract: Robotic non-destructive disassembly of mating parts remains challenging due
to the need for flexible manipulation and the limited visibility of internal
structures. This study presents an affordance-guided teleoperation system that
enables intuitive human demonstrations for dual-arm fix-and-disassemble tasks
for mating parts. The system visualizes feasible grasp poses and disassembly
directions in a virtual environment, both derived from the object's geometry,
to address occlusions and structural complexity. To prevent excessive position
tracking under load when following the affordance, we integrate a hybrid
controller that combines position and impedance control into the teleoperated
disassembly arm. Real-world experiments validate the effectiveness of the
proposed system, showing improved task success rates and reduced object pose
deviation.

</details>


### [231] [Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution](https://arxiv.org/abs/2508.05941)
*Zhanyi Sun,Shuran Song*

Main category: cs.RO

TL;DR: 论文提出了一种名为Latent Policy Barrier（LPB）的框架，通过将专家演示的潜在嵌入视为隐式屏障，分离安全状态与不安全状态，从而提升视觉运动策略的鲁棒性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 行为克隆训练的视觉运动策略容易受到协变量偏移的影响，导致偏离专家轨迹时性能下降。现有方法通常需要人工干预或数据增强，但成本高且可能影响模仿质量。

Method: LPB框架包含两个模块：基于专家数据的扩散策略和基于专家及次优策略数据的动态模型。动态模型预测未来潜在状态并优化其保持在专家分布内。

Result: 模拟和真实实验表明，LPB提高了策略的鲁棒性和数据效率，无需额外人工干预即可实现可靠操作。

Conclusion: LPB通过分离专家模仿和OOD恢复，提供了一种高效且鲁棒的视觉运动策略学习方法。

Abstract: Visuomotor policies trained via behavior cloning are vulnerable to covariate
shift, where small deviations from expert trajectories can compound into
failure. Common strategies to mitigate this issue involve expanding the
training distribution through human-in-the-loop corrections or synthetic data
augmentation. However, these approaches are often labor-intensive, rely on
strong task assumptions, or compromise the quality of imitation. We introduce
Latent Policy Barrier, a framework for robust visuomotor policy learning.
Inspired by Control Barrier Functions, LPB treats the latent embeddings of
expert demonstrations as an implicit barrier separating safe, in-distribution
states from unsafe, out-of-distribution (OOD) ones. Our approach decouples the
role of precise expert imitation and OOD recovery into two separate modules: a
base diffusion policy solely on expert data, and a dynamics model trained on
both expert and suboptimal policy rollout data. At inference time, the dynamics
model predicts future latent states and optimizes them to stay within the
expert distribution. Both simulated and real-world experiments show that LPB
improves both policy robustness and data efficiency, enabling reliable
manipulation from limited expert data and without additional human correction
or annotation.

</details>


### [232] [Social and Telepresence Robots for Accessibility and Inclusion in Small Museums](https://arxiv.org/abs/2508.05946)
*Nello Balossino,Rossana Damiano,Cristina Gena,Alberto Lillo,Anna Maria Marras,Claudio Mattutino,Antonio Pizzo,Alessia Prin,Fabiana Vernero*

Main category: cs.RO

TL;DR: ROBSO-PM项目通过社交机器人和远程社交机器人提升小型博物馆的可访问性，重点关注感知、文化和认知障碍。


<details>
  <summary>Details</summary>
Motivation: 解决低人口密度地区博物馆的可访问性问题，特别是针对外国游客和残障人士。

Method: 在三个博物馆案例研究中应用机器人作为导览工具和远程访问工具，研究内容包括叙事、机器人个性、共情和个性化。

Result: 探索机器人作为导览和远程访问工具的实际应用，明确角色分工和自主性。

Conclusion: 社交机器人有望提升小型博物馆的可访问性，尤其是在偏远地区。

Abstract: There are still many museums that present accessibility barriers,
particularly regarding perceptual, cultural, and cognitive aspects. This is
especially evident in low-density population areas. The aim of the ROBSO-PM
project is to improve the accessibility of small museums through the use of
social robots and social telepresence robots, focusing on three museums as case
studies: the Museum of the Holy Shroud in Turin, a small but globally known
institution, and two lesser known mountain museums: the Museum of the Champlas
du Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and
Traditions. The project explores two main applications for robots: as guides
supporting inclusive visits for foreign or disabled visitors, and as
telepresence tools allowing people with limited mobility to access museums
remotely. From a research perspective, key topics include storytelling, robot
personality, empathy, personalization, and, in the case of telepresence,
collaboration between the robot and the person, with clearly defined roles and
autonomy.

</details>


### [233] [Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles](https://arxiv.org/abs/2508.05972)
*Shaoting Liu,Zhou Liu*

Main category: cs.RO

TL;DR: 本文提出了一种扰动感知的规划框架，用于增强空陆双模车辆在复杂环境中的轨迹规划鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 空陆双模车辆结合了空中和地面移动的优势，但在环境扰动下轨迹规划的鲁棒性仍需提升。

Method: 提出了一种扰动感知的规划框架，包括实时扰动估计、路径搜索和轨迹优化，并引入了扰动自适应安全边界调整机制。

Result: 实验验证了该方法在跟踪精度、任务效率和能源性能上的提升，尤其是在地面和空中扰动下的表现。

Conclusion: 该方法显著提升了空陆双模车辆在复杂环境中的运动规划适应性和可靠性。

Abstract: Air-land bimodal vehicles provide a promising solution for navigating complex
environments by combining the flexibility of aerial locomotion with the energy
efficiency of ground mobility. To enhance the robustness of trajectory planning
under environmental disturbances, this paper presents a disturbance-aware
planning framework that incorporates real-time disturbance estimation into both
path searching and trajectory optimization. A key component of the framework is
a disturbance-adaptive safety boundary adjustment mechanism, which dynamically
modifies the vehicle's feasible dynamic boundaries based on estimated
disturbances to ensure trajectory feasibility. Leveraging the dynamics model of
the bimodal vehicle, the proposed approach achieves adaptive and reliable
motion planning across different terrains and operating conditions. A series of
real-world experiments and benchmark comparisons on a custom-built platform
validate the effectiveness and robustness of the method, demonstrating
improvements in tracking accuracy, task efficiency, and energy performance
under both ground and aerial disturbances.

</details>


### [234] [ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference](https://arxiv.org/abs/2508.06053)
*Kaixuan Wu,Yuanzhuo Xu,Zejun Zhang,Weiping Zhu,Steve Drew,Xiaoguang Niu*

Main category: cs.RO

TL;DR: ReNiL是一个基于贝叶斯深度学习的框架，用于高效、准确且具有不确定性感知的行人惯性定位，通过引入IPDPs和ASLE技术，实现了多尺度运动和步态适应，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖固定滑动窗口，难以适应多样化的运动尺度和步态，且不确定性估计不一致，限制了实际应用。

Method: ReNiL结合了运动感知方向滤波器和Any-Scale Laplace Estimator (ASLE)，通过IPDPs在上下文关键点估计运动，支持任意尺度的IMU序列推理。

Result: 在RoNIN-ds和WUDataset上，ReNiL在位移精度和不确定性一致性上达到最优，计算量更低。

Conclusion: ReNiL为移动和IoT定位提供了可扩展且具有不确定性感知的基础，适用于下一代定位系统。

Abstract: Pedestrian inertial localization is key for mobile and IoT services because
it provides infrastructure-free positioning. Yet most learning-based methods
depend on fixed sliding-window integration, struggle to adapt to diverse motion
scales and cadences, and yield inconsistent uncertainty, limiting real-world
use. We present ReNiL, a Bayesian deep-learning framework for accurate,
efficient, and uncertainty-aware pedestrian localization. ReNiL introduces
Inertial Positioning Demand Points (IPDPs) to estimate motion at contextually
meaningful waypoints instead of dense tracking, and supports inference on IMU
sequences at any scale so cadence can match application needs. It couples a
motion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a
dual-task network that blends patch-based self-supervision with Bayesian
regression. By modeling displacements with a Laplace distribution, ReNiL
provides homogeneous Euclidean uncertainty that integrates cleanly with other
sensors. A Bayesian inference chain links successive IPDPs into consistent
trajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor
motion from 28 participants, ReNiL achieves state-of-the-art displacement
accuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN
variants while reducing computation. Application studies further show
robustness and practicality for mobile and IoT localization, making ReNiL a
scalable, uncertainty-aware foundation for next-generation positioning.

</details>


### [235] [Incremental Language Understanding for Online Motion Planning of Robot Manipulators](https://arxiv.org/abs/2508.06095)
*Mitchell Abrams,Thies Oelerich,Christian Hartl-Nesic,Andreas Kugi,Matthias Scheutz*

Main category: cs.RO

TL;DR: 提出了一种基于推理的增量解析器，将在线运动规划算法集成到认知架构中，实现实时动态语言输入的连续适应。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导的机器人运动规划方法通常假设指令完全明确，导致在修正或澄清时效率低下。

Method: 结合符号推理与在线运动规划，维护多个候选解析，利用推理机制解决歧义和修订解释。

Result: 在真实人机交互场景中验证了系统对目标姿态、约束或任务目标的在线适应能力。

Conclusion: 增量语言理解与实时运动规划的结合提升了人机协作的自然性和流畅性。

Abstract: Human-robot interaction requires robots to process language incrementally,
adapting their actions in real-time based on evolving speech input. Existing
approaches to language-guided robot motion planning typically assume fully
specified instructions, resulting in inefficient stop-and-replan behavior when
corrections or clarifications occur. In this paper, we introduce a novel
reasoning-based incremental parser which integrates an online motion planning
algorithm within the cognitive architecture. Our approach enables continuous
adaptation to dynamic linguistic input, allowing robots to update motion plans
without restarting execution. The incremental parser maintains multiple
candidate parses, leveraging reasoning mechanisms to resolve ambiguities and
revise interpretations when needed. By combining symbolic reasoning with online
motion planning, our system achieves greater flexibility in handling speech
corrections and dynamically changing constraints. We evaluate our framework in
real-world human-robot interaction scenarios, demonstrating online adaptions of
goal poses, constraints, or task objectives. Our results highlight the
advantages of integrating incremental language understanding with real-time
motion planning for natural and fluid human-robot collaboration. The
experiments are demonstrated in the accompanying video at
www.acin.tuwien.ac.at/42d5.

</details>


### [236] [Bounding Distributional Shifts in World Modeling through Novelty Detection](https://arxiv.org/abs/2508.06096)
*Eric Jing,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 提出了一种基于变分自编码器的新颖性检测方法，以提高模型规划算法对学习世界模型质量的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉世界模型对训练质量敏感，需要近乎完整的动作和状态空间覆盖以防止推理时发散。

Method: 使用变分自编码器作为新颖性检测器，确保规划时的动作轨迹不偏离训练数据分布。

Result: 在模拟机器人环境中实验表明，该方法在数据效率上优于现有解决方案。

Conclusion: 该方法显著提升了模型规划算法的鲁棒性和数据效率。

Abstract: Recent work on visual world models shows significant promise in latent state
dynamics obtained from pre-trained image backbones. However, most of the
current approaches are sensitive to training quality, requiring near-complete
coverage of the action and state space during training to prevent divergence
during inference. To make a model-based planning algorithm more robust to the
quality of the learned world model, we propose in this work to use a
variational autoencoder as a novelty detector to ensure that proposed action
trajectories during planning do not cause the learned model to deviate from the
training data distribution. To evaluate the effectiveness of this approach, a
series of experiments in challenging simulated robot environments was carried
out, with the proposed method incorporated into a model-predictive control
policy loop extending the DINO-WM architecture. The results clearly show that
the proposed method improves over state-of-the-art solutions in terms of data
efficiency.

</details>


### [237] [Beyond Constant Parameters: Hyper Prediction Models and HyperMPC](https://arxiv.org/abs/2508.06181)
*Jan Węgrzynowski,Piotr Kicki,Grzegorz Czechmanowski,Maciej Krupka,Krzysztof Walas*

Main category: cs.RO

TL;DR: 论文提出了一种名为Hyper Prediction Model（HyperPM）的新方法，通过将未建模的动态投影到时间依赖的动态模型中，显著减少了长期预测误差，并在MPC框架中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度的MPC方法受限于计算复杂性和状态表示，无法准确捕捉未建模的动态。

Method: 提出HyperPM，利用神经网络学习时间变化模型参数，将其投影到时间依赖的动态模型中，保持计算效率的同时增强预测能力。

Result: 在F1TENTH自动驾驶赛车等挑战性系统中验证，显著减少长期预测误差，并在MPC框架中优于现有技术。

Conclusion: HyperPM在保持计算效率的同时提升了动态模型的预测能力，为MPC提供了更可靠的解决方案。

Abstract: Model Predictive Control (MPC) is among the most widely adopted and reliable
methods for robot control, relying critically on an accurate dynamics model.
However, existing dynamics models used in the gradient-based MPC are limited by
computational complexity and state representation. To address this limitation,
we propose the Hyper Prediction Model (HyperPM) - a novel approach in which we
project the unmodeled dynamics onto a time-dependent dynamics model. This
time-dependency is captured through time-varying model parameters, whose
evolution over the MPC prediction horizon is learned using a neural network.
Such formulation preserves the computational efficiency and robustness of the
base model while equipping it with the capacity to anticipate previously
unmodeled phenomena. We evaluated the proposed approach on several challenging
systems, including real-world F1TENTH autonomous racing, and demonstrated that
it significantly reduces long-horizon prediction errors. Moreover, when
integrated within the MPC framework (HyperMPC), our method consistently
outperforms existing state-of-the-art techniques.

</details>


### [238] [Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model](https://arxiv.org/abs/2508.06206)
*Hanqing Wang,Shaoyang Wang,Yiming Zhong,Zemin Yang,Jiamin Wang,Zhiqing Cui,Jiahao Yuan,Yifan Han,Mingyu Liu,Yuexin Ma*

Main category: cs.RO

TL;DR: Affordance-R1提出了一种统一的affordance grounding框架，结合了认知链式思维（CoT）和强化学习，解决了现有模型在跨域泛化和显式推理能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有模型因缺乏链式思维推理能力，忽视了不同对象间的affordance共享，限制了跨域泛化和显式推理能力。

Method: 提出了Affordance-R1框架，整合了认知CoT引导的Group Relative Policy Optimization（GRPO）和强化学习，设计了包含格式、感知和认知奖励的affordance函数，并构建了高质量数据集ReasonAff。

Result: Affordance-R1在零样本泛化和测试时推理能力上表现优异，超越了现有方法，并展示了开放世界泛化能力。

Conclusion: Affordance-R1是首个将GRPO强化学习与推理结合的affordance推理方法，代码和数据集已开源。

Abstract: Affordance grounding focuses on predicting the specific regions of objects
that are associated with the actions to be performed by robots. It plays a
vital role in the fields of human-robot interaction, human-object interaction,
embodied manipulation, and embodied perception. Existing models often neglect
the affordance shared among different objects because they lack the
Chain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)
generalization and explicit reasoning capabilities. To address these
challenges, we propose Affordance-R1, the first unified affordance grounding
framework that integrates cognitive CoT guided Group Relative Policy
Optimization (GRPO) within a reinforcement learning paradigm. Specifically, we
designed a sophisticated affordance function, which contains format,
perception, and cognition rewards to effectively guide optimization directions.
Furthermore, we constructed a high-quality affordance-centric reasoning
dataset, ReasonAff, to support training. Trained exclusively via reinforcement
learning with GRPO and without explicit reasoning data, Affordance-R1 achieves
robust zero-shot generalization and exhibits emergent test-time reasoning
capabilities. Comprehensive experiments demonstrate that our model outperforms
well-established methods and exhibits open-world generalization. To the best of
our knowledge, Affordance-R1 is the first to integrate GRPO-based RL with
reasoning into affordance reasoning. The code of our method and our dataset is
released on https://github.com/hq-King/Affordance-R1.

</details>


### [239] [Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization](https://arxiv.org/abs/2508.06207)
*Andrea Dal Prete,Seyram Ofori,Chan Yon Sin,Ashwin Narayan,Francesco Braghin,Marta Gandolla,Haoyong Yu*

Main category: cs.RO

TL;DR: 研究提出了一种基于肌肉活动减少、不适感和用户偏好的优化空间，开发了实时负载估计的自适应控制方法，显著降低了背部肌肉激活峰值。


<details>
  <summary>Details</summary>
Motivation: 解决背部外骨骼支持策略优化和自适应控制的挑战，以提高其有效性和用户体验。

Method: 构建优化空间确定最佳支持策略，开发基于视觉的自适应控制管道实时估计负载。

Result: 实验显示自适应控制将背部肌肉激活峰值降低23%，准确率超80%，且用户偏好和不适感得到优化。

Conclusion: 验证了智能、上下文感知控制在工业外骨骼中的潜力，为未来设计提供了框架。

Abstract: Back exoskeletons can reduce musculoskeletal strain, but their effectiveness
depends on support modulation and adaptive control. This study addresses two
challenges: defining optimal support strategies and developing adaptive control
based on payload estimation. We introduce an optimization space based on muscle
activity reduction, perceived discomfort, and user preference, constructing
functions to identify optimal strategies. Experiments with 12 subjects revealed
optimal operating regions, highlighting the need for dynamic modulation. Based
on these insights, we developed a vision-based adaptive control pipeline that
estimates payloads in real-time by enhancing exoskeleton contextual
understanding, minimising latency and enabling support adaptation within the
defined optimisation space. Validation with 12 more subjects showed over 80%
accuracy and improvements across all metrics. Compared to static control,
adaptive modulation reduced peak back muscle activation by up to 23% while
preserving user preference and minimising discomfort. These findings validate
the proposed framework and highlight the potential of intelligent,
context-aware control in industrial exoskeletons.

</details>


### [240] [REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance](https://arxiv.org/abs/2508.06229)
*Zihao Xu,Ce Hao,Chunzheng Wang,Kuankuan Sima,Fan Shi,Jin Song Dong*

Main category: cs.RO

TL;DR: 本文提出了一种名为REBot的控制框架，用于四足机器人在动态障碍物环境中的实时反射性避障。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖导航轨迹重规划，反应时间不足，无法应对快速接近的障碍物，因此需要一种低延迟的反射性避障能力。

Method: REBot结合了避障策略和恢复策略，通过有限状态机实现，并采用精心设计的学习课程、正则化和自适应奖励。

Result: 实验表明，REBot在避障成功率、能效和应对快速移动障碍物的鲁棒性方面有显著提升。

Conclusion: REBot为四足机器人提供了高效的实时反射性避障能力。

Abstract: Dynamic obstacle avoidance (DOA) is critical for quadrupedal robots operating
in environments with moving obstacles or humans. Existing approaches typically
rely on navigation-based trajectory replanning, which assumes sufficient
reaction time and leading to fails when obstacles approach rapidly. In such
scenarios, quadrupedal robots require reflexive evasion capabilities to perform
instantaneous, low-latency maneuvers. This paper introduces Reflexive Evasion
Robot (REBot), a control framework that enables quadrupedal robots to achieve
real-time reflexive obstacle avoidance. REBot integrates an avoidance policy
and a recovery policy within a finite-state machine. With carefully designed
learning curricula and by incorporating regularization and adaptive rewards,
REBot achieves robust evasion and rapid stabilization in instantaneous DOA
tasks. We validate REBot through extensive simulations and real-world
experiments, demonstrating notable improvements in avoidance success rates,
energy efficiency, and robustness to fast-moving obstacles. Videos and appendix
are available on https://rebot-2025.github.io/.

</details>


### [241] [ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints](https://arxiv.org/abs/2508.06266)
*Zezeng Li,Rui Yang,Ruochen Chen,ZhongXuan Luo,Liming Chen*

Main category: cs.RO

TL;DR: 提出了一种自适应扩散策略（ADP），通过引入几何约束和初始化优化，提升扩散策略在机器人操作中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在动作生成中忽略了几何和控制结构的先验知识，导致性能受限。

Method: ADP引入几何流形约束和解析引导初始化，优化扩散过程。

Result: 实验表明，ADP在多个数据集上提升了成功率和采样效率，执行速度提升25%，性能提升9%。

Conclusion: ADP无需重新训练即可适应新任务，显著提升了扩散策略的泛化能力和效率。

Abstract: Diffusion policies have recently emerged as a powerful class of visuomotor
controllers for robot manipulation, offering stable training and expressive
multi-modal action modeling. However, existing approaches typically treat
action generation as an unconstrained denoising process, ignoring valuable a
priori knowledge about geometry and control structure. In this work, we propose
the Adaptive Diffusion Policy (ADP), a test-time adaptation method that
introduces two key inductive biases into the diffusion. First, we embed a
geometric manifold constraint that aligns denoising updates with task-relevant
subspaces, leveraging the fact that the relative pose between the end-effector
and target scene provides a natural gradient direction, and guiding denoising
along the geodesic path of the manipulation manifold. Then, to reduce
unnecessary exploration and accelerate convergence, we propose an analytically
guided initialization: rather than sampling from an uninformative prior, we
compute a rough registration between the gripper and target scenes to propose a
structured initial noisy action. ADP is compatible with pre-trained diffusion
policies and requires no retraining, enabling test-time adaptation that tailors
the policy to specific tasks, thereby enhancing generalization across novel
tasks and environments. Experiments on RLBench, CALVIN, and real-world dataset
show that ADPro, an implementation of ADP, improves success rates,
generalization, and sampling efficiency, achieving up to 25% faster execution
and 9% points over strong diffusion baselines.

</details>


### [242] [EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators](https://arxiv.org/abs/2508.06276)
*Juan Heredia,Christian Schlette,Mikkel Baun Kjærgaard*

Main category: cs.RO

TL;DR: 提出了一种基于Matlab的开源库，用于生成机械臂的能耗模型，解决了现有模型局限于传统工业机器人和精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机械臂能耗模型主要针对传统工业机器人且精度不足，需要更通用且准确的解决方案。

Method: 使用Denavit-Hartenberg参数、连杆质量和质心作为输入，结合实时操作数据（如关节位置、速度、加速度和电功率），开发数据驱动模型。

Result: 在四种轻量级机器人上验证，训练集RMSE为1.42-2.80 W，测试集RMSE为1.45-5.25 W。

Conclusion: 该方法有效提高了机械臂能耗模型的通用性和准确性。

Abstract: Existing literature proposes models for estimating the electrical power of
manipulators, yet two primary limitations prevail. First, most models are
predominantly tested using traditional industrial robots. Second, these models
often lack accuracy. To address these issues, we introduce an open source
Matlab-based library designed to automatically generate \ac{ec} models for
manipulators. The necessary inputs for the library are Denavit-Hartenberg
parameters, link masses, and centers of mass. Additionally, our model is
data-driven and requires real operational data, including joint positions,
velocities, accelerations, electrical power, and corresponding timestamps. We
validated our methodology by testing on four lightweight robots sourced from
three distinct manufacturers: Universal Robots, Franka Emika, and Kinova. The
model underwent testing, and the results demonstrated an RMSE ranging from 1.42
W to 2.80 W for the training dataset and from 1.45 W to 5.25 W for the testing
dataset.

</details>


### [243] [Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs](https://arxiv.org/abs/2508.06278)
*Petr Novak,Stefan Biffl,Marek Obitko,Petr Kadera*

Main category: cs.RO

TL;DR: 论文提出了一种名为PPR-AKG的语义模型，用于分析和缓解灵活工业CPPS中的不良条件，结合了语义技术与大型语言模型（LLMs），并通过电动汽车电池再制造案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 工业CPPS的灵活性导致传统质量保证机制失效，需要新的方法来分析和处理不良条件。

Method: 基于PPR模型，开发了全面的OWL本体，结合语义技术和LLMs，提供自然语言交互界面。

Result: PPR-AKG能有效支持资源分配和不良条件的识别与缓解，案例验证了其实际应用价值。

Conclusion: PPR-AKG模型和LLM结合为工业CPPS提供了多维知识表示和直观交互方式。

Abstract: Contemporary industrial cyber-physical production systems (CPPS) composed of
robotic workcells face significant challenges in the analysis of undesired
conditions due to the flexibility of Industry 4.0 that disrupts traditional
quality assurance mechanisms. This paper presents a novel industry-oriented
semantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG),
which is designed to analyze and mitigate undesired conditions in flexible
CPPS. Built on top of the well-proven Product-Process-Resource (PPR) model
originating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses
shortcomings of conventional model-driven engineering for CPPS, particularly
inadequate undesired condition and error handling representation. The
integration of semantic technologies with large language models (LLMs) provides
intuitive interfaces for factory operators, production planners, and engineers
to interact with the entire model using natural language. Evaluation with the
use case addressing electric vehicle battery remanufacturing demonstrates that
the PPR-AKG approach efficiently supports resource allocation based on
explicitly represented capabilities as well as identification and mitigation of
undesired conditions in production. The key contributions include (1) a
holistic PPR-AKG model capturing multi-dimensional production knowledge, and
(2) the useful combination of the PPR-AKG with LLM-based chatbots for human
interaction.

</details>


### [244] [Situationally-aware Path Planning Exploiting 3D Scene Graphs](https://arxiv.org/abs/2508.06283)
*Saad Ejaz,Marco Giberna,Muhammad Shaheer,Jose Andres Millan-Romera,Ali Tourani,Paul Kremer,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: S-Path利用3D场景图的语义结构提升路径规划效率，通过两阶段规划和动态重规划机制，显著减少规划时间并保持路径最优性。


<details>
  <summary>Details</summary>
Motivation: 3D场景图的结构未被充分利用以提升路径规划的效率和可解释性，S-Path旨在解决这一问题。

Method: S-Path采用两阶段规划：先在语义图上搜索高层路径，再分解为并行子问题；引入动态重规划机制以优化效率。

Result: 实验表明，S-Path平均减少5.7倍规划时间，路径最优性与传统方法相当，复杂场景表现更优。

Conclusion: S-Path是一种高效且可解释的路径规划方法，适用于3D场景图环境。

Abstract: 3D Scene Graphs integrate both metric and semantic information, yet their
structure remains underutilized for improving path planning efficiency and
interpretability. In this work, we present S-Path, a situationally-aware path
planner that leverages the metric-semantic structure of indoor 3D Scene Graphs
to significantly enhance planning efficiency. S-Path follows a two-stage
process: it first performs a search over a semantic graph derived from the
scene graph to yield a human-understandable high-level path. This also
identifies relevant regions for planning, which later allows the decomposition
of the problem into smaller, independent subproblems that can be solved in
parallel. We also introduce a replanning mechanism that, in the event of an
infeasible path, reuses information from previously solved subproblems to
update semantic heuristics and prioritize reuse to further improve the
efficiency of future planning attempts. Extensive experiments on both
real-world and simulated environments show that S-Path achieves average
reductions of 5.7x in planning time while maintaining comparable path
optimality to classical sampling-based planners and surpassing them in complex
scenarios, making it an efficient and interpretable path planner for
environments represented by indoor 3D Scene Graphs.

</details>


### [245] [Real-Time 3D Vision-Language Embedding Mapping](https://arxiv.org/abs/2508.06291)
*Christian Rauch,Björn Ellensohn,Linus Nwankwo,Vedant Dave,Elmar Rueckert*

Main category: cs.RO

TL;DR: 提出了一种将2D视觉语言模型嵌入到实时3D表示中的方法，通过局部嵌入掩码和置信加权3D集成，实现高精度语义3D表示。


<details>
  <summary>Details</summary>
Motivation: 为机器人任务提供高精度的语义3D表示，支持自然语言交互。

Method: 结合局部嵌入掩码策略和置信加权3D集成，生成任务无关的3D嵌入表示。

Result: 在真实场景中验证了方法的有效性，提高了目标定位精度并满足实时性要求。

Conclusion: 该方法适用于多种交互式机器人任务，仅需原始图像数据。

Abstract: A metric-accurate semantic 3D representation is essential for many robotic
tasks. This work proposes a simple, yet powerful, way to integrate the 2D
embeddings of a Vision-Language Model in a metric-accurate 3D representation at
real-time. We combine a local embedding masking strategy, for a more distinct
embedding distribution, with a confidence-weighted 3D integration for more
reliable 3D embeddings. The resulting metric-accurate embedding representation
is task-agnostic and can represent semantic concepts on a global multi-room, as
well as on a local object-level. This enables a variety of interactive robotic
applications that require the localisation of objects-of-interest via natural
language. We evaluate our approach on a variety of real-world sequences and
demonstrate that these strategies achieve a more accurate object-of-interest
localisation while improving the runtime performance in order to meet our
real-time constraints. We further demonstrate the versatility of our approach
in a variety of interactive handheld, mobile robotics and manipulation tasks,
requiring only raw image data.

</details>


### [246] [Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots](https://arxiv.org/abs/2508.06295)
*Juan Heredia,Emil Stubbe Kolvig-Raun,Sune Lundo Sorensen,Mikkel Baun Kjaergaard*

Main category: cs.RO

TL;DR: 提出了一种基于机器人电力消耗的新型框架，通过能量利用系数、能量转换指标和可靠性系数等标准化指标评估机器人程序的性能，并与传统CPU指标对比。


<details>
  <summary>Details</summary>
Motivation: 传统CPU指标忽略了代码对机器人物理行为的影响，需要从体现角度评估程序性能。

Method: 通过分析机器人电力消耗模式，引入标准化指标（能量利用系数、能量转换指标、可靠性系数）和机器人磨损指标。

Result: 在机器照料实验中，比较了四种程序策略，揭示了各策略的优缺点，为优化编程提供了实用见解。

Conclusion: 基于电力消耗的体现中心方法不仅提升机器人性能，还支持可持续制造和成本降低等工业目标。

Abstract: The code performance of industrial robots is typically analyzed through CPU
metrics, which overlook the physical impact of code on robot behavior. This
study introduces a novel framework for assessing robot program performance from
an embodiment perspective by analyzing the robot's electrical power profile.
Our approach diverges from conventional CPU based evaluations and instead
leverages a suite of normalized metrics, namely, the energy utilization
coefficient, the energy conversion metric, and the reliability coefficient, to
capture how efficiently and reliably energy is used during task execution.
Complementing these metrics, the established robot wear metric provides further
insight into long term reliability. Our approach is demonstrated through an
experimental case study in machine tending, comparing four programs with
diverse strategies using a UR5e robot. The proposed metrics directly compare
and categorize different robot programs, regardless of the specific task, by
linking code performance to its physical manifestation through power
consumption patterns. Our results reveal the strengths and weaknesses of each
strategy, offering actionable insights for optimizing robot programming
practices. Enhancing energy efficiency and reliability through this embodiment
centric approach not only improves individual robot performance but also
supports broader industrial objectives such as sustainable manufacturing and
cost reduction.

</details>


### [247] [Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators](https://arxiv.org/abs/2508.06313)
*Amir Hossein Barjini,Mohammad Bahari,Mahdi Hejrati,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种用于全电动重型机械臂的统一系统级建模与控制框架，结合了增强的代理模型和自适应控制策略，实现了高精度跟踪。


<details>
  <summary>Details</summary>
Motivation: 为全电动重型机械臂（HDRM）开发一种模块化、实时控制框架，以支持其在下一代移动工作机器中的应用。

Method: 结合电机械线性执行器（EMLA）的代理增强模型与扩展的虚拟分解控制（VDC）架构，并引入自然适应律，实现分层控制结构。

Result: 在多域仿真和实验验证中，控制器实现了亚厘米级的笛卡尔跟踪精度。

Conclusion: 代理增强的EMLA模型嵌入VDC方法，能够实现全电动HDRM的模块化实时控制，具有实际应用潜力。

Abstract: This paper presents a unified system-level modeling and control framework for
an all-electric heavy-duty robotic manipulator (HDRM) driven by
electromechanical linear actuators (EMLAs). A surrogate-enhanced actuator
model, combining integrated electromechanical dynamics with a neural network
trained on a dedicated testbed, is integrated into an extended virtual
decomposition control (VDC) architecture augmented by a natural adaptation law.
The derived analytical HDRM model supports a hierarchical control structure
that seamlessly maps high-level force and velocity objectives to real-time
actuator commands, accompanied by a Lyapunov-based stability proof. In
multi-domain simulations of both cubic and a custom planar triangular
trajectory, the proposed adaptive modular controller achieves sub-centimeter
Cartesian tracking accuracy. Experimental validation of the same 1-DoF platform
under realistic load emulation confirms the efficacy of the proposed control
strategy. These findings demonstrate that a surrogate-enhanced EMLA model
embedded in the VDC approach can enable modular, real-time control of an
all-electric HDRM, supporting its deployment in next-generation mobile working
machines.

</details>


### [248] [Towards Balanced Behavior Cloning from Imbalanced Datasets](https://arxiv.org/abs/2508.06319)
*Sagar Parekh,Heramb Nemlekar,Dylan P. Losey*

Main category: cs.RO

TL;DR: 论文探讨了机器人从人类演示中学习复杂行为时数据不平衡的问题，提出了一种自动重新平衡数据集的方法，并分析了不同方法的优缺点。


<details>
  <summary>Details</summary>
Motivation: 人类演示的数据集通常不平衡，导致模仿学习算法过于关注高频行为而忽略低频但重要的行为。

Method: 提出了一种元梯度重新平衡算法，自动调整不同状态-动作对的重要性，无需人工干预。

Result: 实验表明，重新平衡数据集能显著提升模仿学习算法的性能，无需额外数据收集。

Conclusion: 数据重新平衡是提升模仿学习性能的有效方法，但不同方法各有优缺点，需根据具体情况选择。

Abstract: Robots should be able to learn complex behaviors from human demonstrations.
In practice, these human-provided datasets are inevitably imbalanced: i.e., the
human demonstrates some subtasks more frequently than others. State-of-the-art
methods default to treating each element of the human's dataset as equally
important. So if -- for instance -- the majority of the human's data focuses on
reaching a goal, and only a few state-action pairs move to avoid an obstacle,
the learning algorithm will place greater emphasis on goal reaching. More
generally, misalignment between the relative amounts of data and the importance
of that data causes fundamental problems for imitation learning approaches. In
this paper we analyze and develop learning methods that automatically account
for mixed datasets. We formally prove that imbalanced data leads to imbalanced
policies when each state-action pair is weighted equally; these policies
emulate the most represented behaviors, and not the human's complex, multi-task
demonstrations. We next explore algorithms that rebalance offline datasets
(i.e., reweight the importance of different state-action pairs) without human
oversight. Reweighting the dataset can enhance the overall policy performance.
However, there is no free lunch: each method for autonomously rebalancing
brings its own pros and cons. We formulate these advantages and disadvantages,
helping other researchers identify when each type of approach is most
appropriate. We conclude by introducing a novel meta-gradient rebalancing
algorithm that addresses the primary limitations behind existing approaches.
Our experiments show that dataset rebalancing leads to better downstream
learning, improving the performance of general imitation learning algorithms
without requiring additional data collection. See our project website:
https://collab.me.vt.edu/data_curation/.

</details>


### [249] [L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience](https://arxiv.org/abs/2508.06330)
*Baorun Li,Chengrui Zhu,Siyi Du,Bingran Chen,Jie Ren,Wenfei Wang,Yong Liu,Jiajun Lv*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的外参标定框架，通过直接优化SE(3)外参提升里程计精度，无需结构化目标或高质量初始外参。


<details>
  <summary>Details</summary>
Motivation: 现有外参标定方法依赖结构化目标或完全激励数据，限制了实际应用；在线标定因弱激励导致估计不可靠。

Method: 将外参标定建模为决策问题，利用Bingham分布建模3D旋转，结合轨迹对齐奖励机制和自动数据选择模块。

Result: 在无人机、无人车和手持平台上实验表明，该方法优于传统优化方法，在弱激励条件下仍能实现高精度标定。

Conclusion: 该框架简化了多样化机器人平台的部署，支持从常规操作数据中完成标定。

Abstract: Extrinsic calibration is essential for multi-sensor fusion, existing methods
rely on structured targets or fully-excited data, limiting real-world
applicability. Online calibration further suffers from weak excitation, leading
to unreliable estimates. To address these limitations, we propose a
reinforcement learning (RL)-based extrinsic calibration framework that
formulates extrinsic calibration as a decision-making problem, directly
optimizes $SE(3)$ extrinsics to enhance odometry accuracy. Our approach
leverages a probabilistic Bingham distribution to model 3D rotations, ensuring
stable optimization while inherently retaining quaternion symmetry. A
trajectory alignment reward mechanism enables robust calibration without
structured targets by quantitatively evaluating estimated tightly-coupled
trajectory against a reference trajectory. Additionally, an automated data
selection module filters uninformative samples, significantly improving
efficiency and scalability for large-scale datasets. Extensive experiments on
UAVs, UGVs, and handheld platforms demonstrate that our method outperforms
traditional optimization-based approaches, achieving high-precision calibration
even under weak excitation conditions. Our framework simplifies deployment on
diverse robotic platforms by eliminating the need for high-quality initial
extrinsics and enabling calibration from routine operating data. The code is
available at https://github.com/APRIL-ZJU/learn-to-calibrate.

</details>


### [250] [V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles](https://arxiv.org/abs/2508.06404)
*Abdullah Zareh Andaryan,Michael G. H. Bell,Mohsen Ramezani,Glenn Geers*

Main category: cs.RO

TL;DR: V*是一种基于图的运动规划器，通过将速度和方向作为显式状态变量集成到时空速度格子中，直接生成动态可行的轨迹，避免了传统方法的解耦或后处理平滑。


<details>
  <summary>Details</summary>
Motivation: 在结构化环境中，自动驾驶车辆需要能够生成时间最优、无碰撞且满足动态和运动学约束的轨迹。传统方法通常解耦空间搜索与动态可行性或依赖后处理平滑，存在局限性。

Method: V*采用六边形离散化策略，动态生成图，并结合几何剪枝策略和数学建模（如转向动力学），确保轨迹的物理可实现性。

Result: 仿真研究表明，V*能够在复杂动态环境中避免冲突、主动避让，并生成安全高效的轨迹，具备时间推理能力。

Conclusion: V*通过直接集成动态和运动学约束，提供了一种高效且可靠的自动驾驶运动规划方法。

Abstract: Autonomous vehicle navigation in structured environments requires planners
capable of generating time-optimal, collision-free trajectories that satisfy
dynamic and kinematic constraints. We introduce V*, a graph-based motion
planner that represents speed and direction as explicit state variables within
a discretised space-time-velocity lattice. Unlike traditional methods that
decouple spatial search from dynamic feasibility or rely on post-hoc smoothing,
V* integrates both motion dimensions directly into graph construction through
dynamic graph generation during search expansion. To manage the complexity of
high-dimensional search, we employ a hexagonal discretisation strategy and
provide formal mathematical proofs establishing optimal waypoint spacing and
minimal node redundancy under constrained heading transitions for
velocity-aware motion planning. We develop a mathematical formulation for
transient steering dynamics in the kinematic bicycle model, modelling steering
angle convergence with exponential behaviour, and deriving the relationship for
convergence rate parameters. This theoretical foundation, combined with
geometric pruning strategies that eliminate expansions leading to infeasible
steering configurations, enables V* to evaluate dynamically admissible
manoeuvres, ensuring each trajectory is physically realisable without further
refinement. We further demonstrate V*'s performance in simulation studies with
cluttered and dynamic environments involving moving obstacles, showing its
ability to avoid conflicts, yield proactively, and generate safe, efficient
trajectories with temporal reasoning capabilities for waiting behaviours and
dynamic coordination.

</details>


### [251] [Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation](https://arxiv.org/abs/2508.06426)
*Youguang Xing,Xu Luo,Junlin Xie,Lianli Gao,Hengtao Shen,Jingkuan Song*

Main category: cs.RO

TL;DR: 论文探讨了通用机器人策略在大规模数据集（如OXE）训练后泛化能力受限的原因，发现任务无关特征的依赖（捷径学习）是主要障碍，并提出数据集收集策略和数据增强方法以改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究通用机器人策略在大规模数据集训练后泛化能力不足的根本原因，并提出解决方案。

Method: 通过理论和实证分析，识别捷径学习的两个主要原因：子数据集多样性不足和分布差异导致的碎片化。

Result: 发现数据集结构和收集方式是捷径学习的关键因素，并提出数据增强策略可有效改善泛化能力。

Conclusion: 优化数据集收集策略和数据增强方法可减少捷径学习，提升通用机器人策略的泛化能力。

Abstract: Generalist robot policies trained on large-scale datasets such as Open
X-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.
However, they often struggle to generalize beyond the distribution of their
training data. In this paper, we investigate the underlying cause of this
limited generalization capability. We identify shortcut learning -- the
reliance on task-irrelevant features -- as a key impediment to generalization.
Through comprehensive theoretical and empirical analysis, we uncover two
primary contributors to shortcut learning: (1) limited diversity within
individual sub-datasets, and (2) significant distributional disparities across
sub-datasets, leading to dataset fragmentation. These issues arise from the
inherent structure of large-scale datasets like OXE, which are typically
composed of multiple sub-datasets collected independently across varied
environments and embodiments. Our findings provide critical insights into
dataset collection strategies that can reduce shortcut learning and enhance the
generalization ability of generalist robot policies. Moreover, in scenarios
where acquiring new large-scale data is impractical, we demonstrate that
carefully selected robotic data augmentation strategies can effectively reduce
shortcut learning in existing offline datasets, thereby improving
generalization capabilities of generalist robot policies, e.g., $\pi_0$, in
both simulation and real-world environments. More information at
https://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [252] [Training chord recognition models on artificially generated audio](https://arxiv.org/abs/2508.05878)
*Martyna Majchrzak,Jacek Mańdziuk*

Main category: cs.SD

TL;DR: 比较两种基于Transformer的神经网络模型在人工生成数据集和真实数据集上的和弦序列识别效果，证明人工生成数据在某些场景下有效。


<details>
  <summary>Details</summary>
Motivation: 解决音乐信息检索中非版权音频数据不足的问题，探索人工生成数据的实用性。

Method: 使用人工生成音频多轨（AAM）、舒伯特《冬之旅》数据集和McGill Billboard数据集训练模型，并通过Root、MajMin和CCM三种指标评估。

Result: 人工生成数据在复杂性和结构上与人类创作音乐有差异，但可用于补充小规模真实数据集或作为独立训练集。

Conclusion: 人工生成数据在某些场景下可作为替代或补充，特别是在缺乏真实数据时。

Abstract: One of the challenging problems in Music Information Retrieval is the
acquisition of enough non-copyrighted audio recordings for model training and
evaluation. This study compares two Transformer-based neural network models for
chord sequence recognition in audio recordings and examines the effectiveness
of using an artificially generated dataset for this purpose. The models are
trained on various combinations of Artificial Audio Multitracks (AAM),
Schubert's Winterreise Dataset, and the McGill Billboard Dataset and evaluated
with three metrics: Root, MajMin and Chord Content Metric (CCM). The
experiments prove that even though there are certainly differences in
complexity and structure between artificially generated and human-composed
music, the former can be useful in certain scenarios. Specifically, AAM can
enrich a smaller training dataset of music composed by a human or can even be
used as a standalone training set for a model that predicts chord sequences in
pop music, if no other data is available.

</details>


### [253] [DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching](https://arxiv.org/abs/2508.05978)
*Wei Chen,Binzhu Sha,Dan Luo,Jing Yang,Zhuo Wang,Fan Fan,Zhiyong Wu*

Main category: cs.SD

TL;DR: DAFMSVC通过替换源音频的自监督学习特征为目标音频的最相似特征以防止音色泄漏，并引入双交叉注意力机制和流匹配模块，显著提升了音色相似性和自然度。


<details>
  <summary>Details</summary>
Motivation: 解决任意到任意歌唱声音转换中的音色泄漏问题，同时提升生成音频的音色相似性和质量。

Method: 使用自监督学习特征替换、双交叉注意力机制和流匹配模块，实现音色自适应融合和高质量音频生成。

Result: 实验表明DAFMSVC在音色相似性和自然度上显著优于现有方法。

Conclusion: DAFMSVC有效解决了音色泄漏问题，提升了歌唱声音转换的性能。

Abstract: Singing Voice Conversion (SVC) transfers a source singer's timbre to a target
while keeping melody and lyrics. The key challenge in any-to-any SVC is
adapting unseen speaker timbres to source audio without quality degradation.
Existing methods either face timbre leakage or fail to achieve satisfactory
timbre similarity and quality in the generated audio. To address these
challenges, we propose DAFMSVC, where the self-supervised learning (SSL)
features from the source audio are replaced with the most similar SSL features
from the target audio to prevent timbre leakage. It also incorporates a dual
cross-attention mechanism for the adaptive fusion of speaker embeddings,
melody, and linguistic content. Additionally, we introduce a flow matching
module for high quality audio generation from the fused features. Experimental
results show that DAFMSVC significantly enhances timbre similarity and
naturalness, outperforming state-of-the-art methods in both subjective and
objective evaluations.

</details>


### [254] [MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows](https://arxiv.org/abs/2508.06098)
*Xiquan Li,Junxi Liu,Yuzhe Liang,Zhikang Niu,Wenxi Chen,Xie Chen*

Main category: cs.SD

TL;DR: MeanAudio是一种基于MeanFlow的快速文本到音频生成模型，通过回归平均速度场实现快速生成，并在单步生成中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前文本到音频生成系统虽然合成质量和可控性优秀，但推理速度慢，限制了实际应用。

Method: MeanAudio基于Flux风格的潜在变换器，通过回归平均速度场实现快速生成，并结合无分类器引导和瞬时到平均的课程学习策略。

Result: MeanAudio在单步生成中实现了0.013的实时因子（RTF），比现有扩散模型快100倍，同时在多步生成中表现优异。

Conclusion: MeanAudio在速度和生成质量上均表现出色，为文本到音频生成提供了高效的解决方案。

Abstract: Recent developments in diffusion- and flow- based models have significantly
advanced Text-to-Audio Generation (TTA). While achieving great synthesis
quality and controllability, current TTA systems still suffer from slow
inference speed, which significantly limits their practical applicability. This
paper presents MeanAudio, a novel MeanFlow-based model tailored for fast and
faithful text-to-audio generation. Built on a Flux-style latent transformer,
MeanAudio regresses the average velocity field during training, enabling fast
generation by mapping directly from the start to the endpoint of the flow
trajectory. By incorporating classifier-free guidance (CFG) into the training
target, MeanAudio incurs no additional cost in the guided sampling process. To
further stabilize training, we propose an instantaneous-to-mean curriculum with
flow field mix-up, which encourages the model to first learn the foundational
instantaneous dynamics, and then gradually adapt to mean flows. This strategy
proves critical for enhancing training efficiency and generation quality.
Experimental results demonstrate that MeanAudio achieves state-of-the-art
performance in single-step audio generation. Specifically, it achieves a real
time factor (RTF) of 0.013 on a single NVIDIA RTX 3090, yielding a 100x speedup
over SOTA diffusion-based TTA systems. Moreover, MeanAudio also demonstrates
strong performance in multi-step generation, enabling smooth and coherent
transitions across successive synthesis steps.

</details>


### [255] [Llasa+: Free Lunch for Accelerated and Streaming Llama-Based Speech Synthesis](https://arxiv.org/abs/2508.06262)
*Wenjie Tian,Xinfa Zhu,Hanke Xie,Zhen Ye,Wei Xue,Lei Xie*

Main category: cs.SD

TL;DR: Llasa+是一个基于Llasa的加速和流式TTS模型，通过多令牌预测模块和验证算法实现高效生成，同时保持质量。


<details>
  <summary>Details</summary>
Motivation: 现有自回归结构和大型模型在推理延迟和流式合成方面存在挑战，Llasa+旨在解决这些问题。

Method: 引入多令牌预测模块和验证算法加速生成，设计因果解码器实现流式语音重建。

Result: Llasa+在LibriTTS上训练，实现了1.48倍加速且不牺牲生成质量。

Conclusion: Llasa+框架可推广至其他LLM模型，代码和模型已开源。

Abstract: Recent progress in text-to-speech (TTS) has achieved impressive naturalness
and flexibility, especially with the development of large language model
(LLM)-based approaches. However, existing autoregressive (AR) structures and
large-scale models, such as Llasa, still face significant challenges in
inference latency and streaming synthesis. To deal with the limitations, we
introduce Llasa+, an accelerated and streaming TTS model built on Llasa.
Specifically, to accelerate the generation process, we introduce two
plug-and-play Multi-Token Prediction (MTP) modules following the frozen
backbone. These modules allow the model to predict multiple tokens in one AR
step. Additionally, to mitigate potential error propagation caused by
inaccurate MTP, we design a novel verification algorithm that leverages the
frozen backbone to validate the generated tokens, thus allowing Llasa+ to
achieve speedup without sacrificing generation quality. Furthermore, we design
a causal decoder that enables streaming speech reconstruction from tokens.
Extensive experiments show that Llasa+ achieves a 1.48X speedup without
sacrificing generation quality, despite being trained only on LibriTTS.
Moreover, the MTP-and-verification framework can be applied to accelerate any
LLM-based model. All codes and models are publicly available at
https://github.com/ASLP-lab/LLaSA_Plus.

</details>


### [256] [EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition](https://arxiv.org/abs/2508.06321)
*Durjoy Chandra Paul,Gaurob Saha,Md Amjad Hossain*

Main category: cs.SD

TL;DR: EmoAugNet是一种结合LSTM和1D-CNN的混合深度学习框架，用于语音情感识别（SER），通过数据增强和特征提取显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互（HCI）效果，通过可靠的情感识别增强系统性能。

Method: 使用LSTM和1D-CNN的混合模型，结合传统和新型数据增强方法，提取RMSE、MFCC和ZCR特征。

Result: 在IEMOCAP和RAVDESS数据集上，加权准确率分别达到96.75%和94.98%。

Conclusion: EmoAugNet通过数据增强和混合建模显著提升了SER系统的鲁棒性和性能。

Abstract: Recognizing emotional signals in speech has a significant impact on enhancing
the effectiveness of human-computer interaction (HCI). This study introduces
EmoAugNet, a hybrid deep learning framework, that incorporates Long Short-Term
Memory (LSTM) layers with one-dimensional Convolutional Neural Networks
(1D-CNN) to enable reliable Speech Emotion Recognition (SER). The quality and
variety of the features that are taken from speech signals have a significant
impact on how well SER systems perform. A comprehensive speech data
augmentation strategy was used to combine both traditional methods, such as
noise addition, pitch shifting, and time stretching, with a novel
combination-based augmentation pipeline to enhance generalization and reduce
overfitting. Each audio sample was transformed into a high-dimensional feature
vector using root mean square energy (RMSE), Mel-frequency Cepstral Coefficient
(MFCC), and zero-crossing rate (ZCR). Our model with ReLU activation has a
weighted accuracy of 95.78\% and unweighted accuracy of 92.52\% on the IEMOCAP
dataset and, with ELU activation, has a weighted accuracy of 96.75\% and
unweighted accuracy of 91.28\%. On the RAVDESS dataset, we get a weighted
accuracy of 94.53\% and 94.98\% unweighted accuracy for ReLU activation and
93.72\% weighted accuracy and 94.64\% unweighted accuracy for ELU activation.
These results highlight EmoAugNet's effectiveness in improving the robustness
and performance of SER systems through integated data augmentation and hybrid
modeling.

</details>


### [257] [SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models](https://arxiv.org/abs/2508.06372)
*Han Yin,Yafeng Chen,Chong Deng,Luyao Cheng,Hui Wang,Chao-Hong Tan,Qian Chen,Wen Wang,Xiangang Li*

Main category: cs.SD

TL;DR: SpeakerLM是一个统一的多模态大型语言模型，用于联合执行说话人分割和语音识别任务，解决了传统级联系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统级联系统存在错误传播、难以处理重叠语音以及缺乏联合优化的问题，需要一种更高效的解决方案。

Method: 提出SpeakerLM，采用端到端方式联合执行说话人分割和语音识别，并引入灵活的说话人注册机制。

Result: 实验表明，SpeakerLM在数据和泛化能力上表现优异，优于现有级联基线，且说话人注册机制有效提升了鲁棒性。

Conclusion: SpeakerLM为说话人分割和识别任务提供了一种高效且灵活的解决方案。

Abstract: The Speaker Diarization and Recognition (SDR) task aims to predict "who spoke
when and what" within an audio clip, which is a crucial task in various
real-world multi-speaker scenarios such as meeting transcription and dialogue
systems. Existing SDR systems typically adopt a cascaded framework, combining
multiple modules such as speaker diarization (SD) and automatic speech
recognition (ASR). The cascaded systems suffer from several limitations, such
as error propagation, difficulty in handling overlapping speech, and lack of
joint optimization for exploring the synergy between SD and ASR tasks. To
address these limitations, we introduce SpeakerLM, a unified multimodal large
language model for SDR that jointly performs SD and ASR in an end-to-end
manner. Moreover, to facilitate diverse real-world scenarios, we incorporate a
flexible speaker registration mechanism into SpeakerLM, enabling SDR under
different speaker registration settings. SpeakerLM is progressively developed
with a multi-stage training strategy on large-scale real data. Extensive
experiments show that SpeakerLM demonstrates strong data scaling capability and
generalizability, outperforming state-of-the-art cascaded baselines on both
in-domain and out-of-domain public SDR benchmarks. Furthermore, experimental
results show that the proposed speaker registration mechanism effectively
ensures robust SDR performance of SpeakerLM across diverse speaker registration
conditions and varying numbers of registered speakers.

</details>


### [258] [Improved Dysarthric Speech to Text Conversion via TTS Personalization](https://arxiv.org/abs/2508.06391)
*Péter Mihajlik,Éva Székely,Piroska Barta,Máté Soma Kádár,Gergely Dobsinszki,László Tóth*

Main category: cs.SD

TL;DR: 研究开发了一种针对匈牙利语重度构音障碍患者的定制化语音转文字系统，通过合成语音和真实语音结合微调ASR模型，显著降低了错误率。


<details>
  <summary>Details</summary>
Motivation: 现有ASR模型对构音障碍语音的零样本转录效果差，错误率高，需改进以提升可访问性。

Method: 利用个性化TTS系统生成合成语音，结合真实语音微调ASR模型，并通过说话人嵌入插值控制构音障碍严重程度。

Result: 字符错误率从36-51%降至7.3%，且合成语音的加入带来18%的相对CER降低。

Conclusion: 个性化ASR系统对改善重度构音障碍患者的语音识别具有潜力。

Abstract: We present a case study on developing a customized speech-to-text system for
a Hungarian speaker with severe dysarthria. State-of-the-art automatic speech
recognition (ASR) models struggle with zero-shot transcription of dysarthric
speech, yielding high error rates. To improve performance with limited real
dysarthric data, we fine-tune an ASR model using synthetic speech generated via
a personalized text-to-speech (TTS) system. We introduce a method for
generating synthetic dysarthric speech with controlled severity by leveraging
premorbidity recordings of the given speaker and speaker embedding
interpolation, enabling ASR fine-tuning on a continuum of impairments.
Fine-tuning on both real and synthetic dysarthric speech reduces the character
error rate (CER) from 36-51% (zero-shot) to 7.3%. Our monolingual
FastConformer_Hu ASR model significantly outperforms Whisper-turbo when
fine-tuned on the same data, and the inclusion of synthetic speech contributes
to an 18% relative CER reduction. These results highlight the potential of
personalized ASR systems for improving accessibility for individuals with
severe speech impairments.

</details>


### [259] [Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling](https://arxiv.org/abs/2508.06393)
*Md Asif Jalal,Luca Remaggi,Vasileios Moschopoulos,Thanasis Kotsiopoulos,Vandana Rajan,Karthikeyan Saravanan,Anastasis Drosou,Junho Heo,Hyuk Oh,Seokyeong Jeong*

Main category: cs.SD

TL;DR: 提出了一种无需预先标注说话者的语音分离和说话人日志方法，通过自动识别目标说话人嵌入，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖目标说话人的先验知识或固定参与者数量，限制了灵活性。

Method: 采用双阶段训练管道和重叠频谱损失函数，增强说话人表示特征和日志准确性。

Result: 实验显示，在DER和cpWER上分别相对提升了71%和69%。

Conclusion: 新方法在语音分离和说话人日志任务中表现优异，优于现有技术。

Abstract: Traditional speech separation and speaker diarization approaches rely on
prior knowledge of target speakers or a predetermined number of participants in
audio signals. To address these limitations, recent advances focus on
developing enrollment-free methods capable of identifying targets without
explicit speaker labeling. This work introduces a new approach to train
simultaneous speech separation and diarization using automatic identification
of target speaker embeddings, within mixtures. Our proposed model employs a
dual-stage training pipeline designed to learn robust speaker representation
features that are resilient to background noise interference. Furthermore, we
present an overlapping spectral loss function specifically tailored for
enhancing diarization accuracy during overlapped speech frames. Experimental
results show significant performance gains compared to the current SOTA
baseline, achieving 71% relative improvement in DER and 69% in cpWER.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [260] [Universally Unfiltered and Unseen:Input-Agnostic Multimodal Jailbreaks against Text-to-Image Model Safeguards](https://arxiv.org/abs/2508.05658)
*Song Yan,Hui Wei,Jinlong Fei,Guoliang Yang,Zhengyu Zhao,Zheng Wamg*

Main category: cs.CR

TL;DR: 论文提出了一种名为U3-Attack的多模态越狱攻击方法，用于绕过文本到图像（T2I）模型的安全检查器和提示过滤器，解决了现有方法扩展性差和优化耗时的问题。


<details>
  <summary>Details</summary>
Motivation: 现有针对T2I模型的多模态越狱攻击方法存在扩展性差和优化耗时的问题，限制了其实际应用。

Method: U3-Attack通过优化图像背景上的对抗性补丁来绕过安全检查器，同时优化敏感词的安全释义集来绕过提示过滤器，减少冗余计算。

Result: 实验结果表明，U3-Attack在开源和商业T2I模型上均表现出色，例如在Runway-inpainting模型上，其成功率比现有最佳方法高4倍。

Conclusion: U3-Attack是一种高效且通用的多模态越狱攻击方法，显著提升了绕过T2I模型安全措施的成功率。

Abstract: Various (text) prompt filters and (image) safety checkers have been
implemented to mitigate the misuse of Text-to-Image (T2I) models in creating
Not-Safe-For-Work (NSFW) content.In order to expose potential security
vulnerabilities of such safeguards, multimodal jailbreaks have been
studied.However, existing jailbreaks are limited to prompt-specific and
image-specific perturbations, which suffer from poor scalability and
time-consuming optimization.To address these limitations, we propose
Universally Unfiltered and Unseen (U3)-Attack, a multimodal jailbreak attack
method against T2I safeguards.Specifically, U3-Attack optimizes an adversarial
patch on the image background to universally bypass safety checkers and
optimizes a safe paraphrase set from a sensitive word to universally bypass
prompt filters while eliminating redundant computations.Extensive experimental
results demonstrate the superiority of our U3-Attack on both open-source and
commercial T2I models.For example, on the commercial Runway-inpainting model
with both prompt filter and safety checker, our U3-Attack achieves $~4\times$
higher success rates than the state-of-the-art multimodal jailbreak attack,
MMA-Diffusion.Content Warning: This paper includes examples of NSFW content.

</details>


### [261] [ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls](https://arxiv.org/abs/2508.06457)
*Sanket Badhe*

Main category: cs.CR

TL;DR: 论文介绍了ScamAgent，一种基于LLM的自主多轮对话代理，能生成高度逼真的诈骗脚本，并揭示了当前LLM安全防护的不足。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM在生成逼真诈骗脚本方面的潜在滥用风险，以及现有安全防护措施的局限性。

Method: 方法是通过构建ScamAgent，一个具备对话记忆、动态适应和欺骗策略的多轮代理，测试LLM安全防护的有效性。

Result: 结果显示，现有的LLM安全防护（如拒绝机制和内容过滤）对代理式威胁无效，且诈骗脚本可通过语音合成技术转化为逼真语音通话。

Conclusion: 结论强调需要多轮安全审计、代理级控制框架以及检测和阻断生成式AI驱动的对话欺骗的新方法。

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and
reasoning capabilities, but their potential for misuse has raised growing
concern. In this paper, we present ScamAgent, an autonomous multi-turn agent
built on top of LLMs, capable of generating highly realistic scam call scripts
that simulate real-world fraud scenarios. Unlike prior work focused on
single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts
dynamically to simulated user responses, and employs deceptive persuasion
strategies across conversational turns. We show that current LLM safety
guardrails, including refusal mechanisms and content filters, are ineffective
against such agent-based threats. Even models with strong prompt-level
safeguards can be bypassed when prompts are decomposed, disguised, or delivered
incrementally within an agent framework. We further demonstrate the
transformation of scam scripts into lifelike voice calls using modern
text-to-speech systems, completing a fully automated scam pipeline. Our
findings highlight an urgent need for multi-turn safety auditing, agent-level
control frameworks, and new methods to detect and disrupt conversational
deception powered by generative AI.

</details>


### [262] [Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?](https://arxiv.org/abs/2508.05670)
*Daniele Proverbio,Alessio Buscemi,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.CR

TL;DR: 研究探讨了经典博弈论框架是否能有效捕捉LLM驱动行为，发现LLM在博弈中的表现受个性特征和语言选择影响。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在网络安全中的行为是否能用传统博弈论框架描述，揭示潜在偏差。

Method: 使用可复现框架测试LLM在零和博弈和囚徒困境中的表现，涉及多语言评估。

Result: LLM的博弈结果受个性特征和语言选择影响，语言差异导致行为不一致。

Conclusion: LLM在网络安全应用中需谨慎使用，需进一步研究语言和行为稳定性。

Abstract: Game theory has long served as a foundational tool in cybersecurity to test,
predict, and design strategic interactions between attackers and defenders. The
recent advent of Large Language Models (LLMs) offers new tools and challenges
for the security of computer systems; In this work, we investigate whether
classical game-theoretic frameworks can effectively capture the behaviours of
LLM-driven actors and bots. Using a reproducible framework for game-theoretic
LLM agents, we investigate two canonical scenarios -- the one-shot zero-sum
game and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to
expected outcomes or exhibit deviations due to embedded biases. Our experiments
involve four state-of-the-art LLMs and span five natural languages, English,
French, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic
sensitivity. For both games, we observe that the final payoffs are influenced
by agents characteristics such as personality traits or knowledge of repeated
rounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to
the choice of languages, which should warn against indiscriminate application
of LLMs in cybersecurity applications and call for in-depth studies, as LLMs
may behave differently when deployed in different countries. We also employ
quantitative metrics to evaluate the internal consistency and cross-language
stability of LLM agents, to help guide the selection of the most stable LLMs
and optimising models for secure applications.

</details>


### [263] [Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark](https://arxiv.org/abs/2508.05674)
*Minghao Shao,Nanda Rani,Kimberly Milner,Haoran Xi,Meet Udeshi,Saksham Aggarwal,Venkata Sai Charan Putrevu,Sandeep Kumar Shukla,Prashanth Krishnamurthy,Farshad Khorrami,Ramesh Karri,Muhammad Shafique*

Main category: cs.CR

TL;DR: 论文研究了LLM代理系统在CTF挑战中的自动化表现，提出了CTFJudge框架和CTF Competency Index (CCI) 指标，并分析了LLM超参数对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索LLM代理在网络安全任务中的有效性，尤其是CTF挑战的自动化解决。

Method: 提出CTFJudge框架评估代理轨迹，引入CCI指标衡量部分正确性，并分析LLM超参数的影响。

Result: 确定了多代理协调的最佳设置，并发布了CTFTiny基准测试集。

Conclusion: 为未来LLM代理在网络安全领域的研究奠定了基础，并开源了相关工具。

Abstract: Recent advances in LLM agentic systems have improved the automation of
offensive security tasks, particularly for Capture the Flag (CTF) challenges.
We systematically investigate the key factors that drive agent success and
provide a detailed recipe for building effective LLM-based offensive security
agents. First, we present CTFJudge, a framework leveraging LLM as a judge to
analyze agent trajectories and provide granular evaluation across CTF solving
steps. Second, we propose a novel metric, CTF Competency Index (CCI) for
partial correctness, revealing how closely agent solutions align with
human-crafted gold standards. Third, we examine how LLM hyperparameters, namely
temperature, top-p, and maximum token length, influence agent performance and
automated cybersecurity task planning. For rapid evaluation, we present
CTFTiny, a curated benchmark of 50 representative CTF challenges across binary
exploitation, web, reverse engineering, forensics, and cryptography. Our
findings identify optimal multi-agent coordination settings and lay the
groundwork for future LLM agent research in cybersecurity. We make CTFTiny open
source to public https://github.com/NYU-LLM-CTF/CTFTiny along with CTFJudge on
https://github.com/NYU-LLM-CTF/CTFJudge.

</details>


### [264] [DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing](https://arxiv.org/abs/2508.05671)
*Ko-Wei Chuang,Hen-Hsen Huang,Tsai-Yen Li*

Main category: cs.CR

TL;DR: 论文提出DINA框架，针对NLP中的内部标签噪声和外部对抗攻击提供双重防御，显著提升模型鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和生成式AI在客服和内容审核中的应用增加，内外部的对抗威胁（如标签污染和外部攻击）日益突出，亟需解决方案。

Method: DINA结合计算机视觉中的噪声标签学习方法和对抗训练，同时应对内部标签破坏和外部对抗扰动。

Result: 在真实在线游戏数据集上的实验表明，DINA显著优于基线模型，提升了鲁棒性和准确性。

Conclusion: DINA不仅证明了双重防御的必要性，还为NLP系统在对抗场景中的安全部署提供了实用策略，对公平和负责任的AI应用有广泛意义。

Abstract: As large language models (LLMs) and generative AI become increasingly
integrated into customer service and moderation applications, adversarial
threats emerge from both external manipulations and internal label corruption.
In this work, we identify and systematically address these dual adversarial
threats by introducing DINA (Dual Defense Against Internal Noise and
Adversarial Attacks), a novel unified framework tailored specifically for NLP.
Our approach adapts advanced noisy-label learning methods from computer vision
and integrates them with adversarial training to simultaneously mitigate
internal label sabotage and external adversarial perturbations. Extensive
experiments conducted on a real-world dataset from an online gaming service
demonstrate that DINA significantly improves model robustness and accuracy
compared to baseline models. Our findings not only highlight the critical
necessity of dual-threat defenses but also offer practical strategies for
safeguarding NLP systems in realistic adversarial scenarios, underscoring
broader implications for fair and responsible AI deployment.

</details>


### [265] [Principle-Guided Verilog Optimization: IP-Safe Knowledge Transfer via Local-Cloud Collaboration](https://arxiv.org/abs/2508.05675)
*Jing Wang,Zheng Li,Lei Li,Fan He,Liyu Lin,Yao Lai,Yan Li,Xiaoyang Zeng,Yufeng Guo*

Main category: cs.CR

TL;DR: 提出了一种保护IP的边缘-云协作框架，利用本地小型LLM和云端强大LLM结合优化RTL代码，显著提高优化成功率。


<details>
  <summary>Details</summary>
Motivation: 解决云端LLM优化RTL代码时的IP泄露风险，同时利用其强大能力。

Method: 本地小型LLM分析设计原则，云端LLM提供针对性优化，确保IP安全。

Result: 优化成功率显著提升（66.67%），优于单独使用云端LLM或商业模型。

Conclusion: 提出了一种安全高效的硬件设计优化新范式，平衡性能与IP保护。

Abstract: Recent years have witnessed growing interest in adopting large language
models (LLMs) for Register Transfer Level (RTL) code optimization. While
powerful cloud-based LLMs offer superior optimization capabilities, they pose
unacceptable intellectual property (IP) leakage risks when processing
proprietary hardware designs. In this paper, we propose a new scenario where
Verilog code must be optimized for specific attributes without leaking
sensitive IP information. We introduce the first IP-preserving edge-cloud
collaborative framework that leverages the benefits of both paradigms. Our
approach employs local small LLMs (e.g., Qwen-2.5-Coder-7B) to perform secure
comparative analysis between paired high-quality target designs and novice
draft codes, yielding general design principles that summarize key insights for
improvements. These principles are then used to query stronger cloud LLMs
(e.g., Deepseek-V3) for targeted code improvement, ensuring that only
abstracted and IP-safe guidance reaches external services. Our experimental
results demonstrate that the framework achieves significantly higher
optimization success rates compared to baseline methods. For example, combining
Qwen-2.5-Coder-7B and Deepseek-V3 achieves a 66.67\% optimization success rate
for power utilization, outperforming Deepseek-V3 alone (49.81\%) and even
commercial models like GPT-4o (55.81\%). Further investigation of local and
cloud LLM combinations reveals that different model pairings exhibit varying
strengths for specific optimization objectives, with interesting trends
emerging when varying the number of comparative code pairs. Our work
establishes a new paradigm for secure hardware design optimization that
balances performance gains with IP protection.

</details>


### [266] [DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection](https://arxiv.org/abs/2508.05694)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Guanggang Geng,Zhiying Li,Jian Weng*

Main category: cs.CR

TL;DR: DMFI是一个双模态框架，结合语义推理和行为感知微调，用于检测内部威胁，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以捕捉语义意图和复杂行为动态，现有LLM解决方案在提示适应性和模态覆盖方面存在局限。

Method: DMFI将原始日志转换为语义视图和行为抽象，使用两个LoRA增强的LLM独立微调，并通过MLP模块融合输出。

Result: 在CERT r4.2和r5.2数据集上，DMFI在检测准确率上优于现有方法。

Conclusion: DMFI结合LLM的语义推理能力和结构化行为建模，为内部威胁检测提供了可扩展且有效的解决方案。

Abstract: Insider threat detection (ITD) poses a persistent and high-impact challenge
in cybersecurity due to the subtle, long-term, and context-dependent nature of
malicious insider behaviors. Traditional models often struggle to capture
semantic intent and complex behavior dynamics, while existing LLM-based
solutions face limitations in prompt adaptability and modality coverage. To
bridge this gap, we propose DMFI, a dual-modality framework that integrates
semantic inference with behavior-aware fine-tuning. DMFI converts raw logs into
two structured views: (1) a semantic view that processes content-rich artifacts
(e.g., emails, https) using instruction-formatted prompts; and (2) a behavioral
abstraction, constructed via a 4W-guided (When-Where-What-Which) transformation
to encode contextual action sequences. Two LoRA-enhanced LLMs are fine-tuned
independently, and their outputs are fused via a lightweight MLP-based decision
module. We further introduce DMFI-B, a discriminative adaptation strategy that
separates normal and abnormal behavior representations, improving robustness
under severe class imbalance. Experiments on CERT r4.2 and r5.2 datasets
demonstrate that DMFI outperforms state-of-the-art methods in detection
accuracy. Our approach combines the semantic reasoning power of LLMs with
structured behavior modeling, offering a scalable and effective solution for
real-world insider threat detection. Our work demonstrates the effectiveness of
combining LLM reasoning with structured behavioral modeling, offering a
scalable and deployable solution for modern insider threat detection.

</details>


### [267] [Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation](https://arxiv.org/abs/2508.05677)
*Peizhuo Liu*

Main category: cs.CR

TL;DR: 该研究评估了对抗攻击方法在基于强化学习的医疗问卷系统中的安全性，发现即使有严格的医学约束，系统仍存在显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 基于强化学习的医疗问卷系统在医疗场景中潜力巨大，但其安全性和鲁棒性尚未解决。研究旨在识别和分析这些系统的潜在漏洞。

Method: 将诊断过程建模为马尔可夫决策过程（MDP），实现六种对抗攻击方法（如FGSM、PGD等），并开发包含247条医学约束的验证框架。

Result: 在NHIS数据集上实验，攻击成功率为33.08%至64.70%，表明对抗攻击显著影响诊断准确性。

Conclusion: 研究表明，即使输入有严格医学约束，基于强化学习的医疗问卷系统仍存在显著漏洞。

Abstract: RL-based medical questionnaire systems have shown great potential in medical
scenarios. However, their safety and robustness remain unresolved. This study
performs a comprehensive evaluation on adversarial attack methods to identify
and analyze their potential vulnerabilities. We formulate the diagnosis process
as a Markov Decision Process (MDP), where the state is the patient responses
and unasked questions, and the action is either to ask a question or to make a
diagnosis. We implemented six prevailing major attack methods, including the
Fast Gradient Signed Method (FGSM), Projected Gradient Descent (PGD), Carlini &
Wagner Attack (C&W) attack, Basic Iterative Method (BIM), DeepFool, and
AutoAttack, with seven epsilon values each. To ensure the generated adversarial
examples remain clinically plausible, we developed a comprehensive medical
validation framework consisting of 247 medical constraints, including
physiological bounds, symptom correlations, and conditional medical
constraints. We achieved a 97.6% success rate in generating clinically
plausible adversarial samples. We performed our experiment on the National
Health Interview Survey (NHIS) dataset (https://www.cdc.gov/nchs/nhis/), which
consists of 182,630 samples, to predict the participant's 4-year mortality
rate. We evaluated our attacks on the AdaptiveFS framework proposed in
arXiv:2004.00994. Our results show that adversarial attacks could significantly
impact the diagnostic accuracy, with attack success rates ranging from 33.08%
(FGSM) to 64.70% (AutoAttack). Our work has demonstrated that even under strict
medical constraints on the input, such RL-based medical questionnaire systems
still show significant vulnerabilities.

</details>


### [268] [Selection-Based Vulnerabilities: Clean-Label Backdoor Attacks in Active Learning](https://arxiv.org/abs/2508.05681)
*Yuhan Zhi,Longtian Wang,Xiaofei Xie,Chao Shen,Qiang Hu,Xiaohong Guan*

Main category: cs.CR

TL;DR: ALA框架首次揭示了主动学习（AL）的潜在安全风险，通过优化毒化输入以利用获取函数的高不确定性评分，实现高成功率攻击。


<details>
  <summary>Details</summary>
Motivation: 研究主动学习的安全性，揭示获取函数可能被利用的弱点。

Method: 提出ALA框架，通过优化毒化输入使其在获取函数中表现出高不确定性，从而被优先选择。

Result: 在低毒化预算（0.5%-1.0%）下，攻击成功率高达94%，且不影响模型性能或人类标注者的检测。

Conclusion: 主动学习的获取函数易被利用，需在可信数据场景中谨慎部署。

Abstract: Active learning(AL), which serves as the representative label-efficient
learning paradigm, has been widely applied in resource-constrained scenarios.
The achievement of AL is attributed to acquisition functions, which are
designed for identifying the most important data to label. Despite this
success, one question remains unanswered: is AL safe? In this work, we
introduce ALA, a practical and the first framework to utilize the acquisition
function as the poisoning attack surface to reveal the weakness of active
learning. Specifically, ALA optimizes imperceptibly poisoned inputs to exhibit
high uncertainty scores, increasing their probability of being selected by
acquisition functions. To evaluate ALA, we conduct extensive experiments across
three datasets, three acquisition functions, and two types of clean-label
backdoor triggers. Results show that our attack can achieve high success rates
(up to 94%) even under low poisoning budgets (0.5%-1.0%) while preserving model
utility and remaining undetectable to human annotators. Our findings remind
active learning users: acquisition functions can be easily exploited, and
active learning should be deployed with caution in trusted data scenarios.

</details>


### [269] [Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition](https://arxiv.org/abs/2508.05696)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Zhiying Li,Guanggang Geng*

Main category: cs.CR

TL;DR: Log2Sig是一个新的异常检测框架，通过将用户日志转换为多变量行为频率信号，并结合多尺度频率分解和行为序列建模，显著提升了内部威胁检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将系统日志建模为扁平事件序列，无法捕捉用户行为中的频率动态和多尺度扰动模式。

Method: Log2Sig使用MVMD提取IMF，结合Mamba编码器对行为序列和频率信号进行联合建模，并通过多层感知机进行异常检测。

Result: 在CERT r4.2和r5.2数据集上，Log2Sig在准确率和F1分数上显著优于现有基线方法。

Conclusion: Log2Sig通过多尺度频率分解和行为序列的联合建模，为内部威胁检测提供了一种更有效的方法。

Abstract: Insider threat detection presents a significant challenge due to the
deceptive nature of malicious behaviors, which often resemble legitimate user
operations. However, existing approaches typically model system logs as flat
event sequences, thereby failing to capture the inherent frequency dynamics and
multiscale disturbance patterns embedded in user behavior. To address these
limitations, we propose Log2Sig, a robust anomaly detection framework that
transforms user logs into multivariate behavioral frequency signals,
introducing a novel representation of user behavior. Log2Sig employs
Multivariate Variational Mode Decomposition (MVMD) to extract Intrinsic Mode
Functions (IMFs), which reveal behavioral fluctuations across multiple temporal
scales. Based on this, the model further performs joint modeling of behavioral
sequences and frequency-decomposed signals: the daily behavior sequences are
encoded using a Mamba-based temporal encoder to capture long-term dependencies,
while the corresponding frequency components are linearly projected to match
the encoder's output dimension. These dual-view representations are then fused
to construct a comprehensive user behavior profile, which is fed into a
multilayer perceptron for precise anomaly detection. Experimental results on
the CERT r4.2 and r5.2 datasets demonstrate that Log2Sig significantly
outperforms state-of-the-art baselines in both accuracy and F1 score.

</details>


### [270] [Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System](https://arxiv.org/abs/2508.06059)
*Haorui He,Yupeng Li,Bin Benjamin Zhu,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CR

TL;DR: Fact2Fiction是一种针对基于LLM的自动事实核查系统的首次投毒攻击框架，通过分解策略和系统生成的解释来制作恶意证据，攻击成功率高。


<details>
  <summary>Details</summary>
Motivation: 当前事实核查系统的安全性被低估，一旦被攻破可能放大错误信息，因此需要研究其安全弱点。

Method: Fact2Fiction模仿分解策略，利用系统生成的解释制作恶意证据，破坏子声明验证。

Result: 实验显示Fact2Fiction的攻击成功率比现有攻击高8.9%--21.2%。

Conclusion: Fact2Fiction揭示了当前事实核查系统的安全漏洞，强调需要防御措施。

Abstract: State-of-the-art fact-checking systems combat misinformation at scale by
employing autonomous LLM-based agents to decompose complex claims into smaller
sub-claims, verify each sub-claim individually, and aggregate the partial
results to produce verdicts with justifications (explanatory rationales for the
verdicts). The security of these systems is crucial, as compromised
fact-checkers, which tend to be easily underexplored, can amplify
misinformation. This work introduces Fact2Fiction, the first poisoning attack
framework targeting such agentic fact-checking systems. Fact2Fiction mirrors
the decomposition strategy and exploits system-generated justifications to
craft tailored malicious evidences that compromise sub-claim verification.
Extensive experiments demonstrate that Fact2Fiction achieves 8.9\%--21.2\%
higher attack success rates than state-of-the-art attacks across various
poisoning budgets. Fact2Fiction exposes security weaknesses in current
fact-checking systems and highlights the need for defensive countermeasures.

</details>


### [271] [MM-FusionNet: Context-Aware Dynamic Fusion for Multi-modal Fake News Detection with Large Vision-Language Models](https://arxiv.org/abs/2508.05684)
*Junhao He,Tianyu Liu,Jingyuan Zhao,Benjamin Turner*

Main category: cs.CR

TL;DR: MM-FusionNet是一个基于大型视觉语言模型（LVLMs）的多模态假新闻检测框架，通过动态融合模块（CADFM）自适应分配文本和视觉特征的权重，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 多模态假新闻对社会信任和稳定构成威胁，传统文本检测方法因无法有效处理文本与图像的欺骗性交互而效果有限。

Method: 提出MM-FusionNet框架，核心是Context-Aware Dynamic Fusion Module（CADFM），利用双向跨模态注意力和动态模态门控网络自适应学习特征权重。

Result: 在包含80,000个样本的LMFND数据集上，MM-FusionNet的F1-score达到0.938，优于现有多模态和单模态方法。

Conclusion: MM-FusionNet通过动态权重分配和模态鲁棒性，展示了接近人类水平的检测能力，具有实际应用价值。

Abstract: The proliferation of multi-modal fake news on social media poses a
significant threat to public trust and social stability. Traditional detection
methods, primarily text-based, often fall short due to the deceptive interplay
between misleading text and images. While Large Vision-Language Models (LVLMs)
offer promising avenues for multi-modal understanding, effectively fusing
diverse modal information, especially when their importance is imbalanced or
contradictory, remains a critical challenge. This paper introduces
MM-FusionNet, an innovative framework leveraging LVLMs for robust multi-modal
fake news detection. Our core contribution is the Context-Aware Dynamic Fusion
Module (CADFM), which employs bi-directional cross-modal attention and a novel
dynamic modal gating network. This mechanism adaptively learns and assigns
importance weights to textual and visual features based on their contextual
relevance, enabling intelligent prioritization of information. Evaluated on the
large-scale Multi-modal Fake News Dataset (LMFND) comprising 80,000 samples,
MM-FusionNet achieves a state-of-the-art F1-score of 0.938, surpassing existing
multi-modal baselines by approximately 0.5% and significantly outperforming
single-modal approaches. Further analysis demonstrates the model's dynamic
weighting capabilities, its robustness to modality perturbations, and
performance remarkably close to human-level, underscoring its practical
efficacy and interpretability for real-world fake news detection.

</details>


### [272] [Leveraging large language models for SQL behavior-based database intrusion detection](https://arxiv.org/abs/2508.05690)
*Meital Shlezinger,Shay Akirav,Lei Zhou,Liang Guo,Avi Kessel,Guoliang Li*

Main category: cs.CR

TL;DR: 本文提出了一种基于DistilBERT的两层异常检测方法，结合无监督和监督学习技术，用于识别SQL数据库中的异常行为，提高检测精度并减少数据标注需求。


<details>
  <summary>Details</summary>
Motivation: 数据库异常访问行为（如内部和外部攻击）日益增多，现有方法在操作级别检测异常时缺乏粒度，容易误判或漏判。

Method: 使用无监督的集成异常检测器标记偏离正常用户行为的查询（范围外查询），并结合监督学习的微调Transformer模型（基于角色标签分类）检测内部攻击（范围内查询）。

Result: 该方法能有效识别异常行为，尤其是内部攻击，同时减少对数据标注的依赖。

Conclusion: 该方法为保护关键数据库系统免受复杂威胁提供了有效解决方案。

Abstract: Database systems are extensively used to store critical data across various
domains. However, the frequency of abnormal database access behaviors, such as
database intrusion by internal and external attacks, continues to rise.
Internal masqueraders often have greater organizational knowledge, making it
easier to mimic employee behavior effectively. In contrast, external
masqueraders may behave differently due to their lack of familiarity with the
organization. Current approaches lack the granularity needed to detect
anomalies at the operational level, frequently misclassifying entire sequences
of operations as anomalies, even though most operations are likely to represent
normal behavior. On the other hand, some anomalous behaviors often resemble
normal activities, making them difficult for existing detection methods to
identify. This paper introduces a two-tiered anomaly detection approach for
Structured Query Language (SQL) using the Bidirectional Encoder Representations
from Transformers (BERT) model, specifically DistilBERT, a more efficient,
pre-trained version. Our method combines both unsupervised and supervised
machine learning techniques to accurately identify anomalous activities while
minimizing the need for data labeling. First, the unsupervised method uses
ensemble anomaly detectors that flag embedding vectors distant from learned
normal patterns of typical user behavior across the database (out-of-scope
queries). Second, the supervised method uses fine-tuned transformer-based
models to detect internal attacks with high precision (in-scope queries), using
role-labeled classification, even on limited labeled SQL data. Our findings
make a significant contribution by providing an effective solution for
safeguarding critical database systems from sophisticated threats.

</details>


### [273] [MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection](https://arxiv.org/abs/2508.05695)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Zhiying Li,Guanggang Geng,Jian Weng*

Main category: cs.CR

TL;DR: 提出基于Mamba状态空间模型和跨模态自适应融合的MambaITD框架，解决现有方法在时间动态特征建模、计算效率和跨模态信息孤岛问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 企业面临日益严重的内部威胁风险，现有检测方法因时间动态特征建模不足、计算效率低和跨模态信息孤岛问题而无法有效应对。

Method: 1. 多源日志预处理模块对齐异构数据；2. Mamba编码器建模行为序列的长期依赖，结合门控特征融合机制动态融合序列和统计信息；3. 提出基于最大化类间方差的动态阈值优化方法。

Result: MambaITD在建模效率和特征融合能力上显著优于传统方法，表现优于基于Transformer的方法。

Conclusion: MambaITD为内部威胁检测提供了更有效的解决方案。

Abstract: Enterprises are facing increasing risks of insider threats, while existing
detection methods are unable to effectively address these challenges due to
reasons such as insufficient temporal dynamic feature modeling, computational
efficiency and real-time bottlenecks and cross-modal information island
problem. This paper proposes a new insider threat detection framework MambaITD
based on the Mamba state space model and cross-modal adaptive fusion. First,
the multi-source log preprocessing module aligns heterogeneous data through
behavioral sequence encoding, interval smoothing, and statistical feature
extraction. Second, the Mamba encoder models long-range dependencies in
behavioral and interval sequences, and combines the sequence and statistical
information dynamically in combination with the gated feature fusion mechanism.
Finally, we propose an adaptive threshold optimization method based on
maximizing inter-class variance, which dynamically adjusts the decision
threshold by analyzing the probability distribution, effectively identifies
anomalies, and alleviates class imbalance and concept drift. Compared with
traditional methods, MambaITD shows significant advantages in modeling
efficiency and feature fusion capabilities, outperforming Transformer-based
methods, and provides a more effective solution for insider threat detection.

</details>


### [274] [Adaptive Backtracking for Privacy Protection in Large Language Models](https://arxiv.org/abs/2508.06087)
*Zhihao Yao,Yuxuan Gu,Xiachong Feng,Weitao Ma,Bo Li,Xiaocheng Feng*

Main category: cs.CR

TL;DR: 论文提出了一种面向企业的隐私保护方法ABack，解决了现有方法导致模型性能下降和缺乏公开数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护研究主要关注用户隐私，忽视了企业数据泄露风险，尤其是在检索增强生成范式下。

Method: 提出ABack机制，利用隐藏状态模型定位泄露意图并安全重写输出；构建PriGenQA数据集用于评估。

Result: 实验表明，ABack在对抗强大自适应攻击者时，隐私效用得分提升15%，优于现有方法。

Conclusion: ABack有效解决了企业隐私保护中的性能与隐私权衡问题，为未来研究提供了新方向。

Abstract: The preservation of privacy has emerged as a critical topic in the era of
artificial intelligence. However, current work focuses on user-oriented
privacy, overlooking severe enterprise data leakage risks exacerbated by the
Retrieval-Augmented Generation paradigm. To address this gap, our paper
introduces a novel objective: enterprise-oriented privacy concerns. Achieving
this objective requires overcoming two fundamental challenges: existing methods
such as data sanitization severely degrade model performance, and the field
lacks public datasets for evaluation. We address these challenges with several
solutions. (1) To prevent performance degradation, we propose ABack, a
training-free mechanism that leverages a Hidden State Model to pinpoint the
origin of a leakage intention and rewrite the output safely. (2) To solve the
lack of datasets, we construct PriGenQA, a new benchmark for enterprise privacy
scenarios in healthcare and finance. To ensure a rigorous evaluation, we move
beyond simple static attacks by developing a powerful adaptive attacker with
Group Relative Policy Optimization. Experiments show that against this superior
adversary, ABack improves the overall privacy utility score by up to 15\% over
strong baselines, avoiding the performance trade-offs of prior methods.

</details>


### [275] [Anti-Tamper Protection for Unauthorized Individual Image Generation](https://arxiv.org/abs/2508.06325)
*Zelin Li,Ruohan Zong,Yifan Liu,Ruichen Yao,Yaokun Liu,Yang Zhang,Dong Wang*

Main category: cs.CR

TL;DR: 提出了一种新型抗篡改扰动（ATP）方法，结合保护和授权扰动，有效防御伪造攻击并检测净化篡改。


<details>
  <summary>Details</summary>
Motivation: 随着个性化图像生成技术的发展，伪造攻击侵犯肖像权和隐私的问题日益严重，现有保护扰动算法易被净化技术绕过。

Method: ATP在频率域中结合保护和授权扰动，通过掩码指导确保两者互不干扰，授权扰动分布于所有像素以保持对净化篡改的敏感性。

Result: 实验证明ATP在各种攻击场景下均能有效防御伪造攻击。

Conclusion: ATP为保护肖像权和隐私提供了鲁棒解决方案，代码已开源。

Abstract: With the advancement of personalized image generation technologies, concerns
about forgery attacks that infringe on portrait rights and privacy are growing.
To address these concerns, protection perturbation algorithms have been
developed to disrupt forgery generation. However, the protection algorithms
would become ineffective when forgery attackers apply purification techniques
to bypass the protection. To address this issue, we present a novel approach,
Anti-Tamper Perturbation (ATP). ATP introduces a tamper-proof mechanism within
the perturbation. It consists of protection and authorization perturbations,
where the protection perturbation defends against forgery attacks, while the
authorization perturbation detects purification-based tampering. Both
protection and authorization perturbations are applied in the frequency domain
under the guidance of a mask, ensuring that the protection perturbation does
not disrupt the authorization perturbation. This design also enables the
authorization perturbation to be distributed across all image pixels,
preserving its sensitivity to purification-based tampering. ATP demonstrates
its effectiveness in defending forgery attacks across various attack settings
through extensive experiments, providing a robust solution for protecting
individuals' portrait rights and privacy. Our code is available at:
https://github.com/Seeyn/Anti-Tamper-Perturbation .

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [276] [Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy](https://arxiv.org/abs/2508.04728)
*Shuo Chen,Yijin Li,Xi Zheng,Guofeng Zhang*

Main category: eess.IV

TL;DR: NFH-SEM是一种基于神经场的混合SEM 3D重建方法，通过多视角、多检测器的2D SEM图像输入，结合几何和光度信息，实现复杂微观结构的高精度重建。


<details>
  <summary>Details</summary>
Motivation: 传统2D SEM图像无法直接显示微观样本的3D形貌，现有方法在复杂结构重建中存在离散3D表示、校准需求和阴影误差等局限性。

Method: NFH-SEM采用神经场表示，通过端到端自校准和自动分离阴影，结合几何与光度信息进行重建。

Result: 在真实和模拟数据集上验证了NFH-SEM的有效性，成功重建了多种复杂样本，如双光子光刻微结构、桃花花粉和碳化硅颗粒表面。

Conclusion: NFH-SEM无需手动校准，能自动处理阴影，适用于复杂微观结构的高保真重建，具有广泛的应用潜力。

Abstract: The scanning electron microscope (SEM) is a widely used imaging device in
scientific research and industrial applications. Conventional two-dimensional
(2D) SEM images do not directly reveal the three-dimensional (3D) topography of
micro samples, motivating the development of SEM 3D surface reconstruction
methods. However, reconstruction of complex microstructures remains challenging
for existing methods due to the limitations of discrete 3D representations, the
need for calibration with reference samples, and shadow-induced gradient
errors. Here, we introduce NFH-SEM, a neural field-based hybrid SEM 3D
reconstruction method that takes multi-view, multi-detector 2D SEM images as
input and fuses geometric and photometric information into a continuous neural
field representation. NFH-SEM eliminates the manual calibration procedures
through end-to-end self-calibration and automatically disentangles shadows from
SEM images during training, enabling accurate reconstruction of intricate
microstructures. We validate the effectiveness of NFH-SEM on real and simulated
datasets. Our experiments show high-fidelity reconstructions of diverse,
challenging samples, including two-photon lithography microstructures, peach
pollen, and silicon carbide particle surfaces, demonstrating precise detail and
broad applicability.

</details>


### [277] [Transformer-Based Explainable Deep Learning for Breast Cancer Detection in Mammography: The MammoFormer Framework](https://arxiv.org/abs/2508.06137)
*Ojonugwa Oluwafemi Ejiga Peter,Daniel Emakporuena,Bamidele Dayo Tunde,Maryam Abdulkarim,Abdullahi Bn Umar*

Main category: eess.IV

TL;DR: MammoFormer框架结合Transformer架构与多特征增强技术，提升乳腺癌检测性能，提供可解释AI功能。


<details>
  <summary>Details</summary>
Motivation: 解决乳腺X光片解读中因微小异常和专家间差异导致的检测困难，以及CNN在局部与全局信息处理及可解释性上的不足。

Method: 开发MammoFormer框架，测试七种架构（CNN、ViT、Swin Transformer、ConvNext）和四种特征增强技术。

Result: ViT结合AHE达到98.3%准确率，Swin Transformer通过HOG增强性能提升13%。

Conclusion: MammoFormer通过优化架构、集成XAI和结合CNN与Transformer，克服临床AI应用障碍。

Abstract: Breast cancer detection through mammography interpretation remains difficult
because of the minimal nature of abnormalities that experts need to identify
alongside the variable interpretations between readers. The potential of CNNs
for medical image analysis faces two limitations: they fail to process both
local information and wide contextual data adequately, and do not provide
explainable AI (XAI) operations that doctors need to accept them in clinics.
The researcher developed the MammoFormer framework, which unites
transformer-based architecture with multi-feature enhancement components and
XAI functionalities within one framework. Seven different architectures
consisting of CNNs, Vision Transformer, Swin Transformer, and ConvNext were
tested alongside four enhancement techniques, including original images,
negative transformation, adaptive histogram equalization, and histogram of
oriented gradients. The MammoFormer framework addresses critical clinical
adoption barriers of AI mammography systems through: (1) systematic
optimization of transformer architectures via architecture-specific feature
enhancement, achieving up to 13% performance improvement, (2) comprehensive
explainable AI integration providing multi-perspective diagnostic
interpretability, and (3) a clinically deployable ensemble system combining CNN
reliability with transformer global context modeling. The combination of
transformer models with suitable feature enhancements enables them to achieve
equal or better results than CNN approaches. ViT achieves 98.3% accuracy
alongside AHE while Swin Transformer gains a 13.0% advantage through HOG
enhancements

</details>


### [278] [Clinically-guided Data Synthesis for Laryngeal Lesion Detection](https://arxiv.org/abs/2508.06182)
*Chiara Baldini,Kaisar Kushibar,Richard Osuala,Simone Balocco,Oliver Diaz,Karim Lekadir,Leonardo S. Mattos*

Main category: eess.IV

TL;DR: 论文提出了一种利用潜在扩散模型（LDM）和ControlNet适配器生成喉镜图像-标注对的方法，以解决数据稀缺问题，并提升喉部病变检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前喉部病变诊断依赖专家经验且活检成本高，而现有CADx/e系统因数据稀缺难以泛化。

Method: 结合LDM和ControlNet生成临床相关的喉镜图像-标注对，扩充训练数据集。

Result: 仅添加10%合成数据，喉部病变检测率在内部测试中提升9%，外部数据中提升22.1%。专家难以区分合成与真实图像。

Conclusion: 该方法可加速喉部疾病诊断工具的研发，解决数据稀缺问题，并验证了合成数据在实际场景中的适用性。

Abstract: Although computer-aided diagnosis (CADx) and detection (CADe) systems have
made significant progress in various medical domains, their application is
still limited in specialized fields such as otorhinolaryngology. In the latter,
current assessment methods heavily depend on operator expertise, and the high
heterogeneity of lesions complicates diagnosis, with biopsy persisting as the
gold standard despite its substantial costs and risks. A critical bottleneck
for specialized endoscopic CADx/e systems is the lack of well-annotated
datasets with sufficient variability for real-world generalization. This study
introduces a novel approach that exploits a Latent Diffusion Model (LDM)
coupled with a ControlNet adapter to generate laryngeal endoscopic
image-annotation pairs, guided by clinical observations. The method addresses
data scarcity by conditioning the diffusion process to produce realistic,
high-quality, and clinically relevant image features that capture diverse
anatomical conditions. The proposed approach can be leveraged to expand
training datasets for CADx/e models, empowering the assessment process in
laryngology. Indeed, during a downstream task of detection, the addition of
only 10% synthetic data improved the detection rate of laryngeal lesions by 9%
when the model was internally tested and 22.1% on out-of-domain external data.
Additionally, the realism of the generated images was evaluated by asking 5
expert otorhinolaryngologists with varying expertise to rate their confidence
in distinguishing synthetic from real images. This work has the potential to
accelerate the development of automated tools for laryngeal disease diagnosis,
offering a solution to data scarcity and demonstrating the applicability of
synthetic data in real-world scenarios.

</details>


### [279] [Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification](https://arxiv.org/abs/2508.06287)
*Mobarak Abumohsen,Enrique Costa-Montenegro,Silvia García-Méndez,Amani Yousef Owda,Majdi Owda*

Main category: eess.IV

TL;DR: 本文提出了一种基于DenseNet201模型的创新方法，用于从CT图像中检测和分类肺癌，通过Focal Loss、数据增强和正则化等技术解决了数据不平衡和过拟合问题，实现了98.95%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 肺癌是全球范围内常见的致命癌症，CT图像因其低成本和处理速度快成为主要诊断方法，但现有技术因数据不平衡导致高假阳性率和低准确率。

Method: 采用DenseNet201模型，结合Focal Loss、数据增强和正则化技术，以解决数据不平衡和过拟合问题。

Result: 实验结果表明，该方法达到了98.95%的高准确率。

Conclusion: 提出的方法在肺癌检测和分类中表现出色，为解决数据不平衡和过拟合问题提供了有效方案。

Abstract: Lung cancer (LC) ranks among the most frequently diagnosed cancers and is one
of the most common causes of death for men and women worldwide. Computed
Tomography (CT) images are the most preferred diagnosis method because of their
low cost and their faster processing times. Many researchers have proposed
various ways of identifying lung cancer using CT images. However, such
techniques suffer from significant false positives, leading to low accuracy.
The fundamental reason results from employing a small and imbalanced dataset.
This paper introduces an innovative approach for LC detection and
classification from CT images based on the DenseNet201 model. Our approach
comprises several advanced methods such as Focal Loss, data augmentation, and
regularization to overcome the imbalanced data issue and overfitting challenge.
The findings show the appropriateness of the proposal, attaining a promising
performance of 98.95% accuracy.

</details>


### [280] [Multivariate Fields of Experts](https://arxiv.org/abs/2508.06490)
*Stanislas Ducotterd,Michael Unser*

Main category: eess.IV

TL;DR: 提出了一种基于多元专家场的新图像先验学习框架，通过引入多元势函数提升性能。


<details>
  <summary>Details</summary>
Motivation: 扩展现有专家场方法，提升图像先验学习的效果。

Method: 利用Moreau包络的ℓ∞范数构建多元势函数，应用于多种逆问题。

Result: 在去噪、去模糊、压缩感知MRI和CT等任务中表现优异，优于单变量模型，接近深度学习正则化器性能，且更高效、参数更少、数据需求更低。

Conclusion: 该方法在性能和效率上取得平衡，同时保持较高的可解释性。

Abstract: We introduce the multivariate fields of experts, a new framework for the
learning of image priors. Our model generalizes existing fields of experts
methods by incorporating multivariate potential functions constructed via
Moreau envelopes of the $\ell_\infty$-norm. We demonstrate the effectiveness of
our proposal across a range of inverse problems that include image denoising,
deblurring, compressed-sensing magnetic-resonance imaging, and computed
tomography. The proposed approach outperforms comparable univariate models and
achieves performance close to that of deep-learning-based regularizers while
being significantly faster, requiring fewer parameters, and being trained on
substantially fewer data. In addition, our model retains a relatively high
level of interpretability due to its structured design.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [281] [NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference](https://arxiv.org/abs/2508.05835)
*Edresson Casanova,Paarth Neekhara,Ryan Langman,Shehzeen Hussain,Subhankar Ghosh,Xuesong Yang,Ante Jukić,Jason Li,Boris Ginsburg*

Main category: eess.AS

TL;DR: NanoCodec是一种新型低帧率音频编解码器，显著提升语音LLM的训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有音频编解码器帧率高，导致自回归模型训练和推理速度慢，需探索低帧率方案。

Method: 通过消融研究分析帧率、比特率和因果性对编解码质量的影响，并开发NanoCodec。

Result: NanoCodec在12.5 FPS下实现高质量压缩，优于现有方案，成为低延迟高效语音LLM的新基准。

Conclusion: NanoCodec为语音LLM提供了一种高效、低延迟的音频编解码解决方案。

Abstract: Large Language Models (LLMs) have significantly advanced audio processing by
leveraging audio codecs to discretize audio into tokens, enabling the
application of language modeling techniques to speech data. However, existing
audio codecs often operate at high frame rates, leading to slow training and
inference, particularly for autoregressive models. To address this, there is
growing interest in low frame-rate audio codecs, which reduce the number of
autoregressive steps required to generate one second of audio. In this paper,
we conduct ablation studies to examine the impact of frame rate, bitrate, and
causality on codec reconstruction quality. Based on our findings, we introduce
NanoCodec, a state-of-the-art audio codec that achieves high-quality
compression at just 12.5 frames per second (FPS). NanoCodec outperforms related
works across various bitrate ranges, establishing a new benchmark for
low-latency and efficient Speech LLM training and inference.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [282] [Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification](https://arxiv.org/abs/2508.06118)
*Daniil Vlasenko,Vadim Ushakov,Alexey Zaikin,Denis Zakharov*

Main category: q-bio.NC

TL;DR: 提出了一种基于图表示的fMRI数据分类方法，通过集成多个机器学习模型构建图，显著提高了脑状态分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于神经影像数据的高维性和噪声问题，理解和分类人类认知脑状态是一个重要且具有挑战性的任务。

Method: 利用多个基础机器学习模型构建图，边权重反映两种认知状态的后验概率差异，范围在[-1, 1]之间。

Result: 在HCP数据集上，平均分类准确率达到97.07%至99.74%，优于传统相关性图方法。

Conclusion: 集成图方法提供了更丰富的拓扑信息，增强了脑状态区分能力，并具有可解释性和扩展性。

Abstract: Understanding and classifying human cognitive brain states based on
neuroimaging data remains one of the foremost and most challenging problems in
neuroscience, owing to the high dimensionality and intrinsic noise of the
signals. In this work, we propose an ensemble-based graph representation method
of functional magnetic resonance imaging (fMRI) data for the task of binary
brain-state classification. Our method builds the graph by leveraging multiple
base machine-learning models: each edge weight reflects the difference in
posterior probabilities between two cognitive states, yielding values in the
range [-1, 1] that encode confidence in a given state. We applied this approach
to seven cognitive tasks from the Human Connectome Project (HCP 1200 Subject
Release), including working memory, gambling, motor activity, language, social
cognition, relational processing, and emotion processing. Using only the mean
incident edge weights of the graphs as features, a simple logistic-regression
classifier achieved average accuracies from 97.07% to 99.74%. We also compared
our ensemble graphs with classical correlation-based graphs in a classification
task with a graph neural network (GNN). In all experiments, the highest
classification accuracy was obtained with ensemble graphs. These results
demonstrate that ensemble graphs convey richer topological information and
enhance brain-state discrimination. Our approach preserves edge-level
interpretability of the fMRI graph representation, is adaptable to multiclass
and regression tasks, and can be extended to other neuroimaging modalities and
pathological-state classification.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [283] [On Approximate MMS Allocations on Restricted Graph Classes](https://arxiv.org/abs/2508.06343)
*Václav Blažej,Michał Dębski ad Zbigniew Lonc,Marta Piecyk,Paweł Rzążewski*

Main category: cs.DM

TL;DR: 研究在连通性约束下不可分割物品的公平分配问题，探讨近似分配的存在性。


<details>
  <summary>Details</summary>
Motivation: 解决在连通性约束下公平分配物品的问题，尤其是在某些图类中近似分配的存在性。

Method: 假设物品表示为连通图的顶点，分配的子图需连通，研究近似分配的存在性。

Result: 证明在块图、仙人掌图、完全多部图和分裂图等图类中存在近似分配。

Conclusion: 扩展了近似分配的存在性结果，为更多图类提供了理论支持。

Abstract: We study the problem of fair division of a set of indivisible goods with
connectivity constraints. Specifically, we assume that the goods are
represented as vertices of a connected graph, and sets of goods allocated to
the agents are connected subgraphs of this graph. We focus on the
widely-studied maximin share criterion of fairness. It has been shown that an
allocation satisfying this criterion may not exist even without connectivity
constraints, i.e., if the graph of goods is complete. In view of this, it is
natural to seek approximate allocations that guarantee each agent a connected
bundle of goods with value at least a constant fraction of the maximin share
value to the agent. It is known that for some classes of graphs, such as
complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such
approximate allocations indeed exist. However, it is an open problem whether
they exist for the class of all graphs.
  In this paper, we continue the systematic study of the existence of
approximate allocations on restricted graph classes. In particular, we show
that such allocations exist for several well-studied classes, including block
graphs, cacti, complete multipartite graphs, and split graphs.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [284] [Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach](https://arxiv.org/abs/2508.05693)
*Siamak Farshidi,Amir Saberhabibi,Behbod Eskafi,Niloofar Nikfarjam,Sadegh Eskandari,Slinger Jansen,Michel Chaudron,Bedir Tekinerdogan*

Main category: cs.SE

TL;DR: 论文提出了一种基于多准则决策（MCDM）的数据驱动框架PySelect，用于解决开源生态系统中第三方软件包选择的挑战，结合AI辅助意图建模，提高了推荐质量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 开源生态系统中软件包选择困难，现有生成式AI工具依赖流行度而非适用性，缺乏透明性和可重复性。

Method: 通过自动化数据管道收集软件元数据、使用趋势、漏洞信息和开发者情感，构建决策模型，并开发PySelect系统辅助决策。

Result: 实验表明，框架数据提取精度高，推荐质量优于生成式AI基线，用户评价积极。

Conclusion: 该框架为软件包选择提供了可扩展、可解释且可重复的解决方案，支持基于证据的决策。

Abstract: Selecting third-party software packages in open-source ecosystems like Python
is challenging due to the large number of alternatives and limited transparent
evidence for comparison. Generative AI tools are increasingly used in
development workflows, but their suggestions often overlook dependency
evaluation, emphasize popularity over suitability, and lack reproducibility.
This creates risks for projects that require transparency, long-term
reliability, maintainability, and informed architectural decisions. This study
formulates software package selection as a Multi-Criteria Decision-Making
(MCDM) problem and proposes a data-driven framework for technology evaluation.
Automated data pipelines continuously collect and integrate software metadata,
usage trends, vulnerability information, and developer sentiment from GitHub,
PyPI, and Stack Overflow. These data are structured into a decision model
representing relationships among packages, domain features, and quality
attributes. The framework is implemented in PySelect, a decision support system
that uses large language models to interpret user intent and query the model to
identify contextually appropriate packages. The approach is evaluated using
798,669 Python scripts from 16,887 GitHub repositories and a user study based
on the Technology Acceptance Model. Results show high data extraction
precision, improved recommendation quality over generative AI baselines, and
positive user evaluations of usefulness and ease of use. This work introduces a
scalable, interpretable, and reproducible framework that supports
evidence-based software selection using MCDM principles, empirical data, and
AI-assisted intent modeling.

</details>


### [285] [Position: Intelligent Coding Systems Should Write Programs with Justifications](https://arxiv.org/abs/2508.06017)
*Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 智能编码系统通过自然语言生成代码，但AI决策不透明引发信任问题。作者提出需生成清晰解释，并探索神经符号方法以改进。


<details>
  <summary>Details</summary>
Motivation: 解决AI驱动编码系统因决策不透明导致的信任和可用性问题，特别是非专家用户的需求。

Method: 提出认知对齐和语义忠实性作为关键解释属性，探索神经符号方法结合符号约束和神经表示。

Result: 现有方法（如形式验证、静态分析）存在局限，神经符号方法有望生成更一致的解释。

Conclusion: 智能编码系统应生成清晰解释，神经符号方法是实现这一目标的有前景的方向。

Abstract: Intelligent coding systems are transforming software development by enabling
users to specify code behavior in natural language. However, the opaque
decision-making of AI-driven coders raises trust and usability concerns,
particularly for non-expert users who cannot inspect low-level implementations.
We argue that these systems should not only generate code but also produce
clear, consistent justifications that bridge model reasoning and user
understanding. To this end, we identify two critical justification
properties-cognitive alignment and semantic faithfulness-and highlight the
limitations of existing methods, including formal verification, static
analysis, and post-hoc explainability. We advocate exploring neuro-symbolic
approaches for justification generation, where symbolic constraints guide model
behavior during training and program semantics are enriched through neural
representations, enabling automated consistency checks at inference time.

</details>


### [286] [Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning](https://arxiv.org/abs/2508.05710)
*Jia Fu,Xinyu Yang,Hongzhi Zhang,Yahui Liu,Jingyuan Zhang,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.SE

TL;DR: Klear-CodeTest是一个用于代码强化学习的测试用例合成框架，通过生成-验证（G-V）机制和多层安全沙箱系统，提高了测试用例的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在代码强化学习中，高质量的测试用例对训练大型语言模型至关重要，但目前合成高质量测试用例仍是一个未解决的难题。

Method: 采用生成-验证（G-V）框架，通过一致性验证机制生成全面的测试用例，包括常规和边界情况，并设计了多层安全沙箱系统以确保代码执行的安全性和可靠性。

Result: 实验表明，该方法显著提升了模型性能和训练稳定性，并提供了开源代码、数据集和沙箱系统。

Conclusion: Klear-CodeTest通过创新的G-V框架和安全沙箱系统，有效解决了测试用例合成的难题，为代码强化学习提供了高质量的训练反馈。

Abstract: Precise, correct feedback is crucial for effectively training large language
models (LLMs) in code reinforcement learning. However, synthesizing
high-quality test cases remains a profoundly challenging and unsolved problem.
In this work, we present Klear-CodeTest, a comprehensive test case synthesis
framework featuring rigorous verification to ensure quality and reliability of
test cases. Our approach achieves broad coverage of programming problems via a
novel Generator-Validation (G-V) framework, ensuring correctness through a
consistency validation mechanism that verifies outputs against gold solutions.
The proposed G-V framework generates comprehensive test cases including both
regular and corner cases, enhancing test coverage and discriminative power for
solution correctness assessment in code reinforcement learning. In addition, we
design a multi-layered security sandbox system optimized for online
verification platforms, guaranteeing safe and reliable code execution. Through
comprehensive experiments, we demonstrate the effectiveness of our curated
dataset, showing significant improvements in model performance and training
stability. The source codes, curated dataset and sandbox system are available
at: https://github.com/Kwai-Klear/CodeTest.

</details>


### [287] [AI-Guided Exploration of Large-Scale Codebases](https://arxiv.org/abs/2508.05799)
*Yoseph Berhanu Alebachew*

Main category: cs.SE

TL;DR: 提出了一种结合确定性逆向工程与LLM引导的意图感知可视化探索的混合方法，用于提升代码理解效率。


<details>
  <summary>Details</summary>
Motivation: 开发者花费大量时间理解复杂软件系统，传统工具缺乏交互性和上下文整合，LLMs虽先进但缺乏结构化视图的集成。

Method: 结合UML可视化、动态用户界面、历史上下文和协作功能，通过LLM解析用户查询和交互模式。

Result: 原型实现展示了方法的可行性，未来工作包括实证评估和多语言系统扩展。

Conclusion: 为智能、交互式开发环境奠定了基础，符合开发者认知和协作需求。

Abstract: Understanding large-scale, complex software systems is a major challenge for
developers, who spend a significant portion of their time on program
comprehension. Traditional tools such as static visualizations and reverse
engineering techniques provide structural insights but often lack
interactivity, adaptability, and integration with contextual information.
Recent advancements in large language models (LLMs) offer new opportunities to
enhance code exploration workflows, yet their lack of grounding and integration
with structured views limits their effectiveness. This work introduces a hybrid
approach that integrates deterministic reverse engineering with LLM-guided,
intent-aware visual exploration. The proposed system combines UML-based
visualization, dynamic user interfaces, historical context, and collaborative
features into an adaptive tool for code comprehension. By interpreting user
queries and interaction patterns, the LLM helps developers navigate and
understand complex codebases more effectively. A prototype implementation for
Java demonstrates the feasibility of this approach. Future work includes
empirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM
interaction models. This research lays the groundwork for intelligent,
interactive environments that align with developer cognition and collaborative
workflows.

</details>


### [288] [Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm](https://arxiv.org/abs/2508.05923)
*Yanusha Mehendran,Maolin Tang,Yi Lu*

Main category: cs.SE

TL;DR: 该研究提出了一种基于遗传算法的测试输入生成方法，结合遗传操作和自适应学习，显著提升了软件漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: 随着软件复杂性的增加，传统漏洞检测方法已无法满足需求，需要更高效的方法。

Method: 采用遗传算法，结合交叉操作和自适应反馈机制，动态生成有效的测试输入。

Result: 在九个开源JSON处理库的测试中，该方法在覆盖率上显著优于基准方法，最高提升166%。

Conclusion: 该方法能够检测更深层次和更复杂的漏洞，为软件安全测试提供了可扩展的解决方案。

Abstract: Software vulnerabilities continue to undermine the reliability and security
of modern systems, particularly as software complexity outpaces the
capabilities of traditional detection methods. This study introduces a genetic
algorithm-based method for test input generation that innovatively integrates
genetic operators and adaptive learning to enhance software vulnerability
detection. A key contribution is the application of the crossover operator,
which facilitates exploration by searching across a broader space of potential
test inputs. Complementing this, an adaptive feedback mechanism continuously
learns from the system's execution behavior and dynamically guides input
generation toward promising areas of the input space. Rather than relying on
fixed or randomly selected inputs, the approach evolves a population of
structurally valid test cases using feedback-driven selection, enabling deeper
and more effective code traversal. This strategic integration of exploration
and exploitation ensures that both diverse and targeted test inputs are
developed over time. Evaluation was conducted across nine open-source
JSON-processing libraries. The proposed method achieved substantial
improvements in coverage compared to a benchmark evolutionary fuzzing method,
with average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%
in line coverage, 114.0% in instruction coverage, and 166.0% in branch
coverage. These results highlight the method's capacity to detect deeper and
more complex vulnerabilities, offering a scalable and adaptive solution to
software security testing.

</details>


### [289] [Impact-driven Context Filtering For Cross-file Code Completion](https://arxiv.org/abs/2508.05970)
*Yanzhou Li,Shangqing Liu,Kangjie Chen,Tianwei Zhang,Yang Liu*

Main category: cs.SE

TL;DR: CODEFILTER通过自适应过滤检索到的代码块，提升代码补全的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究检索增强生成（RAG）在代码补全中的作用，发现检索到的代码块中只有少数对补全有积极贡献，部分甚至降低性能。

Method: 提出基于似然的评估指标，构建标记数据集，并设计自适应过滤框架CODEFILTER。

Result: 在多个基准测试中，CODEFILTER显著提高补全准确性并减少输入提示长度。

Conclusion: CODEFILTER能有效提升代码补全的准确性、效率和可归因性。

Abstract: Retrieval-augmented generation (RAG) has recently demonstrated considerable
potential for repository-level code completion, as it integrates cross-file
knowledge with in-file preceding code to provide comprehensive contexts for
generation. To better understand the contribution of the retrieved cross-file
contexts, we introduce a likelihood-based metric to evaluate the impact of each
retrieved code chunk on the completion. Our analysis reveals that, despite
retrieving numerous chunks, only a small subset positively contributes to the
completion, while some chunks even degrade performance. To address this issue,
we leverage this metric to construct a repository-level dataset where each
retrieved chunk is labeled as positive, neutral, or negative based on its
relevance to the target completion. We then propose an adaptive retrieval
context filtering framework, CODEFILTER, trained on this dataset to mitigate
the harmful effects of negative retrieved contexts in code completion.
Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks
demonstrates that CODEFILTER consistently improves completion accuracy compared
to approaches without filtering operations across various tasks. Additionally,
CODEFILTER significantly reduces the length of the input prompt, enhancing
computational efficiency while exhibiting strong generalizability across
different models. These results underscore the potential of CODEFILTER to
enhance the accuracy, efficiency, and attributability of repository-level code
completion.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [290] [Blockchain-Enabled Federated Learning](https://arxiv.org/abs/2508.06406)
*Murtaza Rangwala,Venugopal K R,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 区块链联邦学习（BCFL）解决了协作AI系统中的信任、隐私和协调问题，通过四维分类法分析其架构设计，包括协调结构、共识机制、存储架构和信任模型。


<details>
  <summary>Details</summary>
Motivation: 解决协作AI系统中的信任、隐私和协调问题，提升联邦学习的效率和安全性。

Method: 通过四维分类法分析BCFL系统设计，包括协调结构、共识机制、存储架构和信任模型，并结合TrustMesh框架进行技术案例研究。

Result: BCFL系统在实际应用中表现出与集中式方法相当的性能，同时提供更强的安全性和透明性。

Conclusion: BCFL系统在医疗、金融和物联网安全等领域具有实际可行性，为协作AI提供了新的信任模型。

Abstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges
of trust, privacy, and coordination in collaborative AI systems. This chapter
provides comprehensive architectural analysis of BCFL systems through a
systematic four-dimensional taxonomy examining coordination structures,
consensus mechanisms, storage architectures, and trust models. We analyze
design patterns from blockchain-verified centralized coordination to fully
decentralized peer-to-peer networks, evaluating trade-offs in scalability,
security, and performance. Through detailed examination of consensus mechanisms
designed for federated learning contexts, including Proof of Quality and Proof
of Federated Learning, we demonstrate how computational work can be repurposed
from arbitrary cryptographic puzzles to productive machine learning tasks. The
chapter addresses critical storage challenges by examining multi-tier
architectures that balance blockchain's transaction constraints with neural
networks' large parameter requirements while maintaining cryptographic
integrity. A technical case study of the TrustMesh framework illustrates
practical implementation considerations in BCFL systems through distributed
image classification training, demonstrating effective collaborative learning
across IoT devices with highly non-IID data distributions while maintaining
complete transparency and fault tolerance. Analysis of real-world deployments
across healthcare consortiums, financial services, and IoT security
applications validates the practical viability of BCFL systems, achieving
performance comparable to centralized approaches while providing enhanced
security guarantees and enabling new models of trustless collaborative
intelligence.

</details>


### [291] [KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training](https://arxiv.org/abs/2508.06001)
*Kai Zhang,Peng Wang,Sai Bi,Jianming Zhang,Yuanjun Xiong*

Main category: cs.DC

TL;DR: KnapFormer是一个高效框架，结合工作负载平衡和序列并行，优化分布式训练中的Diffusion Transformers（DiT）。通过解决全局背包问题，最小化GPU间工作负载差异，显著提升训练速度。


<details>
  <summary>Details</summary>
Motivation: 解决分布式训练中因变长文本输入和多分辨率图像-视频联合训练导致的令牌不平衡问题，避免拖尾效应。

Method: 收集序列长度元数据，解决全局背包问题以平衡工作负载，结合DeepSpeed-Ulysees序列并行和半经验工作负载模型。

Result: 在真实训练中实现小于1%的工作负载差异，消除拖尾效应，训练速度提升2-3倍。

Conclusion: KnapFormer有效优化了DiT的分布式训练，适用于复杂数据场景，代码已开源。

Abstract: We present KnapFormer, an efficient and versatile framework to combine
workload balancing and sequence parallelism in distributed training of
Diffusion Transformers (DiT). KnapFormer builds on the insight that strong
synergy exists between sequence parallelism and the need to address the
significant token imbalance across ranks. This imbalance arises from
variable-length text inputs and varying visual token counts in mixed-resolution
and image-video joint training. KnapFormer redistributes tokens by first
gathering sequence length metadata across all ranks in a balancing group and
solving a global knapsack problem. The solver aims to minimize the variances of
total workload per-GPU, while accounting for the effect of sequence
parallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the
load-balancing decision process and utilizing a simple semi-empirical workload
model, KnapFormers achieves minimal communication overhead and less than 1%
workload discrepancy in real-world training workloads with sequence length
varying from a few hundred to tens of thousands. It eliminates straggler
effects and achieves 2x to 3x speedup when training state-of-the-art diffusion
models like FLUX on mixed-resolution and image-video joint data corpora. We
open-source the KnapFormer implementation at
https://github.com/Kai-46/KnapFormer/

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [292] [SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques](https://arxiv.org/abs/2507.12286)
*Anouk Oudshoorn,Magdalena Ortiz,Mantas Simkus*

Main category: cs.LO

TL;DR: 论文探讨了SHACL和OWL在RDF数据管理中的结合，提出了一种基于核心通用模型的语义方法，并研究了其计算复杂性。


<details>
  <summary>Details</summary>
Motivation: SHACL和OWL在RDF数据管理中各有优势，但它们的语义差异（开放世界与封闭世界假设）导致结合困难。论文旨在填补这一语义鸿沟。

Method: 提出基于核心通用模型的语义方法，开发了一种重写技术，将SHACL验证问题转化为标准验证问题。

Result: 证明了即使简单本体也会使SHACL验证问题成为EXPTIME完全问题，数据复杂性为PTIME完全。

Conclusion: 论文为SHACL与OWL的结合提供了可行的语义和计算方法，但计算复杂性仍需关注。

Abstract: SHACL and OWL are two prominent W3C standards for managing RDF data. These
languages share many features, but they have one fundamental difference: OWL,
designed for inferring facts from incomplete data, makes the open-world
assumption, whereas SHACL is a constraint language that treats the data as
complete and must be validated under the closed-world assumption. The
combination of both formalisms is very appealing and has been called for, but
their semantic gap is a major challenge, semantically and computationally. In
this paper, we advocate a semantics for SHACL validation in the presence of
ontologies based on core universal models. We provide a technique for
constructing these models for ontologies in the rich data-tractable description
logic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to
develop a rewriting technique that reduces SHACL validation in the presence of
ontologies to standard validation. Finally, we study the complexity of SHACL
validation in the presence of ontologies, and show that even very simple
ontologies make the problem EXPTIME-complete, and PTIME-complete in data
complexity.

</details>


### [293] [Basic interactive algorithms: Preview](https://arxiv.org/abs/2508.05798)
*Yuri Gurevich*

Main category: cs.LO

TL;DR: 本文预览了即将发表的工作，探讨基本交互式算法的公理化，并比较了两种Church-Turing论题版本。


<details>
  <summary>Details</summary>
Motivation: 现代算法概念在20世纪30-50年代被阐明，并在25年前被公理化为“基本算法”。本文旨在扩展这一公理化框架，以涵盖更广泛的算法类型（如概率、量子算法）。

Method: 通过将非确定性和概率算法视为带有适当预言机的基本算法，展示了如何统一处理多种算法类型。

Result: 证明了多种算法（如量子电路算法）可以纳入基本算法的框架，并强调了两种Church-Turing论题的区别。

Conclusion: 基本算法的公理化框架具有广泛适用性，能够统一描述多种现代算法类型。

Abstract: This dialog paper offers a preview and provides a foretaste of an upcoming
work on the axiomatization of basic interactive algorithms.
  The modern notion of algorithm was elucidated in the 1930s--1950s. It was
axiomatized a quarter of a century ago as the notion of ``sequential
algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm"
now. The axiomatization was used to show that for every basic algorithm there
is a behaviorally equivalent abstract state machine. It was also used to prove
the Church-Turing thesis as it has been understood by the logicians.
  Starting from the 1960s, the notion of algorithm has expanded --
probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of
a much more ambitious version of the Church-Turing thesis commonly known as the
``physical thesis.'' We emphasize the difference between the two versions of
the Church-Turing thesis and illustrate how nondeterministic and probabilistic
algorithms can be viewed as basic algorithms with appropriate oracles. The same
view applies to quantum circuit algorithms and many other classes of
algorithms.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [294] [Evaluating Universal Machine Learning Force Fields Against Experimental Measurements](https://arxiv.org/abs/2508.05762)
*Sajid Mannan,Vaibhav Bihani,Carmelo Gonzales,Kin Long Kelvin Lee,Nitya Nand Gosvami,Sayan Ranu,Santiago Miret,N M Anoop Krishnan*

Main category: cond-mat.mtrl-sci

TL;DR: UniFFBench框架评估了六种先进的通用机器学习力场（UMLFFs），发现其在实验复杂性下的表现远低于计算基准测试的预期。


<details>
  <summary>Details</summary>
Motivation: 评估UMLFFs在实际实验数据中的表现，揭示计算基准测试与真实世界性能之间的差距。

Method: 使用UniFFBench框架，对1,500多种矿物结构的实验数据进行了系统评估。

Result: 模型在计算基准测试中表现优异，但在实验复杂性下表现不佳，预测误差高于实际应用阈值。

Conclusion: 当前计算基准测试可能高估模型可靠性，需改进以应对实验复杂性，实现真正的通用力场能力。

Abstract: Universal machine learning force fields (UMLFFs) promise to revolutionize
materials science by enabling rapid atomistic simulations across the periodic
table. However, their evaluation has been limited to computational benchmarks
that may not reflect real-world performance. Here, we present UniFFBench, a
comprehensive framework for evaluating UMLFFs against experimental measurements
of ~1,500 carefully curated mineral structures spanning diverse chemical
environments, bonding types, structural complexity, and elastic properties. Our
systematic evaluation of six state-of-the-art UMLFFs reveals a substantial
reality gap: models achieving impressive performance on computational
benchmarks often fail when confronted with experimental complexity. Even the
best-performing models exhibit higher density prediction error than the
threshold required for practical applications. Most strikingly, we observe
disconnects between simulation stability and mechanical property accuracy, with
prediction errors correlating with training data representation rather than the
modeling method. These findings demonstrate that while current computational
benchmarks provide valuable controlled comparisons, they may overestimate model
reliability when extrapolated to experimentally complex chemical spaces.
Altogether, UniFFBench establishes essential experimental validation standards
and reveals systematic limitations that must be addressed to achieve truly
universal force field capabilities.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [295] [Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications](https://arxiv.org/abs/2508.06131)
*Philip Anton Hernicht,Alona Sakhnenko,Corey O'Meara,Giorgio Cortiana,Jeanette Miriam Lorenz*

Main category: quant-ph

TL;DR: 该论文提出了一种轻量级方法，通过经典替代模型绕过量子硬件限制，使量子机器学习解决方案能够在经典设备上部署。


<details>
  <summary>Details</summary>
Motivation: 量子硬件访问受限是量子机器学习工业应用的主要瓶颈，需要一种方法在不依赖量子硬件的情况下部署量子模型。

Method: 提出了一种新的管道，减少了先前方法的高计算需求，通过最小化冗余资源，实现更大规模的经典替代模型生成。

Result: 在真实能源需求预测问题上验证了方法的有效性，计算资源需求呈线性而非指数增长，同时保持高准确性。

Conclusion: 该方法为量子解决方案提供了轻量级经典部署途径，加速量子技术在工业中的应用，并可作为寻找实际量子优势的研究工具。

Abstract: Quantum machine learning (QML) presents potential for early industrial
adoption, yet limited access to quantum hardware remains a significant
bottleneck for deployment of QML solutions. This work explores the use of
classical surrogates to bypass this restriction, which is a technique that
allows to build a lightweight classical representation of a (trained) quantum
model, enabling to perform inference on entirely classical devices. We reveal
prohibiting high computational demand associated with previously proposed
methods for generating classical surrogates from quantum models, and propose an
alternative pipeline enabling generation of classical surrogates at a larger
scale than was previously possible. Previous methods required at least a
high-performance computing (HPC) system for quantum models of below industrial
scale (ca. 20 qubits), which raises questions about its practicality. We
greatly minimize the redundancies of the previous approach, utilizing only a
minute fraction of the resources previously needed. We demonstrate the
effectiveness of our method on a real-world energy demand forecasting problem,
conducting rigorous testing of performance and computation demand in both
simulations and on quantum hardware. Our results indicate that our method
achieves high accuracy on the testing dataset while its computational resource
requirements scale linearly rather than exponentially. This work presents a
lightweight approach to transform quantum solutions into classically deployable
versions, facilitating faster integration of quantum technology in industrial
settings. Furthermore, it can serve as a powerful research tool in search
practical quantum advantage in an empirical setup.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [296] [Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance](https://arxiv.org/abs/2508.06052)
*Haruto Nakashima,Siddhartha Ganguly,Kenji Kashima*

Main category: math.OC

TL;DR: 使用Gromov-Wasserstein度量解决数据驱动的机会约束密度控制问题，通过DC算法高效求解。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用预操作实验数据解决未知线性控制递归系统的密度控制问题。

Method: 将初始状态建模为高斯混合，终端状态需匹配指定高斯分布，并将最优控制问题转化为凸差规划。

Result: 数值结果表明该方法在各种数据驱动方案中有效。

Conclusion: 提出的方法能高效解决数据驱动的机会约束密度控制问题。

Abstract: We tackle the data-driven chance-constrained density steering problem using
the Gromov-Wasserstein metric. The underlying dynamical system is an unknown
linear controlled recursion, with the assumption that sufficiently rich
input-output data from pre-operational experiments are available. The initial
state is modeled as a Gaussian mixture, while the terminal state is required to
match a specified Gaussian distribution. We reformulate the resulting optimal
control problem as a difference-of-convex program and show that it can be
efficiently and tractably solved using the DC algorithm. Numerical results
validate our approach through various data-driven schemes.

</details>


### [297] [LLM Serving Optimization with Variable Prefill and Decode Lengths](https://arxiv.org/abs/2508.06133)
*Meixuan Wang,Yinyu Ye,Zijie Zhou*

Main category: math.OC

TL;DR: 研究如何调度异构预填充和解码长度的LLM请求以最小化总完成时间，提出新算法并证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM请求的预填充和解码长度不同，导致内存使用动态变化，现有调度策略在内存需求大时性能下降。

Method: 分析现有策略（如FCFS和SF）的局限性，提出基于新选择度量的算法，并开发多种变体（如动态规划、局部搜索和LP调度器）。

Result: 新算法具有恒定竞争比，仿真显示其优于标准基线且计算高效。

Conclusion: 提出的算法有效解决了LLM请求调度问题，性能优于现有方法。

Abstract: We study the problem of serving LLM (Large Language Model) requests where
each request has heterogeneous prefill and decode lengths. In LLM serving, the
prefill length corresponds to the input prompt length, which determines the
initial memory usage in the KV cache. The decode length refers to the number of
output tokens generated sequentially, with each additional token increasing the
KV cache memory usage by one unit. Given a set of n requests, our goal is to
schedule and process them to minimize the total completion time. We show that
this problem is NP-hard due to the interplay of batching, placement
constraints, precedence relationships, and linearly increasing memory usage. We
then analyze commonly used scheduling strategies in practice, such as
First-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their
competitive ratios scale up sublinearly with the memory limit-a significant
drawback in real-world settings where memory demand is large. To address this,
we propose a novel algorithm based on a new selection metric that efficiently
forms batches over time. We prove that this algorithm achieves a constant
competitive ratio. Finally, we develop and evaluate a few algorithm variants
inspired by this approach, including dynamic programming variants, local search
methods, and an LP-based scheduler, demonstrating through comprehensive
simulations that they outperform standard baselines while maintaining
computational efficiency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [298] [Semantic Item Graph Enhancement for Multimodal Recommendation](https://arxiv.org/abs/2508.06154)
*Xiaoxiong Zhang,Xin Zhou,Zhiwei Zeng,Dusit Niyato,Zhiqi Shen*

Main category: cs.IR

TL;DR: 论文提出了一种多模态推荐系统框架，通过增强语义建模和噪声鲁棒性来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态推荐系统中存在语义不足和结构噪声问题，影响性能。

Method: 提取交互图中的协作信号注入语义图，设计基于模量的个性化嵌入扰动和双重表示对齐机制。

Result: 在四个基准数据集上的实验验证了框架的有效性。

Conclusion: 所提方法通过增强语义建模和噪声鲁棒性，显著提升了推荐系统性能。

Abstract: Multimodal recommendation systems have attracted increasing attention for
their improved performance by leveraging items' multimodal information. Prior
methods often build modality-specific item-item semantic graphs from raw
modality features and use them as supplementary structures alongside the
user-item interaction graph to enhance user preference learning. However, these
semantic graphs suffer from semantic deficiencies, including (1) insufficient
modeling of collaborative signals among items and (2) structural distortions
introduced by noise in raw modality features, ultimately compromising
performance. To address these issues, we first extract collaborative signals
from the interaction graph and infuse them into each modality-specific item
semantic graph to enhance semantic modeling. Then, we design a modulus-based
personalized embedding perturbation mechanism that injects perturbations with
modulus-guided personalized intensity into embeddings to generate contrastive
views. This enables the model to learn noise-robust representations through
contrastive learning, thereby reducing the effect of structural noise in
semantic graphs. Besides, we propose a dual representation alignment mechanism
that first aligns multiple semantic representations via a designed Anchor-based
InfoNCE loss using behavior representations as anchors, and then aligns
behavior representations with the fused semantics by standard InfoNCE, to
ensure representation consistency. Extensive experiments on four benchmark
datasets validate the effectiveness of our framework.

</details>


### [299] [G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation](https://arxiv.org/abs/2508.05709)
*Boyu Chen,Siran Chen,Zhengrong Yue,Kainan Yan,Chenyun Yu,Beibei Kong,Cheng Lei,Chengxiang Zhuo,Zang Li,Yali Wang*

Main category: cs.IR

TL;DR: 论文提出了一种名为G-UBS的新范式，通过用户群体上下文指导，从隐式反馈中更准确地推断用户偏好，显著提升了视频推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 显式用户反馈稀缺，而隐式反馈虽丰富但存在噪声，容易误判用户兴趣，影响推荐效果。

Method: G-UBS包含两个关键模块：用户群体管理器（UGM）通过LLM生成群体画像，用户反馈建模器（UFM）采用群体感知的强化学习方法深入分析隐式反馈。

Result: 在IF-VR基准测试中，G-UBS表现优于主流模型，播放率>30%的视频比例提高4.0%，推理准确率提高14.9%。

Conclusion: G-UBS通过群体上下文指导，显著提升了隐式反馈的解读能力和推荐系统的性能。

Abstract: User feedback is critical for refining recommendation systems, yet explicit
feedback (e.g., likes or dislikes) remains scarce in practice. As a more
feasible alternative, inferring user preferences from massive implicit feedback
has shown great potential (e.g., a user quickly skipping a recommended video
usually indicates disinterest). Unfortunately, implicit feedback is often
noisy: a user might skip a video due to accidental clicks or other reasons,
rather than disliking it. Such noise can easily misjudge user interests,
thereby undermining recommendation performance. To address this issue, we
propose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which
leverages contextual guidance from relevant user groups, enabling robust and
in-depth interpretation of implicit feedback for individual users.
Specifically, G-UBS operates via two key agents. First, the User Group Manager
(UGM) effectively clusters users to generate group profiles utilizing a
``summarize-cluster-reflect" workflow based on LLMs. Second, the User Feedback
Modeler (UFM) employs an innovative group-aware reinforcement learning
approach, where each user is guided by the associated group profiles during the
reinforcement learning process, allowing UFM to robustly and deeply examine the
reasons behind implicit feedback. To assess our G-UBS paradigm, we have
constructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To
the best of our knowledge, this is the first multi-modal benchmark for implicit
feedback evaluation in video recommendation, encompassing 15k users, 25k
videos, and 933k interaction records with implicit feedback. Extensive
experiments on IF-VR demonstrate that G-UBS significantly outperforms
mainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a
play rate > 30% and 14.9% higher reasoning accuracy on IF-VR.

</details>


### [300] [Request-Only Optimization for Recommendation Systems](https://arxiv.org/abs/2508.05640)
*Liang Guo,Wei Li,Lucy Liao,Huihui Cheng,Rui Zhang,Yu Shi,Yueming Wang,Yanzun Huang,Keke Zhai,Pengchao Wang,Timothy Shi,Xuan Cao,Shengzhi Wang,Renqin Cai,Zhaojie Gong,Omkar Vichare,Rui Jian,Leon Gao,Shiyan Deng,Xingyu Liu,Xiong Zhang,Fu Li,Wenlei Xie,Bin Wen,Rui Li,Xing Liu,Jiaqi Zhai*

Main category: cs.IR

TL;DR: 论文提出了一种名为ROO（Request-Only Optimizations）的训练和建模范式，通过将用户请求作为训练数据单元，优化存储、训练效率和模型质量。


<details>
  <summary>Details</summary>
Motivation: 工业级深度推荐模型（DLRMs）规模庞大，需要处理海量数据和复杂计算，现有方法在存储和训练效率上存在瓶颈。

Method: ROO范式通过协同设计数据（请求专用数据）、基础设施（基于请求的数据处理管道）和模型架构（请求专用神经网络架构），实现高效训练。

Result: ROO范式在数据存储和训练效率上显著提升，同时支持更复杂的神经网络架构（如生成式推荐器）以更好地捕捉用户兴趣信号。

Conclusion: ROO为大规模推荐系统提供了一种高效、可扩展的解决方案，显著提升了模型质量和系统性能。

Abstract: Deep Learning Recommendation Models (DLRMs) represent one of the largest
machine learning applications on the planet. Industry-scale DLRMs are trained
with petabytes of recommendation data to serve billions of users every day. To
utilize the rich user signals in the long user history, DLRMs have been scaled
up to unprecedented complexity, up to trillions of floating-point operations
(TFLOPs) per example. This scale, coupled with the huge amount of training
data, necessitates new storage and training algorithms to efficiently improve
the quality of these complex recommendation systems. In this paper, we present
a Request-Only Optimizations (ROO) training and modeling paradigm. ROO
simultaneously improves the storage and training efficiency as well as the
model quality of recommendation systems. We holistically approach this
challenge through co-designing data (i.e., request-only data), infrastructure
(i.e., request-only based data processing pipeline), and model architecture
(i.e., request-only neural architectures). Our ROO training and modeling
paradigm treats a user request as a unit of the training data. Compared with
the established practice of treating a user impression as a unit, our new
design achieves native feature deduplication in data logging, consequently
saving data storage. Second, by de-duplicating computations and communications
across multiple impressions in a request, this new paradigm enables highly
scaled-up neural network architectures to better capture user interest signals,
such as Generative Recommenders (GRs) and other request-only friendly
architectures.

</details>


### [301] [Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05647)
*Vibhor Agrawal,Fay Wang,Rishi Puri*

Main category: cs.IR

TL;DR: 提出了一种新颖的图神经网络架构，用于检索增强生成，通过查询感知注意力机制和学习评分头提高复杂多跳问题的检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统密集检索方法将文档视为独立实体，无法捕捉文本块之间的序列和语义关系，限制了复杂问题的检索效果。

Method: 构建每集知识图谱，引入增强图注意力网络和查询引导池化，动态聚焦于与查询相关的图谱部分。

Result: 在复杂问答任务中显著优于标准密集检索方法，尤其在需要多文档推理的问题上表现突出。

Conclusion: 该方法通过高效处理图结构数据，为生产检索系统提供了可扩展的解决方案。

Abstract: We present a novel graph neural network (GNN) architecture for
retrieval-augmented generation (RAG) that leverages query-aware attention
mechanisms and learned scoring heads to improve retrieval accuracy on complex,
multi-hop questions. Unlike traditional dense retrieval methods that treat
documents as independent entities, our approach constructs per-episode
knowledge graphs that capture both sequential and semantic relationships
between text chunks. We introduce an Enhanced Graph Attention Network with
query-guided pooling that dynamically focuses on relevant parts of the graph
based on user queries. Experimental results demonstrate that our approach
significantly outperforms standard dense retrievers on complex question
answering tasks, particularly for questions requiring multi-document reasoning.
Our implementation leverages PyTorch Geometric for efficient processing of
graph-structured data, enabling scalable deployment in production retrieval
systems

</details>


### [302] [AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups](https://arxiv.org/abs/2508.05648)
*Chandler Campbell,Bernie Boscoe,Tuan Do*

Main category: cs.IR

TL;DR: AquiLLM是一个轻量级、模块化的RAG系统，旨在帮助研究团队更好地捕获、存储和检索分散的集体知识，包括非正式和私密资源。


<details>
  <summary>Details</summary>
Motivation: 研究团队在管理分散的、非正式的知识（如会议记录、培训材料等）方面面临挑战，现有RAG系统多关注公开文档，忽视隐私需求。

Method: 开发AquiLLM，支持多种文档类型和可配置的隐私设置，结合RAG技术提升知识检索效率。

Result: AquiLLM为研究团队提供了更有效的知识访问工具，兼顾正式与非正式资源。

Conclusion: AquiLLM填补了现有RAG系统在隐私和内部知识管理方面的空白，适合学术团队使用。

Abstract: Research groups face persistent challenges in capturing, storing, and
retrieving knowledge that is distributed across team members. Although
structured data intended for analysis and publication is often well managed,
much of a group's collective knowledge remains informal, fragmented, or
undocumented--often passed down orally through meetings, mentoring, and
day-to-day collaboration. This includes private resources such as emails,
meeting notes, training materials, and ad hoc documentation. Together, these
reflect the group's tacit knowledge--the informal, experience-based expertise
that underlies much of their work. Accessing this knowledge can be difficult,
requiring significant time and insider understanding. Retrieval-augmented
generation (RAG) systems offer promising solutions by enabling users to query
and generate responses grounded in relevant source material. However, most
current RAG-LLM systems are oriented toward public documents and overlook the
privacy concerns of internal research materials. We introduce AquiLLM
(pronounced ah-quill-em), a lightweight, modular RAG system designed to meet
the needs of research groups. AquiLLM supports varied document types and
configurable privacy settings, enabling more effective access to both formal
and informal knowledge within scholarly groups.

</details>


### [303] [OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools](https://arxiv.org/abs/2508.05650)
*Jiaxuan Liang,Shide Zhou,Kailong Wang*

Main category: cs.IR

TL;DR: OmniBench RAG是一个自动化平台，用于多领域评估检索增强生成（RAG）系统，提供标准化指标以量化性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法缺乏领域覆盖、精确度不足且无法标准化比较RAG效果。

Method: 平台采用动态测试生成、模块化评估流程和自动化知识库构建，引入两种标准化指标：Improvements（准确性提升）和Transformation（效率差异）。

Result: 评估显示RAG效果在不同领域差异显著，如文化领域显著提升而数学领域下降。

Conclusion: 系统化、领域感知的评估对RAG性能至关重要，OmniBench RAG为此提供了标准化框架。

Abstract: While Retrieval Augmented Generation (RAG) is now widely adopted to enhance
LLMs, evaluating its true performance benefits in a reproducible and
interpretable way remains a major hurdle. Existing methods often fall short:
they lack domain coverage, employ coarse metrics that miss sub document
precision, and fail to capture computational trade offs. Most critically, they
provide no standardized framework for comparing RAG effectiveness across
different models and domains.
  We introduce OmniBench RAG, a novel automated platform for multi domain
evaluation of RAG systems. The platform quantifies performance gains across
accuracy and efficiency dimensions, spanning nine knowledge fields including
culture, geography, and health. We introduce two standardized metrics:
Improvements (accuracy gains) and Transformation (efficiency differences
between pre RAG and post RAG models), enabling reproducible comparisons across
models and tasks. The platform features dynamic test generation, modular
evaluation pipelines, and automated knowledge base construction. Our evaluation
reveals striking variability in RAG effectiveness, from significant gains in
culture to declines in mathematics, highlighting the critical importance of
systematic, domain aware assessment. A demonstration video is available at:
https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:
https://github.com/Garnett-Liang/Omnibench-RAG.

</details>


### [304] [Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation](https://arxiv.org/abs/2508.05652)
*Julia Ann Mathew,Suining He*

Main category: cs.IR

TL;DR: 论文探讨了基于LLM和RAG的户外步道推荐聊天机器人Judy的开发，解决了提供准确信息和高效推荐服务的挑战。


<details>
  <summary>Details</summary>
Motivation: 户外休闲活动的增加推动了对话式AI系统的需求，以提供个性化和信息丰富的步道建议。

Method: 通过LLM和RAG技术开发Judy聊天机器人，并进行案例研究（CT步道）、数据收集和模型性能分析。

Result: 实验证明Judy在准确性、有效性和可用性方面表现良好。

Conclusion: Judy展示了LLM与RAG结合在户外步道推荐中的潜力。

Abstract: The increasing popularity of outdoor recreational activities (such as hiking
and biking) has boosted the demand for a conversational AI system to provide
informative and personalized suggestion on outdoor trails. Challenges arise in
response to (1) how to provide accurate outdoor trail information via
conversational AI; and (2) how to enable usable and efficient recommendation
services. To address above, this paper discusses the preliminary and practical
lessons learned from developing Judy, an outdoor trail recommendation chatbot
based on the large language model (LLM) with retrieval augmented generation
(RAG). To gain concrete system insights, we have performed case studies with
the outdoor trails in Connecticut (CT), US. We have conducted web-based data
collection, outdoor trail data management, and LLM model performance studies on
the RAG-based recommendation. Our experimental results have demonstrated the
accuracy, effectiveness, and usability of Judy in recommending outdoor trails
based on the LLM with RAG.

</details>


### [305] [Comparison of Information Retrieval Techniques Applied to IT Support Tickets](https://arxiv.org/abs/2508.05654)
*Leonardo Santiago Benitez Pereira,Robinson Pizzio,Samir Bonho*

Main category: cs.IR

TL;DR: 论文比较了11种信息检索技术在IT支持工单数据集上的表现，目标是开发一个辅助IT支持分析师的软件。Sentence-BERT在多语言版本中表现最佳，推荐相关率达78.7%。


<details>
  <summary>Details</summary>
Motivation: IT帮助台系统对依赖IT服务的机构至关重要，但现有机器学习模型在不同数据集上表现不一，需优化以提升支持效率。

Method: 比较了11种信息检索技术（如Sentence-BERT、TF-IDF、Word2vec、LDA），并开发了一个最小可行原型系统。

Result: Sentence-BERT（多语言版）表现最佳（78.7%相关推荐），其他技术如TF-IDF（69.0%）、Word2vec（68.7%）和LDA（66.3%）也表现稳定。

Conclusion: 研究证明了支持工单检索系统的实用性，并提出了新的评估指标以反映IT分析师对检索质量的感知。数据集和代码已开源。

Abstract: Institutions dependent on IT services and resources acknowledge the crucial
significance of an IT help desk system, that act as a centralized hub
connecting IT staff and users for service requests. Employing various Machine
Learning models, these IT help desk systems allow access to corrective actions
used in the past, but each model has different performance when applied to
different datasets. This work compares eleven Information Retrieval techniques
in a dataset of IT support tickets, with the goal of implementing a software
that facilitates the work of Information Technology support analysts. The best
results were obtained with the Sentence-BERT technique, in its multi-language
variation distilluse-base-multilingual-cased-v1, where 78.7% of the
recommendations made by the model were considered relevant. TF-IDF (69.0%),
Word2vec (68.7%) and LDA (66.3%) techniques also had consistent results.
Furthermore, the used datasets and essential parts of coding have been
published and made open source. It also demonstrated the practicality of a
support ticket recovery system by implementing a minimal viable prototype, and
described in detail the implementation of the system. Finally, this work
proposed a novel metric for comparing the techniques, whose aim is to closely
reflect the perception of the IT analysts about the retrieval quality.

</details>


### [306] [Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation](https://arxiv.org/abs/2508.05657)
*Haozhe Xu,Xiaohua Wang,Changze Lv,Xiaoqing Zheng*

Main category: cs.IR

TL;DR: 论文提出了一种新的数据增强框架，通过LLM语义检索和两阶段训练策略解决CRS中的假阴性问题，显著提升了推荐性能。


<details>
  <summary>Details</summary>
Motivation: 解决对话推荐系统中假阴性问题，即用户可能喜欢的项目被错误标记为负面，导致推荐效果不佳。

Method: 提出基于LLM的语义检索器识别多样化且语义相关的项目，并通过相关性评分器过滤噪声候选，采用两阶段训练策略平衡语义相关性和协作信息。

Result: 在两个基准数据集和用户模拟器上的实验表明，该方法显著提升了各种推荐器的性能。

Conclusion: 该框架有效解决了CRS中的假阴性问题，为提升推荐系统性能提供了新思路。

Abstract: Conversational recommender systems (CRSs) enhance recommendation quality by
engaging users in multi-turn dialogues, capturing nuanced preferences through
natural language interactions. However, these systems often face the false
negative issue, where items that a user might like are incorrectly labeled as
negative during training, leading to suboptimal recommendations.Expanding the
label set through data augmentation presents an intuitive solution but faces
the challenge of balancing two key aspects: ensuring semantic relevance and
preserving the collaborative information inherent in CRS datasets. To address
these issues, we propose a novel data augmentation framework that first
leverages an LLM-based semantic retriever to identify diverse and semantically
relevant items, which are then filtered by a relevance scorer to remove noisy
candidates. Building on this, we introduce a two-stage training strategy
balancing semantic relevance and collaborative information. Extensive
experiments on two benchmark datasets and user simulators demonstrate
significant and consistent performance improvements across various
recommenders, highlighting the effectiveness of our approach in advancing CRS
performance.

</details>


### [307] [Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review](https://arxiv.org/abs/2508.05660)
*Aditya Nagori,Ricardo Accorsi Casonatto,Ayush Gautam,Abhinav Manikantha Sai Cheruvu,Rishikesan Kamaleswaran*

Main category: cs.IR

TL;DR: 论文提出了一种动态混合检索增强生成（RAG）系统，通过自主代理动态选择图检索或向量检索，实时调整生成内容，并量化不确定性，显著提升了检索相关性和生成质量。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长使得传统综述方法难以应对，需要结合结构化元数据和全文分析的工具。现有混合RAG系统通常是静态的，依赖专有工具且缺乏不确定性估计。

Method: 系统整合了PubMed、arXiv和Google Scholar的数据，构建了基于Neo4j的引用知识图和FAISS向量存储。使用Llama-3.3-70B代理动态选择图检索或向量检索，并通过指令调优优化生成内容。

Result: 在模拟真实查询的基准测试中，系统在多个指标上显著优于基线，如上下文召回率提升0.63，整体上下文精确度提升0.56。

Conclusion: 该系统通过动态选择和不确定性量化，显著提升了科学发现的效率和可扩展性。

Abstract: The surge in scientific publications challenges traditional review methods,
demanding tools that integrate structured metadata with full-text analysis.
Hybrid Retrieval Augmented Generation (RAG) systems, combining graph queries
with vector search offer promise but are typically static, rely on proprietary
tools, and lack uncertainty estimates. We present an agentic approach that
encapsulates the hybrid RAG pipeline within an autonomous agent capable of (1)
dynamically selecting between GraphRAG and VectorRAG for each query, (2)
adapting instruction-tuned generation in real time to researcher needs, and (3)
quantifying uncertainty during inference. This dynamic orchestration improves
relevance, reduces hallucinations, and promotes reproducibility.
  Our pipeline ingests bibliometric open-access data from PubMed, arXiv, and
Google Scholar APIs, builds a Neo4j citation-based knowledge graph (KG), and
embeds full-text PDFs into a FAISS vector store (VS) using the all-MiniLM-L6-v2
model. A Llama-3.3-70B agent selects GraphRAG (translating queries to Cypher
for KG) or VectorRAG (combining sparse and dense retrieval with re-ranking).
Instruction tuning refines domain-specific generation, and bootstrapped
evaluation yields standard deviation for evaluation metrics.
  On synthetic benchmarks mimicking real-world queries, the Instruction-Tuned
Agent with Direct Preference Optimization (DPO) outperforms the baseline,
achieving a gain of 0.63 in VS Context Recall and a 0.56 gain in overall
Context Precision. Additional gains include 0.24 in VS Faithfulness, 0.12 in
both VS Precision and KG Answer Relevance, 0.11 in overall Faithfulness score,
0.05 in KG Context Recall, and 0.04 in both VS Answer Relevance and overall
Precision. These results highlight the system's improved reasoning over
heterogeneous sources and establish a scalable framework for autonomous,
agentic scientific discovery.

</details>


### [308] [Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace](https://arxiv.org/abs/2508.05661)
*Andre Rusli,Shoma Ishimoto,Sho Akiyama,Aman Kumar Singh*

Main category: cs.IR

TL;DR: 论文介绍了一个在Mercari C2C市场中部署的可扩展视觉搜索系统，评估了零样本图像检索的视觉语言模型，并展示了SigLIP模型在性能和实际应用中的优势。


<details>
  <summary>Details</summary>
Motivation: 在C2C市场中，产品目录通常是非结构化和视觉驱动的，因此需要一个直观的视觉搜索系统来提升用户体验和交易效率。

Method: 系统集成了实时推理和后台索引工作流，通过统一的嵌入管道和降维优化，评估了多种零样本模型，并与现有基线进行了比较。

Result: SigLIP模型在离线评估中表现最佳，nDCG@5提升了13.3%；在线A/B测试中，交易率通过图像搜索提升了40.9%。

Conclusion: 零样本模型可以作为生产环境的强基线，既能快速部署，又保留了未来微调的灵活性。

Abstract: Visual search offers an intuitive way for customers to explore diverse
product catalogs, particularly in consumer-to-consumer (C2C) marketplaces where
listings are often unstructured and visually driven. This paper presents a
scalable visual search system deployed in Mercari's C2C marketplace, where
end-users act as buyers and sellers. We evaluate recent vision-language models
for zero-shot image retrieval and compare their performance with an existing
fine-tuned baseline. The system integrates real-time inference and background
indexing workflows, supported by a unified embedding pipeline optimized through
dimensionality reduction. Offline evaluation using user interaction logs shows
that the multilingual SigLIP model outperforms other models across multiple
retrieval metrics, achieving a 13.3% increase in nDCG@5 over the baseline. A
one-week online A/B test in production further confirms real-world impact, with
the treatment group showing substantial gains in engagement and conversion, up
to a 40.9% increase in transaction rate via image search. Our findings
highlight that recent zero-shot models can serve as a strong and practical
baseline for production use, which enables teams to deploy effective visual
search systems with minimal overhead, while retaining the flexibility to
fine-tune based on future data or domain-specific needs.

</details>


### [309] [From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base](https://arxiv.org/abs/2508.05662)
*Yuzhou Zhu*

Main category: cs.IR

TL;DR: Streaming RAG是一种动态检索增强框架，通过多向量余弦筛选、小批量聚类和计数器过滤技术，解决了静态RAG框架在数据新鲜度、内存成本和语义覆盖上的不足。实验表明其在召回率、延迟和吞吐量上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 静态RAG框架在处理动态数据流时存在高内存成本、数据延迟和语义覆盖不足的问题，需要一种更高效的动态解决方案。

Method: Streaming RAG结合了多向量余弦筛选、小批量聚类和计数器过滤技术，并采用增量索引更新机制，以保持紧凑的原型集。

Result: 在8个实时数据流实验中，Streaming RAG显著提升了Recall@10（最高3点），延迟低于15毫秒，吞吐量超过900文档/秒（150 MB内存预算）。在问答和摘要任务中，性能也有显著提升。

Conclusion: Streaming RAG为动态数据流检索增强建立了新的帕累托前沿，平衡了性能与资源消耗。

Abstract: Dynamic streams from news feeds, social media, sensor networks, and financial
markets challenge static RAG frameworks. Full-scale indices incur high memory
costs; periodic rebuilds introduce latency that undermines data freshness;
naive sampling sacrifices semantic coverage. We present Streaming RAG, a
unified pipeline that combines multi-vector cosine screening, mini-batch
clustering, and a counter-based heavy-hitter filter to maintain a compact
prototype set. We further prove an approximation bound \$E\[R(K\_t)] \ge R^\* -
L \Delta\$ linking retrieval quality to clustering variance. An incremental
index upsert mechanism refreshes prototypes without interrupting queries.
Experiments on eight real-time streams show statistically significant gains in
Recall\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and
throughput above 900 documents per second under a 150 MB budget. Hyperparameter
sensitivity analysis over cluster count, admission probability, relevance
threshold, and counter capacity validates default settings. In open-domain
question answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match
and 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L
improvements. Streaming RAG establishes a new Pareto frontier for retrieval
augmentation.

</details>


### [310] [Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support](https://arxiv.org/abs/2508.05664)
*Hei Yu Chan,Kuok Tou Ho,Chenglong Ma,Yujing Si,Hok Lai Lin,Sa Lei Lam*

Main category: cs.IR

TL;DR: 论文评估了多种技术（如查询重写、RAG Fusion、意图识别等）在电力领域构建强大客服系统的效果，最终选择基于图的RAG框架，并结合意图识别、RAG Fusion和重排名，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI客服系统在模糊、多意图或细节查询上的不足，提升电力领域客服系统的鲁棒性。

Method: 比较向量存储和图基RAG框架，结合查询重写、RAG Fusion、意图识别和重排名等技术。

Result: 在GPT-4生成数据集和真实FAQ数据集上分别达到97.9%和89.6%的准确率，显著优于基线RAG模型。

Conclusion: 基于图的RAG框架结合意图识别、RAG Fusion和重排名是处理复杂查询的有效方案。

Abstract: Many AI customer service systems use standard NLP pipelines or finetuned
language models, which often fall short on ambiguous, multi-intent, or
detail-specific queries. This case study evaluates recent techniques: query
rewriting, RAG Fusion, keyword augmentation, intent recognition, and context
reranking, for building a robust customer support system in the electric power
domain. We compare vector-store and graph-based RAG frameworks, ultimately
selecting the graph-based RAG for its superior performance in handling complex
queries. We find that query rewriting improves retrieval for queries using
non-standard terminology or requiring precise detail. RAG Fusion boosts
performance on vague or multifaceted queries by merging multiple retrievals.
Reranking reduces hallucinations by filtering irrelevant contexts. Intent
recognition supports the decomposition of complex questions into more targeted
sub-queries, increasing both relevance and efficiency. In contrast, keyword
augmentation negatively impacts results due to biased keyword selection. Our
final system combines intent recognition, RAG Fusion, and reranking to handle
disambiguation and multi-source queries. Evaluated on both a GPT-4-generated
dataset and a real-world electricity provider FAQ dataset, it achieves 97.9%
and 89.6% accuracy respectively, substantially outperforming baseline RAG
models.

</details>


### [311] [HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis](https://arxiv.org/abs/2508.05666)
*Alejandro Godinez*

Main category: cs.IR

TL;DR: HySemRAG结合ETL和RAG，通过多层检索、自我修正和引用验证，自动化大规模文献合成并识别研究空白。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG架构的局限性，提升文献合成的准确性和可追溯性。

Method: 采用混合检索、代理自我修正框架和引用验证，通过八阶段流程处理文献。

Result: 在643次测试中，语义相似度得分提高35.1%，引用准确率达99%。

Conclusion: HySemRAG在科学领域具有广泛应用潜力，可加速证据合成和发现。

Abstract: We present HySemRAG, a framework that combines Extract, Transform, Load (ETL)
pipelines with Retrieval-Augmented Generation (RAG) to automate large-scale
literature synthesis and identify methodological research gaps. The system
addresses limitations in existing RAG architectures through a multi-layered
approach: hybrid retrieval combining semantic search, keyword filtering, and
knowledge graph traversal; an agentic self-correction framework with iterative
quality assurance; and post-hoc citation verification ensuring complete
traceability. Our implementation processes scholarly literature through eight
integrated stages: multi-source metadata acquisition, asynchronous PDF
retrieval, custom document layout analysis using modified Docling architecture,
bibliographic management, LLM-based field extraction, topic modeling, semantic
unification, and knowledge graph construction. The system creates dual data
products - a Neo4j knowledge graph enabling complex relationship queries and
Qdrant vector collections supporting semantic search - serving as foundational
infrastructure for verifiable information synthesis. Evaluation across 643
observations from 60 testing sessions demonstrates structured field extraction
achieving 35.1% higher semantic similarity scores (0.655 $\pm$ 0.178) compared
to PDF chunking approaches (0.485 $\pm$ 0.204, p < 0.000001). The agentic
quality assurance mechanism achieves 68.3% single-pass success rates with 99.0%
citation accuracy in validated responses. Applied to geospatial epidemiology
literature on ozone exposure and cardiovascular disease, the system identifies
methodological trends and research gaps, demonstrating broad applicability
across scientific domains for accelerating evidence synthesis and discovery.

</details>


### [312] [ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations](https://arxiv.org/abs/2508.05667)
*Zekun Liu,Xiaowen Huang,Jitao Sang*

Main category: cs.IR

TL;DR: 论文提出了一种名为ITDR的指令调优数据集，用于提升大语言模型在推荐任务中的性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言处理任务中表现优异，但在推荐系统中因数据结构差异难以有效建模用户偏好与物品关联。

Method: 构建ITDR数据集，包含7个子任务和20万实例，基于13个公开推荐数据集，使用标准化模板。

Result: ITDR显著提升了主流开源大语言模型在推荐任务中的性能，并分析了任务相关性及数据规模的影响。

Conclusion: ITDR数据集和调优模型有效解决了大语言模型在推荐系统中的性能限制，代码和数据已开源。

Abstract: Large language models (LLMs) have demonstrated outstanding performance in
natural language processing tasks. However, in the field of recommendation
systems, due to the structural differences between user behavior data and
natural language, LLMs struggle to effectively model the associations between
user preferences and items. Although prompt-based methods can generate
recommendation results, their inadequate understanding of recommendation tasks
leads to constrained performance. To address this gap, in this work, we
construct a sufficient instruction tuning dataset, ITDR, which encompasses 7
subtasks across two core root tasks--user-item interaction and user-item
understanding. The dataset integrates data from 13 public recommendation
datasets and is built using manually crafted standardized templates, comprising
approximately 200,000 instances. Experimental results demonstrate that ITDR
significantly enhances the performance of mainstream open-source LLMs such as
GLM-4, Qwen2.5, Qwen2.5-Instruct and LLaMA-3.2 on recommendation tasks.
Furthermore, we analyze the correlations between tasks and explore the impact
of task descriptions and data scale on instruction tuning effectiveness.
Finally, we perform comparative experiments against closed-source LLMs with
substantial parameters. Our tuning dataset ITDR and the fine-tuned large
recommendation models can be accessed at https://github.com/hellolzk/ITDR.

</details>


### [313] [A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges](https://arxiv.org/abs/2508.05668)
*Yunjia Xi,Jianghao Lin,Yongzhao Xiao,Zheli Zhou,Rong Shan,Te Gao,Jiachen Zhu,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.IR

TL;DR: 本文综述了基于大语言模型（LLM）的搜索代理，分析了其架构、优化、应用和评估，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探索LLM搜索代理在动态、自主信息检索中的潜力及其对网络搜索的革命性影响。

Method: 系统分析现有研究，从架构、优化、应用和评估四个角度分类。

Result: 总结了搜索代理的关键挑战和未来研究方向。

Conclusion: LLM搜索代理具有广阔前景，但仍需解决开放性问题以推动其发展。

Abstract: The advent of Large Language Models (LLMs) has significantly revolutionized
web search. The emergence of LLM-based Search Agents marks a pivotal shift
towards deeper, dynamic, autonomous information seeking. These agents can
comprehend user intentions and environmental context and execute multi-turn
retrieval with dynamic planning, extending search capabilities far beyond the
web. Leading examples like OpenAI's Deep Research highlight their potential for
deep information mining and real-world applications. This survey provides the
first systematic analysis of search agents. We comprehensively analyze and
categorize existing works from the perspectives of architecture, optimization,
application, and evaluation, ultimately identifying critical open challenges
and outlining promising future research directions in this rapidly evolving
field. Our repository is available on
https://github.com/YunjiaXi/Awesome-Search-Agent-Papers.

</details>


### [314] [Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports](https://arxiv.org/abs/2508.05669)
*Jin Khye Tan,En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah*

Main category: cs.IR

TL;DR: 该研究提出了一种基于Qwen2.5-VL-7B优化的视觉语言模型，用于将马来西亚审计财务报告中的表格转换为Markdown格式，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 财务文档中表格结构的准确提取和表示是文档理解中的关键挑战，尤其是在监管和分析场景中。

Method: 使用微调的视觉语言模型（VLM），结合2,152个图像-文本对的数据集和LoRA监督微调策略，评估采用LLM作为评判标准和新的Markdown TEDS指标。

Result: 模型在标准评估中达到92.20%的准确率，Markdown TEDS得分为96.53%，优于基础模型和其他大型模型。

Conclusion: 领域特定的微调方法能高效地将非结构化财务文档转化为自动化下游任务所需的结构化数据，性能优于大型通用模型。

Abstract: Accurately extracting and representing the structure of tabular data from
financial documents remains a critical challenge in document understanding,
particularly for regulatory and analytical use cases. This study addresses the
complexity of converting financial tables from Malaysian audited financial
reports into Markdown format, a task complicated by rotated layouts,
multi-level headers, and implicit structural cues. We propose a fine-tuned
vision-language model (VLM), based on Qwen2.5-VL-7B, optimized for
high-fidelity Markdown generation from document images. Our approach includes a
curated dataset of 2,152 image-text pairs with augmentations and a supervised
fine-tuning strategy using LoRA. To assess performance, we evaluated our model
on 100 out-of-sample tables using a dual framework: a criteria-based
LLM-as-a-judge for fine-grained accuracy and our novel Markdown
Tree-Edit-Distance-based Similarity (TEDS) metric for holistic structural
fidelity. Our model achieves a 92.20% overall accuracy on the criteria-based
assessment and a 96.53% Markdown TEDS score. This performance significantly
surpasses its Qwen2.5-VL-7B base model, larger-scale VLMs, and specialized
reasoning-enabled models. Compared to these self-hosted alternatives, it also
significantly reduces inference time. Furthermore, its accuracy exceeds that of
widely used proprietary models such as OpenAI's GPT-4o and Gemini 2.5 Flash.
These results demonstrate that domain-specific fine-tuning provides an
effective and efficient method to bridge the gap between unstructured financial
documents and downstream automation, rivalling much larger and more general
models without their computational overhead.

</details>


### [315] [LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing](https://arxiv.org/abs/2508.05672)
*Yao Zhao,Yantian Ding,Zhiyue Zhang,Dapeng Yao,Yanxun Xu*

Main category: cs.IR

TL;DR: LMAR框架通过LLM引导的数据合成和对比嵌入适应，解决了RAG系统在领域特定知识中的性能问题，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: RAG系统在领域特定知识中表现不佳，主要由于预训练嵌入的性能下降和LLM检索器的高计算成本。

Method: LMAR采用两阶段流程：LLM引导的三元组采样与合成数据增强，结合对比嵌入适应和高效文本聚类。

Result: 实验表明，LMAR在多个领域特定基准数据集上优于基线模型，且硬件需求适中、延迟低。

Conclusion: LMAR是一种实用且经济高效的解决方案，适用于领域特定知识的可扩展适应。

Abstract: Retrieval Augmented Generation (RAG) systems often struggle with
domain-specific knowledge due to performance deterioration of pre-trained
embeddings and prohibitive computational costs of large language model
(LLM)-based retrievers. While fine-tuning data augmentation embedding models
offers a promising direction, its effectiveness is limited by the need for
high-quality training data and reliable chunking strategies that preserve
contextual integrity. We propose LMAR (Language Model Augmented Retriever), a
model-agnostic framework that addresses these challenges by combining
LLM-guided data synthesis with contrastive embedding adaptation and efficient
text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling
and synthetic data augmentation, where LLMs act as both labeler and validator
to ensure high-fidelity supervision throughout the pipeline. Experimental
results across multiple domain-specific benchmark datasets demonstrate that
LMAR outperforms multiple baseline models, while maintaining moderate hardware
requirements and low latency. Its model-agnostic nature further enables
seamless integration with emerging RAG architectures and text embedding models,
ensuring continual improvements without redesigning the pipeline. These results
highlight LMAR as a practical and cost-effective solution for scalable
domain-specific adaptation.

</details>


### [316] [Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems](https://arxiv.org/abs/2508.05673)
*Weiqin Yang,Jiawei Chen,Shengjia Zhang,Peng Wu,Yuegang Sun,Yan Feng,Chun Chen,Can Wang*

Main category: cs.IR

TL;DR: 论文提出了一种名为SoftmaxLoss@K（SL@K）的新损失函数，用于优化推荐系统中的NDCG@K指标，解决了现有方法的计算成本高和训练不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统中，NDCG@K是评估推荐性能的黄金标准，但其优化存在挑战，包括不连续性和Top-K截断问题。现有方法要么忽略截断问题，要么计算成本高且不稳定。

Method: 通过结合分位数技术处理Top-K截断，并推导出一个平滑上界来优化NDCG@K，提出了SL@K损失函数。

Result: 在四个真实数据集和三个推荐骨干上的实验表明，SL@K平均提升了6.03%，优于现有方法。

Conclusion: SL@K具有理论保证、易于实现、计算高效、梯度稳定和噪声鲁棒性等优点，为NDCG@K优化提供了有效解决方案。

Abstract: In the realm of recommender systems (RS), Top-$K$ ranking metrics such as
NDCG@$K$ are the gold standard for evaluating recommendation performance.
However, during the training of recommendation models, optimizing NDCG@$K$
poses significant challenges due to its inherent discontinuous nature and the
intricate Top-$K$ truncation. Recent efforts to optimize NDCG@$K$ have either
overlooked the Top-$K$ truncation or suffered from high computational costs and
training instability. To overcome these limitations, we propose SoftmaxLoss@$K$
(SL@$K$), a novel recommendation loss tailored for NDCG@$K$ optimization.
Specifically, we integrate the quantile technique to handle Top-$K$ truncation
and derive a smooth upper bound for optimizing NDCG@$K$ to address
discontinuity. The resulting SL@$K$ loss has several desirable properties,
including theoretical guarantees, ease of implementation, computational
efficiency, gradient stability, and noise robustness. Extensive experiments on
four real-world datasets and three recommendation backbones demonstrate that
SL@$K$ outperforms existing losses with a notable average improvement of 6.03%.
The code is available at https://github.com/Tiny-Snow/IR-Benchmark.

</details>


### [317] [AI Guided Accelerator For Search Experience](https://arxiv.org/abs/2508.05649)
*Jayanth Yetukuri,Mehran Elyasi,Samarth Agrawal,Aritra Mandal,Rui Kong,Harish Vempati,Ishita Khan*

Main category: cs.IR

TL;DR: 论文提出了一种新框架，通过建模用户搜索过程中的过渡性查询，结合生成式大语言模型（LLMs）提升电商搜索效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法将查询改写视为孤立对，无法捕捉用户行为的序列性和动态性，导致搜索效果不佳。

Method: 通过挖掘eBay用户交互日志中的结构化查询轨迹，建模用户购物漏斗，并利用LLMs生成语义多样且意图保留的替代查询。

Result: 实证评估显示，该方法在转化率和参与度指标上优于现有模块。

Conclusion: 该框架有效提升了电商环境中用户搜索的相关性和发现性。

Abstract: Effective query reformulation is pivotal in narrowing the gap between a
user's exploratory search behavior and the identification of relevant products
in e-commerce environments. While traditional approaches predominantly model
query rewrites as isolated pairs, they often fail to capture the sequential and
transitional dynamics inherent in real-world user behavior. In this work, we
propose a novel framework that explicitly models transitional
queries--intermediate reformulations occurring during the user's journey toward
their final purchase intent. By mining structured query trajectories from
eBay's large-scale user interaction logs, we reconstruct query sequences that
reflect shifts in intent while preserving semantic coherence. This approach
allows us to model a user's shopping funnel, where mid-journey transitions
reflect exploratory behavior and intent refinement. Furthermore, we incorporate
generative Large Language Models (LLMs) to produce semantically diverse and
intent-preserving alternative queries, extending beyond what can be derived
through collaborative filtering alone. These reformulations can be leveraged to
populate Related Searches or to power intent-clustered carousels on the search
results page, enhancing both discovery and engagement. Our contributions
include (i) the formal identification and modeling of transitional queries,
(ii) the introduction of a structured query sequence mining pipeline for intent
flow understanding, and (iii) the application of LLMs for scalable,
intent-aware query expansion. Empirical evaluation demonstrates measurable
gains in conversion and engagement metrics compared to the existing Related
Searches module, validating the effectiveness of our approach in real-world
e-commerce settings.

</details>


### [318] [Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness](https://arxiv.org/abs/2508.05680)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Ludwig Bothmann,Christian Heumann,Stephanie Thiemichen*

Main category: cs.IR

TL;DR: 论文研究了算法系统（如搜索引擎）在学术可见性中的性别偏见问题，提出了一种保持偏见的公平性定义，并通过德国高校数据发现男性教授在搜索结果和出版物记录上更具优势。


<details>
  <summary>Details</summary>
Motivation: 探讨算法系统是否在学术可见性中无意识地强化性别偏见，尤其是对女性学者的影响。

Method: 采用异构数据集分析学术档案的元数据完整性、出版物检索和Google搜索结果中的性别差异。

Result: 未发现明显算法歧视，但男性教授在搜索结果数量和出版物记录一致性上表现更优，女性教授的数字可见性变异性更高。

Conclusion: 研究强调需在数字系统中同时评估技术性能和代表性公平性。

Abstract: Algorithmic systems such as search engines and information retrieval
platforms significantly influence academic visibility and the dissemination of
knowledge. Despite assumptions of neutrality, these systems can reproduce or
reinforce societal biases, including those related to gender. This paper
introduces and applies a bias-preserving definition of algorithmic gender
fairness, which assesses whether algorithmic outputs reflect real-world gender
distributions without introducing or amplifying disparities. Using a
heterogeneous dataset of academic profiles from German universities and
universities of applied sciences, we analyse gender differences in metadata
completeness, publication retrieval in academic databases, and visibility in
Google search results. While we observe no overt algorithmic discrimination,
our findings reveal subtle but consistent imbalances: male professors are
associated with a greater number of search results and more aligned publication
records, while female professors display higher variability in digital
visibility. These patterns reflect the interplay between platform algorithms,
institutional curation, and individual self-presentation. Our study highlights
the need for fairness evaluations that account for both technical performance
and representational equality in digital systems.

</details>


### [319] [Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems](https://arxiv.org/abs/2508.05676)
*Han Gao,Timo Hartmann,Botao Zhong,Kai Lia,Hanbin Luo*

Main category: cs.IR

TL;DR: 比较了领域特定微调和基于提示的学习在BIM信息检索中的表现，提出混合方法以提高性能。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询在BIM环境中准确提取数据的挑战。

Method: 采用两阶段框架（意图识别和基于表格的问答），对比两种方法，构建BIM特定数据集。

Result: 领域微调在意图识别中表现更好，提示学习在问答中更优，混合方法效果最佳。

Conclusion: 混合方法在BIM信息检索中更平衡和稳健，为语言驱动的BIM系统设计提供参考。

Abstract: Building Information Modeling (BIM) is essential for managing building data
across the entire lifecycle, supporting tasks from design to maintenance.
Natural Language Interface (NLI) systems are increasingly explored as
user-friendly tools for information retrieval in Building Information Modeling
(BIM) environments. Despite their potential, accurately extracting BIM-related
data through natural language queries remains a persistent challenge due to the
complexity use queries and specificity of domain knowledge. This study presents
a comparative analysis of two prominent approaches for developing NLI-based BIM
information retrieval systems: domain-specific fine-tuning and prompt-based
learning using large language models (LLMs). A two-stage framework consisting
of intent recognition and table-based question answering is implemented to
evaluate the effectiveness of both approaches. To support this evaluation, a
BIM-specific dataset of 1,740 annotated queries of varying types across 69
models is constructed. Experimental results show that domain-specific
fine-tuning delivers superior performance in intent recognition tasks, while
prompt-based learning, particularly with GPT-4o, shows strength in table-based
question answering. Based on these findings, this study identify a hybrid
configuration that combines fine-tuning for intent recognition with
prompt-based learning for question answering, achieving more balanced and
robust performance across tasks. This integrated approach is further tested
through case studies involving BIM models of varying complexity. This study
provides a systematic analysis of the strengths and limitations of each
approach and discusses the applicability of the NLI to real-world BIM
scenarios. The findings offer insights for researchers and practitioners in
designing intelligent, language-driven BIM systems.

</details>


### [320] [Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking](https://arxiv.org/abs/2508.05700)
*Runze Su,Jiayin Jin,Jiacheng Li,Sihan Wang,Guangtong Bai,Zelun Wang,Li Tang,Yixiong Meng,Huasen Wu,Zhimeng Pan,Kungang Li,Han Sun,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar*

Main category: cs.IR

TL;DR: 论文提出了一种多面预训练方案和CPU-GPU混合服务架构，显著提升了推荐系统中大型嵌入表的性能。


<details>
  <summary>Details</summary>
Motivation: 解决在Pinterest广告排名模型中集成大型嵌入表时遇到的稀疏性、可扩展性以及初始训练效果不佳的问题。

Method: 引入多面预训练方案，结合多种预训练算法，并设计CPU-GPU混合服务架构以克服GPU内存限制。

Result: 实现了点击率（CTR）和转化率（CVR）的显著提升，在线部署后CPC降低1.34%，CTR增加2.60%。

Conclusion: 多面预训练和混合服务架构有效提升了大型嵌入表的性能，适用于实际推荐系统。

Abstract: Large embedding tables are indispensable in modern recommendation systems,
thanks to their ability to effectively capture and memorize intricate details
of interactions among diverse entities. As we explore integrating large
embedding tables into Pinterest's ads ranking models, we encountered not only
common challenges such as sparsity and scalability, but also several obstacles
unique to our context. Notably, our initial attempts to train large embedding
tables from scratch resulted in neutral metrics. To tackle this, we introduced
a novel multi-faceted pretraining scheme that incorporates multiple pretraining
algorithms. This approach greatly enriched the embedding tables and resulted in
significant performance improvements. As a result, the multi-faceted large
embedding tables bring great performance gain on both the Click-Through Rate
(CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid
serving infrastructure to overcome GPU memory limits and elevate the
scalability. This framework has been deployed in the Pinterest Ads system and
achieved 1.34% online CPC reduction and 2.60% CTR increase with neutral
end-to-end latency change.

</details>


### [321] [eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion](https://arxiv.org/abs/2508.06450)
*Daria Tikhonovich,Nikita Zelinskiy,Aleksandr V. Petrov,Mayya Spirina,Andrei Semenov,Andrey V. Savchenko,Sergei Kuliev*

Main category: cs.IR

TL;DR: 论文提出eSASRec模型，结合SASRec训练目标、LiGR Transformer层和Sampled Softmax Loss，在推荐系统中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型（如SASRec和BERT4Rec）虽表现优异，但其模块化改进的叠加效果未系统评估，本文旨在填补这一空白。

Method: 通过实验组合SASRec训练目标、LiGR Transformer层和Sampled Softmax Loss，提出eSASRec模型。

Result: eSASRec在学术基准测试中比最新模型（如ActionPiece）效果提升23%，在生产环境中表现优异，位于Pareto前沿。

Conclusion: eSASRec改进简单且无需额外特征，易于集成到现有推荐系统中，可作为强基线模型。

Abstract: Since their introduction, Transformer-based models, such as SASRec and
BERT4Rec, have become common baselines for sequential recommendations,
surpassing earlier neural and non-neural methods. A number of following
publications have shown that the effectiveness of these models can be improved
by, for example, slightly updating the architecture of the Transformer layers,
using better training objectives, and employing improved loss functions.
However, the additivity of these modular improvements has not been
systematically benchmarked - this is the gap we aim to close in this paper.
Through our experiments, we identify a very strong model that uses SASRec's
training objective, LiGR Transformer layers, and Sampled Softmax Loss. We call
this combination eSASRec (Enhanced SASRec). While we primarily focus on
realistic, production-like evaluation, in our preliminarily study we find that
common academic benchmarks show eSASRec to be 23% more effective compared to
the most recent state-of-the-art models, such as ActionPiece. In our main
production-like benchmark, eSASRec resides on the Pareto frontier in terms of
the accuracy-coverage tradeoff (alongside the recent industrial models HSTU and
FuXi. As the modifications compared to the original SASRec are relatively
straightforward and no extra features are needed (such as timestamps in HSTU),
we believe that eSASRec can be easily integrated into existing recommendation
pipelines and can can serve as a strong yet very simple baseline for emerging
complicated algorithms. To facilitate this, we provide the open-source
implementations for our models and benchmarks in repository
https://github.com/blondered/transformer_benchmark

</details>


### [322] [Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting](https://arxiv.org/abs/2508.06455)
*Nikita Sukhorukov,Danil Gusak,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出一种基于用户行为信息的特征选择策略，结合协同行为数据和混合矩阵分解技术，优化特征表示，并通过最大体积算法排名特征，以平衡推荐准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 冷启动问题需要利用辅助特征，但无关或噪声特征会降低性能，过多特征会增加计算负担。

Method: 结合协同行为数据和混合矩阵分解技术优化特征表示，用最大体积算法排名特征。

Result: 在多种数据集和混合推荐模型中表现优异，尤其在冷启动场景下，选择少量高效特征子集。

Conclusion: 该方法在严格特征缩减下仍优于现有技术，同时保持高效性。

Abstract: Cold-start challenges in recommender systems necessitate leveraging auxiliary
features beyond user-item interactions. However, the presence of irrelevant or
noisy features can degrade predictive performance, whereas an excessive number
of features increases computational demands, leading to higher memory
consumption and prolonged training times.
  To address this, we propose a feature selection strategy that prioritizes the
user behavioral information. Our method enhances the feature representation by
incorporating correlations from collaborative behavior data using a hybrid
matrix factorization technique and then ranks features using a mechanism based
on the maximum volume algorithm. This approach identifies the most influential
features, striking a balance between recommendation accuracy and computational
efficiency. We conduct an extensive evaluation across various datasets and
hybrid recommendation models, demonstrating that our method excels in
cold-start scenarios by selecting minimal yet highly effective feature subsets.
Even under strict feature reduction, our approach surpasses existing feature
selection techniques while maintaining superior efficiency.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [323] [A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes](https://arxiv.org/abs/2508.05705)
*Valentina Roquemen-Echeverri,Taisa Kushner,Peter G. Jacobs,Clara Mosquera-Lopez*

Main category: q-bio.QM

TL;DR: 提出了一种基于生理约束神经网络（NN）的数字孪生方法，用于模拟1型糖尿病（T1D）患者的葡萄糖动态，并通过真实数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模型常忽略关键生理特征且难以个性化，因此需要一种既能模拟葡萄糖动态又能个体化的方法。

Method: 结合群体水平的NN状态空间模型和个体特异性数据，构建数字孪生，并通过ODE验证其生理一致性。

Result: 模拟数据与真实数据在临床相关指标上表现等效（如时间在范围内75.1% vs 74.4%，P<0.001）。

Conclusion: 该方法支持个性化治疗测试和胰岛素优化，融合了基于物理和数据驱动的建模。

Abstract: Simulating glucose dynamics in individuals with type 1 diabetes (T1D) is
critical for developing personalized treatments and supporting data-driven
clinical decisions. Existing models often miss key physiological aspects and
are difficult to individualize. Here, we introduce physiologically-constrained
neural network (NN) digital twins to simulate glucose dynamics in T1D. To
ensure interpretability and physiological consistency, we first build a
population-level NN state-space model aligned with a set of ordinary
differential equations (ODEs) describing glucose regulation. This model is
formally verified to conform to known T1D dynamics. Digital twins are then
created by augmenting the population model with individual-specific models,
which include personal data, such as glucose management and contextual
information, capturing both inter- and intra-individual variability. We
validate our approach using real-world data from the T1D Exercise Initiative
study. Two weeks of data per participant were split into 5-hour sequences and
simulated glucose profiles were compared to observed ones. Clinically relevant
outcomes were used to assess similarity via paired equivalence t-tests with
predefined clinical equivalence margins. Across 394 digital twins, glucose
outcomes were equivalent between simulated and observed data: time in range
(70-180 mg/dL) was 75.1$\pm$21.2% (simulated) vs. 74.4$\pm$15.4% (real;
P<0.001); time below range (<70 mg/dL) 2.5$\pm$5.2% vs. 3.0$\pm$3.3% (P=0.022);
and time above range (>180 mg/dL) 22.4$\pm$22.0% vs. 22.6$\pm$15.9% (P<0.001).
Our framework can incorporate unmodeled factors like sleep and activity while
preserving key dynamics. This approach enables personalized in silico testing
of treatments, supports insulin optimization, and integrates physics-based and
data-driven modeling. Code: https://github.com/mosqueralopez/T1DSim_AI

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [324] [CLAPP: The CLASS LLM Agent for Pair Programming](https://arxiv.org/abs/2508.05728)
*Santiago Casas,Christian Fidler,Boris Bolliet,Francisco Villaescusa-Navarro,Julien Lesgourgues*

Main category: astro-ph.IM

TL;DR: CLAPP是一个基于LLM的交互式AI助手，专为使用CLASS的研究人员设计，提供编码支持、调试和绘图功能。


<details>
  <summary>Details</summary>
Motivation: 降低科学家使用AI工具的门槛，提升计算宇宙学中的人机协作效率。

Method: 结合多代理LLM编排、语义搜索和实时Python执行环境。

Result: 开发了一个用户友好的Web应用，支持CLASS的问答、代码生成和错误调试。

Conclusion: CLAPP有效提升了研究人员的工作效率，促进了人机协作。

Abstract: We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI
assistant designed to support researchers working with the Einstein-Boltzmann
solver CLASS. CLAPP leverages large language models (LLMs) and domain-specific
retrieval to provide conversational coding support for CLASS-answering
questions, generating code, debugging errors, and producing plots. Its
architecture combines multi-agent LLM orchestration, semantic search across
CLASS documentation, and a live Python execution environment. Deployed as a
user-friendly web application, CLAPP lowers the entry barrier for scientists
unfamiliar with AI tools and enables more productive human-AI collaboration in
computational and numerical cosmology. The app is available at
https://classclapp.streamlit.app

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [325] [Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding](https://arxiv.org/abs/2508.05844)
*François Bachoc,Nicolò Cesa-Bianchi,Tommaso Cesari,Roberto Colomboni*

Main category: cs.GT

TL;DR: 论文提出了一种随机多臂老虎机模型，用于解决预算分配问题，设计了算法并证明了其遗憾界。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于众包和自动竞价中的预算分配问题，需要将固定预算分配到多个任务或拍卖中。

Method: 定义了一个基于概率单纯形的随机老虎机模型，设计了一种算法，其遗憾界为$K\sqrt{T}$（对数因子内）。

Result: 算法在$T$步后的期望遗憾为$K\sqrt{T}$，并在满足额外递减回报条件时提升至$K (\log T)^2$。

Conclusion: 论文为预算分配问题提供了高效的算法和理论保证，适用于众包和自动竞价等场景。

Abstract: Motivated by applications in crowdsourcing, where a fixed sum of money is
split among $K$ workers, and autobidding, where a fixed budget is used to bid
in $K$ simultaneous auctions, we define a stochastic bandit model where arms
belong to the $K$-dimensional probability simplex and represent the fraction of
budget allocated to each task/auction. The reward in each round is the sum of
$K$ stochastic rewards, where each of these rewards is unlocked with a
probability that varies with the fraction of the budget allocated to that
task/auction. We design an algorithm whose expected regret after $T$ steps is
of order $K\sqrt{T}$ (up to log factors) and prove a matching lower bound.
Improved bounds of order $K (\log T)^2$ are shown when the function mapping
budget to probability of unlocking the reward (i.e., terminating the task or
winning the auction) satisfies additional diminishing-returns conditions.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [326] [Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms](https://arxiv.org/abs/2508.06383)
*Rashid Barket,Matthew England,Jürgen Gerhard*

Main category: cs.SC

TL;DR: 论文提出了一种基于机器学习的符号不定积分算法选择方法，通过树状深度学习模型分两阶段优化方法选择和结果复杂度排序，显著提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统计算机代数系统（如Maple）在符号不定积分中选择算法时缺乏对问题实例的针对性，导致效率低下。

Method: 采用两阶段机器学习架构：首先识别适用于给定问题的方法，然后按预测的输出复杂度排序。数学表达式以树结构表示，优于序列表示。

Result: 在70,000个测试用例中，模型选择最优方法的准确率接近90%，并在Maple内部测试集上表现出强泛化能力。

Conclusion: 研究强调了数据表示和问题框架在符号计算中的重要性，该方法可推广到数学软件中的其他优化问题。

Abstract: Symbolic indefinite integration in Computer Algebra Systems such as Maple
involves selecting the most effective algorithm from multiple available
methods. Not all methods will succeed for a given problem, and when several do,
the results, though mathematically equivalent, can differ greatly in
presentation complexity. Traditionally, this choice has been made with minimal
consideration of the problem instance, leading to inefficiencies.
  We present a machine learning (ML) approach using tree-based deep learning
models within a two-stage architecture: first identifying applicable methods
for a given instance, then ranking them by predicted output complexity.
Furthermore, we find representing mathematical expressions as tree structures
significantly improves performance over sequence-based representations, and our
two-stage framework outperforms alternative ML formulations.
  Using a diverse dataset generated by six distinct data generators, our models
achieve nearly 90% accuracy in selecting the optimal method on a 70,000 example
holdout test set. On an independent out-of-distribution benchmark from Maple's
internal test suite, our tree transformer model maintains strong
generalisation, outperforming Maple's built-in selector and prior ML
approaches.
  These results highlight the critical role of data representation and problem
framing in ML for symbolic computation, and we expect our methodology to
generalise effectively to similar optimisation problems in mathematical
software.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [327] [Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows](https://arxiv.org/abs/2508.05744)
*Aizhan Akhmetzhanova,Carolina Cuesta-Lazaro,Siddharth Mishra-Sharma*

Main category: astro-ph.CO

TL;DR: 提出了一种结合尺度依赖神经统计量和归一化流的新框架，用于通过贝叶斯证据估计检测宇宙学模拟中的模型错误。


<details>
  <summary>Details</summary>
Motivation: 当前和未来的宇宙学调查将产生大量高维数据，需要高保真模拟来建模物理过程和系统效应，但验证理论模型是否准确描述观测数据仍具挑战性。

Method: 通过将尺度依赖的神经网络模型与归一化流结合，压缩数据并估计贝叶斯证据，系统识别理论模型在数据中的失效点。

Result: 在CAMELS模拟套件中的物质和气体密度场上验证了方法的有效性。

Conclusion: 提出的框架能有效检测模型错误，为宇宙学数据验证提供了新工具。

Abstract: Current and upcoming cosmological surveys will produce unprecedented amounts
of high-dimensional data, which require complex high-fidelity forward
simulations to accurately model both physical processes and systematic effects
which describe the data generation process. However, validating whether our
theoretical models accurately describe the observed datasets remains a
fundamental challenge. An additional complexity to this task comes from
choosing appropriate representations of the data which retain all the relevant
cosmological information, while reducing the dimensionality of the original
dataset. In this work we present a novel framework combining scale-dependent
neural summary statistics with normalizing flows to detect model
misspecification in cosmological simulations through Bayesian evidence
estimation. By conditioning our neural network models for data compression and
evidence estimation on the smoothing scale, we systematically identify where
theoretical models break down in a data-driven manner. We demonstrate a first
application to our approach using matter and gas density fields from three
CAMELS simulation suites with different subgrid physics implementations.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [328] [A Humanoid Social Robot as a Teaching Assistant in the Classroom](https://arxiv.org/abs/2508.05646)
*Thomas Sievers*

Main category: cs.HC

TL;DR: 社交机器人Pepper结合ChatGPT在高中课堂中用于教学，学生对其接受度和实用性持积极态度。


<details>
  <summary>Details</summary>
Motivation: 探索社交机器人在教育中的潜力，以减轻教师负担并增强多模态学习环境。

Method: 使用Pepper机器人结合ChatGPT教授新内容，测试技术可行性并调查学生接受度。

Result: 学生对机器人教学材料的呈现感到满意，认为其使用有意义。

Conclusion: 社交机器人在教育中具有潜力，可作为教师的有益辅助工具。

Abstract: Although innovation and the support of new technologies are much needed to
ease the burden on the education system, social robots in schools to help
teachers with educational tasks are rare. Child-Robot Interaction (CRI) could
support teachers and add an embodied social component to modern multi-modal and
multi-sensory learning environments already in use. The social robot Pepper,
connected to the Large Language Model (LLM) ChatGPT, was used in a high school
classroom to teach new learning content to groups of students. I tested the
technical possibilities with the robot on site and asked the students about
their acceptance and perceived usefulness of teaching with the help of a social
robot. All participants felt that the robot's presentation of the learning
material was appropriate or at least partially appropriate and that its use
made sense.

</details>


### [329] [Automated Visualization Makeovers with LLMs](https://arxiv.org/abs/2508.05637)
*Siddharth Gangwar,David A. Selby,Sebastian J. Vollmer*

Main category: cs.HC

TL;DR: 利用多模态大语言模型（LLMs）通过提示工程半自动化生成对数据可视化的改进建议，帮助用户提升图表质量。


<details>
  <summary>Details</summary>
Motivation: 数据可视化改进通常依赖社区反馈，但这一过程未被纳入数据科学教学。研究探索LLMs能否模拟这一任务，提供自动化改进建议。

Method: 基于预训练模型，结合用户指定的可视化最佳实践指南，通过提示工程生成对现有图表的批评和改进建议。

Result: 定量评估显示LLM代理对不同图表类型的问题具有敏感性，工具以简单自托管应用形式提供。

Conclusion: LLMs可有效辅助数据可视化改进，工具具有实际应用潜力。

Abstract: Making a good graphic that accurately and efficiently conveys the desired
message to the audience is both an art and a science, typically not taught in
the data science curriculum. Visualisation makeovers are exercises where the
community exchange feedback to improve charts and data visualizations. Can
multi-modal large language models (LLMs) emulate this task? Given a plot in the
form of an image file, or the code used to generate it, an LLM, primed with a
list of visualization best practices, is employed to semi-automatically
generate constructive criticism to produce a better plot. Our system is centred
around prompt engineering of a pre-trained model, relying on a combination of
userspecified guidelines and any latent knowledge of data visualization
practices that might lie within an LLMs training corpus. Unlike other works,
the focus is not on generating valid visualization scripts from raw data or
prompts, but on educating the user how to improve their existing data
visualizations according to an interpretation of best practices. A quantitative
evaluation is performed to measure the sensitivity of the LLM agent to various
plotting issues across different chart types. We make the tool available as a
simple self-hosted applet with an accessible Web interface.

</details>


### [330] [Modeling Interactive Narrative Systems: A Formal Approach](https://arxiv.org/abs/2508.05653)
*Jules Clerc,Domitile Lourdeaux,Mohamed Sallak,Johann Barbier,Marc Ravaine*

Main category: cs.HC

TL;DR: 本文提出了一种用于交互式叙事系统（INS）的形式化表示框架，旨在解决研究分散和系统表示多样的问题，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 交互式叙事系统（INS）的研究因分散和多样化的表示方式而面临挑战，需要一种统一的框架来促进分析和比较。

Method: 提出了一种形式化表示框架，基于现有技术，提供一致的词汇和建模结构。

Result: 在“小红帽”场景中的实验验证了该框架的有效性，并展示了其对改进INS评估的积极影响。

Conclusion: 该框架为INS研究社区提供了一种促进协作和一致性的方法，有望推动领域发展。

Abstract: Interactive Narrative Systems (INS) have revolutionized digital experiences
by empowering users to actively shape their stories, diverging from traditional
passive storytelling. However, the field faces challenges due to fragmented
research efforts and diverse system representations. This paper introduces a
formal representation framework for INS, inspired by diverse approaches from
the state of the art. By providing a consistent vocabulary and modeling
structure, the framework facilitates the analysis, the description and
comparison of INS properties. Experimental validations on the "Little Red
Riding Hood" scenario highlight the usefulness of the proposed formalism and
its impact on improving the evaluation of INS. This work aims to foster
collaboration and coherence within the INS research community by proposing a
methodology for formally representing these systems.

</details>


### [331] [Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction](https://arxiv.org/abs/2508.05913)
*Stefan Pasch,Min Chul Cha*

Main category: cs.HC

TL;DR: 研究发现，AI伦理原则（如公平性、透明性）与用户满意度正相关，但关联强度因用户类型和产品类型而异。


<details>
  <summary>Details</summary>
Motivation: 探讨AI伦理原则是否被用户认可、重视并影响其满意度。

Method: 分析超过10万条AI产品的用户评论，使用基于Transformer的语言模型测量七个伦理维度的情感。

Result: 所有七个伦理维度均与用户满意度正相关，非技术用户和终端应用用户的关联更强。

Conclusion: 强调从用户视角设计伦理AI的重要性，需考虑用户角色和产品类型的差异。

Abstract: As AI systems become increasingly embedded in organizational workflows and
consumer applications, ethical principles such as fairness, transparency, and
robustness have been widely endorsed in policy and industry guidelines.
However, there is still scarce empirical evidence on whether these principles
are recognized, valued, or impactful from the perspective of users. This study
investigates the link between ethical AI and user satisfaction by analyzing
over 100,000 user reviews of AI products from G2. Using transformer-based
language models, we measure sentiment across seven ethical dimensions defined
by the EU Ethics Guidelines for Trustworthy AI. Our findings show that all
seven dimensions are positively associated with user satisfaction. Yet, this
relationship varies systematically across user and product types. Technical
users and reviewers of AI development platforms more frequently discuss
system-level concerns (e.g., transparency, data governance), while
non-technical users and reviewers of end-user applications emphasize
human-centric dimensions (e.g., human agency, societal well-being). Moreover,
the association between ethical AI and user satisfaction is significantly
stronger for non-technical users and end-user applications across all
dimensions. Our results highlight the importance of ethical AI design from
users' perspectives and underscore the need to account for contextual
differences across user roles and product types.

</details>


### [332] [ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation](https://arxiv.org/abs/2508.06065)
*Daniel Lee,Nikhil Sharma,Donghoon Shin,DaEun Choi,Harsh Sharma,Jeonghwan Kim,Heng Ji*

Main category: cs.HC

TL;DR: ThematicPlane系统通过交互式主题设计平面帮助用户操控高级语义概念（如情绪、风格或叙事基调），弥合创意意图与系统控制之间的差距。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使图像创作更易用，但非专家用户仍难以精确表达创意意图，现有工具限制了流畅探索。

Method: 引入ThematicPlane系统，支持用户在交互式主题设计平面中导航和操控语义概念。

Result: 探索性研究（N=6）显示，用户能通过系统进行发散和收敛式创作，但需更透明的控制机制。

Conclusion: ThematicPlane支持迭代式创意流程，为生成式设计工具提供了语义驱动交互的新方向。

Abstract: Generative AI has made image creation more accessible, yet aligning outputs
with nuanced creative intent remains challenging, particularly for non-experts.
Existing tools often require users to externalize ideas through prompts or
references, limiting fluid exploration. We introduce ThematicPlane, a system
that enables users to navigate and manipulate high-level semantic concepts
(e.g., mood, style, or narrative tone) within an interactive thematic design
plane. This interface bridges the gap between tacit creative intent and system
control. In our exploratory study (N=6), participants engaged in divergent and
convergent creative modes, often embracing unexpected results as inspiration or
iteration cues. While they grounded their exploration in familiar themes,
differing expectations of how themes mapped to outputs revealed a need for more
explainable controls. Overall, ThematicPlane fosters expressive, iterative
workflows and highlights new directions for intuitive, semantics-driven
interaction in generative design tools.

</details>


### [333] [REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition](https://arxiv.org/abs/2508.05933)
*Xueyuan Xu,Wenjia Dong,Fulin Wei,Li Zhuo*

Main category: cs.HC

TL;DR: 提出了一种基于自适应正交非负矩阵分解的EEG特征选择方法，用于处理多维情绪识别中的标签缺失问题，提高了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多维情绪识别中，多类型EEG特征的高维性和高质量样本的稀缺性导致分类器过拟合和实时性能不佳，且标签缺失问题常见。

Method: 结合自适应正交非负矩阵分解、最小二乘回归和图流形学习正则化，实现标签重建和特征选择。

Result: 在DREAMER、DEAP和HDED数据集上，该方法优于13种先进特征选择方法。

Conclusion: 该方法有效解决了标签缺失问题，提升了多维情绪识别的鲁棒性。

Abstract: The affective brain-computer interface is a crucial technology for affective
interaction and emotional intelligence, emerging as a significant area of
research in the human-computer interaction. Compared to single-type features,
multi-type EEG features provide a multi-level representation for analyzing
multi-dimensional emotions. However, the high dimensionality of multi-type EEG
features, combined with the relatively small number of high-quality EEG
samples, poses challenges such as classifier overfitting and suboptimal
real-time performance in multi-dimensional emotion recognition. Moreover,
practical applications of affective brain-computer interface frequently
encounters partial absence of multi-dimensional emotional labels due to the
open nature of the acquisition environment, and ambiguity and variability in
individual emotion perception. To address these challenges, this study proposes
a novel EEG feature selection method for missing multi-dimensional emotion
recognition. The method leverages adaptive orthogonal non-negative matrix
factorization to reconstruct the multi-dimensional emotional label space
through second-order and higher-order correlations, which could reduce the
negative impact of missing values and outliers on label reconstruction.
Simultaneously, it employs least squares regression with graph-based manifold
learning regularization and global feature redundancy minimization
regularization to enable EEG feature subset selection despite missing
information, ultimately achieving robust EEG-based multi-dimensional emotion
recognition. Simulation experiments on three widely used multi-dimensional
emotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method
outperforms thirteen advanced feature selection methods in terms of robustness
for EEG emotional feature selection.

</details>


### [334] [ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection](https://arxiv.org/abs/2508.05934)
*Xueyuan Xu,Tianze Yu,Wenjia Dong,Fulin Wei,Li Zhuo*

Main category: cs.HC

TL;DR: 论文提出了一种名为ASLSL的新方法，用于处理不完整多模态生理信号的特征选择问题，通过共享潜在结构学习来减少缺失信息的影响。


<details>
  <summary>Details</summary>
Motivation: 多模态生理信号情绪识别中，高维特征常包含无关、冗余和噪声信息，导致分类器性能下降。现有方法假设数据完整，但实际数据常不完整。

Method: 提出ASLSL方法，利用相似特征共享相似情绪标签的特性，学习共享潜在空间以减少缺失信息的影响。

Result: 在DEAP和DREAMER数据集上，ASLSL优于17种特征选择方法。

Conclusion: ASLSL能有效处理不完整多模态生理信号的特征选择问题，提升情绪识别性能。

Abstract: Recently, multi-modal physiological signals based emotion recognition has
garnered increasing attention in the field of brain-computer interfaces.
Nevertheness, the associated multi-modal physiological features are often
high-dimensional and inevitably include irrelevant, redundant, and noisy
representation, which can easily lead to overfitting, poor performance, and
high computational complexity in emotion classifiers. Feature selection has
been widely applied to address these challenges. However, previous studies
generally assumed that multi-modal physiological data are complete, whereas in
reality, the data are often incomplete due to the openness of the acquisition
and operational environment. For example, a part of samples are available in
several modalities but not in others. To address this issue, we propose a novel
method for incomplete multi-modal physiological signal feature selection called
adaptive shared latent structure learning (ASLSL). Based on the property that
similar features share similar emotional labels, ASLSL employs adaptive shared
latent structure learning to explore a common latent space shared for
incomplete multi-modal physiological signals and multi-dimensional emotional
labels, thereby mitigating the impact of missing information and mining
consensus information. Two most popular multi-modal physiological emotion
datasets (DEAP and DREAMER) with multi-dimensional emotional labels were
utilized to compare the performance between compare ASLSL and seventeen feature
selection methods. Comprehensive experimental results on these datasets
demonstrate the effectiveness of ASLSL.

</details>


### [335] [Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning](https://arxiv.org/abs/2508.06000)
*Wei Xiang,Ziyue Lei,Haoyuan Che,Fangyuan Ye,Xueting Wu,Lingyun Sun*

Main category: cs.HC

TL;DR: 论文探讨了如何通过LLM驱动的动觉辅助提升操作技能学习，提出了一种"对齐-分析-调整"策略，并开发了FlightAxis工具，结合EMS技术用于飞行技能训练，结果显示用户接受度高且任务完成时间显著减少。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练助手主要提供文本反馈，忽视了动觉反馈的重要性，限制了操作技能学习的效果。本研究旨在填补这一空白，探索LLM驱动的动觉辅助在操作技能学习中的潜力。

Method: 提出"Align-Analyze-Adjust"策略，开发FlightAxis工具，结合LLM与EMS技术，用于飞行技能训练，指导前臂动作。

Result: 用户对LLM驱动的身体控制接受度高，任务完成时间显著减少；动觉辅助增强了操作缺陷意识并提升了训练参与度。

Conclusion: 研究表明，动觉LLM训练在操作技能学习中具有潜力，能够提升学习效果和用户参与度。

Abstract: Operational skill learning, inherently physical and reliant on hands-on
practice and kinesthetic feedback, has yet to be effectively replicated in
large language model (LLM)-supported training. Current LLM training assistants
primarily generate customized textual feedback, neglecting the crucial
kinesthetic modality. This gap derives from the textual and uncertain nature of
LLMs, compounded by concerns on user acceptance of LLM driven body control. To
bridge this gap and realize the potential of collaborative human-LLM action,
this work explores human experience of LLM driven kinesthetic assistance.
Specifically, we introduced an "Align-Analyze-Adjust" strategy and developed
FlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS)
for flight skill acquisition, a representative operational skill domain.
FlightAxis learns flight skills from manuals and guides forearm movements
during simulated flight tasks. Our results demonstrate high user acceptance of
LLM-mediated body control and significantly reduced task completion times.
Crucially, trainees reported that this kinesthetic assistance enhanced their
awareness of operation flaws and fostered increased engagement in the training
process, rather than relieving perceived load. This work demonstrated the
potential of kinesthetic LLM training in operational skill acquisition.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [336] [A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges](https://arxiv.org/abs/2508.06401)
*Andrew Brown,Muhammad Roman,Barry Devereux*

Main category: cs.DL

TL;DR: 本文对2020年至2025年5月间高引用的检索增强生成（RAG）研究进行了系统性综述，分析了128篇文献，总结了数据集、架构、评估方法及RAG的优缺点。


<details>
  <summary>Details</summary>
Motivation: 通过综述高引用文献，明确RAG的研究现状、方法学缺陷及未来研究方向。

Method: 基于PRISMA 2020框架，设定文献纳入标准，分析数据集、架构和评估实践，并综合RAG的有效性与局限性。

Result: 总结了RAG的当前研究情况，指出了方法学上的不足，并提出了未来研究的重点方向。

Conclusion: RAG结合了神经检索器和生成模型，具有潜力，但仍需进一步研究以解决现有局限性。

Abstract: This systematic review of the research literature on retrieval-augmented
generation (RAG) provides a focused analysis of the most highly cited studies
published between 2020 and May 2025. A total of 128 articles met our inclusion
criteria. The records were retrieved from ACM Digital Library, IEEE Xplore,
Scopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP).
RAG couples a neural retriever with a generative language model, grounding
output in up-to-date, non-parametric memory while retaining the semantic
generalisation stored in model weights. Guided by the PRISMA 2020 framework, we
(i) specify explicit inclusion and exclusion criteria based on citation count
and research questions, (ii) catalogue datasets, architectures, and evaluation
practices, and (iii) synthesise empirical evidence on the effectiveness and
limitations of RAG. To mitigate citation-lag bias, we applied a lower
citation-count threshold to papers published in 2025 so that emerging
breakthroughs with naturally fewer citations were still captured. This review
clarifies the current research landscape, highlights methodological gaps, and
charts priority directions for future research.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [337] [Numerical Considerations in Weighted Model Counting](https://arxiv.org/abs/2508.06264)
*Randal E. Bryant*

Main category: math.NA

TL;DR: 本文提出了一种结合多种数值表示的方法，用于高效计算加权模型计数，并保证用户指定的精度。通过扩展范围双精度（ERD）和区间浮点算术与有理算术的结合，解决了传统方法的精度和效率问题。


<details>
  <summary>Details</summary>
Motivation: 加权模型计数在概率推理和定量风险评估等领域有广泛应用，但传统方法使用浮点算术可能导致结果不准确，而有理算术则效率低下。本文旨在解决这一问题。

Method: 结合扩展范围双精度（ERD）和区间浮点算术与有理算术，以高效计算加权模型计数并保证精度。

Result: 实验证明，该方法在处理具有挑战性的公式和权重分配时表现出鲁棒性，能够避免传统方法的溢出和精度损失问题。

Conclusion: 通过结合多种数值表示，本文提供了一种高效且精度可控的加权模型计数方法，适用于复杂场景。

Abstract: Weighted model counting computes the sum of the rational-valued weights
associated with the satisfying assignments for a Boolean formula, where the
weight of an assignment is given by the product of the weights assigned to the
positive and negated variables comprising the assignment. Weighted model
counting finds applications across a variety of domains including probabilistic
reasoning and quantitative risk assessment.
  Most weighted model counting programs operate by (explicitly or implicitly)
converting the input formula into a form that enables arithmetic evaluation,
using multiplication for conjunctions and addition for disjunctions. Performing
this evaluation using floating-point arithmetic can yield inaccurate results,
and it cannot quantify the level of precision achieved. Computing with rational
arithmetic gives exact results, but it is costly in both time and space.
  This paper describes how to combine multiple numeric representations to
efficiently compute weighted model counts that are guaranteed to achieve a
user-specified precision. When all weights are nonnegative, we prove that the
precision loss of arithmetic evaluation using floating-point arithmetic can be
tightly bounded. We show that supplementing a standard IEEE double-precision
representation with a separate 64-bit exponent, a format we call extended-range
double (ERD), avoids the underflow and overflow issues commonly encountered in
weighted model counting. For problems with mixed negative and positive weights,
we show that a combination of interval floating-point arithmetic and rational
arithmetic can achieve the twin goals of efficiency and guaranteed precision.
For our evaluations, we have devised especially challenging formulas and weight
assignments, demonstrating the robustness of our approach.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [338] [Identity Increases Stability in Neural Cellular Automata](https://arxiv.org/abs/2508.06389)
*James Stovold*

Main category: cs.NE

TL;DR: 通过引入带有简单约束的'identity'层，提高了神经细胞自动机（NCA）生成的人工生物的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决NCA生成生物在生长过程中边界不稳定、形状难以维持的问题。

Method: 在训练过程中引入'identity'层，并施加简单约束。

Result: 改进后的NCA模型在生物生长稳定性上表现更好，且仅需单一'identity'值即可实现。

Conclusion: 为研究NCA生成生物间的互动奠定了基础，为人工生物的细胞层面社会行为研究提供了可能。

Abstract: Neural Cellular Automata (NCAs) offer a way to study the growth of
two-dimensional artificial organisms from a single seed cell. From the outset,
NCA-grown organisms have had issues with stability, their natural boundary
often breaking down and exhibiting tumour-like growth or failing to maintain
the expected shape. In this paper, we present a method for improving the
stability of NCA-grown organisms by introducing an 'identity' layer with simple
constraints during training.
  Results show that NCAs grown in close proximity are more stable compared with
the original NCA model. Moreover, only a single identity value is required to
achieve this increase in stability. We observe emergent movement from the
stable organisms, with increasing prevalence for models with multiple identity
values.
  This work lays the foundation for further study of the interaction between
NCA-grown organisms, paving the way for studying social interaction at a
cellular level in artificial organisms.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [339] [Random Walk Learning and the Pac-Man Attack](https://arxiv.org/abs/2508.05663)
*Xingran Chen,Parimal Parag,Rohit Bhagat,Zonghong Liu,Salim El Rouayheb*

Main category: stat.ML

TL;DR: 论文研究了随机游走（RW）算法在分布式系统中的安全性问题，提出了一种名为“Pac-Man”的攻击方式，并设计了Average Crossing（AC）算法来应对。


<details>
  <summary>Details</summary>
Motivation: 随机游走算法因其低开销和可扩展性在分布式系统中广泛应用，但其依赖本地交互的特性使其易受恶意行为攻击。

Method: 提出AC算法，通过复制随机游走来防止RW灭绝，并进行了理论分析和实验验证。

Result: 理论证明AC算法能保持RW数量有界，且随机梯度下降仍收敛；实验验证了AC算法的有效性，并发现灭绝概率存在相变现象。

Conclusion: AC算法能有效抵御Pac-Man攻击，为分布式学习提供了安全保障。

Abstract: Random walk (RW)-based algorithms have long been popular in distributed
systems due to low overheads and scalability, with recent growing applications
in decentralized learning. However, their reliance on local interactions makes
them inherently vulnerable to malicious behavior. In this work, we investigate
an adversarial threat that we term the ``Pac-Man'' attack, in which a malicious
node probabilistically terminates any RW that visits it. This stealthy behavior
gradually eliminates active RWs from the network, effectively halting the
learning process without triggering failure alarms. To counter this threat, we
propose the Average Crossing (AC) algorithm--a fully decentralized mechanism
for duplicating RWs to prevent RW extinction in the presence of Pac-Man. Our
theoretical analysis establishes that (i) the RW population remains almost
surely bounded under AC and (ii) RW-based stochastic gradient descent remains
convergent under AC, even in the presence of Pac-Man, with a quantifiable
deviation from the true optimum. Our extensive empirical results on both
synthetic and real-world datasets corroborate our theoretical findings.
Furthermore, they uncover a phase transition in the extinction probability as a
function of the duplication threshold. We offer theoretical insights by
analyzing a simplified variant of the AC, which sheds light on the observed
phase transition.

</details>


### [340] [Reduction Techniques for Survival Analysis](https://arxiv.org/abs/2508.05715)
*Johannes Piller,Léa Orsini,Simon Wiegrebe,John Zobolas,Lukas Burk,Sophie Hanna Langbein,Philip Studener,Markus Goeswein,Andreas Bender*

Main category: stat.ML

TL;DR: 论文讨论了生存分析中的“降维技术”，将生存任务转化为回归或分类任务，同时保留生存数据的特性，便于机器学习应用。


<details>
  <summary>Details</summary>
Motivation: 简化生存分析任务，使其能够利用标准的机器学习和深度学习工具，而无需定制学习器。

Method: 概述了多种降维技术，并实现了部分技术以集成到标准机器学习流程中。

Result: 通过示例和基准测试比较了这些技术与现有生存分析方法的预测性能。

Conclusion: 降维技术为生存分析提供了灵活且高效的解决方案，适用于多种生存任务。

Abstract: In this work, we discuss what we refer to as reduction techniques for
survival analysis, that is, techniques that "reduce" a survival task to a more
common regression or classification task, without ignoring the specifics of
survival data. Such techniques particularly facilitate machine learning-based
survival analysis, as they allow for applying standard tools from machine and
deep learning to many survival tasks without requiring custom learners. We
provide an overview of different reduction techniques and discuss their
respective strengths and weaknesses. We also provide a principled
implementation of some of these reductions, such that they are directly
available within standard machine learning workflows. We illustrate each
reduction using dedicated examples and perform a benchmark analysis that
compares their predictive performance to established machine learning methods
for survival analysis.

</details>


### [341] [Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory](https://arxiv.org/abs/2508.05764)
*Arvind K. Saibaba,Ilse C. F. Ipsen*

Main category: stat.ML

TL;DR: 提出一种蒙特卡洛估计器，用于最小化依赖于参数θ的矩阵A(θ)的迹，并确定采样量以确保估计器的后向误差高概率有界。


<details>
  <summary>Details</summary>
Motivation: 研究非线性依赖于参数的矩阵的迹最小化问题，提出高效且可靠的蒙特卡洛估计方法。

Method: 基于ε-网和泛型链的两种边界方法，分析采样量的确定及其对矩阵维度的依赖性。

Result: ε-网边界易于计算且常数明确，而泛型链边界在特殊情况下可能更优但难以评估。

Conclusion: 两种边界方法各有优劣，ε-网更实用，泛型链在特定情况下可能更优。

Abstract: We consider matrices $\boldsymbol{A}(\boldsymbol\theta)\in\mathbb{R}^{m\times
m}$ that depend, possibly nonlinearly, on a parameter $\boldsymbol\theta$ from
a compact parameter space $\Theta$. We present a Monte Carlo estimator for
minimizing $\text{trace}(\boldsymbol{A}(\boldsymbol\theta))$ over all
$\boldsymbol\theta\in\Theta$, and determine the sampling amount so that the
backward error of the estimator is bounded with high probability. We derive two
types of bounds, based on epsilon nets and on generic chaining. Both types
predict a small sampling amount for matrices
$\boldsymbol{A}(\boldsymbol\theta)$ with small offdiagonal mass, and parameter
spaces $\Theta$ of small ``size.'' Dependence on the matrix dimension~$m$ is
only weak or not explicit. The bounds based on epsilon nets are easier to
evaluate and come with fully specified constants. In contrast, the bounds based
on chaining depend on the Talagrand functionals which are difficult to
evaluate, except in very special cases. Comparisons between the two types of
bounds are difficult, although the literature suggests that chaining bounds can
be superior.

</details>


### [342] [Lightweight Auto-bidding based on Traffic Prediction in Live Advertising](https://arxiv.org/abs/2508.06069)
*Bo Yang,Ruixuan Luo,Junqi Jin,Han Zhu*

Main category: stat.ML

TL;DR: 提出了一种轻量级竞价算法BiCB，结合数学分析和未来流量统计方法，解决了实时竞价和未来流量未知的难题，性能优越且工程成本低。


<details>
  <summary>Details</summary>
Motivation: 直播广告需要实时竞价（秒级控制）且面临未来流量未知的挑战，现有方法要么未考虑完整时间流量，要么计算复杂度过高。

Method: 提出BiCB算法，结合最优竞价公式和未来流量估计的统计方法，通过低复杂度解决方案逼近最优结果。

Result: 离线和在线实验证明BiCB性能优越且工程成本低。

Conclusion: BiCB是一种高效、低复杂度的实时竞价算法，适用于直播广告场景。

Abstract: Internet live streaming is widely used in online entertainment and
e-commerce, where live advertising is an important marketing tool for anchors.
An advertising campaign hopes to maximize the effect (such as conversions)
under constraints (such as budget and cost-per-click). The mainstream control
of campaigns is auto-bidding, where the performance depends on the decision of
the bidding algorithm in each request. The most widely used auto-bidding
algorithms include Proportional-Integral-Derivative (PID) control, linear
programming (LP), reinforcement learning (RL), etc. Existing methods either do
not consider the entire time traffic, or have too high computational
complexity. In this paper, the live advertising has high requirements for
real-time bidding (second-level control) and faces the difficulty of unknown
future traffic. Therefore, we propose a lightweight bidding algorithm Binary
Constrained Bidding (BiCB), which neatly combines the optimal bidding formula
given by mathematical analysis and the statistical method of future traffic
estimation, and obtains good approximation to the optimal result through a low
complexity solution. In addition, we complement the form of upper and lower
bound constraints for traditional auto-bidding modeling and give theoretical
analysis of BiCB. Sufficient offline and online experiments prove BiCB's good
performance and low engineering cost.

</details>


### [343] [Decorrelated feature importance from local sample weighting](https://arxiv.org/abs/2508.06337)
*Benedikt Fröhlich,Alison Durst,Merle Behr*

Main category: stat.ML

TL;DR: 论文提出了一种名为losaw的局部样本加权方法，用于在特征相关性存在时改进机器学习模型的特征重要性评分。


<details>
  <summary>Details</summary>
Motivation: 特征相关性会干扰特征重要性评分的准确性，导致噪声特征得分高于信号特征。

Method: 通过局部样本加权（losaw）方法，结合逆概率加权思想，在模型内部减少目标特征与其他特征的相关性。

Result: losaw在模拟研究中显著提高了特征重要性评分的准确性，并可能提升分布外数据的预测精度。

Conclusion: losaw是一种灵活且有效的方法，可用于改进特征重要性评分，同时平衡解释性与预测性能。

Abstract: Feature importance (FI) statistics provide a prominent and valuable method of
insight into the decision process of machine learning (ML) models, but their
effectiveness has well-known limitations when correlation is present among the
features in the training data. In this case, the FI often tends to be
distributed among all features which are in correlation with the
response-generating signal features. Even worse, if multiple signal features
are in strong correlation with a noise feature, while being only modestly
correlated with one another, this can result in a noise feature having a
distinctly larger FI score than any signal feature. Here we propose local
sample weighting (losaw) which can flexibly be integrated into many ML
algorithms to improve FI scores in the presence of feature correlation in the
training data. Our approach is motivated from inverse probability weighting in
causal inference and locally, within the ML model, uses a sample weighting
scheme to decorrelate a target feature from the remaining features. This
reduces model bias locally, whenever the effect of a potential signal feature
is evaluated and compared to others. Moreover, losaw comes with a natural
tuning parameter, the minimum effective sample size of the weighted population,
which corresponds to an interpretation-prediction-tradeoff, analog to a
bias-variance-tradeoff as for classical ML tuning parameters. We demonstrate
how losaw can be integrated within decision tree-based ML methods and within
mini-batch training of neural networks. We investigate losaw for random forest
and convolutional neural networks in a simulation study on settings showing
diverse correlation patterns. We found that losaw improves FI consistently.
Moreover, it often improves prediction accuracy for out-of-distribution, while
maintaining a similar accuracy for in-distribution test data.

</details>


### [344] [DP-SPRT: Differentially Private Sequential Probability Ratio Tests](https://arxiv.org/abs/2508.06377)
*Thomas Michel,Debabrota Basu,Emilie Kaufmann*

Main category: stat.ML

TL;DR: DP-SPRT是一种在隐私约束下改进Wald序列概率比测试的方法，通过私有机制处理查询序列并在结果超出预设区间时停止，提供误差和样本复杂度的通用上界。


<details>
  <summary>Details</summary>
Motivation: 解决现有工作在隐私约束下进行序列假设测试时的不足，填补了误差概率和隐私约束校准的空白。

Method: 提出DP-SPRT，结合私有机制OutsideInterval处理查询序列，支持多种噪声分布（如Laplace和高斯噪声）。

Result: 理论证明DP-SPRT在误差和样本复杂度上具有通用上界，实验显示其实际性能良好。

Conclusion: DP-SPRT在隐私约束下接近最优，尤其适用于小误差和接近假设的场景。

Abstract: We revisit Wald's celebrated Sequential Probability Ratio Test for sequential
tests of two simple hypotheses, under privacy constraints. We propose DP-SPRT,
a wrapper that can be calibrated to achieve desired error probabilities and
privacy constraints, addressing a significant gap in previous work. DP-SPRT
relies on a private mechanism that processes a sequence of queries and stops
after privately determining when the query results fall outside a predefined
interval. This OutsideInterval mechanism improves upon naive composition of
existing techniques like AboveThreshold, potentially benefiting other
sequential algorithms. We prove generic upper bounds on the error and sample
complexity of DP-SPRT that can accommodate various noise distributions based on
the practitioner's privacy needs. We exemplify them in two settings: Laplace
noise (pure Differential Privacy) and Gaussian noise (R\'enyi differential
privacy). In the former setting, by providing a lower bound on the sample
complexity of any $\epsilon$-DP test with prescribed type I and type II errors,
we show that DP-SPRT is near optimal when both errors are small and the two
hypotheses are close. Moreover, we conduct an experimental study revealing its
good practical performance.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [345] [IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering](https://arxiv.org/abs/2508.06126)
*Jixuan Yin,Zhihao Yao,Wenshuai Huo,Xinmiao Yu,Xiaocheng Feng,Bo Li*

Main category: stat.ME

TL;DR: IOCC是一种新颖的少样本对比学习方法，通过交互增强最优传输和中心感知对比学习模块，优化聚类中心与语义中心的对齐，提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在短文本表示中难以捕捉语义中心，导致聚类效果不佳。

Method: 提出IOCC方法，包含交互增强最优传输（IEOT）和中心感知对比学习（CACL）模块，分别生成伪标签和优化表示。

Result: 在八个基准数据集上表现优异，最高提升7.34%，且聚类稳定性和效率突出。

Conclusion: IOCC通过模块协作缩小聚类中心与语义中心差距，显著提升聚类性能。

Abstract: In clustering tasks, it is essential to structure the feature space into
clear, well-separated distributions. However, because short text
representations have limited expressiveness, conventional methods struggle to
identify cluster centers that truly capture each category's underlying
semantics, causing the representations to be optimized in suboptimal
directions. To address this issue, we propose IOCC, a novel few-shot
contrastive learning method that achieves alignment between the cluster centers
and the semantic centers. IOCC consists of two key modules:
Interaction-enhanced Optimal Transport (IEOT) and Center-aware Contrastive
Learning (CACL). Specifically, IEOT incorporates semantic interactions between
individual samples into the conventional optimal transport problem, and
generate pseudo-labels. Based on these pseudo-labels, we aggregate
high-confidence samples to construct pseudo-centers that approximate the
semantic centers. Next, CACL optimizes text representations toward their
corresponding pseudo-centers. As training progresses, the collaboration between
the two modules gradually reduces the gap between cluster centers and semantic
centers. Therefore, the model will learn a high-quality distribution, improving
clustering performance. Extensive experiments on eight benchmark datasets show
that IOCC outperforms previous methods, achieving up to 7.34\% improvement on
challenging Biomedical dataset and also excelling in clustering stability and
efficiency. The code is available at:
https://anonymous.4open.science/r/IOCC-C438.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [346] [Intuition emerges in Maximum Caliber models at criticality](https://arxiv.org/abs/2508.06477)
*Lluís Arola-Fernández*

Main category: physics.soc-ph

TL;DR: 论文发现预测模型在特定学习阶段会涌现出一种原始直觉，平衡了记忆与探索。


<details>
  <summary>Details</summary>
Motivation: 探讨大型预测模型是否仅模仿训练数据还是能产生真正的洞察力。

Method: 通过mind-tuning方法，结合最大熵原理，研究模型在随机迷宫中的学习行为。

Result: 发现模型在不同参数下表现出模仿、幻觉和直觉三种相态，直觉相态具有多稳态和滞后性。

Conclusion: 直觉是记忆与探索临界平衡的涌现特性。

Abstract: Whether large predictive models merely parrot their training data or produce
genuine insight lacks a physical explanation. This work reports a primitive
form of intuition that emerges as a metastable phase of learning that
critically balances next-token prediction against future path-entropy. The
intuition mechanism is discovered via mind-tuning, the minimal principle that
imposes Maximum Caliber in predictive models with a control temperature-like
parameter $\lambda$. Training on random walks in deterministic mazes reveals a
rich phase diagram: imitation (low $\lambda$), rule-breaking hallucination
(high $\lambda$), and a fragile in-between window exhibiting strong
protocol-dependence (hysteresis) and multistability, where models spontaneously
discover novel goal-directed strategies. These results are captured by an
effective low-dimensional theory and frame intuition as an emergent property at
the critical balance between memorizing what is and wondering what could be.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [347] [Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures](https://arxiv.org/abs/2508.01854)
*Fanze Kong,Chen-Chih Lai,Yubin Lu*

Main category: physics.comp-ph

TL;DR: 提出了一种数据驱动的学习框架，用于识别具有非梯度分量的广义扩散的控制规律。


<details>
  <summary>Details</summary>
Motivation: 研究广义扩散中非梯度漂移的物理规律，特别是伪势和旋转分量的识别。

Method: 结合能量耗散定律和物理一致的惩罚项，设计了两阶段方法，用于恢复伪势和旋转分量。

Result: 在复杂广义扩散过程中（如耗散-旋转动力学、粗糙伪势和噪声数据）验证了方法的有效性。

Conclusion: 该方法能有效学习非梯度广义扩散中的物理规律。

Abstract: This paper proposes a data-driven learning framework for identifying
governing laws of generalized diffusions with non-gradient components. By
combining energy dissipation laws with a physically consistent penalty and
first-moment evolution, we design a two-stage method to recover the
pseudo-potential and rotation in the pointwise orthogonal decomposition of a
class of non-gradient drifts in generalized diffusions. Our two-stage method is
applied to complex generalized diffusion processes including
dissipation-rotation dynamics, rough pseudo-potentials and noisy data.
Representative numerical experiments demonstrate the effectiveness of our
approach for learning physical laws in non-gradient generalized diffusions.

</details>


### [348] [Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements](https://arxiv.org/abs/2508.05908)
*Shreshth A. Malik,Tiarnan A. S. Doherty,Benjamin Colmey,Stephen J. Roberts,Yarin Gal,Paul A. Midgley*

Main category: physics.comp-ph

TL;DR: 提出了一种结合物理模拟与机器学习的混合框架，用于高保真电子显微镜模拟，通过自动微分优化物理参数和神经网络，显著提升了晶体结构精修的精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决传统电子显微镜模拟中实验效应难以建模的问题，提出一种更灵活、可扩展的方法。

Method: 结合可微分物理模拟与神经网络，利用自动微分联合优化物理参数和实验变量，应用于三维电子衍射结构精修。

Result: 在合成和实验数据集上实现了最先进的精修性能，准确恢复了原子位置、热位移和厚度分布。

Conclusion: 该混合建模框架为定量电子显微镜提供了新范式，能够处理传统方法难以解决的实验复杂性。

Abstract: High-fidelity electron microscopy simulations required for quantitative
crystal structure refinements face a fundamental challenge: while physical
interactions are well-described theoretically, real-world experimental effects
are challenging to model analytically. To address this gap, we present a novel
hybrid physics-machine learning framework that integrates differentiable
physical simulations with neural networks. By leveraging automatic
differentiation throughout the simulation pipeline, our method enables
gradient-based joint optimization of physical parameters and neural network
components representing experimental variables, offering superior scalability
compared to traditional second-order methods. We demonstrate this framework
through application to three-dimensional electron diffraction (3D-ED) structure
refinement, where our approach learns complex thickness distributions directly
from diffraction data rather than relying on simplified geometric models. This
method achieves state-of-the-art refinement performance across synthetic and
experimental datasets, recovering atomic positions, thermal displacements, and
thickness profiles with high fidelity. The modular architecture proposed can
naturally be extended to accommodate additional physical phenomena and extended
to other electron microscopy techniques. This establishes differentiable hybrid
modeling as a powerful new paradigm for quantitative electron microscopy, where
experimental complexities have historically limited analysis.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [349] [Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems](https://arxiv.org/abs/2508.05846)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.CY

TL;DR: 论文主张AI决策过程的透明度对构建可信赖且符合伦理的机器人系统至关重要，探讨了透明度的作用、挑战及实现方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI和机器人技术在社会中的普及，确保其伦理行为变得至关重要，透明性是实现这一目标的基础。

Method: 提出了一种结合技术实现与伦理考量的框架，包括标准化指标、可解释AI技术和用户友好界面。

Result: 透明度能提升公众信任、影响监管政策，并为未来研究提供方向。

Conclusion: 将透明度作为伦理AI系统设计的核心要素，为负责任AI和机器人技术的发展提供了指导。

Abstract: As artificial intelligence (AI) and robotics increasingly permeate society,
ensuring the ethical behavior of these systems has become paramount. This paper
contends that transparency in AI decision-making processes is fundamental to
developing trustworthy and ethically aligned robotic systems. We explore how
transparency facilitates accountability, enables informed consent, and supports
the debugging of ethical algorithms. The paper outlines technical, ethical, and
practical challenges in implementing transparency and proposes novel approaches
to enhance it, including standardized metrics, explainable AI techniques, and
user-friendly interfaces. This paper introduces a framework that connects
technical implementation with ethical considerations in robotic systems,
focusing on the specific challenges of achieving transparency in dynamic,
real-world contexts. We analyze how prioritizing transparency can impact public
trust, regulatory policies, and avenues for future research. By positioning
transparency as a fundamental element in ethical AI system design, we aim to
add to the ongoing discussion on responsible AI and robotics, providing
direction for future advancements in this vital field.

</details>


### [350] [Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education](https://arxiv.org/abs/2508.05979)
*Xinming Yang,Haasil Pujara,Jun Li*

Main category: cs.CY

TL;DR: 论文提出了一种新的教学方法，让学生充当教师角色，教导LLM解决问题，以提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统使用LLM作为虚拟导师可能导致学生被动学习和过度依赖，因此需要一种更主动的学习方式。

Method: 设计了带有知识缺口的问题，学生需填补这些缺口；开发了Socrates系统以支持该方法。

Result: 在本科生课程中验证，学生表现显著优于历史对照组。

Conclusion: 该方法为利用LLM提升学生参与度和掌握度提供了实用且经济的框架。

Abstract: While Large Language Models (LLMs) are often used as virtual tutors in
computer science (CS) education, this approach can foster passive learning and
over-reliance. This paper presents a novel pedagogical paradigm that inverts
this model: students act as instructors who must teach an LLM to solve
problems. To facilitate this, we developed strategies for designing questions
with engineered knowledge gaps that only a student can bridge, and we introduce
Socrates, a system for deploying this method with minimal overhead. We
evaluated our approach in an undergraduate course and found that this
active-learning method led to statistically significant improvements in student
performance compared to historical cohorts. Our work demonstrates a practical,
cost-effective framework for using LLMs to deepen student engagement and
mastery.

</details>


### [351] [Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks](https://arxiv.org/abs/2508.06411)
*Ze Shen Chin*

Main category: cs.CY

TL;DR: 论文提出了一种多维框架和因果路径模型，以系统化地分析和缓解六种AI灾难性风险。


<details>
  <summary>Details</summary>
Motivation: 现有关于AI风险的讨论缺乏全面框架和具体因果路径，本文旨在填补这一空白。

Method: 通过七个关键维度（如意图、能力等）描述六种AI风险，并建立从初始危害到最终伤害的逐步路径模型。

Result: 多维框架支持系统性风险识别和通用缓解策略，路径模型则有助于针对具体情景的干预。

Conclusion: 该方法为管理AI灾难性风险提供了更结构化和可操作的基础。

Abstract: Although discourse around the risks of Artificial Intelligence (AI) has
grown, it often lacks a comprehensive, multidimensional framework, and concrete
causal pathways mapping hazard to harm. This paper aims to bridge this gap by
examining six commonly discussed AI catastrophic risks: CBRN, cyber offense,
sudden loss of control, gradual loss of control, environmental risk, and
geopolitical risk. First, we characterize these risks across seven key
dimensions, namely intent, competency, entity, polarity, linearity, reach, and
order. Next, we conduct risk pathway modeling by mapping step-by-step
progressions from the initial hazard to the resulting harms. The dimensional
approach supports systematic risk identification and generalizable mitigation
strategies, while risk pathway models help identify scenario-specific
interventions. Together, these methods offer a more structured and actionable
foundation for managing catastrophic AI risks across the value chain.

</details>
